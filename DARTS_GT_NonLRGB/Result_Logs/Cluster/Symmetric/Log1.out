Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          376Gi        36Gi       216Gi       3.9Gi       122Gi       332Gi
Swap:         1.9Gi       323Mi       1.5Gi
Tue Aug 26 17:58:11 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:1D:00.0 Off |                    0 |
| N/A   49C    P0             74W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 41
Starting training for seed 41...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E/SYYM
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E/SYYM/confignas.yaml
Using device: cuda
2025-08-26 18:00:36,036 - INFO - GPU Mem: 34.1GB
2025-08-26 18:00:36,036 - INFO - Run directory: results/Cluster/Cluster-SparseE-41
2025-08-26 18:00:36,036 - INFO - Seed: 41
2025-08-26 18:00:36,036 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-26 18:00:36,036 - INFO - Routing mode: nas
2025-08-26 18:00:36,036 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-26 18:00:36,036 - INFO - Number of layers: 16
2025-08-26 18:00:36,036 - INFO - Uncertainty enabled: False
2025-08-26 18:00:36,036 - INFO - Training mode: NoMixNas_uncertainty_train
2025-08-26 18:00:36,036 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-26 18:00:36,036 - INFO - Additional features: Router weights logging + JSON export
2025-08-26 18:00:50,174 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-26 18:00:50,176 - INFO -   Data(x=[1406436, 7], edge_index=[2, 51620680], y=[1406436])
2025-08-26 18:00:50,204 - INFO -   undirected: True
2025-08-26 18:00:50,204 - INFO -   num graphs: 12000
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-26 18:00:50,204 - INFO -   avg num_nodes/graph: 117
2025-08-26 18:00:50,204 - INFO -   num node features: 7
2025-08-26 18:00:50,204 - INFO -   num edge features: 0
2025-08-26 18:00:50,206 - INFO -   num classes: 6
2025-08-26 18:00:50,206 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 4, 8, 16]
2025-08-26 18:00:50,206 - INFO - Precomputing Positional Encoding statistics: ['LapPE', 'RWSE'] for all graphs...
2025-08-26 18:00:50,214 - INFO -   ...estimated to be undirected: True
  0%|          | 0/12000 [00:00<?, ?it/s] 16%|█▋        | 1976/12000 [00:10<00:50, 197.58it/s] 33%|███▎      | 3967/12000 [00:20<00:40, 198.42it/s] 50%|█████     | 6050/12000 [00:30<00:29, 202.89it/s] 67%|██████▋   | 8096/12000 [00:40<00:19, 203.54it/s] 84%|████████▍ | 10094/12000 [00:50<00:09, 202.19it/s]100%|██████████| 12000/12000 [00:59<00:00, 202.72it/s]
2025-08-26 18:01:50,108 - INFO - Done! Took 00:00:59.90
2025-08-26 18:01:50,128 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset'
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/nni/nas/nn/pytorch/choice.py:252: UserWarning: "key" is deprecated. Assuming label.
  warnings.warn(f'"key" is deprecated. Assuming label.')
2025-08-26 18:01:50,509 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-26 18:01:50,509 - INFO - Inner model type: <class 'graphgps.network.NAS_model_edge_syym.NASModelEdge'>
2025-08-26 18:01:50,509 - INFO - Inner model has get_darts_model: True
2025-08-26 18:01:50,515 - INFO - GraphGymModule(
  (model): NASModelEdge(
    (encoder): FeatureEncoder(
      (node_encoder): LapPENodeEncoder(
        (linear_x): Linear(in_features=7, out_features=32, bias=True)
        (linear_A): Linear(in_features=2, out_features=32, bias=True)
        (pe_encoder): Sequential(
          (0): ReLU()
          (1): Linear(in_features=32, out_features=16, bias=True)
          (2): ReLU()
        )
      )
      (edge_encoder): DummyEdgeEncoder(
        (encoder): Embedding(1, 48)
      )
    )
    (darts_layers): ModuleList(
      (0): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (6): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_6')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (7): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_7')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (8): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_8')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (9): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_9')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (10): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_10')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (11): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_11')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (12): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_12')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (13): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_13')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (14): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_14')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (15): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_15')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (darts_sequential): Sequential(
      (0): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (6): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_6')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (7): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_7')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (8): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_8')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (9): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_9')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (10): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_10')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (11): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_11')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (12): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_12')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (13): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_13')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (14): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_14')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (15): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_15')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(48, 48, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(48, 48, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(48, 6, bias=True)
          )
        )
      )
    )
  )
)
2025-08-26 18:01:50,525 - INFO - Number of parameters: 728,630
2025-08-26 18:01:50,526 - INFO - Starting optimized training: 2025-08-26 18:01:50.526030
2025-08-26 18:01:55,952 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset':
2025-08-26 18:01:55,952 - INFO -   Data(x=[1406436, 7], edge_index=[2, 51620680], y=[1406436])
2025-08-26 18:01:55,953 - INFO -   undirected: True
2025-08-26 18:01:55,953 - INFO -   num graphs: 12000
2025-08-26 18:01:55,953 - INFO -   avg num_nodes/graph: 117
2025-08-26 18:01:55,954 - INFO -   num node features: 7
2025-08-26 18:01:55,954 - INFO -   num edge features: 0
2025-08-26 18:01:55,955 - INFO -   num classes: 6
2025-08-26 18:01:55,955 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 4, 8, 16]
2025-08-26 18:01:55,955 - INFO - Precomputing Positional Encoding statistics: ['LapPE', 'RWSE'] for all graphs...
2025-08-26 18:01:55,963 - INFO -   ...estimated to be undirected: True
  0%|          | 0/12000 [00:00<?, ?it/s] 17%|█▋        | 2063/12000 [00:10<00:48, 206.18it/s] 35%|███▍      | 4144/12000 [00:20<00:37, 207.28it/s] 52%|█████▏    | 6215/12000 [00:30<00:27, 207.20it/s] 69%|██████▊   | 8232/12000 [00:40<00:18, 205.00it/s] 86%|████████▌ | 10292/12000 [00:50<00:08, 205.31it/s]100%|██████████| 12000/12000 [00:58<00:00, 205.89it/s]
2025-08-26 18:02:54,958 - INFO - Done! Took 00:00:59.00
2025-08-26 18:02:54,982 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset'
2025-08-26 18:02:55,016 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-26 18:02:55,016 - INFO - Start from epoch 0
2025-08-26 18:02:55,017 - INFO - ================================================================================
2025-08-26 18:02:55,017 - INFO - STARTING TWO-PHASE NAS TRAINING
2025-08-26 18:02:55,017 - INFO - ================================================================================
2025-08-26 18:02:55,017 - INFO - Routing mode: nas
2025-08-26 18:02:55,017 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-26 18:02:55,017 - INFO - Phase 1: Architecture search/initialization
2025-08-26 18:02:55,017 - INFO - Phase 2: Discrete training with uncertainty (NO variance)
2025-08-26 18:02:55,017 - INFO - ============================================================
2025-08-26 18:02:55,017 - INFO - PHASE 1: ARCHITECTURE SEARCH/INITIALIZATION
2025-08-26 18:02:55,017 - INFO - ============================================================
2025-08-26 18:02:55,017 - INFO - Splitting dataset for DARTS:
2025-08-26 18:02:55,017 - INFO -   Original train size: 10000
2025-08-26 18:02:55,017 - INFO -   DARTS train size: 6000 (60.0%)
2025-08-26 18:02:55,017 - INFO -   DARTS val size: 4000 (40.0%)
2025-08-26 18:02:55,019 - INFO - Found GraphGym wrapper, using inner model: <class 'graphgps.network.NAS_model_edge_syym.NASModelEdge'>
2025-08-26 18:02:55,019 - INFO - Successfully configured model for DARTS training
2025-08-26 18:02:55,019 - INFO - NAS MODE: Running 25 epochs with DARTS
2025-08-26 18:02:55,019 - INFO - DARTS Configuration:
2025-08-26 18:02:55,019 - INFO -   Epochs: 25
2025-08-26 18:02:55,019 - INFO -   Architecture LR: 0.0004
2025-08-26 18:02:55,019 - INFO -   Grad clip: 5.0
2025-08-26 18:02:55,026 - INFO - Starting DARTS architecture search
2025-08-26 18:02:58,643 - WARNING - Epoch [1/25] Step [1/250]  acc 0.150621 (0.150621)  loss 1.802765 (1.802765)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 3358.0 MB
2025-08-26 18:03:02,893 - WARNING - Epoch [1/25] Step [11/250]  acc 0.160694 (0.174577)  loss 1.795981 (1.794165)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 3460.0 MB
2025-08-26 18:03:07,360 - WARNING - Epoch [1/25] Step [21/250]  acc 0.170492 (0.170280)  loss 1.790938 (1.793203)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 3540.0 MB
2025-08-26 18:03:11,697 - WARNING - Epoch [1/25] Step [31/250]  acc 0.181240 (0.171515)  loss 1.790376 (1.792042)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6798.0 MB
2025-08-26 18:03:15,988 - WARNING - Epoch [1/25] Step [41/250]  acc 0.155031 (0.174372)  loss 1.789731 (1.790912)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6798.0 MB
2025-08-26 18:03:20,288 - WARNING - Epoch [1/25] Step [51/250]  acc 0.202790 (0.176829)  loss 1.783965 (1.789952)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6798.0 MB
2025-08-26 18:03:24,581 - WARNING - Epoch [1/25] Step [61/250]  acc 0.242865 (0.182542)  loss 1.770467 (1.787745)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6798.0 MB
2025-08-26 18:03:28,971 - WARNING - Epoch [1/25] Step [71/250]  acc 0.246880 (0.186829)  loss 1.753932 (1.785006)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6798.0 MB
2025-08-26 18:03:33,323 - WARNING - Epoch [1/25] Step [81/250]  acc 0.244180 (0.192673)  loss 1.741196 (1.780595)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6800.0 MB
2025-08-26 18:03:37,616 - WARNING - Epoch [1/25] Step [91/250]  acc 0.240138 (0.197095)  loss 1.725841 (1.775969)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 6800.0 MB
2025-08-26 18:03:43,116 - WARNING - Epoch [1/25] Step [101/250]  acc 0.262436 (0.202318)  loss 1.730779 (1.771313)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6800.0 MB
2025-08-26 18:03:48,435 - WARNING - Epoch [1/25] Step [111/250]  acc 0.225057 (0.206046)  loss 1.720660 (1.767003)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6800.0 MB
2025-08-26 18:03:53,870 - WARNING - Epoch [1/25] Step [121/250]  acc 0.261315 (0.209816)  loss 1.698846 (1.762304)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 6800.0 MB
2025-08-26 18:03:59,565 - WARNING - Epoch [1/25] Step [131/250]  acc 0.296191 (0.214527)  loss 1.670233 (1.756792)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6800.0 MB
2025-08-26 18:04:04,839 - WARNING - Epoch [1/25] Step [141/250]  acc 0.281972 (0.218169)  loss 1.660725 (1.751020)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6800.0 MB
2025-08-26 18:04:09,593 - WARNING - Epoch [1/25] Step [151/250]  acc 0.240662 (0.220957)  loss 1.680446 (1.745691)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6800.0 MB
2025-08-26 18:04:14,218 - WARNING - Epoch [1/25] Step [161/250]  acc 0.283776 (0.223846)  loss 1.646851 (1.741364)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 6800.0 MB
2025-08-26 18:04:18,564 - WARNING - Epoch [1/25] Step [171/250]  acc 0.262314 (0.226480)  loss 1.663560 (1.736935)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6800.0 MB
2025-08-26 18:04:23,074 - WARNING - Epoch [1/25] Step [181/250]  acc 0.254169 (0.229063)  loss 1.665217 (1.732426)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6800.0 MB
2025-08-26 18:04:28,570 - WARNING - Epoch [1/25] Step [191/250]  acc 0.252987 (0.231336)  loss 1.677883 (1.728461)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6800.0 MB
2025-08-26 18:04:33,780 - WARNING - Epoch [1/25] Step [201/250]  acc 0.256668 (0.233377)  loss 1.676200 (1.724857)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 6800.0 MB
2025-08-26 18:04:39,001 - WARNING - Epoch [1/25] Step [211/250]  acc 0.277484 (0.235390)  loss 1.563023 (1.720357)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 6800.0 MB
2025-08-26 18:04:44,508 - WARNING - Epoch [1/25] Step [221/250]  acc 0.271907 (0.237709)  loss 1.642149 (1.715876)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6800.0 MB
2025-08-26 18:04:49,169 - WARNING - Epoch [1/25] Step [231/250]  acc 0.327541 (0.240311)  loss 1.585309 (1.712129)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6800.0 MB
2025-08-26 18:04:53,432 - WARNING - Epoch [1/25] Step [241/250]  acc 0.296316 (0.242490)  loss 1.588033 (1.708314)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6800.0 MB
Epoch 1 completed in 0:02:02.110307
2025-08-26 18:05:22,617 - WARNING - Epoch [2/25] Step [1/250]  acc 0.298796 (0.298796)  loss 1.619549 (1.619549)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6800.0 MB
2025-08-26 18:05:27,026 - WARNING - Epoch [2/25] Step [11/250]  acc 0.263377 (0.293054)  loss 1.638441 (1.622664)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6800.0 MB
2025-08-26 18:05:31,208 - WARNING - Epoch [2/25] Step [21/250]  acc 0.270642 (0.299224)  loss 1.603728 (1.610829)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 6800.0 MB
2025-08-26 18:05:35,446 - WARNING - Epoch [2/25] Step [31/250]  acc 0.327420 (0.307545)  loss 1.573155 (1.599550)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6800.0 MB
2025-08-26 18:05:39,675 - WARNING - Epoch [2/25] Step [41/250]  acc 0.334004 (0.313018)  loss 1.591650 (1.590290)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6802.0 MB
2025-08-26 18:05:43,931 - WARNING - Epoch [2/25] Step [51/250]  acc 0.271094 (0.314559)  loss 1.595963 (1.586663)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6802.0 MB
2025-08-26 18:05:48,198 - WARNING - Epoch [2/25] Step [61/250]  acc 0.330060 (0.314443)  loss 1.561166 (1.584280)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6802.0 MB
2025-08-26 18:05:52,454 - WARNING - Epoch [2/25] Step [71/250]  acc 0.324507 (0.316078)  loss 1.542936 (1.578714)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 6802.0 MB
2025-08-26 18:05:56,760 - WARNING - Epoch [2/25] Step [81/250]  acc 0.364345 (0.318120)  loss 1.506114 (1.577126)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 6802.0 MB
2025-08-26 18:06:01,037 - WARNING - Epoch [2/25] Step [91/250]  acc 0.325166 (0.319056)  loss 1.554864 (1.573271)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6802.0 MB
2025-08-26 18:06:05,319 - WARNING - Epoch [2/25] Step [101/250]  acc 0.344957 (0.320317)  loss 1.552106 (1.571032)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6802.0 MB
2025-08-26 18:06:09,572 - WARNING - Epoch [2/25] Step [111/250]  acc 0.398364 (0.322068)  loss 1.487370 (1.567655)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 6802.0 MB
2025-08-26 18:06:13,817 - WARNING - Epoch [2/25] Step [121/250]  acc 0.350904 (0.323544)  loss 1.522513 (1.564710)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6802.0 MB
2025-08-26 18:06:18,071 - WARNING - Epoch [2/25] Step [131/250]  acc 0.375448 (0.324548)  loss 1.468175 (1.560861)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6802.0 MB
2025-08-26 18:06:22,313 - WARNING - Epoch [2/25] Step [141/250]  acc 0.330943 (0.325284)  loss 1.506009 (1.559033)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6802.0 MB
2025-08-26 18:06:26,826 - WARNING - Epoch [2/25] Step [151/250]  acc 0.350077 (0.326317)  loss 1.503394 (1.555402)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6802.0 MB
2025-08-26 18:06:31,088 - WARNING - Epoch [2/25] Step [161/250]  acc 0.355809 (0.327311)  loss 1.481051 (1.553689)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6802.0 MB
2025-08-26 18:06:35,394 - WARNING - Epoch [2/25] Step [171/250]  acc 0.355406 (0.327740)  loss 1.458622 (1.550861)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6802.0 MB
2025-08-26 18:06:39,777 - WARNING - Epoch [2/25] Step [181/250]  acc 0.304273 (0.328179)  loss 1.528327 (1.548214)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6802.0 MB
2025-08-26 18:06:44,140 - WARNING - Epoch [2/25] Step [191/250]  acc 0.306818 (0.328620)  loss 1.516454 (1.545048)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6802.0 MB
2025-08-26 18:06:48,460 - WARNING - Epoch [2/25] Step [201/250]  acc 0.344584 (0.329698)  loss 1.433951 (1.541892)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 6802.0 MB
2025-08-26 18:06:52,875 - WARNING - Epoch [2/25] Step [211/250]  acc 0.312290 (0.330111)  loss 1.518528 (1.539626)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6802.0 MB
2025-08-26 18:06:57,409 - WARNING - Epoch [2/25] Step [221/250]  acc 0.322084 (0.330644)  loss 1.511559 (1.537253)
GPU memory consumption  GPU Memory: Allocated: 52.6 MB, Reserved: 6802.0 MB
2025-08-26 18:07:01,893 - WARNING - Epoch [2/25] Step [231/250]  acc 0.345180 (0.331300)  loss 1.502538 (1.534743)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6802.0 MB
2025-08-26 18:07:06,171 - WARNING - Epoch [2/25] Step [241/250]  acc 0.364447 (0.332097)  loss 1.492951 (1.533522)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6802.0 MB
Epoch 2 completed in 0:01:47.841545
2025-08-26 18:07:36,741 - WARNING - Epoch [3/25] Step [1/250]  acc 0.303733 (0.303733)  loss 1.519532 (1.519532)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6802.0 MB
2025-08-26 18:07:40,990 - WARNING - Epoch [3/25] Step [11/250]  acc 0.369488 (0.330455)  loss 1.434861 (1.499600)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6802.0 MB
2025-08-26 18:07:45,230 - WARNING - Epoch [3/25] Step [21/250]  acc 0.340077 (0.342531)  loss 1.520465 (1.484542)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6802.0 MB
2025-08-26 18:07:49,471 - WARNING - Epoch [3/25] Step [31/250]  acc 0.320213 (0.340738)  loss 1.499440 (1.484448)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6802.0 MB
2025-08-26 18:07:53,926 - WARNING - Epoch [3/25] Step [41/250]  acc 0.349404 (0.341148)  loss 1.518292 (1.480569)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6802.0 MB
2025-08-26 18:07:58,161 - WARNING - Epoch [3/25] Step [51/250]  acc 0.325472 (0.342376)  loss 1.475820 (1.477124)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6802.0 MB
2025-08-26 18:08:02,403 - WARNING - Epoch [3/25] Step [61/250]  acc 0.331020 (0.344771)  loss 1.483986 (1.472700)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6802.0 MB
2025-08-26 18:08:06,653 - WARNING - Epoch [3/25] Step [71/250]  acc 0.373769 (0.347038)  loss 1.464865 (1.471625)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 6802.0 MB
2025-08-26 18:08:10,865 - WARNING - Epoch [3/25] Step [81/250]  acc 0.336383 (0.346787)  loss 1.462781 (1.471794)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6802.0 MB
2025-08-26 18:08:15,086 - WARNING - Epoch [3/25] Step [91/250]  acc 0.309935 (0.344933)  loss 1.544121 (1.475089)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 6802.0 MB
2025-08-26 18:08:19,325 - WARNING - Epoch [3/25] Step [101/250]  acc 0.328304 (0.345727)  loss 1.490251 (1.475167)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6802.0 MB
2025-08-26 18:08:23,564 - WARNING - Epoch [3/25] Step [111/250]  acc 0.362808 (0.346063)  loss 1.429666 (1.474077)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6802.0 MB
2025-08-26 18:08:27,794 - WARNING - Epoch [3/25] Step [121/250]  acc 0.339306 (0.345874)  loss 1.475247 (1.473277)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 6802.0 MB
2025-08-26 18:08:32,068 - WARNING - Epoch [3/25] Step [131/250]  acc 0.319494 (0.345434)  loss 1.455283 (1.472713)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6802.0 MB
2025-08-26 18:08:36,283 - WARNING - Epoch [3/25] Step [141/250]  acc 0.325118 (0.345421)  loss 1.525547 (1.473244)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6802.0 MB
2025-08-26 18:08:40,524 - WARNING - Epoch [3/25] Step [151/250]  acc 0.336458 (0.345903)  loss 1.494153 (1.472440)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6802.0 MB
2025-08-26 18:08:44,770 - WARNING - Epoch [3/25] Step [161/250]  acc 0.328358 (0.345852)  loss 1.506864 (1.471760)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6802.0 MB
2025-08-26 18:08:49,032 - WARNING - Epoch [3/25] Step [171/250]  acc 0.351249 (0.345145)  loss 1.483330 (1.472944)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6802.0 MB
2025-08-26 18:08:53,544 - WARNING - Epoch [3/25] Step [181/250]  acc 0.370654 (0.345066)  loss 1.362494 (1.472571)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6802.0 MB
2025-08-26 18:08:57,804 - WARNING - Epoch [3/25] Step [191/250]  acc 0.352218 (0.345189)  loss 1.451640 (1.471146)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6802.0 MB
2025-08-26 18:09:02,071 - WARNING - Epoch [3/25] Step [201/250]  acc 0.387402 (0.345510)  loss 1.401173 (1.470057)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6802.0 MB
2025-08-26 18:09:06,353 - WARNING - Epoch [3/25] Step [211/250]  acc 0.345610 (0.345405)  loss 1.442544 (1.468914)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 6802.0 MB
2025-08-26 18:09:10,601 - WARNING - Epoch [3/25] Step [221/250]  acc 0.368192 (0.345379)  loss 1.411328 (1.467994)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6802.0 MB
2025-08-26 18:09:14,889 - WARNING - Epoch [3/25] Step [231/250]  acc 0.348825 (0.345016)  loss 1.415865 (1.467593)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6802.0 MB
2025-08-26 18:09:19,163 - WARNING - Epoch [3/25] Step [241/250]  acc 0.372183 (0.344988)  loss 1.435909 (1.466746)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6802.0 MB
Epoch 3 completed in 0:01:46.685970
2025-08-26 18:09:49,382 - WARNING - Epoch [4/25] Step [1/250]  acc 0.305630 (0.305630)  loss 1.421673 (1.421673)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6802.0 MB
2025-08-26 18:09:53,639 - WARNING - Epoch [4/25] Step [11/250]  acc 0.358690 (0.334877)  loss 1.440809 (1.447180)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6802.0 MB
2025-08-26 18:09:57,894 - WARNING - Epoch [4/25] Step [21/250]  acc 0.383575 (0.341822)  loss 1.370329 (1.437123)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6802.0 MB
2025-08-26 18:10:02,179 - WARNING - Epoch [4/25] Step [31/250]  acc 0.333145 (0.347203)  loss 1.393081 (1.426368)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 6802.0 MB
2025-08-26 18:10:06,440 - WARNING - Epoch [4/25] Step [41/250]  acc 0.357931 (0.350416)  loss 1.400742 (1.427235)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 6802.0 MB
2025-08-26 18:10:10,729 - WARNING - Epoch [4/25] Step [51/250]  acc 0.332059 (0.346770)  loss 1.462954 (1.433593)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6802.0 MB
2025-08-26 18:10:15,117 - WARNING - Epoch [4/25] Step [61/250]  acc 0.326881 (0.346637)  loss 1.456033 (1.434507)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6802.0 MB
2025-08-26 18:10:19,401 - WARNING - Epoch [4/25] Step [71/250]  acc 0.337916 (0.346158)  loss 1.403642 (1.435114)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6802.0 MB
2025-08-26 18:10:23,902 - WARNING - Epoch [4/25] Step [81/250]  acc 0.370027 (0.346551)  loss 1.365298 (1.435768)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 6802.0 MB
2025-08-26 18:10:28,176 - WARNING - Epoch [4/25] Step [91/250]  acc 0.336534 (0.346326)  loss 1.460825 (1.436756)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 6802.0 MB
2025-08-26 18:10:32,462 - WARNING - Epoch [4/25] Step [101/250]  acc 0.364429 (0.346819)  loss 1.409146 (1.437341)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6802.0 MB
2025-08-26 18:10:36,730 - WARNING - Epoch [4/25] Step [111/250]  acc 0.349189 (0.346885)  loss 1.488191 (1.437994)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6802.0 MB
2025-08-26 18:10:41,007 - WARNING - Epoch [4/25] Step [121/250]  acc 0.341359 (0.347674)  loss 1.399883 (1.436757)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6802.0 MB
2025-08-26 18:10:45,285 - WARNING - Epoch [4/25] Step [131/250]  acc 0.348721 (0.347565)  loss 1.404711 (1.436113)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6802.0 MB
2025-08-26 18:10:49,534 - WARNING - Epoch [4/25] Step [141/250]  acc 0.305031 (0.346429)  loss 1.420211 (1.436323)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6804.0 MB
2025-08-26 18:10:53,792 - WARNING - Epoch [4/25] Step [151/250]  acc 0.361534 (0.346838)  loss 1.449080 (1.436269)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6804.0 MB
2025-08-26 18:10:58,074 - WARNING - Epoch [4/25] Step [161/250]  acc 0.281373 (0.346052)  loss 1.504382 (1.437381)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6804.0 MB
2025-08-26 18:11:02,369 - WARNING - Epoch [4/25] Step [171/250]  acc 0.351320 (0.345897)  loss 1.435621 (1.437097)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6804.0 MB
2025-08-26 18:11:06,645 - WARNING - Epoch [4/25] Step [181/250]  acc 0.315444 (0.345715)  loss 1.449514 (1.436170)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6804.0 MB
2025-08-26 18:11:10,915 - WARNING - Epoch [4/25] Step [191/250]  acc 0.345263 (0.345780)  loss 1.506119 (1.437429)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6804.0 MB
2025-08-26 18:11:15,196 - WARNING - Epoch [4/25] Step [201/250]  acc 0.352279 (0.345964)  loss 1.436749 (1.435985)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6804.0 MB
2025-08-26 18:11:19,633 - WARNING - Epoch [4/25] Step [211/250]  acc 0.323545 (0.345851)  loss 1.458471 (1.436456)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6804.0 MB
2025-08-26 18:11:25,039 - WARNING - Epoch [4/25] Step [221/250]  acc 0.317965 (0.345983)  loss 1.466451 (1.436125)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6804.0 MB
2025-08-26 18:11:30,179 - WARNING - Epoch [4/25] Step [231/250]  acc 0.324059 (0.346164)  loss 1.520034 (1.436247)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6804.0 MB
2025-08-26 18:11:35,659 - WARNING - Epoch [4/25] Step [241/250]  acc 0.371701 (0.346712)  loss 1.466114 (1.435763)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6804.0 MB
Epoch 4 completed in 0:01:51.868188
2025-08-26 18:12:09,174 - WARNING - Epoch [5/25] Step [1/250]  acc 0.316104 (0.316104)  loss 1.510457 (1.510457)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6804.0 MB
2025-08-26 18:12:14,141 - WARNING - Epoch [5/25] Step [11/250]  acc 0.303542 (0.328353)  loss 1.461069 (1.453344)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6804.0 MB
2025-08-26 18:12:19,396 - WARNING - Epoch [5/25] Step [21/250]  acc 0.342975 (0.334143)  loss 1.456517 (1.452701)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6804.0 MB
2025-08-26 18:12:24,428 - WARNING - Epoch [5/25] Step [31/250]  acc 0.311851 (0.337645)  loss 1.501929 (1.445888)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6804.0 MB
2025-08-26 18:12:28,898 - WARNING - Epoch [5/25] Step [41/250]  acc 0.354856 (0.341472)  loss 1.453412 (1.439434)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6804.0 MB
2025-08-26 18:12:33,223 - WARNING - Epoch [5/25] Step [51/250]  acc 0.324547 (0.339039)  loss 1.414299 (1.440703)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6804.0 MB
2025-08-26 18:12:37,515 - WARNING - Epoch [5/25] Step [61/250]  acc 0.359626 (0.342788)  loss 1.397417 (1.438163)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6804.0 MB
2025-08-26 18:12:41,815 - WARNING - Epoch [5/25] Step [71/250]  acc 0.339642 (0.343993)  loss 1.383639 (1.436838)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 6804.0 MB
2025-08-26 18:12:46,099 - WARNING - Epoch [5/25] Step [81/250]  acc 0.330905 (0.345207)  loss 1.534781 (1.435433)
GPU memory consumption  GPU Memory: Allocated: 51.1 MB, Reserved: 6804.0 MB
2025-08-26 18:12:50,410 - WARNING - Epoch [5/25] Step [91/250]  acc 0.370389 (0.344852)  loss 1.371623 (1.434505)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6804.0 MB
2025-08-26 18:12:54,686 - WARNING - Epoch [5/25] Step [101/250]  acc 0.294416 (0.343714)  loss 1.457208 (1.434758)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6804.0 MB
2025-08-26 18:12:58,975 - WARNING - Epoch [5/25] Step [111/250]  acc 0.334151 (0.343889)  loss 1.431062 (1.433720)
GPU memory consumption  GPU Memory: Allocated: 59.4 MB, Reserved: 6804.0 MB
2025-08-26 18:13:03,285 - WARNING - Epoch [5/25] Step [121/250]  acc 0.331335 (0.343901)  loss 1.500650 (1.433821)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 6804.0 MB
2025-08-26 18:13:07,598 - WARNING - Epoch [5/25] Step [131/250]  acc 0.366227 (0.344605)  loss 1.424607 (1.434686)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6804.0 MB
2025-08-26 18:13:12,133 - WARNING - Epoch [5/25] Step [141/250]  acc 0.342386 (0.344783)  loss 1.491305 (1.434585)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6804.0 MB
2025-08-26 18:13:16,395 - WARNING - Epoch [5/25] Step [151/250]  acc 0.320773 (0.344429)  loss 1.452986 (1.434845)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6804.0 MB
2025-08-26 18:13:20,688 - WARNING - Epoch [5/25] Step [161/250]  acc 0.335933 (0.344580)  loss 1.424170 (1.434636)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6804.0 MB
2025-08-26 18:13:24,992 - WARNING - Epoch [5/25] Step [171/250]  acc 0.342557 (0.344180)  loss 1.409299 (1.434376)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6804.0 MB
2025-08-26 18:13:29,306 - WARNING - Epoch [5/25] Step [181/250]  acc 0.358491 (0.344558)  loss 1.384483 (1.434041)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6804.0 MB
2025-08-26 18:13:33,610 - WARNING - Epoch [5/25] Step [191/250]  acc 0.335052 (0.345239)  loss 1.417194 (1.433551)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6804.0 MB
2025-08-26 18:13:37,902 - WARNING - Epoch [5/25] Step [201/250]  acc 0.342827 (0.345873)  loss 1.426476 (1.433556)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6804.0 MB
2025-08-26 18:13:42,176 - WARNING - Epoch [5/25] Step [211/250]  acc 0.312880 (0.346011)  loss 1.476489 (1.432833)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6804.0 MB
2025-08-26 18:13:46,472 - WARNING - Epoch [5/25] Step [221/250]  acc 0.358074 (0.345941)  loss 1.402994 (1.432460)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6804.0 MB
2025-08-26 18:13:50,737 - WARNING - Epoch [5/25] Step [231/250]  acc 0.357524 (0.345999)  loss 1.416164 (1.431694)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6804.0 MB
2025-08-26 18:13:55,022 - WARNING - Epoch [5/25] Step [241/250]  acc 0.344687 (0.345945)  loss 1.390187 (1.431346)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 6804.0 MB
Epoch 5 completed in 0:01:50.237210
2025-08-26 18:14:25,332 - WARNING - Epoch [6/25] Step [1/250]  acc 0.295074 (0.295074)  loss 1.447509 (1.447509)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6804.0 MB
2025-08-26 18:14:29,622 - WARNING - Epoch [6/25] Step [11/250]  acc 0.348039 (0.345820)  loss 1.433477 (1.439343)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6804.0 MB
2025-08-26 18:14:33,901 - WARNING - Epoch [6/25] Step [21/250]  acc 0.345711 (0.346261)  loss 1.404964 (1.421113)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6804.0 MB
2025-08-26 18:14:38,182 - WARNING - Epoch [6/25] Step [31/250]  acc 0.315414 (0.346874)  loss 1.562605 (1.428093)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6804.0 MB
2025-08-26 18:14:42,691 - WARNING - Epoch [6/25] Step [41/250]  acc 0.361312 (0.347364)  loss 1.414993 (1.428107)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6804.0 MB
2025-08-26 18:14:46,975 - WARNING - Epoch [6/25] Step [51/250]  acc 0.317987 (0.346481)  loss 1.511387 (1.425479)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6804.0 MB
2025-08-26 18:14:51,267 - WARNING - Epoch [6/25] Step [61/250]  acc 0.316369 (0.346054)  loss 1.483738 (1.426444)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6804.0 MB
2025-08-26 18:14:55,560 - WARNING - Epoch [6/25] Step [71/250]  acc 0.383938 (0.347687)  loss 1.378591 (1.422528)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6804.0 MB
2025-08-26 18:14:59,837 - WARNING - Epoch [6/25] Step [81/250]  acc 0.330225 (0.346004)  loss 1.410379 (1.421780)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6804.0 MB
2025-08-26 18:15:04,248 - WARNING - Epoch [6/25] Step [91/250]  acc 0.381966 (0.347514)  loss 1.387207 (1.419946)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6804.0 MB
2025-08-26 18:15:08,622 - WARNING - Epoch [6/25] Step [101/250]  acc 0.385911 (0.347677)  loss 1.399815 (1.418982)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6804.0 MB
2025-08-26 18:15:12,907 - WARNING - Epoch [6/25] Step [111/250]  acc 0.328646 (0.348085)  loss 1.472693 (1.419234)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6804.0 MB
2025-08-26 18:15:17,199 - WARNING - Epoch [6/25] Step [121/250]  acc 0.367089 (0.347876)  loss 1.436220 (1.420052)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6804.0 MB
2025-08-26 18:15:21,498 - WARNING - Epoch [6/25] Step [131/250]  acc 0.379837 (0.347793)  loss 1.387276 (1.419729)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 6804.0 MB
2025-08-26 18:15:25,789 - WARNING - Epoch [6/25] Step [141/250]  acc 0.375594 (0.348137)  loss 1.423734 (1.420074)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6808.0 MB
2025-08-26 18:15:30,068 - WARNING - Epoch [6/25] Step [151/250]  acc 0.376172 (0.348762)  loss 1.389338 (1.419897)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6808.0 MB
2025-08-26 18:15:34,356 - WARNING - Epoch [6/25] Step [161/250]  acc 0.343641 (0.348833)  loss 1.424097 (1.419858)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6808.0 MB
2025-08-26 18:15:38,648 - WARNING - Epoch [6/25] Step [171/250]  acc 0.286146 (0.348722)  loss 1.455511 (1.419702)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 6808.0 MB
2025-08-26 18:15:42,939 - WARNING - Epoch [6/25] Step [181/250]  acc 0.322489 (0.348903)  loss 1.401664 (1.419004)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6808.0 MB
2025-08-26 18:15:47,448 - WARNING - Epoch [6/25] Step [191/250]  acc 0.296633 (0.348674)  loss 1.541852 (1.419961)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6808.0 MB
2025-08-26 18:15:51,737 - WARNING - Epoch [6/25] Step [201/250]  acc 0.356457 (0.349051)  loss 1.416961 (1.419840)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6808.0 MB
2025-08-26 18:15:56,028 - WARNING - Epoch [6/25] Step [211/250]  acc 0.358904 (0.348245)  loss 1.510524 (1.422724)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6808.0 MB
2025-08-26 18:16:00,323 - WARNING - Epoch [6/25] Step [221/250]  acc 0.374400 (0.348120)  loss 1.392273 (1.423060)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6808.0 MB
2025-08-26 18:16:04,600 - WARNING - Epoch [6/25] Step [231/250]  acc 0.350140 (0.348147)  loss 1.430029 (1.423155)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6808.0 MB
2025-08-26 18:16:08,899 - WARNING - Epoch [6/25] Step [241/250]  acc 0.340897 (0.348459)  loss 1.387998 (1.422943)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6808.0 MB
Epoch 6 completed in 0:01:47.866820
2025-08-26 18:16:39,235 - WARNING - Epoch [7/25] Step [1/250]  acc 0.424612 (0.424612)  loss 1.324869 (1.324869)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6808.0 MB
2025-08-26 18:16:43,525 - WARNING - Epoch [7/25] Step [11/250]  acc 0.275478 (0.344347)  loss 1.465372 (1.431022)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6808.0 MB
2025-08-26 18:16:47,820 - WARNING - Epoch [7/25] Step [21/250]  acc 0.308986 (0.345063)  loss 1.487547 (1.421706)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6808.0 MB
2025-08-26 18:16:52,108 - WARNING - Epoch [7/25] Step [31/250]  acc 0.389479 (0.351631)  loss 1.325863 (1.418537)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6808.0 MB
2025-08-26 18:16:56,392 - WARNING - Epoch [7/25] Step [41/250]  acc 0.375329 (0.354609)  loss 1.362182 (1.419142)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6808.0 MB
2025-08-26 18:17:00,713 - WARNING - Epoch [7/25] Step [51/250]  acc 0.326913 (0.354272)  loss 1.436532 (1.416921)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6808.0 MB
2025-08-26 18:17:04,997 - WARNING - Epoch [7/25] Step [61/250]  acc 0.386895 (0.353526)  loss 1.343512 (1.411844)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6808.0 MB
2025-08-26 18:17:09,290 - WARNING - Epoch [7/25] Step [71/250]  acc 0.323248 (0.350695)  loss 1.421352 (1.418468)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6808.0 MB
2025-08-26 18:17:13,575 - WARNING - Epoch [7/25] Step [81/250]  acc 0.355923 (0.350023)  loss 1.485003 (1.418422)
GPU memory consumption  GPU Memory: Allocated: 52.8 MB, Reserved: 6808.0 MB
2025-08-26 18:17:18,106 - WARNING - Epoch [7/25] Step [91/250]  acc 0.402820 (0.350180)  loss 1.324576 (1.415701)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6808.0 MB
2025-08-26 18:17:22,364 - WARNING - Epoch [7/25] Step [101/250]  acc 0.352054 (0.349293)  loss 1.473625 (1.417462)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6808.0 MB
2025-08-26 18:17:26,642 - WARNING - Epoch [7/25] Step [111/250]  acc 0.329229 (0.349905)  loss 1.413536 (1.416147)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6808.0 MB
2025-08-26 18:17:30,916 - WARNING - Epoch [7/25] Step [121/250]  acc 0.368452 (0.349506)  loss 1.400901 (1.415544)
GPU memory consumption  GPU Memory: Allocated: 52.6 MB, Reserved: 6808.0 MB
2025-08-26 18:17:35,264 - WARNING - Epoch [7/25] Step [131/250]  acc 0.366596 (0.348292)  loss 1.497833 (1.418383)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6808.0 MB
2025-08-26 18:17:39,558 - WARNING - Epoch [7/25] Step [141/250]  acc 0.372538 (0.347949)  loss 1.350411 (1.417584)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 6808.0 MB
2025-08-26 18:17:43,831 - WARNING - Epoch [7/25] Step [151/250]  acc 0.390398 (0.348910)  loss 1.323424 (1.414739)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6808.0 MB
2025-08-26 18:17:48,096 - WARNING - Epoch [7/25] Step [161/250]  acc 0.353804 (0.348727)  loss 1.453781 (1.414366)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 6808.0 MB
2025-08-26 18:17:52,368 - WARNING - Epoch [7/25] Step [171/250]  acc 0.383548 (0.348477)  loss 1.437263 (1.415784)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6808.0 MB
2025-08-26 18:17:56,654 - WARNING - Epoch [7/25] Step [181/250]  acc 0.323840 (0.347946)  loss 1.454521 (1.416471)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6808.0 MB
2025-08-26 18:18:00,939 - WARNING - Epoch [7/25] Step [191/250]  acc 0.335977 (0.346895)  loss 1.408449 (1.416266)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6808.0 MB
2025-08-26 18:18:05,203 - WARNING - Epoch [7/25] Step [201/250]  acc 0.337845 (0.346975)  loss 1.397033 (1.416010)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6808.0 MB
2025-08-26 18:18:09,441 - WARNING - Epoch [7/25] Step [211/250]  acc 0.302030 (0.347702)  loss 1.436478 (1.414985)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6808.0 MB
2025-08-26 18:18:13,679 - WARNING - Epoch [7/25] Step [221/250]  acc 0.390268 (0.347795)  loss 1.338702 (1.414551)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6808.0 MB
2025-08-26 18:18:17,908 - WARNING - Epoch [7/25] Step [231/250]  acc 0.330608 (0.347592)  loss 1.379104 (1.413890)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6808.0 MB
2025-08-26 18:18:22,154 - WARNING - Epoch [7/25] Step [241/250]  acc 0.357421 (0.347839)  loss 1.423000 (1.413132)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6808.0 MB
Epoch 7 completed in 0:01:47.349958
2025-08-26 18:18:52,015 - WARNING - Epoch [8/25] Step [1/250]  acc 0.375955 (0.375955)  loss 1.335699 (1.335699)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6808.0 MB
2025-08-26 18:18:56,466 - WARNING - Epoch [8/25] Step [11/250]  acc 0.386652 (0.338102)  loss 1.461333 (1.424059)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6808.0 MB
2025-08-26 18:19:02,196 - WARNING - Epoch [8/25] Step [21/250]  acc 0.371668 (0.352443)  loss 1.293737 (1.392756)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6808.0 MB
2025-08-26 18:19:07,578 - WARNING - Epoch [8/25] Step [31/250]  acc 0.342005 (0.356350)  loss 1.436829 (1.395665)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6808.0 MB
2025-08-26 18:19:13,097 - WARNING - Epoch [8/25] Step [41/250]  acc 0.328831 (0.354728)  loss 1.420752 (1.402047)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6808.0 MB
2025-08-26 18:19:18,781 - WARNING - Epoch [8/25] Step [51/250]  acc 0.322530 (0.353087)  loss 1.428098 (1.406260)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6808.0 MB
2025-08-26 18:19:23,431 - WARNING - Epoch [8/25] Step [61/250]  acc 0.309173 (0.348891)  loss 1.447779 (1.411032)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6808.0 MB
2025-08-26 18:19:27,805 - WARNING - Epoch [8/25] Step [71/250]  acc 0.388130 (0.350747)  loss 1.372321 (1.409232)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 6808.0 MB
2025-08-26 18:19:32,084 - WARNING - Epoch [8/25] Step [81/250]  acc 0.319193 (0.350442)  loss 1.351075 (1.407348)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6808.0 MB
2025-08-26 18:19:36,363 - WARNING - Epoch [8/25] Step [91/250]  acc 0.325153 (0.350790)  loss 1.537238 (1.407650)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6808.0 MB
2025-08-26 18:19:41,477 - WARNING - Epoch [8/25] Step [101/250]  acc 0.372610 (0.350981)  loss 1.410152 (1.408578)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 6808.0 MB
2025-08-26 18:19:46,611 - WARNING - Epoch [8/25] Step [111/250]  acc 0.380000 (0.351211)  loss 1.386379 (1.408422)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6808.0 MB
2025-08-26 18:19:51,672 - WARNING - Epoch [8/25] Step [121/250]  acc 0.329072 (0.351021)  loss 1.437394 (1.406781)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6808.0 MB
2025-08-26 18:19:57,111 - WARNING - Epoch [8/25] Step [131/250]  acc 0.380446 (0.350783)  loss 1.365635 (1.405880)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 6808.0 MB
2025-08-26 18:20:02,150 - WARNING - Epoch [8/25] Step [141/250]  acc 0.359173 (0.350797)  loss 1.403663 (1.405563)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6808.0 MB
2025-08-26 18:20:06,519 - WARNING - Epoch [8/25] Step [151/250]  acc 0.322546 (0.351434)  loss 1.367178 (1.405151)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6808.0 MB
2025-08-26 18:20:10,940 - WARNING - Epoch [8/25] Step [161/250]  acc 0.383689 (0.351971)  loss 1.446116 (1.406315)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6808.0 MB
2025-08-26 18:20:15,092 - WARNING - Epoch [8/25] Step [171/250]  acc 0.307407 (0.351771)  loss 1.454764 (1.407913)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6808.0 MB
2025-08-26 18:20:19,293 - WARNING - Epoch [8/25] Step [181/250]  acc 0.348105 (0.350675)  loss 1.398188 (1.408503)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6808.0 MB
2025-08-26 18:20:23,479 - WARNING - Epoch [8/25] Step [191/250]  acc 0.364491 (0.351029)  loss 1.466040 (1.409255)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 6808.0 MB
2025-08-26 18:20:27,730 - WARNING - Epoch [8/25] Step [201/250]  acc 0.373992 (0.350430)  loss 1.421226 (1.409850)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6808.0 MB
2025-08-26 18:20:32,054 - WARNING - Epoch [8/25] Step [211/250]  acc 0.395062 (0.350431)  loss 1.312577 (1.410332)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6808.0 MB
2025-08-26 18:20:36,338 - WARNING - Epoch [8/25] Step [221/250]  acc 0.350823 (0.350372)  loss 1.423961 (1.410315)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6808.0 MB
2025-08-26 18:20:40,638 - WARNING - Epoch [8/25] Step [231/250]  acc 0.334834 (0.350360)  loss 1.413181 (1.411021)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6808.0 MB
2025-08-26 18:20:44,938 - WARNING - Epoch [8/25] Step [241/250]  acc 0.341220 (0.349375)  loss 1.370723 (1.410881)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6808.0 MB
Epoch 8 completed in 0:01:57.209963
2025-08-26 18:21:15,106 - WARNING - Epoch [9/25] Step [1/250]  acc 0.350533 (0.350533)  loss 1.433454 (1.433454)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6808.0 MB
2025-08-26 18:21:19,408 - WARNING - Epoch [9/25] Step [11/250]  acc 0.360164 (0.353254)  loss 1.442917 (1.423370)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6808.0 MB
2025-08-26 18:21:23,845 - WARNING - Epoch [9/25] Step [21/250]  acc 0.355069 (0.350781)  loss 1.380535 (1.424049)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6808.0 MB
2025-08-26 18:21:28,227 - WARNING - Epoch [9/25] Step [31/250]  acc 0.369898 (0.353710)  loss 1.368652 (1.411248)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6808.0 MB
2025-08-26 18:21:32,549 - WARNING - Epoch [9/25] Step [41/250]  acc 0.305919 (0.353412)  loss 1.437472 (1.406339)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6808.0 MB
2025-08-26 18:21:36,841 - WARNING - Epoch [9/25] Step [51/250]  acc 0.300949 (0.349668)  loss 1.495620 (1.408937)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6808.0 MB
2025-08-26 18:21:41,518 - WARNING - Epoch [9/25] Step [61/250]  acc 0.344107 (0.349068)  loss 1.404999 (1.411167)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6808.0 MB
2025-08-26 18:21:45,905 - WARNING - Epoch [9/25] Step [71/250]  acc 0.356833 (0.347848)  loss 1.384385 (1.413634)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6808.0 MB
2025-08-26 18:21:50,310 - WARNING - Epoch [9/25] Step [81/250]  acc 0.335725 (0.348322)  loss 1.380330 (1.412636)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6808.0 MB
2025-08-26 18:21:54,837 - WARNING - Epoch [9/25] Step [91/250]  acc 0.367451 (0.347930)  loss 1.387752 (1.413029)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 6808.0 MB
2025-08-26 18:21:59,285 - WARNING - Epoch [9/25] Step [101/250]  acc 0.350914 (0.347894)  loss 1.363631 (1.412024)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6808.0 MB
2025-08-26 18:22:03,573 - WARNING - Epoch [9/25] Step [111/250]  acc 0.398946 (0.350067)  loss 1.381653 (1.411884)
GPU memory consumption  GPU Memory: Allocated: 60.8 MB, Reserved: 6808.0 MB
2025-08-26 18:22:07,838 - WARNING - Epoch [9/25] Step [121/250]  acc 0.334666 (0.349803)  loss 1.372546 (1.411608)
GPU memory consumption  GPU Memory: Allocated: 52.9 MB, Reserved: 6808.0 MB
2025-08-26 18:22:12,155 - WARNING - Epoch [9/25] Step [131/250]  acc 0.322235 (0.350148)  loss 1.563982 (1.413475)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6808.0 MB
2025-08-26 18:22:16,422 - WARNING - Epoch [9/25] Step [141/250]  acc 0.311741 (0.349297)  loss 1.435210 (1.413092)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6808.0 MB
2025-08-26 18:22:20,765 - WARNING - Epoch [9/25] Step [151/250]  acc 0.334906 (0.348482)  loss 1.429149 (1.412573)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6808.0 MB
2025-08-26 18:22:25,044 - WARNING - Epoch [9/25] Step [161/250]  acc 0.321260 (0.349037)  loss 1.403686 (1.412420)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6808.0 MB
2025-08-26 18:22:29,347 - WARNING - Epoch [9/25] Step [171/250]  acc 0.343635 (0.349584)  loss 1.385319 (1.412085)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6808.0 MB
2025-08-26 18:22:33,668 - WARNING - Epoch [9/25] Step [181/250]  acc 0.324356 (0.349031)  loss 1.347118 (1.412717)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6808.0 MB
2025-08-26 18:22:37,954 - WARNING - Epoch [9/25] Step [191/250]  acc 0.338060 (0.349669)  loss 1.439555 (1.412434)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 6808.0 MB
2025-08-26 18:22:42,241 - WARNING - Epoch [9/25] Step [201/250]  acc 0.389313 (0.349843)  loss 1.384681 (1.412991)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6808.0 MB
2025-08-26 18:22:46,771 - WARNING - Epoch [9/25] Step [211/250]  acc 0.339523 (0.350332)  loss 1.413670 (1.412423)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6808.0 MB
2025-08-26 18:22:51,108 - WARNING - Epoch [9/25] Step [221/250]  acc 0.385948 (0.351111)  loss 1.393267 (1.412154)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6808.0 MB
2025-08-26 18:22:55,381 - WARNING - Epoch [9/25] Step [231/250]  acc 0.348148 (0.351354)  loss 1.377882 (1.410846)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6808.0 MB
2025-08-26 18:22:59,661 - WARNING - Epoch [9/25] Step [241/250]  acc 0.397455 (0.351297)  loss 1.369517 (1.410969)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6808.0 MB
Epoch 9 completed in 0:01:48.878815
2025-08-26 18:23:29,835 - WARNING - Epoch [10/25] Step [1/250]  acc 0.318872 (0.318872)  loss 1.387390 (1.387390)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6808.0 MB
2025-08-26 18:23:34,127 - WARNING - Epoch [10/25] Step [11/250]  acc 0.370255 (0.346849)  loss 1.397847 (1.397719)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6808.0 MB
2025-08-26 18:23:38,416 - WARNING - Epoch [10/25] Step [21/250]  acc 0.329909 (0.345318)  loss 1.440994 (1.401102)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 6808.0 MB
2025-08-26 18:23:42,687 - WARNING - Epoch [10/25] Step [31/250]  acc 0.351618 (0.352099)  loss 1.359083 (1.389067)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6808.0 MB
2025-08-26 18:23:46,964 - WARNING - Epoch [10/25] Step [41/250]  acc 0.356474 (0.348265)  loss 1.377357 (1.397552)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6808.0 MB
2025-08-26 18:23:51,242 - WARNING - Epoch [10/25] Step [51/250]  acc 0.335497 (0.347542)  loss 1.394405 (1.399833)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6808.0 MB
2025-08-26 18:23:55,509 - WARNING - Epoch [10/25] Step [61/250]  acc 0.374105 (0.348167)  loss 1.410780 (1.404102)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6808.0 MB
2025-08-26 18:23:59,792 - WARNING - Epoch [10/25] Step [71/250]  acc 0.374172 (0.349355)  loss 1.377325 (1.403063)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6808.0 MB
2025-08-26 18:24:04,074 - WARNING - Epoch [10/25] Step [81/250]  acc 0.368538 (0.348981)  loss 1.397680 (1.404265)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 6808.0 MB
2025-08-26 18:24:08,363 - WARNING - Epoch [10/25] Step [91/250]  acc 0.352261 (0.349675)  loss 1.381045 (1.401355)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6808.0 MB
2025-08-26 18:24:12,636 - WARNING - Epoch [10/25] Step [101/250]  acc 0.372330 (0.349150)  loss 1.301260 (1.398139)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6808.0 MB
2025-08-26 18:24:16,904 - WARNING - Epoch [10/25] Step [111/250]  acc 0.352499 (0.350240)  loss 1.357279 (1.396355)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6808.0 MB
2025-08-26 18:24:21,425 - WARNING - Epoch [10/25] Step [121/250]  acc 0.346273 (0.349901)  loss 1.382334 (1.396943)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6808.0 MB
2025-08-26 18:24:25,717 - WARNING - Epoch [10/25] Step [131/250]  acc 0.348872 (0.350323)  loss 1.454913 (1.398714)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6808.0 MB
2025-08-26 18:24:29,992 - WARNING - Epoch [10/25] Step [141/250]  acc 0.368445 (0.350411)  loss 1.393963 (1.398636)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 6808.0 MB
2025-08-26 18:24:34,282 - WARNING - Epoch [10/25] Step [151/250]  acc 0.353903 (0.351191)  loss 1.450258 (1.398575)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6808.0 MB
2025-08-26 18:24:38,555 - WARNING - Epoch [10/25] Step [161/250]  acc 0.355841 (0.351989)  loss 1.357543 (1.398835)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6808.0 MB
2025-08-26 18:24:42,828 - WARNING - Epoch [10/25] Step [171/250]  acc 0.310171 (0.351889)  loss 1.393271 (1.398504)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 6808.0 MB
2025-08-26 18:24:47,109 - WARNING - Epoch [10/25] Step [181/250]  acc 0.368992 (0.352043)  loss 1.364591 (1.399202)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6808.0 MB
2025-08-26 18:24:51,374 - WARNING - Epoch [10/25] Step [191/250]  acc 0.328633 (0.352273)  loss 1.415466 (1.399389)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6808.0 MB
2025-08-26 18:24:55,666 - WARNING - Epoch [10/25] Step [201/250]  acc 0.370526 (0.351897)  loss 1.408264 (1.399117)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6808.0 MB
2025-08-26 18:24:59,957 - WARNING - Epoch [10/25] Step [211/250]  acc 0.315638 (0.351571)  loss 1.490616 (1.399461)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 6808.0 MB
2025-08-26 18:25:04,253 - WARNING - Epoch [10/25] Step [221/250]  acc 0.348813 (0.351305)  loss 1.363226 (1.399796)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6808.0 MB
2025-08-26 18:25:08,558 - WARNING - Epoch [10/25] Step [231/250]  acc 0.314642 (0.351013)  loss 1.377818 (1.401303)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6808.0 MB
2025-08-26 18:25:12,842 - WARNING - Epoch [10/25] Step [241/250]  acc 0.343417 (0.350663)  loss 1.391067 (1.401360)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6808.0 MB
Epoch 10 completed in 0:01:47.278665
2025-08-26 18:25:43,077 - WARNING - Epoch [11/25] Step [1/250]  acc 0.356395 (0.356395)  loss 1.369563 (1.369563)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6808.0 MB
2025-08-26 18:25:47,374 - WARNING - Epoch [11/25] Step [11/250]  acc 0.337771 (0.354566)  loss 1.398594 (1.397823)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 6808.0 MB
2025-08-26 18:25:51,893 - WARNING - Epoch [11/25] Step [21/250]  acc 0.312600 (0.346509)  loss 1.426477 (1.412411)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6808.0 MB
2025-08-26 18:25:56,172 - WARNING - Epoch [11/25] Step [31/250]  acc 0.360185 (0.346813)  loss 1.383947 (1.399868)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6808.0 MB
2025-08-26 18:26:00,440 - WARNING - Epoch [11/25] Step [41/250]  acc 0.354717 (0.351265)  loss 1.421933 (1.396725)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6808.0 MB
2025-08-26 18:26:04,727 - WARNING - Epoch [11/25] Step [51/250]  acc 0.321121 (0.348343)  loss 1.522261 (1.405339)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6808.0 MB
2025-08-26 18:26:09,046 - WARNING - Epoch [11/25] Step [61/250]  acc 0.340887 (0.348677)  loss 1.350971 (1.400294)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6808.0 MB
2025-08-26 18:26:13,335 - WARNING - Epoch [11/25] Step [71/250]  acc 0.384840 (0.348782)  loss 1.369483 (1.402389)
GPU memory consumption  GPU Memory: Allocated: 62.0 MB, Reserved: 6808.0 MB
2025-08-26 18:26:17,612 - WARNING - Epoch [11/25] Step [81/250]  acc 0.378872 (0.350142)  loss 1.362546 (1.403588)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6808.0 MB
2025-08-26 18:26:21,888 - WARNING - Epoch [11/25] Step [91/250]  acc 0.357652 (0.351044)  loss 1.407927 (1.401120)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6808.0 MB
2025-08-26 18:26:26,169 - WARNING - Epoch [11/25] Step [101/250]  acc 0.375702 (0.350974)  loss 1.373894 (1.402204)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 6808.0 MB
2025-08-26 18:26:30,472 - WARNING - Epoch [11/25] Step [111/250]  acc 0.356352 (0.351783)  loss 1.401485 (1.400842)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6808.0 MB
2025-08-26 18:26:35,076 - WARNING - Epoch [11/25] Step [121/250]  acc 0.343423 (0.351467)  loss 1.421941 (1.400830)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 6808.0 MB
2025-08-26 18:26:40,901 - WARNING - Epoch [11/25] Step [131/250]  acc 0.347537 (0.351598)  loss 1.395868 (1.398911)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6808.0 MB
2025-08-26 18:26:46,265 - WARNING - Epoch [11/25] Step [141/250]  acc 0.374104 (0.351261)  loss 1.384734 (1.399742)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6808.0 MB
2025-08-26 18:26:51,849 - WARNING - Epoch [11/25] Step [151/250]  acc 0.339751 (0.351230)  loss 1.420752 (1.399077)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 6808.0 MB
2025-08-26 18:26:57,287 - WARNING - Epoch [11/25] Step [161/250]  acc 0.343612 (0.350999)  loss 1.410617 (1.399435)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6808.0 MB
2025-08-26 18:27:02,154 - WARNING - Epoch [11/25] Step [171/250]  acc 0.321816 (0.351331)  loss 1.395913 (1.398975)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6808.0 MB
2025-08-26 18:27:06,497 - WARNING - Epoch [11/25] Step [181/250]  acc 0.361353 (0.350764)  loss 1.369388 (1.398131)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6808.0 MB
2025-08-26 18:27:10,833 - WARNING - Epoch [11/25] Step [191/250]  acc 0.309148 (0.349812)  loss 1.422586 (1.398671)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 6808.0 MB
2025-08-26 18:27:15,170 - WARNING - Epoch [11/25] Step [201/250]  acc 0.351460 (0.350466)  loss 1.400142 (1.397509)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6808.0 MB
2025-08-26 18:27:20,356 - WARNING - Epoch [11/25] Step [211/250]  acc 0.321734 (0.350362)  loss 1.379684 (1.398010)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6808.0 MB
2025-08-26 18:27:25,431 - WARNING - Epoch [11/25] Step [221/250]  acc 0.368843 (0.350411)  loss 1.443839 (1.398044)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 6808.0 MB
2025-08-26 18:27:30,745 - WARNING - Epoch [11/25] Step [231/250]  acc 0.344809 (0.350536)  loss 1.371005 (1.398228)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6808.0 MB
2025-08-26 18:27:36,322 - WARNING - Epoch [11/25] Step [241/250]  acc 0.352815 (0.350448)  loss 1.426954 (1.399485)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6808.0 MB
Epoch 11 completed in 0:01:58.338084
2025-08-26 18:28:07,583 - WARNING - Epoch [12/25] Step [1/250]  acc 0.376410 (0.376410)  loss 1.327346 (1.327346)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6808.0 MB
2025-08-26 18:28:11,850 - WARNING - Epoch [12/25] Step [11/250]  acc 0.394570 (0.346961)  loss 1.390693 (1.395511)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 6808.0 MB
2025-08-26 18:28:16,123 - WARNING - Epoch [12/25] Step [21/250]  acc 0.353880 (0.357760)  loss 1.380014 (1.389732)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 6808.0 MB
2025-08-26 18:28:20,413 - WARNING - Epoch [12/25] Step [31/250]  acc 0.348332 (0.349783)  loss 1.378065 (1.393384)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6808.0 MB
2025-08-26 18:28:24,685 - WARNING - Epoch [12/25] Step [41/250]  acc 0.381026 (0.350486)  loss 1.394756 (1.395086)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6808.0 MB
2025-08-26 18:28:28,986 - WARNING - Epoch [12/25] Step [51/250]  acc 0.326152 (0.351849)  loss 1.355508 (1.393150)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6808.0 MB
2025-08-26 18:28:33,297 - WARNING - Epoch [12/25] Step [61/250]  acc 0.320087 (0.350895)  loss 1.447308 (1.398816)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6808.0 MB
2025-08-26 18:28:37,577 - WARNING - Epoch [12/25] Step [71/250]  acc 0.329558 (0.350243)  loss 1.415346 (1.399273)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6808.0 MB
2025-08-26 18:28:42,120 - WARNING - Epoch [12/25] Step [81/250]  acc 0.423633 (0.351202)  loss 1.331937 (1.399287)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6808.0 MB
2025-08-26 18:28:46,399 - WARNING - Epoch [12/25] Step [91/250]  acc 0.311927 (0.350116)  loss 1.387417 (1.401562)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6808.0 MB
2025-08-26 18:28:50,673 - WARNING - Epoch [12/25] Step [101/250]  acc 0.361022 (0.350845)  loss 1.322767 (1.399469)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6808.0 MB
2025-08-26 18:28:54,941 - WARNING - Epoch [12/25] Step [111/250]  acc 0.356719 (0.352003)  loss 1.366192 (1.398744)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6808.0 MB
2025-08-26 18:28:59,209 - WARNING - Epoch [12/25] Step [121/250]  acc 0.357943 (0.351830)  loss 1.320706 (1.396864)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6808.0 MB
2025-08-26 18:29:03,502 - WARNING - Epoch [12/25] Step [131/250]  acc 0.368585 (0.350972)  loss 1.414922 (1.397643)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6808.0 MB
2025-08-26 18:29:07,760 - WARNING - Epoch [12/25] Step [141/250]  acc 0.341989 (0.350407)  loss 1.406325 (1.397594)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6808.0 MB
2025-08-26 18:29:12,022 - WARNING - Epoch [12/25] Step [151/250]  acc 0.319048 (0.350185)  loss 1.378974 (1.397486)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6808.0 MB
2025-08-26 18:29:16,287 - WARNING - Epoch [12/25] Step [161/250]  acc 0.335817 (0.350158)  loss 1.375482 (1.395616)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6808.0 MB
2025-08-26 18:29:20,567 - WARNING - Epoch [12/25] Step [171/250]  acc 0.323482 (0.349625)  loss 1.442572 (1.395791)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6808.0 MB
2025-08-26 18:29:24,823 - WARNING - Epoch [12/25] Step [181/250]  acc 0.338367 (0.349371)  loss 1.432117 (1.397104)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6808.0 MB
2025-08-26 18:29:29,098 - WARNING - Epoch [12/25] Step [191/250]  acc 0.384615 (0.349480)  loss 1.303341 (1.396524)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 6808.0 MB
2025-08-26 18:29:33,388 - WARNING - Epoch [12/25] Step [201/250]  acc 0.329810 (0.349856)  loss 1.459439 (1.395774)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6808.0 MB
2025-08-26 18:29:37,671 - WARNING - Epoch [12/25] Step [211/250]  acc 0.364256 (0.350216)  loss 1.373787 (1.395837)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6808.0 MB
2025-08-26 18:29:41,980 - WARNING - Epoch [12/25] Step [221/250]  acc 0.361858 (0.349986)  loss 1.411258 (1.396475)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6808.0 MB
2025-08-26 18:29:46,488 - WARNING - Epoch [12/25] Step [231/250]  acc 0.315789 (0.349723)  loss 1.407178 (1.397163)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6808.0 MB
2025-08-26 18:29:50,761 - WARNING - Epoch [12/25] Step [241/250]  acc 0.326257 (0.349611)  loss 1.550308 (1.398187)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6808.0 MB
Epoch 12 completed in 0:01:47.453460
2025-08-26 18:30:21,416 - WARNING - Epoch [13/25] Step [1/250]  acc 0.343276 (0.343276)  loss 1.403730 (1.403730)
GPU memory consumption  GPU Memory: Allocated: 59.4 MB, Reserved: 6808.0 MB
2025-08-26 18:30:25,709 - WARNING - Epoch [13/25] Step [11/250]  acc 0.352910 (0.351364)  loss 1.325657 (1.382128)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6808.0 MB
2025-08-26 18:30:30,013 - WARNING - Epoch [13/25] Step [21/250]  acc 0.312562 (0.354713)  loss 1.411184 (1.381190)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6808.0 MB
2025-08-26 18:30:34,319 - WARNING - Epoch [13/25] Step [31/250]  acc 0.374798 (0.359292)  loss 1.379850 (1.380622)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6808.0 MB
2025-08-26 18:30:38,604 - WARNING - Epoch [13/25] Step [41/250]  acc 0.307908 (0.354625)  loss 1.380364 (1.381817)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6808.0 MB
2025-08-26 18:30:42,888 - WARNING - Epoch [13/25] Step [51/250]  acc 0.328844 (0.350717)  loss 1.488828 (1.392936)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6808.0 MB
2025-08-26 18:30:47,194 - WARNING - Epoch [13/25] Step [61/250]  acc 0.325066 (0.351513)  loss 1.407910 (1.390155)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6808.0 MB
2025-08-26 18:30:51,501 - WARNING - Epoch [13/25] Step [71/250]  acc 0.320219 (0.351280)  loss 1.383966 (1.389076)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6808.0 MB
2025-08-26 18:30:55,788 - WARNING - Epoch [13/25] Step [81/250]  acc 0.359333 (0.348536)  loss 1.390375 (1.392153)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 6808.0 MB
2025-08-26 18:31:00,095 - WARNING - Epoch [13/25] Step [91/250]  acc 0.392657 (0.348316)  loss 1.468883 (1.394901)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6808.0 MB
2025-08-26 18:31:04,384 - WARNING - Epoch [13/25] Step [101/250]  acc 0.360158 (0.348143)  loss 1.392693 (1.397003)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6808.0 MB
2025-08-26 18:31:08,695 - WARNING - Epoch [13/25] Step [111/250]  acc 0.363028 (0.347611)  loss 1.374971 (1.397065)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6808.0 MB
2025-08-26 18:31:13,014 - WARNING - Epoch [13/25] Step [121/250]  acc 0.354090 (0.346902)  loss 1.474808 (1.397944)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6808.0 MB
2025-08-26 18:31:17,563 - WARNING - Epoch [13/25] Step [131/250]  acc 0.344828 (0.347116)  loss 1.483561 (1.398684)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6808.0 MB
2025-08-26 18:31:21,830 - WARNING - Epoch [13/25] Step [141/250]  acc 0.379219 (0.348090)  loss 1.418105 (1.397216)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6808.0 MB
2025-08-26 18:31:26,132 - WARNING - Epoch [13/25] Step [151/250]  acc 0.333900 (0.347642)  loss 1.327242 (1.396259)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 6808.0 MB
2025-08-26 18:31:30,426 - WARNING - Epoch [13/25] Step [161/250]  acc 0.340471 (0.348330)  loss 1.463682 (1.397230)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6808.0 MB
2025-08-26 18:31:34,758 - WARNING - Epoch [13/25] Step [171/250]  acc 0.321637 (0.349136)  loss 1.386488 (1.395857)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6808.0 MB
2025-08-26 18:31:39,102 - WARNING - Epoch [13/25] Step [181/250]  acc 0.360522 (0.348990)  loss 1.382784 (1.396011)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6808.0 MB
2025-08-26 18:31:43,430 - WARNING - Epoch [13/25] Step [191/250]  acc 0.379004 (0.348504)  loss 1.353768 (1.396735)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6808.0 MB
2025-08-26 18:31:47,751 - WARNING - Epoch [13/25] Step [201/250]  acc 0.347156 (0.348899)  loss 1.475782 (1.397609)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6808.0 MB
2025-08-26 18:31:52,079 - WARNING - Epoch [13/25] Step [211/250]  acc 0.396955 (0.348744)  loss 1.427097 (1.397481)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6808.0 MB
2025-08-26 18:31:56,420 - WARNING - Epoch [13/25] Step [221/250]  acc 0.382640 (0.348763)  loss 1.351921 (1.398099)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6808.0 MB
2025-08-26 18:32:00,770 - WARNING - Epoch [13/25] Step [231/250]  acc 0.387786 (0.349558)  loss 1.386629 (1.397659)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 6808.0 MB
2025-08-26 18:32:05,112 - WARNING - Epoch [13/25] Step [241/250]  acc 0.303562 (0.349053)  loss 1.521783 (1.398546)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6808.0 MB
Epoch 13 completed in 0:01:48.011953
2025-08-26 18:32:35,882 - WARNING - Epoch [14/25] Step [1/250]  acc 0.367882 (0.367882)  loss 1.379313 (1.379313)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6808.0 MB
2025-08-26 18:32:40,215 - WARNING - Epoch [14/25] Step [11/250]  acc 0.390285 (0.349749)  loss 1.394183 (1.411359)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6808.0 MB
2025-08-26 18:32:44,537 - WARNING - Epoch [14/25] Step [21/250]  acc 0.340000 (0.355100)  loss 1.334928 (1.396332)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6808.0 MB
2025-08-26 18:32:48,847 - WARNING - Epoch [14/25] Step [31/250]  acc 0.350161 (0.352352)  loss 1.427424 (1.392688)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6808.0 MB
2025-08-26 18:32:53,410 - WARNING - Epoch [14/25] Step [41/250]  acc 0.371782 (0.349195)  loss 1.383346 (1.401483)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6808.0 MB
2025-08-26 18:32:57,735 - WARNING - Epoch [14/25] Step [51/250]  acc 0.379853 (0.352039)  loss 1.371470 (1.400698)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6808.0 MB
2025-08-26 18:33:02,077 - WARNING - Epoch [14/25] Step [61/250]  acc 0.427402 (0.352919)  loss 1.354456 (1.399788)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6808.0 MB
2025-08-26 18:33:06,378 - WARNING - Epoch [14/25] Step [71/250]  acc 0.364666 (0.355172)  loss 1.383966 (1.395553)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6808.0 MB
2025-08-26 18:33:10,669 - WARNING - Epoch [14/25] Step [81/250]  acc 0.367203 (0.356692)  loss 1.420509 (1.393893)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6808.0 MB
2025-08-26 18:33:14,999 - WARNING - Epoch [14/25] Step [91/250]  acc 0.390779 (0.357752)  loss 1.345931 (1.389842)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6808.0 MB
2025-08-26 18:33:19,279 - WARNING - Epoch [14/25] Step [101/250]  acc 0.349643 (0.357069)  loss 1.420883 (1.394187)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6808.0 MB
2025-08-26 18:33:23,557 - WARNING - Epoch [14/25] Step [111/250]  acc 0.298088 (0.356599)  loss 1.465128 (1.395125)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6808.0 MB
2025-08-26 18:33:27,855 - WARNING - Epoch [14/25] Step [121/250]  acc 0.318304 (0.355866)  loss 1.342919 (1.397014)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 6808.0 MB
2025-08-26 18:33:32,177 - WARNING - Epoch [14/25] Step [131/250]  acc 0.369731 (0.355752)  loss 1.381029 (1.396382)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6808.0 MB
2025-08-26 18:33:36,457 - WARNING - Epoch [14/25] Step [141/250]  acc 0.343782 (0.355875)  loss 1.363277 (1.396462)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6808.0 MB
2025-08-26 18:33:40,769 - WARNING - Epoch [14/25] Step [151/250]  acc 0.365569 (0.355823)  loss 1.418056 (1.397890)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6808.0 MB
2025-08-26 18:33:45,073 - WARNING - Epoch [14/25] Step [161/250]  acc 0.367752 (0.354115)  loss 1.396141 (1.400243)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6808.0 MB
2025-08-26 18:33:49,392 - WARNING - Epoch [14/25] Step [171/250]  acc 0.359375 (0.353073)  loss 1.324847 (1.400060)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6808.0 MB
2025-08-26 18:33:53,697 - WARNING - Epoch [14/25] Step [181/250]  acc 0.318710 (0.352327)  loss 1.460272 (1.400156)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6812.0 MB
2025-08-26 18:33:58,225 - WARNING - Epoch [14/25] Step [191/250]  acc 0.296194 (0.352526)  loss 1.442723 (1.399957)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6812.0 MB
2025-08-26 18:34:02,590 - WARNING - Epoch [14/25] Step [201/250]  acc 0.371312 (0.352376)  loss 1.318723 (1.400477)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 6812.0 MB
2025-08-26 18:34:06,897 - WARNING - Epoch [14/25] Step [211/250]  acc 0.336867 (0.352659)  loss 1.420248 (1.399125)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 6812.0 MB
2025-08-26 18:34:11,225 - WARNING - Epoch [14/25] Step [221/250]  acc 0.387715 (0.353166)  loss 1.370690 (1.399479)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6812.0 MB
2025-08-26 18:34:16,276 - WARNING - Epoch [14/25] Step [231/250]  acc 0.379106 (0.353424)  loss 1.369295 (1.399017)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6812.0 MB
2025-08-26 18:34:21,370 - WARNING - Epoch [14/25] Step [241/250]  acc 0.339400 (0.353887)  loss 1.310345 (1.397997)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6812.0 MB
Epoch 14 completed in 0:01:50.489247
2025-08-26 18:34:54,072 - WARNING - Epoch [15/25] Step [1/250]  acc 0.358766 (0.358766)  loss 1.336065 (1.336065)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6812.0 MB
2025-08-26 18:34:59,301 - WARNING - Epoch [15/25] Step [11/250]  acc 0.330677 (0.349890)  loss 1.374606 (1.388139)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 6812.0 MB
2025-08-26 18:35:04,503 - WARNING - Epoch [15/25] Step [21/250]  acc 0.375276 (0.348818)  loss 1.330538 (1.380518)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6812.0 MB
2025-08-26 18:35:09,686 - WARNING - Epoch [15/25] Step [31/250]  acc 0.322348 (0.348337)  loss 1.444076 (1.399130)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6812.0 MB
2025-08-26 18:35:15,210 - WARNING - Epoch [15/25] Step [41/250]  acc 0.355202 (0.349507)  loss 1.432074 (1.400666)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6812.0 MB
2025-08-26 18:35:20,183 - WARNING - Epoch [15/25] Step [51/250]  acc 0.359288 (0.350212)  loss 1.457319 (1.396509)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6812.0 MB
2025-08-26 18:35:24,395 - WARNING - Epoch [15/25] Step [61/250]  acc 0.346154 (0.351018)  loss 1.415289 (1.391394)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6812.0 MB
2025-08-26 18:35:28,578 - WARNING - Epoch [15/25] Step [71/250]  acc 0.393845 (0.350521)  loss 1.399011 (1.394289)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6812.0 MB
2025-08-26 18:35:32,759 - WARNING - Epoch [15/25] Step [81/250]  acc 0.333979 (0.349621)  loss 1.437819 (1.397540)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6812.0 MB
2025-08-26 18:35:36,946 - WARNING - Epoch [15/25] Step [91/250]  acc 0.367488 (0.350803)  loss 1.349221 (1.395509)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6812.0 MB
2025-08-26 18:35:41,367 - WARNING - Epoch [15/25] Step [101/250]  acc 0.358249 (0.352359)  loss 1.400832 (1.395293)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6812.0 MB
2025-08-26 18:35:45,538 - WARNING - Epoch [15/25] Step [111/250]  acc 0.320745 (0.352931)  loss 1.418880 (1.395174)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6812.0 MB
2025-08-26 18:35:49,680 - WARNING - Epoch [15/25] Step [121/250]  acc 0.358602 (0.351888)  loss 1.411930 (1.396775)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 6812.0 MB
2025-08-26 18:35:53,823 - WARNING - Epoch [15/25] Step [131/250]  acc 0.369923 (0.351655)  loss 1.382959 (1.394968)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6812.0 MB
2025-08-26 18:35:57,997 - WARNING - Epoch [15/25] Step [141/250]  acc 0.359208 (0.351277)  loss 1.340249 (1.394005)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6812.0 MB
2025-08-26 18:36:02,201 - WARNING - Epoch [15/25] Step [151/250]  acc 0.311606 (0.350973)  loss 1.448338 (1.394348)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6812.0 MB
2025-08-26 18:36:06,429 - WARNING - Epoch [15/25] Step [161/250]  acc 0.326304 (0.350559)  loss 1.447997 (1.394888)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 6812.0 MB
2025-08-26 18:36:10,742 - WARNING - Epoch [15/25] Step [171/250]  acc 0.338773 (0.351254)  loss 1.340682 (1.394246)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 6812.0 MB
2025-08-26 18:36:15,071 - WARNING - Epoch [15/25] Step [181/250]  acc 0.341021 (0.351583)  loss 1.461423 (1.393498)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6812.0 MB
2025-08-26 18:36:19,374 - WARNING - Epoch [15/25] Step [191/250]  acc 0.326206 (0.351913)  loss 1.415208 (1.394431)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6812.0 MB
2025-08-26 18:36:23,756 - WARNING - Epoch [15/25] Step [201/250]  acc 0.292808 (0.351896)  loss 1.489387 (1.394526)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6812.0 MB
2025-08-26 18:36:28,102 - WARNING - Epoch [15/25] Step [211/250]  acc 0.385083 (0.352246)  loss 1.359429 (1.394278)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6812.0 MB
2025-08-26 18:36:32,783 - WARNING - Epoch [15/25] Step [221/250]  acc 0.367368 (0.351868)  loss 1.382180 (1.394100)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6812.0 MB
2025-08-26 18:36:37,262 - WARNING - Epoch [15/25] Step [231/250]  acc 0.382757 (0.352261)  loss 1.343274 (1.393868)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6812.0 MB
2025-08-26 18:36:41,444 - WARNING - Epoch [15/25] Step [241/250]  acc 0.387555 (0.352312)  loss 1.339192 (1.393577)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6812.0 MB
Epoch 15 completed in 0:01:51.797625
2025-08-26 18:37:10,907 - WARNING - Epoch [16/25] Step [1/250]  acc 0.291758 (0.291758)  loss 1.439558 (1.439558)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6812.0 MB
2025-08-26 18:37:15,085 - WARNING - Epoch [16/25] Step [11/250]  acc 0.354088 (0.339695)  loss 1.401422 (1.397039)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6812.0 MB
2025-08-26 18:37:19,264 - WARNING - Epoch [16/25] Step [21/250]  acc 0.367593 (0.355604)  loss 1.426047 (1.389432)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6812.0 MB
2025-08-26 18:37:23,469 - WARNING - Epoch [16/25] Step [31/250]  acc 0.335899 (0.354492)  loss 1.430057 (1.391190)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6812.0 MB
2025-08-26 18:37:27,783 - WARNING - Epoch [16/25] Step [41/250]  acc 0.360190 (0.356293)  loss 1.423859 (1.394805)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6812.0 MB
2025-08-26 18:37:32,016 - WARNING - Epoch [16/25] Step [51/250]  acc 0.363248 (0.356189)  loss 1.361421 (1.393333)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6812.0 MB
2025-08-26 18:37:36,246 - WARNING - Epoch [16/25] Step [61/250]  acc 0.352510 (0.354995)  loss 1.378857 (1.395695)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6812.0 MB
2025-08-26 18:37:40,475 - WARNING - Epoch [16/25] Step [71/250]  acc 0.414552 (0.355648)  loss 1.339581 (1.392851)
GPU memory consumption  GPU Memory: Allocated: 62.0 MB, Reserved: 6812.0 MB
2025-08-26 18:37:44,665 - WARNING - Epoch [16/25] Step [81/250]  acc 0.328308 (0.356823)  loss 1.336316 (1.393419)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 6812.0 MB
2025-08-26 18:37:48,872 - WARNING - Epoch [16/25] Step [91/250]  acc 0.360111 (0.355892)  loss 1.375594 (1.393092)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6812.0 MB
2025-08-26 18:37:53,047 - WARNING - Epoch [16/25] Step [101/250]  acc 0.358360 (0.355213)  loss 1.400941 (1.395489)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6812.0 MB
2025-08-26 18:37:57,246 - WARNING - Epoch [16/25] Step [111/250]  acc 0.389930 (0.356084)  loss 1.407375 (1.396001)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6812.0 MB
2025-08-26 18:38:01,486 - WARNING - Epoch [16/25] Step [121/250]  acc 0.344099 (0.355112)  loss 1.417756 (1.397473)
GPU memory consumption  GPU Memory: Allocated: 52.2 MB, Reserved: 6812.0 MB
2025-08-26 18:38:05,685 - WARNING - Epoch [16/25] Step [131/250]  acc 0.356012 (0.354154)  loss 1.366004 (1.396485)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6812.0 MB
2025-08-26 18:38:09,830 - WARNING - Epoch [16/25] Step [141/250]  acc 0.363109 (0.353589)  loss 1.434443 (1.396676)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 6812.0 MB
2025-08-26 18:38:14,284 - WARNING - Epoch [16/25] Step [151/250]  acc 0.344245 (0.352716)  loss 1.406034 (1.396457)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6812.0 MB
2025-08-26 18:38:18,481 - WARNING - Epoch [16/25] Step [161/250]  acc 0.325175 (0.352032)  loss 1.405155 (1.396025)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6812.0 MB
2025-08-26 18:38:22,699 - WARNING - Epoch [16/25] Step [171/250]  acc 0.393861 (0.351512)  loss 1.312134 (1.396840)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6812.0 MB
2025-08-26 18:38:26,908 - WARNING - Epoch [16/25] Step [181/250]  acc 0.341716 (0.351515)  loss 1.376757 (1.396943)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6812.0 MB
2025-08-26 18:38:31,236 - WARNING - Epoch [16/25] Step [191/250]  acc 0.367379 (0.352267)  loss 1.298490 (1.394790)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6812.0 MB
2025-08-26 18:38:35,530 - WARNING - Epoch [16/25] Step [201/250]  acc 0.364294 (0.352868)  loss 1.370738 (1.393171)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6812.0 MB
2025-08-26 18:38:39,800 - WARNING - Epoch [16/25] Step [211/250]  acc 0.334473 (0.352831)  loss 1.439523 (1.392384)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 6812.0 MB
2025-08-26 18:38:44,083 - WARNING - Epoch [16/25] Step [221/250]  acc 0.339662 (0.352054)  loss 1.355469 (1.392905)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6812.0 MB
2025-08-26 18:38:48,368 - WARNING - Epoch [16/25] Step [231/250]  acc 0.378953 (0.351543)  loss 1.344285 (1.393377)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 6812.0 MB
2025-08-26 18:38:52,620 - WARNING - Epoch [16/25] Step [241/250]  acc 0.350867 (0.351211)  loss 1.434651 (1.393441)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6812.0 MB
Epoch 16 completed in 0:01:45.998054
2025-08-26 18:39:22,900 - WARNING - Epoch [17/25] Step [1/250]  acc 0.363636 (0.363636)  loss 1.441623 (1.441623)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 6812.0 MB
2025-08-26 18:39:27,185 - WARNING - Epoch [17/25] Step [11/250]  acc 0.288788 (0.347096)  loss 1.381772 (1.385122)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6812.0 MB
2025-08-26 18:39:31,501 - WARNING - Epoch [17/25] Step [21/250]  acc 0.367647 (0.344846)  loss 1.385460 (1.399218)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6812.0 MB
2025-08-26 18:39:35,815 - WARNING - Epoch [17/25] Step [31/250]  acc 0.324635 (0.345869)  loss 1.383106 (1.399326)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6812.0 MB
2025-08-26 18:39:40,121 - WARNING - Epoch [17/25] Step [41/250]  acc 0.327952 (0.347884)  loss 1.390057 (1.399414)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6812.0 MB
2025-08-26 18:39:44,660 - WARNING - Epoch [17/25] Step [51/250]  acc 0.354719 (0.346789)  loss 1.396250 (1.398793)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6812.0 MB
2025-08-26 18:39:48,991 - WARNING - Epoch [17/25] Step [61/250]  acc 0.331579 (0.347667)  loss 1.412119 (1.397288)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6812.0 MB
2025-08-26 18:39:53,315 - WARNING - Epoch [17/25] Step [71/250]  acc 0.315126 (0.347848)  loss 1.416312 (1.393233)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6812.0 MB
2025-08-26 18:39:57,606 - WARNING - Epoch [17/25] Step [81/250]  acc 0.308391 (0.348511)  loss 1.410351 (1.391363)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 6812.0 MB
2025-08-26 18:40:01,923 - WARNING - Epoch [17/25] Step [91/250]  acc 0.338133 (0.349414)  loss 1.366426 (1.389342)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 6812.0 MB
2025-08-26 18:40:06,230 - WARNING - Epoch [17/25] Step [101/250]  acc 0.324567 (0.347795)  loss 1.536929 (1.391163)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 6812.0 MB
2025-08-26 18:40:10,510 - WARNING - Epoch [17/25] Step [111/250]  acc 0.338921 (0.347488)  loss 1.380279 (1.392269)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6812.0 MB
2025-08-26 18:40:14,795 - WARNING - Epoch [17/25] Step [121/250]  acc 0.361126 (0.348357)  loss 1.416669 (1.390602)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 6812.0 MB
2025-08-26 18:40:19,087 - WARNING - Epoch [17/25] Step [131/250]  acc 0.366724 (0.347381)  loss 1.406428 (1.390291)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6812.0 MB
2025-08-26 18:40:23,371 - WARNING - Epoch [17/25] Step [141/250]  acc 0.328291 (0.347196)  loss 1.416161 (1.391438)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 6812.0 MB
2025-08-26 18:40:27,683 - WARNING - Epoch [17/25] Step [151/250]  acc 0.338407 (0.347474)  loss 1.340531 (1.392628)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6812.0 MB
2025-08-26 18:40:31,992 - WARNING - Epoch [17/25] Step [161/250]  acc 0.383204 (0.347076)  loss 1.343424 (1.393348)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 6812.0 MB
2025-08-26 18:40:36,255 - WARNING - Epoch [17/25] Step [171/250]  acc 0.372844 (0.347622)  loss 1.375178 (1.393444)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6812.0 MB
2025-08-26 18:40:40,571 - WARNING - Epoch [17/25] Step [181/250]  acc 0.349949 (0.347791)  loss 1.389017 (1.395246)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6812.0 MB
2025-08-26 18:40:44,892 - WARNING - Epoch [17/25] Step [191/250]  acc 0.354223 (0.347388)  loss 1.531887 (1.396603)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6812.0 MB
2025-08-26 18:40:49,216 - WARNING - Epoch [17/25] Step [201/250]  acc 0.381240 (0.346931)  loss 1.383390 (1.398444)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6812.0 MB
2025-08-26 18:40:53,788 - WARNING - Epoch [17/25] Step [211/250]  acc 0.382560 (0.347397)  loss 1.322949 (1.398331)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6812.0 MB
2025-08-26 18:40:58,104 - WARNING - Epoch [17/25] Step [221/250]  acc 0.336388 (0.347746)  loss 1.415533 (1.397405)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6812.0 MB
2025-08-26 18:41:02,476 - WARNING - Epoch [17/25] Step [231/250]  acc 0.362589 (0.348090)  loss 1.379611 (1.396193)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6812.0 MB
2025-08-26 18:41:06,813 - WARNING - Epoch [17/25] Step [241/250]  acc 0.333496 (0.347856)  loss 1.347934 (1.395685)
GPU memory consumption  GPU Memory: Allocated: 59.4 MB, Reserved: 6812.0 MB
Epoch 17 completed in 0:01:48.210150
2025-08-26 18:41:37,226 - WARNING - Epoch [18/25] Step [1/250]  acc 0.369766 (0.369766)  loss 1.349587 (1.349587)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6812.0 MB
2025-08-26 18:41:41,546 - WARNING - Epoch [18/25] Step [11/250]  acc 0.365694 (0.363943)  loss 1.388854 (1.377009)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6812.0 MB
2025-08-26 18:41:45,848 - WARNING - Epoch [18/25] Step [21/250]  acc 0.322527 (0.366891)  loss 1.412508 (1.377497)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 6812.0 MB
2025-08-26 18:41:50,127 - WARNING - Epoch [18/25] Step [31/250]  acc 0.396013 (0.360722)  loss 1.433976 (1.389613)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6812.0 MB
2025-08-26 18:41:55,634 - WARNING - Epoch [18/25] Step [41/250]  acc 0.340659 (0.356022)  loss 1.398120 (1.392508)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6812.0 MB
2025-08-26 18:42:00,854 - WARNING - Epoch [18/25] Step [51/250]  acc 0.370041 (0.354807)  loss 1.433622 (1.393200)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 6812.0 MB
2025-08-26 18:42:06,077 - WARNING - Epoch [18/25] Step [61/250]  acc 0.383632 (0.352363)  loss 1.402277 (1.395403)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6812.0 MB
2025-08-26 18:42:11,755 - WARNING - Epoch [18/25] Step [71/250]  acc 0.415938 (0.351556)  loss 1.303029 (1.391683)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 6812.0 MB
2025-08-26 18:42:16,693 - WARNING - Epoch [18/25] Step [81/250]  acc 0.362769 (0.352698)  loss 1.349207 (1.387380)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6812.0 MB
2025-08-26 18:42:21,266 - WARNING - Epoch [18/25] Step [91/250]  acc 0.387724 (0.353180)  loss 1.294518 (1.387399)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 6812.0 MB
2025-08-26 18:42:25,598 - WARNING - Epoch [18/25] Step [101/250]  acc 0.372053 (0.351235)  loss 1.360087 (1.389288)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6812.0 MB
2025-08-26 18:42:30,240 - WARNING - Epoch [18/25] Step [111/250]  acc 0.383511 (0.351514)  loss 1.414258 (1.392652)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6812.0 MB
2025-08-26 18:42:35,435 - WARNING - Epoch [18/25] Step [121/250]  acc 0.347622 (0.352503)  loss 1.329523 (1.391156)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6812.0 MB
2025-08-26 18:42:40,754 - WARNING - Epoch [18/25] Step [131/250]  acc 0.379861 (0.352184)  loss 1.348807 (1.391786)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6812.0 MB
2025-08-26 18:42:45,933 - WARNING - Epoch [18/25] Step [141/250]  acc 0.367959 (0.352123)  loss 1.340358 (1.392560)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6812.0 MB
2025-08-26 18:42:51,403 - WARNING - Epoch [18/25] Step [151/250]  acc 0.301435 (0.351440)  loss 1.438264 (1.394330)
GPU memory consumption  GPU Memory: Allocated: 52.8 MB, Reserved: 6812.0 MB
2025-08-26 18:42:56,512 - WARNING - Epoch [18/25] Step [161/250]  acc 0.371618 (0.351376)  loss 1.410547 (1.393497)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6812.0 MB
2025-08-26 18:43:00,980 - WARNING - Epoch [18/25] Step [171/250]  acc 0.377252 (0.351478)  loss 1.419528 (1.393361)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6812.0 MB
2025-08-26 18:43:05,194 - WARNING - Epoch [18/25] Step [181/250]  acc 0.375131 (0.351962)  loss 1.371195 (1.392111)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6812.0 MB
2025-08-26 18:43:09,389 - WARNING - Epoch [18/25] Step [191/250]  acc 0.354664 (0.352589)  loss 1.485478 (1.391418)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6812.0 MB
2025-08-26 18:43:13,632 - WARNING - Epoch [18/25] Step [201/250]  acc 0.389423 (0.353390)  loss 1.388052 (1.389913)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6812.0 MB
2025-08-26 18:43:17,833 - WARNING - Epoch [18/25] Step [211/250]  acc 0.356157 (0.352832)  loss 1.460411 (1.391530)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6812.0 MB
2025-08-26 18:43:22,020 - WARNING - Epoch [18/25] Step [221/250]  acc 0.344735 (0.352279)  loss 1.417700 (1.392746)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6812.0 MB
2025-08-26 18:43:26,260 - WARNING - Epoch [18/25] Step [231/250]  acc 0.337020 (0.352078)  loss 1.363356 (1.392062)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6812.0 MB
2025-08-26 18:43:30,480 - WARNING - Epoch [18/25] Step [241/250]  acc 0.369856 (0.352139)  loss 1.439608 (1.392217)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6812.0 MB
Epoch 18 completed in 0:01:57.491449
2025-08-26 18:43:59,746 - WARNING - Epoch [19/25] Step [1/250]  acc 0.311163 (0.311163)  loss 1.427080 (1.427080)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6812.0 MB
2025-08-26 18:44:04,168 - WARNING - Epoch [19/25] Step [11/250]  acc 0.287486 (0.341954)  loss 1.510080 (1.420952)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 6812.0 MB
2025-08-26 18:44:08,361 - WARNING - Epoch [19/25] Step [21/250]  acc 0.342133 (0.346308)  loss 1.356982 (1.413711)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6812.0 MB
2025-08-26 18:44:12,544 - WARNING - Epoch [19/25] Step [31/250]  acc 0.323388 (0.349654)  loss 1.395248 (1.402636)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6812.0 MB
2025-08-26 18:44:16,726 - WARNING - Epoch [19/25] Step [41/250]  acc 0.350867 (0.347294)  loss 1.376645 (1.398034)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 6812.0 MB
2025-08-26 18:44:20,937 - WARNING - Epoch [19/25] Step [51/250]  acc 0.379190 (0.346945)  loss 1.370937 (1.398675)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6812.0 MB
2025-08-26 18:44:25,164 - WARNING - Epoch [19/25] Step [61/250]  acc 0.306688 (0.346990)  loss 1.427879 (1.400052)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6812.0 MB
2025-08-26 18:44:29,391 - WARNING - Epoch [19/25] Step [71/250]  acc 0.374459 (0.345945)  loss 1.411103 (1.398434)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6812.0 MB
2025-08-26 18:44:33,599 - WARNING - Epoch [19/25] Step [81/250]  acc 0.376656 (0.345887)  loss 1.338767 (1.395562)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6812.0 MB
2025-08-26 18:44:37,828 - WARNING - Epoch [19/25] Step [91/250]  acc 0.346246 (0.346755)  loss 1.344500 (1.393012)
GPU memory consumption  GPU Memory: Allocated: 60.7 MB, Reserved: 6812.0 MB
2025-08-26 18:44:42,045 - WARNING - Epoch [19/25] Step [101/250]  acc 0.365306 (0.346908)  loss 1.379367 (1.393134)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6812.0 MB
2025-08-26 18:44:46,226 - WARNING - Epoch [19/25] Step [111/250]  acc 0.347072 (0.346943)  loss 1.491793 (1.395125)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6812.0 MB
2025-08-26 18:44:50,446 - WARNING - Epoch [19/25] Step [121/250]  acc 0.381299 (0.347544)  loss 1.384645 (1.394758)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6812.0 MB
2025-08-26 18:44:54,636 - WARNING - Epoch [19/25] Step [131/250]  acc 0.400646 (0.348388)  loss 1.384933 (1.394718)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6812.0 MB
2025-08-26 18:44:58,803 - WARNING - Epoch [19/25] Step [141/250]  acc 0.333333 (0.349210)  loss 1.478247 (1.395586)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 6812.0 MB
2025-08-26 18:45:03,102 - WARNING - Epoch [19/25] Step [151/250]  acc 0.334918 (0.349758)  loss 1.367058 (1.394838)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6812.0 MB
2025-08-26 18:45:07,462 - WARNING - Epoch [19/25] Step [161/250]  acc 0.302050 (0.349242)  loss 1.460001 (1.394621)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 6812.0 MB
2025-08-26 18:45:11,929 - WARNING - Epoch [19/25] Step [171/250]  acc 0.395408 (0.349847)  loss 1.344037 (1.393281)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6812.0 MB
2025-08-26 18:45:16,150 - WARNING - Epoch [19/25] Step [181/250]  acc 0.369921 (0.350134)  loss 1.380988 (1.392578)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6812.0 MB
2025-08-26 18:45:20,399 - WARNING - Epoch [19/25] Step [191/250]  acc 0.350410 (0.350371)  loss 1.395644 (1.391738)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6812.0 MB
2025-08-26 18:45:24,659 - WARNING - Epoch [19/25] Step [201/250]  acc 0.369681 (0.350635)  loss 1.416799 (1.391164)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6812.0 MB
2025-08-26 18:45:28,933 - WARNING - Epoch [19/25] Step [211/250]  acc 0.335177 (0.350642)  loss 1.356816 (1.390710)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6812.0 MB
2025-08-26 18:45:33,242 - WARNING - Epoch [19/25] Step [221/250]  acc 0.348509 (0.350881)  loss 1.344056 (1.391303)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6812.0 MB
2025-08-26 18:45:37,521 - WARNING - Epoch [19/25] Step [231/250]  acc 0.342145 (0.351077)  loss 1.351843 (1.391050)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 6812.0 MB
2025-08-26 18:45:41,826 - WARNING - Epoch [19/25] Step [241/250]  acc 0.345096 (0.351050)  loss 1.367951 (1.389544)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6812.0 MB
Epoch 19 completed in 0:01:46.388912
2025-08-26 18:46:12,374 - WARNING - Epoch [20/25] Step [1/250]  acc 0.373029 (0.373029)  loss 1.428730 (1.428730)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6812.0 MB
2025-08-26 18:46:16,690 - WARNING - Epoch [20/25] Step [11/250]  acc 0.326882 (0.359688)  loss 1.347883 (1.373190)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6812.0 MB
2025-08-26 18:46:20,982 - WARNING - Epoch [20/25] Step [21/250]  acc 0.342215 (0.347895)  loss 1.506958 (1.406615)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6812.0 MB
2025-08-26 18:46:25,302 - WARNING - Epoch [20/25] Step [31/250]  acc 0.301867 (0.345325)  loss 1.410910 (1.397301)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6812.0 MB
2025-08-26 18:46:29,600 - WARNING - Epoch [20/25] Step [41/250]  acc 0.418412 (0.348179)  loss 1.417373 (1.398936)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6812.0 MB
2025-08-26 18:46:33,906 - WARNING - Epoch [20/25] Step [51/250]  acc 0.360134 (0.348147)  loss 1.360862 (1.398247)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6812.0 MB
2025-08-26 18:46:38,207 - WARNING - Epoch [20/25] Step [61/250]  acc 0.393803 (0.352640)  loss 1.374478 (1.392307)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 6812.0 MB
2025-08-26 18:46:42,759 - WARNING - Epoch [20/25] Step [71/250]  acc 0.342706 (0.350934)  loss 1.409676 (1.395090)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6812.0 MB
2025-08-26 18:46:47,060 - WARNING - Epoch [20/25] Step [81/250]  acc 0.363541 (0.351107)  loss 1.348744 (1.392886)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6812.0 MB
2025-08-26 18:46:51,353 - WARNING - Epoch [20/25] Step [91/250]  acc 0.343284 (0.350897)  loss 1.356138 (1.391992)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6812.0 MB
2025-08-26 18:46:55,646 - WARNING - Epoch [20/25] Step [101/250]  acc 0.339901 (0.350567)  loss 1.504537 (1.394424)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6812.0 MB
2025-08-26 18:46:59,945 - WARNING - Epoch [20/25] Step [111/250]  acc 0.384820 (0.350842)  loss 1.332591 (1.394892)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6812.0 MB
2025-08-26 18:47:04,284 - WARNING - Epoch [20/25] Step [121/250]  acc 0.314633 (0.351565)  loss 1.490554 (1.393688)
GPU memory consumption  GPU Memory: Allocated: 52.5 MB, Reserved: 6812.0 MB
2025-08-26 18:47:08,620 - WARNING - Epoch [20/25] Step [131/250]  acc 0.378408 (0.351145)  loss 1.396578 (1.392766)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 6812.0 MB
2025-08-26 18:47:12,945 - WARNING - Epoch [20/25] Step [141/250]  acc 0.377517 (0.351087)  loss 1.347509 (1.392082)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 6812.0 MB
2025-08-26 18:47:17,276 - WARNING - Epoch [20/25] Step [151/250]  acc 0.349668 (0.350284)  loss 1.410990 (1.392829)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6812.0 MB
2025-08-26 18:47:21,560 - WARNING - Epoch [20/25] Step [161/250]  acc 0.323434 (0.349574)  loss 1.384944 (1.392320)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6812.0 MB
2025-08-26 18:47:25,872 - WARNING - Epoch [20/25] Step [171/250]  acc 0.344419 (0.349946)  loss 1.367810 (1.393064)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6812.0 MB
2025-08-26 18:47:30,187 - WARNING - Epoch [20/25] Step [181/250]  acc 0.304261 (0.348843)  loss 1.428481 (1.394014)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6812.0 MB
2025-08-26 18:47:34,507 - WARNING - Epoch [20/25] Step [191/250]  acc 0.343782 (0.348449)  loss 1.398710 (1.394213)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6812.0 MB
2025-08-26 18:47:38,844 - WARNING - Epoch [20/25] Step [201/250]  acc 0.375556 (0.348560)  loss 1.391082 (1.393731)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6812.0 MB
2025-08-26 18:47:43,135 - WARNING - Epoch [20/25] Step [211/250]  acc 0.350052 (0.348332)  loss 1.394821 (1.394106)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6812.0 MB
2025-08-26 18:47:47,451 - WARNING - Epoch [20/25] Step [221/250]  acc 0.364055 (0.347973)  loss 1.289405 (1.392817)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6812.0 MB
2025-08-26 18:47:51,950 - WARNING - Epoch [20/25] Step [231/250]  acc 0.320953 (0.347714)  loss 1.366756 (1.392522)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6812.0 MB
2025-08-26 18:47:56,263 - WARNING - Epoch [20/25] Step [241/250]  acc 0.341639 (0.347950)  loss 1.394720 (1.392475)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6812.0 MB
Epoch 20 completed in 0:01:48.211457
2025-08-26 18:48:26,864 - WARNING - Epoch [21/25] Step [1/250]  acc 0.386763 (0.386763)  loss 1.402290 (1.402290)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6812.0 MB
2025-08-26 18:48:31,185 - WARNING - Epoch [21/25] Step [11/250]  acc 0.321637 (0.350132)  loss 1.441386 (1.402949)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6812.0 MB
2025-08-26 18:48:35,487 - WARNING - Epoch [21/25] Step [21/250]  acc 0.371066 (0.354011)  loss 1.375187 (1.387515)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6812.0 MB
2025-08-26 18:48:39,803 - WARNING - Epoch [21/25] Step [31/250]  acc 0.392244 (0.359314)  loss 1.416983 (1.377731)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6812.0 MB
2025-08-26 18:48:44,101 - WARNING - Epoch [21/25] Step [41/250]  acc 0.312563 (0.358186)  loss 1.461717 (1.382507)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6812.0 MB
2025-08-26 18:48:48,410 - WARNING - Epoch [21/25] Step [51/250]  acc 0.278146 (0.355912)  loss 1.437920 (1.390103)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6812.0 MB
2025-08-26 18:48:52,719 - WARNING - Epoch [21/25] Step [61/250]  acc 0.334230 (0.355677)  loss 1.342696 (1.387336)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6812.0 MB
2025-08-26 18:48:57,020 - WARNING - Epoch [21/25] Step [71/250]  acc 0.343564 (0.354462)  loss 1.364529 (1.387222)
GPU memory consumption  GPU Memory: Allocated: 60.5 MB, Reserved: 6812.0 MB
2025-08-26 18:49:01,312 - WARNING - Epoch [21/25] Step [81/250]  acc 0.365362 (0.354912)  loss 1.392919 (1.386724)
GPU memory consumption  GPU Memory: Allocated: 52.4 MB, Reserved: 6812.0 MB
2025-08-26 18:49:05,629 - WARNING - Epoch [21/25] Step [91/250]  acc 0.354654 (0.354558)  loss 1.450825 (1.388875)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6812.0 MB
2025-08-26 18:49:09,929 - WARNING - Epoch [21/25] Step [101/250]  acc 0.372674 (0.355156)  loss 1.431265 (1.387975)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6812.0 MB
2025-08-26 18:49:14,218 - WARNING - Epoch [21/25] Step [111/250]  acc 0.335897 (0.354815)  loss 1.450201 (1.389268)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 6812.0 MB
2025-08-26 18:49:18,519 - WARNING - Epoch [21/25] Step [121/250]  acc 0.360569 (0.354818)  loss 1.342145 (1.390025)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 6812.0 MB
2025-08-26 18:49:23,089 - WARNING - Epoch [21/25] Step [131/250]  acc 0.306469 (0.353389)  loss 1.389929 (1.391313)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6812.0 MB
2025-08-26 18:49:27,394 - WARNING - Epoch [21/25] Step [141/250]  acc 0.347005 (0.354152)  loss 1.360256 (1.389247)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6812.0 MB
2025-08-26 18:49:32,901 - WARNING - Epoch [21/25] Step [151/250]  acc 0.319102 (0.354360)  loss 1.430046 (1.389628)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6812.0 MB
2025-08-26 18:49:38,369 - WARNING - Epoch [21/25] Step [161/250]  acc 0.279437 (0.354354)  loss 1.498301 (1.390719)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 6812.0 MB
2025-08-26 18:49:44,041 - WARNING - Epoch [21/25] Step [171/250]  acc 0.410526 (0.354689)  loss 1.326869 (1.390598)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6812.0 MB
2025-08-26 18:49:49,937 - WARNING - Epoch [21/25] Step [181/250]  acc 0.352004 (0.354761)  loss 1.419222 (1.390023)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6812.0 MB
2025-08-26 18:49:54,917 - WARNING - Epoch [21/25] Step [191/250]  acc 0.366358 (0.355070)  loss 1.314624 (1.388969)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6812.0 MB
2025-08-26 18:49:59,681 - WARNING - Epoch [21/25] Step [201/250]  acc 0.342352 (0.354525)  loss 1.340315 (1.389114)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6812.0 MB
2025-08-26 18:50:04,216 - WARNING - Epoch [21/25] Step [211/250]  acc 0.336113 (0.354044)  loss 1.339183 (1.388195)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6812.0 MB
2025-08-26 18:50:08,602 - WARNING - Epoch [21/25] Step [221/250]  acc 0.312053 (0.353843)  loss 1.395122 (1.389440)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 6812.0 MB
2025-08-26 18:50:13,427 - WARNING - Epoch [21/25] Step [231/250]  acc 0.377593 (0.353392)  loss 1.472152 (1.390650)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6812.0 MB
2025-08-26 18:50:18,905 - WARNING - Epoch [21/25] Step [241/250]  acc 0.389000 (0.352930)  loss 1.374367 (1.390493)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 6812.0 MB
Epoch 21 completed in 0:01:57.126394
2025-08-26 18:50:52,307 - WARNING - Epoch [22/25] Step [1/250]  acc 0.354132 (0.354132)  loss 1.392568 (1.392568)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6812.0 MB
2025-08-26 18:50:56,609 - WARNING - Epoch [22/25] Step [11/250]  acc 0.351409 (0.355627)  loss 1.326651 (1.369217)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6812.0 MB
2025-08-26 18:51:00,912 - WARNING - Epoch [22/25] Step [21/250]  acc 0.388485 (0.359389)  loss 1.398134 (1.370180)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6812.0 MB
2025-08-26 18:51:05,412 - WARNING - Epoch [22/25] Step [31/250]  acc 0.355932 (0.361351)  loss 1.326398 (1.368824)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6812.0 MB
2025-08-26 18:51:09,655 - WARNING - Epoch [22/25] Step [41/250]  acc 0.331332 (0.360399)  loss 1.380726 (1.362764)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6812.0 MB
2025-08-26 18:51:13,905 - WARNING - Epoch [22/25] Step [51/250]  acc 0.400215 (0.359927)  loss 1.287058 (1.364711)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6812.0 MB
2025-08-26 18:51:18,161 - WARNING - Epoch [22/25] Step [61/250]  acc 0.365192 (0.360354)  loss 1.343249 (1.365294)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6812.0 MB
2025-08-26 18:51:22,442 - WARNING - Epoch [22/25] Step [71/250]  acc 0.372238 (0.359753)  loss 1.323482 (1.364335)
GPU memory consumption  GPU Memory: Allocated: 62.0 MB, Reserved: 6812.0 MB
2025-08-26 18:51:26,719 - WARNING - Epoch [22/25] Step [81/250]  acc 0.352105 (0.359065)  loss 1.323973 (1.365004)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 6812.0 MB
2025-08-26 18:51:31,020 - WARNING - Epoch [22/25] Step [91/250]  acc 0.321429 (0.358252)  loss 1.441883 (1.364483)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6812.0 MB
2025-08-26 18:51:35,277 - WARNING - Epoch [22/25] Step [101/250]  acc 0.349046 (0.358322)  loss 1.411281 (1.367043)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6812.0 MB
2025-08-26 18:51:39,529 - WARNING - Epoch [22/25] Step [111/250]  acc 0.357907 (0.357995)  loss 1.340298 (1.366179)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6812.0 MB
2025-08-26 18:51:43,792 - WARNING - Epoch [22/25] Step [121/250]  acc 0.328644 (0.357718)  loss 1.329523 (1.366311)
GPU memory consumption  GPU Memory: Allocated: 53.0 MB, Reserved: 6812.0 MB
2025-08-26 18:51:48,070 - WARNING - Epoch [22/25] Step [131/250]  acc 0.305699 (0.357419)  loss 1.373776 (1.365898)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6812.0 MB
2025-08-26 18:51:52,364 - WARNING - Epoch [22/25] Step [141/250]  acc 0.317501 (0.356215)  loss 1.426431 (1.365695)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6812.0 MB
2025-08-26 18:51:56,625 - WARNING - Epoch [22/25] Step [151/250]  acc 0.327132 (0.356023)  loss 1.373108 (1.366703)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6812.0 MB
2025-08-26 18:52:00,888 - WARNING - Epoch [22/25] Step [161/250]  acc 0.356944 (0.355341)  loss 1.350217 (1.368089)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 6812.0 MB
2025-08-26 18:52:05,137 - WARNING - Epoch [22/25] Step [171/250]  acc 0.349165 (0.355571)  loss 1.391580 (1.370069)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6812.0 MB
2025-08-26 18:52:09,410 - WARNING - Epoch [22/25] Step [181/250]  acc 0.373098 (0.356195)  loss 1.391346 (1.369498)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 6812.0 MB
2025-08-26 18:52:13,912 - WARNING - Epoch [22/25] Step [191/250]  acc 0.340631 (0.356813)  loss 1.349241 (1.369578)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6812.0 MB
2025-08-26 18:52:18,178 - WARNING - Epoch [22/25] Step [201/250]  acc 0.359367 (0.356741)  loss 1.411261 (1.370354)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6812.0 MB
2025-08-26 18:52:22,454 - WARNING - Epoch [22/25] Step [211/250]  acc 0.311189 (0.356638)  loss 1.386169 (1.370560)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6812.0 MB
2025-08-26 18:52:26,722 - WARNING - Epoch [22/25] Step [221/250]  acc 0.338867 (0.356411)  loss 1.345614 (1.370281)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 6812.0 MB
2025-08-26 18:52:30,995 - WARNING - Epoch [22/25] Step [231/250]  acc 0.425578 (0.356848)  loss 1.292596 (1.369866)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6812.0 MB
2025-08-26 18:52:35,274 - WARNING - Epoch [22/25] Step [241/250]  acc 0.344000 (0.357158)  loss 1.438846 (1.369641)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6812.0 MB
Epoch 22 completed in 0:01:47.246415
2025-08-26 18:53:05,550 - WARNING - Epoch [23/25] Step [1/250]  acc 0.372784 (0.372784)  loss 1.447979 (1.447979)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6812.0 MB
2025-08-26 18:53:09,815 - WARNING - Epoch [23/25] Step [11/250]  acc 0.375656 (0.357287)  loss 1.385654 (1.386737)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6812.0 MB
2025-08-26 18:53:14,095 - WARNING - Epoch [23/25] Step [21/250]  acc 0.392448 (0.365461)  loss 1.351549 (1.369723)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 6812.0 MB
2025-08-26 18:53:18,367 - WARNING - Epoch [23/25] Step [31/250]  acc 0.328189 (0.360461)  loss 1.477973 (1.378525)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6812.0 MB
2025-08-26 18:53:22,615 - WARNING - Epoch [23/25] Step [41/250]  acc 0.423764 (0.361845)  loss 1.375197 (1.376858)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6812.0 MB
2025-08-26 18:53:26,873 - WARNING - Epoch [23/25] Step [51/250]  acc 0.323982 (0.359978)  loss 1.343398 (1.375201)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6812.0 MB
2025-08-26 18:53:31,191 - WARNING - Epoch [23/25] Step [61/250]  acc 0.370618 (0.359759)  loss 1.340838 (1.372439)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6812.0 MB
2025-08-26 18:53:35,482 - WARNING - Epoch [23/25] Step [71/250]  acc 0.337958 (0.359139)  loss 1.268913 (1.370483)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6812.0 MB
2025-08-26 18:53:39,766 - WARNING - Epoch [23/25] Step [81/250]  acc 0.362060 (0.360480)  loss 1.319804 (1.367125)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6812.0 MB
2025-08-26 18:53:44,310 - WARNING - Epoch [23/25] Step [91/250]  acc 0.340211 (0.359791)  loss 1.361724 (1.367344)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6812.0 MB
2025-08-26 18:53:48,595 - WARNING - Epoch [23/25] Step [101/250]  acc 0.375072 (0.358977)  loss 1.389695 (1.368213)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6812.0 MB
2025-08-26 18:53:52,890 - WARNING - Epoch [23/25] Step [111/250]  acc 0.317469 (0.358581)  loss 1.375880 (1.365536)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6812.0 MB
2025-08-26 18:53:57,162 - WARNING - Epoch [23/25] Step [121/250]  acc 0.362663 (0.359050)  loss 1.390206 (1.365779)
GPU memory consumption  GPU Memory: Allocated: 51.9 MB, Reserved: 6812.0 MB
2025-08-26 18:54:01,478 - WARNING - Epoch [23/25] Step [131/250]  acc 0.366463 (0.358889)  loss 1.326792 (1.367052)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6812.0 MB
2025-08-26 18:54:05,755 - WARNING - Epoch [23/25] Step [141/250]  acc 0.385366 (0.358874)  loss 1.316166 (1.367856)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6812.0 MB
2025-08-26 18:54:10,050 - WARNING - Epoch [23/25] Step [151/250]  acc 0.298052 (0.359117)  loss 1.309711 (1.366337)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6812.0 MB
2025-08-26 18:54:14,354 - WARNING - Epoch [23/25] Step [161/250]  acc 0.385142 (0.358228)  loss 1.339846 (1.365654)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6812.0 MB
2025-08-26 18:54:18,661 - WARNING - Epoch [23/25] Step [171/250]  acc 0.348516 (0.357392)  loss 1.338288 (1.364974)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6812.0 MB
2025-08-26 18:54:22,957 - WARNING - Epoch [23/25] Step [181/250]  acc 0.376275 (0.357177)  loss 1.325350 (1.363754)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6812.0 MB
2025-08-26 18:54:27,260 - WARNING - Epoch [23/25] Step [191/250]  acc 0.361452 (0.357215)  loss 1.306964 (1.364177)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6812.0 MB
2025-08-26 18:54:31,565 - WARNING - Epoch [23/25] Step [201/250]  acc 0.337389 (0.356895)  loss 1.290024 (1.364618)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6812.0 MB
2025-08-26 18:54:35,862 - WARNING - Epoch [23/25] Step [211/250]  acc 0.356230 (0.356971)  loss 1.313575 (1.363944)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 6812.0 MB
2025-08-26 18:54:40,144 - WARNING - Epoch [23/25] Step [221/250]  acc 0.364632 (0.357035)  loss 1.313354 (1.364307)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6812.0 MB
2025-08-26 18:54:44,434 - WARNING - Epoch [23/25] Step [231/250]  acc 0.369247 (0.357248)  loss 1.360229 (1.364712)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6812.0 MB
2025-08-26 18:54:48,748 - WARNING - Epoch [23/25] Step [241/250]  acc 0.361702 (0.357199)  loss 1.447282 (1.365674)
GPU memory consumption  GPU Memory: Allocated: 53.0 MB, Reserved: 6812.0 MB
Epoch 23 completed in 0:01:47.735746
2025-08-26 18:55:19,408 - WARNING - Epoch [24/25] Step [1/250]  acc 0.322889 (0.322889)  loss 1.360385 (1.360385)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 6812.0 MB
2025-08-26 18:55:23,696 - WARNING - Epoch [24/25] Step [11/250]  acc 0.425926 (0.355564)  loss 1.380975 (1.365439)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6812.0 MB
2025-08-26 18:55:28,018 - WARNING - Epoch [24/25] Step [21/250]  acc 0.374066 (0.354643)  loss 1.350726 (1.366311)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6812.0 MB
2025-08-26 18:55:32,357 - WARNING - Epoch [24/25] Step [31/250]  acc 0.425472 (0.356488)  loss 1.315282 (1.364251)
GPU memory consumption  GPU Memory: Allocated: 59.6 MB, Reserved: 6812.0 MB
2025-08-26 18:55:36,638 - WARNING - Epoch [24/25] Step [41/250]  acc 0.371817 (0.355024)  loss 1.403813 (1.365817)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 6812.0 MB
2025-08-26 18:55:40,931 - WARNING - Epoch [24/25] Step [51/250]  acc 0.414876 (0.356321)  loss 1.341039 (1.367136)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6812.0 MB
2025-08-26 18:55:45,233 - WARNING - Epoch [24/25] Step [61/250]  acc 0.374323 (0.353468)  loss 1.320206 (1.370792)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6812.0 MB
2025-08-26 18:55:49,531 - WARNING - Epoch [24/25] Step [71/250]  acc 0.366895 (0.355374)  loss 1.387378 (1.370332)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6812.0 MB
2025-08-26 18:55:53,837 - WARNING - Epoch [24/25] Step [81/250]  acc 0.374289 (0.355863)  loss 1.407127 (1.371305)
GPU memory consumption  GPU Memory: Allocated: 52.9 MB, Reserved: 6812.0 MB
2025-08-26 18:55:58,156 - WARNING - Epoch [24/25] Step [91/250]  acc 0.407716 (0.356608)  loss 1.309839 (1.371717)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6812.0 MB
2025-08-26 18:56:02,506 - WARNING - Epoch [24/25] Step [101/250]  acc 0.396104 (0.358135)  loss 1.279960 (1.369305)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6812.0 MB
2025-08-26 18:56:06,808 - WARNING - Epoch [24/25] Step [111/250]  acc 0.311265 (0.356161)  loss 1.381865 (1.369824)
GPU memory consumption  GPU Memory: Allocated: 59.5 MB, Reserved: 6812.0 MB
2025-08-26 18:56:11,103 - WARNING - Epoch [24/25] Step [121/250]  acc 0.363307 (0.355596)  loss 1.279819 (1.367662)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6812.0 MB
2025-08-26 18:56:15,396 - WARNING - Epoch [24/25] Step [131/250]  acc 0.415259 (0.355679)  loss 1.291578 (1.367039)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6812.0 MB
2025-08-26 18:56:19,663 - WARNING - Epoch [24/25] Step [141/250]  acc 0.321641 (0.355843)  loss 1.352170 (1.368137)
GPU memory consumption  GPU Memory: Allocated: 52.3 MB, Reserved: 6812.0 MB
2025-08-26 18:56:24,208 - WARNING - Epoch [24/25] Step [151/250]  acc 0.360665 (0.355635)  loss 1.374979 (1.369087)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6812.0 MB
2025-08-26 18:56:28,500 - WARNING - Epoch [24/25] Step [161/250]  acc 0.379273 (0.356387)  loss 1.372126 (1.369183)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6812.0 MB
2025-08-26 18:56:32,796 - WARNING - Epoch [24/25] Step [171/250]  acc 0.294814 (0.356066)  loss 1.423109 (1.369268)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6812.0 MB
2025-08-26 18:56:37,073 - WARNING - Epoch [24/25] Step [181/250]  acc 0.348875 (0.356373)  loss 1.359761 (1.368166)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6812.0 MB
2025-08-26 18:56:41,358 - WARNING - Epoch [24/25] Step [191/250]  acc 0.345011 (0.355842)  loss 1.324626 (1.367036)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6812.0 MB
2025-08-26 18:56:45,652 - WARNING - Epoch [24/25] Step [201/250]  acc 0.324607 (0.355957)  loss 1.404283 (1.366439)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6812.0 MB
2025-08-26 18:56:49,956 - WARNING - Epoch [24/25] Step [211/250]  acc 0.351783 (0.355914)  loss 1.410974 (1.367493)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6812.0 MB
2025-08-26 18:56:54,252 - WARNING - Epoch [24/25] Step [221/250]  acc 0.369256 (0.355899)  loss 1.318622 (1.367395)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 6812.0 MB
2025-08-26 18:56:58,544 - WARNING - Epoch [24/25] Step [231/250]  acc 0.363933 (0.355946)  loss 1.333859 (1.366456)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6812.0 MB
2025-08-26 18:57:02,861 - WARNING - Epoch [24/25] Step [241/250]  acc 0.367195 (0.356080)  loss 1.313346 (1.366053)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 6812.0 MB
Epoch 24 completed in 0:01:47.741517
2025-08-26 18:57:37,598 - WARNING - Epoch [25/25] Step [1/250]  acc 0.397727 (0.397727)  loss 1.321348 (1.321348)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6812.0 MB
2025-08-26 18:57:41,937 - WARNING - Epoch [25/25] Step [11/250]  acc 0.383621 (0.364333)  loss 1.358931 (1.365463)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6812.0 MB
2025-08-26 18:57:46,298 - WARNING - Epoch [25/25] Step [21/250]  acc 0.330307 (0.366317)  loss 1.472914 (1.362248)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6812.0 MB
2025-08-26 18:57:50,815 - WARNING - Epoch [25/25] Step [31/250]  acc 0.369626 (0.367760)  loss 1.291094 (1.354446)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6812.0 MB
2025-08-26 18:57:56,299 - WARNING - Epoch [25/25] Step [41/250]  acc 0.373699 (0.366479)  loss 1.280076 (1.357916)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6812.0 MB
2025-08-26 18:58:01,674 - WARNING - Epoch [25/25] Step [51/250]  acc 0.407269 (0.365503)  loss 1.319699 (1.358883)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6812.0 MB
2025-08-26 18:58:06,827 - WARNING - Epoch [25/25] Step [61/250]  acc 0.358173 (0.365101)  loss 1.382284 (1.359252)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 6812.0 MB
2025-08-26 18:58:12,283 - WARNING - Epoch [25/25] Step [71/250]  acc 0.292453 (0.361796)  loss 1.347900 (1.361712)
GPU memory consumption  GPU Memory: Allocated: 60.2 MB, Reserved: 6812.0 MB
2025-08-26 18:58:16,871 - WARNING - Epoch [25/25] Step [81/250]  acc 0.345180 (0.361924)  loss 1.444466 (1.363507)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 6812.0 MB
2025-08-26 18:58:21,061 - WARNING - Epoch [25/25] Step [91/250]  acc 0.351925 (0.361739)  loss 1.379978 (1.364904)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 6812.0 MB
2025-08-26 18:58:25,258 - WARNING - Epoch [25/25] Step [101/250]  acc 0.332483 (0.360273)  loss 1.381047 (1.365587)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 6812.0 MB
2025-08-26 18:58:29,493 - WARNING - Epoch [25/25] Step [111/250]  acc 0.348742 (0.359641)  loss 1.357419 (1.364808)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6812.0 MB
2025-08-26 18:58:33,722 - WARNING - Epoch [25/25] Step [121/250]  acc 0.330113 (0.359815)  loss 1.375532 (1.364095)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6812.0 MB
2025-08-26 18:58:37,958 - WARNING - Epoch [25/25] Step [131/250]  acc 0.359375 (0.359491)  loss 1.360809 (1.364722)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6812.0 MB
2025-08-26 18:58:42,158 - WARNING - Epoch [25/25] Step [141/250]  acc 0.368366 (0.359197)  loss 1.332652 (1.365091)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6812.0 MB
2025-08-26 18:58:46,311 - WARNING - Epoch [25/25] Step [151/250]  acc 0.354876 (0.358492)  loss 1.387125 (1.364253)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 6812.0 MB
2025-08-26 18:58:50,496 - WARNING - Epoch [25/25] Step [161/250]  acc 0.386617 (0.359138)  loss 1.240867 (1.364295)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6812.0 MB
2025-08-26 18:58:54,687 - WARNING - Epoch [25/25] Step [171/250]  acc 0.376437 (0.358756)  loss 1.359420 (1.365313)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6812.0 MB
2025-08-26 18:58:58,856 - WARNING - Epoch [25/25] Step [181/250]  acc 0.348516 (0.359363)  loss 1.344000 (1.366177)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6812.0 MB
2025-08-26 18:59:03,131 - WARNING - Epoch [25/25] Step [191/250]  acc 0.368192 (0.359275)  loss 1.305350 (1.365989)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6812.0 MB
2025-08-26 18:59:07,424 - WARNING - Epoch [25/25] Step [201/250]  acc 0.363014 (0.358828)  loss 1.320345 (1.365380)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6812.0 MB
2025-08-26 18:59:11,966 - WARNING - Epoch [25/25] Step [211/250]  acc 0.373341 (0.358148)  loss 1.345858 (1.365776)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6812.0 MB
2025-08-26 18:59:16,267 - WARNING - Epoch [25/25] Step [221/250]  acc 0.340251 (0.358169)  loss 1.382277 (1.365694)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 6812.0 MB
2025-08-26 18:59:20,540 - WARNING - Epoch [25/25] Step [231/250]  acc 0.425611 (0.357976)  loss 1.325058 (1.365989)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6812.0 MB
2025-08-26 18:59:24,843 - WARNING - Epoch [25/25] Step [241/250]  acc 0.396237 (0.358024)  loss 1.337126 (1.366688)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6812.0 MB
Epoch 25 completed in 0:01:51.577631
2025-08-26 18:59:54,947 - INFO - DARTS search completed in 3419.93s
2025-08-26 18:59:54,948 - INFO - 
============================================================
2025-08-26 18:59:54,948 - INFO - Layer layer_0 Expert Selection:
2025-08-26 18:59:54,948 - INFO -   Expert 0: GINE (α=0.3711) ← SELECTED
2025-08-26 18:59:54,948 - INFO -   Expert 1: CustomGatedGCN (α=0.3350)
2025-08-26 18:59:54,948 - INFO -   Expert 2: GATV2 (α=0.2939)
2025-08-26 18:59:54,948 - INFO - Selected Expert Index: 0 (GINE)
2025-08-26 18:59:54,948 - INFO - ============================================================

2025-08-26 18:59:54,948 - INFO - 
============================================================
2025-08-26 18:59:54,948 - INFO - Layer layer_1 Expert Selection:
2025-08-26 18:59:54,948 - INFO -   Expert 0: GINE (α=0.2633)
2025-08-26 18:59:54,948 - INFO -   Expert 1: CustomGatedGCN (α=0.2722)
2025-08-26 18:59:54,948 - INFO -   Expert 2: GATV2 (α=0.4646) ← SELECTED
2025-08-26 18:59:54,948 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-26 18:59:54,948 - INFO - ============================================================

2025-08-26 18:59:54,948 - INFO - 
============================================================
2025-08-26 18:59:54,948 - INFO - Layer layer_2 Expert Selection:
2025-08-26 18:59:54,949 - INFO -   Expert 0: GINE (α=0.2341)
2025-08-26 18:59:54,949 - INFO -   Expert 1: CustomGatedGCN (α=0.3140)
2025-08-26 18:59:54,949 - INFO -   Expert 2: GATV2 (α=0.4519) ← SELECTED
2025-08-26 18:59:54,949 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-26 18:59:54,949 - INFO - ============================================================

2025-08-26 18:59:54,949 - INFO - 
============================================================
2025-08-26 18:59:54,949 - INFO - Layer layer_3 Expert Selection:
2025-08-26 18:59:54,949 - INFO -   Expert 0: GINE (α=0.2345)
2025-08-26 18:59:54,949 - INFO -   Expert 1: CustomGatedGCN (α=0.3387)
2025-08-26 18:59:54,949 - INFO -   Expert 2: GATV2 (α=0.4268) ← SELECTED
2025-08-26 18:59:54,949 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-26 18:59:54,949 - INFO - ============================================================

2025-08-26 18:59:54,949 - INFO - 
============================================================
2025-08-26 18:59:54,949 - INFO - Layer layer_4 Expert Selection:
2025-08-26 18:59:54,949 - INFO -   Expert 0: GINE (α=0.3166)
2025-08-26 18:59:54,949 - INFO -   Expert 1: CustomGatedGCN (α=0.3990) ← SELECTED
2025-08-26 18:59:54,949 - INFO -   Expert 2: GATV2 (α=0.2844)
2025-08-26 18:59:54,949 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-26 18:59:54,949 - INFO - ============================================================

2025-08-26 18:59:54,949 - INFO - 
============================================================
2025-08-26 18:59:54,949 - INFO - Layer layer_5 Expert Selection:
2025-08-26 18:59:54,949 - INFO -   Expert 0: GINE (α=0.3386)
2025-08-26 18:59:54,949 - INFO -   Expert 1: CustomGatedGCN (α=0.3418) ← SELECTED
2025-08-26 18:59:54,949 - INFO -   Expert 2: GATV2 (α=0.3197)
2025-08-26 18:59:54,949 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-26 18:59:54,949 - INFO - ============================================================

2025-08-26 18:59:54,950 - INFO - 
============================================================
2025-08-26 18:59:54,950 - INFO - Layer layer_6 Expert Selection:
2025-08-26 18:59:54,950 - INFO -   Expert 0: GINE (α=0.3088)
2025-08-26 18:59:54,950 - INFO -   Expert 1: CustomGatedGCN (α=0.3645) ← SELECTED
2025-08-26 18:59:54,950 - INFO -   Expert 2: GATV2 (α=0.3267)
2025-08-26 18:59:54,950 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-26 18:59:54,950 - INFO - ============================================================

2025-08-26 18:59:54,950 - INFO - 
============================================================
2025-08-26 18:59:54,950 - INFO - Layer layer_7 Expert Selection:
2025-08-26 18:59:54,950 - INFO -   Expert 0: GINE (α=0.2782)
2025-08-26 18:59:54,950 - INFO -   Expert 1: CustomGatedGCN (α=0.4479) ← SELECTED
2025-08-26 18:59:54,950 - INFO -   Expert 2: GATV2 (α=0.2739)
2025-08-26 18:59:54,950 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-26 18:59:54,950 - INFO - ============================================================

2025-08-26 18:59:54,950 - INFO - 
============================================================
2025-08-26 18:59:54,950 - INFO - Layer layer_8 Expert Selection:
2025-08-26 18:59:54,950 - INFO -   Expert 0: GINE (α=0.3139)
2025-08-26 18:59:54,950 - INFO -   Expert 1: CustomGatedGCN (α=0.3993) ← SELECTED
2025-08-26 18:59:54,950 - INFO -   Expert 2: GATV2 (α=0.2868)
2025-08-26 18:59:54,950 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-26 18:59:54,950 - INFO - ============================================================

2025-08-26 18:59:54,950 - INFO - 
============================================================
2025-08-26 18:59:54,950 - INFO - Layer layer_9 Expert Selection:
2025-08-26 18:59:54,950 - INFO -   Expert 0: GINE (α=0.3029)
2025-08-26 18:59:54,950 - INFO -   Expert 1: CustomGatedGCN (α=0.3737) ← SELECTED
2025-08-26 18:59:54,950 - INFO -   Expert 2: GATV2 (α=0.3233)
2025-08-26 18:59:54,951 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-26 18:59:54,951 - INFO - ============================================================

2025-08-26 18:59:54,951 - INFO - 
============================================================
2025-08-26 18:59:54,951 - INFO - Layer layer_10 Expert Selection:
2025-08-26 18:59:54,951 - INFO -   Expert 0: GINE (α=0.3094)
2025-08-26 18:59:54,951 - INFO -   Expert 1: CustomGatedGCN (α=0.3759) ← SELECTED
2025-08-26 18:59:54,951 - INFO -   Expert 2: GATV2 (α=0.3147)
2025-08-26 18:59:54,951 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-26 18:59:54,951 - INFO - ============================================================

2025-08-26 18:59:54,951 - INFO - 
============================================================
2025-08-26 18:59:54,951 - INFO - Layer layer_11 Expert Selection:
2025-08-26 18:59:54,951 - INFO -   Expert 0: GINE (α=0.2897)
2025-08-26 18:59:54,951 - INFO -   Expert 1: CustomGatedGCN (α=0.3661) ← SELECTED
2025-08-26 18:59:54,951 - INFO -   Expert 2: GATV2 (α=0.3442)
2025-08-26 18:59:54,951 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-26 18:59:54,951 - INFO - ============================================================

2025-08-26 18:59:54,951 - INFO - 
============================================================
2025-08-26 18:59:54,951 - INFO - Layer layer_12 Expert Selection:
2025-08-26 18:59:54,951 - INFO -   Expert 0: GINE (α=0.3138)
2025-08-26 18:59:54,951 - INFO -   Expert 1: CustomGatedGCN (α=0.3511) ← SELECTED
2025-08-26 18:59:54,951 - INFO -   Expert 2: GATV2 (α=0.3352)
2025-08-26 18:59:54,951 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-26 18:59:54,951 - INFO - ============================================================

2025-08-26 18:59:54,951 - INFO - 
============================================================
2025-08-26 18:59:54,951 - INFO - Layer layer_13 Expert Selection:
2025-08-26 18:59:54,951 - INFO -   Expert 0: GINE (α=0.2856)
2025-08-26 18:59:54,952 - INFO -   Expert 1: CustomGatedGCN (α=0.4430) ← SELECTED
2025-08-26 18:59:54,952 - INFO -   Expert 2: GATV2 (α=0.2714)
2025-08-26 18:59:54,952 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-26 18:59:54,952 - INFO - ============================================================

2025-08-26 18:59:54,952 - INFO - 
============================================================
2025-08-26 18:59:54,952 - INFO - Layer layer_14 Expert Selection:
2025-08-26 18:59:54,952 - INFO -   Expert 0: GINE (α=0.3352) ← SELECTED
2025-08-26 18:59:54,952 - INFO -   Expert 1: CustomGatedGCN (α=0.3323)
2025-08-26 18:59:54,952 - INFO -   Expert 2: GATV2 (α=0.3325)
2025-08-26 18:59:54,952 - INFO - Selected Expert Index: 0 (GINE)
2025-08-26 18:59:54,952 - INFO - ============================================================

2025-08-26 18:59:54,952 - INFO - 
============================================================
2025-08-26 18:59:54,952 - INFO - Layer layer_15 Expert Selection:
2025-08-26 18:59:54,952 - INFO -   Expert 0: GINE (α=0.2455)
2025-08-26 18:59:54,952 - INFO -   Expert 1: CustomGatedGCN (α=0.4098) ← SELECTED
2025-08-26 18:59:54,952 - INFO -   Expert 2: GATV2 (α=0.3447)
2025-08-26 18:59:54,952 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-26 18:59:54,952 - INFO - ============================================================

=== MODEL PARAMETER COMPARISON ===
Original DARTS model parameters: 728,678
2025-08-26 18:59:55,022 - INFO - Layer 0: Using ONLY Expert 0 (GINE)
2025-08-26 18:59:55,022 - INFO - DiscreteNASLayer 0: Using ONLY Expert 0 (GINE)
2025-08-26 18:59:55,027 - INFO - Layer 1: Using ONLY Expert 2 (GATV2)
2025-08-26 18:59:55,027 - INFO - DiscreteNASLayer 1: Using ONLY Expert 2 (GATV2)
2025-08-26 18:59:55,030 - INFO - Layer 2: Using ONLY Expert 2 (GATV2)
2025-08-26 18:59:55,030 - INFO - DiscreteNASLayer 2: Using ONLY Expert 2 (GATV2)
2025-08-26 18:59:55,032 - INFO - Layer 3: Using ONLY Expert 2 (GATV2)
2025-08-26 18:59:55,032 - INFO - DiscreteNASLayer 3: Using ONLY Expert 2 (GATV2)
2025-08-26 18:59:55,035 - INFO - Layer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,035 - INFO - DiscreteNASLayer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,037 - INFO - Layer 5: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,037 - INFO - DiscreteNASLayer 5: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,040 - INFO - Layer 6: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,040 - INFO - DiscreteNASLayer 6: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,043 - INFO - Layer 7: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,043 - INFO - DiscreteNASLayer 7: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,045 - INFO - Layer 8: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,045 - INFO - DiscreteNASLayer 8: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,048 - INFO - Layer 9: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,048 - INFO - DiscreteNASLayer 9: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,051 - INFO - Layer 10: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,051 - INFO - DiscreteNASLayer 10: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,054 - INFO - Layer 11: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,054 - INFO - DiscreteNASLayer 11: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,056 - INFO - Layer 12: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,056 - INFO - DiscreteNASLayer 12: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,059 - INFO - Layer 13: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,059 - INFO - DiscreteNASLayer 13: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,062 - INFO - Layer 14: Using ONLY Expert 0 (GINE)
2025-08-26 18:59:55,062 - INFO - DiscreteNASLayer 14: Using ONLY Expert 0 (GINE)
2025-08-26 18:59:55,064 - INFO - Layer 15: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-26 18:59:55,064 - INFO - DiscreteNASLayer 15: Using ONLY Expert 1 (CustomGatedGCN)
Fresh discrete model parameters: 510,662
Parameter difference: -218,016
✓ Used cfg.share.dim_in (raw input) instead of self.encoder.dim_in (processed)
✓ Fresh discrete model with correct input dimensions
2025-08-26 18:59:55,089 - INFO - Replaced inner model with discrete version
2025-08-26 18:59:55,091 - INFO - Creating fresh optimizer/scheduler for discrete model...
2025-08-26 18:59:55,095 - INFO - Fresh optimizer created: AdamW
2025-08-26 18:59:55,095 - INFO - Fresh scheduler created: LambdaLR
2025-08-26 18:59:55,095 - INFO - Discrete model parameters: 510,662
2025-08-26 18:59:55,095 - INFO - ============================================================
2025-08-26 18:59:55,095 - INFO - PHASE 2: DISCRETE TRAINING WITH UNCERTAINTY
2025-08-26 18:59:55,096 - INFO - ============================================================
2025-08-26 18:59:55,096 - INFO - === Epoch 0 ===
2025-08-26 19:01:22,286 - INFO - train: {'epoch': 0, 'time_epoch': 86.3534, 'eta': 8548.98693, 'eta_hours': 2.37472, 'loss': 1.79535913, 'lr': 0.0, 'params': 510662, 'time_iter': 0.13817, 'accuracy': 0.16688, 'f1': 0.08223, 'accuracy-SBM': 0.16676, 'auc': 0.50059}
2025-08-26 19:01:22,308 - INFO - ...computing epoch stats took: 0.84s
2025-08-26 19:01:26,821 - INFO - val: {'epoch': 0, 'time_epoch': 4.47635, 'loss': 1.79497772, 'lr': 0, 'params': 510662, 'time_iter': 0.07105, 'accuracy': 0.16695, 'f1': 0.08618, 'accuracy-SBM': 0.16797, 'auc': 0.50316}
2025-08-26 19:01:26,832 - INFO - ...computing epoch stats took: 0.04s
2025-08-26 19:01:32,815 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:01:32,874 - INFO - test: {'epoch': 0, 'time_epoch': 4.75881, 'loss': 1.79552914, 'lr': 0, 'params': 510662, 'time_iter': 0.07554, 'accuracy': 0.16612, 'f1': 0.08743, 'accuracy-SBM': 0.16687, 'auc': 0.50093}
2025-08-26 19:01:32,892 - INFO - ...computing epoch stats took: 0.07s
2025-08-26 19:01:32,892 - INFO - > Epoch 0: took 97.8s (avg 97.8s) | Best so far: epoch 0	train_loss: 1.7954 train_accuracy-SBM: 0.1668	val_loss: 1.7950 val_accuracy-SBM: 0.1680	test_loss: 1.7955 test_accuracy-SBM: 0.1669
2025-08-26 19:01:32,892 - INFO - === Epoch 1 ===
2025-08-26 19:02:57,850 - INFO - train: {'epoch': 1, 'time_epoch': 84.72323, 'eta': 8382.75513, 'eta_hours': 2.32854, 'loss': 1.6060046, 'lr': 0.0002, 'params': 510662, 'time_iter': 0.13556, 'accuracy': 0.40144, 'f1': 0.39245, 'accuracy-SBM': 0.40141, 'auc': 0.732}
2025-08-26 19:02:57,856 - INFO - ...computing epoch stats took: 0.22s
2025-08-26 19:03:02,195 - INFO - val: {'epoch': 1, 'time_epoch': 4.28599, 'loss': 1.55627106, 'lr': 0, 'params': 510662, 'time_iter': 0.06803, 'accuracy': 0.41054, 'f1': 0.40073, 'accuracy-SBM': 0.41056, 'auc': 0.78284}
2025-08-26 19:03:02,197 - INFO - ...computing epoch stats took: 0.05s
2025-08-26 19:03:07,981 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:03:08,034 - INFO - test: {'epoch': 1, 'time_epoch': 4.58846, 'loss': 1.55268934, 'lr': 0, 'params': 510662, 'time_iter': 0.07283, 'accuracy': 0.41355, 'f1': 0.40374, 'accuracy-SBM': 0.41284, 'auc': 0.78382}
2025-08-26 19:03:08,036 - INFO - ...computing epoch stats took: 0.04s
2025-08-26 19:03:08,036 - INFO - > Epoch 1: took 95.1s (avg 96.5s) | Best so far: epoch 1	train_loss: 1.6060 train_accuracy-SBM: 0.4014	val_loss: 1.5563 val_accuracy-SBM: 0.4106	test_loss: 1.5527 test_accuracy-SBM: 0.4128
2025-08-26 19:03:08,036 - INFO - === Epoch 2 ===
2025-08-26 19:04:32,841 - INFO - train: {'epoch': 2, 'time_epoch': 84.56403, 'eta': 8265.71471, 'eta_hours': 2.29603, 'loss': 1.29615368, 'lr': 0.0004, 'params': 510662, 'time_iter': 0.1353, 'accuracy': 0.55766, 'f1': 0.55559, 'accuracy-SBM': 0.55765, 'auc': 0.83744}
2025-08-26 19:04:32,847 - INFO - ...computing epoch stats took: 0.23s
2025-08-26 19:04:37,156 - INFO - val: {'epoch': 2, 'time_epoch': 4.25914, 'loss': 1.5393921, 'lr': 0, 'params': 510662, 'time_iter': 0.06761, 'accuracy': 0.40882, 'f1': 0.39826, 'accuracy-SBM': 0.40795, 'auc': 0.77809}
2025-08-26 19:04:37,157 - INFO - ...computing epoch stats took: 0.05s
2025-08-26 19:04:42,931 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:04:42,972 - INFO - test: {'epoch': 2, 'time_epoch': 4.5747, 'loss': 1.5348291, 'lr': 0, 'params': 510662, 'time_iter': 0.07261, 'accuracy': 0.41039, 'f1': 0.4028, 'accuracy-SBM': 0.41005, 'auc': 0.77887}
2025-08-26 19:04:42,974 - INFO - ...computing epoch stats took: 0.03s
2025-08-26 19:04:42,974 - INFO - > Epoch 2: took 94.9s (avg 96.0s) | Best so far: epoch 1	train_loss: 1.6060 train_accuracy-SBM: 0.4014	val_loss: 1.5563 val_accuracy-SBM: 0.4106	test_loss: 1.5527 test_accuracy-SBM: 0.4128
2025-08-26 19:04:42,974 - INFO - === Epoch 3 ===
2025-08-26 19:06:17,493 - INFO - train: {'epoch': 3, 'time_epoch': 94.26483, 'eta': 8397.73173, 'eta_hours': 2.3327, 'loss': 1.07018365, 'lr': 0.0006, 'params': 510662, 'time_iter': 0.15082, 'accuracy': 0.63217, 'f1': 0.63152, 'accuracy-SBM': 0.63216, 'auc': 0.88923}
2025-08-26 19:06:21,759 - INFO - val: {'epoch': 3, 'time_epoch': 4.22027, 'loss': 1.13673213, 'lr': 0, 'params': 510662, 'time_iter': 0.06699, 'accuracy': 0.59492, 'f1': 0.59759, 'accuracy-SBM': 0.59485, 'auc': 0.8841}
2025-08-26 19:06:27,562 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:06:27,623 - INFO - test: {'epoch': 3, 'time_epoch': 4.57911, 'loss': 1.12215125, 'lr': 0, 'params': 510662, 'time_iter': 0.07268, 'accuracy': 0.60187, 'f1': 0.60439, 'accuracy-SBM': 0.60163, 'auc': 0.88674}
2025-08-26 19:06:27,625 - INFO - > Epoch 3: took 104.7s (avg 98.1s) | Best so far: epoch 3	train_loss: 1.0702 train_accuracy-SBM: 0.6322	val_loss: 1.1367 val_accuracy-SBM: 0.5948	test_loss: 1.1222 test_accuracy-SBM: 0.6016
2025-08-26 19:06:27,625 - INFO - === Epoch 4 ===
2025-08-26 19:07:55,885 - INFO - train: {'epoch': 4, 'time_epoch': 88.02012, 'eta': 8320.58663, 'eta_hours': 2.31127, 'loss': 0.90411496, 'lr': 0.0008, 'params': 510662, 'time_iter': 0.14083, 'accuracy': 0.6854, 'f1': 0.68537, 'accuracy-SBM': 0.6854, 'auc': 0.92107}
2025-08-26 19:08:00,234 - INFO - val: {'epoch': 4, 'time_epoch': 4.29815, 'loss': 0.89886472, 'lr': 0, 'params': 510662, 'time_iter': 0.06822, 'accuracy': 0.6791, 'f1': 0.67894, 'accuracy-SBM': 0.67909, 'auc': 0.92617}
2025-08-26 19:08:06,071 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:08:06,113 - INFO - test: {'epoch': 4, 'time_epoch': 4.60902, 'loss': 0.89797859, 'lr': 0, 'params': 510662, 'time_iter': 0.07316, 'accuracy': 0.68104, 'f1': 0.68119, 'accuracy-SBM': 0.68132, 'auc': 0.92568}
2025-08-26 19:08:06,115 - INFO - > Epoch 4: took 98.5s (avg 98.2s) | Best so far: epoch 4	train_loss: 0.9041 train_accuracy-SBM: 0.6854	val_loss: 0.8989 val_accuracy-SBM: 0.6791	test_loss: 0.8980 test_accuracy-SBM: 0.6813
2025-08-26 19:08:06,116 - INFO - === Epoch 5 ===
2025-08-26 19:09:30,854 - INFO - train: {'epoch': 5, 'time_epoch': 84.49635, 'eta': 8184.61079, 'eta_hours': 2.2735, 'loss': 0.83548644, 'lr': 0.001, 'params': 510662, 'time_iter': 0.13519, 'accuracy': 0.70374, 'f1': 0.70373, 'accuracy-SBM': 0.70374, 'auc': 0.93162}
2025-08-26 19:09:35,121 - INFO - val: {'epoch': 5, 'time_epoch': 4.22214, 'loss': 0.90458552, 'lr': 0, 'params': 510662, 'time_iter': 0.06702, 'accuracy': 0.67089, 'f1': 0.66991, 'accuracy-SBM': 0.67171, 'auc': 0.92566}
2025-08-26 19:09:41,000 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:09:41,052 - INFO - test: {'epoch': 5, 'time_epoch': 4.55275, 'loss': 0.89822056, 'lr': 0, 'params': 510662, 'time_iter': 0.07227, 'accuracy': 0.67303, 'f1': 0.67177, 'accuracy-SBM': 0.67385, 'auc': 0.92662}
2025-08-26 19:09:41,054 - INFO - > Epoch 5: took 94.9s (avg 97.7s) | Best so far: epoch 4	train_loss: 0.9041 train_accuracy-SBM: 0.6854	val_loss: 0.8989 val_accuracy-SBM: 0.6791	test_loss: 0.8980 test_accuracy-SBM: 0.6813
2025-08-26 19:09:41,054 - INFO - === Epoch 6 ===
2025-08-26 19:11:05,841 - INFO - train: {'epoch': 6, 'time_epoch': 84.55061, 'eta': 8064.06415, 'eta_hours': 2.24002, 'loss': 0.78454691, 'lr': 0.00099973, 'params': 510662, 'time_iter': 0.13528, 'accuracy': 0.71961, 'f1': 0.71961, 'accuracy-SBM': 0.71961, 'auc': 0.9392}
2025-08-26 19:11:10,155 - INFO - val: {'epoch': 6, 'time_epoch': 4.26802, 'loss': 0.76824579, 'lr': 0, 'params': 510662, 'time_iter': 0.06775, 'accuracy': 0.72475, 'f1': 0.72495, 'accuracy-SBM': 0.725, 'auc': 0.94282}
2025-08-26 19:11:15,976 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:11:16,015 - INFO - test: {'epoch': 6, 'time_epoch': 4.52375, 'loss': 0.77217326, 'lr': 0, 'params': 510662, 'time_iter': 0.07181, 'accuracy': 0.7233, 'f1': 0.72338, 'accuracy-SBM': 0.72359, 'auc': 0.94216}
2025-08-26 19:11:16,017 - INFO - > Epoch 6: took 95.0s (avg 97.3s) | Best so far: epoch 6	train_loss: 0.7845 train_accuracy-SBM: 0.7196	val_loss: 0.7682 val_accuracy-SBM: 0.7250	test_loss: 0.7722 test_accuracy-SBM: 0.7236
2025-08-26 19:11:16,017 - INFO - === Epoch 7 ===
2025-08-26 19:12:47,385 - INFO - train: {'epoch': 7, 'time_epoch': 90.99655, 'eta': 8026.64485, 'eta_hours': 2.22962, 'loss': 0.75507841, 'lr': 0.00099891, 'params': 510662, 'time_iter': 0.14559, 'accuracy': 0.72954, 'f1': 0.72954, 'accuracy-SBM': 0.72953, 'auc': 0.94346}
2025-08-26 19:12:51,778 - INFO - val: {'epoch': 7, 'time_epoch': 4.33284, 'loss': 0.72924883, 'lr': 0, 'params': 510662, 'time_iter': 0.06878, 'accuracy': 0.73932, 'f1': 0.73923, 'accuracy-SBM': 0.73945, 'auc': 0.94811}
2025-08-26 19:12:57,707 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:12:57,748 - INFO - test: {'epoch': 7, 'time_epoch': 4.60961, 'loss': 0.71972649, 'lr': 0, 'params': 510662, 'time_iter': 0.07317, 'accuracy': 0.74277, 'f1': 0.7428, 'accuracy-SBM': 0.74274, 'auc': 0.94947}
2025-08-26 19:12:57,750 - INFO - > Epoch 7: took 101.7s (avg 97.8s) | Best so far: epoch 7	train_loss: 0.7551 train_accuracy-SBM: 0.7295	val_loss: 0.7292 val_accuracy-SBM: 0.7395	test_loss: 0.7197 test_accuracy-SBM: 0.7427
2025-08-26 19:12:57,751 - INFO - === Epoch 8 ===
2025-08-26 19:14:27,856 - INFO - train: {'epoch': 8, 'time_epoch': 89.74897, 'eta': 7964.70513, 'eta_hours': 2.21242, 'loss': 0.73574658, 'lr': 0.00099754, 'params': 510662, 'time_iter': 0.1436, 'accuracy': 0.73617, 'f1': 0.73617, 'accuracy-SBM': 0.73617, 'auc': 0.9462}
2025-08-26 19:14:32,303 - INFO - val: {'epoch': 8, 'time_epoch': 4.38995, 'loss': 0.74937967, 'lr': 0, 'params': 510662, 'time_iter': 0.06968, 'accuracy': 0.73406, 'f1': 0.73288, 'accuracy-SBM': 0.7334, 'auc': 0.9457}
2025-08-26 19:14:38,222 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:14:38,269 - INFO - test: {'epoch': 8, 'time_epoch': 4.64716, 'loss': 0.74644245, 'lr': 0, 'params': 510662, 'time_iter': 0.07376, 'accuracy': 0.73355, 'f1': 0.73308, 'accuracy-SBM': 0.73319, 'auc': 0.94649}
2025-08-26 19:14:38,271 - INFO - > Epoch 8: took 100.5s (avg 98.1s) | Best so far: epoch 7	train_loss: 0.7551 train_accuracy-SBM: 0.7295	val_loss: 0.7292 val_accuracy-SBM: 0.7395	test_loss: 0.7197 test_accuracy-SBM: 0.7427
2025-08-26 19:14:38,271 - INFO - === Epoch 9 ===
2025-08-26 19:16:03,478 - INFO - train: {'epoch': 9, 'time_epoch': 84.96485, 'eta': 7854.14646, 'eta_hours': 2.18171, 'loss': 0.72298139, 'lr': 0.00099563, 'params': 510662, 'time_iter': 0.13594, 'accuracy': 0.74034, 'f1': 0.74034, 'accuracy-SBM': 0.74034, 'auc': 0.94792}
2025-08-26 19:16:07,768 - INFO - val: {'epoch': 9, 'time_epoch': 4.24495, 'loss': 0.68837223, 'lr': 0, 'params': 510662, 'time_iter': 0.06738, 'accuracy': 0.75457, 'f1': 0.75431, 'accuracy-SBM': 0.75433, 'auc': 0.95316}
2025-08-26 19:16:13,485 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:16:13,526 - INFO - test: {'epoch': 9, 'time_epoch': 4.55562, 'loss': 0.68054258, 'lr': 0, 'params': 510662, 'time_iter': 0.07231, 'accuracy': 0.7564, 'f1': 0.75633, 'accuracy-SBM': 0.75632, 'auc': 0.95437}
2025-08-26 19:16:13,528 - INFO - > Epoch 9: took 95.3s (avg 97.8s) | Best so far: epoch 9	train_loss: 0.7230 train_accuracy-SBM: 0.7403	val_loss: 0.6884 val_accuracy-SBM: 0.7543	test_loss: 0.6805 test_accuracy-SBM: 0.7563
2025-08-26 19:16:13,528 - INFO - === Epoch 10 ===
2025-08-26 19:17:39,185 - INFO - train: {'epoch': 10, 'time_epoch': 85.41254, 'eta': 7751.86343, 'eta_hours': 2.1533, 'loss': 0.707237, 'lr': 0.00099318, 'params': 510662, 'time_iter': 0.13666, 'accuracy': 0.7456, 'f1': 0.7456, 'accuracy-SBM': 0.7456, 'auc': 0.95009}
2025-08-26 19:17:43,500 - INFO - val: {'epoch': 10, 'time_epoch': 4.26848, 'loss': 0.67766725, 'lr': 0, 'params': 510662, 'time_iter': 0.06775, 'accuracy': 0.75806, 'f1': 0.75788, 'accuracy-SBM': 0.75792, 'auc': 0.95456}
2025-08-26 19:17:49,242 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:17:49,282 - INFO - test: {'epoch': 10, 'time_epoch': 4.53433, 'loss': 0.67784085, 'lr': 0, 'params': 510662, 'time_iter': 0.07197, 'accuracy': 0.75751, 'f1': 0.75749, 'accuracy-SBM': 0.75745, 'auc': 0.95457}
2025-08-26 19:17:49,294 - INFO - > Epoch 10: took 95.8s (avg 97.7s) | Best so far: epoch 10	train_loss: 0.7072 train_accuracy-SBM: 0.7456	val_loss: 0.6777 val_accuracy-SBM: 0.7579	test_loss: 0.6778 test_accuracy-SBM: 0.7574
2025-08-26 19:17:49,294 - INFO - === Epoch 11 ===
2025-08-26 19:19:13,954 - INFO - train: {'epoch': 11, 'time_epoch': 84.32128, 'eta': 7644.38955, 'eta_hours': 2.12344, 'loss': 0.70140621, 'lr': 0.00099019, 'params': 510662, 'time_iter': 0.13491, 'accuracy': 0.74805, 'f1': 0.74804, 'accuracy-SBM': 0.74805, 'auc': 0.95086}
2025-08-26 19:19:18,226 - INFO - val: {'epoch': 11, 'time_epoch': 4.22667, 'loss': 0.70306727, 'lr': 0, 'params': 510662, 'time_iter': 0.06709, 'accuracy': 0.74874, 'f1': 0.74869, 'accuracy-SBM': 0.74887, 'auc': 0.95141}
2025-08-26 19:19:23,907 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:19:23,954 - INFO - test: {'epoch': 11, 'time_epoch': 4.53944, 'loss': 0.68608909, 'lr': 0, 'params': 510662, 'time_iter': 0.07205, 'accuracy': 0.75108, 'f1': 0.75121, 'accuracy-SBM': 0.75114, 'auc': 0.9539}
2025-08-26 19:19:23,956 - INFO - > Epoch 11: took 94.7s (avg 97.4s) | Best so far: epoch 10	train_loss: 0.7072 train_accuracy-SBM: 0.7456	val_loss: 0.6777 val_accuracy-SBM: 0.7579	test_loss: 0.6778 test_accuracy-SBM: 0.7574
2025-08-26 19:19:23,956 - INFO - === Epoch 12 ===
2025-08-26 19:20:58,904 - INFO - train: {'epoch': 12, 'time_epoch': 94.62373, 'eta': 7609.42477, 'eta_hours': 2.11373, 'loss': 0.69294057, 'lr': 0.00098666, 'params': 510662, 'time_iter': 0.1514, 'accuracy': 0.75023, 'f1': 0.75023, 'accuracy-SBM': 0.75023, 'auc': 0.95202}
2025-08-26 19:21:03,899 - INFO - val: {'epoch': 12, 'time_epoch': 4.94719, 'loss': 0.69992219, 'lr': 0, 'params': 510662, 'time_iter': 0.07853, 'accuracy': 0.74928, 'f1': 0.74914, 'accuracy-SBM': 0.74925, 'auc': 0.9517}
2025-08-26 19:21:11,064 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:21:11,107 - INFO - test: {'epoch': 12, 'time_epoch': 4.79001, 'loss': 0.6981315, 'lr': 0, 'params': 510662, 'time_iter': 0.07603, 'accuracy': 0.75001, 'f1': 0.74994, 'accuracy-SBM': 0.74999, 'auc': 0.95203}
2025-08-26 19:21:11,110 - INFO - > Epoch 12: took 107.2s (avg 98.2s) | Best so far: epoch 10	train_loss: 0.7072 train_accuracy-SBM: 0.7456	val_loss: 0.6777 val_accuracy-SBM: 0.7579	test_loss: 0.6778 test_accuracy-SBM: 0.7574
2025-08-26 19:21:11,110 - INFO - === Epoch 13 ===
2025-08-26 19:22:37,088 - INFO - train: {'epoch': 13, 'time_epoch': 85.73831, 'eta': 7511.35547, 'eta_hours': 2.08649, 'loss': 0.68214522, 'lr': 0.0009826, 'params': 510662, 'time_iter': 0.13718, 'accuracy': 0.75469, 'f1': 0.75469, 'accuracy-SBM': 0.75469, 'auc': 0.95348}
2025-08-26 19:22:41,369 - INFO - val: {'epoch': 13, 'time_epoch': 4.23464, 'loss': 0.68187182, 'lr': 0, 'params': 510662, 'time_iter': 0.06722, 'accuracy': 0.75736, 'f1': 0.75757, 'accuracy-SBM': 0.75737, 'auc': 0.95416}
2025-08-26 19:22:47,055 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:22:47,097 - INFO - test: {'epoch': 13, 'time_epoch': 4.24918, 'loss': 0.66875445, 'lr': 0, 'params': 510662, 'time_iter': 0.06745, 'accuracy': 0.76059, 'f1': 0.7605, 'accuracy-SBM': 0.76075, 'auc': 0.95624}
2025-08-26 19:22:47,099 - INFO - > Epoch 13: took 96.0s (avg 98.0s) | Best so far: epoch 10	train_loss: 0.7072 train_accuracy-SBM: 0.7456	val_loss: 0.6777 val_accuracy-SBM: 0.7579	test_loss: 0.6778 test_accuracy-SBM: 0.7574
2025-08-26 19:22:47,099 - INFO - === Epoch 14 ===
2025-08-26 19:24:11,905 - INFO - train: {'epoch': 14, 'time_epoch': 84.5654, 'eta': 7408.2838, 'eta_hours': 2.05786, 'loss': 0.67954961, 'lr': 0.00097802, 'params': 510662, 'time_iter': 0.1353, 'accuracy': 0.75567, 'f1': 0.75567, 'accuracy-SBM': 0.75567, 'auc': 0.9538}
2025-08-26 19:24:16,183 - INFO - val: {'epoch': 14, 'time_epoch': 4.23337, 'loss': 0.67078655, 'lr': 0, 'params': 510662, 'time_iter': 0.0672, 'accuracy': 0.75867, 'f1': 0.7585, 'accuracy-SBM': 0.75851, 'auc': 0.95578}
2025-08-26 19:24:21,813 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:24:21,853 - INFO - test: {'epoch': 14, 'time_epoch': 4.57613, 'loss': 0.66615261, 'lr': 0, 'params': 510662, 'time_iter': 0.07264, 'accuracy': 0.76018, 'f1': 0.76032, 'accuracy-SBM': 0.76006, 'auc': 0.95633}
2025-08-26 19:24:21,855 - INFO - > Epoch 14: took 94.8s (avg 97.8s) | Best so far: epoch 14	train_loss: 0.6795 train_accuracy-SBM: 0.7557	val_loss: 0.6708 val_accuracy-SBM: 0.7585	test_loss: 0.6662 test_accuracy-SBM: 0.7601
2025-08-26 19:24:21,855 - INFO - === Epoch 15 ===
2025-08-26 19:25:46,720 - INFO - train: {'epoch': 15, 'time_epoch': 84.62496, 'eta': 7307.83809, 'eta_hours': 2.02996, 'loss': 0.67302526, 'lr': 0.00097291, 'params': 510662, 'time_iter': 0.1354, 'accuracy': 0.75766, 'f1': 0.75766, 'accuracy-SBM': 0.75766, 'auc': 0.95469}
2025-08-26 19:25:51,021 - INFO - val: {'epoch': 15, 'time_epoch': 4.25686, 'loss': 0.67299609, 'lr': 0, 'params': 510662, 'time_iter': 0.06757, 'accuracy': 0.75864, 'f1': 0.75805, 'accuracy-SBM': 0.75827, 'auc': 0.95539}
2025-08-26 19:25:56,617 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:25:56,663 - INFO - test: {'epoch': 15, 'time_epoch': 4.22592, 'loss': 0.66075181, 'lr': 0, 'params': 510662, 'time_iter': 0.06708, 'accuracy': 0.76272, 'f1': 0.7626, 'accuracy-SBM': 0.76263, 'auc': 0.95726}
2025-08-26 19:25:56,665 - INFO - > Epoch 15: took 94.8s (avg 97.6s) | Best so far: epoch 14	train_loss: 0.6795 train_accuracy-SBM: 0.7557	val_loss: 0.6708 val_accuracy-SBM: 0.7585	test_loss: 0.6662 test_accuracy-SBM: 0.7601
2025-08-26 19:25:56,665 - INFO - === Epoch 16 ===
2025-08-26 19:27:21,320 - INFO - train: {'epoch': 16, 'time_epoch': 84.32481, 'eta': 7207.7882, 'eta_hours': 2.00216, 'loss': 0.66749608, 'lr': 0.00096728, 'params': 510662, 'time_iter': 0.13492, 'accuracy': 0.75964, 'f1': 0.75964, 'accuracy-SBM': 0.75964, 'auc': 0.95541}
2025-08-26 19:27:25,596 - INFO - val: {'epoch': 16, 'time_epoch': 4.22843, 'loss': 0.68669329, 'lr': 0, 'params': 510662, 'time_iter': 0.06712, 'accuracy': 0.75277, 'f1': 0.75268, 'accuracy-SBM': 0.7528, 'auc': 0.9536}
2025-08-26 19:27:31,286 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:27:31,325 - INFO - test: {'epoch': 16, 'time_epoch': 4.55313, 'loss': 0.66952813, 'lr': 0, 'params': 510662, 'time_iter': 0.07227, 'accuracy': 0.7583, 'f1': 0.75816, 'accuracy-SBM': 0.75823, 'auc': 0.95572}
2025-08-26 19:27:31,327 - INFO - > Epoch 16: took 94.7s (avg 97.4s) | Best so far: epoch 14	train_loss: 0.6795 train_accuracy-SBM: 0.7557	val_loss: 0.6708 val_accuracy-SBM: 0.7585	test_loss: 0.6662 test_accuracy-SBM: 0.7601
2025-08-26 19:27:31,327 - INFO - === Epoch 17 ===
2025-08-26 19:29:08,405 - INFO - train: {'epoch': 17, 'time_epoch': 96.83125, 'eta': 7166.45933, 'eta_hours': 1.99068, 'loss': 0.66277587, 'lr': 0.00096114, 'params': 510662, 'time_iter': 0.15493, 'accuracy': 0.76147, 'f1': 0.76147, 'accuracy-SBM': 0.76147, 'auc': 0.95604}
2025-08-26 19:29:12,722 - INFO - val: {'epoch': 17, 'time_epoch': 4.23368, 'loss': 0.67529366, 'lr': 0, 'params': 510662, 'time_iter': 0.0672, 'accuracy': 0.75924, 'f1': 0.75919, 'accuracy-SBM': 0.75907, 'auc': 0.95464}
2025-08-26 19:29:18,560 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:29:18,599 - INFO - test: {'epoch': 17, 'time_epoch': 4.58401, 'loss': 0.66802266, 'lr': 0, 'params': 510662, 'time_iter': 0.07276, 'accuracy': 0.75946, 'f1': 0.75946, 'accuracy-SBM': 0.75941, 'auc': 0.95569}
2025-08-26 19:29:18,602 - INFO - > Epoch 17: took 107.3s (avg 98.0s) | Best so far: epoch 17	train_loss: 0.6628 train_accuracy-SBM: 0.7615	val_loss: 0.6753 val_accuracy-SBM: 0.7591	test_loss: 0.6680 test_accuracy-SBM: 0.7594
2025-08-26 19:29:18,602 - INFO - === Epoch 18 ===
2025-08-26 19:30:45,887 - INFO - train: {'epoch': 18, 'time_epoch': 87.04047, 'eta': 7077.54847, 'eta_hours': 1.96599, 'loss': 0.65665151, 'lr': 0.0009545, 'params': 510662, 'time_iter': 0.13926, 'accuracy': 0.76321, 'f1': 0.76321, 'accuracy-SBM': 0.76321, 'auc': 0.95686}
2025-08-26 19:30:50,225 - INFO - val: {'epoch': 18, 'time_epoch': 4.29204, 'loss': 0.68003615, 'lr': 0, 'params': 510662, 'time_iter': 0.06813, 'accuracy': 0.75934, 'f1': 0.75906, 'accuracy-SBM': 0.75907, 'auc': 0.95391}
2025-08-26 19:30:55,769 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:30:55,810 - INFO - test: {'epoch': 18, 'time_epoch': 4.31826, 'loss': 0.671747, 'lr': 0, 'params': 510662, 'time_iter': 0.06854, 'accuracy': 0.75909, 'f1': 0.75894, 'accuracy-SBM': 0.75917, 'auc': 0.95527}
2025-08-26 19:30:55,812 - INFO - > Epoch 18: took 97.2s (avg 97.9s) | Best so far: epoch 17	train_loss: 0.6628 train_accuracy-SBM: 0.7615	val_loss: 0.6753 val_accuracy-SBM: 0.7591	test_loss: 0.6680 test_accuracy-SBM: 0.7594
2025-08-26 19:30:55,812 - INFO - === Epoch 19 ===
2025-08-26 19:32:21,356 - INFO - train: {'epoch': 19, 'time_epoch': 85.30054, 'eta': 6981.86494, 'eta_hours': 1.93941, 'loss': 0.65669394, 'lr': 0.00094736, 'params': 510662, 'time_iter': 0.13648, 'accuracy': 0.76355, 'f1': 0.76355, 'accuracy-SBM': 0.76355, 'auc': 0.95684}
2025-08-26 19:32:25,700 - INFO - val: {'epoch': 19, 'time_epoch': 4.29742, 'loss': 0.67152215, 'lr': 0, 'params': 510662, 'time_iter': 0.06821, 'accuracy': 0.76215, 'f1': 0.76168, 'accuracy-SBM': 0.76186, 'auc': 0.95549}
2025-08-26 19:32:31,477 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:32:31,518 - INFO - test: {'epoch': 19, 'time_epoch': 4.61684, 'loss': 0.65315425, 'lr': 0, 'params': 510662, 'time_iter': 0.07328, 'accuracy': 0.76411, 'f1': 0.76397, 'accuracy-SBM': 0.76405, 'auc': 0.95798}
2025-08-26 19:32:31,520 - INFO - > Epoch 19: took 95.7s (avg 97.8s) | Best so far: epoch 19	train_loss: 0.6567 train_accuracy-SBM: 0.7635	val_loss: 0.6715 val_accuracy-SBM: 0.7619	test_loss: 0.6532 test_accuracy-SBM: 0.7641
2025-08-26 19:32:31,520 - INFO - === Epoch 20 ===
2025-08-26 19:33:57,498 - INFO - train: {'epoch': 20, 'time_epoch': 85.72861, 'eta': 6888.78059, 'eta_hours': 1.91355, 'loss': 0.64987356, 'lr': 0.00093974, 'params': 510662, 'time_iter': 0.13717, 'accuracy': 0.76537, 'f1': 0.76536, 'accuracy-SBM': 0.76537, 'auc': 0.95774}
2025-08-26 19:34:01,834 - INFO - val: {'epoch': 20, 'time_epoch': 4.28878, 'loss': 0.66339184, 'lr': 0, 'params': 510662, 'time_iter': 0.06808, 'accuracy': 0.76388, 'f1': 0.76364, 'accuracy-SBM': 0.76357, 'auc': 0.95619}
2025-08-26 19:34:07,543 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:34:07,583 - INFO - test: {'epoch': 20, 'time_epoch': 4.61401, 'loss': 0.65663684, 'lr': 0, 'params': 510662, 'time_iter': 0.07324, 'accuracy': 0.76338, 'f1': 0.7633, 'accuracy-SBM': 0.76323, 'auc': 0.95726}
2025-08-26 19:34:07,585 - INFO - > Epoch 20: took 96.1s (avg 97.7s) | Best so far: epoch 20	train_loss: 0.6499 train_accuracy-SBM: 0.7654	val_loss: 0.6634 val_accuracy-SBM: 0.7636	test_loss: 0.6566 test_accuracy-SBM: 0.7632
2025-08-26 19:34:07,586 - INFO - === Epoch 21 ===
2025-08-26 19:35:38,089 - INFO - train: {'epoch': 21, 'time_epoch': 90.12211, 'eta': 6811.94192, 'eta_hours': 1.89221, 'loss': 0.64838009, 'lr': 0.00093163, 'params': 510662, 'time_iter': 0.1442, 'accuracy': 0.76632, 'f1': 0.76632, 'accuracy-SBM': 0.76633, 'auc': 0.95789}
2025-08-26 19:35:42,713 - INFO - val: {'epoch': 21, 'time_epoch': 4.57095, 'loss': 0.64546752, 'lr': 0, 'params': 510662, 'time_iter': 0.07255, 'accuracy': 0.77029, 'f1': 0.77004, 'accuracy-SBM': 0.77003, 'auc': 0.9588}
2025-08-26 19:35:48,741 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:35:48,791 - INFO - test: {'epoch': 21, 'time_epoch': 4.89172, 'loss': 0.64757214, 'lr': 0, 'params': 510662, 'time_iter': 0.07765, 'accuracy': 0.76786, 'f1': 0.76773, 'accuracy-SBM': 0.76761, 'auc': 0.95848}
2025-08-26 19:35:48,794 - INFO - > Epoch 21: took 101.2s (avg 97.9s) | Best so far: epoch 21	train_loss: 0.6484 train_accuracy-SBM: 0.7663	val_loss: 0.6455 val_accuracy-SBM: 0.7700	test_loss: 0.6476 test_accuracy-SBM: 0.7676
2025-08-26 19:35:48,794 - INFO - === Epoch 22 ===
2025-08-26 19:37:20,041 - INFO - train: {'epoch': 22, 'time_epoch': 91.00162, 'eta': 6736.89262, 'eta_hours': 1.87136, 'loss': 0.64385919, 'lr': 0.00092305, 'params': 510662, 'time_iter': 0.1456, 'accuracy': 0.76779, 'f1': 0.76779, 'accuracy-SBM': 0.76779, 'auc': 0.95851}
2025-08-26 19:37:24,309 - INFO - val: {'epoch': 22, 'time_epoch': 4.22297, 'loss': 0.64856657, 'lr': 0, 'params': 510662, 'time_iter': 0.06703, 'accuracy': 0.76823, 'f1': 0.76824, 'accuracy-SBM': 0.76819, 'auc': 0.95775}
2025-08-26 19:37:30,022 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:37:30,066 - INFO - test: {'epoch': 22, 'time_epoch': 4.5751, 'loss': 0.63910072, 'lr': 0, 'params': 510662, 'time_iter': 0.07262, 'accuracy': 0.76741, 'f1': 0.76742, 'accuracy-SBM': 0.76744, 'auc': 0.95932}
2025-08-26 19:37:30,079 - INFO - > Epoch 22: took 101.3s (avg 98.0s) | Best so far: epoch 21	train_loss: 0.6484 train_accuracy-SBM: 0.7663	val_loss: 0.6455 val_accuracy-SBM: 0.7700	test_loss: 0.6476 test_accuracy-SBM: 0.7676
2025-08-26 19:37:30,079 - INFO - === Epoch 23 ===
2025-08-26 19:38:54,837 - INFO - train: {'epoch': 23, 'time_epoch': 84.5141, 'eta': 6639.97015, 'eta_hours': 1.84444, 'loss': 0.63926086, 'lr': 0.000914, 'params': 510662, 'time_iter': 0.13522, 'accuracy': 0.76885, 'f1': 0.76885, 'accuracy-SBM': 0.76885, 'auc': 0.95909}
2025-08-26 19:38:59,129 - INFO - val: {'epoch': 23, 'time_epoch': 4.24585, 'loss': 0.64347831, 'lr': 0, 'params': 510662, 'time_iter': 0.06739, 'accuracy': 0.76881, 'f1': 0.7688, 'accuracy-SBM': 0.76884, 'auc': 0.95883}
2025-08-26 19:39:04,780 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:39:04,819 - INFO - test: {'epoch': 23, 'time_epoch': 4.56293, 'loss': 0.64154674, 'lr': 0, 'params': 510662, 'time_iter': 0.07243, 'accuracy': 0.77016, 'f1': 0.7701, 'accuracy-SBM': 0.77012, 'auc': 0.95909}
2025-08-26 19:39:04,820 - INFO - > Epoch 23: took 94.7s (avg 97.9s) | Best so far: epoch 21	train_loss: 0.6484 train_accuracy-SBM: 0.7663	val_loss: 0.6455 val_accuracy-SBM: 0.7700	test_loss: 0.6476 test_accuracy-SBM: 0.7676
2025-08-26 19:39:04,821 - INFO - === Epoch 24 ===
2025-08-26 19:40:29,531 - INFO - train: {'epoch': 24, 'time_epoch': 84.47067, 'eta': 6543.91006, 'eta_hours': 1.81775, 'loss': 0.63496645, 'lr': 0.00090451, 'params': 510662, 'time_iter': 0.13515, 'accuracy': 0.77077, 'f1': 0.77077, 'accuracy-SBM': 0.77077, 'auc': 0.95964}
2025-08-26 19:40:33,861 - INFO - val: {'epoch': 24, 'time_epoch': 4.28523, 'loss': 0.64611348, 'lr': 0, 'params': 510662, 'time_iter': 0.06802, 'accuracy': 0.77116, 'f1': 0.771, 'accuracy-SBM': 0.77104, 'auc': 0.95844}
2025-08-26 19:40:39,648 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:40:39,689 - INFO - test: {'epoch': 24, 'time_epoch': 4.57472, 'loss': 0.63863752, 'lr': 0, 'params': 510662, 'time_iter': 0.07261, 'accuracy': 0.76947, 'f1': 0.76948, 'accuracy-SBM': 0.76944, 'auc': 0.95946}
2025-08-26 19:40:39,691 - INFO - > Epoch 24: took 94.9s (avg 97.8s) | Best so far: epoch 24	train_loss: 0.6350 train_accuracy-SBM: 0.7708	val_loss: 0.6461 val_accuracy-SBM: 0.7710	test_loss: 0.6386 test_accuracy-SBM: 0.7694
2025-08-26 19:40:39,692 - INFO - === Epoch 25 ===
2025-08-26 19:42:05,346 - INFO - train: {'epoch': 25, 'time_epoch': 85.3054, 'eta': 6451.11721, 'eta_hours': 1.79198, 'loss': 0.63149515, 'lr': 0.00089457, 'params': 510662, 'time_iter': 0.13649, 'accuracy': 0.77203, 'f1': 0.77203, 'accuracy-SBM': 0.77203, 'auc': 0.96009}
2025-08-26 19:42:09,674 - INFO - val: {'epoch': 25, 'time_epoch': 4.28198, 'loss': 0.64415039, 'lr': 0, 'params': 510662, 'time_iter': 0.06797, 'accuracy': 0.77256, 'f1': 0.77237, 'accuracy-SBM': 0.7724, 'auc': 0.95903}
2025-08-26 19:42:15,382 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:42:15,421 - INFO - test: {'epoch': 25, 'time_epoch': 4.56447, 'loss': 0.64405606, 'lr': 0, 'params': 510662, 'time_iter': 0.07245, 'accuracy': 0.76976, 'f1': 0.76963, 'accuracy-SBM': 0.76965, 'auc': 0.95905}
2025-08-26 19:42:15,422 - INFO - > Epoch 25: took 95.7s (avg 97.7s) | Best so far: epoch 25	train_loss: 0.6315 train_accuracy-SBM: 0.7720	val_loss: 0.6442 val_accuracy-SBM: 0.7724	test_loss: 0.6441 test_accuracy-SBM: 0.7696
2025-08-26 19:42:15,423 - INFO - === Epoch 26 ===
2025-08-26 19:43:48,989 - INFO - train: {'epoch': 26, 'time_epoch': 93.2806, 'eta': 6380.44158, 'eta_hours': 1.77234, 'loss': 0.62823981, 'lr': 0.0008842, 'params': 510662, 'time_iter': 0.14925, 'accuracy': 0.77272, 'f1': 0.77272, 'accuracy-SBM': 0.77272, 'auc': 0.96049}
2025-08-26 19:43:53,832 - INFO - val: {'epoch': 26, 'time_epoch': 4.78666, 'loss': 0.64595185, 'lr': 0, 'params': 510662, 'time_iter': 0.07598, 'accuracy': 0.76901, 'f1': 0.76893, 'accuracy-SBM': 0.76917, 'auc': 0.95884}
2025-08-26 19:44:00,557 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:44:00,601 - INFO - test: {'epoch': 26, 'time_epoch': 5.55751, 'loss': 0.63573992, 'lr': 0, 'params': 510662, 'time_iter': 0.08821, 'accuracy': 0.77034, 'f1': 0.77033, 'accuracy-SBM': 0.7703, 'auc': 0.96007}
2025-08-26 19:44:00,603 - INFO - > Epoch 26: took 105.2s (avg 98.0s) | Best so far: epoch 25	train_loss: 0.6315 train_accuracy-SBM: 0.7720	val_loss: 0.6442 val_accuracy-SBM: 0.7724	test_loss: 0.6441 test_accuracy-SBM: 0.7696
2025-08-26 19:44:00,603 - INFO - === Epoch 27 ===
2025-08-26 19:45:25,580 - INFO - train: {'epoch': 27, 'time_epoch': 84.62774, 'eta': 6285.90109, 'eta_hours': 1.74608, 'loss': 0.62479603, 'lr': 0.00087341, 'params': 510662, 'time_iter': 0.1354, 'accuracy': 0.77425, 'f1': 0.77425, 'accuracy-SBM': 0.77425, 'auc': 0.96092}
2025-08-26 19:45:29,910 - INFO - val: {'epoch': 27, 'time_epoch': 4.28469, 'loss': 0.64140111, 'lr': 0, 'params': 510662, 'time_iter': 0.06801, 'accuracy': 0.76922, 'f1': 0.76923, 'accuracy-SBM': 0.76933, 'auc': 0.95908}
2025-08-26 19:45:35,615 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:45:35,654 - INFO - test: {'epoch': 27, 'time_epoch': 4.59491, 'loss': 0.64020737, 'lr': 0, 'params': 510662, 'time_iter': 0.07294, 'accuracy': 0.76944, 'f1': 0.76947, 'accuracy-SBM': 0.76952, 'auc': 0.95928}
2025-08-26 19:45:35,656 - INFO - > Epoch 27: took 95.1s (avg 97.9s) | Best so far: epoch 25	train_loss: 0.6315 train_accuracy-SBM: 0.7720	val_loss: 0.6442 val_accuracy-SBM: 0.7724	test_loss: 0.6441 test_accuracy-SBM: 0.7696
2025-08-26 19:45:35,656 - INFO - === Epoch 28 ===
2025-08-26 19:47:00,620 - INFO - train: {'epoch': 28, 'time_epoch': 84.72024, 'eta': 6192.2707, 'eta_hours': 1.72008, 'loss': 0.62209696, 'lr': 0.00086221, 'params': 510662, 'time_iter': 0.13555, 'accuracy': 0.77531, 'f1': 0.77531, 'accuracy-SBM': 0.77531, 'auc': 0.96126}
2025-08-26 19:47:04,897 - INFO - val: {'epoch': 28, 'time_epoch': 4.22905, 'loss': 0.64162655, 'lr': 0, 'params': 510662, 'time_iter': 0.06713, 'accuracy': 0.77227, 'f1': 0.77226, 'accuracy-SBM': 0.77231, 'auc': 0.95948}
2025-08-26 19:47:10,616 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:47:10,656 - INFO - test: {'epoch': 28, 'time_epoch': 4.59436, 'loss': 0.63831995, 'lr': 0, 'params': 510662, 'time_iter': 0.07293, 'accuracy': 0.77227, 'f1': 0.7723, 'accuracy-SBM': 0.77226, 'auc': 0.95985}
2025-08-26 19:47:10,658 - INFO - > Epoch 28: took 95.0s (avg 97.8s) | Best so far: epoch 25	train_loss: 0.6315 train_accuracy-SBM: 0.7720	val_loss: 0.6442 val_accuracy-SBM: 0.7724	test_loss: 0.6441 test_accuracy-SBM: 0.7696
2025-08-26 19:47:10,658 - INFO - === Epoch 29 ===
2025-08-26 19:48:35,753 - INFO - train: {'epoch': 29, 'time_epoch': 84.66353, 'eta': 6099.10201, 'eta_hours': 1.6942, 'loss': 0.61809608, 'lr': 0.00085062, 'params': 510662, 'time_iter': 0.13546, 'accuracy': 0.7767, 'f1': 0.7767, 'accuracy-SBM': 0.7767, 'auc': 0.96175}
2025-08-26 19:48:40,043 - INFO - val: {'epoch': 29, 'time_epoch': 4.24057, 'loss': 0.64585131, 'lr': 0, 'params': 510662, 'time_iter': 0.06731, 'accuracy': 0.77141, 'f1': 0.77139, 'accuracy-SBM': 0.77143, 'auc': 0.95844}
2025-08-26 19:48:45,700 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:48:45,739 - INFO - test: {'epoch': 29, 'time_epoch': 4.54881, 'loss': 0.6308787, 'lr': 0, 'params': 510662, 'time_iter': 0.0722, 'accuracy': 0.77339, 'f1': 0.77339, 'accuracy-SBM': 0.77336, 'auc': 0.96046}
2025-08-26 19:48:45,741 - INFO - > Epoch 29: took 95.1s (avg 97.7s) | Best so far: epoch 25	train_loss: 0.6315 train_accuracy-SBM: 0.7720	val_loss: 0.6442 val_accuracy-SBM: 0.7724	test_loss: 0.6441 test_accuracy-SBM: 0.7696
2025-08-26 19:48:45,741 - INFO - === Epoch 30 ===
2025-08-26 19:50:10,232 - INFO - train: {'epoch': 30, 'time_epoch': 84.24722, 'eta': 6005.5554, 'eta_hours': 1.66821, 'loss': 0.61720664, 'lr': 0.00083864, 'params': 510662, 'time_iter': 0.1348, 'accuracy': 0.77685, 'f1': 0.77685, 'accuracy-SBM': 0.77685, 'auc': 0.96186}
2025-08-26 19:50:14,513 - INFO - val: {'epoch': 30, 'time_epoch': 4.23399, 'loss': 0.63474775, 'lr': 0, 'params': 510662, 'time_iter': 0.06721, 'accuracy': 0.77171, 'f1': 0.77176, 'accuracy-SBM': 0.77161, 'auc': 0.95975}
2025-08-26 19:50:20,238 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:50:20,276 - INFO - test: {'epoch': 30, 'time_epoch': 4.54916, 'loss': 0.63731104, 'lr': 0, 'params': 510662, 'time_iter': 0.07221, 'accuracy': 0.76873, 'f1': 0.76877, 'accuracy-SBM': 0.7688, 'auc': 0.95967}
2025-08-26 19:50:20,278 - INFO - > Epoch 30: took 94.5s (avg 97.6s) | Best so far: epoch 25	train_loss: 0.6315 train_accuracy-SBM: 0.7720	val_loss: 0.6442 val_accuracy-SBM: 0.7724	test_loss: 0.6441 test_accuracy-SBM: 0.7696
2025-08-26 19:50:20,278 - INFO - === Epoch 31 ===
2025-08-26 19:51:55,141 - INFO - train: {'epoch': 31, 'time_epoch': 94.62201, 'eta': 5934.63644, 'eta_hours': 1.64851, 'loss': 0.61265372, 'lr': 0.00082629, 'params': 510662, 'time_iter': 0.1514, 'accuracy': 0.77861, 'f1': 0.77861, 'accuracy-SBM': 0.77861, 'auc': 0.9624}
2025-08-26 19:51:59,439 - INFO - val: {'epoch': 31, 'time_epoch': 4.24993, 'loss': 0.64412132, 'lr': 0, 'params': 510662, 'time_iter': 0.06746, 'accuracy': 0.77286, 'f1': 0.77267, 'accuracy-SBM': 0.77272, 'auc': 0.95849}
2025-08-26 19:52:05,289 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:52:05,332 - INFO - test: {'epoch': 31, 'time_epoch': 4.61169, 'loss': 0.6404871, 'lr': 0, 'params': 510662, 'time_iter': 0.0732, 'accuracy': 0.76825, 'f1': 0.76829, 'accuracy-SBM': 0.7683, 'auc': 0.95926}
2025-08-26 19:52:05,335 - INFO - > Epoch 31: took 105.1s (avg 97.8s) | Best so far: epoch 31	train_loss: 0.6127 train_accuracy-SBM: 0.7786	val_loss: 0.6441 val_accuracy-SBM: 0.7727	test_loss: 0.6405 test_accuracy-SBM: 0.7683
2025-08-26 19:52:05,336 - INFO - === Epoch 32 ===
2025-08-26 19:53:30,094 - INFO - train: {'epoch': 32, 'time_epoch': 84.51287, 'eta': 5841.7563, 'eta_hours': 1.62271, 'loss': 0.60831807, 'lr': 0.00081359, 'params': 510662, 'time_iter': 0.13522, 'accuracy': 0.77981, 'f1': 0.77981, 'accuracy-SBM': 0.77981, 'auc': 0.96296}
2025-08-26 19:53:34,429 - INFO - val: {'epoch': 32, 'time_epoch': 4.28884, 'loss': 0.63481611, 'lr': 0, 'params': 510662, 'time_iter': 0.06808, 'accuracy': 0.77357, 'f1': 0.77329, 'accuracy-SBM': 0.7733, 'auc': 0.96006}
2025-08-26 19:53:40,170 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:53:40,211 - INFO - test: {'epoch': 32, 'time_epoch': 4.62418, 'loss': 0.63532523, 'lr': 0, 'params': 510662, 'time_iter': 0.0734, 'accuracy': 0.77306, 'f1': 0.773, 'accuracy-SBM': 0.77292, 'auc': 0.96001}
2025-08-26 19:53:40,213 - INFO - > Epoch 32: took 94.9s (avg 97.7s) | Best so far: epoch 32	train_loss: 0.6083 train_accuracy-SBM: 0.7798	val_loss: 0.6348 val_accuracy-SBM: 0.7733	test_loss: 0.6353 test_accuracy-SBM: 0.7729
2025-08-26 19:53:40,213 - INFO - === Epoch 33 ===
2025-08-26 19:55:06,020 - INFO - train: {'epoch': 33, 'time_epoch': 85.47106, 'eta': 5751.22838, 'eta_hours': 1.59756, 'loss': 0.60687971, 'lr': 0.00080054, 'params': 510662, 'time_iter': 0.13675, 'accuracy': 0.78013, 'f1': 0.78013, 'accuracy-SBM': 0.78013, 'auc': 0.96313}
2025-08-26 19:55:10,335 - INFO - val: {'epoch': 33, 'time_epoch': 4.26027, 'loss': 0.64209713, 'lr': 0, 'params': 510662, 'time_iter': 0.06762, 'accuracy': 0.77225, 'f1': 0.7723, 'accuracy-SBM': 0.77237, 'auc': 0.95907}
2025-08-26 19:55:16,021 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:55:16,061 - INFO - test: {'epoch': 33, 'time_epoch': 4.55445, 'loss': 0.62264904, 'lr': 0, 'params': 510662, 'time_iter': 0.07229, 'accuracy': 0.778, 'f1': 0.77798, 'accuracy-SBM': 0.77801, 'auc': 0.96146}
2025-08-26 19:55:16,063 - INFO - > Epoch 33: took 95.8s (avg 97.7s) | Best so far: epoch 32	train_loss: 0.6083 train_accuracy-SBM: 0.7798	val_loss: 0.6348 val_accuracy-SBM: 0.7733	test_loss: 0.6353 test_accuracy-SBM: 0.7729
2025-08-26 19:55:16,063 - INFO - === Epoch 34 ===
2025-08-26 19:56:41,541 - INFO - train: {'epoch': 34, 'time_epoch': 85.244, 'eta': 5660.56774, 'eta_hours': 1.57238, 'loss': 0.60467214, 'lr': 0.00078716, 'params': 510662, 'time_iter': 0.13639, 'accuracy': 0.7809, 'f1': 0.7809, 'accuracy-SBM': 0.7809, 'auc': 0.96339}
2025-08-26 19:56:45,809 - INFO - val: {'epoch': 34, 'time_epoch': 4.22188, 'loss': 0.64017125, 'lr': 0, 'params': 510662, 'time_iter': 0.06701, 'accuracy': 0.77304, 'f1': 0.77297, 'accuracy-SBM': 0.77292, 'auc': 0.95937}
2025-08-26 19:56:51,537 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:56:51,576 - INFO - test: {'epoch': 34, 'time_epoch': 4.55358, 'loss': 0.62741, 'lr': 0, 'params': 510662, 'time_iter': 0.07228, 'accuracy': 0.77512, 'f1': 0.77511, 'accuracy-SBM': 0.77511, 'auc': 0.96089}
2025-08-26 19:56:51,578 - INFO - > Epoch 34: took 95.5s (avg 97.6s) | Best so far: epoch 32	train_loss: 0.6083 train_accuracy-SBM: 0.7798	val_loss: 0.6348 val_accuracy-SBM: 0.7733	test_loss: 0.6353 test_accuracy-SBM: 0.7729
2025-08-26 19:56:51,578 - INFO - === Epoch 35 ===
2025-08-26 19:58:17,111 - INFO - train: {'epoch': 35, 'time_epoch': 85.13088, 'eta': 5570.00692, 'eta_hours': 1.54722, 'loss': 0.59745851, 'lr': 0.00077347, 'params': 510662, 'time_iter': 0.13621, 'accuracy': 0.78332, 'f1': 0.78332, 'accuracy-SBM': 0.78332, 'auc': 0.96427}
2025-08-26 19:58:21,942 - INFO - val: {'epoch': 35, 'time_epoch': 4.77732, 'loss': 0.63873869, 'lr': 0, 'params': 510662, 'time_iter': 0.07583, 'accuracy': 0.77603, 'f1': 0.77579, 'accuracy-SBM': 0.77584, 'auc': 0.95945}
2025-08-26 19:58:28,188 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 19:58:28,234 - INFO - test: {'epoch': 35, 'time_epoch': 5.12259, 'loss': 0.63551628, 'lr': 0, 'params': 510662, 'time_iter': 0.08131, 'accuracy': 0.76961, 'f1': 0.76951, 'accuracy-SBM': 0.76959, 'auc': 0.96002}
2025-08-26 19:58:28,236 - INFO - > Epoch 35: took 96.7s (avg 97.6s) | Best so far: epoch 35	train_loss: 0.5975 train_accuracy-SBM: 0.7833	val_loss: 0.6387 val_accuracy-SBM: 0.7758	test_loss: 0.6355 test_accuracy-SBM: 0.7696
2025-08-26 19:58:28,236 - INFO - === Epoch 36 ===
2025-08-26 20:00:00,479 - INFO - train: {'epoch': 36, 'time_epoch': 92.00261, 'eta': 5491.44013, 'eta_hours': 1.5254, 'loss': 0.59853584, 'lr': 0.00075948, 'params': 510662, 'time_iter': 0.1472, 'accuracy': 0.78345, 'f1': 0.78345, 'accuracy-SBM': 0.78345, 'auc': 0.96412}
2025-08-26 20:00:04,806 - INFO - val: {'epoch': 36, 'time_epoch': 4.28233, 'loss': 0.63699706, 'lr': 0, 'params': 510662, 'time_iter': 0.06797, 'accuracy': 0.773, 'f1': 0.7729, 'accuracy-SBM': 0.77317, 'auc': 0.95967}
2025-08-26 20:00:10,459 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:00:10,497 - INFO - test: {'epoch': 36, 'time_epoch': 4.56947, 'loss': 0.63890432, 'lr': 0, 'params': 510662, 'time_iter': 0.07253, 'accuracy': 0.77207, 'f1': 0.77192, 'accuracy-SBM': 0.77204, 'auc': 0.95936}
2025-08-26 20:00:10,500 - INFO - > Epoch 36: took 102.3s (avg 97.7s) | Best so far: epoch 35	train_loss: 0.5975 train_accuracy-SBM: 0.7833	val_loss: 0.6387 val_accuracy-SBM: 0.7758	test_loss: 0.6355 test_accuracy-SBM: 0.7696
2025-08-26 20:00:10,500 - INFO - === Epoch 37 ===
2025-08-26 20:01:34,901 - INFO - train: {'epoch': 37, 'time_epoch': 84.1534, 'eta': 5399.35958, 'eta_hours': 1.49982, 'loss': 0.59604243, 'lr': 0.00074521, 'params': 510662, 'time_iter': 0.13465, 'accuracy': 0.78451, 'f1': 0.78451, 'accuracy-SBM': 0.78451, 'auc': 0.96441}
2025-08-26 20:01:39,189 - INFO - val: {'epoch': 37, 'time_epoch': 4.24308, 'loss': 0.63505939, 'lr': 0, 'params': 510662, 'time_iter': 0.06735, 'accuracy': 0.77432, 'f1': 0.77425, 'accuracy-SBM': 0.77426, 'auc': 0.95988}
2025-08-26 20:01:44,874 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:01:44,913 - INFO - test: {'epoch': 37, 'time_epoch': 4.55526, 'loss': 0.62371058, 'lr': 0, 'params': 510662, 'time_iter': 0.07231, 'accuracy': 0.77704, 'f1': 0.77703, 'accuracy-SBM': 0.77703, 'auc': 0.96127}
2025-08-26 20:01:44,914 - INFO - > Epoch 37: took 94.4s (avg 97.6s) | Best so far: epoch 35	train_loss: 0.5975 train_accuracy-SBM: 0.7833	val_loss: 0.6387 val_accuracy-SBM: 0.7758	test_loss: 0.6355 test_accuracy-SBM: 0.7696
2025-08-26 20:01:44,914 - INFO - === Epoch 38 ===
2025-08-26 20:03:10,024 - INFO - train: {'epoch': 38, 'time_epoch': 84.86796, 'eta': 5308.80319, 'eta_hours': 1.47467, 'loss': 0.59373843, 'lr': 0.00073067, 'params': 510662, 'time_iter': 0.13579, 'accuracy': 0.78482, 'f1': 0.78482, 'accuracy-SBM': 0.78482, 'auc': 0.9647}
2025-08-26 20:03:14,620 - INFO - val: {'epoch': 38, 'time_epoch': 4.54206, 'loss': 0.63948038, 'lr': 0, 'params': 510662, 'time_iter': 0.0721, 'accuracy': 0.77558, 'f1': 0.77552, 'accuracy-SBM': 0.77556, 'auc': 0.95929}
2025-08-26 20:03:20,061 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:03:20,099 - INFO - test: {'epoch': 38, 'time_epoch': 4.28268, 'loss': 0.63088708, 'lr': 0, 'params': 510662, 'time_iter': 0.06798, 'accuracy': 0.77403, 'f1': 0.77398, 'accuracy-SBM': 0.77404, 'auc': 0.96044}
2025-08-26 20:03:20,101 - INFO - > Epoch 38: took 95.2s (avg 97.6s) | Best so far: epoch 35	train_loss: 0.5975 train_accuracy-SBM: 0.7833	val_loss: 0.6387 val_accuracy-SBM: 0.7758	test_loss: 0.6355 test_accuracy-SBM: 0.7696
2025-08-26 20:03:20,101 - INFO - === Epoch 39 ===
2025-08-26 20:04:45,198 - INFO - train: {'epoch': 39, 'time_epoch': 84.86048, 'eta': 5218.52001, 'eta_hours': 1.44959, 'loss': 0.58650611, 'lr': 0.00071588, 'params': 510662, 'time_iter': 0.13578, 'accuracy': 0.78685, 'f1': 0.78685, 'accuracy-SBM': 0.78685, 'auc': 0.96558}
2025-08-26 20:04:49,483 - INFO - val: {'epoch': 39, 'time_epoch': 4.23917, 'loss': 0.63541962, 'lr': 0, 'params': 510662, 'time_iter': 0.06729, 'accuracy': 0.77575, 'f1': 0.77579, 'accuracy-SBM': 0.77577, 'auc': 0.95991}
2025-08-26 20:04:54,825 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:04:54,863 - INFO - test: {'epoch': 39, 'time_epoch': 4.22872, 'loss': 0.6427056, 'lr': 0, 'params': 510662, 'time_iter': 0.06712, 'accuracy': 0.77108, 'f1': 0.77105, 'accuracy-SBM': 0.7711, 'auc': 0.95907}
2025-08-26 20:04:54,865 - INFO - > Epoch 39: took 94.8s (avg 97.5s) | Best so far: epoch 35	train_loss: 0.5975 train_accuracy-SBM: 0.7833	val_loss: 0.6387 val_accuracy-SBM: 0.7758	test_loss: 0.6355 test_accuracy-SBM: 0.7696
2025-08-26 20:04:54,865 - INFO - === Epoch 40 ===
2025-08-26 20:06:25,914 - INFO - train: {'epoch': 40, 'time_epoch': 90.79651, 'eta': 5137.04344, 'eta_hours': 1.42696, 'loss': 0.58479532, 'lr': 0.00070085, 'params': 510662, 'time_iter': 0.14527, 'accuracy': 0.78839, 'f1': 0.78839, 'accuracy-SBM': 0.78839, 'auc': 0.96575}
2025-08-26 20:06:30,193 - INFO - val: {'epoch': 40, 'time_epoch': 4.2317, 'loss': 0.64506918, 'lr': 0, 'params': 510662, 'time_iter': 0.06717, 'accuracy': 0.77469, 'f1': 0.77454, 'accuracy-SBM': 0.77458, 'auc': 0.95921}
2025-08-26 20:06:36,569 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:06:36,619 - INFO - test: {'epoch': 40, 'time_epoch': 5.07187, 'loss': 0.63669193, 'lr': 0, 'params': 510662, 'time_iter': 0.08051, 'accuracy': 0.77642, 'f1': 0.77646, 'accuracy-SBM': 0.77641, 'auc': 0.96019}
2025-08-26 20:06:36,621 - INFO - > Epoch 40: took 101.8s (avg 97.6s) | Best so far: epoch 35	train_loss: 0.5975 train_accuracy-SBM: 0.7833	val_loss: 0.6387 val_accuracy-SBM: 0.7758	test_loss: 0.6355 test_accuracy-SBM: 0.7696
2025-08-26 20:06:36,621 - INFO - === Epoch 41 ===
2025-08-26 20:08:03,872 - INFO - train: {'epoch': 41, 'time_epoch': 86.81002, 'eta': 5049.61792, 'eta_hours': 1.40267, 'loss': 0.58269321, 'lr': 0.0006856, 'params': 510662, 'time_iter': 0.1389, 'accuracy': 0.78882, 'f1': 0.78882, 'accuracy-SBM': 0.78882, 'auc': 0.966}
2025-08-26 20:08:08,148 - INFO - val: {'epoch': 41, 'time_epoch': 4.22918, 'loss': 0.62478747, 'lr': 0, 'params': 510662, 'time_iter': 0.06713, 'accuracy': 0.7791, 'f1': 0.77906, 'accuracy-SBM': 0.7791, 'auc': 0.96141}
2025-08-26 20:08:13,986 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:08:14,025 - INFO - test: {'epoch': 41, 'time_epoch': 4.53036, 'loss': 0.63659444, 'lr': 0, 'params': 510662, 'time_iter': 0.07191, 'accuracy': 0.774, 'f1': 0.77399, 'accuracy-SBM': 0.77399, 'auc': 0.96005}
2025-08-26 20:08:14,028 - INFO - > Epoch 41: took 97.4s (avg 97.6s) | Best so far: epoch 41	train_loss: 0.5827 train_accuracy-SBM: 0.7888	val_loss: 0.6248 val_accuracy-SBM: 0.7791	test_loss: 0.6366 test_accuracy-SBM: 0.7740
2025-08-26 20:08:14,028 - INFO - === Epoch 42 ===
2025-08-26 20:09:37,750 - INFO - train: {'epoch': 42, 'time_epoch': 83.48038, 'eta': 4957.80731, 'eta_hours': 1.37717, 'loss': 0.57921717, 'lr': 0.00067015, 'params': 510662, 'time_iter': 0.13357, 'accuracy': 0.78973, 'f1': 0.78973, 'accuracy-SBM': 0.78973, 'auc': 0.96642}
2025-08-26 20:09:41,987 - INFO - val: {'epoch': 42, 'time_epoch': 4.18286, 'loss': 0.62011224, 'lr': 0, 'params': 510662, 'time_iter': 0.06639, 'accuracy': 0.78053, 'f1': 0.78042, 'accuracy-SBM': 0.78037, 'auc': 0.96215}
2025-08-26 20:09:47,659 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:09:47,696 - INFO - test: {'epoch': 42, 'time_epoch': 4.45471, 'loss': 0.62945512, 'lr': 0, 'params': 510662, 'time_iter': 0.07071, 'accuracy': 0.77607, 'f1': 0.77609, 'accuracy-SBM': 0.77611, 'auc': 0.96119}
2025-08-26 20:09:47,699 - INFO - > Epoch 42: took 93.7s (avg 97.5s) | Best so far: epoch 42	train_loss: 0.5792 train_accuracy-SBM: 0.7897	val_loss: 0.6201 val_accuracy-SBM: 0.7804	test_loss: 0.6295 test_accuracy-SBM: 0.7761
2025-08-26 20:09:47,699 - INFO - === Epoch 43 ===
2025-08-26 20:11:11,545 - INFO - train: {'epoch': 43, 'time_epoch': 83.61162, 'eta': 4866.54238, 'eta_hours': 1.35182, 'loss': 0.57785697, 'lr': 0.00065451, 'params': 510662, 'time_iter': 0.13378, 'accuracy': 0.79041, 'f1': 0.7904, 'accuracy-SBM': 0.79041, 'auc': 0.96656}
2025-08-26 20:11:15,794 - INFO - val: {'epoch': 43, 'time_epoch': 4.19617, 'loss': 0.62012287, 'lr': 0, 'params': 510662, 'time_iter': 0.06661, 'accuracy': 0.77971, 'f1': 0.77958, 'accuracy-SBM': 0.77942, 'auc': 0.96155}
2025-08-26 20:11:21,746 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:11:21,784 - INFO - test: {'epoch': 43, 'time_epoch': 4.4932, 'loss': 0.63090779, 'lr': 0, 'params': 510662, 'time_iter': 0.07132, 'accuracy': 0.77357, 'f1': 0.7736, 'accuracy-SBM': 0.77356, 'auc': 0.9603}
2025-08-26 20:11:21,786 - INFO - > Epoch 43: took 94.1s (avg 97.4s) | Best so far: epoch 42	train_loss: 0.5792 train_accuracy-SBM: 0.7897	val_loss: 0.6201 val_accuracy-SBM: 0.7804	test_loss: 0.6295 test_accuracy-SBM: 0.7761
2025-08-26 20:11:21,786 - INFO - === Epoch 44 ===
2025-08-26 20:12:45,592 - INFO - train: {'epoch': 44, 'time_epoch': 83.56682, 'eta': 4775.56284, 'eta_hours': 1.32655, 'loss': 0.57487153, 'lr': 0.0006387, 'params': 510662, 'time_iter': 0.13371, 'accuracy': 0.79136, 'f1': 0.79136, 'accuracy-SBM': 0.79136, 'auc': 0.96692}
2025-08-26 20:12:49,833 - INFO - val: {'epoch': 44, 'time_epoch': 4.19669, 'loss': 0.6302165, 'lr': 0, 'params': 510662, 'time_iter': 0.06661, 'accuracy': 0.77849, 'f1': 0.77831, 'accuracy-SBM': 0.77831, 'auc': 0.9611}
2025-08-26 20:12:55,672 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:12:55,709 - INFO - test: {'epoch': 44, 'time_epoch': 4.45096, 'loss': 0.63454435, 'lr': 0, 'params': 510662, 'time_iter': 0.07065, 'accuracy': 0.77656, 'f1': 0.77653, 'accuracy-SBM': 0.77649, 'auc': 0.96033}
2025-08-26 20:12:55,711 - INFO - > Epoch 44: took 93.9s (avg 97.3s) | Best so far: epoch 42	train_loss: 0.5792 train_accuracy-SBM: 0.7897	val_loss: 0.6201 val_accuracy-SBM: 0.7804	test_loss: 0.6295 test_accuracy-SBM: 0.7761
2025-08-26 20:12:55,711 - INFO - === Epoch 45 ===
2025-08-26 20:14:31,478 - INFO - train: {'epoch': 45, 'time_epoch': 95.38275, 'eta': 4698.77647, 'eta_hours': 1.30522, 'loss': 0.56826407, 'lr': 0.00062274, 'params': 510662, 'time_iter': 0.15261, 'accuracy': 0.7941, 'f1': 0.7941, 'accuracy-SBM': 0.79411, 'auc': 0.96766}
2025-08-26 20:14:36,002 - INFO - val: {'epoch': 45, 'time_epoch': 4.47205, 'loss': 0.63025569, 'lr': 0, 'params': 510662, 'time_iter': 0.07098, 'accuracy': 0.77888, 'f1': 0.77879, 'accuracy-SBM': 0.77876, 'auc': 0.96068}
2025-08-26 20:14:41,591 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:14:41,629 - INFO - test: {'epoch': 45, 'time_epoch': 4.47305, 'loss': 0.63090724, 'lr': 0, 'params': 510662, 'time_iter': 0.071, 'accuracy': 0.77561, 'f1': 0.77561, 'accuracy-SBM': 0.77551, 'auc': 0.96055}
2025-08-26 20:14:41,645 - INFO - > Epoch 45: took 105.9s (avg 97.5s) | Best so far: epoch 42	train_loss: 0.5792 train_accuracy-SBM: 0.7897	val_loss: 0.6201 val_accuracy-SBM: 0.7804	test_loss: 0.6295 test_accuracy-SBM: 0.7761
2025-08-26 20:14:41,645 - INFO - === Epoch 46 ===
2025-08-26 20:16:05,679 - INFO - train: {'epoch': 46, 'time_epoch': 83.78966, 'eta': 4608.1257, 'eta_hours': 1.28003, 'loss': 0.57103361, 'lr': 0.00060665, 'params': 510662, 'time_iter': 0.13406, 'accuracy': 0.79293, 'f1': 0.79293, 'accuracy-SBM': 0.79293, 'auc': 0.96737}
2025-08-26 20:16:09,957 - INFO - val: {'epoch': 46, 'time_epoch': 4.22481, 'loss': 0.62637156, 'lr': 0, 'params': 510662, 'time_iter': 0.06706, 'accuracy': 0.77911, 'f1': 0.77905, 'accuracy-SBM': 0.77899, 'auc': 0.96095}
2025-08-26 20:16:15,770 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:16:15,816 - INFO - test: {'epoch': 46, 'time_epoch': 4.53251, 'loss': 0.61873695, 'lr': 0, 'params': 510662, 'time_iter': 0.07194, 'accuracy': 0.77807, 'f1': 0.77809, 'accuracy-SBM': 0.7781, 'auc': 0.96198}
2025-08-26 20:16:15,822 - INFO - > Epoch 46: took 94.2s (avg 97.5s) | Best so far: epoch 42	train_loss: 0.5792 train_accuracy-SBM: 0.7897	val_loss: 0.6201 val_accuracy-SBM: 0.7804	test_loss: 0.6295 test_accuracy-SBM: 0.7761
2025-08-26 20:16:15,822 - INFO - === Epoch 47 ===
2025-08-26 20:17:40,175 - INFO - train: {'epoch': 47, 'time_epoch': 84.11513, 'eta': 4518.11341, 'eta_hours': 1.25503, 'loss': 0.56668325, 'lr': 0.00059044, 'params': 510662, 'time_iter': 0.13458, 'accuracy': 0.7948, 'f1': 0.7948, 'accuracy-SBM': 0.7948, 'auc': 0.96786}
2025-08-26 20:17:44,496 - INFO - val: {'epoch': 47, 'time_epoch': 4.26671, 'loss': 0.62244394, 'lr': 0, 'params': 510662, 'time_iter': 0.06773, 'accuracy': 0.78182, 'f1': 0.78187, 'accuracy-SBM': 0.78172, 'auc': 0.96174}
2025-08-26 20:17:50,164 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:17:50,202 - INFO - test: {'epoch': 47, 'time_epoch': 4.58756, 'loss': 0.62886373, 'lr': 0, 'params': 510662, 'time_iter': 0.07282, 'accuracy': 0.77544, 'f1': 0.77544, 'accuracy-SBM': 0.77552, 'auc': 0.96109}
2025-08-26 20:17:50,204 - INFO - > Epoch 47: took 94.4s (avg 97.4s) | Best so far: epoch 47	train_loss: 0.5667 train_accuracy-SBM: 0.7948	val_loss: 0.6224 val_accuracy-SBM: 0.7817	test_loss: 0.6289 test_accuracy-SBM: 0.7755
2025-08-26 20:17:50,204 - INFO - === Epoch 48 ===
2025-08-26 20:19:14,378 - INFO - train: {'epoch': 48, 'time_epoch': 83.93023, 'eta': 4428.14936, 'eta_hours': 1.23004, 'loss': 0.56194289, 'lr': 0.00057413, 'params': 510662, 'time_iter': 0.13429, 'accuracy': 0.79643, 'f1': 0.79643, 'accuracy-SBM': 0.79643, 'auc': 0.96838}
2025-08-26 20:19:18,644 - INFO - val: {'epoch': 48, 'time_epoch': 4.22051, 'loss': 0.62798883, 'lr': 0, 'params': 510662, 'time_iter': 0.06699, 'accuracy': 0.77909, 'f1': 0.779, 'accuracy-SBM': 0.77908, 'auc': 0.96106}
2025-08-26 20:19:24,337 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:19:24,375 - INFO - test: {'epoch': 48, 'time_epoch': 4.53908, 'loss': 0.62230048, 'lr': 0, 'params': 510662, 'time_iter': 0.07205, 'accuracy': 0.77956, 'f1': 0.77958, 'accuracy-SBM': 0.77959, 'auc': 0.96165}
2025-08-26 20:19:24,376 - INFO - > Epoch 48: took 94.2s (avg 97.3s) | Best so far: epoch 47	train_loss: 0.5667 train_accuracy-SBM: 0.7948	val_loss: 0.6224 val_accuracy-SBM: 0.7817	test_loss: 0.6289 test_accuracy-SBM: 0.7755
2025-08-26 20:19:24,377 - INFO - === Epoch 49 ===
2025-08-26 20:20:48,288 - INFO - train: {'epoch': 49, 'time_epoch': 83.57883, 'eta': 4338.07528, 'eta_hours': 1.20502, 'loss': 0.56002638, 'lr': 0.00055774, 'params': 510662, 'time_iter': 0.13373, 'accuracy': 0.79654, 'f1': 0.79654, 'accuracy-SBM': 0.79654, 'auc': 0.9686}
2025-08-26 20:20:52,529 - INFO - val: {'epoch': 49, 'time_epoch': 4.19474, 'loss': 0.63028608, 'lr': 0, 'params': 510662, 'time_iter': 0.06658, 'accuracy': 0.77962, 'f1': 0.77946, 'accuracy-SBM': 0.77946, 'auc': 0.96057}
2025-08-26 20:20:58,159 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:20:58,196 - INFO - test: {'epoch': 49, 'time_epoch': 4.49394, 'loss': 0.6235188, 'lr': 0, 'params': 510662, 'time_iter': 0.07133, 'accuracy': 0.77974, 'f1': 0.7797, 'accuracy-SBM': 0.77968, 'auc': 0.9614}
2025-08-26 20:20:58,198 - INFO - > Epoch 49: took 93.8s (avg 97.3s) | Best so far: epoch 47	train_loss: 0.5667 train_accuracy-SBM: 0.7948	val_loss: 0.6224 val_accuracy-SBM: 0.7817	test_loss: 0.6289 test_accuracy-SBM: 0.7755
2025-08-26 20:20:58,198 - INFO - === Epoch 50 ===
2025-08-26 20:22:32,805 - INFO - train: {'epoch': 50, 'time_epoch': 94.27248, 'eta': 4258.5302, 'eta_hours': 1.18293, 'loss': 0.55514639, 'lr': 0.00054129, 'params': 510662, 'time_iter': 0.15084, 'accuracy': 0.79827, 'f1': 0.79827, 'accuracy-SBM': 0.79827, 'auc': 0.96916}
2025-08-26 20:22:36,912 - INFO - val: {'epoch': 50, 'time_epoch': 4.06083, 'loss': 0.63277023, 'lr': 0, 'params': 510662, 'time_iter': 0.06446, 'accuracy': 0.77773, 'f1': 0.77774, 'accuracy-SBM': 0.77767, 'auc': 0.96047}
2025-08-26 20:22:42,411 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:22:42,449 - INFO - test: {'epoch': 50, 'time_epoch': 4.35479, 'loss': 0.62233969, 'lr': 0, 'params': 510662, 'time_iter': 0.06912, 'accuracy': 0.77931, 'f1': 0.77927, 'accuracy-SBM': 0.77929, 'auc': 0.96162}
2025-08-26 20:22:42,451 - INFO - > Epoch 50: took 104.3s (avg 97.4s) | Best so far: epoch 47	train_loss: 0.5667 train_accuracy-SBM: 0.7948	val_loss: 0.6224 val_accuracy-SBM: 0.7817	test_loss: 0.6289 test_accuracy-SBM: 0.7755
2025-08-26 20:22:42,451 - INFO - === Epoch 51 ===
2025-08-26 20:24:06,081 - INFO - train: {'epoch': 51, 'time_epoch': 83.22248, 'eta': 4168.21868, 'eta_hours': 1.15784, 'loss': 0.55463878, 'lr': 0.00052479, 'params': 510662, 'time_iter': 0.13316, 'accuracy': 0.7983, 'f1': 0.7983, 'accuracy-SBM': 0.7983, 'auc': 0.96921}
2025-08-26 20:24:10,371 - INFO - val: {'epoch': 51, 'time_epoch': 4.24443, 'loss': 0.62041945, 'lr': 0, 'params': 510662, 'time_iter': 0.06737, 'accuracy': 0.78179, 'f1': 0.78173, 'accuracy-SBM': 0.78176, 'auc': 0.96187}
2025-08-26 20:24:16,016 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:24:16,054 - INFO - test: {'epoch': 51, 'time_epoch': 4.53041, 'loss': 0.62663375, 'lr': 0, 'params': 510662, 'time_iter': 0.07191, 'accuracy': 0.779, 'f1': 0.77899, 'accuracy-SBM': 0.77903, 'auc': 0.96118}
2025-08-26 20:24:16,056 - INFO - > Epoch 51: took 93.6s (avg 97.3s) | Best so far: epoch 51	train_loss: 0.5546 train_accuracy-SBM: 0.7983	val_loss: 0.6204 val_accuracy-SBM: 0.7818	test_loss: 0.6266 test_accuracy-SBM: 0.7790
2025-08-26 20:24:16,056 - INFO - === Epoch 52 ===
2025-08-26 20:25:40,807 - INFO - train: {'epoch': 52, 'time_epoch': 84.41988, 'eta': 4079.23652, 'eta_hours': 1.13312, 'loss': 0.55363325, 'lr': 0.00050827, 'params': 510662, 'time_iter': 0.13507, 'accuracy': 0.79909, 'f1': 0.79909, 'accuracy-SBM': 0.79909, 'auc': 0.96931}
2025-08-26 20:25:45,103 - INFO - val: {'epoch': 52, 'time_epoch': 4.2406, 'loss': 0.6299116, 'lr': 0, 'params': 510662, 'time_iter': 0.06731, 'accuracy': 0.78156, 'f1': 0.7814, 'accuracy-SBM': 0.7814, 'auc': 0.96096}
2025-08-26 20:25:50,753 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:25:50,790 - INFO - test: {'epoch': 52, 'time_epoch': 4.26433, 'loss': 0.6193953, 'lr': 0, 'params': 510662, 'time_iter': 0.06769, 'accuracy': 0.78127, 'f1': 0.78122, 'accuracy-SBM': 0.7812, 'auc': 0.96219}
2025-08-26 20:25:50,792 - INFO - > Epoch 52: took 94.7s (avg 97.3s) | Best so far: epoch 51	train_loss: 0.5546 train_accuracy-SBM: 0.7983	val_loss: 0.6204 val_accuracy-SBM: 0.7818	test_loss: 0.6266 test_accuracy-SBM: 0.7790
2025-08-26 20:25:50,792 - INFO - === Epoch 53 ===
2025-08-26 20:27:14,777 - INFO - train: {'epoch': 53, 'time_epoch': 83.74196, 'eta': 3989.84585, 'eta_hours': 1.10829, 'loss': 0.54822622, 'lr': 0.00049173, 'params': 510662, 'time_iter': 0.13399, 'accuracy': 0.80105, 'f1': 0.80105, 'accuracy-SBM': 0.80105, 'auc': 0.96992}
2025-08-26 20:27:19,052 - INFO - val: {'epoch': 53, 'time_epoch': 4.22897, 'loss': 0.63416758, 'lr': 0, 'params': 510662, 'time_iter': 0.06713, 'accuracy': 0.7814, 'f1': 0.78131, 'accuracy-SBM': 0.78134, 'auc': 0.96106}
2025-08-26 20:27:24,702 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:27:24,740 - INFO - test: {'epoch': 53, 'time_epoch': 4.5195, 'loss': 0.63883387, 'lr': 0, 'params': 510662, 'time_iter': 0.07174, 'accuracy': 0.77868, 'f1': 0.77872, 'accuracy-SBM': 0.77861, 'auc': 0.96038}
2025-08-26 20:27:24,742 - INFO - > Epoch 53: took 93.9s (avg 97.2s) | Best so far: epoch 51	train_loss: 0.5546 train_accuracy-SBM: 0.7983	val_loss: 0.6204 val_accuracy-SBM: 0.7818	test_loss: 0.6266 test_accuracy-SBM: 0.7790
2025-08-26 20:27:24,742 - INFO - === Epoch 54 ===
2025-08-26 20:28:51,728 - INFO - train: {'epoch': 54, 'time_epoch': 86.46902, 'eta': 3902.89181, 'eta_hours': 1.08414, 'loss': 0.5485295, 'lr': 0.00047521, 'params': 510662, 'time_iter': 0.13835, 'accuracy': 0.80107, 'f1': 0.80107, 'accuracy-SBM': 0.80107, 'auc': 0.96988}
2025-08-26 20:28:56,554 - INFO - val: {'epoch': 54, 'time_epoch': 4.75537, 'loss': 0.63159876, 'lr': 0, 'params': 510662, 'time_iter': 0.07548, 'accuracy': 0.77971, 'f1': 0.77965, 'accuracy-SBM': 0.7796, 'auc': 0.96055}
2025-08-26 20:29:03,409 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:29:03,463 - INFO - test: {'epoch': 54, 'time_epoch': 4.93354, 'loss': 0.6279169, 'lr': 0, 'params': 510662, 'time_iter': 0.07831, 'accuracy': 0.77836, 'f1': 0.77837, 'accuracy-SBM': 0.7784, 'auc': 0.96104}
2025-08-26 20:29:03,466 - INFO - > Epoch 54: took 98.7s (avg 97.2s) | Best so far: epoch 51	train_loss: 0.5546 train_accuracy-SBM: 0.7983	val_loss: 0.6204 val_accuracy-SBM: 0.7818	test_loss: 0.6266 test_accuracy-SBM: 0.7790
2025-08-26 20:29:03,467 - INFO - === Epoch 55 ===
2025-08-26 20:30:37,258 - INFO - train: {'epoch': 55, 'time_epoch': 93.54096, 'eta': 3821.51162, 'eta_hours': 1.06153, 'loss': 0.54246716, 'lr': 0.00045871, 'params': 510662, 'time_iter': 0.14967, 'accuracy': 0.80282, 'f1': 0.80282, 'accuracy-SBM': 0.80282, 'auc': 0.97055}
2025-08-26 20:30:41,574 - INFO - val: {'epoch': 55, 'time_epoch': 4.266, 'loss': 0.63483479, 'lr': 0, 'params': 510662, 'time_iter': 0.06771, 'accuracy': 0.78053, 'f1': 0.78046, 'accuracy-SBM': 0.78043, 'auc': 0.95997}
2025-08-26 20:30:47,312 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:30:47,354 - INFO - test: {'epoch': 55, 'time_epoch': 4.61117, 'loss': 0.63134308, 'lr': 0, 'params': 510662, 'time_iter': 0.07319, 'accuracy': 0.77801, 'f1': 0.77797, 'accuracy-SBM': 0.77799, 'auc': 0.96046}
2025-08-26 20:30:47,356 - INFO - > Epoch 55: took 103.9s (avg 97.4s) | Best so far: epoch 51	train_loss: 0.5546 train_accuracy-SBM: 0.7983	val_loss: 0.6204 val_accuracy-SBM: 0.7818	test_loss: 0.6266 test_accuracy-SBM: 0.7790
2025-08-26 20:30:47,356 - INFO - === Epoch 56 ===
2025-08-26 20:32:16,647 - INFO - train: {'epoch': 56, 'time_epoch': 89.03522, 'eta': 3736.30567, 'eta_hours': 1.03786, 'loss': 0.54154111, 'lr': 0.00044226, 'params': 510662, 'time_iter': 0.14246, 'accuracy': 0.80309, 'f1': 0.80309, 'accuracy-SBM': 0.80309, 'auc': 0.97065}
2025-08-26 20:32:21,015 - INFO - val: {'epoch': 56, 'time_epoch': 4.32123, 'loss': 0.63559052, 'lr': 0, 'params': 510662, 'time_iter': 0.06859, 'accuracy': 0.78256, 'f1': 0.78239, 'accuracy-SBM': 0.78241, 'auc': 0.96106}
2025-08-26 20:32:31,582 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:32:31,623 - INFO - test: {'epoch': 56, 'time_epoch': 4.75022, 'loss': 0.63119059, 'lr': 0, 'params': 510662, 'time_iter': 0.0754, 'accuracy': 0.78047, 'f1': 0.78044, 'accuracy-SBM': 0.78044, 'auc': 0.96146}
2025-08-26 20:32:31,625 - INFO - > Epoch 56: took 104.3s (avg 97.5s) | Best so far: epoch 56	train_loss: 0.5415 train_accuracy-SBM: 0.8031	val_loss: 0.6356 val_accuracy-SBM: 0.7824	test_loss: 0.6312 test_accuracy-SBM: 0.7804
2025-08-26 20:32:31,625 - INFO - === Epoch 57 ===
2025-08-26 20:33:58,440 - INFO - train: {'epoch': 57, 'time_epoch': 86.56649, 'eta': 3649.17998, 'eta_hours': 1.01366, 'loss': 0.53727687, 'lr': 0.00042587, 'params': 510662, 'time_iter': 0.13851, 'accuracy': 0.80496, 'f1': 0.80496, 'accuracy-SBM': 0.80496, 'auc': 0.9711}
2025-08-26 20:34:02,795 - INFO - val: {'epoch': 57, 'time_epoch': 4.30822, 'loss': 0.62973637, 'lr': 0, 'params': 510662, 'time_iter': 0.06838, 'accuracy': 0.7821, 'f1': 0.78197, 'accuracy-SBM': 0.78194, 'auc': 0.96084}
2025-08-26 20:34:08,220 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:34:08,260 - INFO - test: {'epoch': 57, 'time_epoch': 4.29566, 'loss': 0.61735404, 'lr': 0, 'params': 510662, 'time_iter': 0.06819, 'accuracy': 0.78281, 'f1': 0.78276, 'accuracy-SBM': 0.78276, 'auc': 0.96227}
2025-08-26 20:34:08,262 - INFO - > Epoch 57: took 96.6s (avg 97.5s) | Best so far: epoch 56	train_loss: 0.5415 train_accuracy-SBM: 0.8031	val_loss: 0.6356 val_accuracy-SBM: 0.7824	test_loss: 0.6312 test_accuracy-SBM: 0.7804
2025-08-26 20:34:08,262 - INFO - === Epoch 58 ===
2025-08-26 20:35:34,062 - INFO - train: {'epoch': 58, 'time_epoch': 85.55618, 'eta': 3561.37116, 'eta_hours': 0.98927, 'loss': 0.53586893, 'lr': 0.00040956, 'params': 510662, 'time_iter': 0.13689, 'accuracy': 0.80511, 'f1': 0.80511, 'accuracy-SBM': 0.80511, 'auc': 0.97126}
2025-08-26 20:35:38,338 - INFO - val: {'epoch': 58, 'time_epoch': 4.22955, 'loss': 0.638458, 'lr': 0, 'params': 510662, 'time_iter': 0.06714, 'accuracy': 0.77775, 'f1': 0.77774, 'accuracy-SBM': 0.77771, 'auc': 0.95951}
2025-08-26 20:35:43,935 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:35:43,972 - INFO - test: {'epoch': 58, 'time_epoch': 4.52737, 'loss': 0.6261928, 'lr': 0, 'params': 510662, 'time_iter': 0.07186, 'accuracy': 0.77835, 'f1': 0.77834, 'accuracy-SBM': 0.77835, 'auc': 0.96105}
2025-08-26 20:35:43,974 - INFO - > Epoch 58: took 95.7s (avg 97.4s) | Best so far: epoch 56	train_loss: 0.5415 train_accuracy-SBM: 0.8031	val_loss: 0.6356 val_accuracy-SBM: 0.7824	test_loss: 0.6312 test_accuracy-SBM: 0.7804
2025-08-26 20:35:43,974 - INFO - === Epoch 59 ===
2025-08-26 20:37:15,749 - INFO - train: {'epoch': 59, 'time_epoch': 91.5078, 'eta': 3477.60517, 'eta_hours': 0.966, 'loss': 0.53555288, 'lr': 0.00039335, 'params': 510662, 'time_iter': 0.14641, 'accuracy': 0.80608, 'f1': 0.80608, 'accuracy-SBM': 0.80608, 'auc': 0.97127}
2025-08-26 20:37:20,020 - INFO - val: {'epoch': 59, 'time_epoch': 4.22266, 'loss': 0.63345618, 'lr': 0, 'params': 510662, 'time_iter': 0.06703, 'accuracy': 0.77948, 'f1': 0.77939, 'accuracy-SBM': 0.77932, 'auc': 0.96069}
2025-08-26 20:37:26,093 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:37:26,144 - INFO - test: {'epoch': 59, 'time_epoch': 4.93363, 'loss': 0.62753668, 'lr': 0, 'params': 510662, 'time_iter': 0.07831, 'accuracy': 0.77997, 'f1': 0.77995, 'accuracy-SBM': 0.77998, 'auc': 0.96136}
2025-08-26 20:37:26,147 - INFO - > Epoch 59: took 102.2s (avg 97.5s) | Best so far: epoch 56	train_loss: 0.5415 train_accuracy-SBM: 0.8031	val_loss: 0.6356 val_accuracy-SBM: 0.7824	test_loss: 0.6312 test_accuracy-SBM: 0.7804
2025-08-26 20:37:26,147 - INFO - === Epoch 60 ===
2025-08-26 20:38:55,308 - INFO - train: {'epoch': 60, 'time_epoch': 88.91657, 'eta': 3391.92867, 'eta_hours': 0.9422, 'loss': 0.52998392, 'lr': 0.00037726, 'params': 510662, 'time_iter': 0.14227, 'accuracy': 0.80718, 'f1': 0.80718, 'accuracy-SBM': 0.80718, 'auc': 0.97189}
2025-08-26 20:38:59,592 - INFO - val: {'epoch': 60, 'time_epoch': 4.23741, 'loss': 0.62416371, 'lr': 0, 'params': 510662, 'time_iter': 0.06726, 'accuracy': 0.78459, 'f1': 0.7845, 'accuracy-SBM': 0.78445, 'auc': 0.9618}
2025-08-26 20:39:05,469 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:39:05,508 - INFO - test: {'epoch': 60, 'time_epoch': 4.70837, 'loss': 0.62389554, 'lr': 0, 'params': 510662, 'time_iter': 0.07474, 'accuracy': 0.78155, 'f1': 0.78151, 'accuracy-SBM': 0.78152, 'auc': 0.96175}
2025-08-26 20:39:05,510 - INFO - > Epoch 60: took 99.4s (avg 97.5s) | Best so far: epoch 60	train_loss: 0.5300 train_accuracy-SBM: 0.8072	val_loss: 0.6242 val_accuracy-SBM: 0.7844	test_loss: 0.6239 test_accuracy-SBM: 0.7815
2025-08-26 20:39:05,510 - INFO - === Epoch 61 ===
2025-08-26 20:40:31,385 - INFO - train: {'epoch': 61, 'time_epoch': 85.53101, 'eta': 3304.07262, 'eta_hours': 0.9178, 'loss': 0.52591897, 'lr': 0.0003613, 'params': 510662, 'time_iter': 0.13685, 'accuracy': 0.80907, 'f1': 0.80907, 'accuracy-SBM': 0.80907, 'auc': 0.97231}
2025-08-26 20:40:35,665 - INFO - val: {'epoch': 61, 'time_epoch': 4.23558, 'loss': 0.63648555, 'lr': 0, 'params': 510662, 'time_iter': 0.06723, 'accuracy': 0.7828, 'f1': 0.78267, 'accuracy-SBM': 0.7827, 'auc': 0.96045}
2025-08-26 20:40:41,265 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:40:41,303 - INFO - test: {'epoch': 61, 'time_epoch': 4.51748, 'loss': 0.62775453, 'lr': 0, 'params': 510662, 'time_iter': 0.07171, 'accuracy': 0.78086, 'f1': 0.78083, 'accuracy-SBM': 0.78081, 'auc': 0.96133}
2025-08-26 20:40:41,305 - INFO - > Epoch 61: took 95.8s (avg 97.5s) | Best so far: epoch 60	train_loss: 0.5300 train_accuracy-SBM: 0.8072	val_loss: 0.6242 val_accuracy-SBM: 0.7844	test_loss: 0.6239 test_accuracy-SBM: 0.7815
2025-08-26 20:40:41,305 - INFO - === Epoch 62 ===
2025-08-26 20:42:05,977 - INFO - train: {'epoch': 62, 'time_epoch': 84.32503, 'eta': 3215.58212, 'eta_hours': 0.89322, 'loss': 0.52538365, 'lr': 0.00034549, 'params': 510662, 'time_iter': 0.13492, 'accuracy': 0.80908, 'f1': 0.80908, 'accuracy-SBM': 0.80908, 'auc': 0.97236}
2025-08-26 20:42:10,296 - INFO - val: {'epoch': 62, 'time_epoch': 4.26506, 'loss': 0.62455326, 'lr': 0, 'params': 510662, 'time_iter': 0.0677, 'accuracy': 0.7828, 'f1': 0.78271, 'accuracy-SBM': 0.78274, 'auc': 0.96139}
2025-08-26 20:42:15,972 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:42:16,011 - INFO - test: {'epoch': 62, 'time_epoch': 4.52053, 'loss': 0.6204346, 'lr': 0, 'params': 510662, 'time_iter': 0.07175, 'accuracy': 0.78232, 'f1': 0.7823, 'accuracy-SBM': 0.78232, 'auc': 0.96181}
2025-08-26 20:42:16,013 - INFO - > Epoch 62: took 94.7s (avg 97.5s) | Best so far: epoch 60	train_loss: 0.5300 train_accuracy-SBM: 0.8072	val_loss: 0.6242 val_accuracy-SBM: 0.7844	test_loss: 0.6239 test_accuracy-SBM: 0.7815
2025-08-26 20:42:16,013 - INFO - === Epoch 63 ===
2025-08-26 20:43:40,650 - INFO - train: {'epoch': 63, 'time_epoch': 84.37272, 'eta': 3127.24861, 'eta_hours': 0.86868, 'loss': 0.524345, 'lr': 0.00032985, 'params': 510662, 'time_iter': 0.135, 'accuracy': 0.80977, 'f1': 0.80977, 'accuracy-SBM': 0.80977, 'auc': 0.97248}
2025-08-26 20:43:44,927 - INFO - val: {'epoch': 63, 'time_epoch': 4.23185, 'loss': 0.63494604, 'lr': 0, 'params': 510662, 'time_iter': 0.06717, 'accuracy': 0.78212, 'f1': 0.78199, 'accuracy-SBM': 0.78202, 'auc': 0.9605}
2025-08-26 20:43:50,645 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:43:50,685 - INFO - test: {'epoch': 63, 'time_epoch': 4.60707, 'loss': 0.62142027, 'lr': 0, 'params': 510662, 'time_iter': 0.07313, 'accuracy': 0.7822, 'f1': 0.78219, 'accuracy-SBM': 0.7822, 'auc': 0.96198}
2025-08-26 20:43:50,687 - INFO - > Epoch 63: took 94.7s (avg 97.4s) | Best so far: epoch 60	train_loss: 0.5300 train_accuracy-SBM: 0.8072	val_loss: 0.6242 val_accuracy-SBM: 0.7844	test_loss: 0.6239 test_accuracy-SBM: 0.7815
2025-08-26 20:43:50,687 - INFO - === Epoch 64 ===
2025-08-26 20:45:23,211 - INFO - train: {'epoch': 64, 'time_epoch': 92.2789, 'eta': 3043.29415, 'eta_hours': 0.84536, 'loss': 0.52185336, 'lr': 0.0003144, 'params': 510662, 'time_iter': 0.14765, 'accuracy': 0.81041, 'f1': 0.81041, 'accuracy-SBM': 0.81041, 'auc': 0.97275}
2025-08-26 20:45:27,514 - INFO - val: {'epoch': 64, 'time_epoch': 4.25345, 'loss': 0.62681441, 'lr': 0, 'params': 510662, 'time_iter': 0.06752, 'accuracy': 0.78251, 'f1': 0.78231, 'accuracy-SBM': 0.78233, 'auc': 0.96131}
2025-08-26 20:45:33,318 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:45:33,357 - INFO - test: {'epoch': 64, 'time_epoch': 4.60993, 'loss': 0.61786259, 'lr': 0, 'params': 510662, 'time_iter': 0.07317, 'accuracy': 0.78312, 'f1': 0.78309, 'accuracy-SBM': 0.78307, 'auc': 0.96231}
2025-08-26 20:45:33,359 - INFO - > Epoch 64: took 102.7s (avg 97.5s) | Best so far: epoch 60	train_loss: 0.5300 train_accuracy-SBM: 0.8072	val_loss: 0.6242 val_accuracy-SBM: 0.7844	test_loss: 0.6239 test_accuracy-SBM: 0.7815
2025-08-26 20:45:33,359 - INFO - === Epoch 65 ===
2025-08-26 20:47:00,310 - INFO - train: {'epoch': 65, 'time_epoch': 86.70743, 'eta': 2956.21728, 'eta_hours': 0.82117, 'loss': 0.51922384, 'lr': 0.00029915, 'params': 510662, 'time_iter': 0.13873, 'accuracy': 0.81138, 'f1': 0.81138, 'accuracy-SBM': 0.81138, 'auc': 0.97301}
2025-08-26 20:47:04,590 - INFO - val: {'epoch': 65, 'time_epoch': 4.2343, 'loss': 0.62917797, 'lr': 0, 'params': 510662, 'time_iter': 0.06721, 'accuracy': 0.78529, 'f1': 0.78519, 'accuracy-SBM': 0.78509, 'auc': 0.9614}
2025-08-26 20:47:10,223 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:47:10,261 - INFO - test: {'epoch': 65, 'time_epoch': 4.5047, 'loss': 0.62741965, 'lr': 0, 'params': 510662, 'time_iter': 0.0715, 'accuracy': 0.78177, 'f1': 0.78172, 'accuracy-SBM': 0.78173, 'auc': 0.96158}
2025-08-26 20:47:10,263 - INFO - > Epoch 65: took 96.9s (avg 97.5s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 20:47:10,263 - INFO - === Epoch 66 ===
2025-08-26 20:48:33,907 - INFO - train: {'epoch': 66, 'time_epoch': 83.30813, 'eta': 2867.47715, 'eta_hours': 0.79652, 'loss': 0.51524787, 'lr': 0.00028412, 'params': 510662, 'time_iter': 0.13329, 'accuracy': 0.81277, 'f1': 0.81277, 'accuracy-SBM': 0.81277, 'auc': 0.97342}
2025-08-26 20:48:38,141 - INFO - val: {'epoch': 66, 'time_epoch': 4.19007, 'loss': 0.62527878, 'lr': 0, 'params': 510662, 'time_iter': 0.06651, 'accuracy': 0.78483, 'f1': 0.78468, 'accuracy-SBM': 0.78474, 'auc': 0.96159}
2025-08-26 20:48:44,293 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:48:44,331 - INFO - test: {'epoch': 66, 'time_epoch': 4.5142, 'loss': 0.62688686, 'lr': 0, 'params': 510662, 'time_iter': 0.07165, 'accuracy': 0.78177, 'f1': 0.78172, 'accuracy-SBM': 0.78175, 'auc': 0.96146}
2025-08-26 20:48:44,333 - INFO - > Epoch 66: took 94.1s (avg 97.5s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 20:48:44,333 - INFO - === Epoch 67 ===
2025-08-26 20:50:08,312 - INFO - train: {'epoch': 67, 'time_epoch': 83.74556, 'eta': 2779.10264, 'eta_hours': 0.77197, 'loss': 0.51344784, 'lr': 0.00026933, 'params': 510662, 'time_iter': 0.13399, 'accuracy': 0.81327, 'f1': 0.81327, 'accuracy-SBM': 0.81327, 'auc': 0.97362}
2025-08-26 20:50:12,566 - INFO - val: {'epoch': 67, 'time_epoch': 4.2062, 'loss': 0.63781566, 'lr': 0, 'params': 510662, 'time_iter': 0.06677, 'accuracy': 0.78172, 'f1': 0.78165, 'accuracy-SBM': 0.78165, 'auc': 0.96022}
2025-08-26 20:50:18,197 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:50:18,242 - INFO - test: {'epoch': 67, 'time_epoch': 4.52274, 'loss': 0.63426528, 'lr': 0, 'params': 510662, 'time_iter': 0.07179, 'accuracy': 0.7787, 'f1': 0.77869, 'accuracy-SBM': 0.7787, 'auc': 0.96061}
2025-08-26 20:50:18,250 - INFO - > Epoch 67: took 93.9s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 20:50:18,250 - INFO - === Epoch 68 ===
2025-08-26 20:51:45,038 - INFO - train: {'epoch': 68, 'time_epoch': 86.48324, 'eta': 2692.09227, 'eta_hours': 0.7478, 'loss': 0.51340651, 'lr': 0.00025479, 'params': 510662, 'time_iter': 0.13837, 'accuracy': 0.81351, 'f1': 0.81351, 'accuracy-SBM': 0.81351, 'auc': 0.97362}
2025-08-26 20:51:50,211 - INFO - val: {'epoch': 68, 'time_epoch': 5.10639, 'loss': 0.64054212, 'lr': 0, 'params': 510662, 'time_iter': 0.08105, 'accuracy': 0.78184, 'f1': 0.78162, 'accuracy-SBM': 0.78159, 'auc': 0.96027}
2025-08-26 20:51:56,816 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:51:56,873 - INFO - test: {'epoch': 68, 'time_epoch': 5.38221, 'loss': 0.6366171, 'lr': 0, 'params': 510662, 'time_iter': 0.08543, 'accuracy': 0.77814, 'f1': 0.77813, 'accuracy-SBM': 0.77811, 'auc': 0.96077}
2025-08-26 20:51:56,876 - INFO - > Epoch 68: took 98.6s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 20:51:56,877 - INFO - === Epoch 69 ===
2025-08-26 20:53:28,715 - INFO - train: {'epoch': 69, 'time_epoch': 91.48518, 'eta': 2607.24065, 'eta_hours': 0.72423, 'loss': 0.50982082, 'lr': 0.00024052, 'params': 510662, 'time_iter': 0.14638, 'accuracy': 0.81492, 'f1': 0.81492, 'accuracy-SBM': 0.81492, 'auc': 0.97397}
2025-08-26 20:53:32,990 - INFO - val: {'epoch': 69, 'time_epoch': 4.22959, 'loss': 0.6322229, 'lr': 0, 'params': 510662, 'time_iter': 0.06714, 'accuracy': 0.78436, 'f1': 0.7842, 'accuracy-SBM': 0.78419, 'auc': 0.96108}
2025-08-26 20:53:38,677 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:53:38,724 - INFO - test: {'epoch': 69, 'time_epoch': 4.54561, 'loss': 0.63692736, 'lr': 0, 'params': 510662, 'time_iter': 0.07215, 'accuracy': 0.78074, 'f1': 0.78075, 'accuracy-SBM': 0.78072, 'auc': 0.9605}
2025-08-26 20:53:38,726 - INFO - > Epoch 69: took 101.8s (avg 97.5s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 20:53:38,727 - INFO - === Epoch 70 ===
2025-08-26 20:55:03,219 - INFO - train: {'epoch': 70, 'time_epoch': 84.24829, 'eta': 2519.24626, 'eta_hours': 0.69979, 'loss': 0.50863535, 'lr': 0.00022653, 'params': 510662, 'time_iter': 0.1348, 'accuracy': 0.81528, 'f1': 0.81528, 'accuracy-SBM': 0.81528, 'auc': 0.97411}
2025-08-26 20:55:07,507 - INFO - val: {'epoch': 70, 'time_epoch': 4.24234, 'loss': 0.63484576, 'lr': 0, 'params': 510662, 'time_iter': 0.06734, 'accuracy': 0.78397, 'f1': 0.78378, 'accuracy-SBM': 0.7838, 'auc': 0.96096}
2025-08-26 20:55:13,085 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:55:13,123 - INFO - test: {'epoch': 70, 'time_epoch': 4.54257, 'loss': 0.6376285, 'lr': 0, 'params': 510662, 'time_iter': 0.0721, 'accuracy': 0.77947, 'f1': 0.77946, 'accuracy-SBM': 0.77943, 'auc': 0.96061}
2025-08-26 20:55:13,126 - INFO - > Epoch 70: took 94.4s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 20:55:13,126 - INFO - === Epoch 71 ===
2025-08-26 20:56:37,435 - INFO - train: {'epoch': 71, 'time_epoch': 84.07072, 'eta': 2431.28687, 'eta_hours': 0.67536, 'loss': 0.50652778, 'lr': 0.00021284, 'params': 510662, 'time_iter': 0.13451, 'accuracy': 0.81607, 'f1': 0.81607, 'accuracy-SBM': 0.81607, 'auc': 0.97431}
2025-08-26 20:56:41,679 - INFO - val: {'epoch': 71, 'time_epoch': 4.19937, 'loss': 0.63380905, 'lr': 0, 'params': 510662, 'time_iter': 0.06666, 'accuracy': 0.78274, 'f1': 0.78267, 'accuracy-SBM': 0.78264, 'auc': 0.9607}
2025-08-26 20:56:47,302 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:56:47,340 - INFO - test: {'epoch': 71, 'time_epoch': 4.49043, 'loss': 0.630363, 'lr': 0, 'params': 510662, 'time_iter': 0.07128, 'accuracy': 0.78014, 'f1': 0.78012, 'accuracy-SBM': 0.78014, 'auc': 0.96114}
2025-08-26 20:56:47,342 - INFO - > Epoch 71: took 94.2s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 20:56:47,342 - INFO - === Epoch 72 ===
2025-08-26 20:58:11,564 - INFO - train: {'epoch': 72, 'time_epoch': 83.98867, 'eta': 2343.40368, 'eta_hours': 0.65095, 'loss': 0.50321741, 'lr': 0.00019946, 'params': 510662, 'time_iter': 0.13438, 'accuracy': 0.8174, 'f1': 0.8174, 'accuracy-SBM': 0.8174, 'auc': 0.97465}
2025-08-26 20:58:15,846 - INFO - val: {'epoch': 72, 'time_epoch': 4.22336, 'loss': 0.63872007, 'lr': 0, 'params': 510662, 'time_iter': 0.06704, 'accuracy': 0.78262, 'f1': 0.78255, 'accuracy-SBM': 0.78256, 'auc': 0.96051}
2025-08-26 20:58:21,469 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 20:58:21,506 - INFO - test: {'epoch': 72, 'time_epoch': 4.49539, 'loss': 0.63835825, 'lr': 0, 'params': 510662, 'time_iter': 0.07136, 'accuracy': 0.78105, 'f1': 0.78101, 'accuracy-SBM': 0.78102, 'auc': 0.96046}
2025-08-26 20:58:21,510 - INFO - > Epoch 72: took 94.2s (avg 97.3s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 20:58:21,510 - INFO - === Epoch 73 ===
2025-08-26 20:59:52,879 - INFO - train: {'epoch': 73, 'time_epoch': 91.12336, 'eta': 2258.13252, 'eta_hours': 0.62726, 'loss': 0.50262617, 'lr': 0.00018641, 'params': 510662, 'time_iter': 0.1458, 'accuracy': 0.8175, 'f1': 0.8175, 'accuracy-SBM': 0.8175, 'auc': 0.9747}
2025-08-26 20:59:57,165 - INFO - val: {'epoch': 73, 'time_epoch': 4.23683, 'loss': 0.63205041, 'lr': 0, 'params': 510662, 'time_iter': 0.06725, 'accuracy': 0.78401, 'f1': 0.78392, 'accuracy-SBM': 0.78391, 'auc': 0.96118}
2025-08-26 21:00:03,598 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:00:03,654 - INFO - test: {'epoch': 73, 'time_epoch': 5.12486, 'loss': 0.6343373, 'lr': 0, 'params': 510662, 'time_iter': 0.08135, 'accuracy': 0.78059, 'f1': 0.7806, 'accuracy-SBM': 0.78062, 'auc': 0.96091}
2025-08-26 21:00:03,657 - INFO - > Epoch 73: took 102.1s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:00:03,657 - INFO - === Epoch 74 ===
2025-08-26 21:01:33,265 - INFO - train: {'epoch': 74, 'time_epoch': 89.36062, 'eta': 2172.11773, 'eta_hours': 0.60337, 'loss': 0.50001247, 'lr': 0.00017371, 'params': 510662, 'time_iter': 0.14298, 'accuracy': 0.81776, 'f1': 0.81776, 'accuracy-SBM': 0.81776, 'auc': 0.97498}
2025-08-26 21:01:37,527 - INFO - val: {'epoch': 74, 'time_epoch': 4.21621, 'loss': 0.63777906, 'lr': 0, 'params': 510662, 'time_iter': 0.06692, 'accuracy': 0.78481, 'f1': 0.78469, 'accuracy-SBM': 0.78467, 'auc': 0.96074}
2025-08-26 21:01:43,238 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:01:43,278 - INFO - test: {'epoch': 74, 'time_epoch': 4.54957, 'loss': 0.63506728, 'lr': 0, 'params': 510662, 'time_iter': 0.07222, 'accuracy': 0.78029, 'f1': 0.78029, 'accuracy-SBM': 0.78028, 'auc': 0.96097}
2025-08-26 21:01:43,281 - INFO - > Epoch 74: took 99.6s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:01:43,281 - INFO - === Epoch 75 ===
2025-08-26 21:03:08,725 - INFO - train: {'epoch': 75, 'time_epoch': 85.20405, 'eta': 2084.70228, 'eta_hours': 0.57908, 'loss': 0.50007554, 'lr': 0.00016136, 'params': 510662, 'time_iter': 0.13633, 'accuracy': 0.81839, 'f1': 0.81839, 'accuracy-SBM': 0.81839, 'auc': 0.97496}
2025-08-26 21:03:13,006 - INFO - val: {'epoch': 75, 'time_epoch': 4.23628, 'loss': 0.64002062, 'lr': 0, 'params': 510662, 'time_iter': 0.06724, 'accuracy': 0.78386, 'f1': 0.7837, 'accuracy-SBM': 0.78367, 'auc': 0.96029}
2025-08-26 21:03:18,660 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:03:18,700 - INFO - test: {'epoch': 75, 'time_epoch': 4.52128, 'loss': 0.629779, 'lr': 0, 'params': 510662, 'time_iter': 0.07177, 'accuracy': 0.78095, 'f1': 0.78092, 'accuracy-SBM': 0.78091, 'auc': 0.96137}
2025-08-26 21:03:18,702 - INFO - > Epoch 75: took 95.4s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:03:18,702 - INFO - === Epoch 76 ===
2025-08-26 21:04:43,440 - INFO - train: {'epoch': 76, 'time_epoch': 84.38613, 'eta': 1997.09996, 'eta_hours': 0.55475, 'loss': 0.49779003, 'lr': 0.00014938, 'params': 510662, 'time_iter': 0.13502, 'accuracy': 0.81883, 'f1': 0.81883, 'accuracy-SBM': 0.81883, 'auc': 0.9752}
2025-08-26 21:04:47,725 - INFO - val: {'epoch': 76, 'time_epoch': 4.23966, 'loss': 0.64205449, 'lr': 0, 'params': 510662, 'time_iter': 0.0673, 'accuracy': 0.78348, 'f1': 0.78335, 'accuracy-SBM': 0.78343, 'auc': 0.96029}
2025-08-26 21:04:53,373 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:04:53,412 - INFO - test: {'epoch': 76, 'time_epoch': 4.53961, 'loss': 0.63572999, 'lr': 0, 'params': 510662, 'time_iter': 0.07206, 'accuracy': 0.78011, 'f1': 0.78007, 'accuracy-SBM': 0.78009, 'auc': 0.96087}
2025-08-26 21:04:53,413 - INFO - > Epoch 76: took 94.7s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:04:53,414 - INFO - === Epoch 77 ===
2025-08-26 21:06:17,519 - INFO - train: {'epoch': 77, 'time_epoch': 83.85954, 'eta': 1909.43159, 'eta_hours': 0.5304, 'loss': 0.49313464, 'lr': 0.00013779, 'params': 510662, 'time_iter': 0.13418, 'accuracy': 0.82087, 'f1': 0.82087, 'accuracy-SBM': 0.82087, 'auc': 0.97565}
2025-08-26 21:06:22,085 - INFO - val: {'epoch': 77, 'time_epoch': 4.51973, 'loss': 0.6433183, 'lr': 0, 'params': 510662, 'time_iter': 0.07174, 'accuracy': 0.78235, 'f1': 0.78223, 'accuracy-SBM': 0.78223, 'auc': 0.95999}
2025-08-26 21:06:27,565 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:06:27,604 - INFO - test: {'epoch': 77, 'time_epoch': 4.26248, 'loss': 0.6351111, 'lr': 0, 'params': 510662, 'time_iter': 0.06766, 'accuracy': 0.78155, 'f1': 0.78153, 'accuracy-SBM': 0.78153, 'auc': 0.96082}
2025-08-26 21:06:27,606 - INFO - > Epoch 77: took 94.2s (avg 97.3s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:06:27,606 - INFO - === Epoch 78 ===
2025-08-26 21:08:02,232 - INFO - train: {'epoch': 78, 'time_epoch': 94.33176, 'eta': 1824.64339, 'eta_hours': 0.50685, 'loss': 0.49387066, 'lr': 0.00012659, 'params': 510662, 'time_iter': 0.15093, 'accuracy': 0.82075, 'f1': 0.82075, 'accuracy-SBM': 0.82075, 'auc': 0.97557}
2025-08-26 21:08:06,464 - INFO - val: {'epoch': 78, 'time_epoch': 4.18672, 'loss': 0.64196587, 'lr': 0, 'params': 510662, 'time_iter': 0.06646, 'accuracy': 0.7827, 'f1': 0.78256, 'accuracy-SBM': 0.78252, 'auc': 0.96014}
2025-08-26 21:08:11,858 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:08:11,895 - INFO - test: {'epoch': 78, 'time_epoch': 4.10149, 'loss': 0.63479486, 'lr': 0, 'params': 510662, 'time_iter': 0.0651, 'accuracy': 0.78124, 'f1': 0.78124, 'accuracy-SBM': 0.7812, 'auc': 0.9608}
2025-08-26 21:08:11,897 - INFO - > Epoch 78: took 104.3s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:08:11,897 - INFO - === Epoch 79 ===
2025-08-26 21:09:36,143 - INFO - train: {'epoch': 79, 'time_epoch': 84.00627, 'eta': 1737.03523, 'eta_hours': 0.48251, 'loss': 0.49094325, 'lr': 0.0001158, 'params': 510662, 'time_iter': 0.13441, 'accuracy': 0.82174, 'f1': 0.82174, 'accuracy-SBM': 0.82174, 'auc': 0.97587}
2025-08-26 21:09:40,449 - INFO - val: {'epoch': 79, 'time_epoch': 4.26061, 'loss': 0.63898432, 'lr': 0, 'params': 510662, 'time_iter': 0.06763, 'accuracy': 0.78419, 'f1': 0.78411, 'accuracy-SBM': 0.78407, 'auc': 0.96044}
2025-08-26 21:09:46,319 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:09:46,357 - INFO - test: {'epoch': 79, 'time_epoch': 4.57542, 'loss': 0.63588837, 'lr': 0, 'params': 510662, 'time_iter': 0.07263, 'accuracy': 0.78122, 'f1': 0.78123, 'accuracy-SBM': 0.78122, 'auc': 0.96074}
2025-08-26 21:09:46,359 - INFO - > Epoch 79: took 94.5s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:09:46,360 - INFO - === Epoch 80 ===
2025-08-26 21:11:11,246 - INFO - train: {'epoch': 80, 'time_epoch': 84.63881, 'eta': 1649.66438, 'eta_hours': 0.45824, 'loss': 0.48948915, 'lr': 0.00010543, 'params': 510662, 'time_iter': 0.13542, 'accuracy': 0.8219, 'f1': 0.8219, 'accuracy-SBM': 0.8219, 'auc': 0.97602}
2025-08-26 21:11:15,570 - INFO - val: {'epoch': 80, 'time_epoch': 4.26862, 'loss': 0.63887947, 'lr': 0, 'params': 510662, 'time_iter': 0.06776, 'accuracy': 0.78462, 'f1': 0.78448, 'accuracy-SBM': 0.78444, 'auc': 0.96056}
2025-08-26 21:11:21,465 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:11:21,505 - INFO - test: {'epoch': 80, 'time_epoch': 4.57843, 'loss': 0.63467838, 'lr': 0, 'params': 510662, 'time_iter': 0.07267, 'accuracy': 0.78146, 'f1': 0.78146, 'accuracy-SBM': 0.78147, 'auc': 0.96098}
2025-08-26 21:11:21,507 - INFO - > Epoch 80: took 95.1s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:11:21,507 - INFO - === Epoch 81 ===
2025-08-26 21:12:45,743 - INFO - train: {'epoch': 81, 'time_epoch': 83.99911, 'eta': 1562.21975, 'eta_hours': 0.43395, 'loss': 0.48956437, 'lr': 9.549e-05, 'params': 510662, 'time_iter': 0.1344, 'accuracy': 0.82246, 'f1': 0.82246, 'accuracy-SBM': 0.82246, 'auc': 0.97599}
2025-08-26 21:12:50,016 - INFO - val: {'epoch': 81, 'time_epoch': 4.2262, 'loss': 0.64109533, 'lr': 0, 'params': 510662, 'time_iter': 0.06708, 'accuracy': 0.78358, 'f1': 0.78346, 'accuracy-SBM': 0.78344, 'auc': 0.96042}
2025-08-26 21:12:55,643 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:12:55,681 - INFO - test: {'epoch': 81, 'time_epoch': 4.47958, 'loss': 0.63337735, 'lr': 0, 'params': 510662, 'time_iter': 0.0711, 'accuracy': 0.7828, 'f1': 0.78278, 'accuracy-SBM': 0.78278, 'auc': 0.96119}
2025-08-26 21:12:55,683 - INFO - > Epoch 81: took 94.2s (avg 97.3s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:12:55,684 - INFO - === Epoch 82 ===
2025-08-26 21:14:19,900 - INFO - train: {'epoch': 82, 'time_epoch': 83.97342, 'eta': 1474.85288, 'eta_hours': 0.40968, 'loss': 0.4879834, 'lr': 8.6e-05, 'params': 510662, 'time_iter': 0.13436, 'accuracy': 0.82265, 'f1': 0.82265, 'accuracy-SBM': 0.82265, 'auc': 0.97616}
2025-08-26 21:14:24,163 - INFO - val: {'epoch': 82, 'time_epoch': 4.21801, 'loss': 0.63646944, 'lr': 0, 'params': 510662, 'time_iter': 0.06695, 'accuracy': 0.78426, 'f1': 0.78414, 'accuracy-SBM': 0.78414, 'auc': 0.96072}
2025-08-26 21:14:29,994 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:14:30,035 - INFO - test: {'epoch': 82, 'time_epoch': 4.53223, 'loss': 0.63046057, 'lr': 0, 'params': 510662, 'time_iter': 0.07194, 'accuracy': 0.78238, 'f1': 0.78239, 'accuracy-SBM': 0.78239, 'auc': 0.96134}
2025-08-26 21:14:30,037 - INFO - > Epoch 82: took 94.4s (avg 97.3s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:14:30,037 - INFO - === Epoch 83 ===
2025-08-26 21:16:07,638 - INFO - train: {'epoch': 83, 'time_epoch': 97.35175, 'eta': 1390.11505, 'eta_hours': 0.38614, 'loss': 0.48800707, 'lr': 7.695e-05, 'params': 510662, 'time_iter': 0.15576, 'accuracy': 0.82229, 'f1': 0.82229, 'accuracy-SBM': 0.82229, 'auc': 0.97617}
2025-08-26 21:16:11,914 - INFO - val: {'epoch': 83, 'time_epoch': 4.22501, 'loss': 0.64153536, 'lr': 0, 'params': 510662, 'time_iter': 0.06706, 'accuracy': 0.78398, 'f1': 0.78388, 'accuracy-SBM': 0.78387, 'auc': 0.96055}
2025-08-26 21:16:17,542 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:16:17,582 - INFO - test: {'epoch': 83, 'time_epoch': 4.56044, 'loss': 0.63841866, 'lr': 0, 'params': 510662, 'time_iter': 0.07239, 'accuracy': 0.78183, 'f1': 0.78183, 'accuracy-SBM': 0.78185, 'auc': 0.96084}
2025-08-26 21:16:17,585 - INFO - > Epoch 83: took 107.5s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:16:17,585 - INFO - === Epoch 84 ===
2025-08-26 21:17:42,263 - INFO - train: {'epoch': 84, 'time_epoch': 84.43697, 'eta': 1302.80135, 'eta_hours': 0.36189, 'loss': 0.48555991, 'lr': 6.837e-05, 'params': 510662, 'time_iter': 0.1351, 'accuracy': 0.82367, 'f1': 0.82367, 'accuracy-SBM': 0.82367, 'auc': 0.97641}
2025-08-26 21:17:46,533 - INFO - val: {'epoch': 84, 'time_epoch': 4.22401, 'loss': 0.64092523, 'lr': 0, 'params': 510662, 'time_iter': 0.06705, 'accuracy': 0.78374, 'f1': 0.78362, 'accuracy-SBM': 0.78361, 'auc': 0.96054}
2025-08-26 21:17:52,280 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:17:52,317 - INFO - test: {'epoch': 84, 'time_epoch': 4.53658, 'loss': 0.63688502, 'lr': 0, 'params': 510662, 'time_iter': 0.07201, 'accuracy': 0.78182, 'f1': 0.7818, 'accuracy-SBM': 0.7818, 'auc': 0.96088}
2025-08-26 21:17:52,319 - INFO - > Epoch 84: took 94.7s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:17:52,319 - INFO - === Epoch 85 ===
2025-08-26 21:19:16,876 - INFO - train: {'epoch': 85, 'time_epoch': 84.31722, 'eta': 1215.53506, 'eta_hours': 0.33765, 'loss': 0.48511346, 'lr': 6.026e-05, 'params': 510662, 'time_iter': 0.13491, 'accuracy': 0.82357, 'f1': 0.82357, 'accuracy-SBM': 0.82357, 'auc': 0.97644}
2025-08-26 21:19:21,123 - INFO - val: {'epoch': 85, 'time_epoch': 4.2031, 'loss': 0.64294685, 'lr': 0, 'params': 510662, 'time_iter': 0.06672, 'accuracy': 0.784, 'f1': 0.78389, 'accuracy-SBM': 0.78389, 'auc': 0.96022}
2025-08-26 21:19:26,848 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:19:26,896 - INFO - test: {'epoch': 85, 'time_epoch': 4.52175, 'loss': 0.63635196, 'lr': 0, 'params': 510662, 'time_iter': 0.07177, 'accuracy': 0.78148, 'f1': 0.78146, 'accuracy-SBM': 0.78147, 'auc': 0.96088}
2025-08-26 21:19:26,898 - INFO - > Epoch 85: took 94.6s (avg 97.3s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:19:26,898 - INFO - === Epoch 86 ===
2025-08-26 21:20:51,298 - INFO - train: {'epoch': 86, 'time_epoch': 84.16595, 'eta': 1128.31396, 'eta_hours': 0.31342, 'loss': 0.48464002, 'lr': 5.264e-05, 'params': 510662, 'time_iter': 0.13467, 'accuracy': 0.82402, 'f1': 0.82402, 'accuracy-SBM': 0.82402, 'auc': 0.97648}
2025-08-26 21:20:55,565 - INFO - val: {'epoch': 86, 'time_epoch': 4.22052, 'loss': 0.64143075, 'lr': 0, 'params': 510662, 'time_iter': 0.06699, 'accuracy': 0.78382, 'f1': 0.78369, 'accuracy-SBM': 0.78367, 'auc': 0.96049}
2025-08-26 21:21:01,262 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:21:01,300 - INFO - test: {'epoch': 86, 'time_epoch': 4.52163, 'loss': 0.64003782, 'lr': 0, 'params': 510662, 'time_iter': 0.07177, 'accuracy': 0.78153, 'f1': 0.78154, 'accuracy-SBM': 0.78151, 'auc': 0.96062}
2025-08-26 21:21:01,302 - INFO - > Epoch 86: took 94.4s (avg 97.3s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:21:01,302 - INFO - === Epoch 87 ===
2025-08-26 21:22:32,404 - INFO - train: {'epoch': 87, 'time_epoch': 90.71659, 'eta': 1042.05556, 'eta_hours': 0.28946, 'loss': 0.48288198, 'lr': 4.55e-05, 'params': 510662, 'time_iter': 0.14515, 'accuracy': 0.82439, 'f1': 0.82439, 'accuracy-SBM': 0.82439, 'auc': 0.97665}
2025-08-26 21:22:37,007 - INFO - val: {'epoch': 87, 'time_epoch': 4.55045, 'loss': 0.64155318, 'lr': 0, 'params': 510662, 'time_iter': 0.07223, 'accuracy': 0.7838, 'f1': 0.78369, 'accuracy-SBM': 0.78367, 'auc': 0.96035}
2025-08-26 21:22:42,952 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:22:42,999 - INFO - test: {'epoch': 87, 'time_epoch': 4.85447, 'loss': 0.63479625, 'lr': 0, 'params': 510662, 'time_iter': 0.07706, 'accuracy': 0.78102, 'f1': 0.78101, 'accuracy-SBM': 0.78103, 'auc': 0.96101}
2025-08-26 21:22:43,002 - INFO - > Epoch 87: took 101.7s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:22:43,003 - INFO - === Epoch 88 ===
2025-08-26 21:24:13,434 - INFO - train: {'epoch': 88, 'time_epoch': 90.18646, 'eta': 955.63145, 'eta_hours': 0.26545, 'loss': 0.48232207, 'lr': 3.886e-05, 'params': 510662, 'time_iter': 0.1443, 'accuracy': 0.82502, 'f1': 0.82503, 'accuracy-SBM': 0.82502, 'auc': 0.97671}
2025-08-26 21:24:17,711 - INFO - val: {'epoch': 88, 'time_epoch': 4.21772, 'loss': 0.64535052, 'lr': 0, 'params': 510662, 'time_iter': 0.06695, 'accuracy': 0.78449, 'f1': 0.78439, 'accuracy-SBM': 0.78439, 'auc': 0.96032}
2025-08-26 21:24:23,303 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:24:23,341 - INFO - test: {'epoch': 88, 'time_epoch': 4.48703, 'loss': 0.63920423, 'lr': 0, 'params': 510662, 'time_iter': 0.07122, 'accuracy': 0.78139, 'f1': 0.78137, 'accuracy-SBM': 0.78141, 'auc': 0.96091}
2025-08-26 21:24:23,343 - INFO - > Epoch 88: took 100.3s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:24:23,343 - INFO - === Epoch 89 ===
2025-08-26 21:25:48,145 - INFO - train: {'epoch': 89, 'time_epoch': 84.55913, 'eta': 868.49848, 'eta_hours': 0.24125, 'loss': 0.48211912, 'lr': 3.272e-05, 'params': 510662, 'time_iter': 0.13529, 'accuracy': 0.82467, 'f1': 0.82467, 'accuracy-SBM': 0.82467, 'auc': 0.97673}
2025-08-26 21:25:52,435 - INFO - val: {'epoch': 89, 'time_epoch': 4.24353, 'loss': 0.64987078, 'lr': 0, 'params': 510662, 'time_iter': 0.06736, 'accuracy': 0.7833, 'f1': 0.78321, 'accuracy-SBM': 0.7832, 'auc': 0.95982}
2025-08-26 21:25:58,067 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:25:58,105 - INFO - test: {'epoch': 89, 'time_epoch': 4.54367, 'loss': 0.64084248, 'lr': 0, 'params': 510662, 'time_iter': 0.07212, 'accuracy': 0.78172, 'f1': 0.78173, 'accuracy-SBM': 0.78175, 'auc': 0.96075}
2025-08-26 21:25:58,107 - INFO - > Epoch 89: took 94.8s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:25:58,107 - INFO - === Epoch 90 ===
2025-08-26 21:27:22,501 - INFO - train: {'epoch': 90, 'time_epoch': 84.15192, 'eta': 781.38181, 'eta_hours': 0.21705, 'loss': 0.48174199, 'lr': 2.709e-05, 'params': 510662, 'time_iter': 0.13464, 'accuracy': 0.82479, 'f1': 0.82479, 'accuracy-SBM': 0.82479, 'auc': 0.97677}
2025-08-26 21:27:26,762 - INFO - val: {'epoch': 90, 'time_epoch': 4.21604, 'loss': 0.64175255, 'lr': 0, 'params': 510662, 'time_iter': 0.06692, 'accuracy': 0.78422, 'f1': 0.78412, 'accuracy-SBM': 0.78411, 'auc': 0.96041}
2025-08-26 21:27:34,621 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:27:34,661 - INFO - test: {'epoch': 90, 'time_epoch': 4.55443, 'loss': 0.63678612, 'lr': 0, 'params': 510662, 'time_iter': 0.07229, 'accuracy': 0.78268, 'f1': 0.78268, 'accuracy-SBM': 0.78269, 'auc': 0.96086}
2025-08-26 21:27:34,663 - INFO - > Epoch 90: took 96.6s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:27:34,663 - INFO - === Epoch 91 ===
2025-08-26 21:28:59,279 - INFO - train: {'epoch': 91, 'time_epoch': 84.25176, 'eta': 694.33826, 'eta_hours': 0.19287, 'loss': 0.48028383, 'lr': 2.198e-05, 'params': 510662, 'time_iter': 0.1348, 'accuracy': 0.82561, 'f1': 0.82561, 'accuracy-SBM': 0.82561, 'auc': 0.9769}
2025-08-26 21:29:03,548 - INFO - val: {'epoch': 91, 'time_epoch': 4.22439, 'loss': 0.63956879, 'lr': 0, 'params': 510662, 'time_iter': 0.06705, 'accuracy': 0.78443, 'f1': 0.78431, 'accuracy-SBM': 0.78433, 'auc': 0.96058}
2025-08-26 21:29:09,175 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:29:09,212 - INFO - test: {'epoch': 91, 'time_epoch': 4.2495, 'loss': 0.63589174, 'lr': 0, 'params': 510662, 'time_iter': 0.06745, 'accuracy': 0.78138, 'f1': 0.78138, 'accuracy-SBM': 0.78139, 'auc': 0.96093}
2025-08-26 21:29:09,215 - INFO - > Epoch 91: took 94.6s (avg 97.3s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:29:09,215 - INFO - === Epoch 92 ===
2025-08-26 21:30:41,308 - INFO - train: {'epoch': 92, 'time_epoch': 91.70473, 'eta': 607.91573, 'eta_hours': 0.16887, 'loss': 0.47988224, 'lr': 1.74e-05, 'params': 510662, 'time_iter': 0.14673, 'accuracy': 0.8256, 'f1': 0.8256, 'accuracy-SBM': 0.8256, 'auc': 0.97695}
2025-08-26 21:30:46,138 - INFO - val: {'epoch': 92, 'time_epoch': 4.77294, 'loss': 0.6437126, 'lr': 0, 'params': 510662, 'time_iter': 0.07576, 'accuracy': 0.78387, 'f1': 0.78375, 'accuracy-SBM': 0.78374, 'auc': 0.96032}
2025-08-26 21:30:52,682 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:30:52,734 - INFO - test: {'epoch': 92, 'time_epoch': 5.38731, 'loss': 0.63834654, 'lr': 0, 'params': 510662, 'time_iter': 0.08551, 'accuracy': 0.78123, 'f1': 0.78122, 'accuracy-SBM': 0.78123, 'auc': 0.96083}
2025-08-26 21:30:52,737 - INFO - > Epoch 92: took 103.5s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:30:52,738 - INFO - === Epoch 93 ===
2025-08-26 21:32:18,689 - INFO - train: {'epoch': 93, 'time_epoch': 85.70098, 'eta': 520.9976, 'eta_hours': 0.14472, 'loss': 0.48094013, 'lr': 1.334e-05, 'params': 510662, 'time_iter': 0.13712, 'accuracy': 0.82525, 'f1': 0.82525, 'accuracy-SBM': 0.82525, 'auc': 0.97685}
2025-08-26 21:32:23,140 - INFO - val: {'epoch': 93, 'time_epoch': 4.40489, 'loss': 0.64063077, 'lr': 0, 'params': 510662, 'time_iter': 0.06992, 'accuracy': 0.7846, 'f1': 0.7845, 'accuracy-SBM': 0.78448, 'auc': 0.96048}
2025-08-26 21:32:29,288 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:32:29,331 - INFO - test: {'epoch': 93, 'time_epoch': 4.4345, 'loss': 0.63426998, 'lr': 0, 'params': 510662, 'time_iter': 0.07039, 'accuracy': 0.78204, 'f1': 0.78204, 'accuracy-SBM': 0.78206, 'auc': 0.96114}
2025-08-26 21:32:29,334 - INFO - > Epoch 93: took 96.6s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:32:29,334 - INFO - === Epoch 94 ===
2025-08-26 21:33:57,106 - INFO - train: {'epoch': 94, 'time_epoch': 87.51066, 'eta': 434.20034, 'eta_hours': 0.12061, 'loss': 0.48014363, 'lr': 9.81e-06, 'params': 510662, 'time_iter': 0.14002, 'accuracy': 0.8253, 'f1': 0.8253, 'accuracy-SBM': 0.8253, 'auc': 0.97692}
2025-08-26 21:34:01,215 - INFO - val: {'epoch': 94, 'time_epoch': 4.06381, 'loss': 0.64170799, 'lr': 0, 'params': 510662, 'time_iter': 0.0645, 'accuracy': 0.78467, 'f1': 0.78456, 'accuracy-SBM': 0.78454, 'auc': 0.96048}
2025-08-26 21:34:06,667 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:34:06,705 - INFO - test: {'epoch': 94, 'time_epoch': 4.39323, 'loss': 0.63497081, 'lr': 0, 'params': 510662, 'time_iter': 0.06973, 'accuracy': 0.78289, 'f1': 0.78288, 'accuracy-SBM': 0.78291, 'auc': 0.96118}
2025-08-26 21:34:06,707 - INFO - > Epoch 94: took 97.4s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:34:06,707 - INFO - === Epoch 95 ===
2025-08-26 21:35:28,419 - INFO - train: {'epoch': 95, 'time_epoch': 81.33728, 'eta': 347.13099, 'eta_hours': 0.09643, 'loss': 0.48005267, 'lr': 6.82e-06, 'params': 510662, 'time_iter': 0.13014, 'accuracy': 0.82564, 'f1': 0.82564, 'accuracy-SBM': 0.82564, 'auc': 0.97694}
2025-08-26 21:35:32,575 - INFO - val: {'epoch': 95, 'time_epoch': 4.11201, 'loss': 0.64280266, 'lr': 0, 'params': 510662, 'time_iter': 0.06527, 'accuracy': 0.78418, 'f1': 0.78407, 'accuracy-SBM': 0.78405, 'auc': 0.96044}
2025-08-26 21:35:37,993 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:35:38,030 - INFO - test: {'epoch': 95, 'time_epoch': 4.34694, 'loss': 0.63703737, 'lr': 0, 'params': 510662, 'time_iter': 0.069, 'accuracy': 0.78258, 'f1': 0.78258, 'accuracy-SBM': 0.7826, 'auc': 0.961}
2025-08-26 21:35:38,032 - INFO - > Epoch 95: took 91.3s (avg 97.3s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:35:38,032 - INFO - === Epoch 96 ===
2025-08-26 21:37:02,245 - INFO - train: {'epoch': 96, 'time_epoch': 83.95434, 'eta': 260.26076, 'eta_hours': 0.07229, 'loss': 0.47853856, 'lr': 4.37e-06, 'params': 510662, 'time_iter': 0.13433, 'accuracy': 0.82545, 'f1': 0.82545, 'accuracy-SBM': 0.82545, 'auc': 0.97709}
2025-08-26 21:37:06,335 - INFO - val: {'epoch': 96, 'time_epoch': 4.04656, 'loss': 0.64252541, 'lr': 0, 'params': 510662, 'time_iter': 0.06423, 'accuracy': 0.78448, 'f1': 0.78437, 'accuracy-SBM': 0.78437, 'auc': 0.96052}
2025-08-26 21:37:11,622 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:37:11,661 - INFO - test: {'epoch': 96, 'time_epoch': 4.07563, 'loss': 0.63862734, 'lr': 0, 'params': 510662, 'time_iter': 0.06469, 'accuracy': 0.7814, 'f1': 0.7814, 'accuracy-SBM': 0.7814, 'auc': 0.96093}
2025-08-26 21:37:11,663 - INFO - > Epoch 96: took 93.6s (avg 97.3s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:37:11,663 - INFO - === Epoch 97 ===
2025-08-26 21:38:46,094 - INFO - train: {'epoch': 97, 'time_epoch': 94.16634, 'eta': 173.65846, 'eta_hours': 0.04824, 'loss': 0.47877089, 'lr': 2.46e-06, 'params': 510662, 'time_iter': 0.15067, 'accuracy': 0.8258, 'f1': 0.8258, 'accuracy-SBM': 0.8258, 'auc': 0.97706}
2025-08-26 21:38:50,380 - INFO - val: {'epoch': 97, 'time_epoch': 4.24092, 'loss': 0.64326285, 'lr': 0, 'params': 510662, 'time_iter': 0.06732, 'accuracy': 0.78421, 'f1': 0.7841, 'accuracy-SBM': 0.7841, 'auc': 0.96033}
2025-08-26 21:38:56,065 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:38:56,111 - INFO - test: {'epoch': 97, 'time_epoch': 4.56844, 'loss': 0.63799978, 'lr': 0, 'params': 510662, 'time_iter': 0.07251, 'accuracy': 0.7817, 'f1': 0.78169, 'accuracy-SBM': 0.78169, 'auc': 0.96085}
2025-08-26 21:38:56,113 - INFO - > Epoch 97: took 104.4s (avg 97.4s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:38:56,113 - INFO - === Epoch 98 ===
2025-08-26 21:40:21,130 - INFO - train: {'epoch': 98, 'time_epoch': 84.77168, 'eta': 86.80844, 'eta_hours': 0.02411, 'loss': 0.47849638, 'lr': 1.09e-06, 'params': 510662, 'time_iter': 0.13563, 'accuracy': 0.8258, 'f1': 0.8258, 'accuracy-SBM': 0.8258, 'auc': 0.97708}
2025-08-26 21:40:25,407 - INFO - val: {'epoch': 98, 'time_epoch': 4.23238, 'loss': 0.6427017, 'lr': 0, 'params': 510662, 'time_iter': 0.06718, 'accuracy': 0.78476, 'f1': 0.78465, 'accuracy-SBM': 0.78465, 'auc': 0.96043}
2025-08-26 21:40:31,150 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:40:31,187 - INFO - test: {'epoch': 98, 'time_epoch': 4.58916, 'loss': 0.63776214, 'lr': 0, 'params': 510662, 'time_iter': 0.07284, 'accuracy': 0.78201, 'f1': 0.78201, 'accuracy-SBM': 0.78202, 'auc': 0.96089}
2025-08-26 21:40:31,189 - INFO - > Epoch 98: took 95.1s (avg 97.3s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:40:31,190 - INFO - === Epoch 99 ===
2025-08-26 21:41:55,485 - INFO - train: {'epoch': 99, 'time_epoch': 84.03037, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.47967304, 'lr': 2.7e-07, 'params': 510662, 'time_iter': 0.13445, 'accuracy': 0.82563, 'f1': 0.82563, 'accuracy-SBM': 0.82563, 'auc': 0.97697}
2025-08-26 21:41:59,746 - INFO - val: {'epoch': 99, 'time_epoch': 4.21513, 'loss': 0.64424002, 'lr': 0, 'params': 510662, 'time_iter': 0.06691, 'accuracy': 0.7837, 'f1': 0.78361, 'accuracy-SBM': 0.7836, 'auc': 0.96031}
2025-08-26 21:42:05,335 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-08-26 21:42:05,373 - INFO - test: {'epoch': 99, 'time_epoch': 4.43924, 'loss': 0.63798766, 'lr': 0, 'params': 510662, 'time_iter': 0.07046, 'accuracy': 0.78195, 'f1': 0.78195, 'accuracy-SBM': 0.78197, 'auc': 0.96095}
2025-08-26 21:42:05,572 - INFO - > Epoch 99: took 94.2s (avg 97.3s) | Best so far: epoch 65	train_loss: 0.5192 train_accuracy-SBM: 0.8114	val_loss: 0.6292 val_accuracy-SBM: 0.7851	test_loss: 0.6274 test_accuracy-SBM: 0.7817
2025-08-26 21:42:05,572 - INFO - ================================================================================
2025-08-26 21:42:05,572 - INFO - NAS TRAINING COMPLETED SUCCESSFULLY
2025-08-26 21:42:05,572 - INFO - ================================================================================
2025-08-26 21:42:05,572 - INFO - Avg time per epoch: 97.30s
2025-08-26 21:42:05,573 - INFO - Total train loop time: 2.70h
2025-08-26 21:42:05,573 - INFO - Routing mode: nas
2025-08-26 21:42:05,573 - INFO - Final optimal weights: {'layer_0': 0, 'layer_1': 2, 'layer_2': 2, 'layer_3': 2, 'layer_4': 1, 'layer_5': 1, 'layer_6': 1, 'layer_7': 1, 'layer_8': 1, 'layer_9': 1, 'layer_10': 1, 'layer_11': 1, 'layer_12': 1, 'layer_13': 1, 'layer_14': 0, 'layer_15': 1}
2025-08-26 21:42:05,573 - INFO - Results include routing uncertainty (test only, NO variance)
2025-08-26 21:42:05,574 - INFO - Task done, results saved in results/Cluster/Cluster-SparseE-41
2025-08-26 21:42:05,577 - INFO - Total time: 13215.05s (3.67h)
2025-08-26 21:42:05,579 - INFO - Results aggregated across runs saved in results/Cluster/Cluster-SparseE-41/agg
2025-08-26 21:42:05,579 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-26 21:42:05,579 - INFO - Results saved in: results/Cluster/Cluster-SparseE-41
2025-08-26 21:42:05,579 - INFO - Test results JSON files saved in: results/Cluster/Cluster-SparseE-41/test_results/
Completed seed 41. Results saved in results/Cluster/Cluster-SparseE-41
----------------------------------------
Submitting next job for seed 45
Submitted batch job 5495781
/var/spool/slurmd/job5494769/slurm_script: line 71: syntax error near unexpected token `"/data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E"'
/var/spool/slurmd/job5494769/slurm_script: line 71: `os.chdir("/data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E")'
