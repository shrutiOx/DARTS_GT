Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          251Gi        23Gi       128Gi       2.8Gi        99Gi       222Gi
Swap:         1.9Gi        27Mi       1.8Gi
Wed Aug 27 01:34:22 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA TITAN RTX               On  |   00000000:1B:00.0 Off |                  N/A |
| 56%   66C    P8             39W /  280W |       1MiB /  24576MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 47
Starting training for seed 47...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E/SYYM
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E/SYYM/confignas.yaml
Using device: cuda
2025-08-27 01:36:00,368 - INFO - GPU Mem: 25.2GB
2025-08-27 01:36:00,368 - INFO - Run directory: results/Cluster/Cluster-SparseE-47
2025-08-27 01:36:00,368 - INFO - Seed: 47
2025-08-27 01:36:00,368 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-27 01:36:00,368 - INFO - Routing mode: nas
2025-08-27 01:36:00,368 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-27 01:36:00,368 - INFO - Number of layers: 16
2025-08-27 01:36:00,368 - INFO - Uncertainty enabled: False
2025-08-27 01:36:00,369 - INFO - Training mode: NoMixNas_uncertainty_train
2025-08-27 01:36:00,369 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-27 01:36:00,369 - INFO - Additional features: Router weights logging + JSON export
2025-08-27 01:36:14,083 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-27 01:36:14,098 - INFO -   Data(x=[1406436, 7], edge_index=[2, 51620680], y=[1406436])
2025-08-27 01:36:14,147 - INFO -   undirected: True
2025-08-27 01:36:14,147 - INFO -   num graphs: 12000
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-27 01:36:14,147 - INFO -   avg num_nodes/graph: 117
2025-08-27 01:36:14,148 - INFO -   num node features: 7
2025-08-27 01:36:14,148 - INFO -   num edge features: 0
2025-08-27 01:36:14,149 - INFO -   num classes: 6
2025-08-27 01:36:14,149 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 4, 8, 16]
2025-08-27 01:36:14,149 - INFO - Precomputing Positional Encoding statistics: ['LapPE', 'RWSE'] for all graphs...
2025-08-27 01:36:14,158 - INFO -   ...estimated to be undirected: True
  0%|          | 0/12000 [00:00<?, ?it/s] 15%|█▍        | 1764/12000 [00:10<00:58, 176.36it/s] 29%|██▉       | 3532/12000 [00:20<00:47, 176.60it/s] 44%|████▎     | 5248/12000 [00:30<00:38, 174.31it/s] 58%|█████▊    | 7005/12000 [00:40<00:28, 174.85it/s] 73%|███████▎  | 8772/12000 [00:50<00:18, 175.50it/s] 87%|████████▋ | 10490/12000 [01:00<00:08, 174.24it/s]100%|██████████| 12000/12000 [01:08<00:00, 174.90it/s]
2025-08-27 01:37:23,540 - INFO - Done! Took 00:01:09.39
2025-08-27 01:37:23,561 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset'
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/nni/nas/nn/pytorch/choice.py:252: UserWarning: "key" is deprecated. Assuming label.
  warnings.warn(f'"key" is deprecated. Assuming label.')
2025-08-27 01:37:24,140 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-27 01:37:24,140 - INFO - Inner model type: <class 'graphgps.network.NAS_model_edge_syym.NASModelEdge'>
2025-08-27 01:37:24,140 - INFO - Inner model has get_darts_model: True
2025-08-27 01:37:24,146 - INFO - GraphGymModule(
  (model): NASModelEdge(
    (encoder): FeatureEncoder(
      (node_encoder): LapPENodeEncoder(
        (linear_x): Linear(in_features=7, out_features=32, bias=True)
        (linear_A): Linear(in_features=2, out_features=32, bias=True)
        (pe_encoder): Sequential(
          (0): ReLU()
          (1): Linear(in_features=32, out_features=16, bias=True)
          (2): ReLU()
        )
      )
      (edge_encoder): DummyEdgeEncoder(
        (encoder): Embedding(1, 48)
      )
    )
    (darts_layers): ModuleList(
      (0): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (6): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_6')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (7): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_7')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (8): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_8')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (9): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_9')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (10): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_10')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (11): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_11')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (12): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_12')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (13): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_13')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (14): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_14')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (15): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_15')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (darts_sequential): Sequential(
      (0): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (6): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_6')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (7): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_7')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (8): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_8')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (9): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_9')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (10): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_10')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (11): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_11')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (12): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_12')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (13): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_13')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (14): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_14')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (15): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_15')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(48, 48, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(48, 48, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(48, 6, bias=True)
          )
        )
      )
    )
  )
)
2025-08-27 01:37:24,157 - INFO - Number of parameters: 728,630
2025-08-27 01:37:24,157 - INFO - Starting optimized training: 2025-08-27 01:37:24.157274
2025-08-27 01:37:29,856 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset':
2025-08-27 01:37:29,856 - INFO -   Data(x=[1406436, 7], edge_index=[2, 51620680], y=[1406436])
2025-08-27 01:37:29,857 - INFO -   undirected: True
2025-08-27 01:37:29,857 - INFO -   num graphs: 12000
2025-08-27 01:37:29,857 - INFO -   avg num_nodes/graph: 117
2025-08-27 01:37:29,858 - INFO -   num node features: 7
2025-08-27 01:37:29,858 - INFO -   num edge features: 0
2025-08-27 01:37:29,859 - INFO -   num classes: 6
2025-08-27 01:37:29,859 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 4, 8, 16]
2025-08-27 01:37:29,859 - INFO - Precomputing Positional Encoding statistics: ['LapPE', 'RWSE'] for all graphs...
2025-08-27 01:37:29,867 - INFO -   ...estimated to be undirected: True
  0%|          | 0/12000 [00:00<?, ?it/s] 15%|█▍        | 1743/12000 [00:10<00:58, 174.23it/s] 29%|██▉       | 3501/12000 [00:20<00:48, 175.13it/s] 44%|████▍     | 5270/12000 [00:30<00:38, 175.90it/s] 58%|█████▊    | 7020/12000 [00:40<00:28, 175.51it/s] 73%|███████▎  | 8787/12000 [00:50<00:18, 175.93it/s] 88%|████████▊ | 10538/12000 [01:00<00:08, 175.65it/s]100%|██████████| 12000/12000 [01:08<00:00, 175.94it/s]
2025-08-27 01:38:38,832 - INFO - Done! Took 00:01:08.97
2025-08-27 01:38:38,856 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset'
2025-08-27 01:38:38,895 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-27 01:38:38,895 - INFO - Start from epoch 0
2025-08-27 01:38:38,896 - INFO - ================================================================================
2025-08-27 01:38:38,896 - INFO - STARTING TWO-PHASE NAS TRAINING
2025-08-27 01:38:38,896 - INFO - ================================================================================
2025-08-27 01:38:38,896 - INFO - Routing mode: nas
2025-08-27 01:38:38,896 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-27 01:38:38,896 - INFO - Phase 1: Architecture search/initialization
2025-08-27 01:38:38,896 - INFO - Phase 2: Discrete training with uncertainty (NO variance)
2025-08-27 01:38:38,896 - INFO - ============================================================
2025-08-27 01:38:38,896 - INFO - PHASE 1: ARCHITECTURE SEARCH/INITIALIZATION
2025-08-27 01:38:38,896 - INFO - ============================================================
2025-08-27 01:38:38,896 - INFO - Splitting dataset for DARTS:
2025-08-27 01:38:38,896 - INFO -   Original train size: 10000
2025-08-27 01:38:38,896 - INFO -   DARTS train size: 6000 (60.0%)
2025-08-27 01:38:38,896 - INFO -   DARTS val size: 4000 (40.0%)
2025-08-27 01:38:38,897 - INFO - Found GraphGym wrapper, using inner model: <class 'graphgps.network.NAS_model_edge_syym.NASModelEdge'>
2025-08-27 01:38:38,898 - INFO - Successfully configured model for DARTS training
2025-08-27 01:38:38,898 - INFO - NAS MODE: Running 25 epochs with DARTS
2025-08-27 01:38:38,898 - INFO - DARTS Configuration:
2025-08-27 01:38:38,898 - INFO -   Epochs: 25
2025-08-27 01:38:38,898 - INFO -   Architecture LR: 0.0004
2025-08-27 01:38:38,898 - INFO -   Grad clip: 5.0
2025-08-27 01:38:38,904 - INFO - Starting DARTS architecture search
2025-08-27 01:38:42,552 - WARNING - Epoch [1/25] Step [1/250]  acc 0.162047 (0.162047)  loss 1.802960 (1.802960)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 3182.0 MB
2025-08-27 01:38:47,611 - WARNING - Epoch [1/25] Step [11/250]  acc 0.163863 (0.172313)  loss 1.797663 (1.793766)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 3306.0 MB
2025-08-27 01:38:52,880 - WARNING - Epoch [1/25] Step [21/250]  acc 0.149663 (0.175336)  loss 1.792289 (1.791697)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 4522.0 MB
2025-08-27 01:38:57,766 - WARNING - Epoch [1/25] Step [31/250]  acc 0.181171 (0.177575)  loss 1.785372 (1.790362)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 4522.0 MB
2025-08-27 01:39:02,563 - WARNING - Epoch [1/25] Step [41/250]  acc 0.175824 (0.180509)  loss 1.782817 (1.788479)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 5744.0 MB
2025-08-27 01:39:07,277 - WARNING - Epoch [1/25] Step [51/250]  acc 0.171601 (0.179178)  loss 1.776643 (1.787932)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 5744.0 MB
2025-08-27 01:39:12,028 - WARNING - Epoch [1/25] Step [61/250]  acc 0.178131 (0.179316)  loss 1.785160 (1.786977)
GPU memory consumption  GPU Memory: Allocated: 52.5 MB, Reserved: 5744.0 MB
2025-08-27 01:39:16,762 - WARNING - Epoch [1/25] Step [71/250]  acc 0.225954 (0.181520)  loss 1.742572 (1.784099)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 5744.0 MB
2025-08-27 01:39:21,647 - WARNING - Epoch [1/25] Step [81/250]  acc 0.217611 (0.186352)  loss 1.745419 (1.780796)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 5744.0 MB
2025-08-27 01:39:26,422 - WARNING - Epoch [1/25] Step [91/250]  acc 0.262802 (0.190785)  loss 1.715131 (1.776175)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 5744.0 MB
2025-08-27 01:39:31,457 - WARNING - Epoch [1/25] Step [101/250]  acc 0.245920 (0.195940)  loss 1.715720 (1.770698)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 5744.0 MB
2025-08-27 01:39:36,164 - WARNING - Epoch [1/25] Step [111/250]  acc 0.205362 (0.199009)  loss 1.737590 (1.766994)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 5744.0 MB
2025-08-27 01:39:40,893 - WARNING - Epoch [1/25] Step [121/250]  acc 0.220287 (0.202047)  loss 1.710821 (1.762251)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 5744.0 MB
2025-08-27 01:39:45,587 - WARNING - Epoch [1/25] Step [131/250]  acc 0.236885 (0.204749)  loss 1.676051 (1.756463)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 5748.0 MB
2025-08-27 01:39:50,244 - WARNING - Epoch [1/25] Step [141/250]  acc 0.209337 (0.207026)  loss 1.678663 (1.750339)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 5748.0 MB
2025-08-27 01:39:54,971 - WARNING - Epoch [1/25] Step [151/250]  acc 0.239048 (0.209803)  loss 1.718566 (1.745592)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 5748.0 MB
2025-08-27 01:39:59,874 - WARNING - Epoch [1/25] Step [161/250]  acc 0.278826 (0.212085)  loss 1.647639 (1.739795)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 5748.0 MB
2025-08-27 01:40:04,579 - WARNING - Epoch [1/25] Step [171/250]  acc 0.239719 (0.214512)  loss 1.641282 (1.734771)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 5748.0 MB
2025-08-27 01:40:09,271 - WARNING - Epoch [1/25] Step [181/250]  acc 0.231454 (0.216472)  loss 1.631334 (1.729865)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 5748.0 MB
2025-08-27 01:40:13,923 - WARNING - Epoch [1/25] Step [191/250]  acc 0.266735 (0.218634)  loss 1.642040 (1.725151)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 5748.0 MB
2025-08-27 01:40:18,581 - WARNING - Epoch [1/25] Step [201/250]  acc 0.270776 (0.219907)  loss 1.642508 (1.721198)
GPU memory consumption  GPU Memory: Allocated: 53.0 MB, Reserved: 5748.0 MB
2025-08-27 01:40:23,269 - WARNING - Epoch [1/25] Step [211/250]  acc 0.240865 (0.221217)  loss 1.671229 (1.717502)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 5748.0 MB
2025-08-27 01:40:27,887 - WARNING - Epoch [1/25] Step [221/250]  acc 0.246065 (0.222432)  loss 1.645447 (1.713865)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 5748.0 MB
2025-08-27 01:40:32,565 - WARNING - Epoch [1/25] Step [231/250]  acc 0.266633 (0.223560)  loss 1.641414 (1.710280)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 5748.0 MB
2025-08-27 01:40:37,280 - WARNING - Epoch [1/25] Step [241/250]  acc 0.304264 (0.224709)  loss 1.579493 (1.707055)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 5748.0 MB
Epoch 1 completed in 0:02:02.611210
2025-08-27 01:41:10,117 - WARNING - Epoch [2/25] Step [1/250]  acc 0.280268 (0.280268)  loss 1.639553 (1.639553)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 5748.0 MB
2025-08-27 01:41:14,964 - WARNING - Epoch [2/25] Step [11/250]  acc 0.257431 (0.255089)  loss 1.630653 (1.642367)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 5748.0 MB
2025-08-27 01:41:19,598 - WARNING - Epoch [2/25] Step [21/250]  acc 0.255474 (0.251493)  loss 1.603418 (1.636869)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 5748.0 MB
2025-08-27 01:41:24,246 - WARNING - Epoch [2/25] Step [31/250]  acc 0.254413 (0.253927)  loss 1.606553 (1.633973)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 5748.0 MB
2025-08-27 01:41:28,875 - WARNING - Epoch [2/25] Step [41/250]  acc 0.274307 (0.255151)  loss 1.610234 (1.634340)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 5748.0 MB
2025-08-27 01:41:33,500 - WARNING - Epoch [2/25] Step [51/250]  acc 0.244078 (0.256137)  loss 1.574164 (1.628546)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 5748.0 MB
2025-08-27 01:41:38,217 - WARNING - Epoch [2/25] Step [61/250]  acc 0.242209 (0.256317)  loss 1.673547 (1.627072)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 5748.0 MB
2025-08-27 01:41:42,863 - WARNING - Epoch [2/25] Step [71/250]  acc 0.276148 (0.255124)  loss 1.585411 (1.627856)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 5748.0 MB
2025-08-27 01:41:47,602 - WARNING - Epoch [2/25] Step [81/250]  acc 0.246265 (0.254479)  loss 1.619899 (1.628557)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 5748.0 MB
2025-08-27 01:41:52,318 - WARNING - Epoch [2/25] Step [91/250]  acc 0.273239 (0.254868)  loss 1.564073 (1.626091)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 5748.0 MB
2025-08-27 01:41:57,045 - WARNING - Epoch [2/25] Step [101/250]  acc 0.270242 (0.253966)  loss 1.598977 (1.625740)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 5748.0 MB
2025-08-27 01:42:01,748 - WARNING - Epoch [2/25] Step [111/250]  acc 0.287839 (0.253680)  loss 1.588015 (1.626559)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 5748.0 MB
2025-08-27 01:42:06,433 - WARNING - Epoch [2/25] Step [121/250]  acc 0.291601 (0.254294)  loss 1.610786 (1.626986)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 5748.0 MB
2025-08-27 01:42:11,092 - WARNING - Epoch [2/25] Step [131/250]  acc 0.232033 (0.254933)  loss 1.620107 (1.626961)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 5748.0 MB
2025-08-27 01:42:15,669 - WARNING - Epoch [2/25] Step [141/250]  acc 0.239544 (0.254981)  loss 1.594212 (1.627585)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 5748.0 MB
2025-08-27 01:42:20,529 - WARNING - Epoch [2/25] Step [151/250]  acc 0.238462 (0.255581)  loss 1.686124 (1.626779)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 5748.0 MB
2025-08-27 01:42:25,195 - WARNING - Epoch [2/25] Step [161/250]  acc 0.262166 (0.255601)  loss 1.590374 (1.626143)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 5748.0 MB
2025-08-27 01:42:29,838 - WARNING - Epoch [2/25] Step [171/250]  acc 0.263730 (0.255443)  loss 1.640606 (1.625281)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 5748.0 MB
2025-08-27 01:42:34,443 - WARNING - Epoch [2/25] Step [181/250]  acc 0.251762 (0.255068)  loss 1.645338 (1.624361)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 5748.0 MB
2025-08-27 01:42:39,075 - WARNING - Epoch [2/25] Step [191/250]  acc 0.228497 (0.255017)  loss 1.592177 (1.624249)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 5748.0 MB
2025-08-27 01:42:43,692 - WARNING - Epoch [2/25] Step [201/250]  acc 0.245320 (0.255421)  loss 1.613742 (1.623292)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 5748.0 MB
2025-08-27 01:42:48,350 - WARNING - Epoch [2/25] Step [211/250]  acc 0.270483 (0.256219)  loss 1.616664 (1.622309)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 5748.0 MB
2025-08-27 01:42:53,070 - WARNING - Epoch [2/25] Step [221/250]  acc 0.212939 (0.256752)  loss 1.630990 (1.621272)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 01:42:57,726 - WARNING - Epoch [2/25] Step [231/250]  acc 0.268823 (0.256496)  loss 1.626633 (1.621370)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7800.0 MB
2025-08-27 01:43:02,376 - WARNING - Epoch [2/25] Step [241/250]  acc 0.227421 (0.256316)  loss 1.622549 (1.620528)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
Epoch 2 completed in 0:01:56.869232
2025-08-27 01:43:35,070 - WARNING - Epoch [3/25] Step [1/250]  acc 0.208228 (0.208228)  loss 1.663209 (1.663209)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 01:43:39,722 - WARNING - Epoch [3/25] Step [11/250]  acc 0.246285 (0.247253)  loss 1.588403 (1.600240)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7800.0 MB
2025-08-27 01:43:44,367 - WARNING - Epoch [3/25] Step [21/250]  acc 0.253623 (0.250939)  loss 1.614322 (1.609197)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 01:43:48,976 - WARNING - Epoch [3/25] Step [31/250]  acc 0.261838 (0.250704)  loss 1.623124 (1.611781)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7800.0 MB
2025-08-27 01:43:53,841 - WARNING - Epoch [3/25] Step [41/250]  acc 0.283918 (0.248584)  loss 1.595614 (1.609059)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 7800.0 MB
2025-08-27 01:43:58,496 - WARNING - Epoch [3/25] Step [51/250]  acc 0.266055 (0.250698)  loss 1.603379 (1.607483)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 01:44:03,174 - WARNING - Epoch [3/25] Step [61/250]  acc 0.257649 (0.253897)  loss 1.609025 (1.605731)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7800.0 MB
2025-08-27 01:44:07,851 - WARNING - Epoch [3/25] Step [71/250]  acc 0.255194 (0.253141)  loss 1.611169 (1.605194)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7800.0 MB
2025-08-27 01:44:12,536 - WARNING - Epoch [3/25] Step [81/250]  acc 0.242849 (0.253948)  loss 1.585570 (1.606791)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 01:44:17,213 - WARNING - Epoch [3/25] Step [91/250]  acc 0.252742 (0.254571)  loss 1.586896 (1.607394)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 01:44:21,879 - WARNING - Epoch [3/25] Step [101/250]  acc 0.255814 (0.254318)  loss 1.542661 (1.606092)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7800.0 MB
2025-08-27 01:44:26,527 - WARNING - Epoch [3/25] Step [111/250]  acc 0.255112 (0.253655)  loss 1.590502 (1.605913)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 7800.0 MB
2025-08-27 01:44:31,175 - WARNING - Epoch [3/25] Step [121/250]  acc 0.222338 (0.253817)  loss 1.580742 (1.605342)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 01:44:35,840 - WARNING - Epoch [3/25] Step [131/250]  acc 0.219844 (0.253963)  loss 1.610418 (1.603465)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 7800.0 MB
2025-08-27 01:44:40,530 - WARNING - Epoch [3/25] Step [141/250]  acc 0.263187 (0.253548)  loss 1.588474 (1.605130)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 7800.0 MB
2025-08-27 01:44:45,248 - WARNING - Epoch [3/25] Step [151/250]  acc 0.222732 (0.253684)  loss 1.616137 (1.604872)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 01:44:49,944 - WARNING - Epoch [3/25] Step [161/250]  acc 0.262312 (0.253825)  loss 1.535597 (1.604196)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 01:44:54,646 - WARNING - Epoch [3/25] Step [171/250]  acc 0.274135 (0.253412)  loss 1.584702 (1.605010)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 01:44:59,544 - WARNING - Epoch [3/25] Step [181/250]  acc 0.239615 (0.253929)  loss 1.578979 (1.603363)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 01:45:04,275 - WARNING - Epoch [3/25] Step [191/250]  acc 0.210046 (0.253529)  loss 1.637966 (1.602831)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7800.0 MB
2025-08-27 01:45:09,082 - WARNING - Epoch [3/25] Step [201/250]  acc 0.238485 (0.253140)  loss 1.617672 (1.603071)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 01:45:13,804 - WARNING - Epoch [3/25] Step [211/250]  acc 0.288482 (0.253101)  loss 1.579131 (1.602863)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7800.0 MB
2025-08-27 01:45:18,544 - WARNING - Epoch [3/25] Step [221/250]  acc 0.243105 (0.253418)  loss 1.603332 (1.602299)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 01:45:23,294 - WARNING - Epoch [3/25] Step [231/250]  acc 0.244420 (0.253238)  loss 1.613478 (1.602506)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7800.0 MB
2025-08-27 01:45:27,981 - WARNING - Epoch [3/25] Step [241/250]  acc 0.244601 (0.253080)  loss 1.562867 (1.602041)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 7800.0 MB
Epoch 3 completed in 0:01:57.599293
2025-08-27 01:46:00,724 - WARNING - Epoch [4/25] Step [1/250]  acc 0.257403 (0.257403)  loss 1.574956 (1.574956)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7800.0 MB
2025-08-27 01:46:05,332 - WARNING - Epoch [4/25] Step [11/250]  acc 0.225518 (0.247669)  loss 1.551465 (1.606579)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7800.0 MB
2025-08-27 01:46:10,029 - WARNING - Epoch [4/25] Step [21/250]  acc 0.256117 (0.248374)  loss 1.560610 (1.603029)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 01:46:14,696 - WARNING - Epoch [4/25] Step [31/250]  acc 0.243151 (0.251365)  loss 1.588996 (1.602453)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 7800.0 MB
2025-08-27 01:46:19,389 - WARNING - Epoch [4/25] Step [41/250]  acc 0.267935 (0.251340)  loss 1.617824 (1.604324)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7800.0 MB
2025-08-27 01:46:24,100 - WARNING - Epoch [4/25] Step [51/250]  acc 0.232558 (0.250661)  loss 1.648674 (1.609665)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 7800.0 MB
2025-08-27 01:46:28,810 - WARNING - Epoch [4/25] Step [61/250]  acc 0.239785 (0.250010)  loss 1.592983 (1.610105)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7800.0 MB
2025-08-27 01:46:33,477 - WARNING - Epoch [4/25] Step [71/250]  acc 0.249356 (0.250026)  loss 1.627615 (1.611469)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 01:46:38,170 - WARNING - Epoch [4/25] Step [81/250]  acc 0.286334 (0.250989)  loss 1.565236 (1.610124)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 01:46:43,242 - WARNING - Epoch [4/25] Step [91/250]  acc 0.250527 (0.250472)  loss 1.632059 (1.612078)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7800.0 MB
2025-08-27 01:46:48,047 - WARNING - Epoch [4/25] Step [101/250]  acc 0.267754 (0.250215)  loss 1.601557 (1.611785)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 7800.0 MB
2025-08-27 01:46:52,803 - WARNING - Epoch [4/25] Step [111/250]  acc 0.275049 (0.249538)  loss 1.583423 (1.610305)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 7800.0 MB
2025-08-27 01:46:57,519 - WARNING - Epoch [4/25] Step [121/250]  acc 0.326180 (0.250056)  loss 1.584987 (1.609545)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 01:47:02,225 - WARNING - Epoch [4/25] Step [131/250]  acc 0.285787 (0.250819)  loss 1.559138 (1.608179)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 01:47:06,904 - WARNING - Epoch [4/25] Step [141/250]  acc 0.241860 (0.249649)  loss 1.643959 (1.609101)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 01:47:11,631 - WARNING - Epoch [4/25] Step [151/250]  acc 0.248508 (0.249171)  loss 1.617984 (1.609773)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 7800.0 MB
2025-08-27 01:47:16,366 - WARNING - Epoch [4/25] Step [161/250]  acc 0.246888 (0.249293)  loss 1.626840 (1.610412)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 01:47:21,072 - WARNING - Epoch [4/25] Step [171/250]  acc 0.280978 (0.249906)  loss 1.544081 (1.609931)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
2025-08-27 01:47:25,818 - WARNING - Epoch [4/25] Step [181/250]  acc 0.235479 (0.249876)  loss 1.584073 (1.608259)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 01:47:30,505 - WARNING - Epoch [4/25] Step [191/250]  acc 0.227723 (0.249794)  loss 1.614064 (1.607984)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
2025-08-27 01:47:35,195 - WARNING - Epoch [4/25] Step [201/250]  acc 0.310972 (0.250290)  loss 1.579461 (1.607563)
GPU memory consumption  GPU Memory: Allocated: 52.0 MB, Reserved: 7800.0 MB
2025-08-27 01:47:39,937 - WARNING - Epoch [4/25] Step [211/250]  acc 0.240605 (0.249790)  loss 1.579669 (1.607024)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7800.0 MB
2025-08-27 01:47:44,670 - WARNING - Epoch [4/25] Step [221/250]  acc 0.245357 (0.249830)  loss 1.609613 (1.607079)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 7800.0 MB
2025-08-27 01:47:49,399 - WARNING - Epoch [4/25] Step [231/250]  acc 0.235599 (0.249717)  loss 1.561541 (1.606453)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7800.0 MB
2025-08-27 01:47:54,418 - WARNING - Epoch [4/25] Step [241/250]  acc 0.238217 (0.249787)  loss 1.653985 (1.606406)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7800.0 MB
Epoch 4 completed in 0:01:58.425848
2025-08-27 01:48:27,536 - WARNING - Epoch [5/25] Step [1/250]  acc 0.231764 (0.231764)  loss 1.628475 (1.628475)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 01:48:32,241 - WARNING - Epoch [5/25] Step [11/250]  acc 0.253699 (0.245122)  loss 1.602836 (1.601509)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 01:48:36,956 - WARNING - Epoch [5/25] Step [21/250]  acc 0.308380 (0.251312)  loss 1.577924 (1.596779)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 7800.0 MB
2025-08-27 01:48:41,666 - WARNING - Epoch [5/25] Step [31/250]  acc 0.241218 (0.253869)  loss 1.616510 (1.592296)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 7800.0 MB
2025-08-27 01:48:46,361 - WARNING - Epoch [5/25] Step [41/250]  acc 0.194728 (0.251609)  loss 1.580250 (1.596568)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 01:48:51,004 - WARNING - Epoch [5/25] Step [51/250]  acc 0.265393 (0.250935)  loss 1.574426 (1.598606)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7800.0 MB
2025-08-27 01:48:55,692 - WARNING - Epoch [5/25] Step [61/250]  acc 0.228415 (0.249843)  loss 1.662731 (1.602284)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7800.0 MB
2025-08-27 01:49:00,445 - WARNING - Epoch [5/25] Step [71/250]  acc 0.251004 (0.249499)  loss 1.599789 (1.601431)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7800.0 MB
2025-08-27 01:49:05,151 - WARNING - Epoch [5/25] Step [81/250]  acc 0.229589 (0.249265)  loss 1.674275 (1.601180)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 7800.0 MB
2025-08-27 01:49:09,843 - WARNING - Epoch [5/25] Step [91/250]  acc 0.272155 (0.249286)  loss 1.563840 (1.599870)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 01:49:14,535 - WARNING - Epoch [5/25] Step [101/250]  acc 0.250530 (0.250846)  loss 1.586181 (1.598030)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 7800.0 MB
2025-08-27 01:49:19,234 - WARNING - Epoch [5/25] Step [111/250]  acc 0.232047 (0.251708)  loss 1.588765 (1.598033)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 7800.0 MB
2025-08-27 01:49:23,906 - WARNING - Epoch [5/25] Step [121/250]  acc 0.284165 (0.252418)  loss 1.561432 (1.598169)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 01:49:28,613 - WARNING - Epoch [5/25] Step [131/250]  acc 0.258221 (0.252497)  loss 1.616886 (1.597423)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7800.0 MB
2025-08-27 01:49:33,574 - WARNING - Epoch [5/25] Step [141/250]  acc 0.266921 (0.251717)  loss 1.578767 (1.599826)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7800.0 MB
2025-08-27 01:49:38,270 - WARNING - Epoch [5/25] Step [151/250]  acc 0.217891 (0.251607)  loss 1.612019 (1.599852)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 7800.0 MB
2025-08-27 01:49:42,974 - WARNING - Epoch [5/25] Step [161/250]  acc 0.277602 (0.252203)  loss 1.586084 (1.600613)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 01:49:47,668 - WARNING - Epoch [5/25] Step [171/250]  acc 0.239400 (0.252105)  loss 1.567623 (1.601238)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 01:49:52,321 - WARNING - Epoch [5/25] Step [181/250]  acc 0.209804 (0.252060)  loss 1.609080 (1.601147)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 7800.0 MB
2025-08-27 01:49:56,968 - WARNING - Epoch [5/25] Step [191/250]  acc 0.250131 (0.251930)  loss 1.597600 (1.600445)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7800.0 MB
2025-08-27 01:50:01,667 - WARNING - Epoch [5/25] Step [201/250]  acc 0.260981 (0.251586)  loss 1.612572 (1.599925)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 01:50:06,383 - WARNING - Epoch [5/25] Step [211/250]  acc 0.266528 (0.251698)  loss 1.579713 (1.598768)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7800.0 MB
2025-08-27 01:50:11,076 - WARNING - Epoch [5/25] Step [221/250]  acc 0.269935 (0.251477)  loss 1.578800 (1.598554)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
2025-08-27 01:50:15,739 - WARNING - Epoch [5/25] Step [231/250]  acc 0.250273 (0.251512)  loss 1.588068 (1.598585)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7800.0 MB
2025-08-27 01:50:20,405 - WARNING - Epoch [5/25] Step [241/250]  acc 0.290526 (0.251595)  loss 1.559294 (1.597951)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7800.0 MB
Epoch 5 completed in 0:01:57.563618
2025-08-27 01:50:53,016 - WARNING - Epoch [6/25] Step [1/250]  acc 0.254332 (0.254332)  loss 1.538461 (1.538461)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 01:50:57,668 - WARNING - Epoch [6/25] Step [11/250]  acc 0.300575 (0.255410)  loss 1.581504 (1.586207)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 01:51:02,367 - WARNING - Epoch [6/25] Step [21/250]  acc 0.241138 (0.253790)  loss 1.562853 (1.593693)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 01:51:07,083 - WARNING - Epoch [6/25] Step [31/250]  acc 0.254956 (0.251145)  loss 1.652898 (1.599238)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
2025-08-27 01:51:12,002 - WARNING - Epoch [6/25] Step [41/250]  acc 0.249742 (0.250923)  loss 1.600482 (1.597911)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 01:51:16,648 - WARNING - Epoch [6/25] Step [51/250]  acc 0.244767 (0.250281)  loss 1.570712 (1.601229)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7800.0 MB
2025-08-27 01:51:21,279 - WARNING - Epoch [6/25] Step [61/250]  acc 0.292417 (0.251537)  loss 1.609455 (1.599851)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7800.0 MB
2025-08-27 01:51:25,906 - WARNING - Epoch [6/25] Step [71/250]  acc 0.293684 (0.250778)  loss 1.585787 (1.601591)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7800.0 MB
2025-08-27 01:51:30,663 - WARNING - Epoch [6/25] Step [81/250]  acc 0.279879 (0.251021)  loss 1.587252 (1.600734)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 7800.0 MB
2025-08-27 01:51:35,390 - WARNING - Epoch [6/25] Step [91/250]  acc 0.252417 (0.250893)  loss 1.590998 (1.598980)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7800.0 MB
2025-08-27 01:51:40,122 - WARNING - Epoch [6/25] Step [101/250]  acc 0.271330 (0.251366)  loss 1.579215 (1.598427)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 01:51:44,805 - WARNING - Epoch [6/25] Step [111/250]  acc 0.264463 (0.252474)  loss 1.626468 (1.598542)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
2025-08-27 01:51:49,488 - WARNING - Epoch [6/25] Step [121/250]  acc 0.256983 (0.252546)  loss 1.591066 (1.598096)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 01:51:54,170 - WARNING - Epoch [6/25] Step [131/250]  acc 0.227004 (0.251731)  loss 1.597131 (1.599289)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
2025-08-27 01:51:58,886 - WARNING - Epoch [6/25] Step [141/250]  acc 0.276947 (0.251573)  loss 1.584065 (1.599968)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 01:52:03,578 - WARNING - Epoch [6/25] Step [151/250]  acc 0.254800 (0.251845)  loss 1.610230 (1.600457)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 01:52:08,337 - WARNING - Epoch [6/25] Step [161/250]  acc 0.273102 (0.252120)  loss 1.557818 (1.599465)
GPU memory consumption  GPU Memory: Allocated: 52.9 MB, Reserved: 7800.0 MB
2025-08-27 01:52:13,096 - WARNING - Epoch [6/25] Step [171/250]  acc 0.231320 (0.252227)  loss 1.617038 (1.599273)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 01:52:17,780 - WARNING - Epoch [6/25] Step [181/250]  acc 0.294968 (0.252153)  loss 1.571972 (1.599498)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
2025-08-27 01:52:22,726 - WARNING - Epoch [6/25] Step [191/250]  acc 0.257878 (0.252576)  loss 1.560163 (1.598715)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7800.0 MB
2025-08-27 01:52:27,367 - WARNING - Epoch [6/25] Step [201/250]  acc 0.237916 (0.252543)  loss 1.602883 (1.599526)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 7800.0 MB
2025-08-27 01:52:32,022 - WARNING - Epoch [6/25] Step [211/250]  acc 0.259740 (0.252349)  loss 1.567170 (1.599269)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 7800.0 MB
2025-08-27 01:52:36,678 - WARNING - Epoch [6/25] Step [221/250]  acc 0.279380 (0.252106)  loss 1.569578 (1.599278)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 7800.0 MB
2025-08-27 01:52:41,411 - WARNING - Epoch [6/25] Step [231/250]  acc 0.231257 (0.251500)  loss 1.576228 (1.599673)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 7800.0 MB
2025-08-27 01:52:46,080 - WARNING - Epoch [6/25] Step [241/250]  acc 0.258656 (0.251985)  loss 1.596834 (1.599277)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7800.0 MB
Epoch 6 completed in 0:01:57.738268
2025-08-27 01:53:18,637 - WARNING - Epoch [7/25] Step [1/250]  acc 0.259240 (0.259240)  loss 1.628986 (1.628986)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 01:53:23,296 - WARNING - Epoch [7/25] Step [11/250]  acc 0.254818 (0.256278)  loss 1.585444 (1.612431)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 01:53:27,979 - WARNING - Epoch [7/25] Step [21/250]  acc 0.280060 (0.254354)  loss 1.636901 (1.612475)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 01:53:32,666 - WARNING - Epoch [7/25] Step [31/250]  acc 0.278386 (0.252494)  loss 1.566390 (1.609935)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 7800.0 MB
2025-08-27 01:53:37,396 - WARNING - Epoch [7/25] Step [41/250]  acc 0.257616 (0.252894)  loss 1.556690 (1.606213)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 7800.0 MB
2025-08-27 01:53:42,072 - WARNING - Epoch [7/25] Step [51/250]  acc 0.255509 (0.254575)  loss 1.598931 (1.605350)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 01:53:46,770 - WARNING - Epoch [7/25] Step [61/250]  acc 0.251372 (0.254304)  loss 1.610789 (1.603542)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7800.0 MB
2025-08-27 01:53:51,462 - WARNING - Epoch [7/25] Step [71/250]  acc 0.214098 (0.254004)  loss 1.566436 (1.602140)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7800.0 MB
2025-08-27 01:53:56,071 - WARNING - Epoch [7/25] Step [81/250]  acc 0.278412 (0.254640)  loss 1.570226 (1.600426)
GPU memory consumption  GPU Memory: Allocated: 59.4 MB, Reserved: 7800.0 MB
2025-08-27 01:54:00,979 - WARNING - Epoch [7/25] Step [91/250]  acc 0.253571 (0.255018)  loss 1.591312 (1.601113)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 01:54:05,918 - WARNING - Epoch [7/25] Step [101/250]  acc 0.233465 (0.254939)  loss 1.566721 (1.599590)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7800.0 MB
2025-08-27 01:54:10,670 - WARNING - Epoch [7/25] Step [111/250]  acc 0.246486 (0.255709)  loss 1.616508 (1.599815)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7800.0 MB
2025-08-27 01:54:15,373 - WARNING - Epoch [7/25] Step [121/250]  acc 0.248545 (0.255278)  loss 1.614016 (1.601050)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7800.0 MB
2025-08-27 01:54:20,107 - WARNING - Epoch [7/25] Step [131/250]  acc 0.265496 (0.254901)  loss 1.547154 (1.601206)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 01:54:24,810 - WARNING - Epoch [7/25] Step [141/250]  acc 0.271639 (0.255497)  loss 1.585744 (1.600969)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 01:54:29,511 - WARNING - Epoch [7/25] Step [151/250]  acc 0.236814 (0.254833)  loss 1.618096 (1.600911)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 01:54:34,265 - WARNING - Epoch [7/25] Step [161/250]  acc 0.278060 (0.255332)  loss 1.603870 (1.600503)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 7800.0 MB
2025-08-27 01:54:38,967 - WARNING - Epoch [7/25] Step [171/250]  acc 0.280251 (0.256039)  loss 1.566610 (1.599413)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7800.0 MB
2025-08-27 01:54:43,735 - WARNING - Epoch [7/25] Step [181/250]  acc 0.259948 (0.256321)  loss 1.610537 (1.598716)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 01:54:48,448 - WARNING - Epoch [7/25] Step [191/250]  acc 0.220682 (0.256257)  loss 1.598364 (1.597663)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7800.0 MB
2025-08-27 01:54:53,202 - WARNING - Epoch [7/25] Step [201/250]  acc 0.264479 (0.256816)  loss 1.589945 (1.597168)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 7800.0 MB
2025-08-27 01:54:57,889 - WARNING - Epoch [7/25] Step [211/250]  acc 0.291334 (0.256737)  loss 1.545150 (1.596856)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 7800.0 MB
2025-08-27 01:55:02,646 - WARNING - Epoch [7/25] Step [221/250]  acc 0.216728 (0.255993)  loss 1.618522 (1.598298)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 01:55:07,455 - WARNING - Epoch [7/25] Step [231/250]  acc 0.243030 (0.255577)  loss 1.576932 (1.597913)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 01:55:12,782 - WARNING - Epoch [7/25] Step [241/250]  acc 0.251282 (0.255778)  loss 1.650539 (1.597778)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7800.0 MB
Epoch 7 completed in 0:01:59.307985
2025-08-27 01:55:46,479 - WARNING - Epoch [8/25] Step [1/250]  acc 0.259295 (0.259295)  loss 1.567190 (1.567190)
GPU memory consumption  GPU Memory: Allocated: 59.6 MB, Reserved: 7800.0 MB
2025-08-27 01:55:51,187 - WARNING - Epoch [8/25] Step [11/250]  acc 0.210300 (0.260588)  loss 1.587703 (1.570134)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 01:55:55,857 - WARNING - Epoch [8/25] Step [21/250]  acc 0.259636 (0.254784)  loss 1.578462 (1.582258)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
2025-08-27 01:56:00,610 - WARNING - Epoch [8/25] Step [31/250]  acc 0.269392 (0.252720)  loss 1.616481 (1.588534)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7800.0 MB
2025-08-27 01:56:05,399 - WARNING - Epoch [8/25] Step [41/250]  acc 0.248913 (0.251993)  loss 1.585454 (1.590779)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 01:56:10,129 - WARNING - Epoch [8/25] Step [51/250]  acc 0.251091 (0.251177)  loss 1.582653 (1.591130)
GPU memory consumption  GPU Memory: Allocated: 61.0 MB, Reserved: 7800.0 MB
2025-08-27 01:56:14,840 - WARNING - Epoch [8/25] Step [61/250]  acc 0.248216 (0.251295)  loss 1.600688 (1.593448)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 01:56:19,484 - WARNING - Epoch [8/25] Step [71/250]  acc 0.248965 (0.250621)  loss 1.622622 (1.594807)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 01:56:24,284 - WARNING - Epoch [8/25] Step [81/250]  acc 0.286753 (0.252026)  loss 1.616115 (1.593403)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 01:56:28,954 - WARNING - Epoch [8/25] Step [91/250]  acc 0.233759 (0.252958)  loss 1.614740 (1.591769)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 7800.0 MB
2025-08-27 01:56:33,608 - WARNING - Epoch [8/25] Step [101/250]  acc 0.259811 (0.252568)  loss 1.596588 (1.591520)
GPU memory consumption  GPU Memory: Allocated: 59.5 MB, Reserved: 7800.0 MB
2025-08-27 01:56:38,284 - WARNING - Epoch [8/25] Step [111/250]  acc 0.240064 (0.252337)  loss 1.586402 (1.591158)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7800.0 MB
2025-08-27 01:56:42,974 - WARNING - Epoch [8/25] Step [121/250]  acc 0.259475 (0.252102)  loss 1.558413 (1.591028)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7800.0 MB
2025-08-27 01:56:47,598 - WARNING - Epoch [8/25] Step [131/250]  acc 0.248631 (0.252598)  loss 1.636375 (1.592374)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7800.0 MB
2025-08-27 01:56:52,274 - WARNING - Epoch [8/25] Step [141/250]  acc 0.284655 (0.252796)  loss 1.607512 (1.593560)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7800.0 MB
2025-08-27 01:56:57,156 - WARNING - Epoch [8/25] Step [151/250]  acc 0.248576 (0.253145)  loss 1.630389 (1.594602)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 01:57:01,802 - WARNING - Epoch [8/25] Step [161/250]  acc 0.245155 (0.252091)  loss 1.623076 (1.594615)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 01:57:06,544 - WARNING - Epoch [8/25] Step [171/250]  acc 0.245893 (0.251900)  loss 1.528685 (1.594372)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 01:57:11,240 - WARNING - Epoch [8/25] Step [181/250]  acc 0.251537 (0.252654)  loss 1.561365 (1.593697)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 01:57:15,923 - WARNING - Epoch [8/25] Step [191/250]  acc 0.240532 (0.252978)  loss 1.625592 (1.593625)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7800.0 MB
2025-08-27 01:57:20,604 - WARNING - Epoch [8/25] Step [201/250]  acc 0.254505 (0.253290)  loss 1.574486 (1.593185)
GPU memory consumption  GPU Memory: Allocated: 52.2 MB, Reserved: 7800.0 MB
2025-08-27 01:57:25,326 - WARNING - Epoch [8/25] Step [211/250]  acc 0.282691 (0.253507)  loss 1.541176 (1.593202)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 7800.0 MB
2025-08-27 01:57:30,006 - WARNING - Epoch [8/25] Step [221/250]  acc 0.229961 (0.253108)  loss 1.593119 (1.593860)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
2025-08-27 01:57:34,740 - WARNING - Epoch [8/25] Step [231/250]  acc 0.245000 (0.253153)  loss 1.608936 (1.593571)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7800.0 MB
2025-08-27 01:57:39,411 - WARNING - Epoch [8/25] Step [241/250]  acc 0.223881 (0.253279)  loss 1.588246 (1.592911)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7800.0 MB
Epoch 8 completed in 0:01:57.652075
2025-08-27 01:58:12,378 - WARNING - Epoch [9/25] Step [1/250]  acc 0.219881 (0.219881)  loss 1.593843 (1.593843)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 01:58:17,057 - WARNING - Epoch [9/25] Step [11/250]  acc 0.275824 (0.267278)  loss 1.585934 (1.591312)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7800.0 MB
2025-08-27 01:58:21,735 - WARNING - Epoch [9/25] Step [21/250]  acc 0.203429 (0.264212)  loss 1.650857 (1.591742)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7800.0 MB
2025-08-27 01:58:26,414 - WARNING - Epoch [9/25] Step [31/250]  acc 0.253747 (0.261136)  loss 1.602816 (1.591533)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7800.0 MB
2025-08-27 01:58:31,147 - WARNING - Epoch [9/25] Step [41/250]  acc 0.251748 (0.259085)  loss 1.601687 (1.591711)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 01:58:36,018 - WARNING - Epoch [9/25] Step [51/250]  acc 0.305831 (0.258990)  loss 1.565800 (1.591940)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 01:58:40,727 - WARNING - Epoch [9/25] Step [61/250]  acc 0.249572 (0.259290)  loss 1.612233 (1.591582)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 7800.0 MB
2025-08-27 01:58:45,426 - WARNING - Epoch [9/25] Step [71/250]  acc 0.243664 (0.258479)  loss 1.641431 (1.590784)
GPU memory consumption  GPU Memory: Allocated: 52.6 MB, Reserved: 7800.0 MB
2025-08-27 01:58:50,199 - WARNING - Epoch [9/25] Step [81/250]  acc 0.249221 (0.257669)  loss 1.579776 (1.588986)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 01:58:54,910 - WARNING - Epoch [9/25] Step [91/250]  acc 0.257889 (0.257174)  loss 1.650902 (1.589389)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 7800.0 MB
2025-08-27 01:58:59,558 - WARNING - Epoch [9/25] Step [101/250]  acc 0.221974 (0.256683)  loss 1.566364 (1.588384)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 01:59:04,237 - WARNING - Epoch [9/25] Step [111/250]  acc 0.192577 (0.255772)  loss 1.564792 (1.586489)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 01:59:08,902 - WARNING - Epoch [9/25] Step [121/250]  acc 0.280369 (0.255079)  loss 1.569991 (1.587507)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 01:59:13,620 - WARNING - Epoch [9/25] Step [131/250]  acc 0.220557 (0.255236)  loss 1.616508 (1.587709)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7800.0 MB
2025-08-27 01:59:18,268 - WARNING - Epoch [9/25] Step [141/250]  acc 0.292351 (0.255161)  loss 1.612741 (1.587482)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 7800.0 MB
2025-08-27 01:59:23,015 - WARNING - Epoch [9/25] Step [151/250]  acc 0.246506 (0.254559)  loss 1.616650 (1.588313)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 7800.0 MB
2025-08-27 01:59:27,730 - WARNING - Epoch [9/25] Step [161/250]  acc 0.251803 (0.254433)  loss 1.666049 (1.589784)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7800.0 MB
2025-08-27 01:59:32,421 - WARNING - Epoch [9/25] Step [171/250]  acc 0.267472 (0.254090)  loss 1.570379 (1.589842)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7800.0 MB
2025-08-27 01:59:37,141 - WARNING - Epoch [9/25] Step [181/250]  acc 0.270822 (0.253660)  loss 1.575787 (1.589484)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 01:59:41,818 - WARNING - Epoch [9/25] Step [191/250]  acc 0.273289 (0.253552)  loss 1.574346 (1.589294)
GPU memory consumption  GPU Memory: Allocated: 60.8 MB, Reserved: 7800.0 MB
2025-08-27 01:59:46,489 - WARNING - Epoch [9/25] Step [201/250]  acc 0.272969 (0.253823)  loss 1.613556 (1.590311)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7800.0 MB
2025-08-27 01:59:51,438 - WARNING - Epoch [9/25] Step [211/250]  acc 0.244909 (0.253364)  loss 1.583480 (1.590466)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7800.0 MB
2025-08-27 01:59:56,137 - WARNING - Epoch [9/25] Step [221/250]  acc 0.249443 (0.253584)  loss 1.579289 (1.590357)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
2025-08-27 02:00:00,877 - WARNING - Epoch [9/25] Step [231/250]  acc 0.228823 (0.252776)  loss 1.645535 (1.591247)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7800.0 MB
2025-08-27 02:00:05,652 - WARNING - Epoch [9/25] Step [241/250]  acc 0.255266 (0.252708)  loss 1.630299 (1.591592)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7800.0 MB
Epoch 9 completed in 0:01:58.062208
2025-08-27 02:00:38,739 - WARNING - Epoch [10/25] Step [1/250]  acc 0.267510 (0.267510)  loss 1.564680 (1.564680)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 7800.0 MB
2025-08-27 02:00:43,514 - WARNING - Epoch [10/25] Step [11/250]  acc 0.234409 (0.250862)  loss 1.649808 (1.598081)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7800.0 MB
2025-08-27 02:00:48,282 - WARNING - Epoch [10/25] Step [21/250]  acc 0.277778 (0.254537)  loss 1.580463 (1.592963)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:00:53,072 - WARNING - Epoch [10/25] Step [31/250]  acc 0.281972 (0.254029)  loss 1.530590 (1.589005)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7800.0 MB
2025-08-27 02:00:57,857 - WARNING - Epoch [10/25] Step [41/250]  acc 0.261160 (0.252594)  loss 1.589856 (1.590726)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 02:01:02,584 - WARNING - Epoch [10/25] Step [51/250]  acc 0.237432 (0.251510)  loss 1.554231 (1.594210)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7800.0 MB
2025-08-27 02:01:07,304 - WARNING - Epoch [10/25] Step [61/250]  acc 0.269705 (0.251544)  loss 1.630950 (1.597029)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7800.0 MB
2025-08-27 02:01:11,977 - WARNING - Epoch [10/25] Step [71/250]  acc 0.246313 (0.250645)  loss 1.623988 (1.599556)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 7800.0 MB
2025-08-27 02:01:16,683 - WARNING - Epoch [10/25] Step [81/250]  acc 0.281477 (0.250873)  loss 1.583219 (1.598227)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 02:01:21,351 - WARNING - Epoch [10/25] Step [91/250]  acc 0.250382 (0.250246)  loss 1.529369 (1.597911)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7800.0 MB
2025-08-27 02:01:26,011 - WARNING - Epoch [10/25] Step [101/250]  acc 0.261120 (0.249423)  loss 1.548263 (1.598028)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7800.0 MB
2025-08-27 02:01:30,726 - WARNING - Epoch [10/25] Step [111/250]  acc 0.310471 (0.250447)  loss 1.577632 (1.597834)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7800.0 MB
2025-08-27 02:01:35,670 - WARNING - Epoch [10/25] Step [121/250]  acc 0.257662 (0.250651)  loss 1.649965 (1.597689)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:01:40,374 - WARNING - Epoch [10/25] Step [131/250]  acc 0.241414 (0.250260)  loss 1.584558 (1.597941)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 7800.0 MB
2025-08-27 02:01:45,108 - WARNING - Epoch [10/25] Step [141/250]  acc 0.225959 (0.250686)  loss 1.584390 (1.597325)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:01:49,863 - WARNING - Epoch [10/25] Step [151/250]  acc 0.268743 (0.251219)  loss 1.564101 (1.596274)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 7800.0 MB
2025-08-27 02:01:54,532 - WARNING - Epoch [10/25] Step [161/250]  acc 0.244593 (0.251078)  loss 1.609332 (1.596715)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 02:01:59,223 - WARNING - Epoch [10/25] Step [171/250]  acc 0.262835 (0.250554)  loss 1.649576 (1.597209)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7800.0 MB
2025-08-27 02:02:03,938 - WARNING - Epoch [10/25] Step [181/250]  acc 0.243464 (0.250763)  loss 1.573776 (1.597177)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7800.0 MB
2025-08-27 02:02:08,646 - WARNING - Epoch [10/25] Step [191/250]  acc 0.288557 (0.250876)  loss 1.578619 (1.596779)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 7800.0 MB
2025-08-27 02:02:13,363 - WARNING - Epoch [10/25] Step [201/250]  acc 0.291559 (0.251539)  loss 1.556418 (1.596242)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 02:02:18,017 - WARNING - Epoch [10/25] Step [211/250]  acc 0.228707 (0.251874)  loss 1.573671 (1.595684)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7800.0 MB
2025-08-27 02:02:22,748 - WARNING - Epoch [10/25] Step [221/250]  acc 0.264151 (0.251650)  loss 1.633770 (1.595645)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7800.0 MB
2025-08-27 02:02:27,466 - WARNING - Epoch [10/25] Step [231/250]  acc 0.254299 (0.251547)  loss 1.576555 (1.595328)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7800.0 MB
2025-08-27 02:02:32,199 - WARNING - Epoch [10/25] Step [241/250]  acc 0.253607 (0.251280)  loss 1.581231 (1.594689)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
Epoch 10 completed in 0:01:58.238799
2025-08-27 02:03:05,637 - WARNING - Epoch [11/25] Step [1/250]  acc 0.240411 (0.240411)  loss 1.623432 (1.623432)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:03:10,353 - WARNING - Epoch [11/25] Step [11/250]  acc 0.263213 (0.254232)  loss 1.608633 (1.586402)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:03:15,267 - WARNING - Epoch [11/25] Step [21/250]  acc 0.220226 (0.250067)  loss 1.586653 (1.585718)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:03:19,882 - WARNING - Epoch [11/25] Step [31/250]  acc 0.295798 (0.253153)  loss 1.551399 (1.584095)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7800.0 MB
2025-08-27 02:03:24,638 - WARNING - Epoch [11/25] Step [41/250]  acc 0.280203 (0.253377)  loss 1.617535 (1.586263)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 02:03:29,306 - WARNING - Epoch [11/25] Step [51/250]  acc 0.227248 (0.248875)  loss 1.572005 (1.587943)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 7800.0 MB
2025-08-27 02:03:33,967 - WARNING - Epoch [11/25] Step [61/250]  acc 0.233176 (0.248669)  loss 1.584551 (1.590580)
GPU memory consumption  GPU Memory: Allocated: 52.7 MB, Reserved: 7800.0 MB
2025-08-27 02:03:38,645 - WARNING - Epoch [11/25] Step [71/250]  acc 0.298716 (0.249663)  loss 1.561921 (1.588161)
GPU memory consumption  GPU Memory: Allocated: 53.0 MB, Reserved: 7800.0 MB
2025-08-27 02:03:43,350 - WARNING - Epoch [11/25] Step [81/250]  acc 0.214544 (0.249235)  loss 1.623327 (1.589282)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:03:48,025 - WARNING - Epoch [11/25] Step [91/250]  acc 0.236797 (0.248426)  loss 1.600612 (1.590967)
GPU memory consumption  GPU Memory: Allocated: 52.8 MB, Reserved: 7800.0 MB
2025-08-27 02:03:52,741 - WARNING - Epoch [11/25] Step [101/250]  acc 0.265836 (0.249491)  loss 1.531331 (1.588310)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7800.0 MB
2025-08-27 02:03:57,424 - WARNING - Epoch [11/25] Step [111/250]  acc 0.251687 (0.249279)  loss 1.550653 (1.587708)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7800.0 MB
2025-08-27 02:04:02,116 - WARNING - Epoch [11/25] Step [121/250]  acc 0.256057 (0.248849)  loss 1.615736 (1.586171)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:04:06,761 - WARNING - Epoch [11/25] Step [131/250]  acc 0.221607 (0.248427)  loss 1.604138 (1.587777)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7800.0 MB
2025-08-27 02:04:11,474 - WARNING - Epoch [11/25] Step [141/250]  acc 0.269825 (0.248016)  loss 1.620507 (1.589860)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:04:16,126 - WARNING - Epoch [11/25] Step [151/250]  acc 0.268172 (0.248546)  loss 1.632275 (1.590568)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 7800.0 MB
2025-08-27 02:04:20,891 - WARNING - Epoch [11/25] Step [161/250]  acc 0.222222 (0.248667)  loss 1.620944 (1.589859)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 02:04:25,803 - WARNING - Epoch [11/25] Step [171/250]  acc 0.299051 (0.249240)  loss 1.499689 (1.588257)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7800.0 MB
2025-08-27 02:04:30,519 - WARNING - Epoch [11/25] Step [181/250]  acc 0.209561 (0.249288)  loss 1.656246 (1.589767)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 7800.0 MB
2025-08-27 02:04:35,176 - WARNING - Epoch [11/25] Step [191/250]  acc 0.265781 (0.249074)  loss 1.559293 (1.589319)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7800.0 MB
2025-08-27 02:04:39,885 - WARNING - Epoch [11/25] Step [201/250]  acc 0.249110 (0.248462)  loss 1.545582 (1.589561)
GPU memory consumption  GPU Memory: Allocated: 51.2 MB, Reserved: 7800.0 MB
2025-08-27 02:04:44,582 - WARNING - Epoch [11/25] Step [211/250]  acc 0.248038 (0.248489)  loss 1.601009 (1.590228)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7800.0 MB
2025-08-27 02:04:49,350 - WARNING - Epoch [11/25] Step [221/250]  acc 0.243863 (0.248771)  loss 1.580870 (1.589959)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 02:04:54,046 - WARNING - Epoch [11/25] Step [231/250]  acc 0.266913 (0.248886)  loss 1.665633 (1.589845)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7800.0 MB
2025-08-27 02:04:58,709 - WARNING - Epoch [11/25] Step [241/250]  acc 0.220711 (0.248819)  loss 1.562771 (1.589872)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7800.0 MB
Epoch 11 completed in 0:01:57.676358
2025-08-27 02:05:31,253 - WARNING - Epoch [12/25] Step [1/250]  acc 0.275243 (0.275243)  loss 1.533721 (1.533721)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:05:35,856 - WARNING - Epoch [12/25] Step [11/250]  acc 0.230093 (0.256102)  loss 1.642491 (1.599472)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 7800.0 MB
2025-08-27 02:05:40,432 - WARNING - Epoch [12/25] Step [21/250]  acc 0.226604 (0.256764)  loss 1.666110 (1.596786)
GPU memory consumption  GPU Memory: Allocated: 53.0 MB, Reserved: 7800.0 MB
2025-08-27 02:05:45,016 - WARNING - Epoch [12/25] Step [31/250]  acc 0.256871 (0.255787)  loss 1.550759 (1.593708)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 7800.0 MB
2025-08-27 02:05:49,674 - WARNING - Epoch [12/25] Step [41/250]  acc 0.205688 (0.253033)  loss 1.640840 (1.590306)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 02:05:54,281 - WARNING - Epoch [12/25] Step [51/250]  acc 0.226415 (0.250375)  loss 1.564354 (1.588206)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:05:58,868 - WARNING - Epoch [12/25] Step [61/250]  acc 0.266631 (0.250111)  loss 1.632913 (1.589714)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7800.0 MB
2025-08-27 02:06:03,471 - WARNING - Epoch [12/25] Step [71/250]  acc 0.244845 (0.250423)  loss 1.538637 (1.590841)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 02:06:08,301 - WARNING - Epoch [12/25] Step [81/250]  acc 0.226263 (0.249554)  loss 1.685866 (1.590252)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:06:12,924 - WARNING - Epoch [12/25] Step [91/250]  acc 0.272937 (0.250938)  loss 1.603914 (1.591786)
GPU memory consumption  GPU Memory: Allocated: 52.4 MB, Reserved: 7800.0 MB
2025-08-27 02:06:17,490 - WARNING - Epoch [12/25] Step [101/250]  acc 0.253492 (0.251453)  loss 1.606393 (1.591488)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7800.0 MB
2025-08-27 02:06:22,091 - WARNING - Epoch [12/25] Step [111/250]  acc 0.271534 (0.251445)  loss 1.597760 (1.590461)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7800.0 MB
2025-08-27 02:06:26,636 - WARNING - Epoch [12/25] Step [121/250]  acc 0.260196 (0.251691)  loss 1.589473 (1.590310)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:06:31,278 - WARNING - Epoch [12/25] Step [131/250]  acc 0.219058 (0.251219)  loss 1.593267 (1.588770)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 02:06:35,884 - WARNING - Epoch [12/25] Step [141/250]  acc 0.196342 (0.250909)  loss 1.625190 (1.588912)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7800.0 MB
2025-08-27 02:06:40,471 - WARNING - Epoch [12/25] Step [151/250]  acc 0.232821 (0.251476)  loss 1.564500 (1.588259)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:06:45,105 - WARNING - Epoch [12/25] Step [161/250]  acc 0.282209 (0.251297)  loss 1.532392 (1.587202)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 02:06:49,705 - WARNING - Epoch [12/25] Step [171/250]  acc 0.296158 (0.251486)  loss 1.540902 (1.587147)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7800.0 MB
2025-08-27 02:06:54,319 - WARNING - Epoch [12/25] Step [181/250]  acc 0.255467 (0.251212)  loss 1.601475 (1.587955)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
2025-08-27 02:06:58,935 - WARNING - Epoch [12/25] Step [191/250]  acc 0.246467 (0.250572)  loss 1.616534 (1.588626)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7800.0 MB
2025-08-27 02:07:03,542 - WARNING - Epoch [12/25] Step [201/250]  acc 0.271636 (0.250868)  loss 1.550671 (1.588466)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7800.0 MB
2025-08-27 02:07:08,119 - WARNING - Epoch [12/25] Step [211/250]  acc 0.220670 (0.250607)  loss 1.564780 (1.589014)
GPU memory consumption  GPU Memory: Allocated: 52.9 MB, Reserved: 7800.0 MB
2025-08-27 02:07:12,729 - WARNING - Epoch [12/25] Step [221/250]  acc 0.227666 (0.250579)  loss 1.582060 (1.589873)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7800.0 MB
2025-08-27 02:07:17,558 - WARNING - Epoch [12/25] Step [231/250]  acc 0.267970 (0.250832)  loss 1.560466 (1.589780)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7800.0 MB
2025-08-27 02:07:22,129 - WARNING - Epoch [12/25] Step [241/250]  acc 0.193319 (0.250526)  loss 1.654544 (1.590135)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7800.0 MB
Epoch 12 completed in 0:01:55.533660
2025-08-27 02:07:54,446 - WARNING - Epoch [13/25] Step [1/250]  acc 0.264017 (0.264017)  loss 1.611545 (1.611545)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:07:59,048 - WARNING - Epoch [13/25] Step [11/250]  acc 0.257778 (0.254605)  loss 1.592202 (1.592570)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:08:03,694 - WARNING - Epoch [13/25] Step [21/250]  acc 0.258359 (0.251460)  loss 1.602032 (1.595077)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:08:08,246 - WARNING - Epoch [13/25] Step [31/250]  acc 0.264722 (0.257603)  loss 1.602513 (1.591405)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 02:08:12,861 - WARNING - Epoch [13/25] Step [41/250]  acc 0.210680 (0.256266)  loss 1.582884 (1.585840)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 7800.0 MB
2025-08-27 02:08:17,439 - WARNING - Epoch [13/25] Step [51/250]  acc 0.268793 (0.258183)  loss 1.558077 (1.586608)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
2025-08-27 02:08:22,036 - WARNING - Epoch [13/25] Step [61/250]  acc 0.262942 (0.254770)  loss 1.595590 (1.587322)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:08:26,588 - WARNING - Epoch [13/25] Step [71/250]  acc 0.281053 (0.255303)  loss 1.656443 (1.588175)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7800.0 MB
2025-08-27 02:08:31,250 - WARNING - Epoch [13/25] Step [81/250]  acc 0.226502 (0.254535)  loss 1.551897 (1.588276)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:08:35,838 - WARNING - Epoch [13/25] Step [91/250]  acc 0.280354 (0.254702)  loss 1.598109 (1.587868)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 02:08:40,459 - WARNING - Epoch [13/25] Step [101/250]  acc 0.255848 (0.254454)  loss 1.567980 (1.587184)
GPU memory consumption  GPU Memory: Allocated: 61.4 MB, Reserved: 7800.0 MB
2025-08-27 02:08:45,080 - WARNING - Epoch [13/25] Step [111/250]  acc 0.255054 (0.254300)  loss 1.618500 (1.586699)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7800.0 MB
2025-08-27 02:08:49,653 - WARNING - Epoch [13/25] Step [121/250]  acc 0.284073 (0.254163)  loss 1.559152 (1.585900)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:08:54,443 - WARNING - Epoch [13/25] Step [131/250]  acc 0.273008 (0.254202)  loss 1.557815 (1.586893)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:08:59,066 - WARNING - Epoch [13/25] Step [141/250]  acc 0.265810 (0.253885)  loss 1.607132 (1.588068)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 7800.0 MB
2025-08-27 02:09:03,689 - WARNING - Epoch [13/25] Step [151/250]  acc 0.286702 (0.254496)  loss 1.576987 (1.587307)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 02:09:08,255 - WARNING - Epoch [13/25] Step [161/250]  acc 0.235387 (0.254374)  loss 1.585311 (1.587845)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
2025-08-27 02:09:12,897 - WARNING - Epoch [13/25] Step [171/250]  acc 0.288672 (0.253845)  loss 1.586459 (1.588318)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 7800.0 MB
2025-08-27 02:09:17,535 - WARNING - Epoch [13/25] Step [181/250]  acc 0.238503 (0.253582)  loss 1.567587 (1.588640)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 02:09:22,159 - WARNING - Epoch [13/25] Step [191/250]  acc 0.257300 (0.254151)  loss 1.602559 (1.587768)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7800.0 MB
2025-08-27 02:09:26,742 - WARNING - Epoch [13/25] Step [201/250]  acc 0.254144 (0.253973)  loss 1.567692 (1.587933)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
2025-08-27 02:09:31,357 - WARNING - Epoch [13/25] Step [211/250]  acc 0.249373 (0.253755)  loss 1.582685 (1.587582)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7800.0 MB
2025-08-27 02:09:35,979 - WARNING - Epoch [13/25] Step [221/250]  acc 0.223141 (0.253640)  loss 1.599321 (1.588494)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7800.0 MB
2025-08-27 02:09:40,521 - WARNING - Epoch [13/25] Step [231/250]  acc 0.272109 (0.253582)  loss 1.523095 (1.587869)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7800.0 MB
2025-08-27 02:09:45,159 - WARNING - Epoch [13/25] Step [241/250]  acc 0.289224 (0.253766)  loss 1.591197 (1.588233)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7800.0 MB
Epoch 13 completed in 0:01:55.319187
2025-08-27 02:10:17,656 - WARNING - Epoch [14/25] Step [1/250]  acc 0.258973 (0.258973)  loss 1.591629 (1.591629)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 7800.0 MB
2025-08-27 02:10:22,224 - WARNING - Epoch [14/25] Step [11/250]  acc 0.273882 (0.258518)  loss 1.604652 (1.598012)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 7800.0 MB
2025-08-27 02:10:26,870 - WARNING - Epoch [14/25] Step [21/250]  acc 0.247514 (0.258180)  loss 1.633023 (1.596117)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 02:10:31,500 - WARNING - Epoch [14/25] Step [31/250]  acc 0.261364 (0.255992)  loss 1.604787 (1.595903)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 02:10:36,258 - WARNING - Epoch [14/25] Step [41/250]  acc 0.297884 (0.259088)  loss 1.540761 (1.592531)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 02:10:40,942 - WARNING - Epoch [14/25] Step [51/250]  acc 0.254873 (0.257807)  loss 1.592949 (1.589458)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 7800.0 MB
2025-08-27 02:10:45,544 - WARNING - Epoch [14/25] Step [61/250]  acc 0.270231 (0.257887)  loss 1.606904 (1.591274)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:10:50,125 - WARNING - Epoch [14/25] Step [71/250]  acc 0.302116 (0.256029)  loss 1.537071 (1.591253)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7800.0 MB
2025-08-27 02:10:54,665 - WARNING - Epoch [14/25] Step [81/250]  acc 0.289709 (0.255682)  loss 1.546179 (1.591554)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7800.0 MB
2025-08-27 02:10:59,220 - WARNING - Epoch [14/25] Step [91/250]  acc 0.220468 (0.257032)  loss 1.580928 (1.590911)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 7800.0 MB
2025-08-27 02:11:03,735 - WARNING - Epoch [14/25] Step [101/250]  acc 0.233650 (0.256957)  loss 1.571950 (1.590003)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 7800.0 MB
2025-08-27 02:11:08,268 - WARNING - Epoch [14/25] Step [111/250]  acc 0.259084 (0.256380)  loss 1.625187 (1.589194)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:11:12,740 - WARNING - Epoch [14/25] Step [121/250]  acc 0.248819 (0.256349)  loss 1.558636 (1.587577)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:11:17,191 - WARNING - Epoch [14/25] Step [131/250]  acc 0.207965 (0.255873)  loss 1.626162 (1.587777)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7800.0 MB
2025-08-27 02:11:21,701 - WARNING - Epoch [14/25] Step [141/250]  acc 0.240065 (0.254470)  loss 1.571284 (1.588293)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7800.0 MB
2025-08-27 02:11:26,172 - WARNING - Epoch [14/25] Step [151/250]  acc 0.285539 (0.254516)  loss 1.590807 (1.588034)
GPU memory consumption  GPU Memory: Allocated: 51.7 MB, Reserved: 7800.0 MB
2025-08-27 02:11:30,603 - WARNING - Epoch [14/25] Step [161/250]  acc 0.241860 (0.254332)  loss 1.554001 (1.588314)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 02:11:35,065 - WARNING - Epoch [14/25] Step [171/250]  acc 0.293229 (0.254765)  loss 1.538823 (1.588267)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7800.0 MB
2025-08-27 02:11:39,553 - WARNING - Epoch [14/25] Step [181/250]  acc 0.266350 (0.254688)  loss 1.591043 (1.586751)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 02:11:44,241 - WARNING - Epoch [14/25] Step [191/250]  acc 0.259774 (0.253901)  loss 1.539430 (1.587274)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7800.0 MB
2025-08-27 02:11:48,679 - WARNING - Epoch [14/25] Step [201/250]  acc 0.237888 (0.253345)  loss 1.586312 (1.587718)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 7800.0 MB
2025-08-27 02:11:53,114 - WARNING - Epoch [14/25] Step [211/250]  acc 0.274277 (0.253522)  loss 1.559205 (1.586902)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7800.0 MB
2025-08-27 02:11:57,579 - WARNING - Epoch [14/25] Step [221/250]  acc 0.296029 (0.253412)  loss 1.544905 (1.587310)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 02:12:02,076 - WARNING - Epoch [14/25] Step [231/250]  acc 0.238677 (0.253180)  loss 1.621983 (1.588130)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7800.0 MB
2025-08-27 02:12:06,513 - WARNING - Epoch [14/25] Step [241/250]  acc 0.229482 (0.253656)  loss 1.591329 (1.588131)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
Epoch 14 completed in 0:01:53.350521
2025-08-27 02:12:37,982 - WARNING - Epoch [15/25] Step [1/250]  acc 0.294118 (0.294118)  loss 1.530434 (1.530434)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:12:42,491 - WARNING - Epoch [15/25] Step [11/250]  acc 0.273057 (0.254729)  loss 1.602674 (1.582437)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:12:46,923 - WARNING - Epoch [15/25] Step [21/250]  acc 0.243084 (0.251057)  loss 1.577462 (1.585087)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 7800.0 MB
2025-08-27 02:12:51,398 - WARNING - Epoch [15/25] Step [31/250]  acc 0.238695 (0.255128)  loss 1.628655 (1.585296)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7800.0 MB
2025-08-27 02:12:55,936 - WARNING - Epoch [15/25] Step [41/250]  acc 0.289278 (0.256519)  loss 1.579815 (1.583559)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:13:00,408 - WARNING - Epoch [15/25] Step [51/250]  acc 0.293207 (0.257374)  loss 1.602259 (1.584263)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 7800.0 MB
2025-08-27 02:13:04,880 - WARNING - Epoch [15/25] Step [61/250]  acc 0.253505 (0.257446)  loss 1.541909 (1.585317)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 7800.0 MB
2025-08-27 02:13:09,355 - WARNING - Epoch [15/25] Step [71/250]  acc 0.218875 (0.257644)  loss 1.582220 (1.585513)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7800.0 MB
2025-08-27 02:13:13,798 - WARNING - Epoch [15/25] Step [81/250]  acc 0.218621 (0.255944)  loss 1.581961 (1.586273)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:13:18,259 - WARNING - Epoch [15/25] Step [91/250]  acc 0.314212 (0.257149)  loss 1.586392 (1.587004)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 02:13:22,929 - WARNING - Epoch [15/25] Step [101/250]  acc 0.255647 (0.257516)  loss 1.568909 (1.587091)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 7800.0 MB
2025-08-27 02:13:27,437 - WARNING - Epoch [15/25] Step [111/250]  acc 0.221169 (0.256859)  loss 1.596726 (1.586226)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 02:13:31,901 - WARNING - Epoch [15/25] Step [121/250]  acc 0.235354 (0.256032)  loss 1.623034 (1.587805)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:13:36,345 - WARNING - Epoch [15/25] Step [131/250]  acc 0.261003 (0.255416)  loss 1.546677 (1.587743)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:13:40,821 - WARNING - Epoch [15/25] Step [141/250]  acc 0.261257 (0.255560)  loss 1.523696 (1.587881)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:13:45,256 - WARNING - Epoch [15/25] Step [151/250]  acc 0.260163 (0.256503)  loss 1.591049 (1.586754)
GPU memory consumption  GPU Memory: Allocated: 52.9 MB, Reserved: 7800.0 MB
2025-08-27 02:13:49,765 - WARNING - Epoch [15/25] Step [161/250]  acc 0.298907 (0.256869)  loss 1.530768 (1.586611)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 7800.0 MB
2025-08-27 02:13:54,188 - WARNING - Epoch [15/25] Step [171/250]  acc 0.234683 (0.256514)  loss 1.597666 (1.587211)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7800.0 MB
2025-08-27 02:13:58,644 - WARNING - Epoch [15/25] Step [181/250]  acc 0.237125 (0.256222)  loss 1.590687 (1.587259)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7800.0 MB
2025-08-27 02:14:03,102 - WARNING - Epoch [15/25] Step [191/250]  acc 0.297344 (0.256105)  loss 1.590472 (1.587976)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 7800.0 MB
2025-08-27 02:14:07,547 - WARNING - Epoch [15/25] Step [201/250]  acc 0.222278 (0.255954)  loss 1.583358 (1.587329)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
2025-08-27 02:14:12,012 - WARNING - Epoch [15/25] Step [211/250]  acc 0.239037 (0.255443)  loss 1.592641 (1.587458)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 7800.0 MB
2025-08-27 02:14:16,513 - WARNING - Epoch [15/25] Step [221/250]  acc 0.278475 (0.255386)  loss 1.609841 (1.587521)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 02:14:21,009 - WARNING - Epoch [15/25] Step [231/250]  acc 0.216299 (0.255199)  loss 1.588455 (1.587231)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7800.0 MB
2025-08-27 02:14:25,476 - WARNING - Epoch [15/25] Step [241/250]  acc 0.278400 (0.255403)  loss 1.571649 (1.586849)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7800.0 MB
Epoch 15 completed in 0:01:52.189125
2025-08-27 02:14:57,171 - WARNING - Epoch [16/25] Step [1/250]  acc 0.244212 (0.244212)  loss 1.600053 (1.600053)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 7800.0 MB
2025-08-27 02:15:01,691 - WARNING - Epoch [16/25] Step [11/250]  acc 0.230455 (0.240956)  loss 1.601621 (1.595335)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:15:06,272 - WARNING - Epoch [16/25] Step [21/250]  acc 0.223485 (0.240535)  loss 1.667036 (1.598479)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
2025-08-27 02:15:10,843 - WARNING - Epoch [16/25] Step [31/250]  acc 0.267876 (0.248149)  loss 1.581396 (1.593084)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7800.0 MB
2025-08-27 02:15:15,383 - WARNING - Epoch [16/25] Step [41/250]  acc 0.236624 (0.246433)  loss 1.562123 (1.595704)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
2025-08-27 02:15:19,852 - WARNING - Epoch [16/25] Step [51/250]  acc 0.250887 (0.247277)  loss 1.573479 (1.594578)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:15:24,361 - WARNING - Epoch [16/25] Step [61/250]  acc 0.231481 (0.247800)  loss 1.612038 (1.595097)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:15:28,850 - WARNING - Epoch [16/25] Step [71/250]  acc 0.302526 (0.249547)  loss 1.560401 (1.595854)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7800.0 MB
2025-08-27 02:15:33,366 - WARNING - Epoch [16/25] Step [81/250]  acc 0.260481 (0.249916)  loss 1.568820 (1.593771)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7800.0 MB
2025-08-27 02:15:37,853 - WARNING - Epoch [16/25] Step [91/250]  acc 0.249857 (0.250878)  loss 1.633361 (1.591879)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 7800.0 MB
2025-08-27 02:15:42,348 - WARNING - Epoch [16/25] Step [101/250]  acc 0.236515 (0.251750)  loss 1.567943 (1.591118)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7800.0 MB
2025-08-27 02:15:46,821 - WARNING - Epoch [16/25] Step [111/250]  acc 0.207911 (0.252944)  loss 1.608048 (1.590036)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7800.0 MB
2025-08-27 02:15:51,291 - WARNING - Epoch [16/25] Step [121/250]  acc 0.264547 (0.254035)  loss 1.561398 (1.588314)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 7800.0 MB
2025-08-27 02:15:55,759 - WARNING - Epoch [16/25] Step [131/250]  acc 0.245699 (0.254627)  loss 1.582728 (1.587159)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7800.0 MB
2025-08-27 02:16:00,255 - WARNING - Epoch [16/25] Step [141/250]  acc 0.211420 (0.254360)  loss 1.551467 (1.585908)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:16:04,947 - WARNING - Epoch [16/25] Step [151/250]  acc 0.267998 (0.254314)  loss 1.542250 (1.586098)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
2025-08-27 02:16:09,457 - WARNING - Epoch [16/25] Step [161/250]  acc 0.261538 (0.254130)  loss 1.557092 (1.585481)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7800.0 MB
2025-08-27 02:16:13,998 - WARNING - Epoch [16/25] Step [171/250]  acc 0.211153 (0.253380)  loss 1.678737 (1.587002)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7800.0 MB
2025-08-27 02:16:18,504 - WARNING - Epoch [16/25] Step [181/250]  acc 0.217593 (0.253679)  loss 1.585970 (1.587376)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:16:23,000 - WARNING - Epoch [16/25] Step [191/250]  acc 0.225464 (0.254500)  loss 1.579366 (1.586758)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 02:16:27,467 - WARNING - Epoch [16/25] Step [201/250]  acc 0.238987 (0.254336)  loss 1.570030 (1.587147)
GPU memory consumption  GPU Memory: Allocated: 52.8 MB, Reserved: 7800.0 MB
2025-08-27 02:16:31,975 - WARNING - Epoch [16/25] Step [211/250]  acc 0.274683 (0.253460)  loss 1.601853 (1.587393)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 7800.0 MB
2025-08-27 02:16:36,449 - WARNING - Epoch [16/25] Step [221/250]  acc 0.253960 (0.253711)  loss 1.594329 (1.587212)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 7800.0 MB
2025-08-27 02:16:40,934 - WARNING - Epoch [16/25] Step [231/250]  acc 0.282095 (0.253982)  loss 1.576962 (1.587076)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7800.0 MB
2025-08-27 02:16:45,490 - WARNING - Epoch [16/25] Step [241/250]  acc 0.256661 (0.254203)  loss 1.625643 (1.586966)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
Epoch 16 completed in 0:01:52.821673
2025-08-27 02:17:17,025 - WARNING - Epoch [17/25] Step [1/250]  acc 0.272170 (0.272170)  loss 1.554634 (1.554634)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7800.0 MB
2025-08-27 02:17:21,535 - WARNING - Epoch [17/25] Step [11/250]  acc 0.245355 (0.255169)  loss 1.566918 (1.591880)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 7800.0 MB
2025-08-27 02:17:25,960 - WARNING - Epoch [17/25] Step [21/250]  acc 0.243410 (0.252888)  loss 1.632338 (1.597005)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7800.0 MB
2025-08-27 02:17:30,474 - WARNING - Epoch [17/25] Step [31/250]  acc 0.239070 (0.247293)  loss 1.535156 (1.593932)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 02:17:35,108 - WARNING - Epoch [17/25] Step [41/250]  acc 0.257277 (0.250737)  loss 1.613908 (1.589728)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 02:17:39,941 - WARNING - Epoch [17/25] Step [51/250]  acc 0.278630 (0.250753)  loss 1.580621 (1.586814)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:17:44,602 - WARNING - Epoch [17/25] Step [61/250]  acc 0.298886 (0.252839)  loss 1.544042 (1.585163)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:17:49,353 - WARNING - Epoch [17/25] Step [71/250]  acc 0.243414 (0.254785)  loss 1.590826 (1.584975)
GPU memory consumption  GPU Memory: Allocated: 52.6 MB, Reserved: 7800.0 MB
2025-08-27 02:17:53,861 - WARNING - Epoch [17/25] Step [81/250]  acc 0.273396 (0.253239)  loss 1.580335 (1.586208)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:17:58,359 - WARNING - Epoch [17/25] Step [91/250]  acc 0.233985 (0.254691)  loss 1.567741 (1.585736)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7800.0 MB
2025-08-27 02:18:02,918 - WARNING - Epoch [17/25] Step [101/250]  acc 0.258140 (0.254325)  loss 1.580263 (1.585884)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7800.0 MB
2025-08-27 02:18:07,416 - WARNING - Epoch [17/25] Step [111/250]  acc 0.248215 (0.254552)  loss 1.605359 (1.586495)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7800.0 MB
2025-08-27 02:18:11,974 - WARNING - Epoch [17/25] Step [121/250]  acc 0.260606 (0.254902)  loss 1.591945 (1.584911)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:18:16,520 - WARNING - Epoch [17/25] Step [131/250]  acc 0.221925 (0.254695)  loss 1.605808 (1.584804)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
2025-08-27 02:18:21,021 - WARNING - Epoch [17/25] Step [141/250]  acc 0.297283 (0.255192)  loss 1.522650 (1.584176)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 02:18:25,515 - WARNING - Epoch [17/25] Step [151/250]  acc 0.269211 (0.255035)  loss 1.553154 (1.583893)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
2025-08-27 02:18:29,979 - WARNING - Epoch [17/25] Step [161/250]  acc 0.232296 (0.254875)  loss 1.555477 (1.583942)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7800.0 MB
2025-08-27 02:18:34,508 - WARNING - Epoch [17/25] Step [171/250]  acc 0.262335 (0.254730)  loss 1.581610 (1.584055)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 7800.0 MB
2025-08-27 02:18:39,022 - WARNING - Epoch [17/25] Step [181/250]  acc 0.253731 (0.254912)  loss 1.570378 (1.583451)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:18:43,492 - WARNING - Epoch [17/25] Step [191/250]  acc 0.288098 (0.254819)  loss 1.594831 (1.584427)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7800.0 MB
2025-08-27 02:18:47,946 - WARNING - Epoch [17/25] Step [201/250]  acc 0.252118 (0.254902)  loss 1.580996 (1.585075)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7800.0 MB
2025-08-27 02:18:52,650 - WARNING - Epoch [17/25] Step [211/250]  acc 0.212789 (0.254324)  loss 1.558668 (1.584724)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7800.0 MB
2025-08-27 02:18:57,141 - WARNING - Epoch [17/25] Step [221/250]  acc 0.238025 (0.254471)  loss 1.620888 (1.584851)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 7800.0 MB
2025-08-27 02:19:01,649 - WARNING - Epoch [17/25] Step [231/250]  acc 0.211238 (0.253912)  loss 1.617410 (1.585413)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7800.0 MB
2025-08-27 02:19:06,187 - WARNING - Epoch [17/25] Step [241/250]  acc 0.262933 (0.253713)  loss 1.657800 (1.585779)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7800.0 MB
Epoch 17 completed in 0:01:53.703808
2025-08-27 02:19:37,725 - WARNING - Epoch [18/25] Step [1/250]  acc 0.196739 (0.196739)  loss 1.611246 (1.611246)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7800.0 MB
2025-08-27 02:19:42,152 - WARNING - Epoch [18/25] Step [11/250]  acc 0.217712 (0.236110)  loss 1.603019 (1.598211)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7800.0 MB
2025-08-27 02:19:46,641 - WARNING - Epoch [18/25] Step [21/250]  acc 0.249053 (0.246301)  loss 1.535081 (1.587271)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
2025-08-27 02:19:51,107 - WARNING - Epoch [18/25] Step [31/250]  acc 0.255775 (0.252113)  loss 1.627270 (1.591095)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7800.0 MB
2025-08-27 02:19:55,631 - WARNING - Epoch [18/25] Step [41/250]  acc 0.256291 (0.250476)  loss 1.609317 (1.593276)
GPU memory consumption  GPU Memory: Allocated: 61.1 MB, Reserved: 7800.0 MB
2025-08-27 02:20:00,107 - WARNING - Epoch [18/25] Step [51/250]  acc 0.267568 (0.252448)  loss 1.545390 (1.594165)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 02:20:04,603 - WARNING - Epoch [18/25] Step [61/250]  acc 0.252286 (0.252493)  loss 1.576187 (1.590302)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7800.0 MB
2025-08-27 02:20:09,109 - WARNING - Epoch [18/25] Step [71/250]  acc 0.242007 (0.252807)  loss 1.629214 (1.592570)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 7800.0 MB
2025-08-27 02:20:13,609 - WARNING - Epoch [18/25] Step [81/250]  acc 0.228555 (0.251027)  loss 1.631839 (1.596969)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7800.0 MB
2025-08-27 02:20:18,075 - WARNING - Epoch [18/25] Step [91/250]  acc 0.258271 (0.251064)  loss 1.565299 (1.596985)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 7800.0 MB
2025-08-27 02:20:22,576 - WARNING - Epoch [18/25] Step [101/250]  acc 0.264120 (0.251399)  loss 1.582071 (1.596383)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 7800.0 MB
2025-08-27 02:20:27,299 - WARNING - Epoch [18/25] Step [111/250]  acc 0.236886 (0.250420)  loss 1.602489 (1.595995)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 02:20:31,843 - WARNING - Epoch [18/25] Step [121/250]  acc 0.248731 (0.250909)  loss 1.529389 (1.595326)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:20:36,321 - WARNING - Epoch [18/25] Step [131/250]  acc 0.251082 (0.251165)  loss 1.616372 (1.594944)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7800.0 MB
2025-08-27 02:20:40,801 - WARNING - Epoch [18/25] Step [141/250]  acc 0.241927 (0.251012)  loss 1.564482 (1.594313)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 02:20:45,287 - WARNING - Epoch [18/25] Step [151/250]  acc 0.272681 (0.250059)  loss 1.551160 (1.593952)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 7800.0 MB
2025-08-27 02:20:49,794 - WARNING - Epoch [18/25] Step [161/250]  acc 0.254662 (0.250005)  loss 1.564659 (1.593177)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7800.0 MB
2025-08-27 02:20:54,274 - WARNING - Epoch [18/25] Step [171/250]  acc 0.268720 (0.250673)  loss 1.592155 (1.592265)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 02:20:58,775 - WARNING - Epoch [18/25] Step [181/250]  acc 0.261400 (0.250941)  loss 1.555964 (1.591954)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7800.0 MB
2025-08-27 02:21:03,274 - WARNING - Epoch [18/25] Step [191/250]  acc 0.241752 (0.250714)  loss 1.578115 (1.591970)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7800.0 MB
2025-08-27 02:21:07,751 - WARNING - Epoch [18/25] Step [201/250]  acc 0.218269 (0.250667)  loss 1.590729 (1.591454)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7800.0 MB
2025-08-27 02:21:12,208 - WARNING - Epoch [18/25] Step [211/250]  acc 0.245158 (0.251273)  loss 1.636081 (1.591045)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 7800.0 MB
2025-08-27 02:21:16,733 - WARNING - Epoch [18/25] Step [221/250]  acc 0.301020 (0.251868)  loss 1.567951 (1.590076)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 02:21:21,244 - WARNING - Epoch [18/25] Step [231/250]  acc 0.239307 (0.251614)  loss 1.590575 (1.589972)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 02:21:25,663 - WARNING - Epoch [18/25] Step [241/250]  acc 0.248139 (0.252099)  loss 1.674259 (1.589977)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7800.0 MB
Epoch 18 completed in 0:01:52.335816
2025-08-27 02:21:57,124 - WARNING - Epoch [19/25] Step [1/250]  acc 0.210423 (0.210423)  loss 1.600756 (1.600756)
GPU memory consumption  GPU Memory: Allocated: 59.6 MB, Reserved: 7800.0 MB
2025-08-27 02:22:01,769 - WARNING - Epoch [19/25] Step [11/250]  acc 0.293706 (0.254230)  loss 1.661208 (1.588065)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7800.0 MB
2025-08-27 02:22:06,264 - WARNING - Epoch [19/25] Step [21/250]  acc 0.228023 (0.261007)  loss 1.604193 (1.587104)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7800.0 MB
2025-08-27 02:22:10,765 - WARNING - Epoch [19/25] Step [31/250]  acc 0.291496 (0.258675)  loss 1.580941 (1.581771)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7800.0 MB
2025-08-27 02:22:15,240 - WARNING - Epoch [19/25] Step [41/250]  acc 0.284952 (0.260741)  loss 1.562467 (1.579118)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7800.0 MB
2025-08-27 02:22:19,734 - WARNING - Epoch [19/25] Step [51/250]  acc 0.207000 (0.257933)  loss 1.639718 (1.578195)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 7800.0 MB
2025-08-27 02:22:24,231 - WARNING - Epoch [19/25] Step [61/250]  acc 0.236705 (0.256926)  loss 1.569850 (1.578019)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:22:28,678 - WARNING - Epoch [19/25] Step [71/250]  acc 0.263601 (0.258060)  loss 1.588707 (1.580197)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 7800.0 MB
2025-08-27 02:22:33,209 - WARNING - Epoch [19/25] Step [81/250]  acc 0.218277 (0.257943)  loss 1.614400 (1.580237)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7800.0 MB
2025-08-27 02:22:37,710 - WARNING - Epoch [19/25] Step [91/250]  acc 0.254350 (0.256574)  loss 1.538930 (1.578369)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 02:22:42,185 - WARNING - Epoch [19/25] Step [101/250]  acc 0.265119 (0.257470)  loss 1.558521 (1.577672)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7800.0 MB
2025-08-27 02:22:46,698 - WARNING - Epoch [19/25] Step [111/250]  acc 0.272548 (0.257566)  loss 1.528480 (1.577656)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 7800.0 MB
2025-08-27 02:22:51,194 - WARNING - Epoch [19/25] Step [121/250]  acc 0.269474 (0.257586)  loss 1.559892 (1.578655)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7800.0 MB
2025-08-27 02:22:55,730 - WARNING - Epoch [19/25] Step [131/250]  acc 0.253784 (0.258088)  loss 1.543597 (1.578212)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 02:23:00,240 - WARNING - Epoch [19/25] Step [141/250]  acc 0.280412 (0.257510)  loss 1.563734 (1.578289)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:23:04,678 - WARNING - Epoch [19/25] Step [151/250]  acc 0.276696 (0.257307)  loss 1.628741 (1.578879)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
2025-08-27 02:23:09,165 - WARNING - Epoch [19/25] Step [161/250]  acc 0.217827 (0.256556)  loss 1.633155 (1.580484)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 7800.0 MB
2025-08-27 02:23:13,889 - WARNING - Epoch [19/25] Step [171/250]  acc 0.276356 (0.256386)  loss 1.608947 (1.580749)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 02:23:18,380 - WARNING - Epoch [19/25] Step [181/250]  acc 0.247227 (0.256170)  loss 1.567682 (1.580269)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7800.0 MB
2025-08-27 02:23:22,866 - WARNING - Epoch [19/25] Step [191/250]  acc 0.196206 (0.255154)  loss 1.689135 (1.581537)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 02:23:27,328 - WARNING - Epoch [19/25] Step [201/250]  acc 0.248175 (0.254994)  loss 1.637827 (1.582114)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 02:23:31,798 - WARNING - Epoch [19/25] Step [211/250]  acc 0.277249 (0.255330)  loss 1.542732 (1.582043)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7800.0 MB
2025-08-27 02:23:36,264 - WARNING - Epoch [19/25] Step [221/250]  acc 0.270788 (0.254928)  loss 1.505977 (1.581839)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7800.0 MB
2025-08-27 02:23:40,774 - WARNING - Epoch [19/25] Step [231/250]  acc 0.266055 (0.254668)  loss 1.631498 (1.581965)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
2025-08-27 02:23:45,286 - WARNING - Epoch [19/25] Step [241/250]  acc 0.251872 (0.254461)  loss 1.650752 (1.582884)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7800.0 MB
Epoch 19 completed in 0:01:52.701475
2025-08-27 02:24:16,982 - WARNING - Epoch [20/25] Step [1/250]  acc 0.281250 (0.281250)  loss 1.560561 (1.560561)
GPU memory consumption  GPU Memory: Allocated: 62.0 MB, Reserved: 7800.0 MB
2025-08-27 02:24:21,470 - WARNING - Epoch [20/25] Step [11/250]  acc 0.293753 (0.267689)  loss 1.504514 (1.583014)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:24:25,955 - WARNING - Epoch [20/25] Step [21/250]  acc 0.268412 (0.262904)  loss 1.586680 (1.585063)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7800.0 MB
2025-08-27 02:24:30,513 - WARNING - Epoch [20/25] Step [31/250]  acc 0.227501 (0.261534)  loss 1.659693 (1.582406)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7800.0 MB
2025-08-27 02:24:35,065 - WARNING - Epoch [20/25] Step [41/250]  acc 0.215196 (0.255003)  loss 1.585556 (1.582585)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 02:24:39,707 - WARNING - Epoch [20/25] Step [51/250]  acc 0.215190 (0.252739)  loss 1.625239 (1.585533)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 02:24:44,268 - WARNING - Epoch [20/25] Step [61/250]  acc 0.272243 (0.253687)  loss 1.575528 (1.585194)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7800.0 MB
2025-08-27 02:24:48,966 - WARNING - Epoch [20/25] Step [71/250]  acc 0.239958 (0.254890)  loss 1.571311 (1.582624)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 02:24:53,525 - WARNING - Epoch [20/25] Step [81/250]  acc 0.233613 (0.252977)  loss 1.626197 (1.584469)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 02:24:58,112 - WARNING - Epoch [20/25] Step [91/250]  acc 0.224818 (0.251668)  loss 1.551307 (1.583421)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 02:25:02,801 - WARNING - Epoch [20/25] Step [101/250]  acc 0.266808 (0.251579)  loss 1.606711 (1.583559)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7800.0 MB
2025-08-27 02:25:07,362 - WARNING - Epoch [20/25] Step [111/250]  acc 0.245736 (0.251533)  loss 1.617971 (1.583981)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:25:12,003 - WARNING - Epoch [20/25] Step [121/250]  acc 0.273828 (0.252356)  loss 1.566947 (1.582747)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 02:25:16,586 - WARNING - Epoch [20/25] Step [131/250]  acc 0.245641 (0.252303)  loss 1.591784 (1.581432)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:25:21,138 - WARNING - Epoch [20/25] Step [141/250]  acc 0.222457 (0.251276)  loss 1.609616 (1.583013)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7800.0 MB
2025-08-27 02:25:25,690 - WARNING - Epoch [20/25] Step [151/250]  acc 0.257370 (0.251744)  loss 1.595171 (1.582762)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 7800.0 MB
2025-08-27 02:25:30,283 - WARNING - Epoch [20/25] Step [161/250]  acc 0.250000 (0.251342)  loss 1.535457 (1.581735)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
2025-08-27 02:25:34,849 - WARNING - Epoch [20/25] Step [171/250]  acc 0.202843 (0.251315)  loss 1.661575 (1.581807)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7800.0 MB
2025-08-27 02:25:39,506 - WARNING - Epoch [20/25] Step [181/250]  acc 0.244875 (0.251744)  loss 1.547068 (1.581101)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 02:25:44,061 - WARNING - Epoch [20/25] Step [191/250]  acc 0.226436 (0.251650)  loss 1.644651 (1.581450)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7800.0 MB
2025-08-27 02:25:48,624 - WARNING - Epoch [20/25] Step [201/250]  acc 0.236542 (0.252365)  loss 1.618850 (1.581315)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 7800.0 MB
2025-08-27 02:25:53,161 - WARNING - Epoch [20/25] Step [211/250]  acc 0.224652 (0.252138)  loss 1.584952 (1.581990)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7800.0 MB
2025-08-27 02:25:57,677 - WARNING - Epoch [20/25] Step [221/250]  acc 0.246369 (0.252656)  loss 1.568801 (1.582338)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 02:26:02,414 - WARNING - Epoch [20/25] Step [231/250]  acc 0.231220 (0.253061)  loss 1.604855 (1.582908)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7800.0 MB
2025-08-27 02:26:06,951 - WARNING - Epoch [20/25] Step [241/250]  acc 0.239894 (0.253390)  loss 1.601536 (1.583223)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
Epoch 20 completed in 0:01:54.554862
2025-08-27 02:26:39,039 - WARNING - Epoch [21/25] Step [1/250]  acc 0.207519 (0.207519)  loss 1.590826 (1.590826)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 7800.0 MB
2025-08-27 02:26:43,602 - WARNING - Epoch [21/25] Step [11/250]  acc 0.255912 (0.251263)  loss 1.575202 (1.594748)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 02:26:48,145 - WARNING - Epoch [21/25] Step [21/250]  acc 0.212121 (0.246447)  loss 1.607419 (1.590002)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7800.0 MB
2025-08-27 02:26:52,643 - WARNING - Epoch [21/25] Step [31/250]  acc 0.245699 (0.247982)  loss 1.545432 (1.586658)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7800.0 MB
2025-08-27 02:26:57,167 - WARNING - Epoch [21/25] Step [41/250]  acc 0.288901 (0.249548)  loss 1.527640 (1.586630)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 02:27:01,717 - WARNING - Epoch [21/25] Step [51/250]  acc 0.272589 (0.249540)  loss 1.559426 (1.589248)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:27:06,170 - WARNING - Epoch [21/25] Step [61/250]  acc 0.250262 (0.249571)  loss 1.589359 (1.589752)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:27:10,632 - WARNING - Epoch [21/25] Step [71/250]  acc 0.232421 (0.249598)  loss 1.590061 (1.587984)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 7800.0 MB
2025-08-27 02:27:15,139 - WARNING - Epoch [21/25] Step [81/250]  acc 0.306081 (0.251057)  loss 1.562267 (1.588276)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:27:19,623 - WARNING - Epoch [21/25] Step [91/250]  acc 0.271762 (0.251667)  loss 1.560776 (1.587272)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7800.0 MB
2025-08-27 02:27:24,096 - WARNING - Epoch [21/25] Step [101/250]  acc 0.247925 (0.252406)  loss 1.567668 (1.585720)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7800.0 MB
2025-08-27 02:27:28,562 - WARNING - Epoch [21/25] Step [111/250]  acc 0.298868 (0.253588)  loss 1.588319 (1.583802)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7800.0 MB
2025-08-27 02:27:33,019 - WARNING - Epoch [21/25] Step [121/250]  acc 0.262480 (0.254535)  loss 1.575124 (1.583510)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 02:27:37,670 - WARNING - Epoch [21/25] Step [131/250]  acc 0.245781 (0.255212)  loss 1.626886 (1.583557)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7800.0 MB
2025-08-27 02:27:42,160 - WARNING - Epoch [21/25] Step [141/250]  acc 0.239119 (0.254150)  loss 1.538908 (1.584167)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:27:46,661 - WARNING - Epoch [21/25] Step [151/250]  acc 0.275287 (0.255069)  loss 1.576580 (1.583477)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 7800.0 MB
2025-08-27 02:27:51,100 - WARNING - Epoch [21/25] Step [161/250]  acc 0.252187 (0.254800)  loss 1.573592 (1.584011)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 02:27:55,544 - WARNING - Epoch [21/25] Step [171/250]  acc 0.235326 (0.254476)  loss 1.558962 (1.583842)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7800.0 MB
2025-08-27 02:28:00,045 - WARNING - Epoch [21/25] Step [181/250]  acc 0.261828 (0.255198)  loss 1.572794 (1.582476)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7800.0 MB
2025-08-27 02:28:04,551 - WARNING - Epoch [21/25] Step [191/250]  acc 0.267389 (0.254941)  loss 1.530225 (1.582873)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7800.0 MB
2025-08-27 02:28:09,054 - WARNING - Epoch [21/25] Step [201/250]  acc 0.262146 (0.255162)  loss 1.569563 (1.582377)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 7800.0 MB
2025-08-27 02:28:13,538 - WARNING - Epoch [21/25] Step [211/250]  acc 0.273791 (0.254973)  loss 1.584294 (1.582630)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7800.0 MB
2025-08-27 02:28:18,122 - WARNING - Epoch [21/25] Step [221/250]  acc 0.220366 (0.255227)  loss 1.570496 (1.581979)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 02:28:22,669 - WARNING - Epoch [21/25] Step [231/250]  acc 0.270372 (0.255198)  loss 1.556217 (1.581943)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 02:28:27,171 - WARNING - Epoch [21/25] Step [241/250]  acc 0.215987 (0.255494)  loss 1.592933 (1.581800)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
Epoch 21 completed in 0:01:52.641692
2025-08-27 02:28:59,102 - WARNING - Epoch [22/25] Step [1/250]  acc 0.249097 (0.249097)  loss 1.615328 (1.615328)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:29:03,646 - WARNING - Epoch [22/25] Step [11/250]  acc 0.264589 (0.258327)  loss 1.577776 (1.590602)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7800.0 MB
2025-08-27 02:29:08,144 - WARNING - Epoch [22/25] Step [21/250]  acc 0.205058 (0.253704)  loss 1.627273 (1.595459)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 7800.0 MB
2025-08-27 02:29:12,862 - WARNING - Epoch [22/25] Step [31/250]  acc 0.237480 (0.252472)  loss 1.587007 (1.592555)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7800.0 MB
2025-08-27 02:29:17,384 - WARNING - Epoch [22/25] Step [41/250]  acc 0.253643 (0.256853)  loss 1.604105 (1.586021)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 02:29:21,872 - WARNING - Epoch [22/25] Step [51/250]  acc 0.232847 (0.256340)  loss 1.607337 (1.584428)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7800.0 MB
2025-08-27 02:29:26,374 - WARNING - Epoch [22/25] Step [61/250]  acc 0.269885 (0.254955)  loss 1.563160 (1.582769)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 7800.0 MB
2025-08-27 02:29:30,843 - WARNING - Epoch [22/25] Step [71/250]  acc 0.231921 (0.256109)  loss 1.587891 (1.579199)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 02:29:35,373 - WARNING - Epoch [22/25] Step [81/250]  acc 0.228916 (0.256219)  loss 1.593076 (1.581650)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:29:39,870 - WARNING - Epoch [22/25] Step [91/250]  acc 0.280022 (0.256787)  loss 1.568019 (1.581203)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7800.0 MB
2025-08-27 02:29:44,351 - WARNING - Epoch [22/25] Step [101/250]  acc 0.258734 (0.257009)  loss 1.545090 (1.580235)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7800.0 MB
2025-08-27 02:29:48,842 - WARNING - Epoch [22/25] Step [111/250]  acc 0.244875 (0.256197)  loss 1.609739 (1.581558)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7800.0 MB
2025-08-27 02:29:53,282 - WARNING - Epoch [22/25] Step [121/250]  acc 0.255718 (0.255909)  loss 1.590369 (1.581156)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7800.0 MB
2025-08-27 02:29:57,754 - WARNING - Epoch [22/25] Step [131/250]  acc 0.274947 (0.257010)  loss 1.587731 (1.580959)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7800.0 MB
2025-08-27 02:30:02,291 - WARNING - Epoch [22/25] Step [141/250]  acc 0.256713 (0.256814)  loss 1.592538 (1.580470)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7800.0 MB
2025-08-27 02:30:06,881 - WARNING - Epoch [22/25] Step [151/250]  acc 0.307377 (0.257306)  loss 1.541394 (1.578777)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:30:11,384 - WARNING - Epoch [22/25] Step [161/250]  acc 0.275244 (0.257254)  loss 1.580493 (1.580232)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7800.0 MB
2025-08-27 02:30:15,854 - WARNING - Epoch [22/25] Step [171/250]  acc 0.264205 (0.256574)  loss 1.591109 (1.580806)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 7800.0 MB
2025-08-27 02:30:20,331 - WARNING - Epoch [22/25] Step [181/250]  acc 0.307320 (0.256721)  loss 1.554941 (1.581203)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
2025-08-27 02:30:25,022 - WARNING - Epoch [22/25] Step [191/250]  acc 0.214286 (0.256553)  loss 1.632982 (1.581528)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 02:30:29,509 - WARNING - Epoch [22/25] Step [201/250]  acc 0.267805 (0.256495)  loss 1.548166 (1.581415)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 7800.0 MB
2025-08-27 02:30:33,984 - WARNING - Epoch [22/25] Step [211/250]  acc 0.252886 (0.256839)  loss 1.556968 (1.581795)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 7800.0 MB
2025-08-27 02:30:38,509 - WARNING - Epoch [22/25] Step [221/250]  acc 0.334735 (0.257791)  loss 1.511056 (1.581744)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7800.0 MB
2025-08-27 02:30:43,038 - WARNING - Epoch [22/25] Step [231/250]  acc 0.244726 (0.257967)  loss 1.520228 (1.581038)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7800.0 MB
2025-08-27 02:30:47,538 - WARNING - Epoch [22/25] Step [241/250]  acc 0.264820 (0.258224)  loss 1.578712 (1.581398)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7800.0 MB
Epoch 22 completed in 0:01:52.914660
2025-08-27 02:31:19,205 - WARNING - Epoch [23/25] Step [1/250]  acc 0.238734 (0.238734)  loss 1.632539 (1.632539)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7800.0 MB
2025-08-27 02:31:23,730 - WARNING - Epoch [23/25] Step [11/250]  acc 0.223204 (0.249504)  loss 1.639434 (1.603666)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7800.0 MB
2025-08-27 02:31:28,254 - WARNING - Epoch [23/25] Step [21/250]  acc 0.247191 (0.257878)  loss 1.567804 (1.591510)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:31:32,724 - WARNING - Epoch [23/25] Step [31/250]  acc 0.196375 (0.259046)  loss 1.612717 (1.585114)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 7800.0 MB
2025-08-27 02:31:37,273 - WARNING - Epoch [23/25] Step [41/250]  acc 0.303239 (0.258942)  loss 1.567611 (1.585839)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 7800.0 MB
2025-08-27 02:31:41,737 - WARNING - Epoch [23/25] Step [51/250]  acc 0.285299 (0.259322)  loss 1.552359 (1.584440)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7800.0 MB
2025-08-27 02:31:46,228 - WARNING - Epoch [23/25] Step [61/250]  acc 0.250655 (0.257573)  loss 1.637130 (1.583986)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7800.0 MB
2025-08-27 02:31:50,567 - WARNING - Epoch [23/25] Step [71/250]  acc 0.314864 (0.259693)  loss 1.568491 (1.582399)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 7800.0 MB
2025-08-27 02:31:55,045 - WARNING - Epoch [23/25] Step [81/250]  acc 0.244444 (0.259932)  loss 1.520175 (1.584011)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7800.0 MB
2025-08-27 02:31:59,681 - WARNING - Epoch [23/25] Step [91/250]  acc 0.279540 (0.260090)  loss 1.533133 (1.583914)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7800.0 MB
2025-08-27 02:32:04,084 - WARNING - Epoch [23/25] Step [101/250]  acc 0.277540 (0.260496)  loss 1.528888 (1.581898)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7800.0 MB
2025-08-27 02:32:08,390 - WARNING - Epoch [23/25] Step [111/250]  acc 0.275403 (0.261503)  loss 1.555890 (1.579694)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7800.0 MB
2025-08-27 02:32:12,766 - WARNING - Epoch [23/25] Step [121/250]  acc 0.247084 (0.261578)  loss 1.559722 (1.579749)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7800.0 MB
2025-08-27 02:32:16,996 - WARNING - Epoch [23/25] Step [131/250]  acc 0.276691 (0.261895)  loss 1.571123 (1.579122)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7800.0 MB
2025-08-27 02:32:21,246 - WARNING - Epoch [23/25] Step [141/250]  acc 0.256182 (0.262086)  loss 1.535331 (1.579827)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 7800.0 MB
2025-08-27 02:32:25,482 - WARNING - Epoch [23/25] Step [151/250]  acc 0.250258 (0.261704)  loss 1.608085 (1.580694)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:32:29,730 - WARNING - Epoch [23/25] Step [161/250]  acc 0.264308 (0.262409)  loss 1.561483 (1.580049)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 02:32:33,951 - WARNING - Epoch [23/25] Step [171/250]  acc 0.248672 (0.262453)  loss 1.630721 (1.579439)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 02:32:38,150 - WARNING - Epoch [23/25] Step [181/250]  acc 0.270961 (0.262837)  loss 1.581354 (1.579714)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 02:32:42,365 - WARNING - Epoch [23/25] Step [191/250]  acc 0.221128 (0.263494)  loss 1.611515 (1.579715)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
2025-08-27 02:32:46,798 - WARNING - Epoch [23/25] Step [201/250]  acc 0.240536 (0.263376)  loss 1.597091 (1.580067)
GPU memory consumption  GPU Memory: Allocated: 51.3 MB, Reserved: 7800.0 MB
2025-08-27 02:32:51,288 - WARNING - Epoch [23/25] Step [211/250]  acc 0.268868 (0.263393)  loss 1.575937 (1.579657)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7800.0 MB
2025-08-27 02:32:55,888 - WARNING - Epoch [23/25] Step [221/250]  acc 0.260541 (0.263615)  loss 1.597245 (1.579295)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 7800.0 MB
2025-08-27 02:33:00,669 - WARNING - Epoch [23/25] Step [231/250]  acc 0.262331 (0.263596)  loss 1.567023 (1.579338)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 02:33:05,177 - WARNING - Epoch [23/25] Step [241/250]  acc 0.300462 (0.264135)  loss 1.552014 (1.579409)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7800.0 MB
Epoch 23 completed in 0:01:50.765695
2025-08-27 02:33:37,035 - WARNING - Epoch [24/25] Step [1/250]  acc 0.261320 (0.261320)  loss 1.617215 (1.617215)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:33:41,377 - WARNING - Epoch [24/25] Step [11/250]  acc 0.257158 (0.270538)  loss 1.575346 (1.578072)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:33:45,734 - WARNING - Epoch [24/25] Step [21/250]  acc 0.276607 (0.269827)  loss 1.542176 (1.572368)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 02:33:50,076 - WARNING - Epoch [24/25] Step [31/250]  acc 0.299903 (0.270264)  loss 1.550684 (1.570695)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 7800.0 MB
2025-08-27 02:33:54,441 - WARNING - Epoch [24/25] Step [41/250]  acc 0.266191 (0.270639)  loss 1.555650 (1.571465)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7800.0 MB
2025-08-27 02:33:58,788 - WARNING - Epoch [24/25] Step [51/250]  acc 0.273911 (0.270159)  loss 1.547058 (1.570768)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 7800.0 MB
2025-08-27 02:34:03,448 - WARNING - Epoch [24/25] Step [61/250]  acc 0.258427 (0.272521)  loss 1.574713 (1.571490)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 7800.0 MB
2025-08-27 02:34:08,125 - WARNING - Epoch [24/25] Step [71/250]  acc 0.303077 (0.272783)  loss 1.547340 (1.569431)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 02:34:12,608 - WARNING - Epoch [24/25] Step [81/250]  acc 0.266530 (0.272675)  loss 1.619750 (1.567386)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:34:16,999 - WARNING - Epoch [24/25] Step [91/250]  acc 0.257778 (0.272139)  loss 1.579679 (1.567255)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 7800.0 MB
2025-08-27 02:34:21,453 - WARNING - Epoch [24/25] Step [101/250]  acc 0.250729 (0.272213)  loss 1.564336 (1.568009)
GPU memory consumption  GPU Memory: Allocated: 61.3 MB, Reserved: 7800.0 MB
2025-08-27 02:34:25,834 - WARNING - Epoch [24/25] Step [111/250]  acc 0.286656 (0.273319)  loss 1.561917 (1.567286)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7800.0 MB
2025-08-27 02:34:30,225 - WARNING - Epoch [24/25] Step [121/250]  acc 0.278362 (0.273695)  loss 1.511178 (1.567389)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 02:34:34,593 - WARNING - Epoch [24/25] Step [131/250]  acc 0.262462 (0.273203)  loss 1.555049 (1.567390)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:34:38,966 - WARNING - Epoch [24/25] Step [141/250]  acc 0.219042 (0.273698)  loss 1.681138 (1.567201)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7800.0 MB
2025-08-27 02:34:43,798 - WARNING - Epoch [24/25] Step [151/250]  acc 0.259784 (0.274448)  loss 1.560286 (1.567391)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 7800.0 MB
2025-08-27 02:34:48,155 - WARNING - Epoch [24/25] Step [161/250]  acc 0.274384 (0.273897)  loss 1.580751 (1.567859)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7800.0 MB
2025-08-27 02:34:52,524 - WARNING - Epoch [24/25] Step [171/250]  acc 0.280374 (0.274401)  loss 1.512034 (1.567374)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7800.0 MB
2025-08-27 02:34:56,879 - WARNING - Epoch [24/25] Step [181/250]  acc 0.288818 (0.275260)  loss 1.566603 (1.566886)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7800.0 MB
2025-08-27 02:35:01,265 - WARNING - Epoch [24/25] Step [191/250]  acc 0.293773 (0.275820)  loss 1.546077 (1.567299)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 02:35:05,600 - WARNING - Epoch [24/25] Step [201/250]  acc 0.294479 (0.275168)  loss 1.538274 (1.566923)
GPU memory consumption  GPU Memory: Allocated: 52.8 MB, Reserved: 7800.0 MB
2025-08-27 02:35:09,960 - WARNING - Epoch [24/25] Step [211/250]  acc 0.304569 (0.275546)  loss 1.553464 (1.567033)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 02:35:14,328 - WARNING - Epoch [24/25] Step [221/250]  acc 0.242343 (0.275774)  loss 1.567003 (1.566537)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7800.0 MB
2025-08-27 02:35:18,730 - WARNING - Epoch [24/25] Step [231/250]  acc 0.282850 (0.276474)  loss 1.617167 (1.565848)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7800.0 MB
2025-08-27 02:35:23,142 - WARNING - Epoch [24/25] Step [241/250]  acc 0.292634 (0.276359)  loss 1.546180 (1.565484)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7800.0 MB
Epoch 24 completed in 0:01:50.493311
2025-08-27 02:35:54,659 - WARNING - Epoch [25/25] Step [1/250]  acc 0.284380 (0.284380)  loss 1.580851 (1.580851)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:35:59,042 - WARNING - Epoch [25/25] Step [11/250]  acc 0.267483 (0.287603)  loss 1.601830 (1.573405)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7800.0 MB
2025-08-27 02:36:03,458 - WARNING - Epoch [25/25] Step [21/250]  acc 0.329843 (0.287669)  loss 1.575180 (1.565776)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:36:07,823 - WARNING - Epoch [25/25] Step [31/250]  acc 0.302799 (0.285447)  loss 1.575452 (1.564473)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7800.0 MB
2025-08-27 02:36:12,183 - WARNING - Epoch [25/25] Step [41/250]  acc 0.286481 (0.287543)  loss 1.612031 (1.561501)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7800.0 MB
2025-08-27 02:36:16,785 - WARNING - Epoch [25/25] Step [51/250]  acc 0.268801 (0.285383)  loss 1.529205 (1.563309)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:36:21,173 - WARNING - Epoch [25/25] Step [61/250]  acc 0.269231 (0.285943)  loss 1.583143 (1.562730)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:36:25,532 - WARNING - Epoch [25/25] Step [71/250]  acc 0.279231 (0.284541)  loss 1.528941 (1.561603)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7800.0 MB
2025-08-27 02:36:29,935 - WARNING - Epoch [25/25] Step [81/250]  acc 0.292615 (0.284013)  loss 1.586992 (1.563913)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 02:36:34,436 - WARNING - Epoch [25/25] Step [91/250]  acc 0.254934 (0.284188)  loss 1.584903 (1.562883)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7800.0 MB
2025-08-27 02:36:38,816 - WARNING - Epoch [25/25] Step [101/250]  acc 0.316504 (0.284462)  loss 1.533158 (1.562761)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7800.0 MB
2025-08-27 02:36:43,227 - WARNING - Epoch [25/25] Step [111/250]  acc 0.272285 (0.283329)  loss 1.541977 (1.562100)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7800.0 MB
2025-08-27 02:36:47,616 - WARNING - Epoch [25/25] Step [121/250]  acc 0.316872 (0.282961)  loss 1.550423 (1.562171)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7800.0 MB
2025-08-27 02:36:51,974 - WARNING - Epoch [25/25] Step [131/250]  acc 0.294827 (0.283461)  loss 1.540746 (1.561345)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7800.0 MB
2025-08-27 02:36:56,345 - WARNING - Epoch [25/25] Step [141/250]  acc 0.306070 (0.283305)  loss 1.488385 (1.560598)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7800.0 MB
2025-08-27 02:37:00,715 - WARNING - Epoch [25/25] Step [151/250]  acc 0.262430 (0.283114)  loss 1.579516 (1.561006)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:37:05,103 - WARNING - Epoch [25/25] Step [161/250]  acc 0.294774 (0.283621)  loss 1.529173 (1.561217)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7800.0 MB
2025-08-27 02:37:09,513 - WARNING - Epoch [25/25] Step [171/250]  acc 0.309444 (0.283873)  loss 1.551325 (1.560787)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7800.0 MB
2025-08-27 02:37:13,897 - WARNING - Epoch [25/25] Step [181/250]  acc 0.274531 (0.284422)  loss 1.544059 (1.559689)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 7800.0 MB
2025-08-27 02:37:18,271 - WARNING - Epoch [25/25] Step [191/250]  acc 0.264449 (0.284822)  loss 1.538095 (1.558752)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7800.0 MB
2025-08-27 02:37:22,667 - WARNING - Epoch [25/25] Step [201/250]  acc 0.283620 (0.284665)  loss 1.533748 (1.558744)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7800.0 MB
2025-08-27 02:37:27,325 - WARNING - Epoch [25/25] Step [211/250]  acc 0.258672 (0.284287)  loss 1.542608 (1.558671)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7800.0 MB
2025-08-27 02:37:31,686 - WARNING - Epoch [25/25] Step [221/250]  acc 0.285560 (0.283958)  loss 1.567493 (1.558236)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 7800.0 MB
2025-08-27 02:37:36,043 - WARNING - Epoch [25/25] Step [231/250]  acc 0.254045 (0.283853)  loss 1.538784 (1.558200)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7800.0 MB
2025-08-27 02:37:40,444 - WARNING - Epoch [25/25] Step [241/250]  acc 0.284736 (0.283609)  loss 1.522483 (1.558560)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 7800.0 MB
Epoch 25 completed in 0:01:50.164338
2025-08-27 02:38:11,004 - INFO - DARTS search completed in 3572.11s
2025-08-27 02:38:11,005 - INFO - 
============================================================
2025-08-27 02:38:11,005 - INFO - Layer layer_0 Expert Selection:
2025-08-27 02:38:11,005 - INFO -   Expert 0: GINE (α=0.3635) ← SELECTED
2025-08-27 02:38:11,005 - INFO -   Expert 1: CustomGatedGCN (α=0.3201)
2025-08-27 02:38:11,005 - INFO -   Expert 2: GATV2 (α=0.3164)
2025-08-27 02:38:11,005 - INFO - Selected Expert Index: 0 (GINE)
2025-08-27 02:38:11,006 - INFO - ============================================================

2025-08-27 02:38:11,006 - INFO - 
============================================================
2025-08-27 02:38:11,006 - INFO - Layer layer_1 Expert Selection:
2025-08-27 02:38:11,006 - INFO -   Expert 0: GINE (α=0.2388)
2025-08-27 02:38:11,006 - INFO -   Expert 1: CustomGatedGCN (α=0.2782)
2025-08-27 02:38:11,006 - INFO -   Expert 2: GATV2 (α=0.4830) ← SELECTED
2025-08-27 02:38:11,006 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-27 02:38:11,006 - INFO - ============================================================

2025-08-27 02:38:11,006 - INFO - 
============================================================
2025-08-27 02:38:11,006 - INFO - Layer layer_2 Expert Selection:
2025-08-27 02:38:11,006 - INFO -   Expert 0: GINE (α=0.2686)
2025-08-27 02:38:11,006 - INFO -   Expert 1: CustomGatedGCN (α=0.3360)
2025-08-27 02:38:11,006 - INFO -   Expert 2: GATV2 (α=0.3954) ← SELECTED
2025-08-27 02:38:11,006 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-27 02:38:11,006 - INFO - ============================================================

2025-08-27 02:38:11,006 - INFO - 
============================================================
2025-08-27 02:38:11,006 - INFO - Layer layer_3 Expert Selection:
2025-08-27 02:38:11,006 - INFO -   Expert 0: GINE (α=0.2809)
2025-08-27 02:38:11,006 - INFO -   Expert 1: CustomGatedGCN (α=0.3626) ← SELECTED
2025-08-27 02:38:11,006 - INFO -   Expert 2: GATV2 (α=0.3564)
2025-08-27 02:38:11,006 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-27 02:38:11,006 - INFO - ============================================================

2025-08-27 02:38:11,006 - INFO - 
============================================================
2025-08-27 02:38:11,006 - INFO - Layer layer_4 Expert Selection:
2025-08-27 02:38:11,007 - INFO -   Expert 0: GINE (α=0.2966)
2025-08-27 02:38:11,007 - INFO -   Expert 1: CustomGatedGCN (α=0.3905) ← SELECTED
2025-08-27 02:38:11,007 - INFO -   Expert 2: GATV2 (α=0.3129)
2025-08-27 02:38:11,007 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-27 02:38:11,007 - INFO - ============================================================

2025-08-27 02:38:11,007 - INFO - 
============================================================
2025-08-27 02:38:11,007 - INFO - Layer layer_5 Expert Selection:
2025-08-27 02:38:11,007 - INFO -   Expert 0: GINE (α=0.2962)
2025-08-27 02:38:11,007 - INFO -   Expert 1: CustomGatedGCN (α=0.3815) ← SELECTED
2025-08-27 02:38:11,007 - INFO -   Expert 2: GATV2 (α=0.3223)
2025-08-27 02:38:11,007 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-27 02:38:11,007 - INFO - ============================================================

2025-08-27 02:38:11,007 - INFO - 
============================================================
2025-08-27 02:38:11,007 - INFO - Layer layer_6 Expert Selection:
2025-08-27 02:38:11,007 - INFO -   Expert 0: GINE (α=0.2998)
2025-08-27 02:38:11,007 - INFO -   Expert 1: CustomGatedGCN (α=0.3698) ← SELECTED
2025-08-27 02:38:11,007 - INFO -   Expert 2: GATV2 (α=0.3303)
2025-08-27 02:38:11,007 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-27 02:38:11,007 - INFO - ============================================================

2025-08-27 02:38:11,007 - INFO - 
============================================================
2025-08-27 02:38:11,007 - INFO - Layer layer_7 Expert Selection:
2025-08-27 02:38:11,007 - INFO -   Expert 0: GINE (α=0.3413) ← SELECTED
2025-08-27 02:38:11,007 - INFO -   Expert 1: CustomGatedGCN (α=0.3233)
2025-08-27 02:38:11,007 - INFO -   Expert 2: GATV2 (α=0.3355)
2025-08-27 02:38:11,007 - INFO - Selected Expert Index: 0 (GINE)
2025-08-27 02:38:11,007 - INFO - ============================================================

2025-08-27 02:38:11,007 - INFO - 
============================================================
2025-08-27 02:38:11,007 - INFO - Layer layer_8 Expert Selection:
2025-08-27 02:38:11,008 - INFO -   Expert 0: GINE (α=0.3656) ← SELECTED
2025-08-27 02:38:11,008 - INFO -   Expert 1: CustomGatedGCN (α=0.3298)
2025-08-27 02:38:11,008 - INFO -   Expert 2: GATV2 (α=0.3046)
2025-08-27 02:38:11,008 - INFO - Selected Expert Index: 0 (GINE)
2025-08-27 02:38:11,008 - INFO - ============================================================

2025-08-27 02:38:11,008 - INFO - 
============================================================
2025-08-27 02:38:11,008 - INFO - Layer layer_9 Expert Selection:
2025-08-27 02:38:11,008 - INFO -   Expert 0: GINE (α=0.3373)
2025-08-27 02:38:11,008 - INFO -   Expert 1: CustomGatedGCN (α=0.3554) ← SELECTED
2025-08-27 02:38:11,008 - INFO -   Expert 2: GATV2 (α=0.3073)
2025-08-27 02:38:11,008 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-27 02:38:11,008 - INFO - ============================================================

2025-08-27 02:38:11,008 - INFO - 
============================================================
2025-08-27 02:38:11,008 - INFO - Layer layer_10 Expert Selection:
2025-08-27 02:38:11,008 - INFO -   Expert 0: GINE (α=0.3037)
2025-08-27 02:38:11,008 - INFO -   Expert 1: CustomGatedGCN (α=0.3592) ← SELECTED
2025-08-27 02:38:11,008 - INFO -   Expert 2: GATV2 (α=0.3370)
2025-08-27 02:38:11,008 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-27 02:38:11,008 - INFO - ============================================================

2025-08-27 02:38:11,008 - INFO - 
============================================================
2025-08-27 02:38:11,008 - INFO - Layer layer_11 Expert Selection:
2025-08-27 02:38:11,008 - INFO -   Expert 0: GINE (α=0.3156)
2025-08-27 02:38:11,008 - INFO -   Expert 1: CustomGatedGCN (α=0.3768) ← SELECTED
2025-08-27 02:38:11,008 - INFO -   Expert 2: GATV2 (α=0.3076)
2025-08-27 02:38:11,008 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-27 02:38:11,008 - INFO - ============================================================

2025-08-27 02:38:11,008 - INFO - 
============================================================
2025-08-27 02:38:11,009 - INFO - Layer layer_12 Expert Selection:
2025-08-27 02:38:11,009 - INFO -   Expert 0: GINE (α=0.3587) ← SELECTED
2025-08-27 02:38:11,009 - INFO -   Expert 1: CustomGatedGCN (α=0.3299)
2025-08-27 02:38:11,009 - INFO -   Expert 2: GATV2 (α=0.3113)
2025-08-27 02:38:11,009 - INFO - Selected Expert Index: 0 (GINE)
2025-08-27 02:38:11,009 - INFO - ============================================================

2025-08-27 02:38:11,009 - INFO - 
============================================================
2025-08-27 02:38:11,009 - INFO - Layer layer_13 Expert Selection:
2025-08-27 02:38:11,009 - INFO -   Expert 0: GINE (α=0.2801)
2025-08-27 02:38:11,009 - INFO -   Expert 1: CustomGatedGCN (α=0.4047) ← SELECTED
2025-08-27 02:38:11,009 - INFO -   Expert 2: GATV2 (α=0.3152)
2025-08-27 02:38:11,009 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-27 02:38:11,009 - INFO - ============================================================

2025-08-27 02:38:11,009 - INFO - 
============================================================
2025-08-27 02:38:11,009 - INFO - Layer layer_14 Expert Selection:
2025-08-27 02:38:11,009 - INFO -   Expert 0: GINE (α=0.2666)
2025-08-27 02:38:11,009 - INFO -   Expert 1: CustomGatedGCN (α=0.4573) ← SELECTED
2025-08-27 02:38:11,009 - INFO -   Expert 2: GATV2 (α=0.2761)
2025-08-27 02:38:11,009 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-27 02:38:11,009 - INFO - ============================================================

2025-08-27 02:38:11,009 - INFO - 
============================================================
2025-08-27 02:38:11,009 - INFO - Layer layer_15 Expert Selection:
2025-08-27 02:38:11,009 - INFO -   Expert 0: GINE (α=0.3133)
2025-08-27 02:38:11,009 - INFO -   Expert 1: CustomGatedGCN (α=0.3447) ← SELECTED
2025-08-27 02:38:11,009 - INFO -   Expert 2: GATV2 (α=0.3420)
2025-08-27 02:38:11,009 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-27 02:38:11,009 - INFO - ============================================================

=== MODEL PARAMETER COMPARISON ===
Original DARTS model parameters: 728,678
2025-08-27 02:38:11,067 - INFO - Layer 0: Using ONLY Expert 0 (GINE)
2025-08-27 02:38:11,068 - INFO - DiscreteNASLayer 0: Using ONLY Expert 0 (GINE)
2025-08-27 02:38:11,072 - INFO - Layer 1: Using ONLY Expert 2 (GATV2)
2025-08-27 02:38:11,072 - INFO - DiscreteNASLayer 1: Using ONLY Expert 2 (GATV2)
2025-08-27 02:38:11,074 - INFO - Layer 2: Using ONLY Expert 2 (GATV2)
2025-08-27 02:38:11,074 - INFO - DiscreteNASLayer 2: Using ONLY Expert 2 (GATV2)
2025-08-27 02:38:11,076 - INFO - Layer 3: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,077 - INFO - DiscreteNASLayer 3: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,079 - INFO - Layer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,079 - INFO - DiscreteNASLayer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,081 - INFO - Layer 5: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,082 - INFO - DiscreteNASLayer 5: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,084 - INFO - Layer 6: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,084 - INFO - DiscreteNASLayer 6: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,087 - INFO - Layer 7: Using ONLY Expert 0 (GINE)
2025-08-27 02:38:11,087 - INFO - DiscreteNASLayer 7: Using ONLY Expert 0 (GINE)
2025-08-27 02:38:11,089 - INFO - Layer 8: Using ONLY Expert 0 (GINE)
2025-08-27 02:38:11,089 - INFO - DiscreteNASLayer 8: Using ONLY Expert 0 (GINE)
2025-08-27 02:38:11,092 - INFO - Layer 9: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,092 - INFO - DiscreteNASLayer 9: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,095 - INFO - Layer 10: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,095 - INFO - DiscreteNASLayer 10: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,097 - INFO - Layer 11: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,097 - INFO - DiscreteNASLayer 11: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,100 - INFO - Layer 12: Using ONLY Expert 0 (GINE)
2025-08-27 02:38:11,100 - INFO - DiscreteNASLayer 12: Using ONLY Expert 0 (GINE)
2025-08-27 02:38:11,102 - INFO - Layer 13: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,102 - INFO - DiscreteNASLayer 13: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,105 - INFO - Layer 14: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,105 - INFO - DiscreteNASLayer 14: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,107 - INFO - Layer 15: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-27 02:38:11,107 - INFO - DiscreteNASLayer 15: Using ONLY Expert 1 (CustomGatedGCN)
Fresh discrete model parameters: 501,014
Parameter difference: -227,664
✓ Used cfg.share.dim_in (raw input) instead of self.encoder.dim_in (processed)
✓ Fresh discrete model with correct input dimensions
2025-08-27 02:38:11,130 - INFO - Replaced inner model with discrete version
2025-08-27 02:38:11,132 - INFO - Creating fresh optimizer/scheduler for discrete model...
2025-08-27 02:38:11,136 - INFO - Fresh optimizer created: AdamW
2025-08-27 02:38:11,136 - INFO - Fresh scheduler created: LambdaLR
2025-08-27 02:38:11,136 - INFO - Discrete model parameters: 501,014
2025-08-27 02:38:11,136 - INFO - ============================================================
2025-08-27 02:38:11,136 - INFO - PHASE 2: DISCRETE TRAINING WITH UNCERTAINTY
2025-08-27 02:38:11,136 - INFO - ============================================================
2025-08-27 02:38:11,136 - INFO - === Epoch 0 ===
2025-08-27 02:39:37,976 - INFO - train: {'epoch': 0, 'time_epoch': 86.11445, 'eta': 8525.33095, 'eta_hours': 2.36815, 'loss': 1.79985274, 'lr': 0.0, 'params': 501014, 'time_iter': 0.13778, 'accuracy': 0.16462, 'f1': 0.08408, 'accuracy-SBM': 0.16454, 'auc': 0.50044}
2025-08-27 02:39:37,994 - INFO - ...computing epoch stats took: 0.73s
2025-08-27 02:39:42,558 - INFO - val: {'epoch': 0, 'time_epoch': 4.49794, 'loss': 1.79886021, 'lr': 0, 'params': 501014, 'time_iter': 0.0714, 'accuracy': 0.1664, 'f1': 0.08262, 'accuracy-SBM': 0.16474, 'auc': 0.50027}
2025-08-27 02:39:42,574 - INFO - ...computing epoch stats took: 0.08s
2025-08-27 02:39:48,807 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 02:39:48,874 - INFO - test: {'epoch': 0, 'time_epoch': 4.83028, 'loss': 1.79909869, 'lr': 0, 'params': 501014, 'time_iter': 0.07667, 'accuracy': 0.16708, 'f1': 0.08294, 'accuracy-SBM': 0.16651, 'auc': 0.50225}
2025-08-27 02:39:48,886 - INFO - ...computing epoch stats took: 0.07s
2025-08-27 02:39:48,887 - INFO - > Epoch 0: took 97.8s (avg 97.8s) | Best so far: epoch 0	train_loss: 1.7999 train_accuracy-SBM: 0.1645	val_loss: 1.7989 val_accuracy-SBM: 0.1647	test_loss: 1.7991 test_accuracy-SBM: 0.1665
2025-08-27 02:39:48,887 - INFO - === Epoch 1 ===
2025-08-27 02:41:14,889 - INFO - train: {'epoch': 1, 'time_epoch': 85.57027, 'eta': 8412.55157, 'eta_hours': 2.33682, 'loss': 1.59397656, 'lr': 0.0002, 'params': 501014, 'time_iter': 0.13691, 'accuracy': 0.40389, 'f1': 0.39112, 'accuracy-SBM': 0.40386, 'auc': 0.74425}
2025-08-27 02:41:14,894 - INFO - ...computing epoch stats took: 0.42s
2025-08-27 02:41:19,246 - INFO - val: {'epoch': 1, 'time_epoch': 4.30717, 'loss': 1.55340634, 'lr': 0, 'params': 501014, 'time_iter': 0.06837, 'accuracy': 0.42269, 'f1': 0.39242, 'accuracy-SBM': 0.42299, 'auc': 0.76836}
2025-08-27 02:41:19,248 - INFO - ...computing epoch stats took: 0.04s
2025-08-27 02:41:25,221 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 02:41:25,273 - INFO - test: {'epoch': 1, 'time_epoch': 4.56936, 'loss': 1.55232693, 'lr': 0, 'params': 501014, 'time_iter': 0.07253, 'accuracy': 0.42351, 'f1': 0.39467, 'accuracy-SBM': 0.42392, 'auc': 0.76889}
2025-08-27 02:41:25,275 - INFO - ...computing epoch stats took: 0.04s
2025-08-27 02:41:25,275 - INFO - > Epoch 1: took 96.4s (avg 97.1s) | Best so far: epoch 1	train_loss: 1.5940 train_accuracy-SBM: 0.4039	val_loss: 1.5534 val_accuracy-SBM: 0.4230	test_loss: 1.5523 test_accuracy-SBM: 0.4239
2025-08-27 02:41:25,275 - INFO - === Epoch 2 ===
2025-08-27 02:42:50,670 - INFO - train: {'epoch': 2, 'time_epoch': 84.95876, 'eta': 8298.13923, 'eta_hours': 2.30504, 'loss': 1.29102878, 'lr': 0.0004, 'params': 501014, 'time_iter': 0.13593, 'accuracy': 0.54597, 'f1': 0.53978, 'accuracy-SBM': 0.546, 'auc': 0.83818}
2025-08-27 02:42:50,675 - INFO - ...computing epoch stats took: 0.42s
2025-08-27 02:42:55,027 - INFO - val: {'epoch': 2, 'time_epoch': 4.3112, 'loss': 1.50163242, 'lr': 0, 'params': 501014, 'time_iter': 0.06843, 'accuracy': 0.41785, 'f1': 0.4147, 'accuracy-SBM': 0.41572, 'auc': 0.80205}
2025-08-27 02:42:55,028 - INFO - ...computing epoch stats took: 0.04s
2025-08-27 02:43:00,714 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 02:43:00,762 - INFO - test: {'epoch': 2, 'time_epoch': 4.34682, 'loss': 1.49135014, 'lr': 0, 'params': 501014, 'time_iter': 0.069, 'accuracy': 0.41832, 'f1': 0.41676, 'accuracy-SBM': 0.41855, 'auc': 0.80577}
2025-08-27 02:43:00,763 - INFO - ...computing epoch stats took: 0.04s
2025-08-27 02:43:00,764 - INFO - > Epoch 2: took 95.5s (avg 96.5s) | Best so far: epoch 1	train_loss: 1.5940 train_accuracy-SBM: 0.4039	val_loss: 1.5534 val_accuracy-SBM: 0.4230	test_loss: 1.5523 test_accuracy-SBM: 0.4239
2025-08-27 02:43:00,764 - INFO - === Epoch 3 ===
2025-08-27 02:44:25,912 - INFO - train: {'epoch': 3, 'time_epoch': 84.89095, 'eta': 8196.82637, 'eta_hours': 2.2769, 'loss': 1.13462246, 'lr': 0.0006, 'params': 501014, 'time_iter': 0.13583, 'accuracy': 0.57841, 'f1': 0.5719, 'accuracy-SBM': 0.57846, 'auc': 0.87037}
2025-08-27 02:44:30,144 - INFO - val: {'epoch': 3, 'time_epoch': 4.17614, 'loss': 1.13837409, 'lr': 0, 'params': 501014, 'time_iter': 0.06629, 'accuracy': 0.56792, 'f1': 0.54867, 'accuracy-SBM': 0.56794, 'auc': 0.87357}
2025-08-27 02:44:36,308 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 02:44:36,350 - INFO - test: {'epoch': 3, 'time_epoch': 4.42886, 'loss': 1.13925875, 'lr': 0, 'params': 501014, 'time_iter': 0.0703, 'accuracy': 0.56945, 'f1': 0.5509, 'accuracy-SBM': 0.56954, 'auc': 0.8735}
2025-08-27 02:44:36,351 - INFO - > Epoch 3: took 95.6s (avg 96.3s) | Best so far: epoch 3	train_loss: 1.1346 train_accuracy-SBM: 0.5785	val_loss: 1.1384 val_accuracy-SBM: 0.5679	test_loss: 1.1393 test_accuracy-SBM: 0.5695
2025-08-27 02:44:36,352 - INFO - === Epoch 4 ===
2025-08-27 02:46:01,666 - INFO - train: {'epoch': 4, 'time_epoch': 85.04397, 'eta': 8104.98958, 'eta_hours': 2.25139, 'loss': 1.02834135, 'lr': 0.0008, 'params': 501014, 'time_iter': 0.13607, 'accuracy': 0.62583, 'f1': 0.62229, 'accuracy-SBM': 0.62588, 'auc': 0.8922}
2025-08-27 02:46:05,957 - INFO - val: {'epoch': 4, 'time_epoch': 4.2346, 'loss': 1.23742545, 'lr': 0, 'params': 501014, 'time_iter': 0.06722, 'accuracy': 0.53326, 'f1': 0.52645, 'accuracy-SBM': 0.53542, 'auc': 0.85888}
2025-08-27 02:46:11,934 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 02:46:11,973 - INFO - test: {'epoch': 4, 'time_epoch': 4.51214, 'loss': 1.22234999, 'lr': 0, 'params': 501014, 'time_iter': 0.07162, 'accuracy': 0.54476, 'f1': 0.5376, 'accuracy-SBM': 0.5455, 'auc': 0.86381}
2025-08-27 02:46:11,975 - INFO - > Epoch 4: took 95.6s (avg 96.2s) | Best so far: epoch 3	train_loss: 1.1346 train_accuracy-SBM: 0.5785	val_loss: 1.1384 val_accuracy-SBM: 0.5679	test_loss: 1.1393 test_accuracy-SBM: 0.5695
2025-08-27 02:46:11,976 - INFO - === Epoch 5 ===
2025-08-27 02:47:37,145 - INFO - train: {'epoch': 5, 'time_epoch': 84.79526, 'eta': 8011.52067, 'eta_hours': 2.22542, 'loss': 0.91338481, 'lr': 0.001, 'params': 501014, 'time_iter': 0.13567, 'accuracy': 0.67397, 'f1': 0.67371, 'accuracy-SBM': 0.67398, 'auc': 0.91701}
2025-08-27 02:47:41,414 - INFO - val: {'epoch': 5, 'time_epoch': 4.21243, 'loss': 1.07164834, 'lr': 0, 'params': 501014, 'time_iter': 0.06686, 'accuracy': 0.60773, 'f1': 0.60078, 'accuracy-SBM': 0.60658, 'auc': 0.89718}
2025-08-27 02:47:47,174 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 02:47:47,221 - INFO - test: {'epoch': 5, 'time_epoch': 4.4498, 'loss': 1.04723609, 'lr': 0, 'params': 501014, 'time_iter': 0.07063, 'accuracy': 0.61522, 'f1': 0.61001, 'accuracy-SBM': 0.61546, 'auc': 0.90217}
2025-08-27 02:47:47,223 - INFO - > Epoch 5: took 95.2s (avg 96.0s) | Best so far: epoch 5	train_loss: 0.9134 train_accuracy-SBM: 0.6740	val_loss: 1.0716 val_accuracy-SBM: 0.6066	test_loss: 1.0472 test_accuracy-SBM: 0.6155
2025-08-27 02:47:47,223 - INFO - === Epoch 6 ===
2025-08-27 02:49:13,060 - INFO - train: {'epoch': 6, 'time_epoch': 85.57777, 'eta': 7930.9262, 'eta_hours': 2.20304, 'loss': 0.81393373, 'lr': 0.00099973, 'params': 501014, 'time_iter': 0.13692, 'accuracy': 0.70877, 'f1': 0.70878, 'accuracy-SBM': 0.70877, 'auc': 0.93467}
2025-08-27 02:49:17,422 - INFO - val: {'epoch': 6, 'time_epoch': 4.3073, 'loss': 0.83891812, 'lr': 0, 'params': 501014, 'time_iter': 0.06837, 'accuracy': 0.69657, 'f1': 0.69669, 'accuracy-SBM': 0.69592, 'auc': 0.93363}
2025-08-27 02:49:23,551 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 02:49:23,595 - INFO - test: {'epoch': 6, 'time_epoch': 4.61692, 'loss': 0.82319863, 'lr': 0, 'params': 501014, 'time_iter': 0.07328, 'accuracy': 0.69913, 'f1': 0.69969, 'accuracy-SBM': 0.69914, 'auc': 0.9368}
2025-08-27 02:49:23,597 - INFO - > Epoch 6: took 96.4s (avg 96.1s) | Best so far: epoch 6	train_loss: 0.8139 train_accuracy-SBM: 0.7088	val_loss: 0.8389 val_accuracy-SBM: 0.6959	test_loss: 0.8232 test_accuracy-SBM: 0.6991
2025-08-27 02:49:23,597 - INFO - === Epoch 7 ===
2025-08-27 02:50:49,415 - INFO - train: {'epoch': 7, 'time_epoch': 85.54547, 'eta': 7848.71442, 'eta_hours': 2.1802, 'loss': 0.76928914, 'lr': 0.00099891, 'params': 501014, 'time_iter': 0.13687, 'accuracy': 0.72388, 'f1': 0.72389, 'accuracy-SBM': 0.72388, 'auc': 0.94139}
2025-08-27 02:50:53,790 - INFO - val: {'epoch': 7, 'time_epoch': 4.32668, 'loss': 0.72593194, 'lr': 0, 'params': 501014, 'time_iter': 0.06868, 'accuracy': 0.7381, 'f1': 0.73802, 'accuracy-SBM': 0.73849, 'auc': 0.94904}
2025-08-27 02:50:59,864 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 02:50:59,908 - INFO - test: {'epoch': 7, 'time_epoch': 4.61408, 'loss': 0.73364791, 'lr': 0, 'params': 501014, 'time_iter': 0.07324, 'accuracy': 0.73561, 'f1': 0.73526, 'accuracy-SBM': 0.73568, 'auc': 0.94782}
2025-08-27 02:50:59,910 - INFO - > Epoch 7: took 96.3s (avg 96.1s) | Best so far: epoch 7	train_loss: 0.7693 train_accuracy-SBM: 0.7239	val_loss: 0.7259 val_accuracy-SBM: 0.7385	test_loss: 0.7336 test_accuracy-SBM: 0.7357
2025-08-27 02:50:59,910 - INFO - === Epoch 8 ===
2025-08-27 02:52:25,208 - INFO - train: {'epoch': 8, 'time_epoch': 85.04453, 'eta': 7760.69678, 'eta_hours': 2.15575, 'loss': 0.7468056, 'lr': 0.00099754, 'params': 501014, 'time_iter': 0.13607, 'accuracy': 0.73198, 'f1': 0.73198, 'accuracy-SBM': 0.73198, 'auc': 0.94452}
2025-08-27 02:52:29,552 - INFO - val: {'epoch': 8, 'time_epoch': 4.29403, 'loss': 0.73510254, 'lr': 0, 'params': 501014, 'time_iter': 0.06816, 'accuracy': 0.73569, 'f1': 0.73549, 'accuracy-SBM': 0.73564, 'auc': 0.94716}
2025-08-27 02:52:35,587 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 02:52:35,628 - INFO - test: {'epoch': 8, 'time_epoch': 4.54361, 'loss': 0.72974061, 'lr': 0, 'params': 501014, 'time_iter': 0.07212, 'accuracy': 0.73724, 'f1': 0.73723, 'accuracy-SBM': 0.73708, 'auc': 0.94784}
2025-08-27 02:52:35,630 - INFO - > Epoch 8: took 95.7s (avg 96.1s) | Best so far: epoch 7	train_loss: 0.7693 train_accuracy-SBM: 0.7239	val_loss: 0.7259 val_accuracy-SBM: 0.7385	test_loss: 0.7336 test_accuracy-SBM: 0.7357
2025-08-27 02:52:35,630 - INFO - === Epoch 9 ===
2025-08-27 02:54:01,038 - INFO - train: {'epoch': 9, 'time_epoch': 85.14803, 'eta': 7674.20526, 'eta_hours': 2.13172, 'loss': 0.72924444, 'lr': 0.00099563, 'params': 501014, 'time_iter': 0.13624, 'accuracy': 0.73848, 'f1': 0.73848, 'accuracy-SBM': 0.73848, 'auc': 0.947}
2025-08-27 02:54:05,337 - INFO - val: {'epoch': 9, 'time_epoch': 4.25402, 'loss': 0.69392285, 'lr': 0, 'params': 501014, 'time_iter': 0.06752, 'accuracy': 0.75247, 'f1': 0.75244, 'accuracy-SBM': 0.75243, 'auc': 0.95246}
2025-08-27 02:54:11,389 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 02:54:11,438 - INFO - test: {'epoch': 9, 'time_epoch': 4.28229, 'loss': 0.69645815, 'lr': 0, 'params': 501014, 'time_iter': 0.06797, 'accuracy': 0.74959, 'f1': 0.74965, 'accuracy-SBM': 0.74964, 'auc': 0.95215}
2025-08-27 02:54:11,440 - INFO - > Epoch 9: took 95.8s (avg 96.0s) | Best so far: epoch 9	train_loss: 0.7292 train_accuracy-SBM: 0.7385	val_loss: 0.6939 val_accuracy-SBM: 0.7524	test_loss: 0.6965 test_accuracy-SBM: 0.7496
2025-08-27 02:54:11,441 - INFO - === Epoch 10 ===
2025-08-27 02:55:37,136 - INFO - train: {'epoch': 10, 'time_epoch': 85.34515, 'eta': 7589.55288, 'eta_hours': 2.10821, 'loss': 0.7175472, 'lr': 0.00099318, 'params': 501014, 'time_iter': 0.13655, 'accuracy': 0.74179, 'f1': 0.7418, 'accuracy-SBM': 0.74179, 'auc': 0.94864}
2025-08-27 02:55:41,417 - INFO - val: {'epoch': 10, 'time_epoch': 4.23394, 'loss': 0.69056892, 'lr': 0, 'params': 501014, 'time_iter': 0.06721, 'accuracy': 0.75154, 'f1': 0.75154, 'accuracy-SBM': 0.75146, 'auc': 0.95283}
2025-08-27 02:55:47,436 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 02:55:47,476 - INFO - test: {'epoch': 10, 'time_epoch': 4.48518, 'loss': 0.68374889, 'lr': 0, 'params': 501014, 'time_iter': 0.07119, 'accuracy': 0.75269, 'f1': 0.75271, 'accuracy-SBM': 0.7527, 'auc': 0.9538}
2025-08-27 02:55:47,478 - INFO - > Epoch 10: took 96.0s (avg 96.0s) | Best so far: epoch 9	train_loss: 0.7292 train_accuracy-SBM: 0.7385	val_loss: 0.6939 val_accuracy-SBM: 0.7524	test_loss: 0.6965 test_accuracy-SBM: 0.7496
2025-08-27 02:55:47,478 - INFO - === Epoch 11 ===
2025-08-27 02:57:13,084 - INFO - train: {'epoch': 11, 'time_epoch': 85.35844, 'eta': 7504.88245, 'eta_hours': 2.08469, 'loss': 0.70765426, 'lr': 0.00099019, 'params': 501014, 'time_iter': 0.13657, 'accuracy': 0.7456, 'f1': 0.7456, 'accuracy-SBM': 0.7456, 'auc': 0.95}
2025-08-27 02:57:17,414 - INFO - val: {'epoch': 11, 'time_epoch': 4.27414, 'loss': 0.6871933, 'lr': 0, 'params': 501014, 'time_iter': 0.06784, 'accuracy': 0.75143, 'f1': 0.75117, 'accuracy-SBM': 0.75124, 'auc': 0.95388}
2025-08-27 02:57:23,350 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 02:57:23,393 - INFO - test: {'epoch': 11, 'time_epoch': 4.54841, 'loss': 0.69161445, 'lr': 0, 'params': 501014, 'time_iter': 0.0722, 'accuracy': 0.75115, 'f1': 0.75117, 'accuracy-SBM': 0.75099, 'auc': 0.95304}
2025-08-27 02:57:23,395 - INFO - > Epoch 11: took 95.9s (avg 96.0s) | Best so far: epoch 9	train_loss: 0.7292 train_accuracy-SBM: 0.7385	val_loss: 0.6939 val_accuracy-SBM: 0.7524	test_loss: 0.6965 test_accuracy-SBM: 0.7496
2025-08-27 02:57:23,395 - INFO - === Epoch 12 ===
2025-08-27 02:58:48,594 - INFO - train: {'epoch': 12, 'time_epoch': 84.93924, 'eta': 7417.30076, 'eta_hours': 2.06036, 'loss': 0.69632967, 'lr': 0.00098666, 'params': 501014, 'time_iter': 0.1359, 'accuracy': 0.74935, 'f1': 0.74936, 'accuracy-SBM': 0.74935, 'auc': 0.95157}
2025-08-27 02:58:52,896 - INFO - val: {'epoch': 12, 'time_epoch': 4.25464, 'loss': 0.68185191, 'lr': 0, 'params': 501014, 'time_iter': 0.06753, 'accuracy': 0.75574, 'f1': 0.75554, 'accuracy-SBM': 0.75529, 'auc': 0.95395}
2025-08-27 02:58:58,994 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 02:58:59,034 - INFO - test: {'epoch': 12, 'time_epoch': 4.51914, 'loss': 0.67532423, 'lr': 0, 'params': 501014, 'time_iter': 0.07173, 'accuracy': 0.75514, 'f1': 0.75515, 'accuracy-SBM': 0.75504, 'auc': 0.95508}
2025-08-27 02:58:59,037 - INFO - > Epoch 12: took 95.6s (avg 96.0s) | Best so far: epoch 12	train_loss: 0.6963 train_accuracy-SBM: 0.7493	val_loss: 0.6819 val_accuracy-SBM: 0.7553	test_loss: 0.6753 test_accuracy-SBM: 0.7550
2025-08-27 02:58:59,037 - INFO - === Epoch 13 ===
2025-08-27 03:00:24,428 - INFO - train: {'epoch': 13, 'time_epoch': 85.13115, 'eta': 7331.27545, 'eta_hours': 2.03647, 'loss': 0.68944032, 'lr': 0.0009826, 'params': 501014, 'time_iter': 0.13621, 'accuracy': 0.75124, 'f1': 0.75124, 'accuracy-SBM': 0.75124, 'auc': 0.95252}
2025-08-27 03:00:28,766 - INFO - val: {'epoch': 13, 'time_epoch': 4.28092, 'loss': 0.68749644, 'lr': 0, 'params': 501014, 'time_iter': 0.06795, 'accuracy': 0.75475, 'f1': 0.75478, 'accuracy-SBM': 0.75448, 'auc': 0.95332}
2025-08-27 03:00:36,266 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:00:36,309 - INFO - test: {'epoch': 13, 'time_epoch': 4.58935, 'loss': 0.68321664, 'lr': 0, 'params': 501014, 'time_iter': 0.07285, 'accuracy': 0.75347, 'f1': 0.75352, 'accuracy-SBM': 0.75347, 'auc': 0.9541}
2025-08-27 03:00:36,313 - INFO - > Epoch 13: took 97.3s (avg 96.1s) | Best so far: epoch 12	train_loss: 0.6963 train_accuracy-SBM: 0.7493	val_loss: 0.6819 val_accuracy-SBM: 0.7553	test_loss: 0.6753 test_accuracy-SBM: 0.7550
2025-08-27 03:00:36,313 - INFO - === Epoch 14 ===
2025-08-27 03:02:01,549 - INFO - train: {'epoch': 14, 'time_epoch': 84.98237, 'eta': 7244.52632, 'eta_hours': 2.01237, 'loss': 0.68319316, 'lr': 0.00097802, 'params': 501014, 'time_iter': 0.13597, 'accuracy': 0.75401, 'f1': 0.75401, 'accuracy-SBM': 0.75401, 'auc': 0.95332}
2025-08-27 03:02:05,873 - INFO - val: {'epoch': 14, 'time_epoch': 4.27702, 'loss': 0.67570183, 'lr': 0, 'params': 501014, 'time_iter': 0.06789, 'accuracy': 0.76165, 'f1': 0.76166, 'accuracy-SBM': 0.7617, 'auc': 0.95471}
2025-08-27 03:02:12,003 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:02:12,048 - INFO - test: {'epoch': 14, 'time_epoch': 4.51061, 'loss': 0.6711907, 'lr': 0, 'params': 501014, 'time_iter': 0.0716, 'accuracy': 0.75928, 'f1': 0.75931, 'accuracy-SBM': 0.7594, 'auc': 0.95567}
2025-08-27 03:02:12,050 - INFO - > Epoch 14: took 95.7s (avg 96.1s) | Best so far: epoch 14	train_loss: 0.6832 train_accuracy-SBM: 0.7540	val_loss: 0.6757 val_accuracy-SBM: 0.7617	test_loss: 0.6712 test_accuracy-SBM: 0.7594
2025-08-27 03:02:12,051 - INFO - === Epoch 15 ===
2025-08-27 03:03:37,636 - INFO - train: {'epoch': 15, 'time_epoch': 85.32962, 'eta': 7159.82106, 'eta_hours': 1.98884, 'loss': 0.67585416, 'lr': 0.00097291, 'params': 501014, 'time_iter': 0.13653, 'accuracy': 0.75584, 'f1': 0.75584, 'accuracy-SBM': 0.75584, 'auc': 0.95434}
2025-08-27 03:03:41,957 - INFO - val: {'epoch': 15, 'time_epoch': 4.27437, 'loss': 0.69275669, 'lr': 0, 'params': 501014, 'time_iter': 0.06785, 'accuracy': 0.75142, 'f1': 0.75105, 'accuracy-SBM': 0.75131, 'auc': 0.9525}
2025-08-27 03:03:49,228 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:03:49,269 - INFO - test: {'epoch': 15, 'time_epoch': 4.44545, 'loss': 0.68599506, 'lr': 0, 'params': 501014, 'time_iter': 0.07056, 'accuracy': 0.75171, 'f1': 0.75139, 'accuracy-SBM': 0.75182, 'auc': 0.9533}
2025-08-27 03:03:49,271 - INFO - > Epoch 15: took 97.2s (avg 96.1s) | Best so far: epoch 14	train_loss: 0.6832 train_accuracy-SBM: 0.7540	val_loss: 0.6757 val_accuracy-SBM: 0.7617	test_loss: 0.6712 test_accuracy-SBM: 0.7594
2025-08-27 03:03:49,271 - INFO - === Epoch 16 ===
2025-08-27 03:05:14,141 - INFO - train: {'epoch': 16, 'time_epoch': 84.6098, 'eta': 7071.52796, 'eta_hours': 1.96431, 'loss': 0.67193578, 'lr': 0.00096728, 'params': 501014, 'time_iter': 0.13538, 'accuracy': 0.75743, 'f1': 0.75743, 'accuracy-SBM': 0.75744, 'auc': 0.95484}
2025-08-27 03:05:18,444 - INFO - val: {'epoch': 16, 'time_epoch': 4.23961, 'loss': 0.65438412, 'lr': 0, 'params': 501014, 'time_iter': 0.0673, 'accuracy': 0.76413, 'f1': 0.76418, 'accuracy-SBM': 0.7643, 'auc': 0.95744}
2025-08-27 03:05:24,472 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:05:24,512 - INFO - test: {'epoch': 16, 'time_epoch': 4.50532, 'loss': 0.64619439, 'lr': 0, 'params': 501014, 'time_iter': 0.07151, 'accuracy': 0.7674, 'f1': 0.7674, 'accuracy-SBM': 0.76749, 'auc': 0.95849}
2025-08-27 03:05:24,514 - INFO - > Epoch 16: took 95.2s (avg 96.1s) | Best so far: epoch 16	train_loss: 0.6719 train_accuracy-SBM: 0.7574	val_loss: 0.6544 val_accuracy-SBM: 0.7643	test_loss: 0.6462 test_accuracy-SBM: 0.7675
2025-08-27 03:05:24,514 - INFO - === Epoch 17 ===
2025-08-27 03:06:50,419 - INFO - train: {'epoch': 17, 'time_epoch': 85.54826, 'eta': 6987.91928, 'eta_hours': 1.94109, 'loss': 0.66569631, 'lr': 0.00096114, 'params': 501014, 'time_iter': 0.13688, 'accuracy': 0.75937, 'f1': 0.75937, 'accuracy-SBM': 0.75937, 'auc': 0.95567}
2025-08-27 03:06:54,731 - INFO - val: {'epoch': 17, 'time_epoch': 4.26483, 'loss': 0.65715364, 'lr': 0, 'params': 501014, 'time_iter': 0.0677, 'accuracy': 0.76603, 'f1': 0.76611, 'accuracy-SBM': 0.76608, 'auc': 0.95751}
2025-08-27 03:07:00,879 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:07:00,928 - INFO - test: {'epoch': 17, 'time_epoch': 4.59046, 'loss': 0.65028513, 'lr': 0, 'params': 501014, 'time_iter': 0.07286, 'accuracy': 0.76408, 'f1': 0.76411, 'accuracy-SBM': 0.76415, 'auc': 0.95849}
2025-08-27 03:07:00,930 - INFO - > Epoch 17: took 96.4s (avg 96.1s) | Best so far: epoch 17	train_loss: 0.6657 train_accuracy-SBM: 0.7594	val_loss: 0.6572 val_accuracy-SBM: 0.7661	test_loss: 0.6503 test_accuracy-SBM: 0.7641
2025-08-27 03:07:00,930 - INFO - === Epoch 18 ===
2025-08-27 03:08:25,963 - INFO - train: {'epoch': 18, 'time_epoch': 84.76537, 'eta': 6900.76887, 'eta_hours': 1.91688, 'loss': 0.66141491, 'lr': 0.0009545, 'params': 501014, 'time_iter': 0.13562, 'accuracy': 0.76121, 'f1': 0.7612, 'accuracy-SBM': 0.76121, 'auc': 0.95622}
2025-08-27 03:08:30,253 - INFO - val: {'epoch': 18, 'time_epoch': 4.24097, 'loss': 0.65051297, 'lr': 0, 'params': 501014, 'time_iter': 0.06732, 'accuracy': 0.76712, 'f1': 0.76728, 'accuracy-SBM': 0.7672, 'auc': 0.95789}
2025-08-27 03:08:36,343 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:08:36,384 - INFO - test: {'epoch': 18, 'time_epoch': 4.51341, 'loss': 0.64850375, 'lr': 0, 'params': 501014, 'time_iter': 0.07164, 'accuracy': 0.76722, 'f1': 0.76728, 'accuracy-SBM': 0.76737, 'auc': 0.95813}
2025-08-27 03:08:36,386 - INFO - > Epoch 18: took 95.5s (avg 96.1s) | Best so far: epoch 18	train_loss: 0.6614 train_accuracy-SBM: 0.7612	val_loss: 0.6505 val_accuracy-SBM: 0.7672	test_loss: 0.6485 test_accuracy-SBM: 0.7674
2025-08-27 03:08:36,386 - INFO - === Epoch 19 ===
2025-08-27 03:10:01,965 - INFO - train: {'epoch': 19, 'time_epoch': 85.29458, 'eta': 6815.97382, 'eta_hours': 1.89333, 'loss': 0.65950593, 'lr': 0.00094736, 'params': 501014, 'time_iter': 0.13647, 'accuracy': 0.76215, 'f1': 0.76215, 'accuracy-SBM': 0.76215, 'auc': 0.95645}
2025-08-27 03:10:06,249 - INFO - val: {'epoch': 19, 'time_epoch': 4.23767, 'loss': 0.66321952, 'lr': 0, 'params': 501014, 'time_iter': 0.06726, 'accuracy': 0.76229, 'f1': 0.76219, 'accuracy-SBM': 0.7621, 'auc': 0.95638}
2025-08-27 03:10:15,267 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:10:15,309 - INFO - test: {'epoch': 19, 'time_epoch': 4.51554, 'loss': 0.65873743, 'lr': 0, 'params': 501014, 'time_iter': 0.07168, 'accuracy': 0.76125, 'f1': 0.76127, 'accuracy-SBM': 0.76113, 'auc': 0.95714}
2025-08-27 03:10:15,311 - INFO - > Epoch 19: took 98.9s (avg 96.2s) | Best so far: epoch 18	train_loss: 0.6614 train_accuracy-SBM: 0.7612	val_loss: 0.6505 val_accuracy-SBM: 0.7672	test_loss: 0.6485 test_accuracy-SBM: 0.7674
2025-08-27 03:10:15,311 - INFO - === Epoch 20 ===
2025-08-27 03:11:40,799 - INFO - train: {'epoch': 20, 'time_epoch': 84.91706, 'eta': 6729.71098, 'eta_hours': 1.86936, 'loss': 0.65291544, 'lr': 0.00093974, 'params': 501014, 'time_iter': 0.13587, 'accuracy': 0.76499, 'f1': 0.76499, 'accuracy-SBM': 0.76499, 'auc': 0.95731}
2025-08-27 03:11:45,100 - INFO - val: {'epoch': 20, 'time_epoch': 4.25435, 'loss': 0.66060739, 'lr': 0, 'params': 501014, 'time_iter': 0.06753, 'accuracy': 0.76351, 'f1': 0.76354, 'accuracy-SBM': 0.76351, 'auc': 0.95674}
2025-08-27 03:11:50,807 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:11:50,850 - INFO - test: {'epoch': 20, 'time_epoch': 4.29363, 'loss': 0.65754554, 'lr': 0, 'params': 501014, 'time_iter': 0.06815, 'accuracy': 0.76292, 'f1': 0.76294, 'accuracy-SBM': 0.76291, 'auc': 0.95713}
2025-08-27 03:11:50,852 - INFO - > Epoch 20: took 95.5s (avg 96.2s) | Best so far: epoch 18	train_loss: 0.6614 train_accuracy-SBM: 0.7612	val_loss: 0.6505 val_accuracy-SBM: 0.7672	test_loss: 0.6485 test_accuracy-SBM: 0.7674
2025-08-27 03:11:50,852 - INFO - === Epoch 21 ===
2025-08-27 03:13:16,397 - INFO - train: {'epoch': 21, 'time_epoch': 85.17958, 'eta': 6644.50123, 'eta_hours': 1.84569, 'loss': 0.65203474, 'lr': 0.00093163, 'params': 501014, 'time_iter': 0.13629, 'accuracy': 0.76423, 'f1': 0.76423, 'accuracy-SBM': 0.76423, 'auc': 0.95748}
2025-08-27 03:13:20,762 - INFO - val: {'epoch': 21, 'time_epoch': 4.31682, 'loss': 0.66639191, 'lr': 0, 'params': 501014, 'time_iter': 0.06852, 'accuracy': 0.76266, 'f1': 0.7627, 'accuracy-SBM': 0.76273, 'auc': 0.95649}
2025-08-27 03:13:26,855 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:13:26,904 - INFO - test: {'epoch': 21, 'time_epoch': 4.58395, 'loss': 0.6547544, 'lr': 0, 'params': 501014, 'time_iter': 0.07276, 'accuracy': 0.766, 'f1': 0.76593, 'accuracy-SBM': 0.7659, 'auc': 0.95786}
2025-08-27 03:13:26,906 - INFO - > Epoch 21: took 96.1s (avg 96.2s) | Best so far: epoch 18	train_loss: 0.6614 train_accuracy-SBM: 0.7612	val_loss: 0.6505 val_accuracy-SBM: 0.7672	test_loss: 0.6485 test_accuracy-SBM: 0.7674
2025-08-27 03:13:26,906 - INFO - === Epoch 22 ===
2025-08-27 03:14:53,401 - INFO - train: {'epoch': 22, 'time_epoch': 86.04113, 'eta': 6562.17843, 'eta_hours': 1.82283, 'loss': 0.64412306, 'lr': 0.00092305, 'params': 501014, 'time_iter': 0.13767, 'accuracy': 0.76741, 'f1': 0.76741, 'accuracy-SBM': 0.76741, 'auc': 0.95843}
2025-08-27 03:14:57,622 - INFO - val: {'epoch': 22, 'time_epoch': 4.17383, 'loss': 0.65242082, 'lr': 0, 'params': 501014, 'time_iter': 0.06625, 'accuracy': 0.76988, 'f1': 0.76978, 'accuracy-SBM': 0.76981, 'auc': 0.95789}
2025-08-27 03:15:03,691 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:15:03,739 - INFO - test: {'epoch': 22, 'time_epoch': 4.53772, 'loss': 0.65217002, 'lr': 0, 'params': 501014, 'time_iter': 0.07203, 'accuracy': 0.76776, 'f1': 0.76778, 'accuracy-SBM': 0.76772, 'auc': 0.958}
2025-08-27 03:15:03,767 - INFO - > Epoch 22: took 96.9s (avg 96.2s) | Best so far: epoch 22	train_loss: 0.6441 train_accuracy-SBM: 0.7674	val_loss: 0.6524 val_accuracy-SBM: 0.7698	test_loss: 0.6522 test_accuracy-SBM: 0.7677
2025-08-27 03:15:03,767 - INFO - === Epoch 23 ===
2025-08-27 03:16:28,687 - INFO - train: {'epoch': 23, 'time_epoch': 84.66685, 'eta': 6475.19388, 'eta_hours': 1.79866, 'loss': 0.64204494, 'lr': 0.000914, 'params': 501014, 'time_iter': 0.13547, 'accuracy': 0.76804, 'f1': 0.76804, 'accuracy-SBM': 0.76804, 'auc': 0.95873}
2025-08-27 03:16:33,001 - INFO - val: {'epoch': 23, 'time_epoch': 4.26595, 'loss': 0.6374822, 'lr': 0, 'params': 501014, 'time_iter': 0.06771, 'accuracy': 0.7731, 'f1': 0.77284, 'accuracy-SBM': 0.77287, 'auc': 0.95944}
2025-08-27 03:16:38,975 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:16:39,016 - INFO - test: {'epoch': 23, 'time_epoch': 4.52199, 'loss': 0.63234776, 'lr': 0, 'params': 501014, 'time_iter': 0.07178, 'accuracy': 0.77124, 'f1': 0.7712, 'accuracy-SBM': 0.7712, 'auc': 0.96025}
2025-08-27 03:16:39,018 - INFO - > Epoch 23: took 95.3s (avg 96.2s) | Best so far: epoch 23	train_loss: 0.6420 train_accuracy-SBM: 0.7680	val_loss: 0.6375 val_accuracy-SBM: 0.7729	test_loss: 0.6323 test_accuracy-SBM: 0.7712
2025-08-27 03:16:39,018 - INFO - === Epoch 24 ===
2025-08-27 03:18:04,544 - INFO - train: {'epoch': 24, 'time_epoch': 85.26764, 'eta': 6390.19713, 'eta_hours': 1.77505, 'loss': 0.63934158, 'lr': 0.00090451, 'params': 501014, 'time_iter': 0.13643, 'accuracy': 0.76924, 'f1': 0.76924, 'accuracy-SBM': 0.76924, 'auc': 0.95907}
2025-08-27 03:18:08,793 - INFO - val: {'epoch': 24, 'time_epoch': 4.20238, 'loss': 0.63874269, 'lr': 0, 'params': 501014, 'time_iter': 0.0667, 'accuracy': 0.76784, 'f1': 0.7678, 'accuracy-SBM': 0.76774, 'auc': 0.95928}
2025-08-27 03:18:14,686 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:18:14,725 - INFO - test: {'epoch': 24, 'time_epoch': 4.4761, 'loss': 0.64152191, 'lr': 0, 'params': 501014, 'time_iter': 0.07105, 'accuracy': 0.77026, 'f1': 0.77029, 'accuracy-SBM': 0.77031, 'auc': 0.95887}
2025-08-27 03:18:14,727 - INFO - > Epoch 24: took 95.7s (avg 96.1s) | Best so far: epoch 23	train_loss: 0.6420 train_accuracy-SBM: 0.7680	val_loss: 0.6375 val_accuracy-SBM: 0.7729	test_loss: 0.6323 test_accuracy-SBM: 0.7712
2025-08-27 03:18:14,727 - INFO - === Epoch 25 ===
2025-08-27 03:19:39,962 - INFO - train: {'epoch': 25, 'time_epoch': 84.75696, 'eta': 6303.72607, 'eta_hours': 1.75104, 'loss': 0.63661726, 'lr': 0.00089457, 'params': 501014, 'time_iter': 0.13561, 'accuracy': 0.77006, 'f1': 0.77006, 'accuracy-SBM': 0.77007, 'auc': 0.95944}
2025-08-27 03:19:44,252 - INFO - val: {'epoch': 25, 'time_epoch': 4.2432, 'loss': 0.62633163, 'lr': 0, 'params': 501014, 'time_iter': 0.06735, 'accuracy': 0.77524, 'f1': 0.77514, 'accuracy-SBM': 0.77509, 'auc': 0.96077}
2025-08-27 03:19:50,122 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:19:50,162 - INFO - test: {'epoch': 25, 'time_epoch': 4.53978, 'loss': 0.63486778, 'lr': 0, 'params': 501014, 'time_iter': 0.07206, 'accuracy': 0.77263, 'f1': 0.77258, 'accuracy-SBM': 0.77259, 'auc': 0.95965}
2025-08-27 03:19:50,164 - INFO - > Epoch 25: took 95.4s (avg 96.1s) | Best so far: epoch 25	train_loss: 0.6366 train_accuracy-SBM: 0.7701	val_loss: 0.6263 val_accuracy-SBM: 0.7751	test_loss: 0.6349 test_accuracy-SBM: 0.7726
2025-08-27 03:19:50,164 - INFO - === Epoch 26 ===
2025-08-27 03:21:16,717 - INFO - train: {'epoch': 26, 'time_epoch': 85.98275, 'eta': 6220.69615, 'eta_hours': 1.72797, 'loss': 0.63300392, 'lr': 0.0008842, 'params': 501014, 'time_iter': 0.13757, 'accuracy': 0.77146, 'f1': 0.77146, 'accuracy-SBM': 0.77146, 'auc': 0.95991}
2025-08-27 03:21:21,081 - INFO - val: {'epoch': 26, 'time_epoch': 4.30751, 'loss': 0.64566711, 'lr': 0, 'params': 501014, 'time_iter': 0.06837, 'accuracy': 0.77173, 'f1': 0.77161, 'accuracy-SBM': 0.77163, 'auc': 0.95842}
2025-08-27 03:21:26,958 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:21:27,006 - INFO - test: {'epoch': 26, 'time_epoch': 4.5749, 'loss': 0.64023403, 'lr': 0, 'params': 501014, 'time_iter': 0.07262, 'accuracy': 0.76928, 'f1': 0.76927, 'accuracy-SBM': 0.76922, 'auc': 0.95938}
2025-08-27 03:21:27,009 - INFO - > Epoch 26: took 96.8s (avg 96.1s) | Best so far: epoch 25	train_loss: 0.6366 train_accuracy-SBM: 0.7701	val_loss: 0.6263 val_accuracy-SBM: 0.7751	test_loss: 0.6349 test_accuracy-SBM: 0.7726
2025-08-27 03:21:27,009 - INFO - === Epoch 27 ===
2025-08-27 03:22:52,385 - INFO - train: {'epoch': 27, 'time_epoch': 85.12969, 'eta': 6135.26173, 'eta_hours': 1.70424, 'loss': 0.62824898, 'lr': 0.00087341, 'params': 501014, 'time_iter': 0.13621, 'accuracy': 0.77264, 'f1': 0.77264, 'accuracy-SBM': 0.77265, 'auc': 0.96048}
2025-08-27 03:22:56,705 - INFO - val: {'epoch': 27, 'time_epoch': 4.27291, 'loss': 0.64151811, 'lr': 0, 'params': 501014, 'time_iter': 0.06782, 'accuracy': 0.77293, 'f1': 0.77288, 'accuracy-SBM': 0.7729, 'auc': 0.95901}
2025-08-27 03:23:02,251 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:23:02,290 - INFO - test: {'epoch': 27, 'time_epoch': 4.21126, 'loss': 0.63449385, 'lr': 0, 'params': 501014, 'time_iter': 0.06685, 'accuracy': 0.77374, 'f1': 0.77372, 'accuracy-SBM': 0.77374, 'auc': 0.9599}
2025-08-27 03:23:02,292 - INFO - > Epoch 27: took 95.3s (avg 96.1s) | Best so far: epoch 25	train_loss: 0.6366 train_accuracy-SBM: 0.7701	val_loss: 0.6263 val_accuracy-SBM: 0.7751	test_loss: 0.6349 test_accuracy-SBM: 0.7726
2025-08-27 03:23:02,292 - INFO - === Epoch 28 ===
2025-08-27 03:24:27,942 - INFO - train: {'epoch': 28, 'time_epoch': 85.38563, 'eta': 6050.47494, 'eta_hours': 1.68069, 'loss': 0.62618987, 'lr': 0.00086221, 'params': 501014, 'time_iter': 0.13662, 'accuracy': 0.7734, 'f1': 0.7734, 'accuracy-SBM': 0.7734, 'auc': 0.96073}
2025-08-27 03:24:32,343 - INFO - val: {'epoch': 28, 'time_epoch': 4.3557, 'loss': 0.63285967, 'lr': 0, 'params': 501014, 'time_iter': 0.06914, 'accuracy': 0.77379, 'f1': 0.77382, 'accuracy-SBM': 0.77381, 'auc': 0.96}
2025-08-27 03:24:38,322 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:24:38,367 - INFO - test: {'epoch': 28, 'time_epoch': 4.63362, 'loss': 0.62082437, 'lr': 0, 'params': 501014, 'time_iter': 0.07355, 'accuracy': 0.77637, 'f1': 0.77636, 'accuracy-SBM': 0.77642, 'auc': 0.96156}
2025-08-27 03:24:38,369 - INFO - > Epoch 28: took 96.1s (avg 96.1s) | Best so far: epoch 25	train_loss: 0.6366 train_accuracy-SBM: 0.7701	val_loss: 0.6263 val_accuracy-SBM: 0.7751	test_loss: 0.6349 test_accuracy-SBM: 0.7726
2025-08-27 03:24:38,369 - INFO - === Epoch 29 ===
2025-08-27 03:26:03,935 - INFO - train: {'epoch': 29, 'time_epoch': 85.3116, 'eta': 5965.47548, 'eta_hours': 1.65708, 'loss': 0.62474999, 'lr': 0.00085062, 'params': 501014, 'time_iter': 0.1365, 'accuracy': 0.77415, 'f1': 0.77415, 'accuracy-SBM': 0.77415, 'auc': 0.96093}
2025-08-27 03:26:08,163 - INFO - val: {'epoch': 29, 'time_epoch': 4.18255, 'loss': 0.62449626, 'lr': 0, 'params': 501014, 'time_iter': 0.06639, 'accuracy': 0.77654, 'f1': 0.77656, 'accuracy-SBM': 0.77659, 'auc': 0.9612}
2025-08-27 03:26:13,945 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:26:13,985 - INFO - test: {'epoch': 29, 'time_epoch': 4.47032, 'loss': 0.63263952, 'lr': 0, 'params': 501014, 'time_iter': 0.07096, 'accuracy': 0.7708, 'f1': 0.77087, 'accuracy-SBM': 0.77092, 'auc': 0.96031}
2025-08-27 03:26:13,987 - INFO - > Epoch 29: took 95.6s (avg 96.1s) | Best so far: epoch 29	train_loss: 0.6247 train_accuracy-SBM: 0.7742	val_loss: 0.6245 val_accuracy-SBM: 0.7766	test_loss: 0.6326 test_accuracy-SBM: 0.7709
2025-08-27 03:26:13,987 - INFO - === Epoch 30 ===
2025-08-27 03:27:39,036 - INFO - train: {'epoch': 30, 'time_epoch': 84.79948, 'eta': 5879.316, 'eta_hours': 1.63314, 'loss': 0.61899616, 'lr': 0.00083864, 'params': 501014, 'time_iter': 0.13568, 'accuracy': 0.77609, 'f1': 0.77609, 'accuracy-SBM': 0.77609, 'auc': 0.96163}
2025-08-27 03:27:43,345 - INFO - val: {'epoch': 30, 'time_epoch': 4.26208, 'loss': 0.63563444, 'lr': 0, 'params': 501014, 'time_iter': 0.06765, 'accuracy': 0.77444, 'f1': 0.77442, 'accuracy-SBM': 0.77433, 'auc': 0.95993}
2025-08-27 03:27:49,413 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:27:49,453 - INFO - test: {'epoch': 30, 'time_epoch': 4.55023, 'loss': 0.6267969, 'lr': 0, 'params': 501014, 'time_iter': 0.07223, 'accuracy': 0.77717, 'f1': 0.77713, 'accuracy-SBM': 0.77714, 'auc': 0.96094}
2025-08-27 03:27:49,455 - INFO - > Epoch 30: took 95.5s (avg 96.1s) | Best so far: epoch 29	train_loss: 0.6247 train_accuracy-SBM: 0.7742	val_loss: 0.6245 val_accuracy-SBM: 0.7766	test_loss: 0.6326 test_accuracy-SBM: 0.7709
2025-08-27 03:27:49,455 - INFO - === Epoch 31 ===
2025-08-27 03:29:14,464 - INFO - train: {'epoch': 31, 'time_epoch': 84.76576, 'eta': 5793.16986, 'eta_hours': 1.60921, 'loss': 0.61472136, 'lr': 0.00082629, 'params': 501014, 'time_iter': 0.13563, 'accuracy': 0.77768, 'f1': 0.77768, 'accuracy-SBM': 0.77768, 'auc': 0.96217}
2025-08-27 03:29:18,726 - INFO - val: {'epoch': 31, 'time_epoch': 4.2126, 'loss': 0.63909217, 'lr': 0, 'params': 501014, 'time_iter': 0.06687, 'accuracy': 0.77432, 'f1': 0.77432, 'accuracy-SBM': 0.7744, 'auc': 0.9596}
2025-08-27 03:29:24,772 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:29:24,819 - INFO - test: {'epoch': 31, 'time_epoch': 4.56376, 'loss': 0.63392966, 'lr': 0, 'params': 501014, 'time_iter': 0.07244, 'accuracy': 0.77212, 'f1': 0.7722, 'accuracy-SBM': 0.77212, 'auc': 0.9604}
2025-08-27 03:29:24,821 - INFO - > Epoch 31: took 95.4s (avg 96.1s) | Best so far: epoch 29	train_loss: 0.6247 train_accuracy-SBM: 0.7742	val_loss: 0.6245 val_accuracy-SBM: 0.7766	test_loss: 0.6326 test_accuracy-SBM: 0.7709
2025-08-27 03:29:24,821 - INFO - === Epoch 32 ===
2025-08-27 03:30:49,800 - INFO - train: {'epoch': 32, 'time_epoch': 84.72685, 'eta': 5707.02839, 'eta_hours': 1.58529, 'loss': 0.61340106, 'lr': 0.00081359, 'params': 501014, 'time_iter': 0.13556, 'accuracy': 0.7781, 'f1': 0.7781, 'accuracy-SBM': 0.7781, 'auc': 0.96232}
2025-08-27 03:30:54,031 - INFO - val: {'epoch': 32, 'time_epoch': 4.18551, 'loss': 0.63225559, 'lr': 0, 'params': 501014, 'time_iter': 0.06644, 'accuracy': 0.77532, 'f1': 0.77523, 'accuracy-SBM': 0.77511, 'auc': 0.95997}
2025-08-27 03:31:06,111 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:31:06,154 - INFO - test: {'epoch': 32, 'time_epoch': 4.41577, 'loss': 0.63388685, 'lr': 0, 'params': 501014, 'time_iter': 0.07009, 'accuracy': 0.77194, 'f1': 0.7719, 'accuracy-SBM': 0.77191, 'auc': 0.95992}
2025-08-27 03:31:06,156 - INFO - > Epoch 32: took 101.3s (avg 96.2s) | Best so far: epoch 29	train_loss: 0.6247 train_accuracy-SBM: 0.7742	val_loss: 0.6245 val_accuracy-SBM: 0.7766	test_loss: 0.6326 test_accuracy-SBM: 0.7709
2025-08-27 03:31:06,156 - INFO - === Epoch 33 ===
2025-08-27 03:32:31,586 - INFO - train: {'epoch': 33, 'time_epoch': 85.17639, 'eta': 5621.84277, 'eta_hours': 1.56162, 'loss': 0.61094605, 'lr': 0.00080054, 'params': 501014, 'time_iter': 0.13628, 'accuracy': 0.77878, 'f1': 0.77878, 'accuracy-SBM': 0.77878, 'auc': 0.96262}
2025-08-27 03:32:35,893 - INFO - val: {'epoch': 33, 'time_epoch': 4.26091, 'loss': 0.63463473, 'lr': 0, 'params': 501014, 'time_iter': 0.06763, 'accuracy': 0.77365, 'f1': 0.77359, 'accuracy-SBM': 0.77362, 'auc': 0.96008}
2025-08-27 03:32:41,723 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:32:41,764 - INFO - test: {'epoch': 33, 'time_epoch': 4.47185, 'loss': 0.62981312, 'lr': 0, 'params': 501014, 'time_iter': 0.07098, 'accuracy': 0.77517, 'f1': 0.77514, 'accuracy-SBM': 0.77516, 'auc': 0.96056}
2025-08-27 03:32:41,766 - INFO - > Epoch 33: took 95.6s (avg 96.2s) | Best so far: epoch 29	train_loss: 0.6247 train_accuracy-SBM: 0.7742	val_loss: 0.6245 val_accuracy-SBM: 0.7766	test_loss: 0.6326 test_accuracy-SBM: 0.7709
2025-08-27 03:32:41,766 - INFO - === Epoch 34 ===
2025-08-27 03:34:06,917 - INFO - train: {'epoch': 34, 'time_epoch': 84.89324, 'eta': 5536.13183, 'eta_hours': 1.53781, 'loss': 0.60964122, 'lr': 0.00078716, 'params': 501014, 'time_iter': 0.13583, 'accuracy': 0.77958, 'f1': 0.77958, 'accuracy-SBM': 0.77958, 'auc': 0.96278}
2025-08-27 03:34:11,258 - INFO - val: {'epoch': 34, 'time_epoch': 4.29234, 'loss': 0.64458156, 'lr': 0, 'params': 501014, 'time_iter': 0.06813, 'accuracy': 0.77158, 'f1': 0.77152, 'accuracy-SBM': 0.77156, 'auc': 0.95866}
2025-08-27 03:34:17,214 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:34:17,254 - INFO - test: {'epoch': 34, 'time_epoch': 4.54075, 'loss': 0.62496584, 'lr': 0, 'params': 501014, 'time_iter': 0.07208, 'accuracy': 0.77544, 'f1': 0.77536, 'accuracy-SBM': 0.77535, 'auc': 0.96117}
2025-08-27 03:34:17,256 - INFO - > Epoch 34: took 95.5s (avg 96.2s) | Best so far: epoch 29	train_loss: 0.6247 train_accuracy-SBM: 0.7742	val_loss: 0.6245 val_accuracy-SBM: 0.7766	test_loss: 0.6326 test_accuracy-SBM: 0.7709
2025-08-27 03:34:17,256 - INFO - === Epoch 35 ===
2025-08-27 03:35:42,677 - INFO - train: {'epoch': 35, 'time_epoch': 84.97777, 'eta': 5450.61659, 'eta_hours': 1.51406, 'loss': 0.60427168, 'lr': 0.00077347, 'params': 501014, 'time_iter': 0.13596, 'accuracy': 0.78112, 'f1': 0.78112, 'accuracy-SBM': 0.78112, 'auc': 0.96344}
2025-08-27 03:35:46,980 - INFO - val: {'epoch': 35, 'time_epoch': 4.25445, 'loss': 0.62561211, 'lr': 0, 'params': 501014, 'time_iter': 0.06753, 'accuracy': 0.77761, 'f1': 0.77758, 'accuracy-SBM': 0.77755, 'auc': 0.96126}
2025-08-27 03:35:53,000 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:35:53,039 - INFO - test: {'epoch': 35, 'time_epoch': 4.29922, 'loss': 0.63169025, 'lr': 0, 'params': 501014, 'time_iter': 0.06824, 'accuracy': 0.77379, 'f1': 0.77377, 'accuracy-SBM': 0.7738, 'auc': 0.96043}
2025-08-27 03:35:53,041 - INFO - > Epoch 35: took 95.8s (avg 96.2s) | Best so far: epoch 35	train_loss: 0.6043 train_accuracy-SBM: 0.7811	val_loss: 0.6256 val_accuracy-SBM: 0.7775	test_loss: 0.6317 test_accuracy-SBM: 0.7738
2025-08-27 03:35:53,041 - INFO - === Epoch 36 ===
2025-08-27 03:37:18,121 - INFO - train: {'epoch': 36, 'time_epoch': 84.81615, 'eta': 5364.85521, 'eta_hours': 1.49024, 'loss': 0.60267165, 'lr': 0.00075948, 'params': 501014, 'time_iter': 0.13571, 'accuracy': 0.78175, 'f1': 0.78175, 'accuracy-SBM': 0.78175, 'auc': 0.96363}
2025-08-27 03:37:22,456 - INFO - val: {'epoch': 36, 'time_epoch': 4.28755, 'loss': 0.63772475, 'lr': 0, 'params': 501014, 'time_iter': 0.06806, 'accuracy': 0.77269, 'f1': 0.77251, 'accuracy-SBM': 0.77244, 'auc': 0.95969}
2025-08-27 03:37:28,482 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:37:28,522 - INFO - test: {'epoch': 36, 'time_epoch': 4.53142, 'loss': 0.62239868, 'lr': 0, 'params': 501014, 'time_iter': 0.07193, 'accuracy': 0.77408, 'f1': 0.77388, 'accuracy-SBM': 0.77392, 'auc': 0.9616}
2025-08-27 03:37:28,524 - INFO - > Epoch 36: took 95.5s (avg 96.1s) | Best so far: epoch 35	train_loss: 0.6043 train_accuracy-SBM: 0.7811	val_loss: 0.6256 val_accuracy-SBM: 0.7775	test_loss: 0.6317 test_accuracy-SBM: 0.7738
2025-08-27 03:37:28,524 - INFO - === Epoch 37 ===
2025-08-27 03:38:53,657 - INFO - train: {'epoch': 37, 'time_epoch': 84.8676, 'eta': 5279.22752, 'eta_hours': 1.46645, 'loss': 0.59951406, 'lr': 0.00074521, 'params': 501014, 'time_iter': 0.13579, 'accuracy': 0.78219, 'f1': 0.78219, 'accuracy-SBM': 0.78219, 'auc': 0.96404}
2025-08-27 03:38:57,996 - INFO - val: {'epoch': 37, 'time_epoch': 4.29119, 'loss': 0.62656369, 'lr': 0, 'params': 501014, 'time_iter': 0.06811, 'accuracy': 0.77609, 'f1': 0.77581, 'accuracy-SBM': 0.7758, 'auc': 0.96102}
2025-08-27 03:39:04,437 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:39:04,476 - INFO - test: {'epoch': 37, 'time_epoch': 4.47417, 'loss': 0.62847945, 'lr': 0, 'params': 501014, 'time_iter': 0.07102, 'accuracy': 0.77407, 'f1': 0.774, 'accuracy-SBM': 0.77402, 'auc': 0.96096}
2025-08-27 03:39:04,478 - INFO - > Epoch 37: took 96.0s (avg 96.1s) | Best so far: epoch 35	train_loss: 0.6043 train_accuracy-SBM: 0.7811	val_loss: 0.6256 val_accuracy-SBM: 0.7775	test_loss: 0.6317 test_accuracy-SBM: 0.7738
2025-08-27 03:39:04,478 - INFO - === Epoch 38 ===
2025-08-27 03:40:28,089 - INFO - train: {'epoch': 38, 'time_epoch': 83.25504, 'eta': 5191.11661, 'eta_hours': 1.44198, 'loss': 0.59371737, 'lr': 0.00073067, 'params': 501014, 'time_iter': 0.13321, 'accuracy': 0.78414, 'f1': 0.78414, 'accuracy-SBM': 0.78414, 'auc': 0.96473}
2025-08-27 03:40:32,333 - INFO - val: {'epoch': 38, 'time_epoch': 4.18867, 'loss': 0.61729234, 'lr': 0, 'params': 501014, 'time_iter': 0.06649, 'accuracy': 0.77864, 'f1': 0.77854, 'accuracy-SBM': 0.77865, 'auc': 0.96204}
2025-08-27 03:40:39,139 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:40:39,179 - INFO - test: {'epoch': 38, 'time_epoch': 4.17054, 'loss': 0.61920225, 'lr': 0, 'params': 501014, 'time_iter': 0.0662, 'accuracy': 0.77869, 'f1': 0.77869, 'accuracy-SBM': 0.7787, 'auc': 0.96182}
2025-08-27 03:40:39,182 - INFO - > Epoch 38: took 94.7s (avg 96.1s) | Best so far: epoch 38	train_loss: 0.5937 train_accuracy-SBM: 0.7841	val_loss: 0.6173 val_accuracy-SBM: 0.7786	test_loss: 0.6192 test_accuracy-SBM: 0.7787
2025-08-27 03:40:39,182 - INFO - === Epoch 39 ===
2025-08-27 03:42:02,684 - INFO - train: {'epoch': 39, 'time_epoch': 83.24949, 'eta': 5103.24017, 'eta_hours': 1.41757, 'loss': 0.59573218, 'lr': 0.00071588, 'params': 501014, 'time_iter': 0.1332, 'accuracy': 0.78433, 'f1': 0.78433, 'accuracy-SBM': 0.78433, 'auc': 0.96446}
2025-08-27 03:42:06,942 - INFO - val: {'epoch': 39, 'time_epoch': 4.20954, 'loss': 0.61888945, 'lr': 0, 'params': 501014, 'time_iter': 0.06682, 'accuracy': 0.77802, 'f1': 0.77786, 'accuracy-SBM': 0.77789, 'auc': 0.96189}
2025-08-27 03:42:13,367 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:42:13,406 - INFO - test: {'epoch': 39, 'time_epoch': 4.39403, 'loss': 0.61651203, 'lr': 0, 'params': 501014, 'time_iter': 0.06975, 'accuracy': 0.77794, 'f1': 0.77788, 'accuracy-SBM': 0.77781, 'auc': 0.96214}
2025-08-27 03:42:13,408 - INFO - > Epoch 39: took 94.2s (avg 96.1s) | Best so far: epoch 38	train_loss: 0.5937 train_accuracy-SBM: 0.7841	val_loss: 0.6173 val_accuracy-SBM: 0.7786	test_loss: 0.6192 test_accuracy-SBM: 0.7787
2025-08-27 03:42:13,408 - INFO - === Epoch 40 ===
2025-08-27 03:43:37,628 - INFO - train: {'epoch': 40, 'time_epoch': 83.96047, 'eta': 5016.61255, 'eta_hours': 1.3935, 'loss': 0.59090174, 'lr': 0.00070085, 'params': 501014, 'time_iter': 0.13434, 'accuracy': 0.78641, 'f1': 0.78641, 'accuracy-SBM': 0.78641, 'auc': 0.96504}
2025-08-27 03:43:41,953 - INFO - val: {'epoch': 40, 'time_epoch': 4.27695, 'loss': 0.61657192, 'lr': 0, 'params': 501014, 'time_iter': 0.06789, 'accuracy': 0.77972, 'f1': 0.77963, 'accuracy-SBM': 0.77956, 'auc': 0.96195}
2025-08-27 03:43:47,929 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:43:47,968 - INFO - test: {'epoch': 40, 'time_epoch': 4.54349, 'loss': 0.61204635, 'lr': 0, 'params': 501014, 'time_iter': 0.07212, 'accuracy': 0.77893, 'f1': 0.77891, 'accuracy-SBM': 0.77887, 'auc': 0.9626}
2025-08-27 03:43:47,970 - INFO - > Epoch 40: took 94.6s (avg 96.0s) | Best so far: epoch 40	train_loss: 0.5909 train_accuracy-SBM: 0.7864	val_loss: 0.6166 val_accuracy-SBM: 0.7796	test_loss: 0.6120 test_accuracy-SBM: 0.7789
2025-08-27 03:43:47,970 - INFO - === Epoch 41 ===
2025-08-27 03:45:13,268 - INFO - train: {'epoch': 41, 'time_epoch': 85.05067, 'eta': 4931.61744, 'eta_hours': 1.36989, 'loss': 0.58533926, 'lr': 0.0006856, 'params': 501014, 'time_iter': 0.13608, 'accuracy': 0.78771, 'f1': 0.78771, 'accuracy-SBM': 0.78771, 'auc': 0.96571}
2025-08-27 03:45:17,545 - INFO - val: {'epoch': 41, 'time_epoch': 4.22217, 'loss': 0.62055703, 'lr': 0, 'params': 501014, 'time_iter': 0.06702, 'accuracy': 0.77954, 'f1': 0.77949, 'accuracy-SBM': 0.7794, 'auc': 0.96155}
2025-08-27 03:45:23,545 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:45:23,593 - INFO - test: {'epoch': 41, 'time_epoch': 4.52411, 'loss': 0.61579289, 'lr': 0, 'params': 501014, 'time_iter': 0.07181, 'accuracy': 0.77681, 'f1': 0.77684, 'accuracy-SBM': 0.77686, 'auc': 0.96226}
2025-08-27 03:45:23,595 - INFO - > Epoch 41: took 95.6s (avg 96.0s) | Best so far: epoch 40	train_loss: 0.5909 train_accuracy-SBM: 0.7864	val_loss: 0.6166 val_accuracy-SBM: 0.7796	test_loss: 0.6120 test_accuracy-SBM: 0.7789
2025-08-27 03:45:23,595 - INFO - === Epoch 42 ===
2025-08-27 03:46:48,411 - INFO - train: {'epoch': 42, 'time_epoch': 84.46807, 'eta': 4845.84747, 'eta_hours': 1.34607, 'loss': 0.58535176, 'lr': 0.00067015, 'params': 501014, 'time_iter': 0.13515, 'accuracy': 0.7876, 'f1': 0.7876, 'accuracy-SBM': 0.7876, 'auc': 0.9657}
2025-08-27 03:46:52,712 - INFO - val: {'epoch': 42, 'time_epoch': 4.25343, 'loss': 0.62229404, 'lr': 0, 'params': 501014, 'time_iter': 0.06751, 'accuracy': 0.78049, 'f1': 0.78045, 'accuracy-SBM': 0.78046, 'auc': 0.96174}
2025-08-27 03:46:58,681 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:46:58,723 - INFO - test: {'epoch': 42, 'time_epoch': 4.51336, 'loss': 0.61804078, 'lr': 0, 'params': 501014, 'time_iter': 0.07164, 'accuracy': 0.77876, 'f1': 0.77866, 'accuracy-SBM': 0.77871, 'auc': 0.96222}
2025-08-27 03:46:58,724 - INFO - > Epoch 42: took 95.1s (avg 96.0s) | Best so far: epoch 42	train_loss: 0.5854 train_accuracy-SBM: 0.7876	val_loss: 0.6223 val_accuracy-SBM: 0.7805	test_loss: 0.6180 test_accuracy-SBM: 0.7787
2025-08-27 03:46:58,725 - INFO - === Epoch 43 ===
2025-08-27 03:48:23,854 - INFO - train: {'epoch': 43, 'time_epoch': 84.87628, 'eta': 4760.65621, 'eta_hours': 1.3224, 'loss': 0.58329568, 'lr': 0.00065451, 'params': 501014, 'time_iter': 0.1358, 'accuracy': 0.789, 'f1': 0.789, 'accuracy-SBM': 0.789, 'auc': 0.96593}
2025-08-27 03:48:28,183 - INFO - val: {'epoch': 43, 'time_epoch': 4.28154, 'loss': 0.61796226, 'lr': 0, 'params': 501014, 'time_iter': 0.06796, 'accuracy': 0.77944, 'f1': 0.77946, 'accuracy-SBM': 0.77932, 'auc': 0.96208}
2025-08-27 03:48:34,102 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:48:34,142 - INFO - test: {'epoch': 43, 'time_epoch': 4.5653, 'loss': 0.61854425, 'lr': 0, 'params': 501014, 'time_iter': 0.07247, 'accuracy': 0.77746, 'f1': 0.77751, 'accuracy-SBM': 0.77756, 'auc': 0.96216}
2025-08-27 03:48:34,144 - INFO - > Epoch 43: took 95.4s (avg 96.0s) | Best so far: epoch 42	train_loss: 0.5854 train_accuracy-SBM: 0.7876	val_loss: 0.6223 val_accuracy-SBM: 0.7805	test_loss: 0.6180 test_accuracy-SBM: 0.7787
2025-08-27 03:48:34,144 - INFO - === Epoch 44 ===
2025-08-27 03:49:58,717 - INFO - train: {'epoch': 44, 'time_epoch': 84.32739, 'eta': 4674.80809, 'eta_hours': 1.29856, 'loss': 0.58120082, 'lr': 0.0006387, 'params': 501014, 'time_iter': 0.13492, 'accuracy': 0.78911, 'f1': 0.78911, 'accuracy-SBM': 0.78911, 'auc': 0.96619}
2025-08-27 03:50:03,035 - INFO - val: {'epoch': 44, 'time_epoch': 4.26941, 'loss': 0.6255469, 'lr': 0, 'params': 501014, 'time_iter': 0.06777, 'accuracy': 0.77901, 'f1': 0.77889, 'accuracy-SBM': 0.77885, 'auc': 0.96153}
2025-08-27 03:50:09,065 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:50:09,110 - INFO - test: {'epoch': 44, 'time_epoch': 4.53383, 'loss': 0.61744961, 'lr': 0, 'params': 501014, 'time_iter': 0.07197, 'accuracy': 0.7793, 'f1': 0.77921, 'accuracy-SBM': 0.7792, 'auc': 0.96227}
2025-08-27 03:50:09,112 - INFO - > Epoch 44: took 95.0s (avg 96.0s) | Best so far: epoch 42	train_loss: 0.5854 train_accuracy-SBM: 0.7876	val_loss: 0.6223 val_accuracy-SBM: 0.7805	test_loss: 0.6180 test_accuracy-SBM: 0.7787
2025-08-27 03:50:09,113 - INFO - === Epoch 45 ===
2025-08-27 03:51:34,254 - INFO - train: {'epoch': 45, 'time_epoch': 84.89211, 'eta': 4589.68903, 'eta_hours': 1.27491, 'loss': 0.57725774, 'lr': 0.00062274, 'params': 501014, 'time_iter': 0.13583, 'accuracy': 0.79032, 'f1': 0.79032, 'accuracy-SBM': 0.79032, 'auc': 0.96666}
2025-08-27 03:51:38,566 - INFO - val: {'epoch': 45, 'time_epoch': 4.25651, 'loss': 0.61860274, 'lr': 0, 'params': 501014, 'time_iter': 0.06756, 'accuracy': 0.78052, 'f1': 0.78041, 'accuracy-SBM': 0.78042, 'auc': 0.96196}
2025-08-27 03:51:44,912 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:51:44,951 - INFO - test: {'epoch': 45, 'time_epoch': 4.56239, 'loss': 0.61529542, 'lr': 0, 'params': 501014, 'time_iter': 0.07242, 'accuracy': 0.78, 'f1': 0.77998, 'accuracy-SBM': 0.77998, 'auc': 0.9623}
2025-08-27 03:51:44,961 - INFO - > Epoch 45: took 95.8s (avg 96.0s) | Best so far: epoch 42	train_loss: 0.5854 train_accuracy-SBM: 0.7876	val_loss: 0.6223 val_accuracy-SBM: 0.7805	test_loss: 0.6180 test_accuracy-SBM: 0.7787
2025-08-27 03:51:44,961 - INFO - === Epoch 46 ===
2025-08-27 03:53:10,074 - INFO - train: {'epoch': 46, 'time_epoch': 84.75955, 'eta': 4504.43013, 'eta_hours': 1.25123, 'loss': 0.57297123, 'lr': 0.00060665, 'params': 501014, 'time_iter': 0.13562, 'accuracy': 0.79193, 'f1': 0.79193, 'accuracy-SBM': 0.79193, 'auc': 0.96713}
2025-08-27 03:53:14,379 - INFO - val: {'epoch': 46, 'time_epoch': 4.25801, 'loss': 0.6302478, 'lr': 0, 'params': 501014, 'time_iter': 0.06759, 'accuracy': 0.77839, 'f1': 0.77832, 'accuracy-SBM': 0.77829, 'auc': 0.96052}
2025-08-27 03:53:20,297 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:53:20,339 - INFO - test: {'epoch': 46, 'time_epoch': 4.54062, 'loss': 0.62430689, 'lr': 0, 'params': 501014, 'time_iter': 0.07207, 'accuracy': 0.77602, 'f1': 0.77598, 'accuracy-SBM': 0.77605, 'auc': 0.96125}
2025-08-27 03:53:20,341 - INFO - > Epoch 46: took 95.4s (avg 95.9s) | Best so far: epoch 42	train_loss: 0.5854 train_accuracy-SBM: 0.7876	val_loss: 0.6223 val_accuracy-SBM: 0.7805	test_loss: 0.6180 test_accuracy-SBM: 0.7787
2025-08-27 03:53:20,342 - INFO - === Epoch 47 ===
2025-08-27 03:54:45,804 - INFO - train: {'epoch': 47, 'time_epoch': 85.21655, 'eta': 4419.68713, 'eta_hours': 1.22769, 'loss': 0.57500807, 'lr': 0.00059044, 'params': 501014, 'time_iter': 0.13635, 'accuracy': 0.79226, 'f1': 0.79226, 'accuracy-SBM': 0.79226, 'auc': 0.96688}
2025-08-27 03:54:50,084 - INFO - val: {'epoch': 47, 'time_epoch': 4.23387, 'loss': 0.61651207, 'lr': 0, 'params': 501014, 'time_iter': 0.0672, 'accuracy': 0.78259, 'f1': 0.78254, 'accuracy-SBM': 0.78255, 'auc': 0.96229}
2025-08-27 03:54:55,953 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:54:55,993 - INFO - test: {'epoch': 47, 'time_epoch': 4.50891, 'loss': 0.62510089, 'lr': 0, 'params': 501014, 'time_iter': 0.07157, 'accuracy': 0.77723, 'f1': 0.7772, 'accuracy-SBM': 0.77722, 'auc': 0.96132}
2025-08-27 03:54:55,995 - INFO - > Epoch 47: took 95.7s (avg 95.9s) | Best so far: epoch 47	train_loss: 0.5750 train_accuracy-SBM: 0.7923	val_loss: 0.6165 val_accuracy-SBM: 0.7825	test_loss: 0.6251 test_accuracy-SBM: 0.7772
2025-08-27 03:54:55,995 - INFO - === Epoch 48 ===
2025-08-27 03:56:21,124 - INFO - train: {'epoch': 48, 'time_epoch': 84.88139, 'eta': 4334.57596, 'eta_hours': 1.20405, 'loss': 0.57103566, 'lr': 0.00057413, 'params': 501014, 'time_iter': 0.13581, 'accuracy': 0.79219, 'f1': 0.79219, 'accuracy-SBM': 0.79219, 'auc': 0.96738}
2025-08-27 03:56:25,430 - INFO - val: {'epoch': 48, 'time_epoch': 4.25864, 'loss': 0.615593, 'lr': 0, 'params': 501014, 'time_iter': 0.0676, 'accuracy': 0.7818, 'f1': 0.78174, 'accuracy-SBM': 0.78174, 'auc': 0.96235}
2025-08-27 03:56:31,518 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:56:31,558 - INFO - test: {'epoch': 48, 'time_epoch': 4.54807, 'loss': 0.61054947, 'lr': 0, 'params': 501014, 'time_iter': 0.07219, 'accuracy': 0.78017, 'f1': 0.78019, 'accuracy-SBM': 0.78017, 'auc': 0.96292}
2025-08-27 03:56:31,593 - INFO - > Epoch 48: took 95.6s (avg 95.9s) | Best so far: epoch 47	train_loss: 0.5750 train_accuracy-SBM: 0.7923	val_loss: 0.6165 val_accuracy-SBM: 0.7825	test_loss: 0.6251 test_accuracy-SBM: 0.7772
2025-08-27 03:56:31,593 - INFO - === Epoch 49 ===
2025-08-27 03:57:57,009 - INFO - train: {'epoch': 49, 'time_epoch': 85.04432, 'eta': 4249.63691, 'eta_hours': 1.18045, 'loss': 0.56858165, 'lr': 0.00055774, 'params': 501014, 'time_iter': 0.13607, 'accuracy': 0.79333, 'f1': 0.79333, 'accuracy-SBM': 0.79333, 'auc': 0.96764}
2025-08-27 03:58:01,363 - INFO - val: {'epoch': 49, 'time_epoch': 4.30561, 'loss': 0.61716354, 'lr': 0, 'params': 501014, 'time_iter': 0.06834, 'accuracy': 0.78167, 'f1': 0.78157, 'accuracy-SBM': 0.7815, 'auc': 0.96207}
2025-08-27 03:58:07,212 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:58:07,256 - INFO - test: {'epoch': 49, 'time_epoch': 4.56822, 'loss': 0.61856684, 'lr': 0, 'params': 501014, 'time_iter': 0.07251, 'accuracy': 0.78049, 'f1': 0.78055, 'accuracy-SBM': 0.78056, 'auc': 0.96205}
2025-08-27 03:58:07,258 - INFO - > Epoch 49: took 95.7s (avg 95.9s) | Best so far: epoch 47	train_loss: 0.5750 train_accuracy-SBM: 0.7923	val_loss: 0.6165 val_accuracy-SBM: 0.7825	test_loss: 0.6251 test_accuracy-SBM: 0.7772
2025-08-27 03:58:07,258 - INFO - === Epoch 50 ===
2025-08-27 03:59:32,614 - INFO - train: {'epoch': 50, 'time_epoch': 85.09773, 'eta': 4164.74505, 'eta_hours': 1.15687, 'loss': 0.56395986, 'lr': 0.00054129, 'params': 501014, 'time_iter': 0.13616, 'accuracy': 0.79456, 'f1': 0.79456, 'accuracy-SBM': 0.79456, 'auc': 0.96818}
2025-08-27 03:59:36,914 - INFO - val: {'epoch': 50, 'time_epoch': 4.25203, 'loss': 0.62709882, 'lr': 0, 'params': 501014, 'time_iter': 0.06749, 'accuracy': 0.78073, 'f1': 0.78069, 'accuracy-SBM': 0.78072, 'auc': 0.96149}
2025-08-27 03:59:42,710 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 03:59:42,749 - INFO - test: {'epoch': 50, 'time_epoch': 4.29758, 'loss': 0.62833642, 'lr': 0, 'params': 501014, 'time_iter': 0.06822, 'accuracy': 0.7776, 'f1': 0.77762, 'accuracy-SBM': 0.77758, 'auc': 0.96132}
2025-08-27 03:59:42,751 - INFO - > Epoch 50: took 95.5s (avg 95.9s) | Best so far: epoch 47	train_loss: 0.5750 train_accuracy-SBM: 0.7923	val_loss: 0.6165 val_accuracy-SBM: 0.7825	test_loss: 0.6251 test_accuracy-SBM: 0.7772
2025-08-27 03:59:42,752 - INFO - === Epoch 51 ===
2025-08-27 04:01:07,786 - INFO - train: {'epoch': 51, 'time_epoch': 84.77721, 'eta': 4079.5494, 'eta_hours': 1.13321, 'loss': 0.56279283, 'lr': 0.00052479, 'params': 501014, 'time_iter': 0.13564, 'accuracy': 0.79551, 'f1': 0.79551, 'accuracy-SBM': 0.79551, 'auc': 0.96829}
2025-08-27 04:01:12,128 - INFO - val: {'epoch': 51, 'time_epoch': 4.29171, 'loss': 0.62846306, 'lr': 0, 'params': 501014, 'time_iter': 0.06812, 'accuracy': 0.77982, 'f1': 0.77977, 'accuracy-SBM': 0.77969, 'auc': 0.96118}
2025-08-27 04:01:18,223 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:01:18,263 - INFO - test: {'epoch': 51, 'time_epoch': 4.58102, 'loss': 0.6215682, 'lr': 0, 'params': 501014, 'time_iter': 0.07271, 'accuracy': 0.77759, 'f1': 0.77757, 'accuracy-SBM': 0.77761, 'auc': 0.96187}
2025-08-27 04:01:18,265 - INFO - > Epoch 51: took 95.5s (avg 95.9s) | Best so far: epoch 47	train_loss: 0.5750 train_accuracy-SBM: 0.7923	val_loss: 0.6165 val_accuracy-SBM: 0.7825	test_loss: 0.6251 test_accuracy-SBM: 0.7772
2025-08-27 04:01:18,265 - INFO - === Epoch 52 ===
2025-08-27 04:02:43,468 - INFO - train: {'epoch': 52, 'time_epoch': 84.94672, 'eta': 3994.51986, 'eta_hours': 1.10959, 'loss': 0.55826518, 'lr': 0.00050827, 'params': 501014, 'time_iter': 0.13591, 'accuracy': 0.79687, 'f1': 0.79687, 'accuracy-SBM': 0.79687, 'auc': 0.96881}
2025-08-27 04:02:47,772 - INFO - val: {'epoch': 52, 'time_epoch': 4.25609, 'loss': 0.638621, 'lr': 0, 'params': 501014, 'time_iter': 0.06756, 'accuracy': 0.77786, 'f1': 0.77784, 'accuracy-SBM': 0.77779, 'auc': 0.95949}
2025-08-27 04:02:54,836 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:02:54,878 - INFO - test: {'epoch': 52, 'time_epoch': 4.51441, 'loss': 0.61951311, 'lr': 0, 'params': 501014, 'time_iter': 0.07166, 'accuracy': 0.7803, 'f1': 0.78033, 'accuracy-SBM': 0.78033, 'auc': 0.96184}
2025-08-27 04:02:54,883 - INFO - > Epoch 52: took 96.6s (avg 95.9s) | Best so far: epoch 47	train_loss: 0.5750 train_accuracy-SBM: 0.7923	val_loss: 0.6165 val_accuracy-SBM: 0.7825	test_loss: 0.6251 test_accuracy-SBM: 0.7772
2025-08-27 04:02:54,883 - INFO - === Epoch 53 ===
2025-08-27 04:04:19,519 - INFO - train: {'epoch': 53, 'time_epoch': 84.3831, 'eta': 3909.01327, 'eta_hours': 1.08584, 'loss': 0.55639198, 'lr': 0.00049173, 'params': 501014, 'time_iter': 0.13501, 'accuracy': 0.79799, 'f1': 0.79799, 'accuracy-SBM': 0.79799, 'auc': 0.96902}
2025-08-27 04:04:23,830 - INFO - val: {'epoch': 53, 'time_epoch': 4.26496, 'loss': 0.62028084, 'lr': 0, 'params': 501014, 'time_iter': 0.0677, 'accuracy': 0.78197, 'f1': 0.78184, 'accuracy-SBM': 0.78179, 'auc': 0.96185}
2025-08-27 04:04:29,663 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:04:29,705 - INFO - test: {'epoch': 53, 'time_epoch': 4.52402, 'loss': 0.6135976, 'lr': 0, 'params': 501014, 'time_iter': 0.07181, 'accuracy': 0.77971, 'f1': 0.77969, 'accuracy-SBM': 0.7797, 'auc': 0.96269}
2025-08-27 04:04:29,706 - INFO - > Epoch 53: took 94.8s (avg 95.9s) | Best so far: epoch 47	train_loss: 0.5750 train_accuracy-SBM: 0.7923	val_loss: 0.6165 val_accuracy-SBM: 0.7825	test_loss: 0.6251 test_accuracy-SBM: 0.7772
2025-08-27 04:04:29,706 - INFO - === Epoch 54 ===
2025-08-27 04:05:55,023 - INFO - train: {'epoch': 54, 'time_epoch': 85.06146, 'eta': 3824.10256, 'eta_hours': 1.06225, 'loss': 0.55379463, 'lr': 0.00047521, 'params': 501014, 'time_iter': 0.1361, 'accuracy': 0.79887, 'f1': 0.79887, 'accuracy-SBM': 0.79887, 'auc': 0.9693}
2025-08-27 04:05:59,353 - INFO - val: {'epoch': 54, 'time_epoch': 4.28079, 'loss': 0.62868749, 'lr': 0, 'params': 501014, 'time_iter': 0.06795, 'accuracy': 0.78172, 'f1': 0.78174, 'accuracy-SBM': 0.78171, 'auc': 0.96104}
2025-08-27 04:06:05,546 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:06:05,586 - INFO - test: {'epoch': 54, 'time_epoch': 4.58865, 'loss': 0.6252584, 'lr': 0, 'params': 501014, 'time_iter': 0.07284, 'accuracy': 0.77978, 'f1': 0.7798, 'accuracy-SBM': 0.77989, 'auc': 0.96143}
2025-08-27 04:06:05,588 - INFO - > Epoch 54: took 95.9s (avg 95.9s) | Best so far: epoch 47	train_loss: 0.5750 train_accuracy-SBM: 0.7923	val_loss: 0.6165 val_accuracy-SBM: 0.7825	test_loss: 0.6251 test_accuracy-SBM: 0.7772
2025-08-27 04:06:05,588 - INFO - === Epoch 55 ===
2025-08-27 04:07:30,760 - INFO - train: {'epoch': 55, 'time_epoch': 84.91675, 'eta': 3739.07276, 'eta_hours': 1.03863, 'loss': 0.55002217, 'lr': 0.00045871, 'params': 501014, 'time_iter': 0.13587, 'accuracy': 0.80035, 'f1': 0.80035, 'accuracy-SBM': 0.80035, 'auc': 0.96972}
2025-08-27 04:07:35,022 - INFO - val: {'epoch': 55, 'time_epoch': 4.21542, 'loss': 0.616864, 'lr': 0, 'params': 501014, 'time_iter': 0.06691, 'accuracy': 0.7829, 'f1': 0.78274, 'accuracy-SBM': 0.78265, 'auc': 0.96228}
2025-08-27 04:07:40,992 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:07:41,031 - INFO - test: {'epoch': 55, 'time_epoch': 4.51526, 'loss': 0.6150247, 'lr': 0, 'params': 501014, 'time_iter': 0.07167, 'accuracy': 0.78167, 'f1': 0.78157, 'accuracy-SBM': 0.78156, 'auc': 0.96252}
2025-08-27 04:07:41,033 - INFO - > Epoch 55: took 95.4s (avg 95.9s) | Best so far: epoch 55	train_loss: 0.5500 train_accuracy-SBM: 0.8004	val_loss: 0.6169 val_accuracy-SBM: 0.7826	test_loss: 0.6150 test_accuracy-SBM: 0.7816
2025-08-27 04:07:41,034 - INFO - === Epoch 56 ===
2025-08-27 04:09:06,475 - INFO - train: {'epoch': 56, 'time_epoch': 85.18381, 'eta': 3654.2484, 'eta_hours': 1.01507, 'loss': 0.54948815, 'lr': 0.00044226, 'params': 501014, 'time_iter': 0.13629, 'accuracy': 0.80027, 'f1': 0.80027, 'accuracy-SBM': 0.80027, 'auc': 0.96979}
2025-08-27 04:09:10,880 - INFO - val: {'epoch': 56, 'time_epoch': 4.34869, 'loss': 0.6178974, 'lr': 0, 'params': 501014, 'time_iter': 0.06903, 'accuracy': 0.78328, 'f1': 0.78314, 'accuracy-SBM': 0.7832, 'auc': 0.9622}
2025-08-27 04:09:17,185 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:09:17,227 - INFO - test: {'epoch': 56, 'time_epoch': 4.69589, 'loss': 0.61727819, 'lr': 0, 'params': 501014, 'time_iter': 0.07454, 'accuracy': 0.78158, 'f1': 0.78158, 'accuracy-SBM': 0.78155, 'auc': 0.96225}
2025-08-27 04:09:17,235 - INFO - > Epoch 56: took 96.2s (avg 95.9s) | Best so far: epoch 56	train_loss: 0.5495 train_accuracy-SBM: 0.8003	val_loss: 0.6179 val_accuracy-SBM: 0.7832	test_loss: 0.6173 test_accuracy-SBM: 0.7815
2025-08-27 04:09:17,235 - INFO - === Epoch 57 ===
2025-08-27 04:10:42,752 - INFO - train: {'epoch': 57, 'time_epoch': 85.27197, 'eta': 3569.47548, 'eta_hours': 0.99152, 'loss': 0.54674773, 'lr': 0.00042587, 'params': 501014, 'time_iter': 0.13644, 'accuracy': 0.80098, 'f1': 0.80098, 'accuracy-SBM': 0.80098, 'auc': 0.97009}
2025-08-27 04:10:47,089 - INFO - val: {'epoch': 57, 'time_epoch': 4.28887, 'loss': 0.61786094, 'lr': 0, 'params': 501014, 'time_iter': 0.06808, 'accuracy': 0.78318, 'f1': 0.78309, 'accuracy-SBM': 0.78307, 'auc': 0.96239}
2025-08-27 04:10:53,037 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:10:53,078 - INFO - test: {'epoch': 57, 'time_epoch': 4.33103, 'loss': 0.62095523, 'lr': 0, 'params': 501014, 'time_iter': 0.06875, 'accuracy': 0.78064, 'f1': 0.78056, 'accuracy-SBM': 0.78055, 'auc': 0.96198}
2025-08-27 04:10:53,080 - INFO - > Epoch 57: took 95.8s (avg 95.9s) | Best so far: epoch 56	train_loss: 0.5495 train_accuracy-SBM: 0.8003	val_loss: 0.6179 val_accuracy-SBM: 0.7832	test_loss: 0.6173 test_accuracy-SBM: 0.7815
2025-08-27 04:10:53,080 - INFO - === Epoch 58 ===
2025-08-27 04:12:18,469 - INFO - train: {'epoch': 58, 'time_epoch': 85.14366, 'eta': 3484.59648, 'eta_hours': 0.96794, 'loss': 0.54303984, 'lr': 0.00040956, 'params': 501014, 'time_iter': 0.13623, 'accuracy': 0.80249, 'f1': 0.80249, 'accuracy-SBM': 0.80249, 'auc': 0.97049}
2025-08-27 04:12:22,802 - INFO - val: {'epoch': 58, 'time_epoch': 4.28378, 'loss': 0.63060253, 'lr': 0, 'params': 501014, 'time_iter': 0.068, 'accuracy': 0.78201, 'f1': 0.78196, 'accuracy-SBM': 0.78195, 'auc': 0.96139}
2025-08-27 04:12:28,859 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:12:28,898 - INFO - test: {'epoch': 58, 'time_epoch': 4.5339, 'loss': 0.61563998, 'lr': 0, 'params': 501014, 'time_iter': 0.07197, 'accuracy': 0.78109, 'f1': 0.78113, 'accuracy-SBM': 0.78114, 'auc': 0.96292}
2025-08-27 04:12:28,900 - INFO - > Epoch 58: took 95.8s (avg 95.9s) | Best so far: epoch 56	train_loss: 0.5495 train_accuracy-SBM: 0.8003	val_loss: 0.6179 val_accuracy-SBM: 0.7832	test_loss: 0.6173 test_accuracy-SBM: 0.7815
2025-08-27 04:12:28,900 - INFO - === Epoch 59 ===
2025-08-27 04:13:54,233 - INFO - train: {'epoch': 59, 'time_epoch': 85.08171, 'eta': 3399.66735, 'eta_hours': 0.94435, 'loss': 0.54253126, 'lr': 0.00039335, 'params': 501014, 'time_iter': 0.13613, 'accuracy': 0.80293, 'f1': 0.80293, 'accuracy-SBM': 0.80293, 'auc': 0.97055}
2025-08-27 04:13:58,583 - INFO - val: {'epoch': 59, 'time_epoch': 4.30113, 'loss': 0.619463, 'lr': 0, 'params': 501014, 'time_iter': 0.06827, 'accuracy': 0.78336, 'f1': 0.78332, 'accuracy-SBM': 0.78331, 'auc': 0.96252}
2025-08-27 04:14:04,691 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:14:04,730 - INFO - test: {'epoch': 59, 'time_epoch': 4.61242, 'loss': 0.61533992, 'lr': 0, 'params': 501014, 'time_iter': 0.07321, 'accuracy': 0.78227, 'f1': 0.78222, 'accuracy-SBM': 0.78225, 'auc': 0.96293}
2025-08-27 04:14:04,732 - INFO - > Epoch 59: took 95.8s (avg 95.9s) | Best so far: epoch 59	train_loss: 0.5425 train_accuracy-SBM: 0.8029	val_loss: 0.6195 val_accuracy-SBM: 0.7833	test_loss: 0.6153 test_accuracy-SBM: 0.7823
2025-08-27 04:14:04,732 - INFO - === Epoch 60 ===
2025-08-27 04:15:29,414 - INFO - train: {'epoch': 60, 'time_epoch': 84.43412, 'eta': 3314.3192, 'eta_hours': 0.92064, 'loss': 0.53911914, 'lr': 0.00037726, 'params': 501014, 'time_iter': 0.13509, 'accuracy': 0.80351, 'f1': 0.80351, 'accuracy-SBM': 0.80351, 'auc': 0.97092}
2025-08-27 04:15:33,705 - INFO - val: {'epoch': 60, 'time_epoch': 4.24471, 'loss': 0.62430141, 'lr': 0, 'params': 501014, 'time_iter': 0.06738, 'accuracy': 0.78153, 'f1': 0.7814, 'accuracy-SBM': 0.78128, 'auc': 0.96153}
2025-08-27 04:15:39,674 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:15:39,714 - INFO - test: {'epoch': 60, 'time_epoch': 4.50677, 'loss': 0.61884661, 'lr': 0, 'params': 501014, 'time_iter': 0.07154, 'accuracy': 0.77883, 'f1': 0.77868, 'accuracy-SBM': 0.77869, 'auc': 0.96214}
2025-08-27 04:15:39,715 - INFO - > Epoch 60: took 95.0s (avg 95.9s) | Best so far: epoch 59	train_loss: 0.5425 train_accuracy-SBM: 0.8029	val_loss: 0.6195 val_accuracy-SBM: 0.7833	test_loss: 0.6153 test_accuracy-SBM: 0.7823
2025-08-27 04:15:39,715 - INFO - === Epoch 61 ===
2025-08-27 04:17:05,129 - INFO - train: {'epoch': 61, 'time_epoch': 85.06061, 'eta': 3229.3845, 'eta_hours': 0.89705, 'loss': 0.5346994, 'lr': 0.0003613, 'params': 501014, 'time_iter': 0.1361, 'accuracy': 0.80543, 'f1': 0.80543, 'accuracy-SBM': 0.80544, 'auc': 0.9714}
2025-08-27 04:17:09,456 - INFO - val: {'epoch': 61, 'time_epoch': 4.2787, 'loss': 0.61516858, 'lr': 0, 'params': 501014, 'time_iter': 0.06792, 'accuracy': 0.78576, 'f1': 0.7857, 'accuracy-SBM': 0.78566, 'auc': 0.96283}
2025-08-27 04:17:16,277 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:17:16,316 - INFO - test: {'epoch': 61, 'time_epoch': 4.5185, 'loss': 0.62131195, 'lr': 0, 'params': 501014, 'time_iter': 0.07172, 'accuracy': 0.78056, 'f1': 0.78048, 'accuracy-SBM': 0.78051, 'auc': 0.9621}
2025-08-27 04:17:16,318 - INFO - > Epoch 61: took 96.6s (avg 95.9s) | Best so far: epoch 61	train_loss: 0.5347 train_accuracy-SBM: 0.8054	val_loss: 0.6152 val_accuracy-SBM: 0.7857	test_loss: 0.6213 test_accuracy-SBM: 0.7805
2025-08-27 04:17:16,318 - INFO - === Epoch 62 ===
2025-08-27 04:18:40,856 - INFO - train: {'epoch': 62, 'time_epoch': 84.28795, 'eta': 3143.99202, 'eta_hours': 0.87333, 'loss': 0.53372441, 'lr': 0.00034549, 'params': 501014, 'time_iter': 0.13486, 'accuracy': 0.8059, 'f1': 0.8059, 'accuracy-SBM': 0.8059, 'auc': 0.97148}
2025-08-27 04:18:45,133 - INFO - val: {'epoch': 62, 'time_epoch': 4.23033, 'loss': 0.62331808, 'lr': 0, 'params': 501014, 'time_iter': 0.06715, 'accuracy': 0.78226, 'f1': 0.78216, 'accuracy-SBM': 0.78217, 'auc': 0.96192}
2025-08-27 04:18:51,136 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:18:51,175 - INFO - test: {'epoch': 62, 'time_epoch': 4.4841, 'loss': 0.62946782, 'lr': 0, 'params': 501014, 'time_iter': 0.07118, 'accuracy': 0.7806, 'f1': 0.78062, 'accuracy-SBM': 0.78061, 'auc': 0.96113}
2025-08-27 04:18:51,177 - INFO - > Epoch 62: took 94.9s (avg 95.9s) | Best so far: epoch 61	train_loss: 0.5347 train_accuracy-SBM: 0.8054	val_loss: 0.6152 val_accuracy-SBM: 0.7857	test_loss: 0.6213 test_accuracy-SBM: 0.7805
2025-08-27 04:18:51,177 - INFO - === Epoch 63 ===
2025-08-27 04:20:16,182 - INFO - train: {'epoch': 63, 'time_epoch': 84.75997, 'eta': 3058.89957, 'eta_hours': 0.84969, 'loss': 0.53243762, 'lr': 0.00032985, 'params': 501014, 'time_iter': 0.13562, 'accuracy': 0.806, 'f1': 0.806, 'accuracy-SBM': 0.806, 'auc': 0.97162}
2025-08-27 04:20:20,515 - INFO - val: {'epoch': 63, 'time_epoch': 4.28639, 'loss': 0.62220991, 'lr': 0, 'params': 501014, 'time_iter': 0.06804, 'accuracy': 0.78359, 'f1': 0.78348, 'accuracy-SBM': 0.78342, 'auc': 0.96191}
2025-08-27 04:20:26,360 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:20:26,401 - INFO - test: {'epoch': 63, 'time_epoch': 4.53045, 'loss': 0.61663239, 'lr': 0, 'params': 501014, 'time_iter': 0.07191, 'accuracy': 0.78167, 'f1': 0.7816, 'accuracy-SBM': 0.78154, 'auc': 0.96253}
2025-08-27 04:20:26,403 - INFO - > Epoch 63: took 95.2s (avg 95.9s) | Best so far: epoch 61	train_loss: 0.5347 train_accuracy-SBM: 0.8054	val_loss: 0.6152 val_accuracy-SBM: 0.7857	test_loss: 0.6213 test_accuracy-SBM: 0.7805
2025-08-27 04:20:26,403 - INFO - === Epoch 64 ===
2025-08-27 04:21:51,469 - INFO - train: {'epoch': 64, 'time_epoch': 84.81301, 'eta': 2973.84591, 'eta_hours': 0.82607, 'loss': 0.53213151, 'lr': 0.0003144, 'params': 501014, 'time_iter': 0.1357, 'accuracy': 0.80613, 'f1': 0.80613, 'accuracy-SBM': 0.80613, 'auc': 0.97167}
2025-08-27 04:21:55,787 - INFO - val: {'epoch': 64, 'time_epoch': 4.27134, 'loss': 0.62616024, 'lr': 0, 'params': 501014, 'time_iter': 0.0678, 'accuracy': 0.78106, 'f1': 0.781, 'accuracy-SBM': 0.781, 'auc': 0.96144}
2025-08-27 04:22:01,694 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:22:01,734 - INFO - test: {'epoch': 64, 'time_epoch': 4.30494, 'loss': 0.61348081, 'lr': 0, 'params': 501014, 'time_iter': 0.06833, 'accuracy': 0.78127, 'f1': 0.78133, 'accuracy-SBM': 0.78133, 'auc': 0.9629}
2025-08-27 04:22:01,736 - INFO - > Epoch 64: took 95.3s (avg 95.9s) | Best so far: epoch 61	train_loss: 0.5347 train_accuracy-SBM: 0.8054	val_loss: 0.6152 val_accuracy-SBM: 0.7857	test_loss: 0.6213 test_accuracy-SBM: 0.7805
2025-08-27 04:22:01,736 - INFO - === Epoch 65 ===
2025-08-27 04:23:26,438 - INFO - train: {'epoch': 65, 'time_epoch': 84.45485, 'eta': 2888.61504, 'eta_hours': 0.80239, 'loss': 0.5278666, 'lr': 0.00029915, 'params': 501014, 'time_iter': 0.13513, 'accuracy': 0.80723, 'f1': 0.80723, 'accuracy-SBM': 0.80723, 'auc': 0.97213}
2025-08-27 04:23:30,730 - INFO - val: {'epoch': 65, 'time_epoch': 4.24614, 'loss': 0.61573349, 'lr': 0, 'params': 501014, 'time_iter': 0.0674, 'accuracy': 0.78524, 'f1': 0.78515, 'accuracy-SBM': 0.78512, 'auc': 0.96242}
2025-08-27 04:23:36,720 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:23:36,760 - INFO - test: {'epoch': 65, 'time_epoch': 4.52986, 'loss': 0.61444232, 'lr': 0, 'params': 501014, 'time_iter': 0.0719, 'accuracy': 0.78283, 'f1': 0.78282, 'accuracy-SBM': 0.78284, 'auc': 0.96256}
2025-08-27 04:23:36,762 - INFO - > Epoch 65: took 95.0s (avg 95.8s) | Best so far: epoch 61	train_loss: 0.5347 train_accuracy-SBM: 0.8054	val_loss: 0.6152 val_accuracy-SBM: 0.7857	test_loss: 0.6213 test_accuracy-SBM: 0.7805
2025-08-27 04:23:36,762 - INFO - === Epoch 66 ===
2025-08-27 04:25:02,284 - INFO - train: {'epoch': 66, 'time_epoch': 85.26717, 'eta': 2803.80742, 'eta_hours': 0.77884, 'loss': 0.52663209, 'lr': 0.00028412, 'params': 501014, 'time_iter': 0.13643, 'accuracy': 0.80866, 'f1': 0.80866, 'accuracy-SBM': 0.80866, 'auc': 0.97225}
2025-08-27 04:25:06,769 - INFO - val: {'epoch': 66, 'time_epoch': 4.43587, 'loss': 0.61894855, 'lr': 0, 'params': 501014, 'time_iter': 0.07041, 'accuracy': 0.78367, 'f1': 0.78358, 'accuracy-SBM': 0.78352, 'auc': 0.9621}
2025-08-27 04:25:12,781 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:25:12,820 - INFO - test: {'epoch': 66, 'time_epoch': 4.64393, 'loss': 0.61703012, 'lr': 0, 'params': 501014, 'time_iter': 0.07371, 'accuracy': 0.78148, 'f1': 0.78146, 'accuracy-SBM': 0.78146, 'auc': 0.96224}
2025-08-27 04:25:12,822 - INFO - > Epoch 66: took 96.1s (avg 95.8s) | Best so far: epoch 61	train_loss: 0.5347 train_accuracy-SBM: 0.8054	val_loss: 0.6152 val_accuracy-SBM: 0.7857	test_loss: 0.6213 test_accuracy-SBM: 0.7805
2025-08-27 04:25:12,823 - INFO - === Epoch 67 ===
2025-08-27 04:26:37,520 - INFO - train: {'epoch': 67, 'time_epoch': 84.45093, 'eta': 2718.60218, 'eta_hours': 0.75517, 'loss': 0.5248342, 'lr': 0.00026933, 'params': 501014, 'time_iter': 0.13512, 'accuracy': 0.80891, 'f1': 0.8089, 'accuracy-SBM': 0.80891, 'auc': 0.97244}
2025-08-27 04:26:41,856 - INFO - val: {'epoch': 67, 'time_epoch': 4.29004, 'loss': 0.62164453, 'lr': 0, 'params': 501014, 'time_iter': 0.0681, 'accuracy': 0.78554, 'f1': 0.78551, 'accuracy-SBM': 0.78546, 'auc': 0.96229}
2025-08-27 04:26:47,909 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:26:47,948 - INFO - test: {'epoch': 67, 'time_epoch': 4.5572, 'loss': 0.61802604, 'lr': 0, 'params': 501014, 'time_iter': 0.07234, 'accuracy': 0.78385, 'f1': 0.78379, 'accuracy-SBM': 0.78381, 'auc': 0.96254}
2025-08-27 04:26:47,958 - INFO - > Epoch 67: took 95.1s (avg 95.8s) | Best so far: epoch 61	train_loss: 0.5347 train_accuracy-SBM: 0.8054	val_loss: 0.6152 val_accuracy-SBM: 0.7857	test_loss: 0.6213 test_accuracy-SBM: 0.7805
2025-08-27 04:26:47,958 - INFO - === Epoch 68 ===
2025-08-27 04:28:12,667 - INFO - train: {'epoch': 68, 'time_epoch': 84.4628, 'eta': 2633.42414, 'eta_hours': 0.73151, 'loss': 0.52110112, 'lr': 0.00025479, 'params': 501014, 'time_iter': 0.13514, 'accuracy': 0.80999, 'f1': 0.80999, 'accuracy-SBM': 0.80999, 'auc': 0.97284}
2025-08-27 04:28:16,972 - INFO - val: {'epoch': 68, 'time_epoch': 4.25821, 'loss': 0.61647637, 'lr': 0, 'params': 501014, 'time_iter': 0.06759, 'accuracy': 0.78459, 'f1': 0.78451, 'accuracy-SBM': 0.78442, 'auc': 0.9624}
2025-08-27 04:28:23,063 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:28:23,103 - INFO - test: {'epoch': 68, 'time_epoch': 4.53704, 'loss': 0.61022321, 'lr': 0, 'params': 501014, 'time_iter': 0.07202, 'accuracy': 0.78372, 'f1': 0.7837, 'accuracy-SBM': 0.78369, 'auc': 0.96308}
2025-08-27 04:28:23,105 - INFO - > Epoch 68: took 95.1s (avg 95.8s) | Best so far: epoch 61	train_loss: 0.5347 train_accuracy-SBM: 0.8054	val_loss: 0.6152 val_accuracy-SBM: 0.7857	test_loss: 0.6213 test_accuracy-SBM: 0.7805
2025-08-27 04:28:23,105 - INFO - === Epoch 69 ===
2025-08-27 04:29:47,776 - INFO - train: {'epoch': 69, 'time_epoch': 84.42206, 'eta': 2548.24907, 'eta_hours': 0.70785, 'loss': 0.52034201, 'lr': 0.00024052, 'params': 501014, 'time_iter': 0.13508, 'accuracy': 0.81081, 'f1': 0.81081, 'accuracy-SBM': 0.81081, 'auc': 0.9729}
2025-08-27 04:29:52,139 - INFO - val: {'epoch': 69, 'time_epoch': 4.31534, 'loss': 0.61981322, 'lr': 0, 'params': 501014, 'time_iter': 0.0685, 'accuracy': 0.7833, 'f1': 0.78328, 'accuracy-SBM': 0.78331, 'auc': 0.96232}
2025-08-27 04:29:58,246 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:29:58,285 - INFO - test: {'epoch': 69, 'time_epoch': 4.56601, 'loss': 0.61071816, 'lr': 0, 'params': 501014, 'time_iter': 0.07248, 'accuracy': 0.78377, 'f1': 0.7838, 'accuracy-SBM': 0.78382, 'auc': 0.96326}
2025-08-27 04:29:58,287 - INFO - > Epoch 69: took 95.2s (avg 95.8s) | Best so far: epoch 61	train_loss: 0.5347 train_accuracy-SBM: 0.8054	val_loss: 0.6152 val_accuracy-SBM: 0.7857	test_loss: 0.6213 test_accuracy-SBM: 0.7805
2025-08-27 04:29:58,287 - INFO - === Epoch 70 ===
2025-08-27 04:31:24,055 - INFO - train: {'epoch': 70, 'time_epoch': 85.51521, 'eta': 2463.54171, 'eta_hours': 0.68432, 'loss': 0.51814579, 'lr': 0.00022653, 'params': 501014, 'time_iter': 0.13682, 'accuracy': 0.81142, 'f1': 0.81142, 'accuracy-SBM': 0.81142, 'auc': 0.97314}
2025-08-27 04:31:28,410 - INFO - val: {'epoch': 70, 'time_epoch': 4.28518, 'loss': 0.62415125, 'lr': 0, 'params': 501014, 'time_iter': 0.06802, 'accuracy': 0.78494, 'f1': 0.78488, 'accuracy-SBM': 0.78479, 'auc': 0.96198}
2025-08-27 04:31:34,923 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:31:34,963 - INFO - test: {'epoch': 70, 'time_epoch': 4.566, 'loss': 0.61938774, 'lr': 0, 'params': 501014, 'time_iter': 0.07248, 'accuracy': 0.78334, 'f1': 0.78331, 'accuracy-SBM': 0.78332, 'auc': 0.96238}
2025-08-27 04:31:34,967 - INFO - > Epoch 70: took 96.7s (avg 95.8s) | Best so far: epoch 61	train_loss: 0.5347 train_accuracy-SBM: 0.8054	val_loss: 0.6152 val_accuracy-SBM: 0.7857	test_loss: 0.6213 test_accuracy-SBM: 0.7805
2025-08-27 04:31:34,967 - INFO - === Epoch 71 ===
2025-08-27 04:32:59,451 - INFO - train: {'epoch': 71, 'time_epoch': 84.23666, 'eta': 2378.3147, 'eta_hours': 0.66064, 'loss': 0.51481985, 'lr': 0.00021284, 'params': 501014, 'time_iter': 0.13478, 'accuracy': 0.81245, 'f1': 0.81245, 'accuracy-SBM': 0.81245, 'auc': 0.97349}
2025-08-27 04:33:03,780 - INFO - val: {'epoch': 71, 'time_epoch': 4.28228, 'loss': 0.62010412, 'lr': 0, 'params': 501014, 'time_iter': 0.06797, 'accuracy': 0.78621, 'f1': 0.78613, 'accuracy-SBM': 0.78616, 'auc': 0.96254}
2025-08-27 04:33:10,490 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:33:10,529 - INFO - test: {'epoch': 71, 'time_epoch': 4.52498, 'loss': 0.616412, 'lr': 0, 'params': 501014, 'time_iter': 0.07183, 'accuracy': 0.78319, 'f1': 0.7832, 'accuracy-SBM': 0.78318, 'auc': 0.96287}
2025-08-27 04:33:10,532 - INFO - > Epoch 71: took 95.6s (avg 95.8s) | Best so far: epoch 71	train_loss: 0.5148 train_accuracy-SBM: 0.8125	val_loss: 0.6201 val_accuracy-SBM: 0.7862	test_loss: 0.6164 test_accuracy-SBM: 0.7832
2025-08-27 04:33:10,532 - INFO - === Epoch 72 ===
2025-08-27 04:34:35,566 - INFO - train: {'epoch': 72, 'time_epoch': 84.78952, 'eta': 2293.3193, 'eta_hours': 0.63703, 'loss': 0.5131877, 'lr': 0.00019946, 'params': 501014, 'time_iter': 0.13566, 'accuracy': 0.8127, 'f1': 0.8127, 'accuracy-SBM': 0.8127, 'auc': 0.97366}
2025-08-27 04:34:39,871 - INFO - val: {'epoch': 72, 'time_epoch': 4.25639, 'loss': 0.6212269, 'lr': 0, 'params': 501014, 'time_iter': 0.06756, 'accuracy': 0.78568, 'f1': 0.78562, 'accuracy-SBM': 0.78561, 'auc': 0.9622}
2025-08-27 04:34:46,604 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:34:46,645 - INFO - test: {'epoch': 72, 'time_epoch': 4.51684, 'loss': 0.61746771, 'lr': 0, 'params': 501014, 'time_iter': 0.0717, 'accuracy': 0.78361, 'f1': 0.78349, 'accuracy-SBM': 0.78355, 'auc': 0.96255}
2025-08-27 04:34:46,650 - INFO - > Epoch 72: took 96.1s (avg 95.8s) | Best so far: epoch 71	train_loss: 0.5148 train_accuracy-SBM: 0.8125	val_loss: 0.6201 val_accuracy-SBM: 0.7862	test_loss: 0.6164 test_accuracy-SBM: 0.7832
2025-08-27 04:34:46,650 - INFO - === Epoch 73 ===
2025-08-27 04:36:11,468 - INFO - train: {'epoch': 73, 'time_epoch': 84.55803, 'eta': 2208.24813, 'eta_hours': 0.6134, 'loss': 0.51065229, 'lr': 0.00018641, 'params': 501014, 'time_iter': 0.13529, 'accuracy': 0.81396, 'f1': 0.81396, 'accuracy-SBM': 0.81396, 'auc': 0.9739}
2025-08-27 04:36:15,735 - INFO - val: {'epoch': 73, 'time_epoch': 4.2188, 'loss': 0.62401796, 'lr': 0, 'params': 501014, 'time_iter': 0.06697, 'accuracy': 0.78584, 'f1': 0.78578, 'accuracy-SBM': 0.78574, 'auc': 0.96197}
2025-08-27 04:36:22,000 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:36:22,044 - INFO - test: {'epoch': 73, 'time_epoch': 4.49807, 'loss': 0.61245256, 'lr': 0, 'params': 501014, 'time_iter': 0.0714, 'accuracy': 0.78409, 'f1': 0.78414, 'accuracy-SBM': 0.78411, 'auc': 0.96323}
2025-08-27 04:36:22,047 - INFO - > Epoch 73: took 95.4s (avg 95.8s) | Best so far: epoch 71	train_loss: 0.5148 train_accuracy-SBM: 0.8125	val_loss: 0.6201 val_accuracy-SBM: 0.7862	test_loss: 0.6164 test_accuracy-SBM: 0.7832
2025-08-27 04:36:22,047 - INFO - === Epoch 74 ===
2025-08-27 04:37:47,452 - INFO - train: {'epoch': 74, 'time_epoch': 85.14872, 'eta': 2123.38755, 'eta_hours': 0.58983, 'loss': 0.50984336, 'lr': 0.00017371, 'params': 501014, 'time_iter': 0.13624, 'accuracy': 0.81426, 'f1': 0.81426, 'accuracy-SBM': 0.81426, 'auc': 0.97399}
2025-08-27 04:37:51,971 - INFO - val: {'epoch': 74, 'time_epoch': 4.27195, 'loss': 0.62681636, 'lr': 0, 'params': 501014, 'time_iter': 0.06781, 'accuracy': 0.78548, 'f1': 0.78542, 'accuracy-SBM': 0.78542, 'auc': 0.96173}
2025-08-27 04:37:58,365 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:37:58,404 - INFO - test: {'epoch': 74, 'time_epoch': 4.53193, 'loss': 0.61709422, 'lr': 0, 'params': 501014, 'time_iter': 0.07194, 'accuracy': 0.78505, 'f1': 0.785, 'accuracy-SBM': 0.78502, 'auc': 0.96269}
2025-08-27 04:37:58,411 - INFO - > Epoch 74: took 96.4s (avg 95.8s) | Best so far: epoch 71	train_loss: 0.5148 train_accuracy-SBM: 0.8125	val_loss: 0.6201 val_accuracy-SBM: 0.7862	test_loss: 0.6164 test_accuracy-SBM: 0.7832
2025-08-27 04:37:58,411 - INFO - === Epoch 75 ===
2025-08-27 04:39:23,477 - INFO - train: {'epoch': 75, 'time_epoch': 84.81815, 'eta': 2038.41499, 'eta_hours': 0.56623, 'loss': 0.5094103, 'lr': 0.00016136, 'params': 501014, 'time_iter': 0.13571, 'accuracy': 0.81407, 'f1': 0.81407, 'accuracy-SBM': 0.81407, 'auc': 0.97403}
2025-08-27 04:39:27,787 - INFO - val: {'epoch': 75, 'time_epoch': 4.24838, 'loss': 0.62337559, 'lr': 0, 'params': 501014, 'time_iter': 0.06743, 'accuracy': 0.7863, 'f1': 0.78626, 'accuracy-SBM': 0.7862, 'auc': 0.96201}
2025-08-27 04:39:34,313 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:39:34,362 - INFO - test: {'epoch': 75, 'time_epoch': 4.31643, 'loss': 0.61517329, 'lr': 0, 'params': 501014, 'time_iter': 0.06851, 'accuracy': 0.78435, 'f1': 0.78433, 'accuracy-SBM': 0.78438, 'auc': 0.96284}
2025-08-27 04:39:34,364 - INFO - > Epoch 75: took 96.0s (avg 95.8s) | Best so far: epoch 75	train_loss: 0.5094 train_accuracy-SBM: 0.8141	val_loss: 0.6234 val_accuracy-SBM: 0.7862	test_loss: 0.6152 test_accuracy-SBM: 0.7844
2025-08-27 04:39:34,364 - INFO - === Epoch 76 ===
2025-08-27 04:40:59,213 - INFO - train: {'epoch': 76, 'time_epoch': 84.605, 'eta': 1953.38277, 'eta_hours': 0.54261, 'loss': 0.50556703, 'lr': 0.00014938, 'params': 501014, 'time_iter': 0.13537, 'accuracy': 0.81627, 'f1': 0.81627, 'accuracy-SBM': 0.81627, 'auc': 0.97442}
2025-08-27 04:41:03,502 - INFO - val: {'epoch': 76, 'time_epoch': 4.23988, 'loss': 0.6266383, 'lr': 0, 'params': 501014, 'time_iter': 0.0673, 'accuracy': 0.78413, 'f1': 0.78404, 'accuracy-SBM': 0.78401, 'auc': 0.96161}
2025-08-27 04:41:09,866 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:41:09,906 - INFO - test: {'epoch': 76, 'time_epoch': 4.49783, 'loss': 0.61603341, 'lr': 0, 'params': 501014, 'time_iter': 0.07139, 'accuracy': 0.78366, 'f1': 0.78363, 'accuracy-SBM': 0.78362, 'auc': 0.96275}
2025-08-27 04:41:09,908 - INFO - > Epoch 76: took 95.5s (avg 95.8s) | Best so far: epoch 75	train_loss: 0.5094 train_accuracy-SBM: 0.8141	val_loss: 0.6234 val_accuracy-SBM: 0.7862	test_loss: 0.6152 test_accuracy-SBM: 0.7844
2025-08-27 04:41:09,908 - INFO - === Epoch 77 ===
2025-08-27 04:42:34,583 - INFO - train: {'epoch': 77, 'time_epoch': 84.42726, 'eta': 1868.31137, 'eta_hours': 0.51898, 'loss': 0.5048517, 'lr': 0.00013779, 'params': 501014, 'time_iter': 0.13508, 'accuracy': 0.81575, 'f1': 0.81575, 'accuracy-SBM': 0.81575, 'auc': 0.97451}
2025-08-27 04:42:38,847 - INFO - val: {'epoch': 77, 'time_epoch': 4.21577, 'loss': 0.6303649, 'lr': 0, 'params': 501014, 'time_iter': 0.06692, 'accuracy': 0.78434, 'f1': 0.78427, 'accuracy-SBM': 0.78423, 'auc': 0.96122}
2025-08-27 04:42:45,421 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:42:45,461 - INFO - test: {'epoch': 77, 'time_epoch': 4.50925, 'loss': 0.6191254, 'lr': 0, 'params': 501014, 'time_iter': 0.07158, 'accuracy': 0.78371, 'f1': 0.78366, 'accuracy-SBM': 0.78367, 'auc': 0.96241}
2025-08-27 04:42:45,465 - INFO - > Epoch 77: took 95.6s (avg 95.8s) | Best so far: epoch 75	train_loss: 0.5094 train_accuracy-SBM: 0.8141	val_loss: 0.6234 val_accuracy-SBM: 0.7862	test_loss: 0.6152 test_accuracy-SBM: 0.7844
2025-08-27 04:42:45,465 - INFO - === Epoch 78 ===
2025-08-27 04:44:09,783 - INFO - train: {'epoch': 78, 'time_epoch': 83.96704, 'eta': 1783.13395, 'eta_hours': 0.49531, 'loss': 0.50454847, 'lr': 0.00012659, 'params': 501014, 'time_iter': 0.13435, 'accuracy': 0.81605, 'f1': 0.81605, 'accuracy-SBM': 0.81605, 'auc': 0.97453}
2025-08-27 04:44:14,101 - INFO - val: {'epoch': 78, 'time_epoch': 4.27053, 'loss': 0.63029894, 'lr': 0, 'params': 501014, 'time_iter': 0.06779, 'accuracy': 0.78436, 'f1': 0.78428, 'accuracy-SBM': 0.78428, 'auc': 0.96163}
2025-08-27 04:44:20,144 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:44:20,183 - INFO - test: {'epoch': 78, 'time_epoch': 4.54074, 'loss': 0.61628284, 'lr': 0, 'params': 501014, 'time_iter': 0.07208, 'accuracy': 0.78459, 'f1': 0.78455, 'accuracy-SBM': 0.78454, 'auc': 0.96304}
2025-08-27 04:44:20,185 - INFO - > Epoch 78: took 94.7s (avg 95.8s) | Best so far: epoch 75	train_loss: 0.5094 train_accuracy-SBM: 0.8141	val_loss: 0.6234 val_accuracy-SBM: 0.7862	test_loss: 0.6152 test_accuracy-SBM: 0.7844
2025-08-27 04:44:20,185 - INFO - === Epoch 79 ===
2025-08-27 04:45:45,321 - INFO - train: {'epoch': 79, 'time_epoch': 84.86928, 'eta': 1698.21234, 'eta_hours': 0.47173, 'loss': 0.50284847, 'lr': 0.0001158, 'params': 501014, 'time_iter': 0.13579, 'accuracy': 0.81649, 'f1': 0.81649, 'accuracy-SBM': 0.81649, 'auc': 0.9747}
2025-08-27 04:45:49,735 - INFO - val: {'epoch': 79, 'time_epoch': 4.35783, 'loss': 0.63364401, 'lr': 0, 'params': 501014, 'time_iter': 0.06917, 'accuracy': 0.78434, 'f1': 0.78429, 'accuracy-SBM': 0.78426, 'auc': 0.96117}
2025-08-27 04:45:55,838 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:45:55,877 - INFO - test: {'epoch': 79, 'time_epoch': 4.61881, 'loss': 0.62169698, 'lr': 0, 'params': 501014, 'time_iter': 0.07331, 'accuracy': 0.78338, 'f1': 0.78335, 'accuracy-SBM': 0.78337, 'auc': 0.96243}
2025-08-27 04:45:55,880 - INFO - > Epoch 79: took 95.7s (avg 95.8s) | Best so far: epoch 75	train_loss: 0.5094 train_accuracy-SBM: 0.8141	val_loss: 0.6234 val_accuracy-SBM: 0.7862	test_loss: 0.6152 test_accuracy-SBM: 0.7844
2025-08-27 04:45:55,880 - INFO - === Epoch 80 ===
2025-08-27 04:47:20,740 - INFO - train: {'epoch': 80, 'time_epoch': 84.61469, 'eta': 1613.23231, 'eta_hours': 0.44812, 'loss': 0.50166086, 'lr': 0.00010543, 'params': 501014, 'time_iter': 0.13538, 'accuracy': 0.81697, 'f1': 0.81697, 'accuracy-SBM': 0.81697, 'auc': 0.97482}
2025-08-27 04:47:25,043 - INFO - val: {'epoch': 80, 'time_epoch': 4.25564, 'loss': 0.62822903, 'lr': 0, 'params': 501014, 'time_iter': 0.06755, 'accuracy': 0.78538, 'f1': 0.7853, 'accuracy-SBM': 0.78528, 'auc': 0.96172}
2025-08-27 04:47:31,047 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:47:31,087 - INFO - test: {'epoch': 80, 'time_epoch': 4.51661, 'loss': 0.6196248, 'lr': 0, 'params': 501014, 'time_iter': 0.07169, 'accuracy': 0.7831, 'f1': 0.78306, 'accuracy-SBM': 0.78307, 'auc': 0.96261}
2025-08-27 04:47:31,089 - INFO - > Epoch 80: took 95.2s (avg 95.8s) | Best so far: epoch 75	train_loss: 0.5094 train_accuracy-SBM: 0.8141	val_loss: 0.6234 val_accuracy-SBM: 0.7862	test_loss: 0.6152 test_accuracy-SBM: 0.7844
2025-08-27 04:47:31,089 - INFO - === Epoch 81 ===
2025-08-27 04:48:55,945 - INFO - train: {'epoch': 81, 'time_epoch': 84.60522, 'eta': 1528.25911, 'eta_hours': 0.42452, 'loss': 0.49904714, 'lr': 9.549e-05, 'params': 501014, 'time_iter': 0.13537, 'accuracy': 0.81791, 'f1': 0.81791, 'accuracy-SBM': 0.81791, 'auc': 0.97508}
2025-08-27 04:49:00,293 - INFO - val: {'epoch': 81, 'time_epoch': 4.2989, 'loss': 0.62676356, 'lr': 0, 'params': 501014, 'time_iter': 0.06824, 'accuracy': 0.78606, 'f1': 0.78596, 'accuracy-SBM': 0.78593, 'auc': 0.96194}
2025-08-27 04:49:06,252 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:49:06,291 - INFO - test: {'epoch': 81, 'time_epoch': 4.53982, 'loss': 0.61974206, 'lr': 0, 'params': 501014, 'time_iter': 0.07206, 'accuracy': 0.7829, 'f1': 0.7829, 'accuracy-SBM': 0.78292, 'auc': 0.96265}
2025-08-27 04:49:06,293 - INFO - > Epoch 81: took 95.2s (avg 95.8s) | Best so far: epoch 75	train_loss: 0.5094 train_accuracy-SBM: 0.8141	val_loss: 0.6234 val_accuracy-SBM: 0.7862	test_loss: 0.6152 test_accuracy-SBM: 0.7844
2025-08-27 04:49:06,293 - INFO - === Epoch 82 ===
2025-08-27 04:50:31,483 - INFO - train: {'epoch': 82, 'time_epoch': 84.83697, 'eta': 1443.34224, 'eta_hours': 0.40093, 'loss': 0.49807029, 'lr': 8.6e-05, 'params': 501014, 'time_iter': 0.13574, 'accuracy': 0.81803, 'f1': 0.81803, 'accuracy-SBM': 0.81803, 'auc': 0.9752}
2025-08-27 04:50:35,813 - INFO - val: {'epoch': 82, 'time_epoch': 4.28204, 'loss': 0.6296309, 'lr': 0, 'params': 501014, 'time_iter': 0.06797, 'accuracy': 0.78443, 'f1': 0.78438, 'accuracy-SBM': 0.78439, 'auc': 0.96149}
2025-08-27 04:50:41,543 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:50:41,583 - INFO - test: {'epoch': 82, 'time_epoch': 4.33292, 'loss': 0.62132703, 'lr': 0, 'params': 501014, 'time_iter': 0.06878, 'accuracy': 0.78381, 'f1': 0.78378, 'accuracy-SBM': 0.7838, 'auc': 0.96228}
2025-08-27 04:50:41,585 - INFO - > Epoch 82: took 95.3s (avg 95.8s) | Best so far: epoch 75	train_loss: 0.5094 train_accuracy-SBM: 0.8141	val_loss: 0.6234 val_accuracy-SBM: 0.7862	test_loss: 0.6152 test_accuracy-SBM: 0.7844
2025-08-27 04:50:41,586 - INFO - === Epoch 83 ===
2025-08-27 04:52:06,477 - INFO - train: {'epoch': 83, 'time_epoch': 84.6506, 'eta': 1358.39178, 'eta_hours': 0.37733, 'loss': 0.49653668, 'lr': 7.695e-05, 'params': 501014, 'time_iter': 0.13544, 'accuracy': 0.81907, 'f1': 0.81907, 'accuracy-SBM': 0.81907, 'auc': 0.97533}
2025-08-27 04:52:10,748 - INFO - val: {'epoch': 83, 'time_epoch': 4.21537, 'loss': 0.6338597, 'lr': 0, 'params': 501014, 'time_iter': 0.06691, 'accuracy': 0.78435, 'f1': 0.78429, 'accuracy-SBM': 0.78425, 'auc': 0.96133}
2025-08-27 04:52:16,768 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:52:16,809 - INFO - test: {'epoch': 83, 'time_epoch': 4.50134, 'loss': 0.6197467, 'lr': 0, 'params': 501014, 'time_iter': 0.07145, 'accuracy': 0.78416, 'f1': 0.78416, 'accuracy-SBM': 0.78419, 'auc': 0.96271}
2025-08-27 04:52:16,811 - INFO - > Epoch 83: took 95.2s (avg 95.8s) | Best so far: epoch 75	train_loss: 0.5094 train_accuracy-SBM: 0.8141	val_loss: 0.6234 val_accuracy-SBM: 0.7862	test_loss: 0.6152 test_accuracy-SBM: 0.7844
2025-08-27 04:52:16,811 - INFO - === Epoch 84 ===
2025-08-27 04:53:42,275 - INFO - train: {'epoch': 84, 'time_epoch': 85.20786, 'eta': 1273.54671, 'eta_hours': 0.35376, 'loss': 0.49623122, 'lr': 6.837e-05, 'params': 501014, 'time_iter': 0.13633, 'accuracy': 0.81871, 'f1': 0.81871, 'accuracy-SBM': 0.81871, 'auc': 0.97538}
2025-08-27 04:53:46,646 - INFO - val: {'epoch': 84, 'time_epoch': 4.3228, 'loss': 0.62759079, 'lr': 0, 'params': 501014, 'time_iter': 0.06862, 'accuracy': 0.78615, 'f1': 0.78609, 'accuracy-SBM': 0.78605, 'auc': 0.96179}
2025-08-27 04:53:52,652 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:53:52,692 - INFO - test: {'epoch': 84, 'time_epoch': 4.58504, 'loss': 0.62209417, 'lr': 0, 'params': 501014, 'time_iter': 0.07278, 'accuracy': 0.78325, 'f1': 0.78323, 'accuracy-SBM': 0.78327, 'auc': 0.96232}
2025-08-27 04:53:52,694 - INFO - > Epoch 84: took 95.9s (avg 95.8s) | Best so far: epoch 75	train_loss: 0.5094 train_accuracy-SBM: 0.8141	val_loss: 0.6234 val_accuracy-SBM: 0.7862	test_loss: 0.6152 test_accuracy-SBM: 0.7844
2025-08-27 04:53:52,694 - INFO - === Epoch 85 ===
2025-08-27 04:55:19,355 - INFO - train: {'epoch': 85, 'time_epoch': 86.41227, 'eta': 1188.88928, 'eta_hours': 0.33025, 'loss': 0.4951616, 'lr': 6.026e-05, 'params': 501014, 'time_iter': 0.13826, 'accuracy': 0.81949, 'f1': 0.81949, 'accuracy-SBM': 0.81949, 'auc': 0.97547}
2025-08-27 04:55:23,677 - INFO - val: {'epoch': 85, 'time_epoch': 4.27325, 'loss': 0.63116195, 'lr': 0, 'params': 501014, 'time_iter': 0.06783, 'accuracy': 0.78537, 'f1': 0.78525, 'accuracy-SBM': 0.78523, 'auc': 0.96169}
2025-08-27 04:55:29,635 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:55:29,684 - INFO - test: {'epoch': 85, 'time_epoch': 4.52809, 'loss': 0.62289996, 'lr': 0, 'params': 501014, 'time_iter': 0.07187, 'accuracy': 0.783, 'f1': 0.78298, 'accuracy-SBM': 0.78297, 'auc': 0.96249}
2025-08-27 04:55:29,685 - INFO - > Epoch 85: took 97.0s (avg 95.8s) | Best so far: epoch 75	train_loss: 0.5094 train_accuracy-SBM: 0.8141	val_loss: 0.6234 val_accuracy-SBM: 0.7862	test_loss: 0.6152 test_accuracy-SBM: 0.7844
2025-08-27 04:55:29,686 - INFO - === Epoch 86 ===
2025-08-27 04:56:54,827 - INFO - train: {'epoch': 86, 'time_epoch': 84.8975, 'eta': 1103.96515, 'eta_hours': 0.30666, 'loss': 0.49537989, 'lr': 5.264e-05, 'params': 501014, 'time_iter': 0.13584, 'accuracy': 0.81927, 'f1': 0.81926, 'accuracy-SBM': 0.81927, 'auc': 0.97545}
2025-08-27 04:56:59,168 - INFO - val: {'epoch': 86, 'time_epoch': 4.29357, 'loss': 0.63074889, 'lr': 0, 'params': 501014, 'time_iter': 0.06815, 'accuracy': 0.78595, 'f1': 0.78588, 'accuracy-SBM': 0.78587, 'auc': 0.96164}
2025-08-27 04:57:05,195 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:57:05,234 - INFO - test: {'epoch': 86, 'time_epoch': 4.56534, 'loss': 0.62247766, 'lr': 0, 'params': 501014, 'time_iter': 0.07247, 'accuracy': 0.78438, 'f1': 0.78436, 'accuracy-SBM': 0.78437, 'auc': 0.96242}
2025-08-27 04:57:05,237 - INFO - > Epoch 86: took 95.6s (avg 95.8s) | Best so far: epoch 75	train_loss: 0.5094 train_accuracy-SBM: 0.8141	val_loss: 0.6234 val_accuracy-SBM: 0.7862	test_loss: 0.6152 test_accuracy-SBM: 0.7844
2025-08-27 04:57:05,237 - INFO - === Epoch 87 ===
2025-08-27 04:58:29,949 - INFO - train: {'epoch': 87, 'time_epoch': 84.46256, 'eta': 1018.98232, 'eta_hours': 0.28305, 'loss': 0.49309935, 'lr': 4.55e-05, 'params': 501014, 'time_iter': 0.13514, 'accuracy': 0.81994, 'f1': 0.81994, 'accuracy-SBM': 0.81994, 'auc': 0.97567}
2025-08-27 04:58:34,271 - INFO - val: {'epoch': 87, 'time_epoch': 4.27447, 'loss': 0.62866344, 'lr': 0, 'params': 501014, 'time_iter': 0.06785, 'accuracy': 0.78559, 'f1': 0.7855, 'accuracy-SBM': 0.78549, 'auc': 0.96173}
2025-08-27 04:58:40,183 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 04:58:40,222 - INFO - test: {'epoch': 87, 'time_epoch': 4.5399, 'loss': 0.62253379, 'lr': 0, 'params': 501014, 'time_iter': 0.07206, 'accuracy': 0.78342, 'f1': 0.7834, 'accuracy-SBM': 0.78341, 'auc': 0.9623}
2025-08-27 04:58:40,224 - INFO - > Epoch 87: took 95.0s (avg 95.8s) | Best so far: epoch 75	train_loss: 0.5094 train_accuracy-SBM: 0.8141	val_loss: 0.6234 val_accuracy-SBM: 0.7862	test_loss: 0.6152 test_accuracy-SBM: 0.7844
2025-08-27 04:58:40,224 - INFO - === Epoch 88 ===
2025-08-27 05:00:04,879 - INFO - train: {'epoch': 88, 'time_epoch': 84.30254, 'eta': 933.99141, 'eta_hours': 0.25944, 'loss': 0.49192455, 'lr': 3.886e-05, 'params': 501014, 'time_iter': 0.13488, 'accuracy': 0.82067, 'f1': 0.82067, 'accuracy-SBM': 0.82067, 'auc': 0.9758}
2025-08-27 05:00:09,234 - INFO - val: {'epoch': 88, 'time_epoch': 4.29742, 'loss': 0.62815324, 'lr': 0, 'params': 501014, 'time_iter': 0.06821, 'accuracy': 0.78701, 'f1': 0.78691, 'accuracy-SBM': 0.78688, 'auc': 0.96176}
2025-08-27 05:00:15,228 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 05:00:15,267 - INFO - test: {'epoch': 88, 'time_epoch': 4.52357, 'loss': 0.62218127, 'lr': 0, 'params': 501014, 'time_iter': 0.0718, 'accuracy': 0.78344, 'f1': 0.7834, 'accuracy-SBM': 0.78341, 'auc': 0.96235}
2025-08-27 05:00:15,269 - INFO - > Epoch 88: took 95.0s (avg 95.8s) | Best so far: epoch 88	train_loss: 0.4919 train_accuracy-SBM: 0.8207	val_loss: 0.6282 val_accuracy-SBM: 0.7869	test_loss: 0.6222 test_accuracy-SBM: 0.7834
2025-08-27 05:00:15,269 - INFO - === Epoch 89 ===
2025-08-27 05:01:40,234 - INFO - train: {'epoch': 89, 'time_epoch': 84.61561, 'eta': 849.05058, 'eta_hours': 0.23585, 'loss': 0.49240693, 'lr': 3.272e-05, 'params': 501014, 'time_iter': 0.13538, 'accuracy': 0.82061, 'f1': 0.82061, 'accuracy-SBM': 0.82061, 'auc': 0.97574}
2025-08-27 05:01:44,532 - INFO - val: {'epoch': 89, 'time_epoch': 4.25195, 'loss': 0.63136784, 'lr': 0, 'params': 501014, 'time_iter': 0.06749, 'accuracy': 0.78587, 'f1': 0.78577, 'accuracy-SBM': 0.78575, 'auc': 0.96141}
2025-08-27 05:01:50,460 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 05:01:50,500 - INFO - test: {'epoch': 89, 'time_epoch': 4.50969, 'loss': 0.62370803, 'lr': 0, 'params': 501014, 'time_iter': 0.07158, 'accuracy': 0.78349, 'f1': 0.78346, 'accuracy-SBM': 0.78348, 'auc': 0.9622}
2025-08-27 05:01:50,502 - INFO - > Epoch 89: took 95.2s (avg 95.8s) | Best so far: epoch 88	train_loss: 0.4919 train_accuracy-SBM: 0.8207	val_loss: 0.6282 val_accuracy-SBM: 0.7869	test_loss: 0.6222 test_accuracy-SBM: 0.7834
2025-08-27 05:01:50,502 - INFO - === Epoch 90 ===
2025-08-27 05:03:15,143 - INFO - train: {'epoch': 90, 'time_epoch': 84.38776, 'eta': 764.09436, 'eta_hours': 0.21225, 'loss': 0.4906736, 'lr': 2.709e-05, 'params': 501014, 'time_iter': 0.13502, 'accuracy': 0.82093, 'f1': 0.82093, 'accuracy-SBM': 0.82093, 'auc': 0.97591}
2025-08-27 05:03:19,495 - INFO - val: {'epoch': 90, 'time_epoch': 4.30403, 'loss': 0.63147228, 'lr': 0, 'params': 501014, 'time_iter': 0.06832, 'accuracy': 0.78549, 'f1': 0.78541, 'accuracy-SBM': 0.78541, 'auc': 0.96155}
2025-08-27 05:03:25,522 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 05:03:25,562 - INFO - test: {'epoch': 90, 'time_epoch': 4.3315, 'loss': 0.62261238, 'lr': 0, 'params': 501014, 'time_iter': 0.06875, 'accuracy': 0.78333, 'f1': 0.78333, 'accuracy-SBM': 0.78334, 'auc': 0.96242}
2025-08-27 05:03:25,565 - INFO - > Epoch 90: took 95.1s (avg 95.8s) | Best so far: epoch 88	train_loss: 0.4919 train_accuracy-SBM: 0.8207	val_loss: 0.6282 val_accuracy-SBM: 0.7869	test_loss: 0.6222 test_accuracy-SBM: 0.7834
2025-08-27 05:03:25,565 - INFO - === Epoch 91 ===
2025-08-27 05:04:50,998 - INFO - train: {'epoch': 91, 'time_epoch': 85.17657, 'eta': 679.21909, 'eta_hours': 0.18867, 'loss': 0.49104475, 'lr': 2.198e-05, 'params': 501014, 'time_iter': 0.13628, 'accuracy': 0.82116, 'f1': 0.82116, 'accuracy-SBM': 0.82116, 'auc': 0.97588}
2025-08-27 05:04:55,310 - INFO - val: {'epoch': 91, 'time_epoch': 4.25559, 'loss': 0.62905172, 'lr': 0, 'params': 501014, 'time_iter': 0.06755, 'accuracy': 0.78654, 'f1': 0.78643, 'accuracy-SBM': 0.78641, 'auc': 0.96172}
2025-08-27 05:05:03,576 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 05:05:03,631 - INFO - test: {'epoch': 91, 'time_epoch': 4.51956, 'loss': 0.62408488, 'lr': 0, 'params': 501014, 'time_iter': 0.07174, 'accuracy': 0.78312, 'f1': 0.78309, 'accuracy-SBM': 0.78308, 'auc': 0.96218}
2025-08-27 05:05:03,633 - INFO - > Epoch 91: took 98.1s (avg 95.8s) | Best so far: epoch 88	train_loss: 0.4919 train_accuracy-SBM: 0.8207	val_loss: 0.6282 val_accuracy-SBM: 0.7869	test_loss: 0.6222 test_accuracy-SBM: 0.7834
2025-08-27 05:05:03,633 - INFO - === Epoch 92 ===
2025-08-27 05:06:28,620 - INFO - train: {'epoch': 92, 'time_epoch': 84.73981, 'eta': 594.30447, 'eta_hours': 0.16508, 'loss': 0.49005357, 'lr': 1.74e-05, 'params': 501014, 'time_iter': 0.13558, 'accuracy': 0.82092, 'f1': 0.82092, 'accuracy-SBM': 0.82092, 'auc': 0.97597}
2025-08-27 05:06:32,950 - INFO - val: {'epoch': 92, 'time_epoch': 4.27375, 'loss': 0.63247747, 'lr': 0, 'params': 501014, 'time_iter': 0.06784, 'accuracy': 0.78549, 'f1': 0.7854, 'accuracy-SBM': 0.78539, 'auc': 0.9615}
2025-08-27 05:06:39,226 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 05:06:39,266 - INFO - test: {'epoch': 92, 'time_epoch': 4.53429, 'loss': 0.62507955, 'lr': 0, 'params': 501014, 'time_iter': 0.07197, 'accuracy': 0.78334, 'f1': 0.78329, 'accuracy-SBM': 0.7833, 'auc': 0.96219}
2025-08-27 05:06:39,269 - INFO - > Epoch 92: took 95.6s (avg 95.8s) | Best so far: epoch 88	train_loss: 0.4919 train_accuracy-SBM: 0.8207	val_loss: 0.6282 val_accuracy-SBM: 0.7869	test_loss: 0.6222 test_accuracy-SBM: 0.7834
2025-08-27 05:06:39,269 - INFO - === Epoch 93 ===
2025-08-27 05:08:04,351 - INFO - train: {'epoch': 93, 'time_epoch': 84.82754, 'eta': 509.39916, 'eta_hours': 0.1415, 'loss': 0.48930026, 'lr': 1.334e-05, 'params': 501014, 'time_iter': 0.13572, 'accuracy': 0.82156, 'f1': 0.82156, 'accuracy-SBM': 0.82156, 'auc': 0.97604}
2025-08-27 05:08:08,750 - INFO - val: {'epoch': 93, 'time_epoch': 4.30429, 'loss': 0.63062247, 'lr': 0, 'params': 501014, 'time_iter': 0.06832, 'accuracy': 0.78554, 'f1': 0.78546, 'accuracy-SBM': 0.78545, 'auc': 0.96153}
2025-08-27 05:08:15,039 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 05:08:15,093 - INFO - test: {'epoch': 93, 'time_epoch': 4.27773, 'loss': 0.61983102, 'lr': 0, 'params': 501014, 'time_iter': 0.0679, 'accuracy': 0.78398, 'f1': 0.78396, 'accuracy-SBM': 0.78398, 'auc': 0.96259}
2025-08-27 05:08:15,095 - INFO - > Epoch 93: took 95.8s (avg 95.8s) | Best so far: epoch 88	train_loss: 0.4919 train_accuracy-SBM: 0.8207	val_loss: 0.6282 val_accuracy-SBM: 0.7869	test_loss: 0.6222 test_accuracy-SBM: 0.7834
2025-08-27 05:08:15,095 - INFO - === Epoch 94 ===
2025-08-27 05:09:39,470 - INFO - train: {'epoch': 94, 'time_epoch': 84.10876, 'eta': 424.45766, 'eta_hours': 0.1179, 'loss': 0.48989891, 'lr': 9.81e-06, 'params': 501014, 'time_iter': 0.13457, 'accuracy': 0.82124, 'f1': 0.82124, 'accuracy-SBM': 0.82124, 'auc': 0.97599}
2025-08-27 05:09:43,741 - INFO - val: {'epoch': 94, 'time_epoch': 4.22362, 'loss': 0.63084382, 'lr': 0, 'params': 501014, 'time_iter': 0.06704, 'accuracy': 0.78625, 'f1': 0.78618, 'accuracy-SBM': 0.78616, 'auc': 0.96166}
2025-08-27 05:09:50,054 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 05:09:50,099 - INFO - test: {'epoch': 94, 'time_epoch': 4.55475, 'loss': 0.62347365, 'lr': 0, 'params': 501014, 'time_iter': 0.0723, 'accuracy': 0.78374, 'f1': 0.78372, 'accuracy-SBM': 0.78374, 'auc': 0.96234}
2025-08-27 05:09:50,101 - INFO - > Epoch 94: took 95.0s (avg 95.8s) | Best so far: epoch 88	train_loss: 0.4919 train_accuracy-SBM: 0.8207	val_loss: 0.6282 val_accuracy-SBM: 0.7869	test_loss: 0.6222 test_accuracy-SBM: 0.7834
2025-08-27 05:09:50,102 - INFO - === Epoch 95 ===
2025-08-27 05:11:15,245 - INFO - train: {'epoch': 95, 'time_epoch': 84.88924, 'eta': 339.56604, 'eta_hours': 0.09432, 'loss': 0.48961307, 'lr': 6.82e-06, 'params': 501014, 'time_iter': 0.13582, 'accuracy': 0.82155, 'f1': 0.82155, 'accuracy-SBM': 0.82156, 'auc': 0.97601}
2025-08-27 05:11:19,542 - INFO - val: {'epoch': 95, 'time_epoch': 4.24982, 'loss': 0.63026248, 'lr': 0, 'params': 501014, 'time_iter': 0.06746, 'accuracy': 0.78594, 'f1': 0.78588, 'accuracy-SBM': 0.78584, 'auc': 0.96164}
2025-08-27 05:11:25,606 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 05:11:25,645 - INFO - test: {'epoch': 95, 'time_epoch': 4.53026, 'loss': 0.62037688, 'lr': 0, 'params': 501014, 'time_iter': 0.07191, 'accuracy': 0.7839, 'f1': 0.78388, 'accuracy-SBM': 0.7839, 'auc': 0.96262}
2025-08-27 05:11:25,647 - INFO - > Epoch 95: took 95.5s (avg 95.8s) | Best so far: epoch 88	train_loss: 0.4919 train_accuracy-SBM: 0.8207	val_loss: 0.6282 val_accuracy-SBM: 0.7869	test_loss: 0.6222 test_accuracy-SBM: 0.7834
2025-08-27 05:11:25,647 - INFO - === Epoch 96 ===
2025-08-27 05:12:50,344 - INFO - train: {'epoch': 96, 'time_epoch': 84.44971, 'eta': 254.66086, 'eta_hours': 0.07074, 'loss': 0.48999869, 'lr': 4.37e-06, 'params': 501014, 'time_iter': 0.13512, 'accuracy': 0.82096, 'f1': 0.82096, 'accuracy-SBM': 0.82096, 'auc': 0.97599}
2025-08-27 05:12:54,637 - INFO - val: {'epoch': 96, 'time_epoch': 4.24447, 'loss': 0.62965214, 'lr': 0, 'params': 501014, 'time_iter': 0.06737, 'accuracy': 0.78638, 'f1': 0.78631, 'accuracy-SBM': 0.78631, 'auc': 0.96171}
2025-08-27 05:13:00,583 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 05:13:00,634 - INFO - test: {'epoch': 96, 'time_epoch': 4.54512, 'loss': 0.62180201, 'lr': 0, 'params': 501014, 'time_iter': 0.07214, 'accuracy': 0.78444, 'f1': 0.78441, 'accuracy-SBM': 0.78442, 'auc': 0.96248}
2025-08-27 05:13:00,636 - INFO - > Epoch 96: took 95.0s (avg 95.8s) | Best so far: epoch 88	train_loss: 0.4919 train_accuracy-SBM: 0.8207	val_loss: 0.6282 val_accuracy-SBM: 0.7869	test_loss: 0.6222 test_accuracy-SBM: 0.7834
2025-08-27 05:13:00,636 - INFO - === Epoch 97 ===
2025-08-27 05:14:25,448 - INFO - train: {'epoch': 97, 'time_epoch': 84.56297, 'eta': 169.7673, 'eta_hours': 0.04716, 'loss': 0.49032767, 'lr': 2.46e-06, 'params': 501014, 'time_iter': 0.1353, 'accuracy': 0.82118, 'f1': 0.82118, 'accuracy-SBM': 0.82118, 'auc': 0.97595}
2025-08-27 05:14:29,764 - INFO - val: {'epoch': 97, 'time_epoch': 4.27003, 'loss': 0.63155799, 'lr': 0, 'params': 501014, 'time_iter': 0.06778, 'accuracy': 0.78626, 'f1': 0.78619, 'accuracy-SBM': 0.78617, 'auc': 0.96153}
2025-08-27 05:14:35,714 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 05:14:35,753 - INFO - test: {'epoch': 97, 'time_epoch': 4.53061, 'loss': 0.62371776, 'lr': 0, 'params': 501014, 'time_iter': 0.07191, 'accuracy': 0.78379, 'f1': 0.78374, 'accuracy-SBM': 0.78376, 'auc': 0.96229}
2025-08-27 05:14:35,755 - INFO - > Epoch 97: took 95.1s (avg 95.8s) | Best so far: epoch 88	train_loss: 0.4919 train_accuracy-SBM: 0.8207	val_loss: 0.6282 val_accuracy-SBM: 0.7869	test_loss: 0.6222 test_accuracy-SBM: 0.7834
2025-08-27 05:14:35,755 - INFO - === Epoch 98 ===
2025-08-27 05:16:00,584 - INFO - train: {'epoch': 98, 'time_epoch': 84.57553, 'eta': 84.88054, 'eta_hours': 0.02358, 'loss': 0.49008528, 'lr': 1.09e-06, 'params': 501014, 'time_iter': 0.13532, 'accuracy': 0.82114, 'f1': 0.82114, 'accuracy-SBM': 0.82114, 'auc': 0.97597}
2025-08-27 05:16:04,892 - INFO - val: {'epoch': 98, 'time_epoch': 4.26111, 'loss': 0.62908901, 'lr': 0, 'params': 501014, 'time_iter': 0.06764, 'accuracy': 0.78644, 'f1': 0.78638, 'accuracy-SBM': 0.78636, 'auc': 0.96178}
2025-08-27 05:16:10,894 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 05:16:10,934 - INFO - test: {'epoch': 98, 'time_epoch': 4.51118, 'loss': 0.61942903, 'lr': 0, 'params': 501014, 'time_iter': 0.07161, 'accuracy': 0.78437, 'f1': 0.78434, 'accuracy-SBM': 0.78436, 'auc': 0.96274}
2025-08-27 05:16:10,936 - INFO - > Epoch 98: took 95.2s (avg 95.8s) | Best so far: epoch 88	train_loss: 0.4919 train_accuracy-SBM: 0.8207	val_loss: 0.6282 val_accuracy-SBM: 0.7869	test_loss: 0.6222 test_accuracy-SBM: 0.7834
2025-08-27 05:16:10,936 - INFO - === Epoch 99 ===
2025-08-27 05:17:35,568 - INFO - train: {'epoch': 99, 'time_epoch': 84.38396, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.48886724, 'lr': 2.7e-07, 'params': 501014, 'time_iter': 0.13501, 'accuracy': 0.82147, 'f1': 0.82147, 'accuracy-SBM': 0.82147, 'auc': 0.97609}
2025-08-27 05:17:39,847 - INFO - val: {'epoch': 99, 'time_epoch': 4.23155, 'loss': 0.63018941, 'lr': 0, 'params': 501014, 'time_iter': 0.06717, 'accuracy': 0.78674, 'f1': 0.78667, 'accuracy-SBM': 0.78664, 'auc': 0.96157}
2025-08-27 05:17:45,812 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-27 05:17:45,851 - INFO - test: {'epoch': 99, 'time_epoch': 4.5149, 'loss': 0.62200727, 'lr': 0, 'params': 501014, 'time_iter': 0.07167, 'accuracy': 0.78364, 'f1': 0.78361, 'accuracy-SBM': 0.78364, 'auc': 0.9624}
2025-08-27 05:17:46,074 - INFO - > Epoch 99: took 94.9s (avg 95.7s) | Best so far: epoch 88	train_loss: 0.4919 train_accuracy-SBM: 0.8207	val_loss: 0.6282 val_accuracy-SBM: 0.7869	test_loss: 0.6222 test_accuracy-SBM: 0.7834
2025-08-27 05:17:46,074 - INFO - ================================================================================
2025-08-27 05:17:46,074 - INFO - NAS TRAINING COMPLETED SUCCESSFULLY
2025-08-27 05:17:46,074 - INFO - ================================================================================
2025-08-27 05:17:46,074 - INFO - Avg time per epoch: 95.75s
2025-08-27 05:17:46,074 - INFO - Total train loop time: 2.66h
2025-08-27 05:17:46,074 - INFO - Routing mode: nas
2025-08-27 05:17:46,074 - INFO - Final optimal weights: {'layer_0': 0, 'layer_1': 2, 'layer_2': 2, 'layer_3': 1, 'layer_4': 1, 'layer_5': 1, 'layer_6': 1, 'layer_7': 0, 'layer_8': 0, 'layer_9': 1, 'layer_10': 1, 'layer_11': 1, 'layer_12': 0, 'layer_13': 1, 'layer_14': 1, 'layer_15': 1}
2025-08-27 05:17:46,074 - INFO - Results include routing uncertainty (test only, NO variance)
2025-08-27 05:17:46,076 - INFO - Task done, results saved in results/Cluster/Cluster-SparseE-47
2025-08-27 05:17:46,079 - INFO - Total time: 13221.92s (3.67h)
2025-08-27 05:17:46,114 - INFO - Results aggregated across runs saved in results/Cluster/Cluster-SparseE-47/agg
2025-08-27 05:17:46,115 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-27 05:17:46,115 - INFO - Results saved in: results/Cluster/Cluster-SparseE-47
2025-08-27 05:17:46,115 - INFO - Test results JSON files saved in: results/Cluster/Cluster-SparseE-47/test_results/
Completed seed 47. Results saved in results/Cluster/Cluster-SparseE-47
----------------------------------------
All experiments completed!
/var/spool/slurmd/job5497907/slurm_script: line 71: syntax error near unexpected token `"/data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E"'
/var/spool/slurmd/job5497907/slurm_script: line 71: `os.chdir("/data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E")'
