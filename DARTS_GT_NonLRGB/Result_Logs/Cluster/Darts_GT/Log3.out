Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          376Gi        14Gi       344Gi       1.5Gi        17Gi       357Gi
Swap:         1.9Gi       657Mi       1.2Gi
Sat Aug 16 21:51:35 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:1A:00.0 Off |                    0 |
| N/A   46C    P0             45W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 49
Starting training for seed 49...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E/confignas.yaml
Using device: cuda
2025-08-16 21:51:58,879 - INFO - GPU Mem: 34.1GB
2025-08-16 21:51:58,879 - INFO - Run directory: results/Cluster/Cluster-SparseE-49
2025-08-16 21:51:58,879 - INFO - Seed: 49
2025-08-16 21:51:58,879 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-16 21:51:58,879 - INFO - Routing mode: nas
2025-08-16 21:51:58,879 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-16 21:51:58,879 - INFO - Number of layers: 16
2025-08-16 21:51:58,879 - INFO - Uncertainty enabled: False
2025-08-16 21:51:58,879 - INFO - Training mode: NoMixNas_uncertainty_train
2025-08-16 21:51:58,879 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-16 21:51:58,879 - INFO - Additional features: Router weights logging + JSON export
2025-08-16 21:52:12,732 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 21:52:12,734 - INFO -   Data(x=[1406436, 7], edge_index=[2, 51620680], y=[1406436])
2025-08-16 21:52:12,736 - INFO -   undirected: True
2025-08-16 21:52:12,736 - INFO -   num graphs: 12000
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 21:52:12,736 - INFO -   avg num_nodes/graph: 117
2025-08-16 21:52:12,736 - INFO -   num node features: 7
2025-08-16 21:52:12,737 - INFO -   num edge features: 0
2025-08-16 21:52:12,738 - INFO -   num classes: 6
2025-08-16 21:52:12,738 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 4, 8, 16]
2025-08-16 21:52:12,738 - INFO - Precomputing Positional Encoding statistics: ['LapPE', 'RWSE'] for all graphs...
2025-08-16 21:52:12,747 - INFO -   ...estimated to be undirected: True

  0%|          | 0/12000 [00:00<?, ?it/s]
 16%|█▋        | 1959/12000 [00:10<00:51, 195.90it/s]
 32%|███▏      | 3853/12000 [00:20<00:42, 192.01it/s]
 48%|████▊     | 5797/12000 [00:30<00:32, 193.07it/s]
 65%|██████▍   | 7779/12000 [00:40<00:21, 195.06it/s]
 82%|████████▏ | 9781/12000 [00:50<00:11, 196.90it/s]
 98%|█████████▊| 11806/12000 [01:00<00:00, 198.80it/s]
100%|██████████| 12000/12000 [01:00<00:00, 196.80it/s]
2025-08-16 21:53:14,507 - INFO - Done! Took 00:01:01.77
2025-08-16 21:53:14,528 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset'
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/nni/nas/nn/pytorch/choice.py:252: UserWarning: "key" is deprecated. Assuming label.
  warnings.warn(f'"key" is deprecated. Assuming label.')
2025-08-16 21:53:14,958 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-16 21:53:14,959 - INFO - Inner model type: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-08-16 21:53:14,959 - INFO - Inner model has get_darts_model: True
2025-08-16 21:53:14,964 - INFO - GraphGymModule(
  (model): NASModelEdge(
    (encoder): FeatureEncoder(
      (node_encoder): LapPENodeEncoder(
        (linear_x): Linear(in_features=7, out_features=32, bias=True)
        (linear_A): Linear(in_features=2, out_features=32, bias=True)
        (pe_encoder): Sequential(
          (0): ReLU()
          (1): Linear(in_features=32, out_features=16, bias=True)
          (2): ReLU()
        )
      )
      (edge_encoder): DummyEdgeEncoder(
        (encoder): Embedding(1, 48)
      )
    )
    (darts_layers): ModuleList(
      (0): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (6): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_6')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (7): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_7')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (8): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_8')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (9): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_9')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (10): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_10')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (11): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_11')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (12): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_12')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (13): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_13')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (14): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_14')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (15): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_15')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (darts_sequential): Sequential(
      (0): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (6): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_6')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (7): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_7')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (8): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_8')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (9): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_9')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (10): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_10')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (11): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_11')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (12): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_12')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (13): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_13')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (14): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_14')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (15): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_15')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(48, 48, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(48, 48, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(48, 6, bias=True)
          )
        )
      )
    )
  )
)
2025-08-16 21:53:14,976 - INFO - Number of parameters: 728,630
2025-08-16 21:53:14,976 - INFO - Starting optimized training: 2025-08-16 21:53:14.976178
2025-08-16 21:53:20,388 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset':
2025-08-16 21:53:20,388 - INFO -   Data(x=[1406436, 7], edge_index=[2, 51620680], y=[1406436])
2025-08-16 21:53:20,390 - INFO -   undirected: True
2025-08-16 21:53:20,390 - INFO -   num graphs: 12000
2025-08-16 21:53:20,390 - INFO -   avg num_nodes/graph: 117
2025-08-16 21:53:20,390 - INFO -   num node features: 7
2025-08-16 21:53:20,390 - INFO -   num edge features: 0
2025-08-16 21:53:20,392 - INFO -   num classes: 6
2025-08-16 21:53:20,392 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 4, 8, 16]
2025-08-16 21:53:20,392 - INFO - Precomputing Positional Encoding statistics: ['LapPE', 'RWSE'] for all graphs...
2025-08-16 21:53:20,400 - INFO -   ...estimated to be undirected: True

  0%|          | 0/12000 [00:00<?, ?it/s]
 17%|█▋        | 2008/12000 [00:10<00:49, 200.75it/s]
 34%|███▍      | 4054/12000 [00:20<00:39, 203.00it/s]
 52%|█████▏    | 6198/12000 [00:30<00:27, 208.17it/s]
 68%|██████▊   | 8203/12000 [00:40<00:18, 205.12it/s]
 85%|████████▌ | 10235/12000 [00:50<00:08, 204.42it/s]
100%|██████████| 12000/12000 [00:58<00:00, 204.75it/s]
2025-08-16 21:54:19,743 - INFO - Done! Took 00:00:59.35
2025-08-16 21:54:19,767 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset'
2025-08-16 21:54:19,910 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-16 21:54:19,910 - INFO - Start from epoch 0
2025-08-16 21:54:19,910 - INFO - ================================================================================
2025-08-16 21:54:19,910 - INFO - STARTING TWO-PHASE NAS TRAINING
2025-08-16 21:54:19,910 - INFO - ================================================================================
2025-08-16 21:54:19,910 - INFO - Routing mode: nas
2025-08-16 21:54:19,910 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-16 21:54:19,910 - INFO - Phase 1: Architecture search/initialization
2025-08-16 21:54:19,910 - INFO - Phase 2: Discrete training with uncertainty (NO variance)
2025-08-16 21:54:19,910 - INFO - ============================================================
2025-08-16 21:54:19,910 - INFO - PHASE 1: ARCHITECTURE SEARCH/INITIALIZATION
2025-08-16 21:54:19,910 - INFO - ============================================================
2025-08-16 21:54:19,910 - INFO - Splitting dataset for DARTS:
2025-08-16 21:54:19,910 - INFO -   Original train size: 10000
2025-08-16 21:54:19,910 - INFO -   DARTS train size: 6000 (60.0%)
2025-08-16 21:54:19,911 - INFO -   DARTS val size: 4000 (40.0%)
2025-08-16 21:54:19,911 - INFO - Found GraphGym wrapper, using inner model: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-08-16 21:54:19,912 - INFO - Successfully configured model for DARTS training
2025-08-16 21:54:19,912 - INFO - NAS MODE: Running 25 epochs with DARTS
2025-08-16 21:54:19,912 - INFO - DARTS Configuration:
2025-08-16 21:54:19,912 - INFO -   Epochs: 25
2025-08-16 21:54:19,912 - INFO -   Architecture LR: 0.0004
2025-08-16 21:54:19,912 - INFO -   Grad clip: 5.0
2025-08-16 21:54:19,916 - INFO - Starting DARTS architecture search
2025-08-16 21:54:23,059 - WARNING - Epoch [1/25] Step [1/250]  acc 0.177445 (0.177445)  loss 1.798213 (1.798213)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 3026.0 MB
2025-08-16 21:54:27,424 - WARNING - Epoch [1/25] Step [11/250]  acc 0.161522 (0.162277)  loss 1.792385 (1.794630)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 5982.0 MB
2025-08-16 21:54:31,814 - WARNING - Epoch [1/25] Step [21/250]  acc 0.182627 (0.167356)  loss 1.793369 (1.793127)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 5998.0 MB
2025-08-16 21:54:36,173 - WARNING - Epoch [1/25] Step [31/250]  acc 0.186211 (0.170483)  loss 1.790555 (1.792374)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 6000.0 MB
2025-08-16 21:54:40,523 - WARNING - Epoch [1/25] Step [41/250]  acc 0.168378 (0.171185)  loss 1.793250 (1.791831)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6000.0 MB
2025-08-16 21:54:45,113 - WARNING - Epoch [1/25] Step [51/250]  acc 0.162023 (0.171921)  loss 1.792884 (1.791376)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 7206.0 MB
2025-08-16 21:54:49,447 - WARNING - Epoch [1/25] Step [61/250]  acc 0.179541 (0.172941)  loss 1.787820 (1.790814)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7206.0 MB
2025-08-16 21:54:53,824 - WARNING - Epoch [1/25] Step [71/250]  acc 0.181956 (0.174284)  loss 1.785849 (1.790137)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 7206.0 MB
2025-08-16 21:54:58,162 - WARNING - Epoch [1/25] Step [81/250]  acc 0.205711 (0.177238)  loss 1.775506 (1.788921)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7206.0 MB
2025-08-16 21:55:02,601 - WARNING - Epoch [1/25] Step [91/250]  acc 0.194826 (0.179778)  loss 1.777228 (1.787622)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 7206.0 MB
2025-08-16 21:55:07,005 - WARNING - Epoch [1/25] Step [101/250]  acc 0.199405 (0.183017)  loss 1.753514 (1.785035)
GPU memory consumption  GPU Memory: Allocated: 60.2 MB, Reserved: 7206.0 MB
2025-08-16 21:55:11,413 - WARNING - Epoch [1/25] Step [111/250]  acc 0.227447 (0.186947)  loss 1.740462 (1.781690)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7206.0 MB
2025-08-16 21:55:15,786 - WARNING - Epoch [1/25] Step [121/250]  acc 0.243837 (0.191243)  loss 1.725099 (1.777741)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7206.0 MB
2025-08-16 21:55:20,388 - WARNING - Epoch [1/25] Step [131/250]  acc 0.233779 (0.194071)  loss 1.720858 (1.773710)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7206.0 MB
2025-08-16 21:55:24,729 - WARNING - Epoch [1/25] Step [141/250]  acc 0.238122 (0.197749)  loss 1.712100 (1.768784)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7210.0 MB
2025-08-16 21:55:29,047 - WARNING - Epoch [1/25] Step [151/250]  acc 0.256764 (0.201019)  loss 1.701202 (1.764131)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7210.0 MB
2025-08-16 21:55:33,420 - WARNING - Epoch [1/25] Step [161/250]  acc 0.241121 (0.203950)  loss 1.690064 (1.759259)
GPU memory consumption  GPU Memory: Allocated: 61.4 MB, Reserved: 7210.0 MB
2025-08-16 21:55:37,773 - WARNING - Epoch [1/25] Step [171/250]  acc 0.275171 (0.207275)  loss 1.666563 (1.753961)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7210.0 MB
2025-08-16 21:55:42,143 - WARNING - Epoch [1/25] Step [181/250]  acc 0.251251 (0.209342)  loss 1.669913 (1.750653)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 7210.0 MB
2025-08-16 21:55:46,691 - WARNING - Epoch [1/25] Step [191/250]  acc 0.251326 (0.211753)  loss 1.638205 (1.745668)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 7210.0 MB
2025-08-16 21:55:51,091 - WARNING - Epoch [1/25] Step [201/250]  acc 0.217914 (0.213703)  loss 1.709751 (1.741559)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7210.0 MB
2025-08-16 21:55:55,456 - WARNING - Epoch [1/25] Step [211/250]  acc 0.251455 (0.214748)  loss 1.647847 (1.737651)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 7210.0 MB
2025-08-16 21:55:59,805 - WARNING - Epoch [1/25] Step [221/250]  acc 0.211117 (0.216122)  loss 1.636910 (1.733545)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7210.0 MB
2025-08-16 21:56:04,213 - WARNING - Epoch [1/25] Step [231/250]  acc 0.259145 (0.217342)  loss 1.623695 (1.729456)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7210.0 MB
2025-08-16 21:56:08,594 - WARNING - Epoch [1/25] Step [241/250]  acc 0.262312 (0.218748)  loss 1.651534 (1.725780)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7210.0 MB
Epoch 1 completed in 0:01:52.625675
2025-08-16 21:56:39,459 - WARNING - Epoch [2/25] Step [1/250]  acc 0.251438 (0.251438)  loss 1.602239 (1.602239)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7210.0 MB
2025-08-16 21:56:43,788 - WARNING - Epoch [2/25] Step [11/250]  acc 0.291267 (0.247076)  loss 1.631829 (1.636364)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 7210.0 MB
2025-08-16 21:56:48,130 - WARNING - Epoch [2/25] Step [21/250]  acc 0.227923 (0.254283)  loss 1.638788 (1.629769)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 7210.0 MB
2025-08-16 21:56:52,504 - WARNING - Epoch [2/25] Step [31/250]  acc 0.222851 (0.251712)  loss 1.591249 (1.630738)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7210.0 MB
2025-08-16 21:56:56,855 - WARNING - Epoch [2/25] Step [41/250]  acc 0.269909 (0.253315)  loss 1.602812 (1.627858)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 7210.0 MB
2025-08-16 21:57:01,503 - WARNING - Epoch [2/25] Step [51/250]  acc 0.304072 (0.253341)  loss 1.606404 (1.628418)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7210.0 MB
2025-08-16 21:57:05,848 - WARNING - Epoch [2/25] Step [61/250]  acc 0.279598 (0.253044)  loss 1.628122 (1.630138)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7210.0 MB
2025-08-16 21:57:10,208 - WARNING - Epoch [2/25] Step [71/250]  acc 0.210309 (0.252337)  loss 1.654814 (1.628464)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 7210.0 MB
2025-08-16 21:57:14,586 - WARNING - Epoch [2/25] Step [81/250]  acc 0.260349 (0.254098)  loss 1.627150 (1.625911)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 7210.0 MB
2025-08-16 21:57:18,916 - WARNING - Epoch [2/25] Step [91/250]  acc 0.292589 (0.254241)  loss 1.640448 (1.626706)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7210.0 MB
2025-08-16 21:57:23,269 - WARNING - Epoch [2/25] Step [101/250]  acc 0.234155 (0.253586)  loss 1.689667 (1.627320)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7210.0 MB
2025-08-16 21:57:27,602 - WARNING - Epoch [2/25] Step [111/250]  acc 0.208891 (0.252107)  loss 1.658582 (1.627286)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7210.0 MB
2025-08-16 21:57:32,007 - WARNING - Epoch [2/25] Step [121/250]  acc 0.228778 (0.251108)  loss 1.612864 (1.626390)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 7210.0 MB
2025-08-16 21:57:36,325 - WARNING - Epoch [2/25] Step [131/250]  acc 0.259809 (0.250869)  loss 1.684957 (1.627915)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7210.0 MB
2025-08-16 21:57:40,650 - WARNING - Epoch [2/25] Step [141/250]  acc 0.223670 (0.250229)  loss 1.628606 (1.627839)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 7210.0 MB
2025-08-16 21:57:44,982 - WARNING - Epoch [2/25] Step [151/250]  acc 0.254009 (0.250057)  loss 1.621446 (1.628151)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7210.0 MB
2025-08-16 21:57:49,309 - WARNING - Epoch [2/25] Step [161/250]  acc 0.240805 (0.249701)  loss 1.584069 (1.627768)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 9262.0 MB
2025-08-16 21:57:53,655 - WARNING - Epoch [2/25] Step [171/250]  acc 0.233825 (0.249618)  loss 1.607464 (1.627358)
GPU memory consumption  GPU Memory: Allocated: 52.5 MB, Reserved: 9262.0 MB
2025-08-16 21:57:57,966 - WARNING - Epoch [2/25] Step [181/250]  acc 0.235263 (0.250046)  loss 1.644023 (1.627109)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9262.0 MB
2025-08-16 21:58:02,553 - WARNING - Epoch [2/25] Step [191/250]  acc 0.290650 (0.250248)  loss 1.568556 (1.626116)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9262.0 MB
2025-08-16 21:58:06,881 - WARNING - Epoch [2/25] Step [201/250]  acc 0.236667 (0.250511)  loss 1.602250 (1.626122)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 9262.0 MB
2025-08-16 21:58:11,222 - WARNING - Epoch [2/25] Step [211/250]  acc 0.251645 (0.250557)  loss 1.613786 (1.625593)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 9262.0 MB
2025-08-16 21:58:15,541 - WARNING - Epoch [2/25] Step [221/250]  acc 0.265675 (0.250507)  loss 1.585939 (1.624646)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 9264.0 MB
2025-08-16 21:58:19,841 - WARNING - Epoch [2/25] Step [231/250]  acc 0.257173 (0.250711)  loss 1.607557 (1.623132)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9264.0 MB
2025-08-16 21:58:24,104 - WARNING - Epoch [2/25] Step [241/250]  acc 0.255992 (0.250460)  loss 1.588717 (1.623087)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9264.0 MB
Epoch 2 completed in 0:01:48.941493
2025-08-16 21:58:54,695 - WARNING - Epoch [3/25] Step [1/250]  acc 0.233759 (0.233759)  loss 1.614215 (1.614215)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 9264.0 MB
2025-08-16 21:58:59,014 - WARNING - Epoch [3/25] Step [11/250]  acc 0.244235 (0.239996)  loss 1.578917 (1.606542)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 9264.0 MB
2025-08-16 21:59:03,367 - WARNING - Epoch [3/25] Step [21/250]  acc 0.277089 (0.248373)  loss 1.631140 (1.608232)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9264.0 MB
2025-08-16 21:59:07,665 - WARNING - Epoch [3/25] Step [31/250]  acc 0.255235 (0.250395)  loss 1.591047 (1.606885)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 9264.0 MB
2025-08-16 21:59:11,969 - WARNING - Epoch [3/25] Step [41/250]  acc 0.245459 (0.247216)  loss 1.621057 (1.609530)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9264.0 MB
2025-08-16 21:59:16,255 - WARNING - Epoch [3/25] Step [51/250]  acc 0.256890 (0.248716)  loss 1.637229 (1.608305)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9264.0 MB
2025-08-16 21:59:20,590 - WARNING - Epoch [3/25] Step [61/250]  acc 0.255777 (0.246313)  loss 1.610290 (1.607737)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9264.0 MB
2025-08-16 21:59:24,934 - WARNING - Epoch [3/25] Step [71/250]  acc 0.253036 (0.246719)  loss 1.597809 (1.608349)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 9264.0 MB
2025-08-16 21:59:29,514 - WARNING - Epoch [3/25] Step [81/250]  acc 0.254902 (0.247713)  loss 1.557210 (1.606291)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 9264.0 MB
2025-08-16 21:59:33,853 - WARNING - Epoch [3/25] Step [91/250]  acc 0.281087 (0.249152)  loss 1.567946 (1.606753)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 9264.0 MB
2025-08-16 21:59:38,168 - WARNING - Epoch [3/25] Step [101/250]  acc 0.225736 (0.249162)  loss 1.681603 (1.608116)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9264.0 MB
2025-08-16 21:59:42,481 - WARNING - Epoch [3/25] Step [111/250]  acc 0.229131 (0.249703)  loss 1.667176 (1.607816)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 9264.0 MB
2025-08-16 21:59:46,800 - WARNING - Epoch [3/25] Step [121/250]  acc 0.236605 (0.251533)  loss 1.591962 (1.606640)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9264.0 MB
2025-08-16 21:59:51,138 - WARNING - Epoch [3/25] Step [131/250]  acc 0.252347 (0.250846)  loss 1.596323 (1.606913)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 9264.0 MB
2025-08-16 21:59:55,477 - WARNING - Epoch [3/25] Step [141/250]  acc 0.245763 (0.250998)  loss 1.587002 (1.607428)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 9264.0 MB
2025-08-16 21:59:59,838 - WARNING - Epoch [3/25] Step [151/250]  acc 0.258012 (0.251325)  loss 1.578515 (1.606326)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 9264.0 MB
2025-08-16 22:00:04,411 - WARNING - Epoch [3/25] Step [161/250]  acc 0.253061 (0.250959)  loss 1.562683 (1.605889)
GPU memory consumption  GPU Memory: Allocated: 61.3 MB, Reserved: 9264.0 MB
2025-08-16 22:00:09,057 - WARNING - Epoch [3/25] Step [171/250]  acc 0.253024 (0.250882)  loss 1.574106 (1.606304)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 9264.0 MB
2025-08-16 22:00:13,550 - WARNING - Epoch [3/25] Step [181/250]  acc 0.222998 (0.251380)  loss 1.600687 (1.605928)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9264.0 MB
2025-08-16 22:00:17,897 - WARNING - Epoch [3/25] Step [191/250]  acc 0.253362 (0.251277)  loss 1.610122 (1.606147)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9264.0 MB
2025-08-16 22:00:22,243 - WARNING - Epoch [3/25] Step [201/250]  acc 0.258117 (0.250981)  loss 1.601766 (1.606311)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 9264.0 MB
2025-08-16 22:00:26,592 - WARNING - Epoch [3/25] Step [211/250]  acc 0.242333 (0.251469)  loss 1.597674 (1.605268)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9264.0 MB
2025-08-16 22:00:30,950 - WARNING - Epoch [3/25] Step [221/250]  acc 0.210160 (0.251474)  loss 1.624094 (1.605552)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 9264.0 MB
2025-08-16 22:00:35,541 - WARNING - Epoch [3/25] Step [231/250]  acc 0.215909 (0.251478)  loss 1.615238 (1.605534)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9264.0 MB
2025-08-16 22:00:39,862 - WARNING - Epoch [3/25] Step [241/250]  acc 0.264673 (0.251211)  loss 1.624259 (1.606077)
GPU memory consumption  GPU Memory: Allocated: 53.0 MB, Reserved: 9264.0 MB
Epoch 3 completed in 0:01:49.516612
2025-08-16 22:01:10,337 - WARNING - Epoch [4/25] Step [1/250]  acc 0.244119 (0.244119)  loss 1.681791 (1.681791)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9264.0 MB
2025-08-16 22:01:14,653 - WARNING - Epoch [4/25] Step [11/250]  acc 0.307735 (0.238891)  loss 1.593549 (1.636371)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9264.0 MB
2025-08-16 22:01:19,030 - WARNING - Epoch [4/25] Step [21/250]  acc 0.278529 (0.242189)  loss 1.595678 (1.629934)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9264.0 MB
2025-08-16 22:01:23,358 - WARNING - Epoch [4/25] Step [31/250]  acc 0.258351 (0.248220)  loss 1.645075 (1.627240)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9264.0 MB
2025-08-16 22:01:27,717 - WARNING - Epoch [4/25] Step [41/250]  acc 0.253158 (0.248023)  loss 1.657094 (1.622316)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 9264.0 MB
2025-08-16 22:01:32,072 - WARNING - Epoch [4/25] Step [51/250]  acc 0.254303 (0.246712)  loss 1.571174 (1.618720)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 9264.0 MB
2025-08-16 22:01:36,420 - WARNING - Epoch [4/25] Step [61/250]  acc 0.226571 (0.245686)  loss 1.603819 (1.616992)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9264.0 MB
2025-08-16 22:01:40,759 - WARNING - Epoch [4/25] Step [71/250]  acc 0.253928 (0.245311)  loss 1.670709 (1.618513)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9264.0 MB
2025-08-16 22:01:45,108 - WARNING - Epoch [4/25] Step [81/250]  acc 0.218266 (0.244301)  loss 1.633926 (1.619473)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9264.0 MB
2025-08-16 22:01:49,484 - WARNING - Epoch [4/25] Step [91/250]  acc 0.303526 (0.245843)  loss 1.584155 (1.615493)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9264.0 MB
2025-08-16 22:01:53,869 - WARNING - Epoch [4/25] Step [101/250]  acc 0.247312 (0.246638)  loss 1.601702 (1.612403)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 9264.0 MB
2025-08-16 22:01:58,256 - WARNING - Epoch [4/25] Step [111/250]  acc 0.234756 (0.245777)  loss 1.563482 (1.611697)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9264.0 MB
2025-08-16 22:02:02,652 - WARNING - Epoch [4/25] Step [121/250]  acc 0.261289 (0.246803)  loss 1.597499 (1.610352)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9264.0 MB
2025-08-16 22:02:07,261 - WARNING - Epoch [4/25] Step [131/250]  acc 0.261302 (0.246322)  loss 1.602076 (1.610657)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 9264.0 MB
2025-08-16 22:02:11,654 - WARNING - Epoch [4/25] Step [141/250]  acc 0.268142 (0.246241)  loss 1.577605 (1.608688)
GPU memory consumption  GPU Memory: Allocated: 60.1 MB, Reserved: 9264.0 MB
2025-08-16 22:02:16,062 - WARNING - Epoch [4/25] Step [151/250]  acc 0.262652 (0.246784)  loss 1.580310 (1.608608)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9264.0 MB
2025-08-16 22:02:20,410 - WARNING - Epoch [4/25] Step [161/250]  acc 0.252224 (0.246761)  loss 1.567605 (1.608101)
GPU memory consumption  GPU Memory: Allocated: 60.2 MB, Reserved: 9264.0 MB
2025-08-16 22:02:24,740 - WARNING - Epoch [4/25] Step [171/250]  acc 0.211572 (0.246506)  loss 1.605600 (1.607952)
GPU memory consumption  GPU Memory: Allocated: 52.3 MB, Reserved: 9264.0 MB
2025-08-16 22:02:29,095 - WARNING - Epoch [4/25] Step [181/250]  acc 0.243495 (0.247417)  loss 1.615840 (1.607191)
GPU memory consumption  GPU Memory: Allocated: 59.9 MB, Reserved: 9264.0 MB
2025-08-16 22:02:33,551 - WARNING - Epoch [4/25] Step [191/250]  acc 0.255721 (0.247920)  loss 1.622737 (1.607081)
GPU memory consumption  GPU Memory: Allocated: 59.4 MB, Reserved: 9264.0 MB
2025-08-16 22:02:37,950 - WARNING - Epoch [4/25] Step [201/250]  acc 0.257513 (0.247780)  loss 1.565252 (1.606850)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 9264.0 MB
2025-08-16 22:02:42,319 - WARNING - Epoch [4/25] Step [211/250]  acc 0.225352 (0.247224)  loss 1.575017 (1.606756)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 9264.0 MB
2025-08-16 22:02:46,686 - WARNING - Epoch [4/25] Step [221/250]  acc 0.229979 (0.246812)  loss 1.606407 (1.606896)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9264.0 MB
2025-08-16 22:02:51,091 - WARNING - Epoch [4/25] Step [231/250]  acc 0.274436 (0.246913)  loss 1.560872 (1.606068)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9264.0 MB
2025-08-16 22:02:55,428 - WARNING - Epoch [4/25] Step [241/250]  acc 0.261868 (0.246928)  loss 1.613858 (1.606203)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9264.0 MB
Epoch 4 completed in 0:01:49.472709
2025-08-16 22:03:26,257 - WARNING - Epoch [5/25] Step [1/250]  acc 0.282102 (0.282102)  loss 1.587201 (1.587201)
GPU memory consumption  GPU Memory: Allocated: 59.6 MB, Reserved: 9264.0 MB
2025-08-16 22:03:30,619 - WARNING - Epoch [5/25] Step [11/250]  acc 0.255561 (0.249145)  loss 1.548817 (1.595938)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 9264.0 MB
2025-08-16 22:03:34,989 - WARNING - Epoch [5/25] Step [21/250]  acc 0.218077 (0.249034)  loss 1.622059 (1.595368)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9264.0 MB
2025-08-16 22:03:39,619 - WARNING - Epoch [5/25] Step [31/250]  acc 0.227953 (0.245271)  loss 1.595641 (1.602404)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9264.0 MB
2025-08-16 22:03:43,999 - WARNING - Epoch [5/25] Step [41/250]  acc 0.222642 (0.245025)  loss 1.611052 (1.601770)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 9264.0 MB
2025-08-16 22:03:48,362 - WARNING - Epoch [5/25] Step [51/250]  acc 0.269441 (0.245207)  loss 1.545810 (1.598094)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 9264.0 MB
2025-08-16 22:03:52,731 - WARNING - Epoch [5/25] Step [61/250]  acc 0.251016 (0.246504)  loss 1.591810 (1.597048)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9264.0 MB
2025-08-16 22:03:57,089 - WARNING - Epoch [5/25] Step [71/250]  acc 0.280282 (0.246624)  loss 1.647463 (1.597012)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9264.0 MB
2025-08-16 22:04:01,437 - WARNING - Epoch [5/25] Step [81/250]  acc 0.257485 (0.246481)  loss 1.608917 (1.599079)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 9264.0 MB
2025-08-16 22:04:05,770 - WARNING - Epoch [5/25] Step [91/250]  acc 0.290116 (0.248531)  loss 1.582702 (1.598968)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 9264.0 MB
2025-08-16 22:04:10,103 - WARNING - Epoch [5/25] Step [101/250]  acc 0.220397 (0.249124)  loss 1.595987 (1.597733)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 9264.0 MB
2025-08-16 22:04:14,486 - WARNING - Epoch [5/25] Step [111/250]  acc 0.268320 (0.248494)  loss 1.608828 (1.598602)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 9264.0 MB
2025-08-16 22:04:18,842 - WARNING - Epoch [5/25] Step [121/250]  acc 0.259220 (0.249161)  loss 1.650099 (1.598605)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 9264.0 MB
2025-08-16 22:04:23,207 - WARNING - Epoch [5/25] Step [131/250]  acc 0.202762 (0.248637)  loss 1.628795 (1.599195)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 9264.0 MB
2025-08-16 22:04:27,560 - WARNING - Epoch [5/25] Step [141/250]  acc 0.251106 (0.248187)  loss 1.631965 (1.598167)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 9264.0 MB
2025-08-16 22:04:31,939 - WARNING - Epoch [5/25] Step [151/250]  acc 0.259753 (0.248460)  loss 1.614157 (1.599207)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 9268.0 MB
2025-08-16 22:04:36,278 - WARNING - Epoch [5/25] Step [161/250]  acc 0.222050 (0.248085)  loss 1.602201 (1.600285)
GPU memory consumption  GPU Memory: Allocated: 61.3 MB, Reserved: 9268.0 MB
2025-08-16 22:04:40,620 - WARNING - Epoch [5/25] Step [171/250]  acc 0.245429 (0.248258)  loss 1.555068 (1.600470)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 9268.0 MB
2025-08-16 22:04:44,963 - WARNING - Epoch [5/25] Step [181/250]  acc 0.247033 (0.248311)  loss 1.594124 (1.600314)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9268.0 MB
2025-08-16 22:04:49,570 - WARNING - Epoch [5/25] Step [191/250]  acc 0.248600 (0.248985)  loss 1.597966 (1.599477)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 9268.0 MB
2025-08-16 22:04:53,977 - WARNING - Epoch [5/25] Step [201/250]  acc 0.275749 (0.248852)  loss 1.605024 (1.599619)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 9268.0 MB
2025-08-16 22:04:58,363 - WARNING - Epoch [5/25] Step [211/250]  acc 0.259039 (0.248656)  loss 1.602263 (1.599949)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 9268.0 MB
2025-08-16 22:05:02,801 - WARNING - Epoch [5/25] Step [221/250]  acc 0.234043 (0.248199)  loss 1.576867 (1.599792)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 9268.0 MB
2025-08-16 22:05:07,268 - WARNING - Epoch [5/25] Step [231/250]  acc 0.241489 (0.248193)  loss 1.624100 (1.599609)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9268.0 MB
2025-08-16 22:05:11,664 - WARNING - Epoch [5/25] Step [241/250]  acc 0.258830 (0.248241)  loss 1.603128 (1.599427)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 9268.0 MB
Epoch 5 completed in 0:01:49.738766
2025-08-16 22:05:42,453 - WARNING - Epoch [6/25] Step [1/250]  acc 0.320657 (0.320657)  loss 1.571126 (1.571126)
GPU memory consumption  GPU Memory: Allocated: 61.1 MB, Reserved: 9268.0 MB
2025-08-16 22:05:46,788 - WARNING - Epoch [6/25] Step [11/250]  acc 0.240474 (0.263109)  loss 1.589632 (1.599725)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 9268.0 MB
2025-08-16 22:05:51,165 - WARNING - Epoch [6/25] Step [21/250]  acc 0.304972 (0.256526)  loss 1.556988 (1.596079)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:05:55,498 - WARNING - Epoch [6/25] Step [31/250]  acc 0.231285 (0.254086)  loss 1.641708 (1.605973)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:05:59,862 - WARNING - Epoch [6/25] Step [41/250]  acc 0.219809 (0.253289)  loss 1.720897 (1.604606)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 9268.0 MB
2025-08-16 22:06:04,254 - WARNING - Epoch [6/25] Step [51/250]  acc 0.251361 (0.252252)  loss 1.610740 (1.606977)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9268.0 MB
2025-08-16 22:06:08,638 - WARNING - Epoch [6/25] Step [61/250]  acc 0.268354 (0.251993)  loss 1.585180 (1.606859)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9268.0 MB
2025-08-16 22:06:13,037 - WARNING - Epoch [6/25] Step [71/250]  acc 0.237418 (0.250205)  loss 1.592770 (1.605547)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 9268.0 MB
2025-08-16 22:06:17,405 - WARNING - Epoch [6/25] Step [81/250]  acc 0.238283 (0.250370)  loss 1.626852 (1.606065)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 9268.0 MB
2025-08-16 22:06:22,055 - WARNING - Epoch [6/25] Step [91/250]  acc 0.240548 (0.249642)  loss 1.592819 (1.606639)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9268.0 MB
2025-08-16 22:06:26,404 - WARNING - Epoch [6/25] Step [101/250]  acc 0.248552 (0.250063)  loss 1.607047 (1.607044)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 9268.0 MB
2025-08-16 22:06:30,793 - WARNING - Epoch [6/25] Step [111/250]  acc 0.254255 (0.249319)  loss 1.596964 (1.604727)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9268.0 MB
2025-08-16 22:06:35,157 - WARNING - Epoch [6/25] Step [121/250]  acc 0.274074 (0.250051)  loss 1.561173 (1.604110)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 9268.0 MB
2025-08-16 22:06:39,540 - WARNING - Epoch [6/25] Step [131/250]  acc 0.256098 (0.250631)  loss 1.617836 (1.603230)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 9268.0 MB
2025-08-16 22:06:43,897 - WARNING - Epoch [6/25] Step [141/250]  acc 0.202794 (0.251084)  loss 1.606792 (1.603483)
GPU memory consumption  GPU Memory: Allocated: 60.1 MB, Reserved: 9268.0 MB
2025-08-16 22:06:48,257 - WARNING - Epoch [6/25] Step [151/250]  acc 0.239956 (0.250842)  loss 1.644547 (1.603119)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 9268.0 MB
2025-08-16 22:06:52,647 - WARNING - Epoch [6/25] Step [161/250]  acc 0.268371 (0.251054)  loss 1.556468 (1.603142)
GPU memory consumption  GPU Memory: Allocated: 59.9 MB, Reserved: 9268.0 MB
2025-08-16 22:06:56,932 - WARNING - Epoch [6/25] Step [171/250]  acc 0.280580 (0.250938)  loss 1.620020 (1.603096)
GPU memory consumption  GPU Memory: Allocated: 52.3 MB, Reserved: 9268.0 MB
2025-08-16 22:07:01,311 - WARNING - Epoch [6/25] Step [181/250]  acc 0.244235 (0.250622)  loss 1.607113 (1.602446)
GPU memory consumption  GPU Memory: Allocated: 61.2 MB, Reserved: 9268.0 MB
2025-08-16 22:07:05,770 - WARNING - Epoch [6/25] Step [191/250]  acc 0.233470 (0.250270)  loss 1.557360 (1.602195)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 9268.0 MB
2025-08-16 22:07:10,171 - WARNING - Epoch [6/25] Step [201/250]  acc 0.200339 (0.249632)  loss 1.639118 (1.602483)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 9268.0 MB
2025-08-16 22:07:14,743 - WARNING - Epoch [6/25] Step [211/250]  acc 0.269438 (0.249712)  loss 1.555976 (1.602098)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 9268.0 MB
2025-08-16 22:07:19,425 - WARNING - Epoch [6/25] Step [221/250]  acc 0.250387 (0.249541)  loss 1.587551 (1.602331)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9268.0 MB
2025-08-16 22:07:24,158 - WARNING - Epoch [6/25] Step [231/250]  acc 0.256568 (0.249637)  loss 1.652187 (1.602498)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 9268.0 MB
2025-08-16 22:07:29,345 - WARNING - Epoch [6/25] Step [241/250]  acc 0.253976 (0.249783)  loss 1.609408 (1.602423)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 9268.0 MB
Epoch 6 completed in 0:01:51.448828
2025-08-16 22:08:00,858 - WARNING - Epoch [7/25] Step [1/250]  acc 0.230687 (0.230687)  loss 1.592394 (1.592394)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 9268.0 MB
2025-08-16 22:08:05,328 - WARNING - Epoch [7/25] Step [11/250]  acc 0.222991 (0.252143)  loss 1.609190 (1.591037)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 9268.0 MB
2025-08-16 22:08:09,745 - WARNING - Epoch [7/25] Step [21/250]  acc 0.243085 (0.250126)  loss 1.564133 (1.589020)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 9268.0 MB
2025-08-16 22:08:14,092 - WARNING - Epoch [7/25] Step [31/250]  acc 0.270833 (0.246973)  loss 1.562601 (1.599695)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:08:18,491 - WARNING - Epoch [7/25] Step [41/250]  acc 0.262971 (0.249711)  loss 1.604032 (1.594416)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:08:22,826 - WARNING - Epoch [7/25] Step [51/250]  acc 0.270450 (0.249637)  loss 1.568216 (1.590863)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9268.0 MB
2025-08-16 22:08:27,170 - WARNING - Epoch [7/25] Step [61/250]  acc 0.247836 (0.249182)  loss 1.632511 (1.593518)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 9268.0 MB
2025-08-16 22:08:31,616 - WARNING - Epoch [7/25] Step [71/250]  acc 0.248887 (0.249653)  loss 1.612126 (1.594283)
GPU memory consumption  GPU Memory: Allocated: 59.6 MB, Reserved: 9268.0 MB
2025-08-16 22:08:36,004 - WARNING - Epoch [7/25] Step [81/250]  acc 0.241013 (0.249964)  loss 1.587872 (1.594723)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:08:40,345 - WARNING - Epoch [7/25] Step [91/250]  acc 0.266368 (0.249762)  loss 1.600149 (1.595421)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 9268.0 MB
2025-08-16 22:08:44,685 - WARNING - Epoch [7/25] Step [101/250]  acc 0.241028 (0.248962)  loss 1.533899 (1.595218)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 9268.0 MB
2025-08-16 22:08:49,061 - WARNING - Epoch [7/25] Step [111/250]  acc 0.261625 (0.249452)  loss 1.576817 (1.594502)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9268.0 MB
2025-08-16 22:08:53,499 - WARNING - Epoch [7/25] Step [121/250]  acc 0.268858 (0.250531)  loss 1.576266 (1.594112)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 9268.0 MB
2025-08-16 22:08:57,864 - WARNING - Epoch [7/25] Step [131/250]  acc 0.275308 (0.251033)  loss 1.567753 (1.593627)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 9268.0 MB
2025-08-16 22:09:02,224 - WARNING - Epoch [7/25] Step [141/250]  acc 0.290880 (0.251377)  loss 1.560799 (1.593335)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 9268.0 MB
2025-08-16 22:09:06,843 - WARNING - Epoch [7/25] Step [151/250]  acc 0.274268 (0.252223)  loss 1.627127 (1.593486)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9268.0 MB
2025-08-16 22:09:11,197 - WARNING - Epoch [7/25] Step [161/250]  acc 0.246590 (0.251608)  loss 1.594556 (1.594430)
GPU memory consumption  GPU Memory: Allocated: 60.2 MB, Reserved: 9268.0 MB
2025-08-16 22:09:15,509 - WARNING - Epoch [7/25] Step [171/250]  acc 0.252123 (0.251369)  loss 1.550194 (1.594819)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 9268.0 MB
2025-08-16 22:09:19,805 - WARNING - Epoch [7/25] Step [181/250]  acc 0.236733 (0.251257)  loss 1.586529 (1.594998)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:09:24,133 - WARNING - Epoch [7/25] Step [191/250]  acc 0.235323 (0.250686)  loss 1.589036 (1.595581)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 9268.0 MB
2025-08-16 22:09:28,477 - WARNING - Epoch [7/25] Step [201/250]  acc 0.267913 (0.250880)  loss 1.548765 (1.595529)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 9268.0 MB
2025-08-16 22:09:32,855 - WARNING - Epoch [7/25] Step [211/250]  acc 0.244637 (0.250979)  loss 1.595006 (1.595840)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9268.0 MB
2025-08-16 22:09:37,180 - WARNING - Epoch [7/25] Step [221/250]  acc 0.230609 (0.251053)  loss 1.563589 (1.595304)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9268.0 MB
2025-08-16 22:09:41,547 - WARNING - Epoch [7/25] Step [231/250]  acc 0.257313 (0.251276)  loss 1.593775 (1.594891)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 9268.0 MB
2025-08-16 22:09:45,899 - WARNING - Epoch [7/25] Step [241/250]  acc 0.260622 (0.251281)  loss 1.570985 (1.594915)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9268.0 MB
Epoch 7 completed in 0:01:49.424099
2025-08-16 22:10:16,610 - WARNING - Epoch [8/25] Step [1/250]  acc 0.258421 (0.258421)  loss 1.576055 (1.576055)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 9268.0 MB
2025-08-16 22:10:20,927 - WARNING - Epoch [8/25] Step [11/250]  acc 0.225446 (0.252275)  loss 1.593223 (1.598180)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 9268.0 MB
2025-08-16 22:10:25,309 - WARNING - Epoch [8/25] Step [21/250]  acc 0.271240 (0.256099)  loss 1.550750 (1.593785)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9268.0 MB
2025-08-16 22:10:29,578 - WARNING - Epoch [8/25] Step [31/250]  acc 0.254564 (0.252727)  loss 1.564481 (1.592375)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:10:33,863 - WARNING - Epoch [8/25] Step [41/250]  acc 0.243154 (0.253548)  loss 1.565778 (1.591083)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 9268.0 MB
2025-08-16 22:10:38,449 - WARNING - Epoch [8/25] Step [51/250]  acc 0.244267 (0.251408)  loss 1.592810 (1.592027)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9268.0 MB
2025-08-16 22:10:42,792 - WARNING - Epoch [8/25] Step [61/250]  acc 0.235390 (0.251534)  loss 1.593263 (1.593554)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 9268.0 MB
2025-08-16 22:10:47,120 - WARNING - Epoch [8/25] Step [71/250]  acc 0.247748 (0.252475)  loss 1.568803 (1.593742)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 9268.0 MB
2025-08-16 22:10:51,488 - WARNING - Epoch [8/25] Step [81/250]  acc 0.212206 (0.251590)  loss 1.621470 (1.594999)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 9268.0 MB
2025-08-16 22:10:55,831 - WARNING - Epoch [8/25] Step [91/250]  acc 0.277533 (0.251145)  loss 1.606570 (1.594480)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 9268.0 MB
2025-08-16 22:11:00,166 - WARNING - Epoch [8/25] Step [101/250]  acc 0.239359 (0.250991)  loss 1.627676 (1.594602)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9268.0 MB
2025-08-16 22:11:04,517 - WARNING - Epoch [8/25] Step [111/250]  acc 0.279812 (0.250203)  loss 1.585755 (1.595029)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9268.0 MB
2025-08-16 22:11:08,841 - WARNING - Epoch [8/25] Step [121/250]  acc 0.255739 (0.249763)  loss 1.587773 (1.594232)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 9268.0 MB
2025-08-16 22:11:13,174 - WARNING - Epoch [8/25] Step [131/250]  acc 0.189532 (0.248461)  loss 1.631325 (1.594713)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 9268.0 MB
2025-08-16 22:11:17,502 - WARNING - Epoch [8/25] Step [141/250]  acc 0.269991 (0.248605)  loss 1.613719 (1.594848)
GPU memory consumption  GPU Memory: Allocated: 62.1 MB, Reserved: 9268.0 MB
2025-08-16 22:11:21,834 - WARNING - Epoch [8/25] Step [151/250]  acc 0.227702 (0.248777)  loss 1.554112 (1.594891)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9268.0 MB
2025-08-16 22:11:26,157 - WARNING - Epoch [8/25] Step [161/250]  acc 0.288644 (0.249480)  loss 1.591272 (1.594699)
GPU memory consumption  GPU Memory: Allocated: 60.1 MB, Reserved: 9268.0 MB
2025-08-16 22:11:30,514 - WARNING - Epoch [8/25] Step [171/250]  acc 0.225754 (0.249402)  loss 1.629640 (1.595142)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 9268.0 MB
2025-08-16 22:11:34,762 - WARNING - Epoch [8/25] Step [181/250]  acc 0.257470 (0.249727)  loss 1.584752 (1.595137)
GPU memory consumption  GPU Memory: Allocated: 59.6 MB, Reserved: 9268.0 MB
2025-08-16 22:11:39,079 - WARNING - Epoch [8/25] Step [191/250]  acc 0.234402 (0.249385)  loss 1.624071 (1.595322)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 9268.0 MB
2025-08-16 22:11:43,636 - WARNING - Epoch [8/25] Step [201/250]  acc 0.275986 (0.249581)  loss 1.596009 (1.594796)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 9268.0 MB
2025-08-16 22:11:47,945 - WARNING - Epoch [8/25] Step [211/250]  acc 0.245314 (0.249635)  loss 1.604804 (1.594621)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 9268.0 MB
2025-08-16 22:11:52,245 - WARNING - Epoch [8/25] Step [221/250]  acc 0.213362 (0.249441)  loss 1.619085 (1.594502)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 9268.0 MB
2025-08-16 22:11:56,494 - WARNING - Epoch [8/25] Step [231/250]  acc 0.265816 (0.250040)  loss 1.566629 (1.593998)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9268.0 MB
2025-08-16 22:12:00,815 - WARNING - Epoch [8/25] Step [241/250]  acc 0.266142 (0.250170)  loss 1.600024 (1.593983)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 9268.0 MB
Epoch 8 completed in 0:01:48.551806
2025-08-16 22:12:31,470 - WARNING - Epoch [9/25] Step [1/250]  acc 0.232597 (0.232597)  loss 1.586128 (1.586128)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 9268.0 MB
2025-08-16 22:12:35,839 - WARNING - Epoch [9/25] Step [11/250]  acc 0.225536 (0.253771)  loss 1.669452 (1.613577)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 9268.0 MB
2025-08-16 22:12:40,175 - WARNING - Epoch [9/25] Step [21/250]  acc 0.256011 (0.259343)  loss 1.584813 (1.600360)
GPU memory consumption  GPU Memory: Allocated: 61.3 MB, Reserved: 9268.0 MB
2025-08-16 22:12:44,447 - WARNING - Epoch [9/25] Step [31/250]  acc 0.233206 (0.255646)  loss 1.597940 (1.592494)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 9268.0 MB
2025-08-16 22:12:48,754 - WARNING - Epoch [9/25] Step [41/250]  acc 0.254469 (0.253598)  loss 1.596699 (1.590786)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 9268.0 MB
2025-08-16 22:12:53,109 - WARNING - Epoch [9/25] Step [51/250]  acc 0.247608 (0.253955)  loss 1.718851 (1.591587)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 9268.0 MB
2025-08-16 22:12:57,430 - WARNING - Epoch [9/25] Step [61/250]  acc 0.230551 (0.251849)  loss 1.629514 (1.595609)
GPU memory consumption  GPU Memory: Allocated: 52.8 MB, Reserved: 9268.0 MB
2025-08-16 22:13:01,793 - WARNING - Epoch [9/25] Step [71/250]  acc 0.234671 (0.250246)  loss 1.540616 (1.595567)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 9268.0 MB
2025-08-16 22:13:06,160 - WARNING - Epoch [9/25] Step [81/250]  acc 0.233820 (0.251108)  loss 1.586905 (1.594778)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9268.0 MB
2025-08-16 22:13:10,496 - WARNING - Epoch [9/25] Step [91/250]  acc 0.255138 (0.251216)  loss 1.563887 (1.592275)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 9268.0 MB
2025-08-16 22:13:14,835 - WARNING - Epoch [9/25] Step [101/250]  acc 0.278749 (0.252633)  loss 1.565727 (1.588989)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 9268.0 MB
2025-08-16 22:13:19,433 - WARNING - Epoch [9/25] Step [111/250]  acc 0.233962 (0.251335)  loss 1.602511 (1.590252)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 9268.0 MB
2025-08-16 22:13:23,801 - WARNING - Epoch [9/25] Step [121/250]  acc 0.271630 (0.250997)  loss 1.566272 (1.591145)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9268.0 MB
2025-08-16 22:13:28,151 - WARNING - Epoch [9/25] Step [131/250]  acc 0.234606 (0.250898)  loss 1.569083 (1.592182)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:13:32,560 - WARNING - Epoch [9/25] Step [141/250]  acc 0.230687 (0.251027)  loss 1.575162 (1.591052)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 9268.0 MB
2025-08-16 22:13:37,089 - WARNING - Epoch [9/25] Step [151/250]  acc 0.241041 (0.250649)  loss 1.620805 (1.592036)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9268.0 MB
2025-08-16 22:13:41,807 - WARNING - Epoch [9/25] Step [161/250]  acc 0.223747 (0.250166)  loss 1.571867 (1.591529)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 9268.0 MB
2025-08-16 22:13:46,966 - WARNING - Epoch [9/25] Step [171/250]  acc 0.234020 (0.249653)  loss 1.645896 (1.592023)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 9268.0 MB
2025-08-16 22:13:52,187 - WARNING - Epoch [9/25] Step [181/250]  acc 0.281513 (0.249480)  loss 1.584937 (1.592905)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9268.0 MB
2025-08-16 22:13:57,403 - WARNING - Epoch [9/25] Step [191/250]  acc 0.224785 (0.249769)  loss 1.568947 (1.592689)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9268.0 MB
2025-08-16 22:14:02,523 - WARNING - Epoch [9/25] Step [201/250]  acc 0.296417 (0.250472)  loss 1.593885 (1.592049)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 9268.0 MB
2025-08-16 22:14:07,710 - WARNING - Epoch [9/25] Step [211/250]  acc 0.241453 (0.250286)  loss 1.636127 (1.592118)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9268.0 MB
2025-08-16 22:14:12,963 - WARNING - Epoch [9/25] Step [221/250]  acc 0.234694 (0.250007)  loss 1.613033 (1.591611)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 9268.0 MB
2025-08-16 22:14:18,173 - WARNING - Epoch [9/25] Step [231/250]  acc 0.268350 (0.249781)  loss 1.613566 (1.591196)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 9268.0 MB
2025-08-16 22:14:23,269 - WARNING - Epoch [9/25] Step [241/250]  acc 0.237232 (0.250271)  loss 1.606435 (1.590745)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 9268.0 MB
Epoch 9 completed in 0:01:56.837272
2025-08-16 22:14:57,861 - WARNING - Epoch [10/25] Step [1/250]  acc 0.243100 (0.243100)  loss 1.577670 (1.577670)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 9268.0 MB
2025-08-16 22:15:02,765 - WARNING - Epoch [10/25] Step [11/250]  acc 0.274360 (0.250433)  loss 1.577752 (1.581706)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 9268.0 MB
2025-08-16 22:15:07,520 - WARNING - Epoch [10/25] Step [21/250]  acc 0.231820 (0.249275)  loss 1.654153 (1.587910)
GPU memory consumption  GPU Memory: Allocated: 59.9 MB, Reserved: 9268.0 MB
2025-08-16 22:15:12,215 - WARNING - Epoch [10/25] Step [31/250]  acc 0.276688 (0.250570)  loss 1.549423 (1.590220)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 9268.0 MB
2025-08-16 22:15:16,673 - WARNING - Epoch [10/25] Step [41/250]  acc 0.305181 (0.255695)  loss 1.577749 (1.587450)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:15:21,104 - WARNING - Epoch [10/25] Step [51/250]  acc 0.306330 (0.256438)  loss 1.597615 (1.590985)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9268.0 MB
2025-08-16 22:15:25,499 - WARNING - Epoch [10/25] Step [61/250]  acc 0.262045 (0.258546)  loss 1.571232 (1.589896)
GPU memory consumption  GPU Memory: Allocated: 52.0 MB, Reserved: 9268.0 MB
2025-08-16 22:15:29,925 - WARNING - Epoch [10/25] Step [71/250]  acc 0.257980 (0.257755)  loss 1.621057 (1.594666)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9268.0 MB
2025-08-16 22:15:34,335 - WARNING - Epoch [10/25] Step [81/250]  acc 0.254122 (0.257993)  loss 1.594874 (1.593898)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 9268.0 MB
2025-08-16 22:15:38,724 - WARNING - Epoch [10/25] Step [91/250]  acc 0.257801 (0.256457)  loss 1.570948 (1.593498)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9268.0 MB
2025-08-16 22:15:43,125 - WARNING - Epoch [10/25] Step [101/250]  acc 0.258386 (0.256160)  loss 1.588825 (1.592978)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 9268.0 MB
2025-08-16 22:15:47,540 - WARNING - Epoch [10/25] Step [111/250]  acc 0.282620 (0.256846)  loss 1.571318 (1.591511)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 9268.0 MB
2025-08-16 22:15:52,010 - WARNING - Epoch [10/25] Step [121/250]  acc 0.271501 (0.256967)  loss 1.556341 (1.591478)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 9268.0 MB
2025-08-16 22:15:56,460 - WARNING - Epoch [10/25] Step [131/250]  acc 0.204009 (0.255943)  loss 1.659005 (1.592296)
GPU memory consumption  GPU Memory: Allocated: 52.1 MB, Reserved: 9268.0 MB
2025-08-16 22:16:00,946 - WARNING - Epoch [10/25] Step [141/250]  acc 0.256369 (0.255446)  loss 1.574219 (1.591924)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 9268.0 MB
2025-08-16 22:16:05,477 - WARNING - Epoch [10/25] Step [151/250]  acc 0.248980 (0.254950)  loss 1.591483 (1.591829)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9268.0 MB
2025-08-16 22:16:10,351 - WARNING - Epoch [10/25] Step [161/250]  acc 0.261206 (0.254483)  loss 1.595017 (1.592037)
GPU memory consumption  GPU Memory: Allocated: 61.3 MB, Reserved: 9268.0 MB
2025-08-16 22:16:15,180 - WARNING - Epoch [10/25] Step [171/250]  acc 0.261597 (0.254269)  loss 1.585385 (1.591458)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 9268.0 MB
2025-08-16 22:16:20,115 - WARNING - Epoch [10/25] Step [181/250]  acc 0.238596 (0.254474)  loss 1.639588 (1.590954)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 9268.0 MB
2025-08-16 22:16:24,989 - WARNING - Epoch [10/25] Step [191/250]  acc 0.277922 (0.254758)  loss 1.586347 (1.590459)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:16:29,529 - WARNING - Epoch [10/25] Step [201/250]  acc 0.263100 (0.254525)  loss 1.618814 (1.591742)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 9268.0 MB
2025-08-16 22:16:34,066 - WARNING - Epoch [10/25] Step [211/250]  acc 0.292362 (0.254645)  loss 1.568865 (1.591741)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9268.0 MB
2025-08-16 22:16:38,555 - WARNING - Epoch [10/25] Step [221/250]  acc 0.222397 (0.254233)  loss 1.608539 (1.591938)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 9268.0 MB
2025-08-16 22:16:43,039 - WARNING - Epoch [10/25] Step [231/250]  acc 0.223264 (0.253828)  loss 1.621269 (1.592515)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 9268.0 MB
2025-08-16 22:16:47,499 - WARNING - Epoch [10/25] Step [241/250]  acc 0.250419 (0.254026)  loss 1.588057 (1.592195)
GPU memory consumption  GPU Memory: Allocated: 52.6 MB, Reserved: 9268.0 MB
Epoch 10 completed in 0:01:54.060711
2025-08-16 22:17:18,398 - WARNING - Epoch [11/25] Step [1/250]  acc 0.229708 (0.229708)  loss 1.630501 (1.630501)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 9268.0 MB
2025-08-16 22:17:22,732 - WARNING - Epoch [11/25] Step [11/250]  acc 0.258962 (0.253358)  loss 1.575363 (1.604950)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 9268.0 MB
2025-08-16 22:17:27,064 - WARNING - Epoch [11/25] Step [21/250]  acc 0.233241 (0.249442)  loss 1.604162 (1.603668)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:17:31,425 - WARNING - Epoch [11/25] Step [31/250]  acc 0.296024 (0.251392)  loss 1.627841 (1.599698)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9268.0 MB
2025-08-16 22:17:35,820 - WARNING - Epoch [11/25] Step [41/250]  acc 0.215843 (0.250750)  loss 1.663210 (1.600323)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 9268.0 MB
2025-08-16 22:17:40,179 - WARNING - Epoch [11/25] Step [51/250]  acc 0.258148 (0.249707)  loss 1.557998 (1.598246)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9268.0 MB
2025-08-16 22:17:44,531 - WARNING - Epoch [11/25] Step [61/250]  acc 0.270226 (0.251870)  loss 1.609129 (1.597943)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 9268.0 MB
2025-08-16 22:17:49,125 - WARNING - Epoch [11/25] Step [71/250]  acc 0.266701 (0.251913)  loss 1.522126 (1.595612)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9268.0 MB
2025-08-16 22:17:53,518 - WARNING - Epoch [11/25] Step [81/250]  acc 0.235707 (0.250539)  loss 1.584113 (1.596102)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9268.0 MB
2025-08-16 22:17:57,841 - WARNING - Epoch [11/25] Step [91/250]  acc 0.249168 (0.250599)  loss 1.607325 (1.595309)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 9268.0 MB
2025-08-16 22:18:02,185 - WARNING - Epoch [11/25] Step [101/250]  acc 0.245682 (0.249540)  loss 1.515734 (1.594102)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 9268.0 MB
2025-08-16 22:18:06,516 - WARNING - Epoch [11/25] Step [111/250]  acc 0.206088 (0.249417)  loss 1.597266 (1.594030)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9268.0 MB
2025-08-16 22:18:10,853 - WARNING - Epoch [11/25] Step [121/250]  acc 0.242188 (0.249902)  loss 1.710724 (1.594774)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 9268.0 MB
2025-08-16 22:18:15,175 - WARNING - Epoch [11/25] Step [131/250]  acc 0.274219 (0.250585)  loss 1.597224 (1.594628)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 9268.0 MB
2025-08-16 22:18:19,512 - WARNING - Epoch [11/25] Step [141/250]  acc 0.215812 (0.250177)  loss 1.618967 (1.595066)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 9268.0 MB
2025-08-16 22:18:23,868 - WARNING - Epoch [11/25] Step [151/250]  acc 0.276873 (0.250080)  loss 1.578607 (1.594304)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 9268.0 MB
2025-08-16 22:18:28,219 - WARNING - Epoch [11/25] Step [161/250]  acc 0.219614 (0.250706)  loss 1.644470 (1.593636)
GPU memory consumption  GPU Memory: Allocated: 61.3 MB, Reserved: 9268.0 MB
2025-08-16 22:18:32,568 - WARNING - Epoch [11/25] Step [171/250]  acc 0.225360 (0.251015)  loss 1.566197 (1.592554)
GPU memory consumption  GPU Memory: Allocated: 52.5 MB, Reserved: 9268.0 MB
2025-08-16 22:18:36,880 - WARNING - Epoch [11/25] Step [181/250]  acc 0.289906 (0.251989)  loss 1.562288 (1.591382)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 9268.0 MB
2025-08-16 22:18:41,178 - WARNING - Epoch [11/25] Step [191/250]  acc 0.278238 (0.251649)  loss 1.588738 (1.591814)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:18:45,517 - WARNING - Epoch [11/25] Step [201/250]  acc 0.209171 (0.251311)  loss 1.592669 (1.592416)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 9268.0 MB
2025-08-16 22:18:49,846 - WARNING - Epoch [11/25] Step [211/250]  acc 0.211817 (0.251451)  loss 1.553861 (1.592271)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 9268.0 MB
2025-08-16 22:18:54,463 - WARNING - Epoch [11/25] Step [221/250]  acc 0.277925 (0.251224)  loss 1.560997 (1.591430)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 9268.0 MB
2025-08-16 22:18:58,783 - WARNING - Epoch [11/25] Step [231/250]  acc 0.236058 (0.251370)  loss 1.550192 (1.590495)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 9268.0 MB
2025-08-16 22:19:03,135 - WARNING - Epoch [11/25] Step [241/250]  acc 0.258147 (0.251273)  loss 1.602911 (1.590844)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9268.0 MB
Epoch 11 completed in 0:01:49.065502
2025-08-16 22:19:33,731 - WARNING - Epoch [12/25] Step [1/250]  acc 0.212742 (0.212742)  loss 1.587048 (1.587048)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 9268.0 MB
2025-08-16 22:19:38,051 - WARNING - Epoch [12/25] Step [11/250]  acc 0.283092 (0.250103)  loss 1.532974 (1.589603)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9268.0 MB
2025-08-16 22:19:42,373 - WARNING - Epoch [12/25] Step [21/250]  acc 0.239239 (0.253313)  loss 1.597687 (1.585613)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 9268.0 MB
2025-08-16 22:19:46,679 - WARNING - Epoch [12/25] Step [31/250]  acc 0.214433 (0.256897)  loss 1.633274 (1.585084)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:19:51,018 - WARNING - Epoch [12/25] Step [41/250]  acc 0.271450 (0.256531)  loss 1.603972 (1.585294)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 9268.0 MB
2025-08-16 22:19:55,341 - WARNING - Epoch [12/25] Step [51/250]  acc 0.263298 (0.257533)  loss 1.594140 (1.586674)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 9268.0 MB
2025-08-16 22:19:59,625 - WARNING - Epoch [12/25] Step [61/250]  acc 0.243230 (0.257755)  loss 1.565597 (1.588885)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 9268.0 MB
2025-08-16 22:20:04,052 - WARNING - Epoch [12/25] Step [71/250]  acc 0.223267 (0.255113)  loss 1.534165 (1.584310)
GPU memory consumption  GPU Memory: Allocated: 59.5 MB, Reserved: 9268.0 MB
2025-08-16 22:20:08,480 - WARNING - Epoch [12/25] Step [81/250]  acc 0.246409 (0.252034)  loss 1.611452 (1.589223)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 9268.0 MB
2025-08-16 22:20:12,845 - WARNING - Epoch [12/25] Step [91/250]  acc 0.253261 (0.252014)  loss 1.598387 (1.588932)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 9268.0 MB
2025-08-16 22:20:17,171 - WARNING - Epoch [12/25] Step [101/250]  acc 0.238965 (0.251705)  loss 1.550108 (1.588862)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 9268.0 MB
2025-08-16 22:20:21,502 - WARNING - Epoch [12/25] Step [111/250]  acc 0.259036 (0.251545)  loss 1.602025 (1.587553)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 9268.0 MB
2025-08-16 22:20:26,088 - WARNING - Epoch [12/25] Step [121/250]  acc 0.269657 (0.251021)  loss 1.586633 (1.588828)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 9268.0 MB
2025-08-16 22:20:30,425 - WARNING - Epoch [12/25] Step [131/250]  acc 0.275278 (0.251541)  loss 1.601263 (1.589304)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 9268.0 MB
2025-08-16 22:20:34,754 - WARNING - Epoch [12/25] Step [141/250]  acc 0.248992 (0.251994)  loss 1.636886 (1.589816)
GPU memory consumption  GPU Memory: Allocated: 60.1 MB, Reserved: 9268.0 MB
2025-08-16 22:20:39,057 - WARNING - Epoch [12/25] Step [151/250]  acc 0.213406 (0.252091)  loss 1.623137 (1.590373)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9268.0 MB
2025-08-16 22:20:43,377 - WARNING - Epoch [12/25] Step [161/250]  acc 0.298409 (0.253028)  loss 1.605582 (1.589665)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 9268.0 MB
2025-08-16 22:20:47,729 - WARNING - Epoch [12/25] Step [171/250]  acc 0.238625 (0.252877)  loss 1.625395 (1.589091)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 9268.0 MB
2025-08-16 22:20:52,093 - WARNING - Epoch [12/25] Step [181/250]  acc 0.254555 (0.253093)  loss 1.630571 (1.589354)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:20:56,459 - WARNING - Epoch [12/25] Step [191/250]  acc 0.275777 (0.253708)  loss 1.564317 (1.589531)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 9268.0 MB
2025-08-16 22:21:00,794 - WARNING - Epoch [12/25] Step [201/250]  acc 0.247886 (0.254160)  loss 1.602305 (1.589207)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 9268.0 MB
2025-08-16 22:21:05,112 - WARNING - Epoch [12/25] Step [211/250]  acc 0.229891 (0.254440)  loss 1.573094 (1.589132)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 9268.0 MB
2025-08-16 22:21:09,435 - WARNING - Epoch [12/25] Step [221/250]  acc 0.269107 (0.254218)  loss 1.602491 (1.588971)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 9268.0 MB
2025-08-16 22:21:13,767 - WARNING - Epoch [12/25] Step [231/250]  acc 0.243926 (0.254140)  loss 1.630587 (1.588837)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 9268.0 MB
2025-08-16 22:21:18,112 - WARNING - Epoch [12/25] Step [241/250]  acc 0.275862 (0.254717)  loss 1.562420 (1.588500)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 9268.0 MB
Epoch 12 completed in 0:01:48.735158
2025-08-16 22:21:48,362 - WARNING - Epoch [13/25] Step [1/250]  acc 0.285217 (0.285217)  loss 1.521630 (1.521630)
GPU memory consumption  GPU Memory: Allocated: 59.5 MB, Reserved: 9268.0 MB
2025-08-16 22:21:52,882 - WARNING - Epoch [13/25] Step [11/250]  acc 0.281298 (0.263982)  loss 1.604413 (1.586953)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 9268.0 MB
2025-08-16 22:21:57,550 - WARNING - Epoch [13/25] Step [21/250]  acc 0.280374 (0.258316)  loss 1.567202 (1.583288)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 9268.0 MB
2025-08-16 22:22:01,957 - WARNING - Epoch [13/25] Step [31/250]  acc 0.250129 (0.259608)  loss 1.607442 (1.584707)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:22:06,315 - WARNING - Epoch [13/25] Step [41/250]  acc 0.257497 (0.255324)  loss 1.598205 (1.587693)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:22:10,769 - WARNING - Epoch [13/25] Step [51/250]  acc 0.228493 (0.254637)  loss 1.597124 (1.591500)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 9268.0 MB
2025-08-16 22:22:15,268 - WARNING - Epoch [13/25] Step [61/250]  acc 0.268519 (0.254379)  loss 1.583316 (1.590306)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 9268.0 MB
2025-08-16 22:22:19,769 - WARNING - Epoch [13/25] Step [71/250]  acc 0.267112 (0.255375)  loss 1.584689 (1.588345)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:22:24,174 - WARNING - Epoch [13/25] Step [81/250]  acc 0.292745 (0.255357)  loss 1.586426 (1.589912)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:22:28,455 - WARNING - Epoch [13/25] Step [91/250]  acc 0.262542 (0.255592)  loss 1.567354 (1.590585)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 9268.0 MB
2025-08-16 22:22:32,865 - WARNING - Epoch [13/25] Step [101/250]  acc 0.227475 (0.255078)  loss 1.557878 (1.590814)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 9268.0 MB
2025-08-16 22:22:37,215 - WARNING - Epoch [13/25] Step [111/250]  acc 0.277891 (0.254317)  loss 1.570895 (1.591452)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9268.0 MB
2025-08-16 22:22:41,552 - WARNING - Epoch [13/25] Step [121/250]  acc 0.303833 (0.254437)  loss 1.583800 (1.592341)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 9268.0 MB
2025-08-16 22:22:45,834 - WARNING - Epoch [13/25] Step [131/250]  acc 0.237158 (0.254682)  loss 1.586641 (1.592591)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 9268.0 MB
2025-08-16 22:22:50,151 - WARNING - Epoch [13/25] Step [141/250]  acc 0.287368 (0.254862)  loss 1.573653 (1.592194)
GPU memory consumption  GPU Memory: Allocated: 60.1 MB, Reserved: 9268.0 MB
2025-08-16 22:22:54,559 - WARNING - Epoch [13/25] Step [151/250]  acc 0.203693 (0.254402)  loss 1.630158 (1.591734)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 9268.0 MB
2025-08-16 22:22:58,885 - WARNING - Epoch [13/25] Step [161/250]  acc 0.254043 (0.255169)  loss 1.556033 (1.590763)
GPU memory consumption  GPU Memory: Allocated: 61.3 MB, Reserved: 9268.0 MB
2025-08-16 22:23:03,218 - WARNING - Epoch [13/25] Step [171/250]  acc 0.251656 (0.254183)  loss 1.586540 (1.590833)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9268.0 MB
2025-08-16 22:23:07,739 - WARNING - Epoch [13/25] Step [181/250]  acc 0.245077 (0.254662)  loss 1.571146 (1.590492)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 9268.0 MB
2025-08-16 22:23:12,061 - WARNING - Epoch [13/25] Step [191/250]  acc 0.244909 (0.254881)  loss 1.701577 (1.590383)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 9268.0 MB
2025-08-16 22:23:16,369 - WARNING - Epoch [13/25] Step [201/250]  acc 0.218857 (0.255122)  loss 1.621261 (1.590171)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 9268.0 MB
2025-08-16 22:23:20,629 - WARNING - Epoch [13/25] Step [211/250]  acc 0.259363 (0.255366)  loss 1.612435 (1.590649)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 9268.0 MB
2025-08-16 22:23:24,901 - WARNING - Epoch [13/25] Step [221/250]  acc 0.264274 (0.255236)  loss 1.654368 (1.591378)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 9268.0 MB
2025-08-16 22:23:29,174 - WARNING - Epoch [13/25] Step [231/250]  acc 0.268100 (0.254769)  loss 1.570577 (1.591270)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 9268.0 MB
2025-08-16 22:23:33,431 - WARNING - Epoch [13/25] Step [241/250]  acc 0.265482 (0.254212)  loss 1.595116 (1.591278)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 9268.0 MB
Epoch 13 completed in 0:01:49.337889
2025-08-16 22:24:03,709 - WARNING - Epoch [14/25] Step [1/250]  acc 0.269451 (0.269451)  loss 1.574881 (1.574881)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 9268.0 MB
2025-08-16 22:24:07,978 - WARNING - Epoch [14/25] Step [11/250]  acc 0.261053 (0.246021)  loss 1.524016 (1.576956)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 9268.0 MB
2025-08-16 22:24:12,274 - WARNING - Epoch [14/25] Step [21/250]  acc 0.248113 (0.253133)  loss 1.566320 (1.580579)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 9268.0 MB
2025-08-16 22:24:16,514 - WARNING - Epoch [14/25] Step [31/250]  acc 0.236570 (0.250788)  loss 1.558131 (1.581047)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:24:20,780 - WARNING - Epoch [14/25] Step [41/250]  acc 0.260102 (0.254128)  loss 1.572597 (1.581101)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 9268.0 MB
2025-08-16 22:24:25,043 - WARNING - Epoch [14/25] Step [51/250]  acc 0.256674 (0.253650)  loss 1.567767 (1.583454)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9268.0 MB
2025-08-16 22:24:29,282 - WARNING - Epoch [14/25] Step [61/250]  acc 0.236517 (0.250477)  loss 1.597143 (1.584958)
GPU memory consumption  GPU Memory: Allocated: 52.9 MB, Reserved: 9268.0 MB
2025-08-16 22:24:33,558 - WARNING - Epoch [14/25] Step [71/250]  acc 0.247680 (0.250873)  loss 1.552355 (1.586386)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 9268.0 MB
2025-08-16 22:24:38,055 - WARNING - Epoch [14/25] Step [81/250]  acc 0.265809 (0.251545)  loss 1.627534 (1.586670)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9268.0 MB
2025-08-16 22:24:42,306 - WARNING - Epoch [14/25] Step [91/250]  acc 0.247348 (0.252253)  loss 1.564965 (1.585691)
GPU memory consumption  GPU Memory: Allocated: 60.1 MB, Reserved: 9268.0 MB
2025-08-16 22:24:46,543 - WARNING - Epoch [14/25] Step [101/250]  acc 0.264914 (0.252900)  loss 1.621123 (1.586437)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 9268.0 MB
2025-08-16 22:24:50,810 - WARNING - Epoch [14/25] Step [111/250]  acc 0.244524 (0.252966)  loss 1.633451 (1.587913)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9268.0 MB
2025-08-16 22:24:55,103 - WARNING - Epoch [14/25] Step [121/250]  acc 0.278879 (0.254164)  loss 1.624999 (1.587101)
GPU memory consumption  GPU Memory: Allocated: 59.4 MB, Reserved: 9268.0 MB
2025-08-16 22:24:59,373 - WARNING - Epoch [14/25] Step [131/250]  acc 0.209607 (0.253149)  loss 1.544152 (1.586496)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 9268.0 MB
2025-08-16 22:25:03,672 - WARNING - Epoch [14/25] Step [141/250]  acc 0.244876 (0.252128)  loss 1.601392 (1.587384)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 9268.0 MB
2025-08-16 22:25:08,010 - WARNING - Epoch [14/25] Step [151/250]  acc 0.249863 (0.253011)  loss 1.646676 (1.586470)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 9268.0 MB
2025-08-16 22:25:12,268 - WARNING - Epoch [14/25] Step [161/250]  acc 0.251811 (0.253277)  loss 1.570464 (1.586497)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 9268.0 MB
2025-08-16 22:25:16,509 - WARNING - Epoch [14/25] Step [171/250]  acc 0.325843 (0.254223)  loss 1.597325 (1.585843)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 9268.0 MB
2025-08-16 22:25:20,739 - WARNING - Epoch [14/25] Step [181/250]  acc 0.271850 (0.254168)  loss 1.620833 (1.586725)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 9268.0 MB
2025-08-16 22:25:25,015 - WARNING - Epoch [14/25] Step [191/250]  acc 0.227676 (0.253755)  loss 1.595260 (1.587270)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:25:29,267 - WARNING - Epoch [14/25] Step [201/250]  acc 0.234054 (0.253633)  loss 1.626673 (1.586879)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 9268.0 MB
2025-08-16 22:25:33,592 - WARNING - Epoch [14/25] Step [211/250]  acc 0.244833 (0.253084)  loss 1.638833 (1.586724)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9268.0 MB
2025-08-16 22:25:37,861 - WARNING - Epoch [14/25] Step [221/250]  acc 0.247962 (0.252708)  loss 1.579796 (1.586918)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 9268.0 MB
2025-08-16 22:25:42,121 - WARNING - Epoch [14/25] Step [231/250]  acc 0.245720 (0.252637)  loss 1.610848 (1.587264)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9268.0 MB
2025-08-16 22:25:46,577 - WARNING - Epoch [14/25] Step [241/250]  acc 0.294517 (0.252348)  loss 1.591180 (1.587324)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 9268.0 MB
Epoch 14 completed in 0:01:47.140010
2025-08-16 22:26:16,709 - WARNING - Epoch [15/25] Step [1/250]  acc 0.281853 (0.281853)  loss 1.565241 (1.565241)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 9268.0 MB
2025-08-16 22:26:20,969 - WARNING - Epoch [15/25] Step [11/250]  acc 0.268159 (0.241430)  loss 1.537548 (1.593064)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 9268.0 MB
2025-08-16 22:26:25,253 - WARNING - Epoch [15/25] Step [21/250]  acc 0.244675 (0.241263)  loss 1.589490 (1.589479)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:26:29,495 - WARNING - Epoch [15/25] Step [31/250]  acc 0.240361 (0.242747)  loss 1.602745 (1.585656)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 9268.0 MB
2025-08-16 22:26:33,765 - WARNING - Epoch [15/25] Step [41/250]  acc 0.242913 (0.244103)  loss 1.636754 (1.587947)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:26:38,003 - WARNING - Epoch [15/25] Step [51/250]  acc 0.262842 (0.244569)  loss 1.536301 (1.587572)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 9268.0 MB
2025-08-16 22:26:42,259 - WARNING - Epoch [15/25] Step [61/250]  acc 0.269700 (0.245735)  loss 1.533158 (1.587767)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 9268.0 MB
2025-08-16 22:26:46,529 - WARNING - Epoch [15/25] Step [71/250]  acc 0.213209 (0.247443)  loss 1.599690 (1.587902)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:26:50,808 - WARNING - Epoch [15/25] Step [81/250]  acc 0.275151 (0.248711)  loss 1.599179 (1.586244)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 9268.0 MB
2025-08-16 22:26:55,067 - WARNING - Epoch [15/25] Step [91/250]  acc 0.244070 (0.249784)  loss 1.584177 (1.585151)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9268.0 MB
2025-08-16 22:26:59,310 - WARNING - Epoch [15/25] Step [101/250]  acc 0.247995 (0.249542)  loss 1.634142 (1.586191)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:27:03,578 - WARNING - Epoch [15/25] Step [111/250]  acc 0.237557 (0.249268)  loss 1.574856 (1.585155)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 9268.0 MB
2025-08-16 22:27:07,824 - WARNING - Epoch [15/25] Step [121/250]  acc 0.236184 (0.249368)  loss 1.589127 (1.585023)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:27:12,068 - WARNING - Epoch [15/25] Step [131/250]  acc 0.252772 (0.249928)  loss 1.563040 (1.584867)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 9268.0 MB
2025-08-16 22:27:16,524 - WARNING - Epoch [15/25] Step [141/250]  acc 0.236705 (0.249961)  loss 1.549332 (1.584859)
GPU memory consumption  GPU Memory: Allocated: 60.1 MB, Reserved: 9268.0 MB
2025-08-16 22:27:20,789 - WARNING - Epoch [15/25] Step [151/250]  acc 0.261635 (0.250516)  loss 1.686571 (1.585013)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 9268.0 MB
2025-08-16 22:27:25,058 - WARNING - Epoch [15/25] Step [161/250]  acc 0.292007 (0.250784)  loss 1.591213 (1.586001)
GPU memory consumption  GPU Memory: Allocated: 59.4 MB, Reserved: 9268.0 MB
2025-08-16 22:27:29,297 - WARNING - Epoch [15/25] Step [171/250]  acc 0.254202 (0.250538)  loss 1.611389 (1.586330)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 9268.0 MB
2025-08-16 22:27:33,589 - WARNING - Epoch [15/25] Step [181/250]  acc 0.287774 (0.251506)  loss 1.618498 (1.585797)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 9268.0 MB
2025-08-16 22:27:37,864 - WARNING - Epoch [15/25] Step [191/250]  acc 0.277869 (0.251911)  loss 1.653999 (1.585957)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 9268.0 MB
2025-08-16 22:27:42,111 - WARNING - Epoch [15/25] Step [201/250]  acc 0.244713 (0.251347)  loss 1.671422 (1.586921)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 9268.0 MB
2025-08-16 22:27:46,362 - WARNING - Epoch [15/25] Step [211/250]  acc 0.267771 (0.251466)  loss 1.574452 (1.586880)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 9268.0 MB
2025-08-16 22:27:50,602 - WARNING - Epoch [15/25] Step [221/250]  acc 0.298774 (0.251725)  loss 1.568095 (1.586964)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9268.0 MB
2025-08-16 22:27:54,846 - WARNING - Epoch [15/25] Step [231/250]  acc 0.231654 (0.251940)  loss 1.574000 (1.586888)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 9268.0 MB
2025-08-16 22:27:59,116 - WARNING - Epoch [15/25] Step [241/250]  acc 0.252954 (0.251435)  loss 1.598405 (1.587375)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 9268.0 MB
Epoch 15 completed in 0:01:46.678995
2025-08-16 22:28:28,951 - WARNING - Epoch [16/25] Step [1/250]  acc 0.288401 (0.288401)  loss 1.552098 (1.552098)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:28:33,141 - WARNING - Epoch [16/25] Step [11/250]  acc 0.210351 (0.262926)  loss 1.582397 (1.582761)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9268.0 MB
2025-08-16 22:28:37,321 - WARNING - Epoch [16/25] Step [21/250]  acc 0.258099 (0.255671)  loss 1.604689 (1.588999)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 9268.0 MB
2025-08-16 22:28:41,472 - WARNING - Epoch [16/25] Step [31/250]  acc 0.215415 (0.253474)  loss 1.617179 (1.588330)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 9268.0 MB
2025-08-16 22:28:45,831 - WARNING - Epoch [16/25] Step [41/250]  acc 0.271314 (0.255596)  loss 1.572048 (1.585314)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 9268.0 MB
2025-08-16 22:28:49,965 - WARNING - Epoch [16/25] Step [51/250]  acc 0.282225 (0.256345)  loss 1.593109 (1.583510)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:28:54,130 - WARNING - Epoch [16/25] Step [61/250]  acc 0.237558 (0.254803)  loss 1.603647 (1.584249)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9268.0 MB
2025-08-16 22:28:58,328 - WARNING - Epoch [16/25] Step [71/250]  acc 0.246934 (0.253917)  loss 1.627847 (1.585600)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 9268.0 MB
2025-08-16 22:29:02,529 - WARNING - Epoch [16/25] Step [81/250]  acc 0.242781 (0.252154)  loss 1.578629 (1.585766)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 9268.0 MB
2025-08-16 22:29:06,698 - WARNING - Epoch [16/25] Step [91/250]  acc 0.283692 (0.253416)  loss 1.574040 (1.584934)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9268.0 MB
2025-08-16 22:29:10,886 - WARNING - Epoch [16/25] Step [101/250]  acc 0.279122 (0.253669)  loss 1.584210 (1.585263)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 9268.0 MB
2025-08-16 22:29:15,073 - WARNING - Epoch [16/25] Step [111/250]  acc 0.250959 (0.254258)  loss 1.585652 (1.584607)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 9268.0 MB
2025-08-16 22:29:19,241 - WARNING - Epoch [16/25] Step [121/250]  acc 0.279082 (0.255243)  loss 1.614305 (1.584253)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9268.0 MB
2025-08-16 22:29:23,413 - WARNING - Epoch [16/25] Step [131/250]  acc 0.255864 (0.255928)  loss 1.545004 (1.585253)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 9268.0 MB
2025-08-16 22:29:27,573 - WARNING - Epoch [16/25] Step [141/250]  acc 0.258225 (0.256601)  loss 1.596932 (1.585043)
GPU memory consumption  GPU Memory: Allocated: 60.5 MB, Reserved: 9268.0 MB
2025-08-16 22:29:31,767 - WARNING - Epoch [16/25] Step [151/250]  acc 0.253666 (0.256795)  loss 1.571078 (1.583714)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 9268.0 MB
2025-08-16 22:29:35,927 - WARNING - Epoch [16/25] Step [161/250]  acc 0.281705 (0.256625)  loss 1.646510 (1.584379)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 9268.0 MB
2025-08-16 22:29:40,097 - WARNING - Epoch [16/25] Step [171/250]  acc 0.271722 (0.256717)  loss 1.678021 (1.584775)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 9268.0 MB
2025-08-16 22:29:44,253 - WARNING - Epoch [16/25] Step [181/250]  acc 0.242928 (0.256462)  loss 1.580686 (1.584302)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 9268.0 MB
2025-08-16 22:29:48,441 - WARNING - Epoch [16/25] Step [191/250]  acc 0.207745 (0.256370)  loss 1.567605 (1.583946)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:29:52,860 - WARNING - Epoch [16/25] Step [201/250]  acc 0.229715 (0.255798)  loss 1.595068 (1.584110)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 9268.0 MB
2025-08-16 22:29:57,047 - WARNING - Epoch [16/25] Step [211/250]  acc 0.258188 (0.255712)  loss 1.559924 (1.584046)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 9268.0 MB
2025-08-16 22:30:01,214 - WARNING - Epoch [16/25] Step [221/250]  acc 0.246545 (0.255643)  loss 1.581890 (1.583949)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 9268.0 MB
2025-08-16 22:30:05,621 - WARNING - Epoch [16/25] Step [231/250]  acc 0.243103 (0.255499)  loss 1.621069 (1.583447)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9268.0 MB
2025-08-16 22:30:09,944 - WARNING - Epoch [16/25] Step [241/250]  acc 0.244681 (0.254466)  loss 1.601471 (1.583930)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 9268.0 MB
Epoch 16 completed in 0:01:45.261851
2025-08-16 22:30:39,802 - WARNING - Epoch [17/25] Step [1/250]  acc 0.298875 (0.298875)  loss 1.609896 (1.609896)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 9268.0 MB
2025-08-16 22:30:44,000 - WARNING - Epoch [17/25] Step [11/250]  acc 0.242911 (0.255539)  loss 1.547366 (1.586995)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 9268.0 MB
2025-08-16 22:30:48,160 - WARNING - Epoch [17/25] Step [21/250]  acc 0.208377 (0.250157)  loss 1.571746 (1.592457)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:30:52,308 - WARNING - Epoch [17/25] Step [31/250]  acc 0.260959 (0.249831)  loss 1.589451 (1.592614)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:30:56,464 - WARNING - Epoch [17/25] Step [41/250]  acc 0.219043 (0.252409)  loss 1.672726 (1.594659)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:31:00,629 - WARNING - Epoch [17/25] Step [51/250]  acc 0.294578 (0.252157)  loss 1.543663 (1.594197)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 9268.0 MB
2025-08-16 22:31:04,827 - WARNING - Epoch [17/25] Step [61/250]  acc 0.250388 (0.253307)  loss 1.552265 (1.589278)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9268.0 MB
2025-08-16 22:31:08,965 - WARNING - Epoch [17/25] Step [71/250]  acc 0.228216 (0.252401)  loss 1.618049 (1.590602)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:31:13,162 - WARNING - Epoch [17/25] Step [81/250]  acc 0.236842 (0.252367)  loss 1.632248 (1.590878)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:31:17,351 - WARNING - Epoch [17/25] Step [91/250]  acc 0.257748 (0.252419)  loss 1.606058 (1.589864)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9268.0 MB
2025-08-16 22:31:21,750 - WARNING - Epoch [17/25] Step [101/250]  acc 0.252886 (0.252233)  loss 1.561866 (1.589876)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 9268.0 MB
2025-08-16 22:31:25,934 - WARNING - Epoch [17/25] Step [111/250]  acc 0.262670 (0.252200)  loss 1.584875 (1.590652)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 9268.0 MB
2025-08-16 22:31:30,098 - WARNING - Epoch [17/25] Step [121/250]  acc 0.222980 (0.252117)  loss 1.548142 (1.590939)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 9268.0 MB
2025-08-16 22:31:34,278 - WARNING - Epoch [17/25] Step [131/250]  acc 0.227072 (0.251429)  loss 1.619902 (1.592460)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 9268.0 MB
2025-08-16 22:31:38,462 - WARNING - Epoch [17/25] Step [141/250]  acc 0.272334 (0.251466)  loss 1.606973 (1.592139)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 9268.0 MB
2025-08-16 22:31:42,650 - WARNING - Epoch [17/25] Step [151/250]  acc 0.237818 (0.251138)  loss 1.555950 (1.592297)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 9268.0 MB
2025-08-16 22:31:46,812 - WARNING - Epoch [17/25] Step [161/250]  acc 0.214401 (0.251030)  loss 1.598833 (1.592467)
GPU memory consumption  GPU Memory: Allocated: 59.5 MB, Reserved: 9268.0 MB
2025-08-16 22:31:50,997 - WARNING - Epoch [17/25] Step [171/250]  acc 0.260483 (0.251074)  loss 1.557459 (1.591907)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 9268.0 MB
2025-08-16 22:31:55,176 - WARNING - Epoch [17/25] Step [181/250]  acc 0.242171 (0.250911)  loss 1.636978 (1.592128)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:31:59,341 - WARNING - Epoch [17/25] Step [191/250]  acc 0.256801 (0.250677)  loss 1.564945 (1.592330)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 9268.0 MB
2025-08-16 22:32:03,528 - WARNING - Epoch [17/25] Step [201/250]  acc 0.263349 (0.250977)  loss 1.565303 (1.592634)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 9268.0 MB
2025-08-16 22:32:07,698 - WARNING - Epoch [17/25] Step [211/250]  acc 0.253619 (0.250912)  loss 1.551104 (1.592492)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 9268.0 MB
2025-08-16 22:32:11,882 - WARNING - Epoch [17/25] Step [221/250]  acc 0.287447 (0.251386)  loss 1.540433 (1.591117)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 9268.0 MB
2025-08-16 22:32:16,063 - WARNING - Epoch [17/25] Step [231/250]  acc 0.247244 (0.251417)  loss 1.583194 (1.591144)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9268.0 MB
2025-08-16 22:32:20,221 - WARNING - Epoch [17/25] Step [241/250]  acc 0.257431 (0.251403)  loss 1.539704 (1.590600)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 9268.0 MB
Epoch 17 completed in 0:01:44.603399
2025-08-16 22:32:50,172 - WARNING - Epoch [18/25] Step [1/250]  acc 0.219598 (0.219598)  loss 1.629232 (1.629232)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 9268.0 MB
2025-08-16 22:32:54,376 - WARNING - Epoch [18/25] Step [11/250]  acc 0.231701 (0.246064)  loss 1.570007 (1.579224)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 9268.0 MB
2025-08-16 22:32:58,577 - WARNING - Epoch [18/25] Step [21/250]  acc 0.258147 (0.251510)  loss 1.598845 (1.565854)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9268.0 MB
2025-08-16 22:33:02,761 - WARNING - Epoch [18/25] Step [31/250]  acc 0.287278 (0.255476)  loss 1.584624 (1.573647)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:33:06,930 - WARNING - Epoch [18/25] Step [41/250]  acc 0.271996 (0.253825)  loss 1.581918 (1.581457)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 9268.0 MB
2025-08-16 22:33:11,106 - WARNING - Epoch [18/25] Step [51/250]  acc 0.237787 (0.254812)  loss 1.573155 (1.578771)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 9268.0 MB
2025-08-16 22:33:15,282 - WARNING - Epoch [18/25] Step [61/250]  acc 0.265451 (0.256512)  loss 1.600228 (1.579771)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9268.0 MB
2025-08-16 22:33:19,460 - WARNING - Epoch [18/25] Step [71/250]  acc 0.250743 (0.255821)  loss 1.628877 (1.582456)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 9268.0 MB
2025-08-16 22:33:23,662 - WARNING - Epoch [18/25] Step [81/250]  acc 0.258304 (0.256183)  loss 1.519192 (1.582447)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 9268.0 MB
2025-08-16 22:33:27,850 - WARNING - Epoch [18/25] Step [91/250]  acc 0.274882 (0.256126)  loss 1.598209 (1.583600)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 9268.0 MB
2025-08-16 22:33:32,069 - WARNING - Epoch [18/25] Step [101/250]  acc 0.273118 (0.255712)  loss 1.571610 (1.581680)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 9268.0 MB
2025-08-16 22:33:36,255 - WARNING - Epoch [18/25] Step [111/250]  acc 0.265651 (0.256125)  loss 1.541753 (1.581982)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 9268.0 MB
2025-08-16 22:33:40,449 - WARNING - Epoch [18/25] Step [121/250]  acc 0.233370 (0.256442)  loss 1.585012 (1.582100)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 9268.0 MB
2025-08-16 22:33:44,613 - WARNING - Epoch [18/25] Step [131/250]  acc 0.282415 (0.257094)  loss 1.572323 (1.583217)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9268.0 MB
2025-08-16 22:33:48,746 - WARNING - Epoch [18/25] Step [141/250]  acc 0.273610 (0.256547)  loss 1.564245 (1.583825)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 9268.0 MB
2025-08-16 22:33:52,929 - WARNING - Epoch [18/25] Step [151/250]  acc 0.236886 (0.256840)  loss 1.663329 (1.583286)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 9268.0 MB
2025-08-16 22:33:57,310 - WARNING - Epoch [18/25] Step [161/250]  acc 0.222834 (0.256335)  loss 1.550253 (1.583582)
GPU memory consumption  GPU Memory: Allocated: 61.3 MB, Reserved: 9268.0 MB
2025-08-16 22:34:01,487 - WARNING - Epoch [18/25] Step [171/250]  acc 0.227835 (0.256151)  loss 1.550758 (1.583029)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 9268.0 MB
2025-08-16 22:34:05,664 - WARNING - Epoch [18/25] Step [181/250]  acc 0.255929 (0.256191)  loss 1.537358 (1.582639)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 9268.0 MB
2025-08-16 22:34:09,806 - WARNING - Epoch [18/25] Step [191/250]  acc 0.277154 (0.255628)  loss 1.528508 (1.582522)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 9268.0 MB
2025-08-16 22:34:13,965 - WARNING - Epoch [18/25] Step [201/250]  acc 0.296963 (0.256709)  loss 1.533803 (1.582422)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 9268.0 MB
2025-08-16 22:34:18,098 - WARNING - Epoch [18/25] Step [211/250]  acc 0.280987 (0.256653)  loss 1.549543 (1.582787)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 9268.0 MB
2025-08-16 22:34:22,258 - WARNING - Epoch [18/25] Step [221/250]  acc 0.288293 (0.256196)  loss 1.603034 (1.583575)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9268.0 MB
2025-08-16 22:34:26,393 - WARNING - Epoch [18/25] Step [231/250]  acc 0.254303 (0.256420)  loss 1.605314 (1.583453)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 9268.0 MB
2025-08-16 22:34:30,573 - WARNING - Epoch [18/25] Step [241/250]  acc 0.261062 (0.255571)  loss 1.588684 (1.584086)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 9268.0 MB
Epoch 18 completed in 0:01:44.589576
2025-08-16 22:35:00,116 - WARNING - Epoch [19/25] Step [1/250]  acc 0.247065 (0.247065)  loss 1.571149 (1.571149)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 9268.0 MB
2025-08-16 22:35:04,315 - WARNING - Epoch [19/25] Step [11/250]  acc 0.287150 (0.258272)  loss 1.559471 (1.585899)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 9268.0 MB
2025-08-16 22:35:08,546 - WARNING - Epoch [19/25] Step [21/250]  acc 0.238195 (0.258116)  loss 1.549872 (1.586364)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9268.0 MB
2025-08-16 22:35:12,700 - WARNING - Epoch [19/25] Step [31/250]  acc 0.257618 (0.257319)  loss 1.599275 (1.588003)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 9268.0 MB
2025-08-16 22:35:16,841 - WARNING - Epoch [19/25] Step [41/250]  acc 0.233035 (0.257426)  loss 1.601158 (1.584474)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 9268.0 MB
2025-08-16 22:35:20,976 - WARNING - Epoch [19/25] Step [51/250]  acc 0.241758 (0.253648)  loss 1.611865 (1.587408)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 9268.0 MB
2025-08-16 22:35:25,336 - WARNING - Epoch [19/25] Step [61/250]  acc 0.283922 (0.254469)  loss 1.544028 (1.587541)
GPU memory consumption  GPU Memory: Allocated: 52.6 MB, Reserved: 9268.0 MB
2025-08-16 22:35:29,480 - WARNING - Epoch [19/25] Step [71/250]  acc 0.219104 (0.254676)  loss 1.626460 (1.587475)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9268.0 MB
2025-08-16 22:35:33,663 - WARNING - Epoch [19/25] Step [81/250]  acc 0.246162 (0.255157)  loss 1.560540 (1.586691)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 9268.0 MB
2025-08-16 22:35:37,785 - WARNING - Epoch [19/25] Step [91/250]  acc 0.252886 (0.254818)  loss 1.551984 (1.586485)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9268.0 MB
2025-08-16 22:35:41,920 - WARNING - Epoch [19/25] Step [101/250]  acc 0.268081 (0.255843)  loss 1.626915 (1.584832)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 9268.0 MB
2025-08-16 22:35:46,089 - WARNING - Epoch [19/25] Step [111/250]  acc 0.296336 (0.255978)  loss 1.582525 (1.583725)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 9268.0 MB
2025-08-16 22:35:50,263 - WARNING - Epoch [19/25] Step [121/250]  acc 0.271605 (0.256635)  loss 1.586318 (1.582220)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 9268.0 MB
2025-08-16 22:35:54,421 - WARNING - Epoch [19/25] Step [131/250]  acc 0.225926 (0.257469)  loss 1.571992 (1.581858)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 9268.0 MB
2025-08-16 22:35:58,551 - WARNING - Epoch [19/25] Step [141/250]  acc 0.254849 (0.256843)  loss 1.562849 (1.582134)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 9268.0 MB
2025-08-16 22:36:02,724 - WARNING - Epoch [19/25] Step [151/250]  acc 0.249084 (0.256433)  loss 1.616421 (1.583224)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9268.0 MB
2025-08-16 22:36:06,843 - WARNING - Epoch [19/25] Step [161/250]  acc 0.234494 (0.256050)  loss 1.645136 (1.583404)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 9272.0 MB
2025-08-16 22:36:10,994 - WARNING - Epoch [19/25] Step [171/250]  acc 0.253653 (0.255546)  loss 1.597176 (1.584329)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 9272.0 MB
2025-08-16 22:36:15,127 - WARNING - Epoch [19/25] Step [181/250]  acc 0.275998 (0.254954)  loss 1.556736 (1.584347)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 9272.0 MB
2025-08-16 22:36:19,292 - WARNING - Epoch [19/25] Step [191/250]  acc 0.264594 (0.254952)  loss 1.591481 (1.583676)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9272.0 MB
2025-08-16 22:36:23,461 - WARNING - Epoch [19/25] Step [201/250]  acc 0.259016 (0.255357)  loss 1.625786 (1.583325)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 9272.0 MB
2025-08-16 22:36:27,800 - WARNING - Epoch [19/25] Step [211/250]  acc 0.273151 (0.255165)  loss 1.566789 (1.583966)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9272.0 MB
2025-08-16 22:36:31,970 - WARNING - Epoch [19/25] Step [221/250]  acc 0.208068 (0.254999)  loss 1.591082 (1.583666)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 9272.0 MB
2025-08-16 22:36:36,083 - WARNING - Epoch [19/25] Step [231/250]  acc 0.253063 (0.254937)  loss 1.569906 (1.583247)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9272.0 MB
2025-08-16 22:36:40,155 - WARNING - Epoch [19/25] Step [241/250]  acc 0.235692 (0.254585)  loss 1.611398 (1.584100)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9272.0 MB
Epoch 19 completed in 0:01:44.146446
2025-08-16 22:37:09,390 - WARNING - Epoch [20/25] Step [1/250]  acc 0.207577 (0.207577)  loss 1.639903 (1.639903)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 9272.0 MB
2025-08-16 22:37:13,519 - WARNING - Epoch [20/25] Step [11/250]  acc 0.204522 (0.232511)  loss 1.688190 (1.615634)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 9272.0 MB
2025-08-16 22:37:17,647 - WARNING - Epoch [20/25] Step [21/250]  acc 0.244744 (0.241869)  loss 1.570568 (1.599186)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 9272.0 MB
2025-08-16 22:37:21,774 - WARNING - Epoch [20/25] Step [31/250]  acc 0.225916 (0.245388)  loss 1.693603 (1.593999)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 9272.0 MB
2025-08-16 22:37:25,917 - WARNING - Epoch [20/25] Step [41/250]  acc 0.217538 (0.246571)  loss 1.563731 (1.593715)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 9272.0 MB
2025-08-16 22:37:30,053 - WARNING - Epoch [20/25] Step [51/250]  acc 0.282738 (0.248224)  loss 1.616819 (1.592508)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 9272.0 MB
2025-08-16 22:37:34,222 - WARNING - Epoch [20/25] Step [61/250]  acc 0.227578 (0.250196)  loss 1.624194 (1.591816)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 9272.0 MB
2025-08-16 22:37:38,442 - WARNING - Epoch [20/25] Step [71/250]  acc 0.270869 (0.250556)  loss 1.594142 (1.589852)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9272.0 MB
2025-08-16 22:37:42,630 - WARNING - Epoch [20/25] Step [81/250]  acc 0.271195 (0.250236)  loss 1.571195 (1.588683)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 9272.0 MB
2025-08-16 22:37:46,861 - WARNING - Epoch [20/25] Step [91/250]  acc 0.298812 (0.251966)  loss 1.573453 (1.587926)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 9272.0 MB
2025-08-16 22:37:51,099 - WARNING - Epoch [20/25] Step [101/250]  acc 0.265979 (0.251687)  loss 1.556837 (1.586132)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 9272.0 MB
2025-08-16 22:37:55,329 - WARNING - Epoch [20/25] Step [111/250]  acc 0.243414 (0.253038)  loss 1.612450 (1.586666)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 9272.0 MB
2025-08-16 22:37:59,861 - WARNING - Epoch [20/25] Step [121/250]  acc 0.238019 (0.252306)  loss 1.579233 (1.586551)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9272.0 MB
2025-08-16 22:38:04,215 - WARNING - Epoch [20/25] Step [131/250]  acc 0.231109 (0.252788)  loss 1.640474 (1.587512)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 9272.0 MB
2025-08-16 22:38:08,607 - WARNING - Epoch [20/25] Step [141/250]  acc 0.305198 (0.253473)  loss 1.552396 (1.587336)
GPU memory consumption  GPU Memory: Allocated: 60.1 MB, Reserved: 9272.0 MB
2025-08-16 22:38:13,048 - WARNING - Epoch [20/25] Step [151/250]  acc 0.253018 (0.254667)  loss 1.610844 (1.586494)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9272.0 MB
2025-08-16 22:38:17,348 - WARNING - Epoch [20/25] Step [161/250]  acc 0.266702 (0.254728)  loss 1.563791 (1.586426)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 9272.0 MB
2025-08-16 22:38:21,510 - WARNING - Epoch [20/25] Step [171/250]  acc 0.244831 (0.254192)  loss 1.672368 (1.585980)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 9272.0 MB
2025-08-16 22:38:25,648 - WARNING - Epoch [20/25] Step [181/250]  acc 0.282192 (0.253877)  loss 1.601367 (1.585522)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 9272.0 MB
2025-08-16 22:38:29,791 - WARNING - Epoch [20/25] Step [191/250]  acc 0.252621 (0.254470)  loss 1.606260 (1.585751)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9272.0 MB
2025-08-16 22:38:33,966 - WARNING - Epoch [20/25] Step [201/250]  acc 0.252664 (0.254255)  loss 1.590325 (1.585743)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 9272.0 MB
2025-08-16 22:38:38,101 - WARNING - Epoch [20/25] Step [211/250]  acc 0.269891 (0.254813)  loss 1.531872 (1.585210)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9272.0 MB
2025-08-16 22:38:42,232 - WARNING - Epoch [20/25] Step [221/250]  acc 0.275583 (0.254569)  loss 1.558070 (1.584811)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9272.0 MB
2025-08-16 22:38:46,443 - WARNING - Epoch [20/25] Step [231/250]  acc 0.253240 (0.254743)  loss 1.541180 (1.584745)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 9272.0 MB
2025-08-16 22:38:50,629 - WARNING - Epoch [20/25] Step [241/250]  acc 0.244664 (0.254527)  loss 1.609789 (1.584044)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9272.0 MB
Epoch 20 completed in 0:01:45.394913
2025-08-16 22:39:20,222 - WARNING - Epoch [21/25] Step [1/250]  acc 0.238624 (0.238624)  loss 1.562982 (1.562982)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 9272.0 MB
2025-08-16 22:39:24,371 - WARNING - Epoch [21/25] Step [11/250]  acc 0.268453 (0.257766)  loss 1.513594 (1.572945)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9272.0 MB
2025-08-16 22:39:28,748 - WARNING - Epoch [21/25] Step [21/250]  acc 0.196550 (0.253574)  loss 1.614001 (1.576148)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9272.0 MB
2025-08-16 22:39:32,917 - WARNING - Epoch [21/25] Step [31/250]  acc 0.242291 (0.254446)  loss 1.591838 (1.581483)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 9272.0 MB
2025-08-16 22:39:37,062 - WARNING - Epoch [21/25] Step [41/250]  acc 0.215784 (0.253721)  loss 1.611837 (1.582625)
GPU memory consumption  GPU Memory: Allocated: 59.4 MB, Reserved: 9272.0 MB
2025-08-16 22:39:41,186 - WARNING - Epoch [21/25] Step [51/250]  acc 0.247445 (0.255985)  loss 1.557797 (1.582161)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9272.0 MB
2025-08-16 22:39:45,347 - WARNING - Epoch [21/25] Step [61/250]  acc 0.255243 (0.257835)  loss 1.559765 (1.579540)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 9272.0 MB
2025-08-16 22:39:49,487 - WARNING - Epoch [21/25] Step [71/250]  acc 0.242346 (0.257600)  loss 1.580359 (1.579676)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9272.0 MB
2025-08-16 22:39:53,681 - WARNING - Epoch [21/25] Step [81/250]  acc 0.231244 (0.256600)  loss 1.598414 (1.580388)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9272.0 MB
2025-08-16 22:39:57,816 - WARNING - Epoch [21/25] Step [91/250]  acc 0.229225 (0.256512)  loss 1.572422 (1.578110)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 9272.0 MB
2025-08-16 22:40:01,975 - WARNING - Epoch [21/25] Step [101/250]  acc 0.273182 (0.255787)  loss 1.538273 (1.578045)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9272.0 MB
2025-08-16 22:40:06,227 - WARNING - Epoch [21/25] Step [111/250]  acc 0.294148 (0.255384)  loss 1.507470 (1.577183)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9272.0 MB
2025-08-16 22:40:10,442 - WARNING - Epoch [21/25] Step [121/250]  acc 0.267388 (0.254761)  loss 1.579511 (1.577784)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9272.0 MB
2025-08-16 22:40:14,593 - WARNING - Epoch [21/25] Step [131/250]  acc 0.310811 (0.255142)  loss 1.566346 (1.577339)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 9272.0 MB
2025-08-16 22:40:18,722 - WARNING - Epoch [21/25] Step [141/250]  acc 0.261117 (0.254971)  loss 1.555983 (1.576635)
GPU memory consumption  GPU Memory: Allocated: 60.1 MB, Reserved: 9272.0 MB
2025-08-16 22:40:22,875 - WARNING - Epoch [21/25] Step [151/250]  acc 0.218397 (0.254889)  loss 1.617557 (1.577065)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 9272.0 MB
2025-08-16 22:40:27,015 - WARNING - Epoch [21/25] Step [161/250]  acc 0.289691 (0.254834)  loss 1.541781 (1.576375)
GPU memory consumption  GPU Memory: Allocated: 61.3 MB, Reserved: 9272.0 MB
2025-08-16 22:40:31,395 - WARNING - Epoch [21/25] Step [171/250]  acc 0.260892 (0.255041)  loss 1.531563 (1.576154)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 9272.0 MB
2025-08-16 22:40:35,533 - WARNING - Epoch [21/25] Step [181/250]  acc 0.224875 (0.254821)  loss 1.588418 (1.575861)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 9272.0 MB
2025-08-16 22:40:39,690 - WARNING - Epoch [21/25] Step [191/250]  acc 0.256784 (0.255220)  loss 1.550829 (1.576249)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9272.0 MB
2025-08-16 22:40:43,852 - WARNING - Epoch [21/25] Step [201/250]  acc 0.256853 (0.255243)  loss 1.590288 (1.576744)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 9272.0 MB
2025-08-16 22:40:47,979 - WARNING - Epoch [21/25] Step [211/250]  acc 0.236948 (0.255367)  loss 1.636451 (1.576892)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 9272.0 MB
2025-08-16 22:40:52,140 - WARNING - Epoch [21/25] Step [221/250]  acc 0.234946 (0.255119)  loss 1.616829 (1.576830)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 9272.0 MB
2025-08-16 22:40:56,270 - WARNING - Epoch [21/25] Step [231/250]  acc 0.211029 (0.255053)  loss 1.573981 (1.576708)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 9272.0 MB
2025-08-16 22:41:00,416 - WARNING - Epoch [21/25] Step [241/250]  acc 0.186468 (0.254868)  loss 1.585175 (1.576450)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 9272.0 MB
Epoch 21 completed in 0:01:44.345392
2025-08-16 22:41:29,745 - WARNING - Epoch [22/25] Step [1/250]  acc 0.300777 (0.300777)  loss 1.547438 (1.547438)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 9272.0 MB
2025-08-16 22:41:33,914 - WARNING - Epoch [22/25] Step [11/250]  acc 0.233604 (0.259586)  loss 1.614994 (1.574484)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9272.0 MB
2025-08-16 22:41:38,063 - WARNING - Epoch [22/25] Step [21/250]  acc 0.255003 (0.256226)  loss 1.548100 (1.576630)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9272.0 MB
2025-08-16 22:41:42,226 - WARNING - Epoch [22/25] Step [31/250]  acc 0.237666 (0.253852)  loss 1.540736 (1.578530)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 9272.0 MB
2025-08-16 22:41:46,377 - WARNING - Epoch [22/25] Step [41/250]  acc 0.268704 (0.257212)  loss 1.576424 (1.574928)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 9272.0 MB
2025-08-16 22:41:50,547 - WARNING - Epoch [22/25] Step [51/250]  acc 0.312686 (0.257794)  loss 1.528991 (1.572662)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 9272.0 MB
2025-08-16 22:41:54,715 - WARNING - Epoch [22/25] Step [61/250]  acc 0.223872 (0.256643)  loss 1.540416 (1.573834)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 9272.0 MB
2025-08-16 22:41:58,857 - WARNING - Epoch [22/25] Step [71/250]  acc 0.256528 (0.255964)  loss 1.581537 (1.574368)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9272.0 MB
2025-08-16 22:42:03,230 - WARNING - Epoch [22/25] Step [81/250]  acc 0.262961 (0.254977)  loss 1.566921 (1.576858)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 9272.0 MB
2025-08-16 22:42:07,372 - WARNING - Epoch [22/25] Step [91/250]  acc 0.246509 (0.255190)  loss 1.509518 (1.574207)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 9272.0 MB
2025-08-16 22:42:11,529 - WARNING - Epoch [22/25] Step [101/250]  acc 0.222043 (0.256251)  loss 1.542813 (1.574043)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 9272.0 MB
2025-08-16 22:42:15,675 - WARNING - Epoch [22/25] Step [111/250]  acc 0.246137 (0.256125)  loss 1.546447 (1.573846)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 9272.0 MB
2025-08-16 22:42:19,801 - WARNING - Epoch [22/25] Step [121/250]  acc 0.231151 (0.255215)  loss 1.590078 (1.574369)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 9272.0 MB
2025-08-16 22:42:23,953 - WARNING - Epoch [22/25] Step [131/250]  acc 0.253870 (0.256134)  loss 1.587509 (1.574548)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9272.0 MB
2025-08-16 22:42:28,118 - WARNING - Epoch [22/25] Step [141/250]  acc 0.234749 (0.256613)  loss 1.595820 (1.574060)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 9272.0 MB
2025-08-16 22:42:32,316 - WARNING - Epoch [22/25] Step [151/250]  acc 0.227092 (0.256551)  loss 1.574891 (1.573637)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 9272.0 MB
2025-08-16 22:42:36,536 - WARNING - Epoch [22/25] Step [161/250]  acc 0.284492 (0.257243)  loss 1.535624 (1.572845)
GPU memory consumption  GPU Memory: Allocated: 59.6 MB, Reserved: 9272.0 MB
2025-08-16 22:42:40,685 - WARNING - Epoch [22/25] Step [171/250]  acc 0.230853 (0.256201)  loss 1.678569 (1.574722)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 9272.0 MB
2025-08-16 22:42:44,832 - WARNING - Epoch [22/25] Step [181/250]  acc 0.267018 (0.256205)  loss 1.560035 (1.574728)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 9272.0 MB
2025-08-16 22:42:48,998 - WARNING - Epoch [22/25] Step [191/250]  acc 0.250784 (0.256367)  loss 1.590381 (1.574927)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 9272.0 MB
2025-08-16 22:42:53,173 - WARNING - Epoch [22/25] Step [201/250]  acc 0.271792 (0.256032)  loss 1.536757 (1.574776)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 9272.0 MB
2025-08-16 22:42:57,315 - WARNING - Epoch [22/25] Step [211/250]  acc 0.252381 (0.255623)  loss 1.605839 (1.574762)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 9272.0 MB
2025-08-16 22:43:01,474 - WARNING - Epoch [22/25] Step [221/250]  acc 0.271396 (0.255415)  loss 1.589773 (1.574840)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 9272.0 MB
2025-08-16 22:43:05,848 - WARNING - Epoch [22/25] Step [231/250]  acc 0.254011 (0.256037)  loss 1.609782 (1.574302)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9272.0 MB
2025-08-16 22:43:10,016 - WARNING - Epoch [22/25] Step [241/250]  acc 0.246546 (0.256211)  loss 1.536869 (1.573215)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 9272.0 MB
Epoch 22 completed in 0:01:44.402421
2025-08-16 22:43:39,567 - WARNING - Epoch [23/25] Step [1/250]  acc 0.250863 (0.250863)  loss 1.596883 (1.596883)
GPU memory consumption  GPU Memory: Allocated: 59.9 MB, Reserved: 9272.0 MB
2025-08-16 22:43:43,748 - WARNING - Epoch [23/25] Step [11/250]  acc 0.243498 (0.233117)  loss 1.565109 (1.583970)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9272.0 MB
2025-08-16 22:43:47,944 - WARNING - Epoch [23/25] Step [21/250]  acc 0.258081 (0.247497)  loss 1.530042 (1.578133)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9272.0 MB
2025-08-16 22:43:52,150 - WARNING - Epoch [23/25] Step [31/250]  acc 0.211939 (0.247287)  loss 1.586136 (1.577046)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 9272.0 MB
2025-08-16 22:43:56,309 - WARNING - Epoch [23/25] Step [41/250]  acc 0.218783 (0.249306)  loss 1.595554 (1.575322)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 9272.0 MB
2025-08-16 22:44:00,454 - WARNING - Epoch [23/25] Step [51/250]  acc 0.259278 (0.249302)  loss 1.576493 (1.577944)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 9272.0 MB
2025-08-16 22:44:04,623 - WARNING - Epoch [23/25] Step [61/250]  acc 0.238967 (0.249351)  loss 1.598354 (1.578532)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 9272.0 MB
2025-08-16 22:44:08,767 - WARNING - Epoch [23/25] Step [71/250]  acc 0.269500 (0.249804)  loss 1.574286 (1.577228)
GPU memory consumption  GPU Memory: Allocated: 61.2 MB, Reserved: 9272.0 MB
2025-08-16 22:44:12,938 - WARNING - Epoch [23/25] Step [81/250]  acc 0.193001 (0.250312)  loss 1.653152 (1.576739)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 9272.0 MB
2025-08-16 22:44:17,108 - WARNING - Epoch [23/25] Step [91/250]  acc 0.236650 (0.251006)  loss 1.547145 (1.576769)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 9272.0 MB
2025-08-16 22:44:21,278 - WARNING - Epoch [23/25] Step [101/250]  acc 0.269603 (0.251296)  loss 1.523918 (1.576714)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 9272.0 MB
2025-08-16 22:44:25,440 - WARNING - Epoch [23/25] Step [111/250]  acc 0.280151 (0.252120)  loss 1.599762 (1.576059)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 9272.0 MB
2025-08-16 22:44:29,614 - WARNING - Epoch [23/25] Step [121/250]  acc 0.215392 (0.251646)  loss 1.569108 (1.577033)
GPU memory consumption  GPU Memory: Allocated: 59.6 MB, Reserved: 9272.0 MB
2025-08-16 22:44:34,040 - WARNING - Epoch [23/25] Step [131/250]  acc 0.251744 (0.252217)  loss 1.506747 (1.576421)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 9272.0 MB
2025-08-16 22:44:38,176 - WARNING - Epoch [23/25] Step [141/250]  acc 0.214973 (0.252459)  loss 1.580393 (1.574914)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 9272.0 MB
2025-08-16 22:44:42,322 - WARNING - Epoch [23/25] Step [151/250]  acc 0.266195 (0.253182)  loss 1.573138 (1.575230)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 9272.0 MB
2025-08-16 22:44:46,478 - WARNING - Epoch [23/25] Step [161/250]  acc 0.240876 (0.253343)  loss 1.586318 (1.573991)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 9272.0 MB
2025-08-16 22:44:50,667 - WARNING - Epoch [23/25] Step [171/250]  acc 0.237103 (0.253404)  loss 1.572698 (1.574883)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 9272.0 MB
2025-08-16 22:44:54,810 - WARNING - Epoch [23/25] Step [181/250]  acc 0.294656 (0.253639)  loss 1.557395 (1.574907)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9272.0 MB
2025-08-16 22:44:58,971 - WARNING - Epoch [23/25] Step [191/250]  acc 0.245104 (0.253583)  loss 1.613350 (1.574756)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 9272.0 MB
2025-08-16 22:45:03,232 - WARNING - Epoch [23/25] Step [201/250]  acc 0.267649 (0.254320)  loss 1.566261 (1.575046)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 9272.0 MB
2025-08-16 22:45:07,701 - WARNING - Epoch [23/25] Step [211/250]  acc 0.285864 (0.254820)  loss 1.548648 (1.575022)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9272.0 MB
2025-08-16 22:45:12,131 - WARNING - Epoch [23/25] Step [221/250]  acc 0.258730 (0.254936)  loss 1.568161 (1.574993)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 9272.0 MB
2025-08-16 22:45:16,266 - WARNING - Epoch [23/25] Step [231/250]  acc 0.304791 (0.254819)  loss 1.527920 (1.575099)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9272.0 MB
2025-08-16 22:45:20,413 - WARNING - Epoch [23/25] Step [241/250]  acc 0.265947 (0.254975)  loss 1.521990 (1.574441)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9272.0 MB
Epoch 23 completed in 0:01:45.029298
2025-08-16 22:45:49,981 - WARNING - Epoch [24/25] Step [1/250]  acc 0.248373 (0.248373)  loss 1.541348 (1.541348)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 9272.0 MB
2025-08-16 22:45:54,168 - WARNING - Epoch [24/25] Step [11/250]  acc 0.251545 (0.249154)  loss 1.548274 (1.568262)
GPU memory consumption  GPU Memory: Allocated: 61.7 MB, Reserved: 9272.0 MB
2025-08-16 22:45:58,324 - WARNING - Epoch [24/25] Step [21/250]  acc 0.275377 (0.251768)  loss 1.574751 (1.563420)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 9272.0 MB
2025-08-16 22:46:02,488 - WARNING - Epoch [24/25] Step [31/250]  acc 0.288831 (0.259259)  loss 1.527787 (1.567801)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 9272.0 MB
2025-08-16 22:46:06,888 - WARNING - Epoch [24/25] Step [41/250]  acc 0.291343 (0.258305)  loss 1.576312 (1.566013)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9272.0 MB
2025-08-16 22:46:11,057 - WARNING - Epoch [24/25] Step [51/250]  acc 0.200549 (0.257094)  loss 1.641579 (1.569706)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 9272.0 MB
2025-08-16 22:46:15,209 - WARNING - Epoch [24/25] Step [61/250]  acc 0.246479 (0.259180)  loss 1.559054 (1.572260)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 9272.0 MB
2025-08-16 22:46:19,376 - WARNING - Epoch [24/25] Step [71/250]  acc 0.242274 (0.257473)  loss 1.553666 (1.573621)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 9272.0 MB
2025-08-16 22:46:23,533 - WARNING - Epoch [24/25] Step [81/250]  acc 0.214978 (0.256208)  loss 1.608340 (1.574880)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 9272.0 MB
2025-08-16 22:46:27,640 - WARNING - Epoch [24/25] Step [91/250]  acc 0.243131 (0.256794)  loss 1.582024 (1.574346)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 9272.0 MB
2025-08-16 22:46:31,832 - WARNING - Epoch [24/25] Step [101/250]  acc 0.254965 (0.256406)  loss 1.569576 (1.575061)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 9272.0 MB
2025-08-16 22:46:36,016 - WARNING - Epoch [24/25] Step [111/250]  acc 0.251994 (0.256127)  loss 1.562786 (1.573336)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 9272.0 MB
2025-08-16 22:46:40,202 - WARNING - Epoch [24/25] Step [121/250]  acc 0.281168 (0.257093)  loss 1.581196 (1.572284)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9272.0 MB
2025-08-16 22:46:44,380 - WARNING - Epoch [24/25] Step [131/250]  acc 0.248395 (0.257790)  loss 1.566549 (1.571504)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 9272.0 MB
2025-08-16 22:46:48,534 - WARNING - Epoch [24/25] Step [141/250]  acc 0.242162 (0.257595)  loss 1.653830 (1.572438)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 9272.0 MB
2025-08-16 22:46:52,712 - WARNING - Epoch [24/25] Step [151/250]  acc 0.267003 (0.257325)  loss 1.569541 (1.571933)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9272.0 MB
2025-08-16 22:46:56,779 - WARNING - Epoch [24/25] Step [161/250]  acc 0.265683 (0.257263)  loss 1.558871 (1.572227)
GPU memory consumption  GPU Memory: Allocated: 60.1 MB, Reserved: 9272.0 MB
2025-08-16 22:47:00,877 - WARNING - Epoch [24/25] Step [171/250]  acc 0.276255 (0.257102)  loss 1.576903 (1.572167)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 9272.0 MB
2025-08-16 22:47:04,996 - WARNING - Epoch [24/25] Step [181/250]  acc 0.276405 (0.257511)  loss 1.538734 (1.571961)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 9272.0 MB
2025-08-16 22:47:09,333 - WARNING - Epoch [24/25] Step [191/250]  acc 0.249721 (0.256859)  loss 1.614267 (1.572122)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 9272.0 MB
2025-08-16 22:47:13,494 - WARNING - Epoch [24/25] Step [201/250]  acc 0.253266 (0.256980)  loss 1.588902 (1.572699)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9272.0 MB
2025-08-16 22:47:17,628 - WARNING - Epoch [24/25] Step [211/250]  acc 0.261101 (0.256695)  loss 1.603164 (1.572988)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 9272.0 MB
2025-08-16 22:47:21,782 - WARNING - Epoch [24/25] Step [221/250]  acc 0.257768 (0.256695)  loss 1.583591 (1.572718)
GPU memory consumption  GPU Memory: Allocated: 52.3 MB, Reserved: 9272.0 MB
2025-08-16 22:47:25,922 - WARNING - Epoch [24/25] Step [231/250]  acc 0.239578 (0.256413)  loss 1.615073 (1.574166)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 9272.0 MB
2025-08-16 22:47:30,057 - WARNING - Epoch [24/25] Step [241/250]  acc 0.261843 (0.255930)  loss 1.568234 (1.573491)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 9272.0 MB
Epoch 24 completed in 0:01:44.252331
2025-08-16 22:47:59,742 - WARNING - Epoch [25/25] Step [1/250]  acc 0.281712 (0.281712)  loss 1.582403 (1.582403)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9272.0 MB
2025-08-16 22:48:03,938 - WARNING - Epoch [25/25] Step [11/250]  acc 0.267168 (0.261714)  loss 1.546702 (1.570055)
GPU memory consumption  GPU Memory: Allocated: 60.2 MB, Reserved: 9272.0 MB
2025-08-16 22:48:08,102 - WARNING - Epoch [25/25] Step [21/250]  acc 0.250651 (0.256224)  loss 1.630846 (1.580566)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9272.0 MB
2025-08-16 22:48:12,255 - WARNING - Epoch [25/25] Step [31/250]  acc 0.261419 (0.253545)  loss 1.575527 (1.579116)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 9272.0 MB
2025-08-16 22:48:16,399 - WARNING - Epoch [25/25] Step [41/250]  acc 0.229860 (0.250956)  loss 1.549749 (1.578216)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 9272.0 MB
2025-08-16 22:48:20,541 - WARNING - Epoch [25/25] Step [51/250]  acc 0.272142 (0.254236)  loss 1.538553 (1.577264)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 9272.0 MB
2025-08-16 22:48:24,727 - WARNING - Epoch [25/25] Step [61/250]  acc 0.261420 (0.255707)  loss 1.627873 (1.576371)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 9272.0 MB
2025-08-16 22:48:28,891 - WARNING - Epoch [25/25] Step [71/250]  acc 0.251603 (0.255339)  loss 1.574829 (1.575116)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 9272.0 MB
2025-08-16 22:48:33,096 - WARNING - Epoch [25/25] Step [81/250]  acc 0.276693 (0.255596)  loss 1.558131 (1.574938)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 9272.0 MB
2025-08-16 22:48:37,257 - WARNING - Epoch [25/25] Step [91/250]  acc 0.246435 (0.255640)  loss 1.574561 (1.574698)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 9272.0 MB
2025-08-16 22:48:41,627 - WARNING - Epoch [25/25] Step [101/250]  acc 0.245758 (0.256155)  loss 1.557839 (1.574250)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 9272.0 MB
2025-08-16 22:48:45,772 - WARNING - Epoch [25/25] Step [111/250]  acc 0.247434 (0.256243)  loss 1.539533 (1.572957)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 9272.0 MB
2025-08-16 22:48:49,908 - WARNING - Epoch [25/25] Step [121/250]  acc 0.269657 (0.257142)  loss 1.622817 (1.573145)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 9272.0 MB
2025-08-16 22:48:54,072 - WARNING - Epoch [25/25] Step [131/250]  acc 0.248066 (0.256843)  loss 1.537904 (1.574426)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 9272.0 MB
2025-08-16 22:48:58,236 - WARNING - Epoch [25/25] Step [141/250]  acc 0.257771 (0.256721)  loss 1.529426 (1.574104)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 9272.0 MB
2025-08-16 22:49:02,420 - WARNING - Epoch [25/25] Step [151/250]  acc 0.296686 (0.256414)  loss 1.512642 (1.573715)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 9272.0 MB
2025-08-16 22:49:06,583 - WARNING - Epoch [25/25] Step [161/250]  acc 0.280945 (0.256521)  loss 1.614607 (1.574074)
GPU memory consumption  GPU Memory: Allocated: 61.3 MB, Reserved: 9272.0 MB
2025-08-16 22:49:10,760 - WARNING - Epoch [25/25] Step [171/250]  acc 0.258883 (0.256421)  loss 1.528504 (1.574305)
GPU memory consumption  GPU Memory: Allocated: 53.0 MB, Reserved: 9272.0 MB
2025-08-16 22:49:14,911 - WARNING - Epoch [25/25] Step [181/250]  acc 0.244920 (0.256202)  loss 1.636079 (1.574456)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 9272.0 MB
2025-08-16 22:49:19,060 - WARNING - Epoch [25/25] Step [191/250]  acc 0.240835 (0.256087)  loss 1.549926 (1.574010)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 9272.0 MB
2025-08-16 22:49:23,213 - WARNING - Epoch [25/25] Step [201/250]  acc 0.297714 (0.256792)  loss 1.577217 (1.573793)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 9272.0 MB
2025-08-16 22:49:27,350 - WARNING - Epoch [25/25] Step [211/250]  acc 0.285000 (0.256595)  loss 1.571360 (1.574126)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 9272.0 MB
2025-08-16 22:49:31,519 - WARNING - Epoch [25/25] Step [221/250]  acc 0.265048 (0.257313)  loss 1.546501 (1.572781)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 9272.0 MB
2025-08-16 22:49:35,657 - WARNING - Epoch [25/25] Step [231/250]  acc 0.257279 (0.257196)  loss 1.565619 (1.572277)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 9272.0 MB
2025-08-16 22:49:39,803 - WARNING - Epoch [25/25] Step [241/250]  acc 0.256721 (0.257320)  loss 1.550534 (1.572366)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 9272.0 MB
Epoch 25 completed in 0:01:44.432528
2025-08-16 22:50:09,269 - INFO - DARTS search completed in 3349.36s
2025-08-16 22:50:09,270 - INFO - 
============================================================
2025-08-16 22:50:09,270 - INFO - Layer layer_0 Expert Selection:
2025-08-16 22:50:09,270 - INFO -   Expert 0: GINE (α=0.3375)
2025-08-16 22:50:09,270 - INFO -   Expert 1: CustomGatedGCN (α=0.3246)
2025-08-16 22:50:09,270 - INFO -   Expert 2: GATV2 (α=0.3380) ← SELECTED
2025-08-16 22:50:09,270 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-16 22:50:09,270 - INFO - ============================================================

2025-08-16 22:50:09,270 - INFO - 
============================================================
2025-08-16 22:50:09,270 - INFO - Layer layer_1 Expert Selection:
2025-08-16 22:50:09,270 - INFO -   Expert 0: GINE (α=0.3211)
2025-08-16 22:50:09,270 - INFO -   Expert 1: CustomGatedGCN (α=0.3550) ← SELECTED
2025-08-16 22:50:09,270 - INFO -   Expert 2: GATV2 (α=0.3239)
2025-08-16 22:50:09,270 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 22:50:09,270 - INFO - ============================================================

2025-08-16 22:50:09,270 - INFO - 
============================================================
2025-08-16 22:50:09,270 - INFO - Layer layer_2 Expert Selection:
2025-08-16 22:50:09,270 - INFO -   Expert 0: GINE (α=0.3261)
2025-08-16 22:50:09,270 - INFO -   Expert 1: CustomGatedGCN (α=0.3568) ← SELECTED
2025-08-16 22:50:09,270 - INFO -   Expert 2: GATV2 (α=0.3170)
2025-08-16 22:50:09,270 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 22:50:09,270 - INFO - ============================================================

2025-08-16 22:50:09,270 - INFO - 
============================================================
2025-08-16 22:50:09,271 - INFO - Layer layer_3 Expert Selection:
2025-08-16 22:50:09,271 - INFO -   Expert 0: GINE (α=0.3287)
2025-08-16 22:50:09,271 - INFO -   Expert 1: CustomGatedGCN (α=0.3324)
2025-08-16 22:50:09,271 - INFO -   Expert 2: GATV2 (α=0.3389) ← SELECTED
2025-08-16 22:50:09,271 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-16 22:50:09,271 - INFO - ============================================================

2025-08-16 22:50:09,271 - INFO - 
============================================================
2025-08-16 22:50:09,271 - INFO - Layer layer_4 Expert Selection:
2025-08-16 22:50:09,271 - INFO -   Expert 0: GINE (α=0.3474)
2025-08-16 22:50:09,271 - INFO -   Expert 1: CustomGatedGCN (α=0.2860)
2025-08-16 22:50:09,271 - INFO -   Expert 2: GATV2 (α=0.3666) ← SELECTED
2025-08-16 22:50:09,271 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-16 22:50:09,271 - INFO - ============================================================

2025-08-16 22:50:09,271 - INFO - 
============================================================
2025-08-16 22:50:09,271 - INFO - Layer layer_5 Expert Selection:
2025-08-16 22:50:09,271 - INFO -   Expert 0: GINE (α=0.2828)
2025-08-16 22:50:09,271 - INFO -   Expert 1: CustomGatedGCN (α=0.3248)
2025-08-16 22:50:09,271 - INFO -   Expert 2: GATV2 (α=0.3924) ← SELECTED
2025-08-16 22:50:09,271 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-16 22:50:09,271 - INFO - ============================================================

2025-08-16 22:50:09,271 - INFO - 
============================================================
2025-08-16 22:50:09,271 - INFO - Layer layer_6 Expert Selection:
2025-08-16 22:50:09,271 - INFO -   Expert 0: GINE (α=0.2795)
2025-08-16 22:50:09,271 - INFO -   Expert 1: CustomGatedGCN (α=0.3933) ← SELECTED
2025-08-16 22:50:09,271 - INFO -   Expert 2: GATV2 (α=0.3272)
2025-08-16 22:50:09,272 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 22:50:09,272 - INFO - ============================================================

2025-08-16 22:50:09,272 - INFO - 
============================================================
2025-08-16 22:50:09,272 - INFO - Layer layer_7 Expert Selection:
2025-08-16 22:50:09,272 - INFO -   Expert 0: GINE (α=0.2658)
2025-08-16 22:50:09,272 - INFO -   Expert 1: CustomGatedGCN (α=0.3471)
2025-08-16 22:50:09,272 - INFO -   Expert 2: GATV2 (α=0.3871) ← SELECTED
2025-08-16 22:50:09,272 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-16 22:50:09,272 - INFO - ============================================================

2025-08-16 22:50:09,272 - INFO - 
============================================================
2025-08-16 22:50:09,272 - INFO - Layer layer_8 Expert Selection:
2025-08-16 22:50:09,272 - INFO -   Expert 0: GINE (α=0.2970)
2025-08-16 22:50:09,272 - INFO -   Expert 1: CustomGatedGCN (α=0.3849) ← SELECTED
2025-08-16 22:50:09,272 - INFO -   Expert 2: GATV2 (α=0.3181)
2025-08-16 22:50:09,272 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 22:50:09,272 - INFO - ============================================================

2025-08-16 22:50:09,272 - INFO - 
============================================================
2025-08-16 22:50:09,272 - INFO - Layer layer_9 Expert Selection:
2025-08-16 22:50:09,272 - INFO -   Expert 0: GINE (α=0.3313)
2025-08-16 22:50:09,272 - INFO -   Expert 1: CustomGatedGCN (α=0.3294)
2025-08-16 22:50:09,272 - INFO -   Expert 2: GATV2 (α=0.3393) ← SELECTED
2025-08-16 22:50:09,272 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-16 22:50:09,272 - INFO - ============================================================

2025-08-16 22:50:09,272 - INFO - 
============================================================
2025-08-16 22:50:09,272 - INFO - Layer layer_10 Expert Selection:
2025-08-16 22:50:09,272 - INFO -   Expert 0: GINE (α=0.3340)
2025-08-16 22:50:09,273 - INFO -   Expert 1: CustomGatedGCN (α=0.3370) ← SELECTED
2025-08-16 22:50:09,273 - INFO -   Expert 2: GATV2 (α=0.3290)
2025-08-16 22:50:09,273 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 22:50:09,273 - INFO - ============================================================

2025-08-16 22:50:09,273 - INFO - 
============================================================
2025-08-16 22:50:09,273 - INFO - Layer layer_11 Expert Selection:
2025-08-16 22:50:09,273 - INFO -   Expert 0: GINE (α=0.3322)
2025-08-16 22:50:09,273 - INFO -   Expert 1: CustomGatedGCN (α=0.3528) ← SELECTED
2025-08-16 22:50:09,273 - INFO -   Expert 2: GATV2 (α=0.3149)
2025-08-16 22:50:09,273 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 22:50:09,273 - INFO - ============================================================

2025-08-16 22:50:09,273 - INFO - 
============================================================
2025-08-16 22:50:09,273 - INFO - Layer layer_12 Expert Selection:
2025-08-16 22:50:09,273 - INFO -   Expert 0: GINE (α=0.3044)
2025-08-16 22:50:09,273 - INFO -   Expert 1: CustomGatedGCN (α=0.3849) ← SELECTED
2025-08-16 22:50:09,273 - INFO -   Expert 2: GATV2 (α=0.3106)
2025-08-16 22:50:09,273 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 22:50:09,273 - INFO - ============================================================

2025-08-16 22:50:09,273 - INFO - 
============================================================
2025-08-16 22:50:09,273 - INFO - Layer layer_13 Expert Selection:
2025-08-16 22:50:09,273 - INFO -   Expert 0: GINE (α=0.2610)
2025-08-16 22:50:09,273 - INFO -   Expert 1: CustomGatedGCN (α=0.4506) ← SELECTED
2025-08-16 22:50:09,273 - INFO -   Expert 2: GATV2 (α=0.2884)
2025-08-16 22:50:09,273 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 22:50:09,273 - INFO - ============================================================

2025-08-16 22:50:09,274 - INFO - 
============================================================
2025-08-16 22:50:09,274 - INFO - Layer layer_14 Expert Selection:
2025-08-16 22:50:09,274 - INFO -   Expert 0: GINE (α=0.3004)
2025-08-16 22:50:09,274 - INFO -   Expert 1: CustomGatedGCN (α=0.4274) ← SELECTED
2025-08-16 22:50:09,274 - INFO -   Expert 2: GATV2 (α=0.2722)
2025-08-16 22:50:09,274 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 22:50:09,274 - INFO - ============================================================

2025-08-16 22:50:09,274 - INFO - 
============================================================
2025-08-16 22:50:09,274 - INFO - Layer layer_15 Expert Selection:
2025-08-16 22:50:09,274 - INFO -   Expert 0: GINE (α=0.2761)
2025-08-16 22:50:09,274 - INFO -   Expert 1: CustomGatedGCN (α=0.3381)
2025-08-16 22:50:09,274 - INFO -   Expert 2: GATV2 (α=0.3857) ← SELECTED
2025-08-16 22:50:09,274 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-16 22:50:09,274 - INFO - ============================================================

=== MODEL PARAMETER COMPARISON ===
Original DARTS model parameters: 728,678
2025-08-16 22:50:09,366 - INFO - Layer 0: Using ONLY Expert 2 (GATV2)
2025-08-16 22:50:09,366 - INFO - DiscreteNASLayer 0: Using ONLY Expert 2 (GATV2)
2025-08-16 22:50:09,370 - INFO - Layer 1: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,370 - INFO - DiscreteNASLayer 1: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,373 - INFO - Layer 2: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,373 - INFO - DiscreteNASLayer 2: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,375 - INFO - Layer 3: Using ONLY Expert 2 (GATV2)
2025-08-16 22:50:09,376 - INFO - DiscreteNASLayer 3: Using ONLY Expert 2 (GATV2)
2025-08-16 22:50:09,378 - INFO - Layer 4: Using ONLY Expert 2 (GATV2)
2025-08-16 22:50:09,378 - INFO - DiscreteNASLayer 4: Using ONLY Expert 2 (GATV2)
2025-08-16 22:50:09,380 - INFO - Layer 5: Using ONLY Expert 2 (GATV2)
2025-08-16 22:50:09,380 - INFO - DiscreteNASLayer 5: Using ONLY Expert 2 (GATV2)
2025-08-16 22:50:09,383 - INFO - Layer 6: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,383 - INFO - DiscreteNASLayer 6: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,385 - INFO - Layer 7: Using ONLY Expert 2 (GATV2)
2025-08-16 22:50:09,385 - INFO - DiscreteNASLayer 7: Using ONLY Expert 2 (GATV2)
2025-08-16 22:50:09,388 - INFO - Layer 8: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,388 - INFO - DiscreteNASLayer 8: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,390 - INFO - Layer 9: Using ONLY Expert 2 (GATV2)
2025-08-16 22:50:09,390 - INFO - DiscreteNASLayer 9: Using ONLY Expert 2 (GATV2)
2025-08-16 22:50:09,392 - INFO - Layer 10: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,393 - INFO - DiscreteNASLayer 10: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,395 - INFO - Layer 11: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,395 - INFO - DiscreteNASLayer 11: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,398 - INFO - Layer 12: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,398 - INFO - DiscreteNASLayer 12: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,400 - INFO - Layer 13: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,400 - INFO - DiscreteNASLayer 13: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,403 - INFO - Layer 14: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,403 - INFO - DiscreteNASLayer 14: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 22:50:09,405 - INFO - Layer 15: Using ONLY Expert 2 (GATV2)
2025-08-16 22:50:09,406 - INFO - DiscreteNASLayer 15: Using ONLY Expert 2 (GATV2)
Fresh discrete model parameters: 505,766
Parameter difference: -222,912
✓ Used cfg.share.dim_in (raw input) instead of self.encoder.dim_in (processed)
✓ Fresh discrete model with correct input dimensions
2025-08-16 22:50:09,429 - INFO - Replaced inner model with discrete version
2025-08-16 22:50:09,431 - INFO - Creating fresh optimizer/scheduler for discrete model...
2025-08-16 22:50:09,434 - INFO - Fresh optimizer created: AdamW
2025-08-16 22:50:09,434 - INFO - Fresh scheduler created: LambdaLR
2025-08-16 22:50:09,434 - INFO - Discrete model parameters: 505,766
2025-08-16 22:50:09,434 - INFO - ============================================================
2025-08-16 22:50:09,434 - INFO - PHASE 2: DISCRETE TRAINING WITH UNCERTAINTY
2025-08-16 22:50:09,434 - INFO - ============================================================
2025-08-16 22:50:09,434 - INFO - === Epoch 0 ===
2025-08-16 22:51:35,883 - INFO - train: {'epoch': 0, 'time_epoch': 85.8386, 'eta': 8498.02153, 'eta_hours': 2.36056, 'loss': 1.79323601, 'lr': 0.0, 'params': 505766, 'time_iter': 0.13734, 'accuracy': 0.16602, 'f1': 0.1304, 'accuracy-SBM': 0.16601, 'auc': 0.49806}
2025-08-16 22:51:35,920 - INFO - ...computing epoch stats took: 0.63s
2025-08-16 22:51:40,414 - INFO - val: {'epoch': 0, 'time_epoch': 4.44924, 'loss': 1.79301198, 'lr': 0, 'params': 505766, 'time_iter': 0.07062, 'accuracy': 0.16568, 'f1': 0.12688, 'accuracy-SBM': 0.1662, 'auc': 0.49904}
2025-08-16 22:51:40,427 - INFO - ...computing epoch stats took: 0.05s
2025-08-16 22:51:46,588 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 22:51:46,633 - INFO - test: {'epoch': 0, 'time_epoch': 4.74802, 'loss': 1.7933908, 'lr': 0, 'params': 505766, 'time_iter': 0.07537, 'accuracy': 0.16751, 'f1': 0.12722, 'accuracy-SBM': 0.16868, 'auc': 0.49746}
2025-08-16 22:51:46,635 - INFO - ...computing epoch stats took: 0.04s
2025-08-16 22:51:46,635 - INFO - > Epoch 0: took 97.2s (avg 97.2s) | Best so far: epoch 0	train_loss: 1.7932 train_accuracy-SBM: 0.1660	val_loss: 1.7930 val_accuracy-SBM: 0.1662	test_loss: 1.7934 test_accuracy-SBM: 0.1687
2025-08-16 22:51:46,635 - INFO - === Epoch 1 ===
2025-08-16 22:53:13,279 - INFO - train: {'epoch': 1, 'time_epoch': 86.31233, 'eta': 8435.39547, 'eta_hours': 2.34317, 'loss': 1.63133186, 'lr': 0.0002, 'params': 505766, 'time_iter': 0.1381, 'accuracy': 0.35313, 'f1': 0.33707, 'accuracy-SBM': 0.35307, 'auc': 0.7089}
2025-08-16 22:53:13,285 - INFO - ...computing epoch stats took: 0.32s
2025-08-16 22:53:17,623 - INFO - val: {'epoch': 1, 'time_epoch': 4.29848, 'loss': 1.59061953, 'lr': 0, 'params': 505766, 'time_iter': 0.06823, 'accuracy': 0.36451, 'f1': 0.34506, 'accuracy-SBM': 0.36658, 'auc': 0.75669}
2025-08-16 22:53:17,625 - INFO - ...computing epoch stats took: 0.04s
2025-08-16 22:53:23,764 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 22:53:23,815 - INFO - test: {'epoch': 1, 'time_epoch': 4.6429, 'loss': 1.58773129, 'lr': 0, 'params': 505766, 'time_iter': 0.0737, 'accuracy': 0.36763, 'f1': 0.34851, 'accuracy-SBM': 0.3689, 'auc': 0.75719}
2025-08-16 22:53:23,816 - INFO - ...computing epoch stats took: 0.04s
2025-08-16 22:53:23,817 - INFO - > Epoch 1: took 97.2s (avg 97.2s) | Best so far: epoch 1	train_loss: 1.6313 train_accuracy-SBM: 0.3531	val_loss: 1.5906 val_accuracy-SBM: 0.3666	test_loss: 1.5877 test_accuracy-SBM: 0.3689
2025-08-16 22:53:23,817 - INFO - === Epoch 2 ===
2025-08-16 22:54:49,615 - INFO - train: {'epoch': 2, 'time_epoch': 85.54947, 'eta': 8332.31291, 'eta_hours': 2.31453, 'loss': 1.35059449, 'lr': 0.0004, 'params': 505766, 'time_iter': 0.13688, 'accuracy': 0.51493, 'f1': 0.50352, 'accuracy-SBM': 0.51483, 'auc': 0.81789}
2025-08-16 22:54:49,621 - INFO - ...computing epoch stats took: 0.24s
2025-08-16 22:54:53,960 - INFO - val: {'epoch': 2, 'time_epoch': 4.29925, 'loss': 1.35550447, 'lr': 0, 'params': 505766, 'time_iter': 0.06824, 'accuracy': 0.49621, 'f1': 0.48249, 'accuracy-SBM': 0.49467, 'auc': 0.82628}
2025-08-16 22:54:53,962 - INFO - ...computing epoch stats took: 0.04s
2025-08-16 22:54:59,976 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 22:55:00,029 - INFO - test: {'epoch': 2, 'time_epoch': 4.55042, 'loss': 1.34671711, 'lr': 0, 'params': 505766, 'time_iter': 0.07223, 'accuracy': 0.5004, 'f1': 0.48755, 'accuracy-SBM': 0.49942, 'auc': 0.82892}
2025-08-16 22:55:00,031 - INFO - ...computing epoch stats took: 0.04s
2025-08-16 22:55:00,031 - INFO - > Epoch 2: took 96.2s (avg 96.9s) | Best so far: epoch 2	train_loss: 1.3506 train_accuracy-SBM: 0.5148	val_loss: 1.3555 val_accuracy-SBM: 0.4947	test_loss: 1.3467 test_accuracy-SBM: 0.4994
2025-08-16 22:55:00,032 - INFO - === Epoch 3 ===
2025-08-16 22:56:26,087 - INFO - train: {'epoch': 3, 'time_epoch': 85.79862, 'eta': 8243.97644, 'eta_hours': 2.28999, 'loss': 1.13028106, 'lr': 0.0006, 'params': 505766, 'time_iter': 0.13728, 'accuracy': 0.60047, 'f1': 0.59807, 'accuracy-SBM': 0.60041, 'auc': 0.87427}
2025-08-16 22:56:30,508 - INFO - val: {'epoch': 3, 'time_epoch': 4.35007, 'loss': 1.30036219, 'lr': 0, 'params': 505766, 'time_iter': 0.06905, 'accuracy': 0.52201, 'f1': 0.50854, 'accuracy-SBM': 0.52311, 'auc': 0.86054}
2025-08-16 22:56:36,415 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 22:56:36,463 - INFO - test: {'epoch': 3, 'time_epoch': 4.6226, 'loss': 1.28820358, 'lr': 0, 'params': 505766, 'time_iter': 0.07337, 'accuracy': 0.52788, 'f1': 0.5135, 'accuracy-SBM': 0.52825, 'auc': 0.86363}
2025-08-16 22:56:36,465 - INFO - > Epoch 3: took 96.4s (avg 96.8s) | Best so far: epoch 3	train_loss: 1.1303 train_accuracy-SBM: 0.6004	val_loss: 1.3004 val_accuracy-SBM: 0.5231	test_loss: 1.2882 test_accuracy-SBM: 0.5282
2025-08-16 22:56:36,465 - INFO - === Epoch 4 ===
2025-08-16 22:58:02,251 - INFO - train: {'epoch': 4, 'time_epoch': 85.52056, 'eta': 8151.37193, 'eta_hours': 2.26427, 'loss': 0.9512631, 'lr': 0.0008, 'params': 505766, 'time_iter': 0.13683, 'accuracy': 0.66551, 'f1': 0.66548, 'accuracy-SBM': 0.66551, 'auc': 0.91228}
2025-08-16 22:58:06,648 - INFO - val: {'epoch': 4, 'time_epoch': 4.34419, 'loss': 0.99809603, 'lr': 0, 'params': 505766, 'time_iter': 0.06896, 'accuracy': 0.64694, 'f1': 0.64542, 'accuracy-SBM': 0.6473, 'auc': 0.90674}
2025-08-16 22:58:12,669 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 22:58:12,709 - INFO - test: {'epoch': 4, 'time_epoch': 4.77372, 'loss': 0.98957512, 'lr': 0, 'params': 505766, 'time_iter': 0.07577, 'accuracy': 0.64949, 'f1': 0.64815, 'accuracy-SBM': 0.64961, 'auc': 0.90817}
2025-08-16 22:58:12,710 - INFO - > Epoch 4: took 96.2s (avg 96.7s) | Best so far: epoch 4	train_loss: 0.9513 train_accuracy-SBM: 0.6655	val_loss: 0.9981 val_accuracy-SBM: 0.6473	test_loss: 0.9896 test_accuracy-SBM: 0.6496
2025-08-16 22:58:12,711 - INFO - === Epoch 5 ===
2025-08-16 22:59:40,546 - INFO - train: {'epoch': 5, 'time_epoch': 87.57619, 'eta': 8093.33359, 'eta_hours': 2.24815, 'loss': 0.87398628, 'lr': 0.001, 'params': 505766, 'time_iter': 0.14012, 'accuracy': 0.68745, 'f1': 0.68746, 'accuracy-SBM': 0.68745, 'auc': 0.92502}
2025-08-16 22:59:44,985 - INFO - val: {'epoch': 5, 'time_epoch': 4.3823, 'loss': 0.85868334, 'lr': 0, 'params': 505766, 'time_iter': 0.06956, 'accuracy': 0.69656, 'f1': 0.69665, 'accuracy-SBM': 0.69639, 'auc': 0.93276}
2025-08-16 22:59:50,935 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 22:59:50,976 - INFO - test: {'epoch': 5, 'time_epoch': 4.68202, 'loss': 0.85678113, 'lr': 0, 'params': 505766, 'time_iter': 0.07432, 'accuracy': 0.69549, 'f1': 0.69566, 'accuracy-SBM': 0.69574, 'auc': 0.93339}
2025-08-16 22:59:50,978 - INFO - > Epoch 5: took 98.3s (avg 96.9s) | Best so far: epoch 5	train_loss: 0.8740 train_accuracy-SBM: 0.6875	val_loss: 0.8587 val_accuracy-SBM: 0.6964	test_loss: 0.8568 test_accuracy-SBM: 0.6957
2025-08-16 22:59:50,978 - INFO - === Epoch 6 ===
2025-08-16 23:01:18,885 - INFO - train: {'epoch': 6, 'time_epoch': 87.64689, 'eta': 8027.7952, 'eta_hours': 2.22994, 'loss': 0.8234989, 'lr': 0.00099973, 'params': 505766, 'time_iter': 0.14024, 'accuracy': 0.70409, 'f1': 0.70409, 'accuracy-SBM': 0.70409, 'auc': 0.93296}
2025-08-16 23:01:23,300 - INFO - val: {'epoch': 6, 'time_epoch': 4.3614, 'loss': 0.76762702, 'lr': 0, 'params': 505766, 'time_iter': 0.06923, 'accuracy': 0.7281, 'f1': 0.72785, 'accuracy-SBM': 0.72779, 'auc': 0.94401}
2025-08-16 23:01:29,298 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:01:29,339 - INFO - test: {'epoch': 6, 'time_epoch': 4.64856, 'loss': 0.75971825, 'lr': 0, 'params': 505766, 'time_iter': 0.07379, 'accuracy': 0.72889, 'f1': 0.72881, 'accuracy-SBM': 0.72881, 'auc': 0.94572}
2025-08-16 23:01:29,341 - INFO - > Epoch 6: took 98.4s (avg 97.1s) | Best so far: epoch 6	train_loss: 0.8235 train_accuracy-SBM: 0.7041	val_loss: 0.7676 val_accuracy-SBM: 0.7278	test_loss: 0.7597 test_accuracy-SBM: 0.7288
2025-08-16 23:01:29,341 - INFO - === Epoch 7 ===
2025-08-16 23:02:58,530 - INFO - train: {'epoch': 7, 'time_epoch': 88.93078, 'eta': 7971.4944, 'eta_hours': 2.2143, 'loss': 0.79373852, 'lr': 0.00099891, 'params': 505766, 'time_iter': 0.14229, 'accuracy': 0.71438, 'f1': 0.71438, 'accuracy-SBM': 0.71438, 'auc': 0.93746}
2025-08-16 23:03:02,975 - INFO - val: {'epoch': 7, 'time_epoch': 4.3909, 'loss': 0.75882036, 'lr': 0, 'params': 505766, 'time_iter': 0.0697, 'accuracy': 0.72638, 'f1': 0.72601, 'accuracy-SBM': 0.72622, 'auc': 0.9441}
2025-08-16 23:03:08,650 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:03:08,691 - INFO - test: {'epoch': 7, 'time_epoch': 4.40794, 'loss': 0.74754347, 'lr': 0, 'params': 505766, 'time_iter': 0.06997, 'accuracy': 0.72963, 'f1': 0.72926, 'accuracy-SBM': 0.72941, 'auc': 0.94595}
2025-08-16 23:03:08,693 - INFO - > Epoch 7: took 99.4s (avg 97.4s) | Best so far: epoch 6	train_loss: 0.8235 train_accuracy-SBM: 0.7041	val_loss: 0.7676 val_accuracy-SBM: 0.7278	test_loss: 0.7597 test_accuracy-SBM: 0.7288
2025-08-16 23:03:08,693 - INFO - === Epoch 8 ===
2025-08-16 23:04:36,588 - INFO - train: {'epoch': 8, 'time_epoch': 87.63127, 'eta': 7894.80308, 'eta_hours': 2.193, 'loss': 0.77519768, 'lr': 0.00099754, 'params': 505766, 'time_iter': 0.14021, 'accuracy': 0.72027, 'f1': 0.72027, 'accuracy-SBM': 0.72027, 'auc': 0.94022}
2025-08-16 23:04:41,042 - INFO - val: {'epoch': 8, 'time_epoch': 4.38897, 'loss': 0.7223771, 'lr': 0, 'params': 505766, 'time_iter': 0.06967, 'accuracy': 0.74113, 'f1': 0.74103, 'accuracy-SBM': 0.74092, 'auc': 0.94841}
2025-08-16 23:04:46,992 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:04:47,034 - INFO - test: {'epoch': 8, 'time_epoch': 4.69646, 'loss': 0.71360146, 'lr': 0, 'params': 505766, 'time_iter': 0.07455, 'accuracy': 0.74179, 'f1': 0.74196, 'accuracy-SBM': 0.74185, 'auc': 0.95005}
2025-08-16 23:04:47,036 - INFO - > Epoch 8: took 98.3s (avg 97.5s) | Best so far: epoch 8	train_loss: 0.7752 train_accuracy-SBM: 0.7203	val_loss: 0.7224 val_accuracy-SBM: 0.7409	test_loss: 0.7136 test_accuracy-SBM: 0.7419
2025-08-16 23:04:47,036 - INFO - === Epoch 9 ===
2025-08-16 23:06:14,963 - INFO - train: {'epoch': 9, 'time_epoch': 87.66572, 'eta': 7816.23382, 'eta_hours': 2.17118, 'loss': 0.75966959, 'lr': 0.00099563, 'params': 505766, 'time_iter': 0.14027, 'accuracy': 0.72592, 'f1': 0.72592, 'accuracy-SBM': 0.72592, 'auc': 0.94248}
2025-08-16 23:06:18,963 - INFO - val: {'epoch': 9, 'time_epoch': 3.95661, 'loss': 0.73232125, 'lr': 0, 'params': 505766, 'time_iter': 0.0628, 'accuracy': 0.73824, 'f1': 0.73822, 'accuracy-SBM': 0.73842, 'auc': 0.94829}
2025-08-16 23:06:24,952 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:06:24,993 - INFO - test: {'epoch': 9, 'time_epoch': 4.32222, 'loss': 0.73273826, 'lr': 0, 'params': 505766, 'time_iter': 0.06861, 'accuracy': 0.73513, 'f1': 0.73524, 'accuracy-SBM': 0.73514, 'auc': 0.9483}
2025-08-16 23:06:24,995 - INFO - > Epoch 9: took 98.0s (avg 97.6s) | Best so far: epoch 8	train_loss: 0.7752 train_accuracy-SBM: 0.7203	val_loss: 0.7224 val_accuracy-SBM: 0.7409	test_loss: 0.7136 test_accuracy-SBM: 0.7419
2025-08-16 23:06:24,995 - INFO - === Epoch 10 ===
2025-08-16 23:07:44,350 - INFO - train: {'epoch': 10, 'time_epoch': 79.09282, 'eta': 7666.64804, 'eta_hours': 2.12962, 'loss': 0.74932962, 'lr': 0.00099318, 'params': 505766, 'time_iter': 0.12655, 'accuracy': 0.72834, 'f1': 0.72834, 'accuracy-SBM': 0.72834, 'auc': 0.94403}
2025-08-16 23:07:48,420 - INFO - val: {'epoch': 10, 'time_epoch': 4.02128, 'loss': 0.72757088, 'lr': 0, 'params': 505766, 'time_iter': 0.06383, 'accuracy': 0.73843, 'f1': 0.73814, 'accuracy-SBM': 0.73816, 'auc': 0.94762}
2025-08-16 23:07:54,411 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:07:54,448 - INFO - test: {'epoch': 10, 'time_epoch': 4.1598, 'loss': 0.7158705, 'lr': 0, 'params': 505766, 'time_iter': 0.06603, 'accuracy': 0.74131, 'f1': 0.74122, 'accuracy-SBM': 0.7413, 'auc': 0.94958}
2025-08-16 23:07:54,450 - INFO - > Epoch 10: took 89.5s (avg 96.8s) | Best so far: epoch 8	train_loss: 0.7752 train_accuracy-SBM: 0.7203	val_loss: 0.7224 val_accuracy-SBM: 0.7409	test_loss: 0.7136 test_accuracy-SBM: 0.7419
2025-08-16 23:07:54,451 - INFO - === Epoch 11 ===
2025-08-16 23:09:14,435 - INFO - train: {'epoch': 11, 'time_epoch': 79.75412, 'eta': 7533.66062, 'eta_hours': 2.09268, 'loss': 0.74108752, 'lr': 0.00099019, 'params': 505766, 'time_iter': 0.12761, 'accuracy': 0.73103, 'f1': 0.73103, 'accuracy-SBM': 0.73103, 'auc': 0.94521}
2025-08-16 23:09:18,535 - INFO - val: {'epoch': 11, 'time_epoch': 4.04902, 'loss': 0.71292064, 'lr': 0, 'params': 505766, 'time_iter': 0.06427, 'accuracy': 0.74357, 'f1': 0.74365, 'accuracy-SBM': 0.74363, 'auc': 0.95004}
2025-08-16 23:09:24,560 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:09:24,599 - INFO - test: {'epoch': 11, 'time_epoch': 4.30193, 'loss': 0.70883379, 'lr': 0, 'params': 505766, 'time_iter': 0.06828, 'accuracy': 0.74238, 'f1': 0.7423, 'accuracy-SBM': 0.74249, 'auc': 0.95082}
2025-08-16 23:09:24,601 - INFO - > Epoch 11: took 90.1s (avg 96.3s) | Best so far: epoch 11	train_loss: 0.7411 train_accuracy-SBM: 0.7310	val_loss: 0.7129 val_accuracy-SBM: 0.7436	test_loss: 0.7088 test_accuracy-SBM: 0.7425
2025-08-16 23:09:24,601 - INFO - === Epoch 12 ===
2025-08-16 23:10:49,969 - INFO - train: {'epoch': 12, 'time_epoch': 85.1279, 'eta': 7444.82593, 'eta_hours': 2.06801, 'loss': 0.7313722, 'lr': 0.00098666, 'params': 505766, 'time_iter': 0.1362, 'accuracy': 0.73461, 'f1': 0.73461, 'accuracy-SBM': 0.73461, 'auc': 0.9466}
2025-08-16 23:10:54,284 - INFO - val: {'epoch': 12, 'time_epoch': 4.26214, 'loss': 0.70785056, 'lr': 0, 'params': 505766, 'time_iter': 0.06765, 'accuracy': 0.74422, 'f1': 0.74405, 'accuracy-SBM': 0.74407, 'auc': 0.95074}
2025-08-16 23:11:00,391 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:11:00,431 - INFO - test: {'epoch': 12, 'time_epoch': 4.55798, 'loss': 0.71087647, 'lr': 0, 'params': 505766, 'time_iter': 0.07235, 'accuracy': 0.74144, 'f1': 0.74142, 'accuracy-SBM': 0.74144, 'auc': 0.95031}
2025-08-16 23:11:00,499 - INFO - > Epoch 12: took 95.9s (avg 96.2s) | Best so far: epoch 12	train_loss: 0.7314 train_accuracy-SBM: 0.7346	val_loss: 0.7079 val_accuracy-SBM: 0.7441	test_loss: 0.7109 test_accuracy-SBM: 0.7414
2025-08-16 23:11:00,499 - INFO - === Epoch 13 ===
2025-08-16 23:12:24,583 - INFO - train: {'epoch': 13, 'time_epoch': 83.85662, 'eta': 7348.71154, 'eta_hours': 2.04131, 'loss': 0.72660883, 'lr': 0.0009826, 'params': 505766, 'time_iter': 0.13417, 'accuracy': 0.73637, 'f1': 0.73637, 'accuracy-SBM': 0.73637, 'auc': 0.94727}
2025-08-16 23:12:28,556 - INFO - val: {'epoch': 13, 'time_epoch': 3.9284, 'loss': 0.68018897, 'lr': 0, 'params': 505766, 'time_iter': 0.06236, 'accuracy': 0.75306, 'f1': 0.75302, 'accuracy-SBM': 0.75311, 'auc': 0.95424}
2025-08-16 23:12:34,686 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:12:34,723 - INFO - test: {'epoch': 13, 'time_epoch': 4.16779, 'loss': 0.67307802, 'lr': 0, 'params': 505766, 'time_iter': 0.06616, 'accuracy': 0.75574, 'f1': 0.75563, 'accuracy-SBM': 0.75575, 'auc': 0.95508}
2025-08-16 23:12:34,726 - INFO - > Epoch 13: took 94.2s (avg 96.1s) | Best so far: epoch 13	train_loss: 0.7266 train_accuracy-SBM: 0.7364	val_loss: 0.6802 val_accuracy-SBM: 0.7531	test_loss: 0.6731 test_accuracy-SBM: 0.7558
2025-08-16 23:12:34,726 - INFO - === Epoch 14 ===
2025-08-16 23:13:54,622 - INFO - train: {'epoch': 14, 'time_epoch': 79.6691, 'eta': 7230.50223, 'eta_hours': 2.00847, 'loss': 0.72058046, 'lr': 0.00097802, 'params': 505766, 'time_iter': 0.12747, 'accuracy': 0.739, 'f1': 0.739, 'accuracy-SBM': 0.739, 'auc': 0.94808}
2025-08-16 23:13:58,629 - INFO - val: {'epoch': 14, 'time_epoch': 3.95957, 'loss': 0.68725093, 'lr': 0, 'params': 505766, 'time_iter': 0.06285, 'accuracy': 0.75123, 'f1': 0.75128, 'accuracy-SBM': 0.75117, 'auc': 0.95308}
2025-08-16 23:14:09,674 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:14:09,715 - INFO - test: {'epoch': 14, 'time_epoch': 4.00271, 'loss': 0.67591302, 'lr': 0, 'params': 505766, 'time_iter': 0.06354, 'accuracy': 0.75492, 'f1': 0.75488, 'accuracy-SBM': 0.75493, 'auc': 0.95478}
2025-08-16 23:14:09,720 - INFO - > Epoch 14: took 95.0s (avg 96.0s) | Best so far: epoch 13	train_loss: 0.7266 train_accuracy-SBM: 0.7364	val_loss: 0.6802 val_accuracy-SBM: 0.7531	test_loss: 0.6731 test_accuracy-SBM: 0.7558
2025-08-16 23:14:09,721 - INFO - === Epoch 15 ===
2025-08-16 23:15:32,795 - INFO - train: {'epoch': 15, 'time_epoch': 82.81906, 'eta': 7133.6477, 'eta_hours': 1.98157, 'loss': 0.71386958, 'lr': 0.00097291, 'params': 505766, 'time_iter': 0.13251, 'accuracy': 0.74058, 'f1': 0.74058, 'accuracy-SBM': 0.74058, 'auc': 0.94908}
2025-08-16 23:15:37,124 - INFO - val: {'epoch': 15, 'time_epoch': 4.27672, 'loss': 0.69134805, 'lr': 0, 'params': 505766, 'time_iter': 0.06788, 'accuracy': 0.7503, 'f1': 0.75015, 'accuracy-SBM': 0.75028, 'auc': 0.95257}
2025-08-16 23:15:45,829 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:15:45,877 - INFO - test: {'epoch': 15, 'time_epoch': 4.56749, 'loss': 0.6897961, 'lr': 0, 'params': 505766, 'time_iter': 0.0725, 'accuracy': 0.7498, 'f1': 0.74971, 'accuracy-SBM': 0.74978, 'auc': 0.95289}
2025-08-16 23:15:45,881 - INFO - > Epoch 15: took 96.2s (avg 96.0s) | Best so far: epoch 13	train_loss: 0.7266 train_accuracy-SBM: 0.7364	val_loss: 0.6802 val_accuracy-SBM: 0.7531	test_loss: 0.6731 test_accuracy-SBM: 0.7558
2025-08-16 23:15:45,882 - INFO - === Epoch 16 ===
2025-08-16 23:17:12,509 - INFO - train: {'epoch': 16, 'time_epoch': 86.38028, 'eta': 7055.83154, 'eta_hours': 1.95995, 'loss': 0.70827225, 'lr': 0.00096728, 'params': 505766, 'time_iter': 0.13821, 'accuracy': 0.7428, 'f1': 0.7428, 'accuracy-SBM': 0.74281, 'auc': 0.94985}
2025-08-16 23:17:16,814 - INFO - val: {'epoch': 16, 'time_epoch': 4.25085, 'loss': 0.67437035, 'lr': 0, 'params': 505766, 'time_iter': 0.06747, 'accuracy': 0.75764, 'f1': 0.75757, 'accuracy-SBM': 0.75752, 'auc': 0.95469}
2025-08-16 23:17:27,124 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:17:27,166 - INFO - test: {'epoch': 16, 'time_epoch': 4.50221, 'loss': 0.67089182, 'lr': 0, 'params': 505766, 'time_iter': 0.07146, 'accuracy': 0.75586, 'f1': 0.75582, 'accuracy-SBM': 0.75598, 'auc': 0.95535}
2025-08-16 23:17:27,171 - INFO - > Epoch 16: took 101.3s (avg 96.3s) | Best so far: epoch 16	train_loss: 0.7083 train_accuracy-SBM: 0.7428	val_loss: 0.6744 val_accuracy-SBM: 0.7575	test_loss: 0.6709 test_accuracy-SBM: 0.7560
2025-08-16 23:17:27,171 - INFO - === Epoch 17 ===
2025-08-16 23:18:53,765 - INFO - train: {'epoch': 17, 'time_epoch': 86.35252, 'eta': 6976.93736, 'eta_hours': 1.93804, 'loss': 0.70687223, 'lr': 0.00096114, 'params': 505766, 'time_iter': 0.13816, 'accuracy': 0.74349, 'f1': 0.74349, 'accuracy-SBM': 0.74349, 'auc': 0.95004}
2025-08-16 23:18:57,952 - INFO - val: {'epoch': 17, 'time_epoch': 4.1364, 'loss': 0.67701899, 'lr': 0, 'params': 505766, 'time_iter': 0.06566, 'accuracy': 0.75751, 'f1': 0.75741, 'accuracy-SBM': 0.75748, 'auc': 0.95441}
2025-08-16 23:19:05,775 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:19:05,814 - INFO - test: {'epoch': 17, 'time_epoch': 4.43745, 'loss': 0.6675842, 'lr': 0, 'params': 505766, 'time_iter': 0.07044, 'accuracy': 0.75892, 'f1': 0.75881, 'accuracy-SBM': 0.75885, 'auc': 0.95578}
2025-08-16 23:19:05,818 - INFO - > Epoch 17: took 98.6s (avg 96.5s) | Best so far: epoch 16	train_loss: 0.7083 train_accuracy-SBM: 0.7428	val_loss: 0.6744 val_accuracy-SBM: 0.7575	test_loss: 0.6709 test_accuracy-SBM: 0.7560
2025-08-16 23:19:05,818 - INFO - === Epoch 18 ===
2025-08-16 23:20:33,447 - INFO - train: {'epoch': 18, 'time_epoch': 87.38915, 'eta': 6901.67739, 'eta_hours': 1.91713, 'loss': 0.7009411, 'lr': 0.0009545, 'params': 505766, 'time_iter': 0.13982, 'accuracy': 0.74546, 'f1': 0.74546, 'accuracy-SBM': 0.74546, 'auc': 0.95086}
2025-08-16 23:20:37,760 - INFO - val: {'epoch': 18, 'time_epoch': 4.25698, 'loss': 0.68110835, 'lr': 0, 'params': 505766, 'time_iter': 0.06757, 'accuracy': 0.75432, 'f1': 0.75422, 'accuracy-SBM': 0.75422, 'auc': 0.95378}
2025-08-16 23:20:46,268 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:20:46,320 - INFO - test: {'epoch': 18, 'time_epoch': 4.28046, 'loss': 0.67284575, 'lr': 0, 'params': 505766, 'time_iter': 0.06794, 'accuracy': 0.75519, 'f1': 0.75523, 'accuracy-SBM': 0.75512, 'auc': 0.95498}
2025-08-16 23:20:46,324 - INFO - > Epoch 18: took 100.5s (avg 96.7s) | Best so far: epoch 16	train_loss: 0.7083 train_accuracy-SBM: 0.7428	val_loss: 0.6744 val_accuracy-SBM: 0.7575	test_loss: 0.6709 test_accuracy-SBM: 0.7560
2025-08-16 23:20:46,324 - INFO - === Epoch 19 ===
2025-08-16 23:22:16,726 - INFO - train: {'epoch': 19, 'time_epoch': 90.14824, 'eta': 6836.2409, 'eta_hours': 1.89896, 'loss': 0.69868455, 'lr': 0.00094736, 'params': 505766, 'time_iter': 0.14424, 'accuracy': 0.74576, 'f1': 0.74576, 'accuracy-SBM': 0.74576, 'auc': 0.95118}
2025-08-16 23:22:21,103 - INFO - val: {'epoch': 19, 'time_epoch': 4.31464, 'loss': 0.69864546, 'lr': 0, 'params': 505766, 'time_iter': 0.06849, 'accuracy': 0.74725, 'f1': 0.74739, 'accuracy-SBM': 0.74721, 'auc': 0.95158}
2025-08-16 23:22:30,028 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:22:30,085 - INFO - test: {'epoch': 19, 'time_epoch': 4.62264, 'loss': 0.69153764, 'lr': 0, 'params': 505766, 'time_iter': 0.07338, 'accuracy': 0.74831, 'f1': 0.74847, 'accuracy-SBM': 0.74847, 'auc': 0.95276}
2025-08-16 23:22:30,089 - INFO - > Epoch 19: took 103.8s (avg 97.0s) | Best so far: epoch 16	train_loss: 0.7083 train_accuracy-SBM: 0.7428	val_loss: 0.6744 val_accuracy-SBM: 0.7575	test_loss: 0.6709 test_accuracy-SBM: 0.7560
2025-08-16 23:22:30,090 - INFO - === Epoch 20 ===
2025-08-16 23:24:04,108 - INFO - train: {'epoch': 20, 'time_epoch': 93.75077, 'eta': 6782.00327, 'eta_hours': 1.88389, 'loss': 0.69208125, 'lr': 0.00093974, 'params': 505766, 'time_iter': 0.15, 'accuracy': 0.74924, 'f1': 0.74924, 'accuracy-SBM': 0.74924, 'auc': 0.95206}
2025-08-16 23:24:08,637 - INFO - val: {'epoch': 20, 'time_epoch': 4.47249, 'loss': 0.66795806, 'lr': 0, 'params': 505766, 'time_iter': 0.07099, 'accuracy': 0.75839, 'f1': 0.7583, 'accuracy-SBM': 0.75839, 'auc': 0.95578}
2025-08-16 23:24:18,114 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:24:18,159 - INFO - test: {'epoch': 20, 'time_epoch': 4.77305, 'loss': 0.66868438, 'lr': 0, 'params': 505766, 'time_iter': 0.07576, 'accuracy': 0.7566, 'f1': 0.75664, 'accuracy-SBM': 0.75665, 'auc': 0.95581}
2025-08-16 23:24:18,164 - INFO - > Epoch 20: took 108.1s (avg 97.6s) | Best so far: epoch 20	train_loss: 0.6921 train_accuracy-SBM: 0.7492	val_loss: 0.6680 val_accuracy-SBM: 0.7584	test_loss: 0.6687 test_accuracy-SBM: 0.7567
2025-08-16 23:24:18,164 - INFO - === Epoch 21 ===
2025-08-16 23:25:44,176 - INFO - train: {'epoch': 21, 'time_epoch': 85.65471, 'eta': 6695.46933, 'eta_hours': 1.85985, 'loss': 0.68932933, 'lr': 0.00093163, 'params': 505766, 'time_iter': 0.13705, 'accuracy': 0.74968, 'f1': 0.74967, 'accuracy-SBM': 0.74968, 'auc': 0.95247}
2025-08-16 23:25:48,521 - INFO - val: {'epoch': 21, 'time_epoch': 4.29519, 'loss': 0.70430969, 'lr': 0, 'params': 505766, 'time_iter': 0.06818, 'accuracy': 0.74752, 'f1': 0.74726, 'accuracy-SBM': 0.74735, 'auc': 0.95057}
2025-08-16 23:25:58,609 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:25:58,651 - INFO - test: {'epoch': 21, 'time_epoch': 4.55411, 'loss': 0.6948633, 'lr': 0, 'params': 505766, 'time_iter': 0.07229, 'accuracy': 0.75103, 'f1': 0.7509, 'accuracy-SBM': 0.75094, 'auc': 0.95217}
2025-08-16 23:25:58,655 - INFO - > Epoch 21: took 100.5s (avg 97.7s) | Best so far: epoch 20	train_loss: 0.6921 train_accuracy-SBM: 0.7492	val_loss: 0.6680 val_accuracy-SBM: 0.7584	test_loss: 0.6687 test_accuracy-SBM: 0.7567
2025-08-16 23:25:58,655 - INFO - === Epoch 22 ===
2025-08-16 23:27:25,527 - INFO - train: {'epoch': 22, 'time_epoch': 86.62213, 'eta': 6612.25061, 'eta_hours': 1.83674, 'loss': 0.68499973, 'lr': 0.00092305, 'params': 505766, 'time_iter': 0.1386, 'accuracy': 0.75149, 'f1': 0.75149, 'accuracy-SBM': 0.75149, 'auc': 0.95304}
2025-08-16 23:27:30,025 - INFO - val: {'epoch': 22, 'time_epoch': 4.4394, 'loss': 0.66432416, 'lr': 0, 'params': 505766, 'time_iter': 0.07047, 'accuracy': 0.75856, 'f1': 0.7585, 'accuracy-SBM': 0.75858, 'auc': 0.95604}
2025-08-16 23:27:39,121 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:27:39,165 - INFO - test: {'epoch': 22, 'time_epoch': 4.67811, 'loss': 0.66622981, 'lr': 0, 'params': 505766, 'time_iter': 0.07426, 'accuracy': 0.75684, 'f1': 0.75685, 'accuracy-SBM': 0.75688, 'auc': 0.95582}
2025-08-16 23:27:39,170 - INFO - > Epoch 22: took 100.5s (avg 97.8s) | Best so far: epoch 22	train_loss: 0.6850 train_accuracy-SBM: 0.7515	val_loss: 0.6643 val_accuracy-SBM: 0.7586	test_loss: 0.6662 test_accuracy-SBM: 0.7569
2025-08-16 23:27:39,170 - INFO - === Epoch 23 ===
2025-08-16 23:29:10,398 - INFO - train: {'epoch': 23, 'time_epoch': 90.8651, 'eta': 6542.18433, 'eta_hours': 1.81727, 'loss': 0.68054585, 'lr': 0.000914, 'params': 505766, 'time_iter': 0.14538, 'accuracy': 0.75249, 'f1': 0.75249, 'accuracy-SBM': 0.75249, 'auc': 0.95366}
2025-08-16 23:29:14,901 - INFO - val: {'epoch': 23, 'time_epoch': 4.43644, 'loss': 0.66522905, 'lr': 0, 'params': 505766, 'time_iter': 0.07042, 'accuracy': 0.76127, 'f1': 0.76119, 'accuracy-SBM': 0.76122, 'auc': 0.95588}
2025-08-16 23:29:23,527 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:29:23,568 - INFO - test: {'epoch': 23, 'time_epoch': 4.67037, 'loss': 0.66552644, 'lr': 0, 'params': 505766, 'time_iter': 0.07413, 'accuracy': 0.75948, 'f1': 0.75955, 'accuracy-SBM': 0.75949, 'auc': 0.95593}
2025-08-16 23:29:23,570 - INFO - > Epoch 23: took 104.4s (avg 98.1s) | Best so far: epoch 23	train_loss: 0.6805 train_accuracy-SBM: 0.7525	val_loss: 0.6652 val_accuracy-SBM: 0.7612	test_loss: 0.6655 test_accuracy-SBM: 0.7595
2025-08-16 23:29:23,570 - INFO - === Epoch 24 ===
2025-08-16 23:30:56,754 - INFO - train: {'epoch': 24, 'time_epoch': 92.82707, 'eta': 6476.34005, 'eta_hours': 1.79898, 'loss': 0.67848504, 'lr': 0.00090451, 'params': 505766, 'time_iter': 0.14852, 'accuracy': 0.75339, 'f1': 0.75339, 'accuracy-SBM': 0.75339, 'auc': 0.95395}
2025-08-16 23:31:01,228 - INFO - val: {'epoch': 24, 'time_epoch': 4.41732, 'loss': 0.66652229, 'lr': 0, 'params': 505766, 'time_iter': 0.07012, 'accuracy': 0.76057, 'f1': 0.76068, 'accuracy-SBM': 0.76062, 'auc': 0.95579}
2025-08-16 23:31:09,727 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:31:09,768 - INFO - test: {'epoch': 24, 'time_epoch': 4.73695, 'loss': 0.65763846, 'lr': 0, 'params': 505766, 'time_iter': 0.07519, 'accuracy': 0.76245, 'f1': 0.76245, 'accuracy-SBM': 0.76257, 'auc': 0.95728}
2025-08-16 23:31:09,773 - INFO - > Epoch 24: took 106.2s (avg 98.4s) | Best so far: epoch 23	train_loss: 0.6805 train_accuracy-SBM: 0.7525	val_loss: 0.6652 val_accuracy-SBM: 0.7612	test_loss: 0.6655 test_accuracy-SBM: 0.7595
2025-08-16 23:31:09,774 - INFO - === Epoch 25 ===
2025-08-16 23:32:39,944 - INFO - train: {'epoch': 25, 'time_epoch': 89.91759, 'eta': 6400.13935, 'eta_hours': 1.77782, 'loss': 0.67491278, 'lr': 0.00089457, 'params': 505766, 'time_iter': 0.14387, 'accuracy': 0.75493, 'f1': 0.75493, 'accuracy-SBM': 0.75493, 'auc': 0.9544}
2025-08-16 23:32:44,351 - INFO - val: {'epoch': 25, 'time_epoch': 4.34749, 'loss': 0.66903808, 'lr': 0, 'params': 505766, 'time_iter': 0.06901, 'accuracy': 0.75823, 'f1': 0.75809, 'accuracy-SBM': 0.75805, 'auc': 0.95556}
2025-08-16 23:32:53,947 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:32:53,986 - INFO - test: {'epoch': 25, 'time_epoch': 4.39213, 'loss': 0.66617342, 'lr': 0, 'params': 505766, 'time_iter': 0.06972, 'accuracy': 0.76104, 'f1': 0.76094, 'accuracy-SBM': 0.76089, 'auc': 0.95575}
2025-08-16 23:32:53,990 - INFO - > Epoch 25: took 104.2s (avg 98.6s) | Best so far: epoch 23	train_loss: 0.6805 train_accuracy-SBM: 0.7525	val_loss: 0.6652 val_accuracy-SBM: 0.7612	test_loss: 0.6655 test_accuracy-SBM: 0.7595
2025-08-16 23:32:53,990 - INFO - === Epoch 26 ===
2025-08-16 23:34:23,686 - INFO - train: {'epoch': 26, 'time_epoch': 89.46106, 'eta': 6321.68825, 'eta_hours': 1.75602, 'loss': 0.66832387, 'lr': 0.0008842, 'params': 505766, 'time_iter': 0.14314, 'accuracy': 0.75708, 'f1': 0.75708, 'accuracy-SBM': 0.75708, 'auc': 0.95532}
2025-08-16 23:34:28,101 - INFO - val: {'epoch': 26, 'time_epoch': 4.36924, 'loss': 0.66483482, 'lr': 0, 'params': 505766, 'time_iter': 0.06935, 'accuracy': 0.76204, 'f1': 0.76191, 'accuracy-SBM': 0.76188, 'auc': 0.95608}
2025-08-16 23:34:37,026 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:34:37,073 - INFO - test: {'epoch': 26, 'time_epoch': 4.56551, 'loss': 0.65201682, 'lr': 0, 'params': 505766, 'time_iter': 0.07247, 'accuracy': 0.76329, 'f1': 0.76333, 'accuracy-SBM': 0.76326, 'auc': 0.95778}
2025-08-16 23:34:37,075 - INFO - > Epoch 26: took 103.1s (avg 98.8s) | Best so far: epoch 26	train_loss: 0.6683 train_accuracy-SBM: 0.7571	val_loss: 0.6648 val_accuracy-SBM: 0.7619	test_loss: 0.6520 test_accuracy-SBM: 0.7633
2025-08-16 23:34:37,076 - INFO - === Epoch 27 ===
2025-08-16 23:36:08,301 - INFO - train: {'epoch': 27, 'time_epoch': 90.97197, 'eta': 6246.33592, 'eta_hours': 1.73509, 'loss': 0.66848167, 'lr': 0.00087341, 'params': 505766, 'time_iter': 0.14556, 'accuracy': 0.75677, 'f1': 0.75677, 'accuracy-SBM': 0.75677, 'auc': 0.95529}
2025-08-16 23:36:12,800 - INFO - val: {'epoch': 27, 'time_epoch': 4.44652, 'loss': 0.65721818, 'lr': 0, 'params': 505766, 'time_iter': 0.07058, 'accuracy': 0.76389, 'f1': 0.76377, 'accuracy-SBM': 0.76379, 'auc': 0.95694}
2025-08-16 23:36:22,710 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:36:22,755 - INFO - test: {'epoch': 27, 'time_epoch': 4.70334, 'loss': 0.65189742, 'lr': 0, 'params': 505766, 'time_iter': 0.07466, 'accuracy': 0.76482, 'f1': 0.7649, 'accuracy-SBM': 0.76487, 'auc': 0.95764}
2025-08-16 23:36:22,758 - INFO - > Epoch 27: took 105.7s (avg 99.0s) | Best so far: epoch 27	train_loss: 0.6685 train_accuracy-SBM: 0.7568	val_loss: 0.6572 val_accuracy-SBM: 0.7638	test_loss: 0.6519 test_accuracy-SBM: 0.7649
2025-08-16 23:36:22,758 - INFO - === Epoch 28 ===
2025-08-16 23:37:59,254 - INFO - train: {'epoch': 28, 'time_epoch': 96.21205, 'eta': 6182.73553, 'eta_hours': 1.71743, 'loss': 0.66463626, 'lr': 0.00086221, 'params': 505766, 'time_iter': 0.15394, 'accuracy': 0.7583, 'f1': 0.7583, 'accuracy-SBM': 0.7583, 'auc': 0.9558}
2025-08-16 23:38:03,820 - INFO - val: {'epoch': 28, 'time_epoch': 4.51307, 'loss': 0.64777094, 'lr': 0, 'params': 505766, 'time_iter': 0.07164, 'accuracy': 0.76641, 'f1': 0.76646, 'accuracy-SBM': 0.76646, 'auc': 0.95826}
2025-08-16 23:38:12,796 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:38:12,840 - INFO - test: {'epoch': 28, 'time_epoch': 4.77076, 'loss': 0.65252418, 'lr': 0, 'params': 505766, 'time_iter': 0.07573, 'accuracy': 0.76443, 'f1': 0.7644, 'accuracy-SBM': 0.76454, 'auc': 0.95771}
2025-08-16 23:38:12,845 - INFO - > Epoch 28: took 110.1s (avg 99.4s) | Best so far: epoch 28	train_loss: 0.6646 train_accuracy-SBM: 0.7583	val_loss: 0.6478 val_accuracy-SBM: 0.7665	test_loss: 0.6525 test_accuracy-SBM: 0.7645
2025-08-16 23:38:12,845 - INFO - === Epoch 29 ===
2025-08-16 23:39:47,801 - INFO - train: {'epoch': 29, 'time_epoch': 94.69362, 'eta': 6113.41803, 'eta_hours': 1.69817, 'loss': 0.66391359, 'lr': 0.00085062, 'params': 505766, 'time_iter': 0.15151, 'accuracy': 0.75801, 'f1': 0.75801, 'accuracy-SBM': 0.75801, 'auc': 0.9559}
2025-08-16 23:39:52,240 - INFO - val: {'epoch': 29, 'time_epoch': 4.38585, 'loss': 0.64948602, 'lr': 0, 'params': 505766, 'time_iter': 0.06962, 'accuracy': 0.76529, 'f1': 0.76523, 'accuracy-SBM': 0.76535, 'auc': 0.95794}
2025-08-16 23:40:01,110 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:40:01,153 - INFO - test: {'epoch': 29, 'time_epoch': 4.4753, 'loss': 0.6454928, 'lr': 0, 'params': 505766, 'time_iter': 0.07104, 'accuracy': 0.76713, 'f1': 0.76707, 'accuracy-SBM': 0.76707, 'auc': 0.95845}
2025-08-16 23:40:01,157 - INFO - > Epoch 29: took 108.3s (avg 99.7s) | Best so far: epoch 28	train_loss: 0.6646 train_accuracy-SBM: 0.7583	val_loss: 0.6478 val_accuracy-SBM: 0.7665	test_loss: 0.6525 test_accuracy-SBM: 0.7645
2025-08-16 23:40:01,157 - INFO - === Epoch 30 ===
2025-08-16 23:41:34,457 - INFO - train: {'epoch': 30, 'time_epoch': 93.04617, 'eta': 6038.79646, 'eta_hours': 1.67744, 'loss': 0.66190364, 'lr': 0.00083864, 'params': 505766, 'time_iter': 0.14887, 'accuracy': 0.75909, 'f1': 0.75909, 'accuracy-SBM': 0.75909, 'auc': 0.95616}
2025-08-16 23:41:38,928 - INFO - val: {'epoch': 30, 'time_epoch': 4.41825, 'loss': 0.64805261, 'lr': 0, 'params': 505766, 'time_iter': 0.07013, 'accuracy': 0.76876, 'f1': 0.7686, 'accuracy-SBM': 0.7685, 'auc': 0.9583}
2025-08-16 23:41:49,593 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:41:49,637 - INFO - test: {'epoch': 30, 'time_epoch': 4.80673, 'loss': 0.65197287, 'lr': 0, 'params': 505766, 'time_iter': 0.0763, 'accuracy': 0.76452, 'f1': 0.76452, 'accuracy-SBM': 0.76452, 'auc': 0.95786}
2025-08-16 23:41:49,642 - INFO - > Epoch 30: took 108.5s (avg 100.0s) | Best so far: epoch 30	train_loss: 0.6619 train_accuracy-SBM: 0.7591	val_loss: 0.6481 val_accuracy-SBM: 0.7685	test_loss: 0.6520 test_accuracy-SBM: 0.7645
2025-08-16 23:41:49,642 - INFO - === Epoch 31 ===
2025-08-16 23:43:23,269 - INFO - train: {'epoch': 31, 'time_epoch': 93.36229, 'eta': 5963.69511, 'eta_hours': 1.65658, 'loss': 0.65884894, 'lr': 0.00082629, 'params': 505766, 'time_iter': 0.14938, 'accuracy': 0.76065, 'f1': 0.76065, 'accuracy-SBM': 0.76065, 'auc': 0.95656}
2025-08-16 23:43:27,816 - INFO - val: {'epoch': 31, 'time_epoch': 4.4915, 'loss': 0.65870706, 'lr': 0, 'params': 505766, 'time_iter': 0.07129, 'accuracy': 0.76384, 'f1': 0.76378, 'accuracy-SBM': 0.76386, 'auc': 0.95675}
2025-08-16 23:43:37,542 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:43:37,584 - INFO - test: {'epoch': 31, 'time_epoch': 4.78549, 'loss': 0.6503605, 'lr': 0, 'params': 505766, 'time_iter': 0.07596, 'accuracy': 0.76523, 'f1': 0.76528, 'accuracy-SBM': 0.7653, 'auc': 0.95798}
2025-08-16 23:43:37,587 - INFO - > Epoch 31: took 107.9s (avg 100.3s) | Best so far: epoch 30	train_loss: 0.6619 train_accuracy-SBM: 0.7591	val_loss: 0.6481 val_accuracy-SBM: 0.7685	test_loss: 0.6520 test_accuracy-SBM: 0.7645
2025-08-16 23:43:37,588 - INFO - === Epoch 32 ===
2025-08-16 23:45:06,099 - INFO - train: {'epoch': 32, 'time_epoch': 88.17173, 'eta': 5876.94863, 'eta_hours': 1.63249, 'loss': 0.6563899, 'lr': 0.00081359, 'params': 505766, 'time_iter': 0.14107, 'accuracy': 0.76121, 'f1': 0.76121, 'accuracy-SBM': 0.76121, 'auc': 0.9569}
2025-08-16 23:45:10,280 - INFO - val: {'epoch': 32, 'time_epoch': 4.1314, 'loss': 0.65928177, 'lr': 0, 'params': 505766, 'time_iter': 0.06558, 'accuracy': 0.76445, 'f1': 0.76436, 'accuracy-SBM': 0.76423, 'auc': 0.95668}
2025-08-16 23:45:19,179 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:45:19,219 - INFO - test: {'epoch': 32, 'time_epoch': 4.43642, 'loss': 0.64869203, 'lr': 0, 'params': 505766, 'time_iter': 0.07042, 'accuracy': 0.76392, 'f1': 0.76398, 'accuracy-SBM': 0.76398, 'auc': 0.9582}
2025-08-16 23:45:19,223 - INFO - > Epoch 32: took 101.6s (avg 100.3s) | Best so far: epoch 30	train_loss: 0.6619 train_accuracy-SBM: 0.7591	val_loss: 0.6481 val_accuracy-SBM: 0.7685	test_loss: 0.6520 test_accuracy-SBM: 0.7645
2025-08-16 23:45:19,223 - INFO - === Epoch 33 ===
2025-08-16 23:46:39,557 - INFO - train: {'epoch': 33, 'time_epoch': 80.1089, 'eta': 5774.46693, 'eta_hours': 1.60402, 'loss': 0.65305812, 'lr': 0.00080054, 'params': 505766, 'time_iter': 0.12817, 'accuracy': 0.76267, 'f1': 0.76267, 'accuracy-SBM': 0.76267, 'auc': 0.95731}
2025-08-16 23:46:43,540 - INFO - val: {'epoch': 33, 'time_epoch': 3.93959, 'loss': 0.65578873, 'lr': 0, 'params': 505766, 'time_iter': 0.06253, 'accuracy': 0.76477, 'f1': 0.76481, 'accuracy-SBM': 0.76478, 'auc': 0.95736}
2025-08-16 23:46:52,051 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:46:52,089 - INFO - test: {'epoch': 33, 'time_epoch': 4.17953, 'loss': 0.65202548, 'lr': 0, 'params': 505766, 'time_iter': 0.06634, 'accuracy': 0.76573, 'f1': 0.76572, 'accuracy-SBM': 0.76577, 'auc': 0.95774}
2025-08-16 23:46:52,095 - INFO - > Epoch 33: took 92.9s (avg 100.1s) | Best so far: epoch 30	train_loss: 0.6619 train_accuracy-SBM: 0.7591	val_loss: 0.6481 val_accuracy-SBM: 0.7685	test_loss: 0.6520 test_accuracy-SBM: 0.7645
2025-08-16 23:46:52,095 - INFO - === Epoch 34 ===
2025-08-16 23:48:12,372 - INFO - train: {'epoch': 34, 'time_epoch': 80.05337, 'eta': 5673.16055, 'eta_hours': 1.57588, 'loss': 0.65018776, 'lr': 0.00078716, 'params': 505766, 'time_iter': 0.12809, 'accuracy': 0.76346, 'f1': 0.76346, 'accuracy-SBM': 0.76346, 'auc': 0.95771}
2025-08-16 23:48:16,380 - INFO - val: {'epoch': 34, 'time_epoch': 3.95343, 'loss': 0.63960477, 'lr': 0, 'params': 505766, 'time_iter': 0.06275, 'accuracy': 0.77001, 'f1': 0.76988, 'accuracy-SBM': 0.76993, 'auc': 0.95936}
2025-08-16 23:48:25,033 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:48:25,070 - INFO - test: {'epoch': 34, 'time_epoch': 4.19939, 'loss': 0.64309318, 'lr': 0, 'params': 505766, 'time_iter': 0.06666, 'accuracy': 0.76759, 'f1': 0.7675, 'accuracy-SBM': 0.76752, 'auc': 0.95879}
2025-08-16 23:48:25,075 - INFO - > Epoch 34: took 93.0s (avg 99.9s) | Best so far: epoch 34	train_loss: 0.6502 train_accuracy-SBM: 0.7635	val_loss: 0.6396 val_accuracy-SBM: 0.7699	test_loss: 0.6431 test_accuracy-SBM: 0.7675
2025-08-16 23:48:25,075 - INFO - === Epoch 35 ===
2025-08-16 23:49:45,223 - INFO - train: {'epoch': 35, 'time_epoch': 79.92386, 'eta': 5572.80464, 'eta_hours': 1.548, 'loss': 0.6502359, 'lr': 0.00077347, 'params': 505766, 'time_iter': 0.12788, 'accuracy': 0.76394, 'f1': 0.76394, 'accuracy-SBM': 0.76394, 'auc': 0.95767}
2025-08-16 23:49:49,248 - INFO - val: {'epoch': 35, 'time_epoch': 3.97564, 'loss': 0.64410178, 'lr': 0, 'params': 505766, 'time_iter': 0.06311, 'accuracy': 0.76819, 'f1': 0.76817, 'accuracy-SBM': 0.76821, 'auc': 0.95865}
2025-08-16 23:50:00,256 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:50:00,302 - INFO - test: {'epoch': 35, 'time_epoch': 4.25641, 'loss': 0.64207186, 'lr': 0, 'params': 505766, 'time_iter': 0.06756, 'accuracy': 0.76881, 'f1': 0.7688, 'accuracy-SBM': 0.76879, 'auc': 0.95881}
2025-08-16 23:50:00,306 - INFO - > Epoch 35: took 95.2s (avg 99.7s) | Best so far: epoch 34	train_loss: 0.6502 train_accuracy-SBM: 0.7635	val_loss: 0.6396 val_accuracy-SBM: 0.7699	test_loss: 0.6431 test_accuracy-SBM: 0.7675
2025-08-16 23:50:00,306 - INFO - === Epoch 36 ===
2025-08-16 23:51:21,294 - INFO - train: {'epoch': 36, 'time_epoch': 80.76246, 'eta': 5474.98107, 'eta_hours': 1.52083, 'loss': 0.64448898, 'lr': 0.00075948, 'params': 505766, 'time_iter': 0.12922, 'accuracy': 0.76548, 'f1': 0.76548, 'accuracy-SBM': 0.76548, 'auc': 0.95844}
2025-08-16 23:51:25,409 - INFO - val: {'epoch': 36, 'time_epoch': 4.05877, 'loss': 0.64496261, 'lr': 0, 'params': 505766, 'time_iter': 0.06442, 'accuracy': 0.7672, 'f1': 0.76707, 'accuracy-SBM': 0.76706, 'auc': 0.95873}
2025-08-16 23:51:34,316 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:51:34,364 - INFO - test: {'epoch': 36, 'time_epoch': 4.32651, 'loss': 0.64496669, 'lr': 0, 'params': 505766, 'time_iter': 0.06867, 'accuracy': 0.76653, 'f1': 0.76654, 'accuracy-SBM': 0.76639, 'auc': 0.95874}
2025-08-16 23:51:34,369 - INFO - > Epoch 36: took 94.1s (avg 99.6s) | Best so far: epoch 34	train_loss: 0.6502 train_accuracy-SBM: 0.7635	val_loss: 0.6396 val_accuracy-SBM: 0.7699	test_loss: 0.6431 test_accuracy-SBM: 0.7675
2025-08-16 23:51:34,369 - INFO - === Epoch 37 ===
2025-08-16 23:52:56,623 - INFO - train: {'epoch': 37, 'time_epoch': 82.00935, 'eta': 5380.08985, 'eta_hours': 1.49447, 'loss': 0.64126108, 'lr': 0.00074521, 'params': 505766, 'time_iter': 0.13121, 'accuracy': 0.767, 'f1': 0.767, 'accuracy-SBM': 0.767, 'auc': 0.95885}
2025-08-16 23:53:00,661 - INFO - val: {'epoch': 37, 'time_epoch': 3.99168, 'loss': 0.65281987, 'lr': 0, 'params': 505766, 'time_iter': 0.06336, 'accuracy': 0.76678, 'f1': 0.7667, 'accuracy-SBM': 0.76668, 'auc': 0.95746}
2025-08-16 23:53:09,145 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:53:09,184 - INFO - test: {'epoch': 37, 'time_epoch': 4.3002, 'loss': 0.64784313, 'lr': 0, 'params': 505766, 'time_iter': 0.06826, 'accuracy': 0.76623, 'f1': 0.76618, 'accuracy-SBM': 0.76626, 'auc': 0.9581}
2025-08-16 23:53:09,189 - INFO - > Epoch 37: took 94.8s (avg 99.5s) | Best so far: epoch 34	train_loss: 0.6502 train_accuracy-SBM: 0.7635	val_loss: 0.6396 val_accuracy-SBM: 0.7699	test_loss: 0.6431 test_accuracy-SBM: 0.7675
2025-08-16 23:53:09,190 - INFO - === Epoch 38 ===
2025-08-16 23:54:30,504 - INFO - train: {'epoch': 38, 'time_epoch': 81.08735, 'eta': 5284.41713, 'eta_hours': 1.46789, 'loss': 0.63855232, 'lr': 0.00073067, 'params': 505766, 'time_iter': 0.12974, 'accuracy': 0.76792, 'f1': 0.76792, 'accuracy-SBM': 0.76792, 'auc': 0.95919}
2025-08-16 23:54:34,588 - INFO - val: {'epoch': 38, 'time_epoch': 4.03508, 'loss': 0.64855487, 'lr': 0, 'params': 505766, 'time_iter': 0.06405, 'accuracy': 0.76691, 'f1': 0.76669, 'accuracy-SBM': 0.76678, 'auc': 0.95798}
2025-08-16 23:54:44,298 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:54:44,336 - INFO - test: {'epoch': 38, 'time_epoch': 4.29719, 'loss': 0.63869244, 'lr': 0, 'params': 505766, 'time_iter': 0.06821, 'accuracy': 0.76921, 'f1': 0.7692, 'accuracy-SBM': 0.76921, 'auc': 0.95931}
2025-08-16 23:54:44,340 - INFO - > Epoch 38: took 95.2s (avg 99.4s) | Best so far: epoch 34	train_loss: 0.6502 train_accuracy-SBM: 0.7635	val_loss: 0.6396 val_accuracy-SBM: 0.7699	test_loss: 0.6431 test_accuracy-SBM: 0.7675
2025-08-16 23:54:44,340 - INFO - === Epoch 39 ===
2025-08-16 23:56:06,704 - INFO - train: {'epoch': 39, 'time_epoch': 82.03714, 'eta': 5190.89837, 'eta_hours': 1.44192, 'loss': 0.63634184, 'lr': 0.00071588, 'params': 505766, 'time_iter': 0.13126, 'accuracy': 0.76874, 'f1': 0.76874, 'accuracy-SBM': 0.76874, 'auc': 0.95947}
2025-08-16 23:56:10,714 - INFO - val: {'epoch': 39, 'time_epoch': 3.95855, 'loss': 0.64073804, 'lr': 0, 'params': 505766, 'time_iter': 0.06283, 'accuracy': 0.76987, 'f1': 0.76978, 'accuracy-SBM': 0.76987, 'auc': 0.95894}
2025-08-16 23:56:19,035 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:56:19,071 - INFO - test: {'epoch': 39, 'time_epoch': 4.21662, 'loss': 0.6433483, 'lr': 0, 'params': 505766, 'time_iter': 0.06693, 'accuracy': 0.76917, 'f1': 0.76912, 'accuracy-SBM': 0.76912, 'auc': 0.95865}
2025-08-16 23:56:19,075 - INFO - > Epoch 39: took 94.7s (avg 99.2s) | Best so far: epoch 34	train_loss: 0.6502 train_accuracy-SBM: 0.7635	val_loss: 0.6396 val_accuracy-SBM: 0.7699	test_loss: 0.6431 test_accuracy-SBM: 0.7675
2025-08-16 23:56:19,075 - INFO - === Epoch 40 ===
2025-08-16 23:57:42,408 - INFO - train: {'epoch': 40, 'time_epoch': 83.01395, 'eta': 5099.34534, 'eta_hours': 1.41648, 'loss': 0.63460749, 'lr': 0.00070085, 'params': 505766, 'time_iter': 0.13282, 'accuracy': 0.76947, 'f1': 0.76947, 'accuracy-SBM': 0.76947, 'auc': 0.9597}
2025-08-16 23:57:46,531 - INFO - val: {'epoch': 40, 'time_epoch': 4.06951, 'loss': 0.64077996, 'lr': 0, 'params': 505766, 'time_iter': 0.0646, 'accuracy': 0.76937, 'f1': 0.76925, 'accuracy-SBM': 0.76924, 'auc': 0.95924}
2025-08-16 23:57:55,281 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:57:55,320 - INFO - test: {'epoch': 40, 'time_epoch': 4.41195, 'loss': 0.64334031, 'lr': 0, 'params': 505766, 'time_iter': 0.07003, 'accuracy': 0.7692, 'f1': 0.76915, 'accuracy-SBM': 0.76925, 'auc': 0.95899}
2025-08-16 23:57:55,324 - INFO - > Epoch 40: took 96.2s (avg 99.2s) | Best so far: epoch 34	train_loss: 0.6502 train_accuracy-SBM: 0.7635	val_loss: 0.6396 val_accuracy-SBM: 0.7699	test_loss: 0.6431 test_accuracy-SBM: 0.7675
2025-08-16 23:57:55,325 - INFO - === Epoch 41 ===
2025-08-16 23:59:19,058 - INFO - train: {'epoch': 41, 'time_epoch': 83.50167, 'eta': 5008.87246, 'eta_hours': 1.39135, 'loss': 0.62824136, 'lr': 0.0006856, 'params': 505766, 'time_iter': 0.1336, 'accuracy': 0.77162, 'f1': 0.77162, 'accuracy-SBM': 0.77162, 'auc': 0.96049}
2025-08-16 23:59:23,272 - INFO - val: {'epoch': 41, 'time_epoch': 4.16328, 'loss': 0.63688524, 'lr': 0, 'params': 505766, 'time_iter': 0.06608, 'accuracy': 0.77167, 'f1': 0.77158, 'accuracy-SBM': 0.7716, 'auc': 0.95974}
2025-08-16 23:59:31,873 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-16 23:59:31,912 - INFO - test: {'epoch': 41, 'time_epoch': 4.38655, 'loss': 0.63063893, 'lr': 0, 'params': 505766, 'time_iter': 0.06963, 'accuracy': 0.77186, 'f1': 0.77177, 'accuracy-SBM': 0.77181, 'auc': 0.9604}
2025-08-16 23:59:31,917 - INFO - > Epoch 41: took 96.6s (avg 99.1s) | Best so far: epoch 41	train_loss: 0.6282 train_accuracy-SBM: 0.7716	val_loss: 0.6369 val_accuracy-SBM: 0.7716	test_loss: 0.6306 test_accuracy-SBM: 0.7718
2025-08-16 23:59:31,917 - INFO - === Epoch 42 ===
2025-08-17 00:00:54,968 - INFO - train: {'epoch': 42, 'time_epoch': 82.82221, 'eta': 4917.82313, 'eta_hours': 1.36606, 'loss': 0.62886112, 'lr': 0.00067015, 'params': 505766, 'time_iter': 0.13252, 'accuracy': 0.77091, 'f1': 0.77091, 'accuracy-SBM': 0.77091, 'auc': 0.96043}
2025-08-17 00:00:59,105 - INFO - val: {'epoch': 42, 'time_epoch': 4.08745, 'loss': 0.63465809, 'lr': 0, 'params': 505766, 'time_iter': 0.06488, 'accuracy': 0.77286, 'f1': 0.77282, 'accuracy-SBM': 0.77281, 'auc': 0.95989}
2025-08-17 00:01:08,996 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:01:09,033 - INFO - test: {'epoch': 42, 'time_epoch': 4.30299, 'loss': 0.63914027, 'lr': 0, 'params': 505766, 'time_iter': 0.0683, 'accuracy': 0.77083, 'f1': 0.77089, 'accuracy-SBM': 0.77095, 'auc': 0.95931}
2025-08-17 00:01:09,039 - INFO - > Epoch 42: took 97.1s (avg 99.1s) | Best so far: epoch 42	train_loss: 0.6289 train_accuracy-SBM: 0.7709	val_loss: 0.6347 val_accuracy-SBM: 0.7728	test_loss: 0.6391 test_accuracy-SBM: 0.7710
2025-08-17 00:01:09,039 - INFO - === Epoch 43 ===
2025-08-17 00:02:32,060 - INFO - train: {'epoch': 43, 'time_epoch': 82.78099, 'eta': 4827.09529, 'eta_hours': 1.34086, 'loss': 0.62494342, 'lr': 0.00065451, 'params': 505766, 'time_iter': 0.13245, 'accuracy': 0.77268, 'f1': 0.77268, 'accuracy-SBM': 0.77268, 'auc': 0.96091}
2025-08-17 00:02:36,338 - INFO - val: {'epoch': 43, 'time_epoch': 4.23198, 'loss': 0.64733983, 'lr': 0, 'params': 505766, 'time_iter': 0.06717, 'accuracy': 0.76894, 'f1': 0.76863, 'accuracy-SBM': 0.76865, 'auc': 0.95858}
2025-08-17 00:02:42,978 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:02:43,023 - INFO - test: {'epoch': 43, 'time_epoch': 4.43146, 'loss': 0.65006939, 'lr': 0, 'params': 505766, 'time_iter': 0.07034, 'accuracy': 0.76701, 'f1': 0.76691, 'accuracy-SBM': 0.76697, 'auc': 0.95823}
2025-08-17 00:02:43,026 - INFO - > Epoch 43: took 94.0s (avg 98.9s) | Best so far: epoch 42	train_loss: 0.6289 train_accuracy-SBM: 0.7709	val_loss: 0.6347 val_accuracy-SBM: 0.7728	test_loss: 0.6391 test_accuracy-SBM: 0.7710
2025-08-17 00:02:43,026 - INFO - === Epoch 44 ===
2025-08-17 00:04:06,306 - INFO - train: {'epoch': 44, 'time_epoch': 83.04625, 'eta': 4737.04486, 'eta_hours': 1.31585, 'loss': 0.62472178, 'lr': 0.0006387, 'params': 505766, 'time_iter': 0.13287, 'accuracy': 0.77305, 'f1': 0.77305, 'accuracy-SBM': 0.77305, 'auc': 0.96094}
2025-08-17 00:04:10,622 - INFO - val: {'epoch': 44, 'time_epoch': 4.26901, 'loss': 0.63225047, 'lr': 0, 'params': 505766, 'time_iter': 0.06776, 'accuracy': 0.7732, 'f1': 0.77307, 'accuracy-SBM': 0.77307, 'auc': 0.96017}
2025-08-17 00:04:20,264 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:04:20,303 - INFO - test: {'epoch': 44, 'time_epoch': 4.24016, 'loss': 0.6277441, 'lr': 0, 'params': 505766, 'time_iter': 0.0673, 'accuracy': 0.77477, 'f1': 0.7748, 'accuracy-SBM': 0.7747, 'auc': 0.96072}
2025-08-17 00:04:20,305 - INFO - > Epoch 44: took 97.3s (avg 98.9s) | Best so far: epoch 44	train_loss: 0.6247 train_accuracy-SBM: 0.7731	val_loss: 0.6323 val_accuracy-SBM: 0.7731	test_loss: 0.6277 test_accuracy-SBM: 0.7747
2025-08-17 00:04:20,305 - INFO - === Epoch 45 ===
2025-08-17 00:05:44,461 - INFO - train: {'epoch': 45, 'time_epoch': 83.9206, 'eta': 4648.32537, 'eta_hours': 1.2912, 'loss': 0.62083922, 'lr': 0.00062274, 'params': 505766, 'time_iter': 0.13427, 'accuracy': 0.77372, 'f1': 0.77372, 'accuracy-SBM': 0.77372, 'auc': 0.96145}
2025-08-17 00:05:48,582 - INFO - val: {'epoch': 45, 'time_epoch': 4.06966, 'loss': 0.63530332, 'lr': 0, 'params': 505766, 'time_iter': 0.0646, 'accuracy': 0.77135, 'f1': 0.77126, 'accuracy-SBM': 0.77126, 'auc': 0.95973}
2025-08-17 00:05:57,489 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:05:57,551 - INFO - test: {'epoch': 45, 'time_epoch': 4.34067, 'loss': 0.62602848, 'lr': 0, 'params': 505766, 'time_iter': 0.0689, 'accuracy': 0.77269, 'f1': 0.77263, 'accuracy-SBM': 0.77263, 'auc': 0.96096}
2025-08-17 00:05:57,556 - INFO - > Epoch 45: took 97.3s (avg 98.9s) | Best so far: epoch 44	train_loss: 0.6247 train_accuracy-SBM: 0.7731	val_loss: 0.6323 val_accuracy-SBM: 0.7731	test_loss: 0.6277 test_accuracy-SBM: 0.7747
2025-08-17 00:05:57,556 - INFO - === Epoch 46 ===
2025-08-17 00:07:25,974 - INFO - train: {'epoch': 46, 'time_epoch': 88.17804, 'eta': 4564.61103, 'eta_hours': 1.26795, 'loss': 0.61778502, 'lr': 0.00060665, 'params': 505766, 'time_iter': 0.14108, 'accuracy': 0.77547, 'f1': 0.77547, 'accuracy-SBM': 0.77547, 'auc': 0.96181}
2025-08-17 00:07:30,132 - INFO - val: {'epoch': 46, 'time_epoch': 4.11354, 'loss': 0.6264173, 'lr': 0, 'params': 505766, 'time_iter': 0.06529, 'accuracy': 0.77387, 'f1': 0.77384, 'accuracy-SBM': 0.77388, 'auc': 0.9608}
2025-08-17 00:07:37,918 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:07:37,957 - INFO - test: {'epoch': 46, 'time_epoch': 4.34077, 'loss': 0.6270843, 'lr': 0, 'params': 505766, 'time_iter': 0.0689, 'accuracy': 0.77362, 'f1': 0.77358, 'accuracy-SBM': 0.77361, 'auc': 0.96077}
2025-08-17 00:07:37,959 - INFO - > Epoch 46: took 100.4s (avg 98.9s) | Best so far: epoch 46	train_loss: 0.6178 train_accuracy-SBM: 0.7755	val_loss: 0.6264 val_accuracy-SBM: 0.7739	test_loss: 0.6271 test_accuracy-SBM: 0.7736
2025-08-17 00:07:37,959 - INFO - === Epoch 47 ===
2025-08-17 00:09:01,971 - INFO - train: {'epoch': 47, 'time_epoch': 83.6869, 'eta': 4475.84531, 'eta_hours': 1.24329, 'loss': 0.61374995, 'lr': 0.00059044, 'params': 505766, 'time_iter': 0.1339, 'accuracy': 0.7764, 'f1': 0.7764, 'accuracy-SBM': 0.7764, 'auc': 0.96231}
2025-08-17 00:09:06,018 - INFO - val: {'epoch': 47, 'time_epoch': 4.00369, 'loss': 0.6272886, 'lr': 0, 'params': 505766, 'time_iter': 0.06355, 'accuracy': 0.77476, 'f1': 0.77462, 'accuracy-SBM': 0.77459, 'auc': 0.96062}
2025-08-17 00:09:13,896 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:09:13,936 - INFO - test: {'epoch': 47, 'time_epoch': 4.25888, 'loss': 0.62544681, 'lr': 0, 'params': 505766, 'time_iter': 0.0676, 'accuracy': 0.77588, 'f1': 0.77588, 'accuracy-SBM': 0.77589, 'auc': 0.96092}
2025-08-17 00:09:13,940 - INFO - > Epoch 47: took 96.0s (avg 98.8s) | Best so far: epoch 47	train_loss: 0.6137 train_accuracy-SBM: 0.7764	val_loss: 0.6273 val_accuracy-SBM: 0.7746	test_loss: 0.6254 test_accuracy-SBM: 0.7759
2025-08-17 00:09:13,940 - INFO - === Epoch 48 ===
2025-08-17 00:10:39,297 - INFO - train: {'epoch': 48, 'time_epoch': 85.03309, 'eta': 4388.68802, 'eta_hours': 1.21908, 'loss': 0.61089082, 'lr': 0.00057413, 'params': 505766, 'time_iter': 0.13605, 'accuracy': 0.7776, 'f1': 0.7776, 'accuracy-SBM': 0.7776, 'auc': 0.96266}
2025-08-17 00:10:43,422 - INFO - val: {'epoch': 48, 'time_epoch': 4.07692, 'loss': 0.63270164, 'lr': 0, 'params': 505766, 'time_iter': 0.06471, 'accuracy': 0.77256, 'f1': 0.77255, 'accuracy-SBM': 0.77253, 'auc': 0.96004}
2025-08-17 00:10:49,451 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:10:49,487 - INFO - test: {'epoch': 48, 'time_epoch': 4.0734, 'loss': 0.63049337, 'lr': 0, 'params': 505766, 'time_iter': 0.06466, 'accuracy': 0.77335, 'f1': 0.77333, 'accuracy-SBM': 0.77338, 'auc': 0.96033}
2025-08-17 00:10:49,490 - INFO - > Epoch 48: took 95.5s (avg 98.8s) | Best so far: epoch 47	train_loss: 0.6137 train_accuracy-SBM: 0.7764	val_loss: 0.6273 val_accuracy-SBM: 0.7746	test_loss: 0.6254 test_accuracy-SBM: 0.7759
2025-08-17 00:10:49,490 - INFO - === Epoch 49 ===
2025-08-17 00:12:14,667 - INFO - train: {'epoch': 49, 'time_epoch': 84.84297, 'eta': 4301.42557, 'eta_hours': 1.19484, 'loss': 0.60742817, 'lr': 0.00055774, 'params': 505766, 'time_iter': 0.13575, 'accuracy': 0.77909, 'f1': 0.77909, 'accuracy-SBM': 0.77909, 'auc': 0.96308}
2025-08-17 00:12:18,899 - INFO - val: {'epoch': 49, 'time_epoch': 4.18496, 'loss': 0.63435277, 'lr': 0, 'params': 505766, 'time_iter': 0.06643, 'accuracy': 0.77287, 'f1': 0.77277, 'accuracy-SBM': 0.77283, 'auc': 0.95995}
2025-08-17 00:12:28,124 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:12:28,162 - INFO - test: {'epoch': 49, 'time_epoch': 4.4303, 'loss': 0.63022348, 'lr': 0, 'params': 505766, 'time_iter': 0.07032, 'accuracy': 0.7746, 'f1': 0.77459, 'accuracy-SBM': 0.77459, 'auc': 0.96038}
2025-08-17 00:12:28,167 - INFO - > Epoch 49: took 98.7s (avg 98.8s) | Best so far: epoch 47	train_loss: 0.6137 train_accuracy-SBM: 0.7764	val_loss: 0.6273 val_accuracy-SBM: 0.7746	test_loss: 0.6254 test_accuracy-SBM: 0.7759
2025-08-17 00:12:28,167 - INFO - === Epoch 50 ===
2025-08-17 00:13:56,122 - INFO - train: {'epoch': 50, 'time_epoch': 87.61839, 'eta': 4216.92459, 'eta_hours': 1.17137, 'loss': 0.60565543, 'lr': 0.00054129, 'params': 505766, 'time_iter': 0.14019, 'accuracy': 0.77933, 'f1': 0.77933, 'accuracy-SBM': 0.77934, 'auc': 0.96331}
2025-08-17 00:14:00,384 - INFO - val: {'epoch': 50, 'time_epoch': 4.20162, 'loss': 0.6291974, 'lr': 0, 'params': 505766, 'time_iter': 0.06669, 'accuracy': 0.7757, 'f1': 0.77554, 'accuracy-SBM': 0.77556, 'auc': 0.96057}
2025-08-17 00:14:09,045 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:14:09,083 - INFO - test: {'epoch': 50, 'time_epoch': 4.56727, 'loss': 0.62229072, 'lr': 0, 'params': 505766, 'time_iter': 0.0725, 'accuracy': 0.77791, 'f1': 0.7779, 'accuracy-SBM': 0.77789, 'auc': 0.96132}
2025-08-17 00:14:09,091 - INFO - > Epoch 50: took 100.9s (avg 98.8s) | Best so far: epoch 50	train_loss: 0.6057 train_accuracy-SBM: 0.7793	val_loss: 0.6292 val_accuracy-SBM: 0.7756	test_loss: 0.6223 test_accuracy-SBM: 0.7779
2025-08-17 00:14:09,091 - INFO - === Epoch 51 ===
2025-08-17 00:15:35,266 - INFO - train: {'epoch': 51, 'time_epoch': 85.84589, 'eta': 4130.66756, 'eta_hours': 1.14741, 'loss': 0.60395419, 'lr': 0.00052479, 'params': 505766, 'time_iter': 0.13735, 'accuracy': 0.78027, 'f1': 0.78027, 'accuracy-SBM': 0.78027, 'auc': 0.9635}
2025-08-17 00:15:39,384 - INFO - val: {'epoch': 51, 'time_epoch': 4.06488, 'loss': 0.63629922, 'lr': 0, 'params': 505766, 'time_iter': 0.06452, 'accuracy': 0.77436, 'f1': 0.77425, 'accuracy-SBM': 0.77424, 'auc': 0.95957}
2025-08-17 00:15:45,570 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:15:45,608 - INFO - test: {'epoch': 51, 'time_epoch': 4.40276, 'loss': 0.63242181, 'lr': 0, 'params': 505766, 'time_iter': 0.06989, 'accuracy': 0.77395, 'f1': 0.77384, 'accuracy-SBM': 0.77386, 'auc': 0.96002}
2025-08-17 00:15:45,610 - INFO - > Epoch 51: took 96.5s (avg 98.8s) | Best so far: epoch 50	train_loss: 0.6057 train_accuracy-SBM: 0.7793	val_loss: 0.6292 val_accuracy-SBM: 0.7756	test_loss: 0.6223 test_accuracy-SBM: 0.7779
2025-08-17 00:15:45,610 - INFO - === Epoch 52 ===
2025-08-17 00:17:06,657 - INFO - train: {'epoch': 52, 'time_epoch': 80.81974, 'eta': 4039.96888, 'eta_hours': 1.12221, 'loss': 0.60362311, 'lr': 0.00050827, 'params': 505766, 'time_iter': 0.12931, 'accuracy': 0.78046, 'f1': 0.78046, 'accuracy-SBM': 0.78046, 'auc': 0.96354}
2025-08-17 00:17:10,790 - INFO - val: {'epoch': 52, 'time_epoch': 4.08707, 'loss': 0.62881475, 'lr': 0, 'params': 505766, 'time_iter': 0.06487, 'accuracy': 0.77466, 'f1': 0.77453, 'accuracy-SBM': 0.77453, 'auc': 0.96049}
2025-08-17 00:17:19,652 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:17:19,691 - INFO - test: {'epoch': 52, 'time_epoch': 4.4758, 'loss': 0.62514085, 'lr': 0, 'params': 505766, 'time_iter': 0.07104, 'accuracy': 0.77477, 'f1': 0.77477, 'accuracy-SBM': 0.77476, 'auc': 0.961}
2025-08-17 00:17:19,699 - INFO - > Epoch 52: took 94.1s (avg 98.7s) | Best so far: epoch 50	train_loss: 0.6057 train_accuracy-SBM: 0.7793	val_loss: 0.6292 val_accuracy-SBM: 0.7756	test_loss: 0.6223 test_accuracy-SBM: 0.7779
2025-08-17 00:17:19,700 - INFO - === Epoch 53 ===
2025-08-17 00:18:46,308 - INFO - train: {'epoch': 53, 'time_epoch': 86.36446, 'eta': 3954.35938, 'eta_hours': 1.09843, 'loss': 0.59828999, 'lr': 0.00049173, 'params': 505766, 'time_iter': 0.13818, 'accuracy': 0.7821, 'f1': 0.7821, 'accuracy-SBM': 0.7821, 'auc': 0.96419}
2025-08-17 00:18:50,586 - INFO - val: {'epoch': 53, 'time_epoch': 4.22589, 'loss': 0.62834293, 'lr': 0, 'params': 505766, 'time_iter': 0.06708, 'accuracy': 0.7759, 'f1': 0.77587, 'accuracy-SBM': 0.77588, 'auc': 0.9605}
2025-08-17 00:19:00,251 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:19:00,312 - INFO - test: {'epoch': 53, 'time_epoch': 4.50611, 'loss': 0.62966083, 'lr': 0, 'params': 505766, 'time_iter': 0.07153, 'accuracy': 0.77422, 'f1': 0.77426, 'accuracy-SBM': 0.77427, 'auc': 0.96039}
2025-08-17 00:19:00,328 - INFO - > Epoch 53: took 100.6s (avg 98.7s) | Best so far: epoch 53	train_loss: 0.5983 train_accuracy-SBM: 0.7821	val_loss: 0.6283 val_accuracy-SBM: 0.7759	test_loss: 0.6297 test_accuracy-SBM: 0.7743
2025-08-17 00:19:00,328 - INFO - === Epoch 54 ===
2025-08-17 00:20:27,095 - INFO - train: {'epoch': 54, 'time_epoch': 86.41224, 'eta': 3868.76151, 'eta_hours': 1.07466, 'loss': 0.59503612, 'lr': 0.00047521, 'params': 505766, 'time_iter': 0.13826, 'accuracy': 0.78343, 'f1': 0.78343, 'accuracy-SBM': 0.78343, 'auc': 0.96457}
2025-08-17 00:20:31,367 - INFO - val: {'epoch': 54, 'time_epoch': 4.22525, 'loss': 0.61972184, 'lr': 0, 'params': 505766, 'time_iter': 0.06707, 'accuracy': 0.77683, 'f1': 0.7767, 'accuracy-SBM': 0.77669, 'auc': 0.96172}
2025-08-17 00:20:40,573 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:20:40,613 - INFO - test: {'epoch': 54, 'time_epoch': 4.38118, 'loss': 0.62322881, 'lr': 0, 'params': 505766, 'time_iter': 0.06954, 'accuracy': 0.77685, 'f1': 0.77684, 'accuracy-SBM': 0.77686, 'auc': 0.96124}
2025-08-17 00:20:40,618 - INFO - > Epoch 54: took 100.3s (avg 98.7s) | Best so far: epoch 54	train_loss: 0.5950 train_accuracy-SBM: 0.7834	val_loss: 0.6197 val_accuracy-SBM: 0.7767	test_loss: 0.6232 test_accuracy-SBM: 0.7769
2025-08-17 00:20:40,619 - INFO - === Epoch 55 ===
2025-08-17 00:22:08,115 - INFO - train: {'epoch': 55, 'time_epoch': 87.25739, 'eta': 3783.79861, 'eta_hours': 1.05106, 'loss': 0.59324475, 'lr': 0.00045871, 'params': 505766, 'time_iter': 0.13961, 'accuracy': 0.7837, 'f1': 0.7837, 'accuracy-SBM': 0.7837, 'auc': 0.96478}
2025-08-17 00:22:12,440 - INFO - val: {'epoch': 55, 'time_epoch': 4.27363, 'loss': 0.6333685, 'lr': 0, 'params': 505766, 'time_iter': 0.06784, 'accuracy': 0.77458, 'f1': 0.77457, 'accuracy-SBM': 0.77455, 'auc': 0.96012}
2025-08-17 00:22:21,363 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:22:21,404 - INFO - test: {'epoch': 55, 'time_epoch': 4.47795, 'loss': 0.62567972, 'lr': 0, 'params': 505766, 'time_iter': 0.07108, 'accuracy': 0.77539, 'f1': 0.77536, 'accuracy-SBM': 0.77541, 'auc': 0.96093}
2025-08-17 00:22:21,409 - INFO - > Epoch 55: took 100.8s (avg 98.8s) | Best so far: epoch 54	train_loss: 0.5950 train_accuracy-SBM: 0.7834	val_loss: 0.6197 val_accuracy-SBM: 0.7767	test_loss: 0.6232 test_accuracy-SBM: 0.7769
2025-08-17 00:22:21,409 - INFO - === Epoch 56 ===
2025-08-17 00:23:48,015 - INFO - train: {'epoch': 56, 'time_epoch': 86.34298, 'eta': 3698.06537, 'eta_hours': 1.02724, 'loss': 0.58953257, 'lr': 0.00044226, 'params': 505766, 'time_iter': 0.13815, 'accuracy': 0.78474, 'f1': 0.78474, 'accuracy-SBM': 0.78474, 'auc': 0.96524}
2025-08-17 00:23:52,280 - INFO - val: {'epoch': 56, 'time_epoch': 4.21189, 'loss': 0.62743387, 'lr': 0, 'params': 505766, 'time_iter': 0.06686, 'accuracy': 0.77726, 'f1': 0.77726, 'accuracy-SBM': 0.77724, 'auc': 0.96098}
2025-08-17 00:24:02,645 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:24:02,682 - INFO - test: {'epoch': 56, 'time_epoch': 4.52698, 'loss': 0.62842774, 'lr': 0, 'params': 505766, 'time_iter': 0.07186, 'accuracy': 0.77575, 'f1': 0.77578, 'accuracy-SBM': 0.77583, 'auc': 0.96087}
2025-08-17 00:24:02,686 - INFO - > Epoch 56: took 101.3s (avg 98.8s) | Best so far: epoch 56	train_loss: 0.5895 train_accuracy-SBM: 0.7847	val_loss: 0.6274 val_accuracy-SBM: 0.7772	test_loss: 0.6284 test_accuracy-SBM: 0.7758
2025-08-17 00:24:02,687 - INFO - === Epoch 57 ===
2025-08-17 00:25:26,947 - INFO - train: {'epoch': 57, 'time_epoch': 84.02387, 'eta': 3610.63176, 'eta_hours': 1.00295, 'loss': 0.58756884, 'lr': 0.00042587, 'params': 505766, 'time_iter': 0.13444, 'accuracy': 0.78606, 'f1': 0.78606, 'accuracy-SBM': 0.78606, 'auc': 0.96547}
2025-08-17 00:25:31,312 - INFO - val: {'epoch': 57, 'time_epoch': 4.3122, 'loss': 0.6259412, 'lr': 0, 'params': 505766, 'time_iter': 0.06845, 'accuracy': 0.77641, 'f1': 0.77623, 'accuracy-SBM': 0.77628, 'auc': 0.96101}
2025-08-17 00:25:41,536 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:25:41,576 - INFO - test: {'epoch': 57, 'time_epoch': 4.38679, 'loss': 0.63072086, 'lr': 0, 'params': 505766, 'time_iter': 0.06963, 'accuracy': 0.77466, 'f1': 0.7746, 'accuracy-SBM': 0.77453, 'auc': 0.96035}
2025-08-17 00:25:41,585 - INFO - > Epoch 57: took 98.9s (avg 98.8s) | Best so far: epoch 56	train_loss: 0.5895 train_accuracy-SBM: 0.7847	val_loss: 0.6274 val_accuracy-SBM: 0.7772	test_loss: 0.6284 test_accuracy-SBM: 0.7758
2025-08-17 00:25:41,585 - INFO - === Epoch 58 ===
2025-08-17 00:27:07,916 - INFO - train: {'epoch': 58, 'time_epoch': 86.09676, 'eta': 3524.75422, 'eta_hours': 0.9791, 'loss': 0.58881544, 'lr': 0.00040956, 'params': 505766, 'time_iter': 0.13775, 'accuracy': 0.78546, 'f1': 0.78546, 'accuracy-SBM': 0.78546, 'auc': 0.96533}
2025-08-17 00:27:12,274 - INFO - val: {'epoch': 58, 'time_epoch': 4.30248, 'loss': 0.62578771, 'lr': 0, 'params': 505766, 'time_iter': 0.06829, 'accuracy': 0.77809, 'f1': 0.77794, 'accuracy-SBM': 0.77788, 'auc': 0.96093}
2025-08-17 00:27:21,801 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:27:21,843 - INFO - test: {'epoch': 58, 'time_epoch': 4.56557, 'loss': 0.616212, 'lr': 0, 'params': 505766, 'time_iter': 0.07247, 'accuracy': 0.77749, 'f1': 0.77746, 'accuracy-SBM': 0.77745, 'auc': 0.96215}
2025-08-17 00:27:21,851 - INFO - > Epoch 58: took 100.3s (avg 98.9s) | Best so far: epoch 58	train_loss: 0.5888 train_accuracy-SBM: 0.7855	val_loss: 0.6258 val_accuracy-SBM: 0.7779	test_loss: 0.6162 test_accuracy-SBM: 0.7774
2025-08-17 00:27:21,851 - INFO - === Epoch 59 ===
2025-08-17 00:28:48,700 - INFO - train: {'epoch': 59, 'time_epoch': 86.60177, 'eta': 3439.20603, 'eta_hours': 0.95534, 'loss': 0.58550506, 'lr': 0.00039335, 'params': 505766, 'time_iter': 0.13856, 'accuracy': 0.78639, 'f1': 0.78638, 'accuracy-SBM': 0.78638, 'auc': 0.96572}
2025-08-17 00:28:53,045 - INFO - val: {'epoch': 59, 'time_epoch': 4.28929, 'loss': 0.62686215, 'lr': 0, 'params': 505766, 'time_iter': 0.06808, 'accuracy': 0.7759, 'f1': 0.77585, 'accuracy-SBM': 0.7759, 'auc': 0.96112}
2025-08-17 00:29:03,173 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:29:03,213 - INFO - test: {'epoch': 59, 'time_epoch': 4.57377, 'loss': 0.62492082, 'lr': 0, 'params': 505766, 'time_iter': 0.0726, 'accuracy': 0.77717, 'f1': 0.77722, 'accuracy-SBM': 0.77722, 'auc': 0.96123}
2025-08-17 00:29:03,217 - INFO - > Epoch 59: took 101.4s (avg 98.9s) | Best so far: epoch 58	train_loss: 0.5888 train_accuracy-SBM: 0.7855	val_loss: 0.6258 val_accuracy-SBM: 0.7779	test_loss: 0.6162 test_accuracy-SBM: 0.7774
2025-08-17 00:29:03,218 - INFO - === Epoch 60 ===
2025-08-17 00:30:28,677 - INFO - train: {'epoch': 60, 'time_epoch': 85.22943, 'eta': 3352.74592, 'eta_hours': 0.93132, 'loss': 0.5817656, 'lr': 0.00037726, 'params': 505766, 'time_iter': 0.13637, 'accuracy': 0.78786, 'f1': 0.78785, 'accuracy-SBM': 0.78786, 'auc': 0.96615}
2025-08-17 00:30:32,698 - INFO - val: {'epoch': 60, 'time_epoch': 3.97793, 'loss': 0.62417566, 'lr': 0, 'params': 505766, 'time_iter': 0.06314, 'accuracy': 0.77769, 'f1': 0.77754, 'accuracy-SBM': 0.77749, 'auc': 0.96108}
2025-08-17 00:30:42,075 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:30:42,114 - INFO - test: {'epoch': 60, 'time_epoch': 4.23511, 'loss': 0.62075153, 'lr': 0, 'params': 505766, 'time_iter': 0.06722, 'accuracy': 0.77876, 'f1': 0.77875, 'accuracy-SBM': 0.77876, 'auc': 0.96153}
2025-08-17 00:30:42,118 - INFO - > Epoch 60: took 98.9s (avg 98.9s) | Best so far: epoch 58	train_loss: 0.5888 train_accuracy-SBM: 0.7855	val_loss: 0.6258 val_accuracy-SBM: 0.7779	test_loss: 0.6162 test_accuracy-SBM: 0.7774
2025-08-17 00:30:42,119 - INFO - === Epoch 61 ===
2025-08-17 00:32:07,165 - INFO - train: {'epoch': 61, 'time_epoch': 84.8058, 'eta': 3266.06585, 'eta_hours': 0.90724, 'loss': 0.57987079, 'lr': 0.0003613, 'params': 505766, 'time_iter': 0.13569, 'accuracy': 0.78875, 'f1': 0.78875, 'accuracy-SBM': 0.78875, 'auc': 0.96637}
2025-08-17 00:32:11,443 - INFO - val: {'epoch': 61, 'time_epoch': 4.2321, 'loss': 0.63443841, 'lr': 0, 'params': 505766, 'time_iter': 0.06718, 'accuracy': 0.7754, 'f1': 0.77537, 'accuracy-SBM': 0.77536, 'auc': 0.95996}
2025-08-17 00:32:21,805 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:32:21,846 - INFO - test: {'epoch': 61, 'time_epoch': 4.50424, 'loss': 0.63066078, 'lr': 0, 'params': 505766, 'time_iter': 0.0715, 'accuracy': 0.77711, 'f1': 0.77711, 'accuracy-SBM': 0.77715, 'auc': 0.96036}
2025-08-17 00:32:21,848 - INFO - > Epoch 61: took 99.7s (avg 98.9s) | Best so far: epoch 58	train_loss: 0.5888 train_accuracy-SBM: 0.7855	val_loss: 0.6258 val_accuracy-SBM: 0.7779	test_loss: 0.6162 test_accuracy-SBM: 0.7774
2025-08-17 00:32:21,849 - INFO - === Epoch 62 ===
2025-08-17 00:33:48,456 - INFO - train: {'epoch': 62, 'time_epoch': 86.3572, 'eta': 3180.35643, 'eta_hours': 0.88343, 'loss': 0.57709663, 'lr': 0.00034549, 'params': 505766, 'time_iter': 0.13817, 'accuracy': 0.78955, 'f1': 0.78955, 'accuracy-SBM': 0.78955, 'auc': 0.9667}
2025-08-17 00:33:52,706 - INFO - val: {'epoch': 62, 'time_epoch': 4.19673, 'loss': 0.623744, 'lr': 0, 'params': 505766, 'time_iter': 0.06661, 'accuracy': 0.78094, 'f1': 0.7808, 'accuracy-SBM': 0.78081, 'auc': 0.96165}
2025-08-17 00:34:16,196 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:34:16,237 - INFO - test: {'epoch': 62, 'time_epoch': 4.45643, 'loss': 0.62485383, 'lr': 0, 'params': 505766, 'time_iter': 0.07074, 'accuracy': 0.78051, 'f1': 0.78045, 'accuracy-SBM': 0.78046, 'auc': 0.96143}
2025-08-17 00:34:16,243 - INFO - > Epoch 62: took 114.4s (avg 99.2s) | Best so far: epoch 62	train_loss: 0.5771 train_accuracy-SBM: 0.7895	val_loss: 0.6237 val_accuracy-SBM: 0.7808	test_loss: 0.6249 test_accuracy-SBM: 0.7805
2025-08-17 00:34:16,243 - INFO - === Epoch 63 ===
2025-08-17 00:35:43,477 - INFO - train: {'epoch': 63, 'time_epoch': 86.99096, 'eta': 3094.98325, 'eta_hours': 0.85972, 'loss': 0.57419085, 'lr': 0.00032985, 'params': 505766, 'time_iter': 0.13919, 'accuracy': 0.79097, 'f1': 0.79097, 'accuracy-SBM': 0.79097, 'auc': 0.96702}
2025-08-17 00:35:47,837 - INFO - val: {'epoch': 63, 'time_epoch': 4.30921, 'loss': 0.62307704, 'lr': 0, 'params': 505766, 'time_iter': 0.0684, 'accuracy': 0.77925, 'f1': 0.77917, 'accuracy-SBM': 0.77915, 'auc': 0.96119}
2025-08-17 00:35:57,840 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:35:57,881 - INFO - test: {'epoch': 63, 'time_epoch': 4.33253, 'loss': 0.61844715, 'lr': 0, 'params': 505766, 'time_iter': 0.06877, 'accuracy': 0.77984, 'f1': 0.77981, 'accuracy-SBM': 0.77983, 'auc': 0.9617}
2025-08-17 00:35:57,886 - INFO - > Epoch 63: took 101.6s (avg 99.2s) | Best so far: epoch 62	train_loss: 0.5771 train_accuracy-SBM: 0.7895	val_loss: 0.6237 val_accuracy-SBM: 0.7808	test_loss: 0.6249 test_accuracy-SBM: 0.7805
2025-08-17 00:35:57,886 - INFO - === Epoch 64 ===
2025-08-17 00:37:18,790 - INFO - train: {'epoch': 64, 'time_epoch': 80.67692, 'eta': 3006.16042, 'eta_hours': 0.83504, 'loss': 0.57233115, 'lr': 0.0003144, 'params': 505766, 'time_iter': 0.12908, 'accuracy': 0.79156, 'f1': 0.79156, 'accuracy-SBM': 0.79156, 'auc': 0.96722}
2025-08-17 00:37:22,791 - INFO - val: {'epoch': 64, 'time_epoch': 3.95165, 'loss': 0.62262963, 'lr': 0, 'params': 505766, 'time_iter': 0.06272, 'accuracy': 0.77939, 'f1': 0.77928, 'accuracy-SBM': 0.77928, 'auc': 0.96144}
2025-08-17 00:37:28,661 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:37:28,698 - INFO - test: {'epoch': 64, 'time_epoch': 4.25684, 'loss': 0.62651953, 'lr': 0, 'params': 505766, 'time_iter': 0.06757, 'accuracy': 0.77798, 'f1': 0.778, 'accuracy-SBM': 0.77799, 'auc': 0.9609}
2025-08-17 00:37:28,700 - INFO - > Epoch 64: took 90.8s (avg 99.1s) | Best so far: epoch 62	train_loss: 0.5771 train_accuracy-SBM: 0.7895	val_loss: 0.6237 val_accuracy-SBM: 0.7808	test_loss: 0.6249 test_accuracy-SBM: 0.7805
2025-08-17 00:37:28,700 - INFO - === Epoch 65 ===
2025-08-17 00:38:48,867 - INFO - train: {'epoch': 65, 'time_epoch': 79.94205, 'eta': 2917.20588, 'eta_hours': 0.81033, 'loss': 0.5717724, 'lr': 0.00029915, 'params': 505766, 'time_iter': 0.12791, 'accuracy': 0.79134, 'f1': 0.79134, 'accuracy-SBM': 0.79134, 'auc': 0.9673}
2025-08-17 00:38:52,862 - INFO - val: {'epoch': 65, 'time_epoch': 3.95219, 'loss': 0.62583078, 'lr': 0, 'params': 505766, 'time_iter': 0.06273, 'accuracy': 0.77864, 'f1': 0.7786, 'accuracy-SBM': 0.77857, 'auc': 0.96127}
2025-08-17 00:38:59,612 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:38:59,649 - INFO - test: {'epoch': 65, 'time_epoch': 4.18026, 'loss': 0.62057677, 'lr': 0, 'params': 505766, 'time_iter': 0.06635, 'accuracy': 0.77901, 'f1': 0.77898, 'accuracy-SBM': 0.779, 'auc': 0.96181}
2025-08-17 00:38:59,651 - INFO - > Epoch 65: took 91.0s (avg 98.9s) | Best so far: epoch 62	train_loss: 0.5771 train_accuracy-SBM: 0.7895	val_loss: 0.6237 val_accuracy-SBM: 0.7808	test_loss: 0.6249 test_accuracy-SBM: 0.7805
2025-08-17 00:38:59,651 - INFO - === Epoch 66 ===
2025-08-17 00:40:19,360 - INFO - train: {'epoch': 66, 'time_epoch': 79.47839, 'eta': 2828.29199, 'eta_hours': 0.78564, 'loss': 0.56619876, 'lr': 0.00028412, 'params': 505766, 'time_iter': 0.12717, 'accuracy': 0.79372, 'f1': 0.79372, 'accuracy-SBM': 0.79372, 'auc': 0.96793}
2025-08-17 00:40:23,380 - INFO - val: {'epoch': 66, 'time_epoch': 3.97622, 'loss': 0.62518098, 'lr': 0, 'params': 505766, 'time_iter': 0.06311, 'accuracy': 0.77933, 'f1': 0.77924, 'accuracy-SBM': 0.7792, 'auc': 0.96141}
2025-08-17 00:40:30,650 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:40:30,687 - INFO - test: {'epoch': 66, 'time_epoch': 4.18535, 'loss': 0.62790039, 'lr': 0, 'params': 505766, 'time_iter': 0.06643, 'accuracy': 0.77736, 'f1': 0.77736, 'accuracy-SBM': 0.77737, 'auc': 0.96098}
2025-08-17 00:40:30,689 - INFO - > Epoch 66: took 91.0s (avg 98.8s) | Best so far: epoch 62	train_loss: 0.5771 train_accuracy-SBM: 0.7895	val_loss: 0.6237 val_accuracy-SBM: 0.7808	test_loss: 0.6249 test_accuracy-SBM: 0.7805
2025-08-17 00:40:30,689 - INFO - === Epoch 67 ===
2025-08-17 00:41:55,792 - INFO - train: {'epoch': 67, 'time_epoch': 84.86231, 'eta': 2742.18923, 'eta_hours': 0.76172, 'loss': 0.56487001, 'lr': 0.00026933, 'params': 505766, 'time_iter': 0.13578, 'accuracy': 0.79416, 'f1': 0.79416, 'accuracy-SBM': 0.79416, 'auc': 0.96809}
2025-08-17 00:42:00,199 - INFO - val: {'epoch': 67, 'time_epoch': 4.35426, 'loss': 0.62380321, 'lr': 0, 'params': 505766, 'time_iter': 0.06912, 'accuracy': 0.78007, 'f1': 0.77989, 'accuracy-SBM': 0.77986, 'auc': 0.9613}
2025-08-17 00:42:11,672 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:42:11,713 - INFO - test: {'epoch': 67, 'time_epoch': 4.37939, 'loss': 0.62306161, 'lr': 0, 'params': 505766, 'time_iter': 0.06951, 'accuracy': 0.77764, 'f1': 0.77756, 'accuracy-SBM': 0.77759, 'auc': 0.96132}
2025-08-17 00:42:11,718 - INFO - > Epoch 67: took 101.0s (avg 98.9s) | Best so far: epoch 62	train_loss: 0.5771 train_accuracy-SBM: 0.7895	val_loss: 0.6237 val_accuracy-SBM: 0.7808	test_loss: 0.6249 test_accuracy-SBM: 0.7805
2025-08-17 00:42:11,718 - INFO - === Epoch 68 ===
2025-08-17 00:43:40,356 - INFO - train: {'epoch': 68, 'time_epoch': 88.26971, 'eta': 2657.65328, 'eta_hours': 0.73824, 'loss': 0.5648885, 'lr': 0.00025479, 'params': 505766, 'time_iter': 0.14123, 'accuracy': 0.79416, 'f1': 0.79416, 'accuracy-SBM': 0.79416, 'auc': 0.96809}
2025-08-17 00:43:44,617 - INFO - val: {'epoch': 68, 'time_epoch': 4.20485, 'loss': 0.62732773, 'lr': 0, 'params': 505766, 'time_iter': 0.06674, 'accuracy': 0.77928, 'f1': 0.77929, 'accuracy-SBM': 0.77933, 'auc': 0.96088}
2025-08-17 00:43:52,879 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:43:52,919 - INFO - test: {'epoch': 68, 'time_epoch': 4.45436, 'loss': 0.6183133, 'lr': 0, 'params': 505766, 'time_iter': 0.0707, 'accuracy': 0.77856, 'f1': 0.7786, 'accuracy-SBM': 0.77864, 'auc': 0.96197}
2025-08-17 00:43:52,922 - INFO - > Epoch 68: took 101.2s (avg 98.9s) | Best so far: epoch 62	train_loss: 0.5771 train_accuracy-SBM: 0.7895	val_loss: 0.6237 val_accuracy-SBM: 0.7808	test_loss: 0.6249 test_accuracy-SBM: 0.7805
2025-08-17 00:43:52,922 - INFO - === Epoch 69 ===
2025-08-17 00:45:21,108 - INFO - train: {'epoch': 69, 'time_epoch': 87.93328, 'eta': 2572.86647, 'eta_hours': 0.71469, 'loss': 0.56040137, 'lr': 0.00024052, 'params': 505766, 'time_iter': 0.14069, 'accuracy': 0.79536, 'f1': 0.79536, 'accuracy-SBM': 0.79536, 'auc': 0.96859}
2025-08-17 00:45:25,565 - INFO - val: {'epoch': 69, 'time_epoch': 4.38628, 'loss': 0.62173034, 'lr': 0, 'params': 505766, 'time_iter': 0.06962, 'accuracy': 0.78107, 'f1': 0.78096, 'accuracy-SBM': 0.78097, 'auc': 0.96175}
2025-08-17 00:45:37,089 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:45:37,132 - INFO - test: {'epoch': 69, 'time_epoch': 4.72981, 'loss': 0.62266145, 'lr': 0, 'params': 505766, 'time_iter': 0.07508, 'accuracy': 0.77962, 'f1': 0.77962, 'accuracy-SBM': 0.7796, 'auc': 0.96158}
2025-08-17 00:45:37,135 - INFO - > Epoch 69: took 104.2s (avg 99.0s) | Best so far: epoch 69	train_loss: 0.5604 train_accuracy-SBM: 0.7954	val_loss: 0.6217 val_accuracy-SBM: 0.7810	test_loss: 0.6227 test_accuracy-SBM: 0.7796
2025-08-17 00:45:37,135 - INFO - === Epoch 70 ===
2025-08-17 00:47:03,372 - INFO - train: {'epoch': 70, 'time_epoch': 86.00925, 'eta': 2487.20516, 'eta_hours': 0.69089, 'loss': 0.56123821, 'lr': 0.00022653, 'params': 505766, 'time_iter': 0.13761, 'accuracy': 0.7957, 'f1': 0.7957, 'accuracy-SBM': 0.7957, 'auc': 0.96849}
2025-08-17 00:47:07,366 - INFO - val: {'epoch': 70, 'time_epoch': 3.94942, 'loss': 0.62638753, 'lr': 0, 'params': 505766, 'time_iter': 0.06269, 'accuracy': 0.78021, 'f1': 0.7801, 'accuracy-SBM': 0.78009, 'auc': 0.9613}
2025-08-17 00:47:17,675 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:47:17,713 - INFO - test: {'epoch': 70, 'time_epoch': 4.22116, 'loss': 0.62588087, 'lr': 0, 'params': 505766, 'time_iter': 0.067, 'accuracy': 0.77924, 'f1': 0.7792, 'accuracy-SBM': 0.77923, 'auc': 0.96124}
2025-08-17 00:47:17,717 - INFO - > Epoch 70: took 100.6s (avg 99.0s) | Best so far: epoch 69	train_loss: 0.5604 train_accuracy-SBM: 0.7954	val_loss: 0.6217 val_accuracy-SBM: 0.7810	test_loss: 0.6227 test_accuracy-SBM: 0.7796
2025-08-17 00:47:17,717 - INFO - === Epoch 71 ===
2025-08-17 00:48:46,315 - INFO - train: {'epoch': 71, 'time_epoch': 88.35466, 'eta': 2402.44628, 'eta_hours': 0.66735, 'loss': 0.55847042, 'lr': 0.00021284, 'params': 505766, 'time_iter': 0.14137, 'accuracy': 0.79629, 'f1': 0.79629, 'accuracy-SBM': 0.79629, 'auc': 0.96881}
2025-08-17 00:48:50,598 - INFO - val: {'epoch': 71, 'time_epoch': 4.23685, 'loss': 0.62500458, 'lr': 0, 'params': 505766, 'time_iter': 0.06725, 'accuracy': 0.78026, 'f1': 0.78012, 'accuracy-SBM': 0.78013, 'auc': 0.96132}
2025-08-17 00:48:59,263 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:48:59,308 - INFO - test: {'epoch': 71, 'time_epoch': 4.73949, 'loss': 0.62420803, 'lr': 0, 'params': 505766, 'time_iter': 0.07523, 'accuracy': 0.77893, 'f1': 0.77893, 'accuracy-SBM': 0.77896, 'auc': 0.96138}
2025-08-17 00:48:59,311 - INFO - > Epoch 71: took 101.6s (avg 99.0s) | Best so far: epoch 69	train_loss: 0.5604 train_accuracy-SBM: 0.7954	val_loss: 0.6217 val_accuracy-SBM: 0.7810	test_loss: 0.6227 test_accuracy-SBM: 0.7796
2025-08-17 00:48:59,311 - INFO - === Epoch 72 ===
2025-08-17 00:50:28,668 - INFO - train: {'epoch': 72, 'time_epoch': 89.11684, 'eta': 2317.8708, 'eta_hours': 0.64385, 'loss': 0.55662739, 'lr': 0.00019946, 'params': 505766, 'time_iter': 0.14259, 'accuracy': 0.79662, 'f1': 0.79662, 'accuracy-SBM': 0.79662, 'auc': 0.96902}
2025-08-17 00:50:33,072 - INFO - val: {'epoch': 72, 'time_epoch': 4.35899, 'loss': 0.62473181, 'lr': 0, 'params': 505766, 'time_iter': 0.06919, 'accuracy': 0.78011, 'f1': 0.78006, 'accuracy-SBM': 0.78007, 'auc': 0.96146}
2025-08-17 00:50:42,430 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:50:42,470 - INFO - test: {'epoch': 72, 'time_epoch': 4.70901, 'loss': 0.63038821, 'lr': 0, 'params': 505766, 'time_iter': 0.07475, 'accuracy': 0.77722, 'f1': 0.7772, 'accuracy-SBM': 0.77725, 'auc': 0.96073}
2025-08-17 00:50:42,474 - INFO - > Epoch 72: took 103.2s (avg 99.1s) | Best so far: epoch 69	train_loss: 0.5604 train_accuracy-SBM: 0.7954	val_loss: 0.6217 val_accuracy-SBM: 0.7810	test_loss: 0.6227 test_accuracy-SBM: 0.7796
2025-08-17 00:50:42,475 - INFO - === Epoch 73 ===
2025-08-17 00:52:17,168 - INFO - train: {'epoch': 73, 'time_epoch': 94.37847, 'eta': 2235.02125, 'eta_hours': 0.62084, 'loss': 0.55169683, 'lr': 0.00018641, 'params': 505766, 'time_iter': 0.15101, 'accuracy': 0.79879, 'f1': 0.79879, 'accuracy-SBM': 0.79879, 'auc': 0.96955}
2025-08-17 00:52:21,895 - INFO - val: {'epoch': 73, 'time_epoch': 4.66617, 'loss': 0.62251609, 'lr': 0, 'params': 505766, 'time_iter': 0.07407, 'accuracy': 0.78112, 'f1': 0.781, 'accuracy-SBM': 0.78102, 'auc': 0.9617}
2025-08-17 00:52:31,647 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:52:31,691 - INFO - test: {'epoch': 73, 'time_epoch': 5.10924, 'loss': 0.61911919, 'lr': 0, 'params': 505766, 'time_iter': 0.0811, 'accuracy': 0.78011, 'f1': 0.78008, 'accuracy-SBM': 0.78009, 'auc': 0.96197}
2025-08-17 00:52:31,696 - INFO - > Epoch 73: took 109.2s (avg 99.2s) | Best so far: epoch 73	train_loss: 0.5517 train_accuracy-SBM: 0.7988	val_loss: 0.6225 val_accuracy-SBM: 0.7810	test_loss: 0.6191 test_accuracy-SBM: 0.7801
2025-08-17 00:52:31,696 - INFO - === Epoch 74 ===
2025-08-17 00:54:05,351 - INFO - train: {'epoch': 74, 'time_epoch': 93.30717, 'eta': 2151.50716, 'eta_hours': 0.59764, 'loss': 0.54943653, 'lr': 0.00017371, 'params': 505766, 'time_iter': 0.14929, 'accuracy': 0.79944, 'f1': 0.79944, 'accuracy-SBM': 0.79944, 'auc': 0.96981}
2025-08-17 00:54:09,611 - INFO - val: {'epoch': 74, 'time_epoch': 4.19376, 'loss': 0.62423293, 'lr': 0, 'params': 505766, 'time_iter': 0.06657, 'accuracy': 0.7813, 'f1': 0.7812, 'accuracy-SBM': 0.78117, 'auc': 0.96158}
2025-08-17 00:54:18,067 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:54:18,108 - INFO - test: {'epoch': 74, 'time_epoch': 4.65961, 'loss': 0.6220044, 'lr': 0, 'params': 505766, 'time_iter': 0.07396, 'accuracy': 0.78063, 'f1': 0.78061, 'accuracy-SBM': 0.7806, 'auc': 0.96168}
2025-08-17 00:54:18,113 - INFO - > Epoch 74: took 106.4s (avg 99.3s) | Best so far: epoch 74	train_loss: 0.5494 train_accuracy-SBM: 0.7994	val_loss: 0.6242 val_accuracy-SBM: 0.7812	test_loss: 0.6220 test_accuracy-SBM: 0.7806
2025-08-17 00:54:18,113 - INFO - === Epoch 75 ===
2025-08-17 00:55:49,032 - INFO - train: {'epoch': 75, 'time_epoch': 90.56158, 'eta': 2066.86834, 'eta_hours': 0.57413, 'loss': 0.54824809, 'lr': 0.00016136, 'params': 505766, 'time_iter': 0.1449, 'accuracy': 0.79985, 'f1': 0.79985, 'accuracy-SBM': 0.79985, 'auc': 0.96994}
2025-08-17 00:55:53,496 - INFO - val: {'epoch': 75, 'time_epoch': 4.41449, 'loss': 0.62562853, 'lr': 0, 'params': 505766, 'time_iter': 0.07007, 'accuracy': 0.78072, 'f1': 0.78063, 'accuracy-SBM': 0.78061, 'auc': 0.96111}
2025-08-17 00:56:02,852 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:56:02,893 - INFO - test: {'epoch': 75, 'time_epoch': 4.75431, 'loss': 0.61834782, 'lr': 0, 'params': 505766, 'time_iter': 0.07547, 'accuracy': 0.78013, 'f1': 0.78017, 'accuracy-SBM': 0.7802, 'auc': 0.96198}
2025-08-17 00:56:02,897 - INFO - > Epoch 75: took 104.8s (avg 99.4s) | Best so far: epoch 74	train_loss: 0.5494 train_accuracy-SBM: 0.7994	val_loss: 0.6242 val_accuracy-SBM: 0.7812	test_loss: 0.6220 test_accuracy-SBM: 0.7806
2025-08-17 00:56:02,898 - INFO - === Epoch 76 ===
2025-08-17 00:57:33,198 - INFO - train: {'epoch': 76, 'time_epoch': 89.94476, 'eta': 1981.89143, 'eta_hours': 0.55053, 'loss': 0.54610846, 'lr': 0.00014938, 'params': 505766, 'time_iter': 0.14391, 'accuracy': 0.80118, 'f1': 0.80118, 'accuracy-SBM': 0.80118, 'auc': 0.97016}
2025-08-17 00:57:37,616 - INFO - val: {'epoch': 76, 'time_epoch': 4.37349, 'loss': 0.62263602, 'lr': 0, 'params': 505766, 'time_iter': 0.06942, 'accuracy': 0.78041, 'f1': 0.7803, 'accuracy-SBM': 0.78027, 'auc': 0.96163}
2025-08-17 00:57:47,512 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:57:47,555 - INFO - test: {'epoch': 76, 'time_epoch': 4.62254, 'loss': 0.6219965, 'lr': 0, 'params': 505766, 'time_iter': 0.07337, 'accuracy': 0.78052, 'f1': 0.78047, 'accuracy-SBM': 0.78049, 'auc': 0.96158}
2025-08-17 00:57:47,559 - INFO - > Epoch 76: took 104.7s (avg 99.5s) | Best so far: epoch 74	train_loss: 0.5494 train_accuracy-SBM: 0.7994	val_loss: 0.6242 val_accuracy-SBM: 0.7812	test_loss: 0.6220 test_accuracy-SBM: 0.7806
2025-08-17 00:57:47,559 - INFO - === Epoch 77 ===
2025-08-17 00:59:22,668 - INFO - train: {'epoch': 77, 'time_epoch': 94.63813, 'eta': 1898.11091, 'eta_hours': 0.52725, 'loss': 0.54679234, 'lr': 0.00013779, 'params': 505766, 'time_iter': 0.15142, 'accuracy': 0.80062, 'f1': 0.80062, 'accuracy-SBM': 0.80062, 'auc': 0.9701}
2025-08-17 00:59:27,233 - INFO - val: {'epoch': 77, 'time_epoch': 4.50284, 'loss': 0.63136094, 'lr': 0, 'params': 505766, 'time_iter': 0.07147, 'accuracy': 0.78003, 'f1': 0.77996, 'accuracy-SBM': 0.77995, 'auc': 0.96095}
2025-08-17 00:59:36,266 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 00:59:36,310 - INFO - test: {'epoch': 77, 'time_epoch': 4.79088, 'loss': 0.62620985, 'lr': 0, 'params': 505766, 'time_iter': 0.07605, 'accuracy': 0.77913, 'f1': 0.77912, 'accuracy-SBM': 0.77913, 'auc': 0.96133}
2025-08-17 00:59:36,314 - INFO - > Epoch 77: took 108.8s (avg 99.6s) | Best so far: epoch 74	train_loss: 0.5494 train_accuracy-SBM: 0.7994	val_loss: 0.6242 val_accuracy-SBM: 0.7812	test_loss: 0.6220 test_accuracy-SBM: 0.7806
2025-08-17 00:59:36,314 - INFO - === Epoch 78 ===
2025-08-17 01:01:09,800 - INFO - train: {'epoch': 78, 'time_epoch': 93.12249, 'eta': 1813.65263, 'eta_hours': 0.50379, 'loss': 0.54403835, 'lr': 0.00012659, 'params': 505766, 'time_iter': 0.149, 'accuracy': 0.80165, 'f1': 0.80164, 'accuracy-SBM': 0.80165, 'auc': 0.97039}
2025-08-17 01:01:14,330 - INFO - val: {'epoch': 78, 'time_epoch': 4.47321, 'loss': 0.63004, 'lr': 0, 'params': 505766, 'time_iter': 0.071, 'accuracy': 0.77982, 'f1': 0.77972, 'accuracy-SBM': 0.77967, 'auc': 0.96076}
2025-08-17 01:01:23,505 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:01:23,548 - INFO - test: {'epoch': 78, 'time_epoch': 4.71375, 'loss': 0.6236255, 'lr': 0, 'params': 505766, 'time_iter': 0.07482, 'accuracy': 0.77989, 'f1': 0.77984, 'accuracy-SBM': 0.77992, 'auc': 0.96139}
2025-08-17 01:01:23,553 - INFO - > Epoch 78: took 107.2s (avg 99.7s) | Best so far: epoch 74	train_loss: 0.5494 train_accuracy-SBM: 0.7994	val_loss: 0.6242 val_accuracy-SBM: 0.7812	test_loss: 0.6220 test_accuracy-SBM: 0.7806
2025-08-17 01:01:23,553 - INFO - === Epoch 79 ===
2025-08-17 01:02:52,911 - INFO - train: {'epoch': 79, 'time_epoch': 89.10063, 'eta': 1727.97227, 'eta_hours': 0.47999, 'loss': 0.54222134, 'lr': 0.0001158, 'params': 505766, 'time_iter': 0.14256, 'accuracy': 0.80238, 'f1': 0.80238, 'accuracy-SBM': 0.80238, 'auc': 0.9706}
2025-08-17 01:02:57,403 - INFO - val: {'epoch': 79, 'time_epoch': 4.4364, 'loss': 0.62650927, 'lr': 0, 'params': 505766, 'time_iter': 0.07042, 'accuracy': 0.78141, 'f1': 0.78133, 'accuracy-SBM': 0.7813, 'auc': 0.96139}
2025-08-17 01:03:07,844 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:03:07,886 - INFO - test: {'epoch': 79, 'time_epoch': 4.78561, 'loss': 0.62139123, 'lr': 0, 'params': 505766, 'time_iter': 0.07596, 'accuracy': 0.78103, 'f1': 0.78104, 'accuracy-SBM': 0.78106, 'auc': 0.96187}
2025-08-17 01:03:07,890 - INFO - > Epoch 79: took 104.3s (avg 99.7s) | Best so far: epoch 79	train_loss: 0.5422 train_accuracy-SBM: 0.8024	val_loss: 0.6265 val_accuracy-SBM: 0.7813	test_loss: 0.6214 test_accuracy-SBM: 0.7811
2025-08-17 01:03:07,890 - INFO - === Epoch 80 ===
2025-08-17 01:04:37,652 - INFO - train: {'epoch': 80, 'time_epoch': 89.38829, 'eta': 1642.27494, 'eta_hours': 0.45619, 'loss': 0.54084485, 'lr': 0.00010543, 'params': 505766, 'time_iter': 0.14302, 'accuracy': 0.8026, 'f1': 0.8026, 'accuracy-SBM': 0.8026, 'auc': 0.97075}
2025-08-17 01:04:42,146 - INFO - val: {'epoch': 80, 'time_epoch': 4.43927, 'loss': 0.62706425, 'lr': 0, 'params': 505766, 'time_iter': 0.07046, 'accuracy': 0.78187, 'f1': 0.78175, 'accuracy-SBM': 0.78171, 'auc': 0.96139}
2025-08-17 01:04:51,511 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:04:51,551 - INFO - test: {'epoch': 80, 'time_epoch': 4.66819, 'loss': 0.62542931, 'lr': 0, 'params': 505766, 'time_iter': 0.0741, 'accuracy': 0.78023, 'f1': 0.78024, 'accuracy-SBM': 0.78023, 'auc': 0.9615}
2025-08-17 01:04:51,555 - INFO - > Epoch 80: took 103.7s (avg 99.8s) | Best so far: epoch 80	train_loss: 0.5408 train_accuracy-SBM: 0.8026	val_loss: 0.6271 val_accuracy-SBM: 0.7817	test_loss: 0.6254 test_accuracy-SBM: 0.7802
2025-08-17 01:04:51,555 - INFO - === Epoch 81 ===
2025-08-17 01:06:21,341 - INFO - train: {'epoch': 81, 'time_epoch': 89.42844, 'eta': 1556.4964, 'eta_hours': 0.43236, 'loss': 0.53944347, 'lr': 9.549e-05, 'params': 505766, 'time_iter': 0.14309, 'accuracy': 0.80297, 'f1': 0.80297, 'accuracy-SBM': 0.80297, 'auc': 0.9709}
2025-08-17 01:06:25,850 - INFO - val: {'epoch': 81, 'time_epoch': 4.45171, 'loss': 0.62417722, 'lr': 0, 'params': 505766, 'time_iter': 0.07066, 'accuracy': 0.7811, 'f1': 0.78102, 'accuracy-SBM': 0.78097, 'auc': 0.96156}
2025-08-17 01:06:36,071 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:06:36,111 - INFO - test: {'epoch': 81, 'time_epoch': 4.66932, 'loss': 0.62336574, 'lr': 0, 'params': 505766, 'time_iter': 0.07412, 'accuracy': 0.77946, 'f1': 0.77945, 'accuracy-SBM': 0.7795, 'auc': 0.96158}
2025-08-17 01:06:36,118 - INFO - > Epoch 81: took 104.6s (avg 99.8s) | Best so far: epoch 80	train_loss: 0.5408 train_accuracy-SBM: 0.8026	val_loss: 0.6271 val_accuracy-SBM: 0.7817	test_loss: 0.6254 test_accuracy-SBM: 0.7802
2025-08-17 01:06:36,118 - INFO - === Epoch 82 ===
2025-08-17 01:08:05,017 - INFO - train: {'epoch': 82, 'time_epoch': 88.38653, 'eta': 1470.4165, 'eta_hours': 0.40845, 'loss': 0.539369, 'lr': 8.6e-05, 'params': 505766, 'time_iter': 0.14142, 'accuracy': 0.80333, 'f1': 0.80333, 'accuracy-SBM': 0.80333, 'auc': 0.97092}
2025-08-17 01:08:08,956 - INFO - val: {'epoch': 82, 'time_epoch': 3.87624, 'loss': 0.62565762, 'lr': 0, 'params': 505766, 'time_iter': 0.06153, 'accuracy': 0.78209, 'f1': 0.78197, 'accuracy-SBM': 0.78195, 'auc': 0.96148}
2025-08-17 01:08:20,860 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:08:20,897 - INFO - test: {'epoch': 82, 'time_epoch': 3.91796, 'loss': 0.62291336, 'lr': 0, 'params': 505766, 'time_iter': 0.06219, 'accuracy': 0.7813, 'f1': 0.78126, 'accuracy-SBM': 0.78129, 'auc': 0.96169}
2025-08-17 01:08:20,901 - INFO - > Epoch 82: took 104.8s (avg 99.9s) | Best so far: epoch 82	train_loss: 0.5394 train_accuracy-SBM: 0.8033	val_loss: 0.6257 val_accuracy-SBM: 0.7820	test_loss: 0.6229 test_accuracy-SBM: 0.7813
2025-08-17 01:08:20,901 - INFO - === Epoch 83 ===
2025-08-17 01:09:44,576 - INFO - train: {'epoch': 83, 'time_epoch': 83.28807, 'eta': 1383.31056, 'eta_hours': 0.38425, 'loss': 0.53775746, 'lr': 7.695e-05, 'params': 505766, 'time_iter': 0.13326, 'accuracy': 0.80359, 'f1': 0.80359, 'accuracy-SBM': 0.80359, 'auc': 0.97108}
2025-08-17 01:09:49,152 - INFO - val: {'epoch': 83, 'time_epoch': 4.51085, 'loss': 0.62401996, 'lr': 0, 'params': 505766, 'time_iter': 0.0716, 'accuracy': 0.78369, 'f1': 0.78359, 'accuracy-SBM': 0.78358, 'auc': 0.96162}
2025-08-17 01:10:00,120 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:10:00,161 - INFO - test: {'epoch': 83, 'time_epoch': 4.87094, 'loss': 0.62116683, 'lr': 0, 'params': 505766, 'time_iter': 0.07732, 'accuracy': 0.78091, 'f1': 0.78089, 'accuracy-SBM': 0.78089, 'auc': 0.96191}
2025-08-17 01:10:00,166 - INFO - > Epoch 83: took 99.3s (avg 99.9s) | Best so far: epoch 83	train_loss: 0.5378 train_accuracy-SBM: 0.8036	val_loss: 0.6240 val_accuracy-SBM: 0.7836	test_loss: 0.6212 test_accuracy-SBM: 0.7809
2025-08-17 01:10:00,166 - INFO - === Epoch 84 ===
2025-08-17 01:11:30,447 - INFO - train: {'epoch': 84, 'time_epoch': 90.02846, 'eta': 1297.48392, 'eta_hours': 0.36041, 'loss': 0.53701188, 'lr': 6.837e-05, 'params': 505766, 'time_iter': 0.14405, 'accuracy': 0.80424, 'f1': 0.80423, 'accuracy-SBM': 0.80424, 'auc': 0.97116}
2025-08-17 01:11:34,788 - INFO - val: {'epoch': 84, 'time_epoch': 4.29046, 'loss': 0.61746134, 'lr': 0, 'params': 505766, 'time_iter': 0.0681, 'accuracy': 0.78349, 'f1': 0.78336, 'accuracy-SBM': 0.78333, 'auc': 0.96224}
2025-08-17 01:11:44,208 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:11:44,251 - INFO - test: {'epoch': 84, 'time_epoch': 4.57473, 'loss': 0.62430509, 'lr': 0, 'params': 505766, 'time_iter': 0.07261, 'accuracy': 0.78018, 'f1': 0.78015, 'accuracy-SBM': 0.78016, 'auc': 0.96142}
2025-08-17 01:11:44,255 - INFO - > Epoch 84: took 104.1s (avg 99.9s) | Best so far: epoch 83	train_loss: 0.5378 train_accuracy-SBM: 0.8036	val_loss: 0.6240 val_accuracy-SBM: 0.7836	test_loss: 0.6212 test_accuracy-SBM: 0.7809
2025-08-17 01:11:44,256 - INFO - === Epoch 85 ===
2025-08-17 01:13:13,719 - INFO - train: {'epoch': 85, 'time_epoch': 89.0168, 'eta': 1211.39488, 'eta_hours': 0.3365, 'loss': 0.53520985, 'lr': 6.026e-05, 'params': 505766, 'time_iter': 0.14243, 'accuracy': 0.80475, 'f1': 0.80475, 'accuracy-SBM': 0.80475, 'auc': 0.97134}
2025-08-17 01:13:18,334 - INFO - val: {'epoch': 85, 'time_epoch': 4.55798, 'loss': 0.62235847, 'lr': 0, 'params': 505766, 'time_iter': 0.07235, 'accuracy': 0.78399, 'f1': 0.78388, 'accuracy-SBM': 0.78386, 'auc': 0.96187}
2025-08-17 01:13:28,397 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:13:28,442 - INFO - test: {'epoch': 85, 'time_epoch': 4.58995, 'loss': 0.62330412, 'lr': 0, 'params': 505766, 'time_iter': 0.07286, 'accuracy': 0.78054, 'f1': 0.78055, 'accuracy-SBM': 0.78055, 'auc': 0.96172}
2025-08-17 01:13:28,446 - INFO - > Epoch 85: took 104.2s (avg 100.0s) | Best so far: epoch 85	train_loss: 0.5352 train_accuracy-SBM: 0.8047	val_loss: 0.6224 val_accuracy-SBM: 0.7839	test_loss: 0.6233 test_accuracy-SBM: 0.7805
2025-08-17 01:13:28,446 - INFO - === Epoch 86 ===
2025-08-17 01:14:57,110 - INFO - train: {'epoch': 86, 'time_epoch': 88.41111, 'eta': 1125.14802, 'eta_hours': 0.31254, 'loss': 0.53485, 'lr': 5.264e-05, 'params': 505766, 'time_iter': 0.14146, 'accuracy': 0.80519, 'f1': 0.80519, 'accuracy-SBM': 0.80519, 'auc': 0.9714}
2025-08-17 01:15:01,456 - INFO - val: {'epoch': 86, 'time_epoch': 4.29316, 'loss': 0.6210718, 'lr': 0, 'params': 505766, 'time_iter': 0.06815, 'accuracy': 0.78303, 'f1': 0.78286, 'accuracy-SBM': 0.78284, 'auc': 0.962}
2025-08-17 01:15:12,122 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:15:12,162 - INFO - test: {'epoch': 86, 'time_epoch': 4.32471, 'loss': 0.62275819, 'lr': 0, 'params': 505766, 'time_iter': 0.06865, 'accuracy': 0.7811, 'f1': 0.7811, 'accuracy-SBM': 0.78111, 'auc': 0.96174}
2025-08-17 01:15:12,170 - INFO - > Epoch 86: took 103.7s (avg 100.0s) | Best so far: epoch 85	train_loss: 0.5352 train_accuracy-SBM: 0.8047	val_loss: 0.6224 val_accuracy-SBM: 0.7839	test_loss: 0.6233 test_accuracy-SBM: 0.7805
2025-08-17 01:15:12,170 - INFO - === Epoch 87 ===
2025-08-17 01:16:33,553 - INFO - train: {'epoch': 87, 'time_epoch': 81.14127, 'eta': 1037.86064, 'eta_hours': 0.28829, 'loss': 0.53448947, 'lr': 4.55e-05, 'params': 505766, 'time_iter': 0.12983, 'accuracy': 0.80514, 'f1': 0.80514, 'accuracy-SBM': 0.80514, 'auc': 0.97143}
2025-08-17 01:16:37,631 - INFO - val: {'epoch': 87, 'time_epoch': 4.02193, 'loss': 0.62414734, 'lr': 0, 'params': 505766, 'time_iter': 0.06384, 'accuracy': 0.78279, 'f1': 0.78268, 'accuracy-SBM': 0.78267, 'auc': 0.96163}
2025-08-17 01:16:48,943 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:16:48,986 - INFO - test: {'epoch': 87, 'time_epoch': 4.27318, 'loss': 0.62033362, 'lr': 0, 'params': 505766, 'time_iter': 0.06783, 'accuracy': 0.7813, 'f1': 0.78127, 'accuracy-SBM': 0.78128, 'auc': 0.96195}
2025-08-17 01:16:48,989 - INFO - > Epoch 87: took 96.8s (avg 100.0s) | Best so far: epoch 85	train_loss: 0.5352 train_accuracy-SBM: 0.8047	val_loss: 0.6224 val_accuracy-SBM: 0.7839	test_loss: 0.6233 test_accuracy-SBM: 0.7805
2025-08-17 01:16:48,989 - INFO - === Epoch 88 ===
2025-08-17 01:18:17,315 - INFO - train: {'epoch': 88, 'time_epoch': 88.03557, 'eta': 951.56348, 'eta_hours': 0.26432, 'loss': 0.53397044, 'lr': 3.886e-05, 'params': 505766, 'time_iter': 0.14086, 'accuracy': 0.80499, 'f1': 0.80499, 'accuracy-SBM': 0.80499, 'auc': 0.97149}
2025-08-17 01:18:21,727 - INFO - val: {'epoch': 88, 'time_epoch': 4.36309, 'loss': 0.62475263, 'lr': 0, 'params': 505766, 'time_iter': 0.06926, 'accuracy': 0.78187, 'f1': 0.78175, 'accuracy-SBM': 0.78173, 'auc': 0.96159}
2025-08-17 01:18:29,212 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:18:29,259 - INFO - test: {'epoch': 88, 'time_epoch': 4.65959, 'loss': 0.62445723, 'lr': 0, 'params': 505766, 'time_iter': 0.07396, 'accuracy': 0.78064, 'f1': 0.78062, 'accuracy-SBM': 0.78063, 'auc': 0.96151}
2025-08-17 01:18:29,261 - INFO - > Epoch 88: took 100.3s (avg 100.0s) | Best so far: epoch 85	train_loss: 0.5352 train_accuracy-SBM: 0.8047	val_loss: 0.6224 val_accuracy-SBM: 0.7839	test_loss: 0.6233 test_accuracy-SBM: 0.7805
2025-08-17 01:18:29,262 - INFO - === Epoch 89 ===
2025-08-17 01:19:58,512 - INFO - train: {'epoch': 89, 'time_epoch': 88.99003, 'eta': 865.33374, 'eta_hours': 0.24037, 'loss': 0.53156512, 'lr': 3.272e-05, 'params': 505766, 'time_iter': 0.14238, 'accuracy': 0.8065, 'f1': 0.8065, 'accuracy-SBM': 0.8065, 'auc': 0.97174}
2025-08-17 01:20:02,872 - INFO - val: {'epoch': 89, 'time_epoch': 4.31468, 'loss': 0.62393791, 'lr': 0, 'params': 505766, 'time_iter': 0.06849, 'accuracy': 0.7821, 'f1': 0.78197, 'accuracy-SBM': 0.78196, 'auc': 0.9616}
2025-08-17 01:20:12,252 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:20:12,298 - INFO - test: {'epoch': 89, 'time_epoch': 4.69892, 'loss': 0.62481126, 'lr': 0, 'params': 505766, 'time_iter': 0.07459, 'accuracy': 0.78017, 'f1': 0.78015, 'accuracy-SBM': 0.78014, 'auc': 0.96141}
2025-08-17 01:20:12,303 - INFO - > Epoch 89: took 103.0s (avg 100.0s) | Best so far: epoch 85	train_loss: 0.5352 train_accuracy-SBM: 0.8047	val_loss: 0.6224 val_accuracy-SBM: 0.7839	test_loss: 0.6233 test_accuracy-SBM: 0.7805
2025-08-17 01:20:12,303 - INFO - === Epoch 90 ===
2025-08-17 01:21:42,775 - INFO - train: {'epoch': 90, 'time_epoch': 90.08029, 'eta': 779.15116, 'eta_hours': 0.21643, 'loss': 0.53295899, 'lr': 2.709e-05, 'params': 505766, 'time_iter': 0.14413, 'accuracy': 0.80589, 'f1': 0.80589, 'accuracy-SBM': 0.80589, 'auc': 0.97159}
2025-08-17 01:21:47,770 - INFO - val: {'epoch': 90, 'time_epoch': 4.9381, 'loss': 0.62239042, 'lr': 0, 'params': 505766, 'time_iter': 0.07838, 'accuracy': 0.78284, 'f1': 0.7827, 'accuracy-SBM': 0.78268, 'auc': 0.96181}
2025-08-17 01:21:57,073 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:21:57,114 - INFO - test: {'epoch': 90, 'time_epoch': 5.29001, 'loss': 0.62621149, 'lr': 0, 'params': 505766, 'time_iter': 0.08397, 'accuracy': 0.78023, 'f1': 0.78019, 'accuracy-SBM': 0.78019, 'auc': 0.96128}
2025-08-17 01:21:57,119 - INFO - > Epoch 90: took 104.8s (avg 100.1s) | Best so far: epoch 85	train_loss: 0.5352 train_accuracy-SBM: 0.8047	val_loss: 0.6224 val_accuracy-SBM: 0.7839	test_loss: 0.6233 test_accuracy-SBM: 0.7805
2025-08-17 01:21:57,119 - INFO - === Epoch 91 ===
2025-08-17 01:23:28,469 - INFO - train: {'epoch': 91, 'time_epoch': 91.09053, 'eta': 692.97169, 'eta_hours': 0.19249, 'loss': 0.53260726, 'lr': 2.198e-05, 'params': 505766, 'time_iter': 0.14574, 'accuracy': 0.80589, 'f1': 0.80589, 'accuracy-SBM': 0.80589, 'auc': 0.97163}
2025-08-17 01:23:32,977 - INFO - val: {'epoch': 91, 'time_epoch': 4.45385, 'loss': 0.6248576, 'lr': 0, 'params': 505766, 'time_iter': 0.0707, 'accuracy': 0.78301, 'f1': 0.78287, 'accuracy-SBM': 0.78286, 'auc': 0.9616}
2025-08-17 01:23:39,485 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:23:39,526 - INFO - test: {'epoch': 91, 'time_epoch': 4.60781, 'loss': 0.6246746, 'lr': 0, 'params': 505766, 'time_iter': 0.07314, 'accuracy': 0.78095, 'f1': 0.78093, 'accuracy-SBM': 0.78093, 'auc': 0.96152}
2025-08-17 01:23:39,527 - INFO - > Epoch 91: took 102.4s (avg 100.1s) | Best so far: epoch 85	train_loss: 0.5352 train_accuracy-SBM: 0.8047	val_loss: 0.6224 val_accuracy-SBM: 0.7839	test_loss: 0.6233 test_accuracy-SBM: 0.7805
2025-08-17 01:23:39,528 - INFO - === Epoch 92 ===
2025-08-17 01:25:08,962 - INFO - train: {'epoch': 92, 'time_epoch': 89.16671, 'eta': 606.54181, 'eta_hours': 0.16848, 'loss': 0.53068623, 'lr': 1.74e-05, 'params': 505766, 'time_iter': 0.14267, 'accuracy': 0.80609, 'f1': 0.80609, 'accuracy-SBM': 0.80609, 'auc': 0.97185}
2025-08-17 01:25:13,523 - INFO - val: {'epoch': 92, 'time_epoch': 4.50441, 'loss': 0.62405392, 'lr': 0, 'params': 505766, 'time_iter': 0.0715, 'accuracy': 0.78383, 'f1': 0.78372, 'accuracy-SBM': 0.7837, 'auc': 0.96173}
2025-08-17 01:25:23,618 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:25:23,658 - INFO - test: {'epoch': 92, 'time_epoch': 4.75814, 'loss': 0.62538457, 'lr': 0, 'params': 505766, 'time_iter': 0.07553, 'accuracy': 0.78103, 'f1': 0.78099, 'accuracy-SBM': 0.78102, 'auc': 0.96148}
2025-08-17 01:25:23,664 - INFO - > Epoch 92: took 104.1s (avg 100.2s) | Best so far: epoch 85	train_loss: 0.5352 train_accuracy-SBM: 0.8047	val_loss: 0.6224 val_accuracy-SBM: 0.7839	test_loss: 0.6233 test_accuracy-SBM: 0.7805
2025-08-17 01:25:23,664 - INFO - === Epoch 93 ===
2025-08-17 01:26:55,019 - INFO - train: {'epoch': 93, 'time_epoch': 91.08862, 'eta': 520.17637, 'eta_hours': 0.14449, 'loss': 0.53159067, 'lr': 1.334e-05, 'params': 505766, 'time_iter': 0.14574, 'accuracy': 0.80565, 'f1': 0.80565, 'accuracy-SBM': 0.80565, 'auc': 0.97175}
2025-08-17 01:26:59,415 - INFO - val: {'epoch': 93, 'time_epoch': 4.34678, 'loss': 0.62462827, 'lr': 0, 'params': 505766, 'time_iter': 0.069, 'accuracy': 0.78272, 'f1': 0.7826, 'accuracy-SBM': 0.78258, 'auc': 0.96164}
2025-08-17 01:27:07,026 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:27:07,064 - INFO - test: {'epoch': 93, 'time_epoch': 4.60038, 'loss': 0.62638127, 'lr': 0, 'params': 505766, 'time_iter': 0.07302, 'accuracy': 0.78083, 'f1': 0.78083, 'accuracy-SBM': 0.78082, 'auc': 0.96133}
2025-08-17 01:27:07,066 - INFO - > Epoch 93: took 103.4s (avg 100.2s) | Best so far: epoch 85	train_loss: 0.5352 train_accuracy-SBM: 0.8047	val_loss: 0.6224 val_accuracy-SBM: 0.7839	test_loss: 0.6233 test_accuracy-SBM: 0.7805
2025-08-17 01:27:07,066 - INFO - === Epoch 94 ===
2025-08-17 01:28:38,848 - INFO - train: {'epoch': 94, 'time_epoch': 91.40809, 'eta': 433.72831, 'eta_hours': 0.12048, 'loss': 0.52960945, 'lr': 9.81e-06, 'params': 505766, 'time_iter': 0.14625, 'accuracy': 0.80672, 'f1': 0.80672, 'accuracy-SBM': 0.80672, 'auc': 0.97195}
2025-08-17 01:28:43,415 - INFO - val: {'epoch': 94, 'time_epoch': 4.51035, 'loss': 0.62257389, 'lr': 0, 'params': 505766, 'time_iter': 0.07159, 'accuracy': 0.78312, 'f1': 0.783, 'accuracy-SBM': 0.783, 'auc': 0.96178}
2025-08-17 01:28:52,890 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:28:52,932 - INFO - test: {'epoch': 94, 'time_epoch': 4.76287, 'loss': 0.62404493, 'lr': 0, 'params': 505766, 'time_iter': 0.0756, 'accuracy': 0.78078, 'f1': 0.78077, 'accuracy-SBM': 0.78078, 'auc': 0.96152}
2025-08-17 01:28:52,936 - INFO - > Epoch 94: took 105.9s (avg 100.2s) | Best so far: epoch 85	train_loss: 0.5352 train_accuracy-SBM: 0.8047	val_loss: 0.6224 val_accuracy-SBM: 0.7839	test_loss: 0.6233 test_accuracy-SBM: 0.7805
2025-08-17 01:28:52,936 - INFO - === Epoch 95 ===
2025-08-17 01:30:20,849 - INFO - train: {'epoch': 95, 'time_epoch': 87.64635, 'eta': 347.02018, 'eta_hours': 0.09639, 'loss': 0.530124, 'lr': 6.82e-06, 'params': 505766, 'time_iter': 0.14023, 'accuracy': 0.80683, 'f1': 0.80683, 'accuracy-SBM': 0.80683, 'auc': 0.9719}
2025-08-17 01:30:25,075 - INFO - val: {'epoch': 95, 'time_epoch': 4.17344, 'loss': 0.6243767, 'lr': 0, 'params': 505766, 'time_iter': 0.06625, 'accuracy': 0.78327, 'f1': 0.78315, 'accuracy-SBM': 0.78314, 'auc': 0.96161}
2025-08-17 01:30:33,842 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:30:33,885 - INFO - test: {'epoch': 95, 'time_epoch': 4.44796, 'loss': 0.62478587, 'lr': 0, 'params': 505766, 'time_iter': 0.0706, 'accuracy': 0.78067, 'f1': 0.78063, 'accuracy-SBM': 0.78066, 'auc': 0.96148}
2025-08-17 01:30:33,891 - INFO - > Epoch 95: took 101.0s (avg 100.3s) | Best so far: epoch 85	train_loss: 0.5352 train_accuracy-SBM: 0.8047	val_loss: 0.6224 val_accuracy-SBM: 0.7839	test_loss: 0.6233 test_accuracy-SBM: 0.7805
2025-08-17 01:30:33,891 - INFO - === Epoch 96 ===
2025-08-17 01:31:59,329 - INFO - train: {'epoch': 96, 'time_epoch': 84.93577, 'eta': 260.20887, 'eta_hours': 0.07228, 'loss': 0.52942255, 'lr': 4.37e-06, 'params': 505766, 'time_iter': 0.1359, 'accuracy': 0.80704, 'f1': 0.80704, 'accuracy-SBM': 0.80704, 'auc': 0.97197}
2025-08-17 01:32:03,515 - INFO - val: {'epoch': 96, 'time_epoch': 4.14035, 'loss': 0.62214173, 'lr': 0, 'params': 505766, 'time_iter': 0.06572, 'accuracy': 0.78288, 'f1': 0.78276, 'accuracy-SBM': 0.78276, 'auc': 0.96192}
2025-08-17 01:32:09,313 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:32:09,351 - INFO - test: {'epoch': 96, 'time_epoch': 4.41626, 'loss': 0.6238992, 'lr': 0, 'params': 505766, 'time_iter': 0.0701, 'accuracy': 0.78064, 'f1': 0.78062, 'accuracy-SBM': 0.78064, 'auc': 0.96162}
2025-08-17 01:32:09,353 - INFO - > Epoch 96: took 95.5s (avg 100.2s) | Best so far: epoch 85	train_loss: 0.5352 train_accuracy-SBM: 0.8047	val_loss: 0.6224 val_accuracy-SBM: 0.7839	test_loss: 0.6233 test_accuracy-SBM: 0.7805
2025-08-17 01:32:09,353 - INFO - === Epoch 97 ===
2025-08-17 01:33:34,006 - INFO - train: {'epoch': 97, 'time_epoch': 84.4217, 'eta': 173.42534, 'eta_hours': 0.04817, 'loss': 0.529569, 'lr': 2.46e-06, 'params': 505766, 'time_iter': 0.13507, 'accuracy': 0.807, 'f1': 0.807, 'accuracy-SBM': 0.807, 'auc': 0.97195}
2025-08-17 01:33:38,167 - INFO - val: {'epoch': 97, 'time_epoch': 4.11115, 'loss': 0.62263583, 'lr': 0, 'params': 505766, 'time_iter': 0.06526, 'accuracy': 0.78296, 'f1': 0.78283, 'accuracy-SBM': 0.78281, 'auc': 0.96177}
2025-08-17 01:33:47,519 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:33:47,560 - INFO - test: {'epoch': 97, 'time_epoch': 4.38252, 'loss': 0.62247487, 'lr': 0, 'params': 505766, 'time_iter': 0.06956, 'accuracy': 0.78099, 'f1': 0.78098, 'accuracy-SBM': 0.78099, 'auc': 0.96168}
2025-08-17 01:33:47,564 - INFO - > Epoch 97: took 98.2s (avg 100.2s) | Best so far: epoch 85	train_loss: 0.5352 train_accuracy-SBM: 0.8047	val_loss: 0.6224 val_accuracy-SBM: 0.7839	test_loss: 0.6233 test_accuracy-SBM: 0.7805
2025-08-17 01:33:47,565 - INFO - === Epoch 98 ===
2025-08-17 01:35:11,730 - INFO - train: {'epoch': 98, 'time_epoch': 83.94225, 'eta': 86.68469, 'eta_hours': 0.02408, 'loss': 0.52960448, 'lr': 1.09e-06, 'params': 505766, 'time_iter': 0.13431, 'accuracy': 0.80669, 'f1': 0.80668, 'accuracy-SBM': 0.80669, 'auc': 0.97195}
2025-08-17 01:35:15,574 - INFO - val: {'epoch': 98, 'time_epoch': 3.79647, 'loss': 0.62271136, 'lr': 0, 'params': 505766, 'time_iter': 0.06026, 'accuracy': 0.78331, 'f1': 0.78319, 'accuracy-SBM': 0.78318, 'auc': 0.96176}
2025-08-17 01:35:24,030 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:35:24,065 - INFO - test: {'epoch': 98, 'time_epoch': 4.06922, 'loss': 0.62442349, 'lr': 0, 'params': 505766, 'time_iter': 0.06459, 'accuracy': 0.78073, 'f1': 0.78072, 'accuracy-SBM': 0.78072, 'auc': 0.96147}
2025-08-17 01:35:24,070 - INFO - > Epoch 98: took 96.5s (avg 100.1s) | Best so far: epoch 85	train_loss: 0.5352 train_accuracy-SBM: 0.8047	val_loss: 0.6224 val_accuracy-SBM: 0.7839	test_loss: 0.6233 test_accuracy-SBM: 0.7805
2025-08-17 01:35:24,070 - INFO - === Epoch 99 ===
2025-08-17 01:36:42,242 - INFO - train: {'epoch': 99, 'time_epoch': 77.95169, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.53046527, 'lr': 2.7e-07, 'params': 505766, 'time_iter': 0.12472, 'accuracy': 0.80615, 'f1': 0.80615, 'accuracy-SBM': 0.80615, 'auc': 0.97188}
2025-08-17 01:36:46,121 - INFO - val: {'epoch': 99, 'time_epoch': 3.83212, 'loss': 0.62242541, 'lr': 0, 'params': 505766, 'time_iter': 0.06083, 'accuracy': 0.78323, 'f1': 0.78311, 'accuracy-SBM': 0.7831, 'auc': 0.96185}
2025-08-17 01:36:55,104 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-49/test_results
2025-08-17 01:36:55,140 - INFO - test: {'epoch': 99, 'time_epoch': 4.07385, 'loss': 0.62429544, 'lr': 0, 'params': 505766, 'time_iter': 0.06466, 'accuracy': 0.78051, 'f1': 0.78049, 'accuracy-SBM': 0.78051, 'auc': 0.96155}
2025-08-17 01:36:55,483 - INFO - > Epoch 99: took 91.1s (avg 100.1s) | Best so far: epoch 85	train_loss: 0.5352 train_accuracy-SBM: 0.8047	val_loss: 0.6224 val_accuracy-SBM: 0.7839	test_loss: 0.6233 test_accuracy-SBM: 0.7805
2025-08-17 01:36:55,484 - INFO - ================================================================================
2025-08-17 01:36:55,484 - INFO - NAS TRAINING COMPLETED SUCCESSFULLY
2025-08-17 01:36:55,484 - INFO - ================================================================================
2025-08-17 01:36:55,484 - INFO - Avg time per epoch: 100.06s
2025-08-17 01:36:55,484 - INFO - Total train loop time: 2.78h
2025-08-17 01:36:55,484 - INFO - Routing mode: nas
2025-08-17 01:36:55,484 - INFO - Final optimal weights: {'layer_0': 2, 'layer_1': 1, 'layer_2': 1, 'layer_3': 2, 'layer_4': 2, 'layer_5': 2, 'layer_6': 1, 'layer_7': 2, 'layer_8': 1, 'layer_9': 2, 'layer_10': 1, 'layer_11': 1, 'layer_12': 1, 'layer_13': 1, 'layer_14': 1, 'layer_15': 2}
2025-08-17 01:36:55,484 - INFO - Results include routing uncertainty (test only, NO variance)
