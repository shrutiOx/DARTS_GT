Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          376Gi        14Gi       344Gi       1.5Gi        17Gi       357Gi
Swap:         1.9Gi       657Mi       1.2Gi
Sat Aug 16 12:16:38 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:1D:00.0 Off |                    0 |
| N/A   34C    P0             41W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 45
Starting training for seed 45...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E/confignas.yaml
Using device: cuda
2025-08-16 12:16:52,231 - INFO - GPU Mem: 34.1GB
2025-08-16 12:16:52,231 - INFO - Run directory: results/Cluster/Cluster-SparseE-45
2025-08-16 12:16:52,231 - INFO - Seed: 45
2025-08-16 12:16:52,231 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-16 12:16:52,232 - INFO - Routing mode: nas
2025-08-16 12:16:52,232 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-16 12:16:52,232 - INFO - Number of layers: 16
2025-08-16 12:16:52,232 - INFO - Uncertainty enabled: False
2025-08-16 12:16:52,232 - INFO - Training mode: NoMixNas_uncertainty_train
2025-08-16 12:16:52,232 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-16 12:16:52,232 - INFO - Additional features: Router weights logging + JSON export
2025-08-16 12:17:06,036 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 12:17:06,037 - INFO -   Data(x=[1406436, 7], edge_index=[2, 51620680], y=[1406436])
2025-08-16 12:17:06,069 - INFO -   undirected: True
2025-08-16 12:17:06,069 - INFO -   num graphs: 12000
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 12:17:06,070 - INFO -   avg num_nodes/graph: 117
2025-08-16 12:17:06,070 - INFO -   num node features: 7
2025-08-16 12:17:06,070 - INFO -   num edge features: 0
2025-08-16 12:17:06,071 - INFO -   num classes: 6
2025-08-16 12:17:06,072 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 4, 8, 16]
2025-08-16 12:17:06,072 - INFO - Precomputing Positional Encoding statistics: ['LapPE', 'RWSE'] for all graphs...
2025-08-16 12:17:06,080 - INFO -   ...estimated to be undirected: True

  0%|          | 0/12000 [00:00<?, ?it/s]
 17%|█▋        | 2003/12000 [00:10<00:49, 200.25it/s]
 33%|███▎      | 3958/12000 [00:20<00:40, 197.43it/s]
 50%|████▉     | 5973/12000 [00:30<00:30, 199.28it/s]
 66%|██████▋   | 7969/12000 [00:40<00:20, 199.40it/s]
 83%|████████▎ | 9963/12000 [00:50<00:10, 199.39it/s]
100%|██████████| 12000/12000 [00:59<00:00, 200.53it/s]
2025-08-16 12:18:06,674 - INFO - Done! Took 00:01:00.60
2025-08-16 12:18:06,707 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset'
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/nni/nas/nn/pytorch/choice.py:252: UserWarning: "key" is deprecated. Assuming label.
  warnings.warn(f'"key" is deprecated. Assuming label.')
2025-08-16 12:18:07,173 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-16 12:18:07,173 - INFO - Inner model type: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-08-16 12:18:07,173 - INFO - Inner model has get_darts_model: True
2025-08-16 12:18:07,179 - INFO - GraphGymModule(
  (model): NASModelEdge(
    (encoder): FeatureEncoder(
      (node_encoder): LapPENodeEncoder(
        (linear_x): Linear(in_features=7, out_features=32, bias=True)
        (linear_A): Linear(in_features=2, out_features=32, bias=True)
        (pe_encoder): Sequential(
          (0): ReLU()
          (1): Linear(in_features=32, out_features=16, bias=True)
          (2): ReLU()
        )
      )
      (edge_encoder): DummyEdgeEncoder(
        (encoder): Embedding(1, 48)
      )
    )
    (darts_layers): ModuleList(
      (0): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (6): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_6')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (7): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_7')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (8): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_8')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (9): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_9')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (10): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_10')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (11): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_11')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (12): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_12')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (13): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_13')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (14): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_14')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (15): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_15')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (darts_sequential): Sequential(
      (0): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (6): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_6')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (7): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_7')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (8): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_8')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (9): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_9')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (10): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_10')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (11): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_11')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (12): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_12')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (13): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_13')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (14): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_14')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (15): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_15')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(48, 48, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(48, 48, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(48, 6, bias=True)
          )
        )
      )
    )
  )
)
2025-08-16 12:18:07,190 - INFO - Number of parameters: 728,630
2025-08-16 12:18:07,190 - INFO - Starting optimized training: 2025-08-16 12:18:07.190446
2025-08-16 12:18:12,691 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset':
2025-08-16 12:18:12,691 - INFO -   Data(x=[1406436, 7], edge_index=[2, 51620680], y=[1406436])
2025-08-16 12:18:12,693 - INFO -   undirected: True
2025-08-16 12:18:12,693 - INFO -   num graphs: 12000
2025-08-16 12:18:12,693 - INFO -   avg num_nodes/graph: 117
2025-08-16 12:18:12,693 - INFO -   num node features: 7
2025-08-16 12:18:12,693 - INFO -   num edge features: 0
2025-08-16 12:18:12,695 - INFO -   num classes: 6
2025-08-16 12:18:12,695 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 4, 8, 16]
2025-08-16 12:18:12,695 - INFO - Precomputing Positional Encoding statistics: ['LapPE', 'RWSE'] for all graphs...
2025-08-16 12:18:12,703 - INFO -   ...estimated to be undirected: True

  0%|          | 0/12000 [00:00<?, ?it/s]
 17%|█▋        | 2076/12000 [00:10<00:47, 207.52it/s]
 35%|███▍      | 4195/12000 [00:20<00:37, 210.03it/s]
 53%|█████▎    | 6301/12000 [00:30<00:27, 210.23it/s]
 69%|██████▉   | 8312/12000 [00:40<00:17, 206.63it/s]
 87%|████████▋ | 10385/12000 [00:50<00:07, 206.87it/s]
100%|██████████| 12000/12000 [00:57<00:00, 208.09it/s]
2025-08-16 12:19:11,111 - INFO - Done! Took 00:00:58.42
2025-08-16 12:19:11,135 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset'
2025-08-16 12:19:11,290 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-16 12:19:11,291 - INFO - Start from epoch 0
2025-08-16 12:19:11,291 - INFO - ================================================================================
2025-08-16 12:19:11,291 - INFO - STARTING TWO-PHASE NAS TRAINING
2025-08-16 12:19:11,291 - INFO - ================================================================================
2025-08-16 12:19:11,291 - INFO - Routing mode: nas
2025-08-16 12:19:11,291 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-16 12:19:11,291 - INFO - Phase 1: Architecture search/initialization
2025-08-16 12:19:11,291 - INFO - Phase 2: Discrete training with uncertainty (NO variance)
2025-08-16 12:19:11,291 - INFO - ============================================================
2025-08-16 12:19:11,291 - INFO - PHASE 1: ARCHITECTURE SEARCH/INITIALIZATION
2025-08-16 12:19:11,291 - INFO - ============================================================
2025-08-16 12:19:11,291 - INFO - Splitting dataset for DARTS:
2025-08-16 12:19:11,291 - INFO -   Original train size: 10000
2025-08-16 12:19:11,291 - INFO -   DARTS train size: 6000 (60.0%)
2025-08-16 12:19:11,291 - INFO -   DARTS val size: 4000 (40.0%)
2025-08-16 12:19:11,292 - INFO - Found GraphGym wrapper, using inner model: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-08-16 12:19:11,292 - INFO - Successfully configured model for DARTS training
2025-08-16 12:19:11,292 - INFO - NAS MODE: Running 25 epochs with DARTS
2025-08-16 12:19:11,292 - INFO - DARTS Configuration:
2025-08-16 12:19:11,292 - INFO -   Epochs: 25
2025-08-16 12:19:11,292 - INFO -   Architecture LR: 0.0004
2025-08-16 12:19:11,293 - INFO -   Grad clip: 5.0
2025-08-16 12:19:11,296 - INFO - Starting DARTS architecture search
2025-08-16 12:19:14,285 - WARNING - Epoch [1/25] Step [1/250]  acc 0.192869 (0.192869)  loss 1.795848 (1.795848)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 3806.0 MB
2025-08-16 12:19:18,703 - WARNING - Epoch [1/25] Step [11/250]  acc 0.188773 (0.171974)  loss 1.789860 (1.794147)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6754.0 MB
2025-08-16 12:19:23,128 - WARNING - Epoch [1/25] Step [21/250]  acc 0.149877 (0.170100)  loss 1.796247 (1.793096)
GPU memory consumption  GPU Memory: Allocated: 60.5 MB, Reserved: 6758.0 MB
2025-08-16 12:19:27,678 - WARNING - Epoch [1/25] Step [31/250]  acc 0.172303 (0.168331)  loss 1.789350 (1.793038)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 6762.0 MB
2025-08-16 12:19:32,081 - WARNING - Epoch [1/25] Step [41/250]  acc 0.163353 (0.169567)  loss 1.790204 (1.792022)
GPU memory consumption  GPU Memory: Allocated: 60.4 MB, Reserved: 6762.0 MB
2025-08-16 12:19:36,472 - WARNING - Epoch [1/25] Step [51/250]  acc 0.215566 (0.172910)  loss 1.782471 (1.790881)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6762.0 MB
2025-08-16 12:19:40,887 - WARNING - Epoch [1/25] Step [61/250]  acc 0.199270 (0.177936)  loss 1.781594 (1.789150)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 6762.0 MB
2025-08-16 12:19:45,338 - WARNING - Epoch [1/25] Step [71/250]  acc 0.224749 (0.181711)  loss 1.767771 (1.787248)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6762.0 MB
2025-08-16 12:19:49,760 - WARNING - Epoch [1/25] Step [81/250]  acc 0.197698 (0.186346)  loss 1.773450 (1.783919)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 6762.0 MB
2025-08-16 12:19:54,162 - WARNING - Epoch [1/25] Step [91/250]  acc 0.212877 (0.191069)  loss 1.750437 (1.780689)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 6762.0 MB
2025-08-16 12:19:58,587 - WARNING - Epoch [1/25] Step [101/250]  acc 0.236141 (0.195651)  loss 1.734961 (1.776510)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6764.0 MB
2025-08-16 12:20:03,033 - WARNING - Epoch [1/25] Step [111/250]  acc 0.197439 (0.198840)  loss 1.796078 (1.773693)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6764.0 MB
2025-08-16 12:20:07,676 - WARNING - Epoch [1/25] Step [121/250]  acc 0.240063 (0.203449)  loss 1.719673 (1.768671)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 6764.0 MB
2025-08-16 12:20:12,092 - WARNING - Epoch [1/25] Step [131/250]  acc 0.247925 (0.207284)  loss 1.683960 (1.763439)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 6764.0 MB
2025-08-16 12:20:16,522 - WARNING - Epoch [1/25] Step [141/250]  acc 0.270974 (0.210830)  loss 1.663375 (1.758591)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6766.0 MB
2025-08-16 12:20:20,946 - WARNING - Epoch [1/25] Step [151/250]  acc 0.229101 (0.213280)  loss 1.694943 (1.754461)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6766.0 MB
2025-08-16 12:20:25,356 - WARNING - Epoch [1/25] Step [161/250]  acc 0.291529 (0.215885)  loss 1.656242 (1.748458)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6768.0 MB
2025-08-16 12:20:29,769 - WARNING - Epoch [1/25] Step [171/250]  acc 0.281170 (0.219040)  loss 1.643703 (1.743079)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 6768.0 MB
2025-08-16 12:20:34,180 - WARNING - Epoch [1/25] Step [181/250]  acc 0.270957 (0.221766)  loss 1.646616 (1.737953)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6768.0 MB
2025-08-16 12:20:38,603 - WARNING - Epoch [1/25] Step [191/250]  acc 0.279148 (0.224515)  loss 1.659386 (1.732784)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6768.0 MB
2025-08-16 12:20:43,025 - WARNING - Epoch [1/25] Step [201/250]  acc 0.276013 (0.226945)  loss 1.610066 (1.728146)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6768.0 MB
2025-08-16 12:20:47,652 - WARNING - Epoch [1/25] Step [211/250]  acc 0.261507 (0.228643)  loss 1.612746 (1.724150)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 6768.0 MB
2025-08-16 12:20:52,076 - WARNING - Epoch [1/25] Step [221/250]  acc 0.263023 (0.230314)  loss 1.633404 (1.720423)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6768.0 MB
2025-08-16 12:20:56,553 - WARNING - Epoch [1/25] Step [231/250]  acc 0.283871 (0.232660)  loss 1.657337 (1.716258)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6768.0 MB
2025-08-16 12:21:01,025 - WARNING - Epoch [1/25] Step [241/250]  acc 0.275439 (0.234549)  loss 1.650969 (1.712365)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6768.0 MB
Epoch 1 completed in 0:01:53.736480
2025-08-16 12:21:32,317 - WARNING - Epoch [2/25] Step [1/250]  acc 0.259762 (0.259762)  loss 1.662632 (1.662632)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6768.0 MB
2025-08-16 12:21:36,778 - WARNING - Epoch [2/25] Step [11/250]  acc 0.298378 (0.291909)  loss 1.616658 (1.625035)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6784.0 MB
2025-08-16 12:21:41,216 - WARNING - Epoch [2/25] Step [21/250]  acc 0.296536 (0.292157)  loss 1.607257 (1.620935)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 6784.0 MB
2025-08-16 12:21:45,652 - WARNING - Epoch [2/25] Step [31/250]  acc 0.321465 (0.295891)  loss 1.602843 (1.609615)
GPU memory consumption  GPU Memory: Allocated: 60.6 MB, Reserved: 6784.0 MB
2025-08-16 12:21:50,093 - WARNING - Epoch [2/25] Step [41/250]  acc 0.290801 (0.297956)  loss 1.610713 (1.608625)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6784.0 MB
2025-08-16 12:21:54,534 - WARNING - Epoch [2/25] Step [51/250]  acc 0.298082 (0.298223)  loss 1.558351 (1.604421)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 6784.0 MB
2025-08-16 12:21:59,013 - WARNING - Epoch [2/25] Step [61/250]  acc 0.314911 (0.299097)  loss 1.558056 (1.600655)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10042.0 MB
2025-08-16 12:22:03,437 - WARNING - Epoch [2/25] Step [71/250]  acc 0.327657 (0.302764)  loss 1.561349 (1.596664)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10042.0 MB
2025-08-16 12:22:08,132 - WARNING - Epoch [2/25] Step [81/250]  acc 0.366320 (0.305760)  loss 1.497159 (1.590779)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 10042.0 MB
2025-08-16 12:22:12,585 - WARNING - Epoch [2/25] Step [91/250]  acc 0.346513 (0.306451)  loss 1.527454 (1.587157)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 10042.0 MB
2025-08-16 12:22:17,026 - WARNING - Epoch [2/25] Step [101/250]  acc 0.346096 (0.307152)  loss 1.518893 (1.583294)
GPU memory consumption  GPU Memory: Allocated: 59.9 MB, Reserved: 10042.0 MB
2025-08-16 12:22:21,482 - WARNING - Epoch [2/25] Step [111/250]  acc 0.305596 (0.308370)  loss 1.558078 (1.579852)
GPU memory consumption  GPU Memory: Allocated: 60.5 MB, Reserved: 10042.0 MB
2025-08-16 12:22:25,928 - WARNING - Epoch [2/25] Step [121/250]  acc 0.347926 (0.311198)  loss 1.560535 (1.576808)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 10042.0 MB
2025-08-16 12:22:30,547 - WARNING - Epoch [2/25] Step [131/250]  acc 0.333693 (0.313243)  loss 1.533095 (1.573865)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 10042.0 MB
2025-08-16 12:22:35,011 - WARNING - Epoch [2/25] Step [141/250]  acc 0.331507 (0.314400)  loss 1.536937 (1.570764)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 10042.0 MB
2025-08-16 12:22:39,498 - WARNING - Epoch [2/25] Step [151/250]  acc 0.314875 (0.316110)  loss 1.507755 (1.566437)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 10042.0 MB
2025-08-16 12:22:44,015 - WARNING - Epoch [2/25] Step [161/250]  acc 0.338252 (0.318232)  loss 1.537464 (1.563127)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 10042.0 MB
2025-08-16 12:22:48,537 - WARNING - Epoch [2/25] Step [171/250]  acc 0.367412 (0.319673)  loss 1.513549 (1.560456)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 10042.0 MB
2025-08-16 12:22:53,053 - WARNING - Epoch [2/25] Step [181/250]  acc 0.320065 (0.320618)  loss 1.515075 (1.557202)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 10042.0 MB
2025-08-16 12:22:57,615 - WARNING - Epoch [2/25] Step [191/250]  acc 0.354779 (0.321543)  loss 1.485414 (1.555089)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 10042.0 MB
2025-08-16 12:23:02,069 - WARNING - Epoch [2/25] Step [201/250]  acc 0.323483 (0.322520)  loss 1.499767 (1.552638)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10042.0 MB
2025-08-16 12:23:06,762 - WARNING - Epoch [2/25] Step [211/250]  acc 0.378867 (0.323366)  loss 1.462417 (1.549837)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 10042.0 MB
2025-08-16 12:23:11,197 - WARNING - Epoch [2/25] Step [221/250]  acc 0.350572 (0.324628)  loss 1.515826 (1.547370)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 10042.0 MB
2025-08-16 12:23:15,641 - WARNING - Epoch [2/25] Step [231/250]  acc 0.309983 (0.325220)  loss 1.597043 (1.546200)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10042.0 MB
2025-08-16 12:23:20,077 - WARNING - Epoch [2/25] Step [241/250]  acc 0.323626 (0.325336)  loss 1.512610 (1.544987)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10042.0 MB
Epoch 2 completed in 0:01:52.219248
2025-08-16 12:23:51,309 - WARNING - Epoch [3/25] Step [1/250]  acc 0.350265 (0.350265)  loss 1.517733 (1.517733)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 10042.0 MB
2025-08-16 12:23:55,770 - WARNING - Epoch [3/25] Step [11/250]  acc 0.352345 (0.361864)  loss 1.497512 (1.474729)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 10042.0 MB
2025-08-16 12:24:00,197 - WARNING - Epoch [3/25] Step [21/250]  acc 0.346323 (0.355740)  loss 1.482421 (1.482868)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10042.0 MB
2025-08-16 12:24:04,654 - WARNING - Epoch [3/25] Step [31/250]  acc 0.352391 (0.356917)  loss 1.455322 (1.478920)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 10042.0 MB
2025-08-16 12:24:09,093 - WARNING - Epoch [3/25] Step [41/250]  acc 0.379255 (0.356607)  loss 1.459850 (1.476015)
GPU memory consumption  GPU Memory: Allocated: 60.7 MB, Reserved: 10042.0 MB
2025-08-16 12:24:13,536 - WARNING - Epoch [3/25] Step [51/250]  acc 0.286621 (0.351721)  loss 1.596959 (1.481493)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 10042.0 MB
2025-08-16 12:24:17,980 - WARNING - Epoch [3/25] Step [61/250]  acc 0.364589 (0.352502)  loss 1.470384 (1.480969)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10042.0 MB
2025-08-16 12:24:22,435 - WARNING - Epoch [3/25] Step [71/250]  acc 0.349165 (0.354261)  loss 1.464048 (1.478891)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10042.0 MB
2025-08-16 12:24:26,862 - WARNING - Epoch [3/25] Step [81/250]  acc 0.342400 (0.353063)  loss 1.479829 (1.477528)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10042.0 MB
2025-08-16 12:24:31,291 - WARNING - Epoch [3/25] Step [91/250]  acc 0.395542 (0.352898)  loss 1.424427 (1.477114)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10042.0 MB
2025-08-16 12:24:35,719 - WARNING - Epoch [3/25] Step [101/250]  acc 0.363064 (0.351711)  loss 1.457452 (1.479415)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10042.0 MB
2025-08-16 12:24:40,420 - WARNING - Epoch [3/25] Step [111/250]  acc 0.352332 (0.352514)  loss 1.486149 (1.478780)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10042.0 MB
2025-08-16 12:24:44,863 - WARNING - Epoch [3/25] Step [121/250]  acc 0.364700 (0.352357)  loss 1.495038 (1.478839)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 10042.0 MB
2025-08-16 12:24:49,308 - WARNING - Epoch [3/25] Step [131/250]  acc 0.350262 (0.352322)  loss 1.478533 (1.478044)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10042.0 MB
2025-08-16 12:24:53,751 - WARNING - Epoch [3/25] Step [141/250]  acc 0.337192 (0.352421)  loss 1.513287 (1.476628)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 10042.0 MB
2025-08-16 12:24:58,185 - WARNING - Epoch [3/25] Step [151/250]  acc 0.310651 (0.353142)  loss 1.537333 (1.476174)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 10042.0 MB
2025-08-16 12:25:02,615 - WARNING - Epoch [3/25] Step [161/250]  acc 0.351379 (0.352886)  loss 1.488986 (1.476441)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 10042.0 MB
2025-08-16 12:25:07,082 - WARNING - Epoch [3/25] Step [171/250]  acc 0.335091 (0.352687)  loss 1.508028 (1.476383)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10042.0 MB
2025-08-16 12:25:11,529 - WARNING - Epoch [3/25] Step [181/250]  acc 0.389321 (0.353122)  loss 1.454147 (1.475463)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 10042.0 MB
2025-08-16 12:25:15,994 - WARNING - Epoch [3/25] Step [191/250]  acc 0.295455 (0.352564)  loss 1.551413 (1.475165)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10042.0 MB
2025-08-16 12:25:20,451 - WARNING - Epoch [3/25] Step [201/250]  acc 0.325516 (0.352519)  loss 1.467893 (1.475020)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 10042.0 MB
2025-08-16 12:25:24,928 - WARNING - Epoch [3/25] Step [211/250]  acc 0.343386 (0.351314)  loss 1.423777 (1.475369)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 10042.0 MB
2025-08-16 12:25:29,377 - WARNING - Epoch [3/25] Step [221/250]  acc 0.331672 (0.351091)  loss 1.501835 (1.474530)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10042.0 MB
2025-08-16 12:25:33,829 - WARNING - Epoch [3/25] Step [231/250]  acc 0.352181 (0.350940)  loss 1.431057 (1.473274)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 10042.0 MB
2025-08-16 12:25:38,276 - WARNING - Epoch [3/25] Step [241/250]  acc 0.344357 (0.350994)  loss 1.436958 (1.472031)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10042.0 MB
Epoch 3 completed in 0:01:51.405702
2025-08-16 12:26:09,735 - WARNING - Epoch [4/25] Step [1/250]  acc 0.330636 (0.330636)  loss 1.489788 (1.489788)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 10042.0 MB
2025-08-16 12:26:14,212 - WARNING - Epoch [4/25] Step [11/250]  acc 0.361828 (0.343216)  loss 1.498762 (1.465660)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 10042.0 MB
2025-08-16 12:26:18,678 - WARNING - Epoch [4/25] Step [21/250]  acc 0.318970 (0.348035)  loss 1.489169 (1.458736)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10042.0 MB
2025-08-16 12:26:23,150 - WARNING - Epoch [4/25] Step [31/250]  acc 0.336585 (0.352947)  loss 1.478945 (1.454407)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10042.0 MB
2025-08-16 12:26:27,632 - WARNING - Epoch [4/25] Step [41/250]  acc 0.325260 (0.347784)  loss 1.431065 (1.457951)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 10042.0 MB
2025-08-16 12:26:32,140 - WARNING - Epoch [4/25] Step [51/250]  acc 0.344542 (0.346904)  loss 1.440724 (1.455101)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10042.0 MB
2025-08-16 12:26:36,606 - WARNING - Epoch [4/25] Step [61/250]  acc 0.356113 (0.347863)  loss 1.510528 (1.455620)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 10042.0 MB
2025-08-16 12:26:41,048 - WARNING - Epoch [4/25] Step [71/250]  acc 0.332287 (0.347320)  loss 1.439612 (1.456001)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10042.0 MB
2025-08-16 12:26:45,495 - WARNING - Epoch [4/25] Step [81/250]  acc 0.378571 (0.347710)  loss 1.469799 (1.456931)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10042.0 MB
2025-08-16 12:26:49,946 - WARNING - Epoch [4/25] Step [91/250]  acc 0.374932 (0.349164)  loss 1.386657 (1.455111)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 10042.0 MB
2025-08-16 12:26:54,413 - WARNING - Epoch [4/25] Step [101/250]  acc 0.347488 (0.349234)  loss 1.551972 (1.455337)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 10042.0 MB
2025-08-16 12:26:58,875 - WARNING - Epoch [4/25] Step [111/250]  acc 0.368507 (0.348512)  loss 1.387852 (1.454168)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10042.0 MB
2025-08-16 12:27:03,362 - WARNING - Epoch [4/25] Step [121/250]  acc 0.364511 (0.349488)  loss 1.426382 (1.451873)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 10042.0 MB
2025-08-16 12:27:07,844 - WARNING - Epoch [4/25] Step [131/250]  acc 0.361910 (0.349754)  loss 1.413565 (1.451250)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10042.0 MB
2025-08-16 12:27:12,290 - WARNING - Epoch [4/25] Step [141/250]  acc 0.316263 (0.350631)  loss 1.510066 (1.449887)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 10042.0 MB
2025-08-16 12:27:17,001 - WARNING - Epoch [4/25] Step [151/250]  acc 0.352211 (0.351137)  loss 1.412877 (1.449545)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 10042.0 MB
2025-08-16 12:27:21,481 - WARNING - Epoch [4/25] Step [161/250]  acc 0.333158 (0.351085)  loss 1.422473 (1.448840)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10042.0 MB
2025-08-16 12:27:25,941 - WARNING - Epoch [4/25] Step [171/250]  acc 0.366416 (0.351782)  loss 1.446127 (1.448134)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 10042.0 MB
2025-08-16 12:27:30,405 - WARNING - Epoch [4/25] Step [181/250]  acc 0.375335 (0.352608)  loss 1.401444 (1.446778)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 10042.0 MB
2025-08-16 12:27:34,872 - WARNING - Epoch [4/25] Step [191/250]  acc 0.393305 (0.352747)  loss 1.426630 (1.446826)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 10042.0 MB
2025-08-16 12:27:39,358 - WARNING - Epoch [4/25] Step [201/250]  acc 0.309768 (0.352818)  loss 1.537952 (1.446282)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 10042.0 MB
2025-08-16 12:27:43,856 - WARNING - Epoch [4/25] Step [211/250]  acc 0.358867 (0.353046)  loss 1.477857 (1.445836)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 10042.0 MB
2025-08-16 12:27:48,305 - WARNING - Epoch [4/25] Step [221/250]  acc 0.387672 (0.353214)  loss 1.423030 (1.445778)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10042.0 MB
2025-08-16 12:27:52,783 - WARNING - Epoch [4/25] Step [231/250]  acc 0.373591 (0.353305)  loss 1.459277 (1.446100)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 10042.0 MB
2025-08-16 12:27:57,236 - WARNING - Epoch [4/25] Step [241/250]  acc 0.346894 (0.352855)  loss 1.423198 (1.446720)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10042.0 MB
Epoch 4 completed in 0:01:51.941642
2025-08-16 12:28:28,421 - WARNING - Epoch [5/25] Step [1/250]  acc 0.374332 (0.374332)  loss 1.465409 (1.465409)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 10042.0 MB
2025-08-16 12:28:32,905 - WARNING - Epoch [5/25] Step [11/250]  acc 0.380161 (0.376146)  loss 1.456920 (1.433710)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 10042.0 MB
2025-08-16 12:28:37,369 - WARNING - Epoch [5/25] Step [21/250]  acc 0.386838 (0.367842)  loss 1.355711 (1.439326)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10042.0 MB
2025-08-16 12:28:41,826 - WARNING - Epoch [5/25] Step [31/250]  acc 0.334054 (0.363827)  loss 1.477992 (1.435804)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 10042.0 MB
2025-08-16 12:28:46,298 - WARNING - Epoch [5/25] Step [41/250]  acc 0.399784 (0.365361)  loss 1.462133 (1.433733)
GPU memory consumption  GPU Memory: Allocated: 60.1 MB, Reserved: 10042.0 MB
2025-08-16 12:28:50,801 - WARNING - Epoch [5/25] Step [51/250]  acc 0.335144 (0.363449)  loss 1.468416 (1.434981)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10042.0 MB
2025-08-16 12:28:55,546 - WARNING - Epoch [5/25] Step [61/250]  acc 0.341667 (0.362281)  loss 1.431347 (1.435534)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10042.0 MB
2025-08-16 12:29:00,015 - WARNING - Epoch [5/25] Step [71/250]  acc 0.366036 (0.360600)  loss 1.428427 (1.439111)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 10048.0 MB
2025-08-16 12:29:04,485 - WARNING - Epoch [5/25] Step [81/250]  acc 0.339652 (0.359467)  loss 1.495052 (1.442253)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 10048.0 MB
2025-08-16 12:29:08,961 - WARNING - Epoch [5/25] Step [91/250]  acc 0.334574 (0.357482)  loss 1.432632 (1.442999)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 10048.0 MB
2025-08-16 12:29:13,425 - WARNING - Epoch [5/25] Step [101/250]  acc 0.412933 (0.356783)  loss 1.392370 (1.442695)
GPU memory consumption  GPU Memory: Allocated: 59.9 MB, Reserved: 10048.0 MB
2025-08-16 12:29:17,921 - WARNING - Epoch [5/25] Step [111/250]  acc 0.372250 (0.356959)  loss 1.399999 (1.442813)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:29:22,416 - WARNING - Epoch [5/25] Step [121/250]  acc 0.364070 (0.356133)  loss 1.358753 (1.442804)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 10048.0 MB
2025-08-16 12:29:26,897 - WARNING - Epoch [5/25] Step [131/250]  acc 0.359676 (0.354861)  loss 1.414145 (1.444432)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 10048.0 MB
2025-08-16 12:29:31,402 - WARNING - Epoch [5/25] Step [141/250]  acc 0.376727 (0.356186)  loss 1.425819 (1.442434)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 10048.0 MB
2025-08-16 12:29:35,869 - WARNING - Epoch [5/25] Step [151/250]  acc 0.357993 (0.356733)  loss 1.390674 (1.440376)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10048.0 MB
2025-08-16 12:29:40,344 - WARNING - Epoch [5/25] Step [161/250]  acc 0.385762 (0.356419)  loss 1.450505 (1.440430)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 10048.0 MB
2025-08-16 12:29:44,817 - WARNING - Epoch [5/25] Step [171/250]  acc 0.367639 (0.356806)  loss 1.346559 (1.438810)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:29:49,289 - WARNING - Epoch [5/25] Step [181/250]  acc 0.332188 (0.355977)  loss 1.492980 (1.440569)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 10048.0 MB
2025-08-16 12:29:53,754 - WARNING - Epoch [5/25] Step [191/250]  acc 0.359563 (0.355916)  loss 1.438773 (1.439684)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 10048.0 MB
2025-08-16 12:29:58,241 - WARNING - Epoch [5/25] Step [201/250]  acc 0.374432 (0.356060)  loss 1.413215 (1.438722)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 10048.0 MB
2025-08-16 12:30:02,967 - WARNING - Epoch [5/25] Step [211/250]  acc 0.356865 (0.355870)  loss 1.485059 (1.439187)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:30:07,478 - WARNING - Epoch [5/25] Step [221/250]  acc 0.292776 (0.355221)  loss 1.596840 (1.439793)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 10048.0 MB
2025-08-16 12:30:11,969 - WARNING - Epoch [5/25] Step [231/250]  acc 0.349622 (0.355026)  loss 1.430425 (1.439552)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 10048.0 MB
2025-08-16 12:30:16,435 - WARNING - Epoch [5/25] Step [241/250]  acc 0.365141 (0.355298)  loss 1.424697 (1.439026)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
Epoch 5 completed in 0:01:52.488070
2025-08-16 12:30:47,707 - WARNING - Epoch [6/25] Step [1/250]  acc 0.392385 (0.392385)  loss 1.413871 (1.413871)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 10048.0 MB
2025-08-16 12:30:52,240 - WARNING - Epoch [6/25] Step [11/250]  acc 0.364298 (0.365709)  loss 1.342333 (1.416679)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:30:56,730 - WARNING - Epoch [6/25] Step [21/250]  acc 0.399796 (0.361841)  loss 1.419612 (1.419955)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10048.0 MB
2025-08-16 12:31:01,226 - WARNING - Epoch [6/25] Step [31/250]  acc 0.368114 (0.362237)  loss 1.453525 (1.420311)
GPU memory consumption  GPU Memory: Allocated: 60.6 MB, Reserved: 10048.0 MB
2025-08-16 12:31:05,716 - WARNING - Epoch [6/25] Step [41/250]  acc 0.375706 (0.361862)  loss 1.422179 (1.421187)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10048.0 MB
2025-08-16 12:31:10,206 - WARNING - Epoch [6/25] Step [51/250]  acc 0.395980 (0.359810)  loss 1.403724 (1.424047)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 10048.0 MB
2025-08-16 12:31:14,698 - WARNING - Epoch [6/25] Step [61/250]  acc 0.333333 (0.358585)  loss 1.493901 (1.427053)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:31:19,170 - WARNING - Epoch [6/25] Step [71/250]  acc 0.335036 (0.357841)  loss 1.417128 (1.425652)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 10048.0 MB
2025-08-16 12:31:23,657 - WARNING - Epoch [6/25] Step [81/250]  acc 0.297884 (0.355844)  loss 1.577991 (1.428354)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 10048.0 MB
2025-08-16 12:31:28,128 - WARNING - Epoch [6/25] Step [91/250]  acc 0.361828 (0.354772)  loss 1.379106 (1.429955)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 10048.0 MB
2025-08-16 12:31:32,596 - WARNING - Epoch [6/25] Step [101/250]  acc 0.353612 (0.354573)  loss 1.420065 (1.429643)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 10048.0 MB
2025-08-16 12:31:37,062 - WARNING - Epoch [6/25] Step [111/250]  acc 0.353273 (0.355730)  loss 1.417110 (1.428965)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:31:41,801 - WARNING - Epoch [6/25] Step [121/250]  acc 0.394867 (0.355548)  loss 1.359096 (1.428824)
GPU memory consumption  GPU Memory: Allocated: 60.5 MB, Reserved: 10048.0 MB
2025-08-16 12:31:46,301 - WARNING - Epoch [6/25] Step [131/250]  acc 0.320247 (0.355994)  loss 1.415162 (1.427106)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:31:50,771 - WARNING - Epoch [6/25] Step [141/250]  acc 0.345836 (0.356113)  loss 1.417982 (1.428673)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 10048.0 MB
2025-08-16 12:31:55,255 - WARNING - Epoch [6/25] Step [151/250]  acc 0.407591 (0.356239)  loss 1.324106 (1.428361)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10048.0 MB
2025-08-16 12:31:59,727 - WARNING - Epoch [6/25] Step [161/250]  acc 0.407657 (0.356882)  loss 1.260508 (1.425696)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 10048.0 MB
2025-08-16 12:32:04,232 - WARNING - Epoch [6/25] Step [171/250]  acc 0.330614 (0.357298)  loss 1.480560 (1.425352)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 10048.0 MB
2025-08-16 12:32:08,714 - WARNING - Epoch [6/25] Step [181/250]  acc 0.309838 (0.357695)  loss 1.510063 (1.425099)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 10048.0 MB
2025-08-16 12:32:13,201 - WARNING - Epoch [6/25] Step [191/250]  acc 0.381032 (0.357892)  loss 1.397385 (1.426046)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:32:17,703 - WARNING - Epoch [6/25] Step [201/250]  acc 0.349549 (0.357737)  loss 1.365322 (1.426621)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10048.0 MB
2025-08-16 12:32:22,232 - WARNING - Epoch [6/25] Step [211/250]  acc 0.381393 (0.357196)  loss 1.376689 (1.426225)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 10048.0 MB
2025-08-16 12:32:26,733 - WARNING - Epoch [6/25] Step [221/250]  acc 0.334251 (0.356865)  loss 1.458166 (1.426249)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:32:31,217 - WARNING - Epoch [6/25] Step [231/250]  acc 0.373520 (0.356554)  loss 1.404735 (1.426315)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 10048.0 MB
2025-08-16 12:32:35,694 - WARNING - Epoch [6/25] Step [241/250]  acc 0.348384 (0.356417)  loss 1.399904 (1.425975)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
Epoch 6 completed in 0:01:52.468729
2025-08-16 12:33:06,567 - WARNING - Epoch [7/25] Step [1/250]  acc 0.375680 (0.375680)  loss 1.382708 (1.382708)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10048.0 MB
2025-08-16 12:33:11,009 - WARNING - Epoch [7/25] Step [11/250]  acc 0.342333 (0.363996)  loss 1.395141 (1.422684)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 10048.0 MB
2025-08-16 12:33:15,710 - WARNING - Epoch [7/25] Step [21/250]  acc 0.357290 (0.357084)  loss 1.484743 (1.437825)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10048.0 MB
2025-08-16 12:33:20,126 - WARNING - Epoch [7/25] Step [31/250]  acc 0.367687 (0.353299)  loss 1.450199 (1.438997)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 10048.0 MB
2025-08-16 12:33:24,572 - WARNING - Epoch [7/25] Step [41/250]  acc 0.309988 (0.353466)  loss 1.507749 (1.437338)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 10048.0 MB
2025-08-16 12:33:28,993 - WARNING - Epoch [7/25] Step [51/250]  acc 0.364274 (0.353963)  loss 1.394614 (1.438524)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10048.0 MB
2025-08-16 12:33:33,443 - WARNING - Epoch [7/25] Step [61/250]  acc 0.314908 (0.355509)  loss 1.609482 (1.436296)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:33:37,878 - WARNING - Epoch [7/25] Step [71/250]  acc 0.351337 (0.355465)  loss 1.359589 (1.431813)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:33:42,312 - WARNING - Epoch [7/25] Step [81/250]  acc 0.392178 (0.356812)  loss 1.348224 (1.428172)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 10048.0 MB
2025-08-16 12:33:46,761 - WARNING - Epoch [7/25] Step [91/250]  acc 0.334426 (0.356697)  loss 1.480102 (1.430304)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:33:51,192 - WARNING - Epoch [7/25] Step [101/250]  acc 0.313600 (0.355827)  loss 1.454367 (1.431016)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 10048.0 MB
2025-08-16 12:33:55,630 - WARNING - Epoch [7/25] Step [111/250]  acc 0.361323 (0.354973)  loss 1.427024 (1.433737)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10048.0 MB
2025-08-16 12:34:00,043 - WARNING - Epoch [7/25] Step [121/250]  acc 0.345016 (0.354437)  loss 1.426103 (1.434164)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
2025-08-16 12:34:04,491 - WARNING - Epoch [7/25] Step [131/250]  acc 0.361345 (0.355309)  loss 1.401445 (1.433997)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:34:08,922 - WARNING - Epoch [7/25] Step [141/250]  acc 0.314076 (0.354556)  loss 1.466437 (1.435870)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 10048.0 MB
2025-08-16 12:34:13,346 - WARNING - Epoch [7/25] Step [151/250]  acc 0.388036 (0.355607)  loss 1.387268 (1.434586)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:34:17,770 - WARNING - Epoch [7/25] Step [161/250]  acc 0.344004 (0.355466)  loss 1.418420 (1.434000)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 10048.0 MB
2025-08-16 12:34:22,420 - WARNING - Epoch [7/25] Step [171/250]  acc 0.396154 (0.356609)  loss 1.390553 (1.432673)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 10048.0 MB
2025-08-16 12:34:26,844 - WARNING - Epoch [7/25] Step [181/250]  acc 0.332790 (0.356092)  loss 1.440016 (1.432976)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 10048.0 MB
2025-08-16 12:34:31,268 - WARNING - Epoch [7/25] Step [191/250]  acc 0.374797 (0.355985)  loss 1.428313 (1.431906)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:34:35,700 - WARNING - Epoch [7/25] Step [201/250]  acc 0.354981 (0.355436)  loss 1.432613 (1.432969)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 10048.0 MB
2025-08-16 12:34:40,159 - WARNING - Epoch [7/25] Step [211/250]  acc 0.351229 (0.355514)  loss 1.386768 (1.432178)
GPU memory consumption  GPU Memory: Allocated: 59.9 MB, Reserved: 10048.0 MB
2025-08-16 12:34:44,601 - WARNING - Epoch [7/25] Step [221/250]  acc 0.400629 (0.356057)  loss 1.355570 (1.431427)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 10048.0 MB
2025-08-16 12:34:49,050 - WARNING - Epoch [7/25] Step [231/250]  acc 0.330044 (0.356142)  loss 1.477254 (1.431220)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:34:53,488 - WARNING - Epoch [7/25] Step [241/250]  acc 0.343189 (0.356303)  loss 1.467373 (1.429986)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 10048.0 MB
Epoch 7 completed in 0:01:51.377896
2025-08-16 12:35:24,777 - WARNING - Epoch [8/25] Step [1/250]  acc 0.374395 (0.374395)  loss 1.396128 (1.396128)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 10048.0 MB
2025-08-16 12:35:29,343 - WARNING - Epoch [8/25] Step [11/250]  acc 0.347351 (0.360228)  loss 1.423556 (1.404346)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:35:33,832 - WARNING - Epoch [8/25] Step [21/250]  acc 0.360459 (0.358786)  loss 1.393038 (1.404427)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
2025-08-16 12:35:38,298 - WARNING - Epoch [8/25] Step [31/250]  acc 0.368981 (0.358127)  loss 1.436295 (1.407740)
GPU memory consumption  GPU Memory: Allocated: 60.8 MB, Reserved: 10048.0 MB
2025-08-16 12:35:42,816 - WARNING - Epoch [8/25] Step [41/250]  acc 0.428645 (0.360039)  loss 1.355518 (1.412908)
GPU memory consumption  GPU Memory: Allocated: 61.8 MB, Reserved: 10048.0 MB
2025-08-16 12:35:47,327 - WARNING - Epoch [8/25] Step [51/250]  acc 0.342718 (0.359743)  loss 1.446357 (1.412527)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 10048.0 MB
2025-08-16 12:35:51,829 - WARNING - Epoch [8/25] Step [61/250]  acc 0.345902 (0.356901)  loss 1.431565 (1.419117)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 10048.0 MB
2025-08-16 12:35:56,522 - WARNING - Epoch [8/25] Step [71/250]  acc 0.388114 (0.356167)  loss 1.389379 (1.418593)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:36:01,024 - WARNING - Epoch [8/25] Step [81/250]  acc 0.354222 (0.357398)  loss 1.362806 (1.414621)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 10048.0 MB
2025-08-16 12:36:05,504 - WARNING - Epoch [8/25] Step [91/250]  acc 0.357641 (0.358835)  loss 1.408402 (1.416132)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 10048.0 MB
2025-08-16 12:36:09,995 - WARNING - Epoch [8/25] Step [101/250]  acc 0.366861 (0.358664)  loss 1.432182 (1.416039)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10048.0 MB
2025-08-16 12:36:14,441 - WARNING - Epoch [8/25] Step [111/250]  acc 0.381892 (0.359330)  loss 1.366910 (1.415423)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 10048.0 MB
2025-08-16 12:36:18,909 - WARNING - Epoch [8/25] Step [121/250]  acc 0.355611 (0.358586)  loss 1.395661 (1.417740)
GPU memory consumption  GPU Memory: Allocated: 60.2 MB, Reserved: 10048.0 MB
2025-08-16 12:36:23,389 - WARNING - Epoch [8/25] Step [131/250]  acc 0.398143 (0.358333)  loss 1.390931 (1.419341)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
2025-08-16 12:36:27,864 - WARNING - Epoch [8/25] Step [141/250]  acc 0.368496 (0.358118)  loss 1.406434 (1.420260)
GPU memory consumption  GPU Memory: Allocated: 60.6 MB, Reserved: 10048.0 MB
2025-08-16 12:36:32,363 - WARNING - Epoch [8/25] Step [151/250]  acc 0.349223 (0.359025)  loss 1.444556 (1.418495)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 10048.0 MB
2025-08-16 12:36:36,839 - WARNING - Epoch [8/25] Step [161/250]  acc 0.397683 (0.359642)  loss 1.366791 (1.419068)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 10048.0 MB
2025-08-16 12:36:41,297 - WARNING - Epoch [8/25] Step [171/250]  acc 0.363890 (0.359961)  loss 1.375731 (1.418535)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:36:45,630 - WARNING - Epoch [8/25] Step [181/250]  acc 0.334007 (0.359717)  loss 1.487053 (1.419649)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10048.0 MB
2025-08-16 12:36:49,952 - WARNING - Epoch [8/25] Step [191/250]  acc 0.332451 (0.360165)  loss 1.467096 (1.419863)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 10048.0 MB
2025-08-16 12:36:54,378 - WARNING - Epoch [8/25] Step [201/250]  acc 0.358794 (0.359964)  loss 1.382628 (1.420440)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 10048.0 MB
2025-08-16 12:36:58,839 - WARNING - Epoch [8/25] Step [211/250]  acc 0.359027 (0.360372)  loss 1.452428 (1.420267)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10048.0 MB
2025-08-16 12:37:03,265 - WARNING - Epoch [8/25] Step [221/250]  acc 0.337809 (0.359300)  loss 1.437159 (1.420812)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 10048.0 MB
2025-08-16 12:37:07,968 - WARNING - Epoch [8/25] Step [231/250]  acc 0.330859 (0.359743)  loss 1.420317 (1.419658)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 10048.0 MB
2025-08-16 12:37:12,369 - WARNING - Epoch [8/25] Step [241/250]  acc 0.344068 (0.359857)  loss 1.462575 (1.419159)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
Epoch 8 completed in 0:01:52.007574
2025-08-16 12:37:43,530 - WARNING - Epoch [9/25] Step [1/250]  acc 0.357900 (0.357900)  loss 1.438866 (1.438866)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10048.0 MB
2025-08-16 12:37:47,999 - WARNING - Epoch [9/25] Step [11/250]  acc 0.361345 (0.367376)  loss 1.441971 (1.402591)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 10048.0 MB
2025-08-16 12:37:52,434 - WARNING - Epoch [9/25] Step [21/250]  acc 0.384496 (0.371923)  loss 1.336802 (1.395820)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10048.0 MB
2025-08-16 12:37:56,846 - WARNING - Epoch [9/25] Step [31/250]  acc 0.296619 (0.361588)  loss 1.499772 (1.411865)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 10048.0 MB
2025-08-16 12:38:01,273 - WARNING - Epoch [9/25] Step [41/250]  acc 0.388044 (0.360181)  loss 1.357678 (1.421902)
GPU memory consumption  GPU Memory: Allocated: 61.8 MB, Reserved: 10048.0 MB
2025-08-16 12:38:05,720 - WARNING - Epoch [9/25] Step [51/250]  acc 0.329976 (0.355847)  loss 1.471217 (1.427575)
GPU memory consumption  GPU Memory: Allocated: 61.8 MB, Reserved: 10048.0 MB
2025-08-16 12:38:10,143 - WARNING - Epoch [9/25] Step [61/250]  acc 0.414970 (0.357014)  loss 1.364652 (1.423645)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:38:14,551 - WARNING - Epoch [9/25] Step [71/250]  acc 0.342020 (0.355350)  loss 1.416532 (1.425756)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 10048.0 MB
2025-08-16 12:38:19,040 - WARNING - Epoch [9/25] Step [81/250]  acc 0.357912 (0.356377)  loss 1.444331 (1.424508)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 10048.0 MB
2025-08-16 12:38:23,504 - WARNING - Epoch [9/25] Step [91/250]  acc 0.336181 (0.355989)  loss 1.395053 (1.424056)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
2025-08-16 12:38:27,972 - WARNING - Epoch [9/25] Step [101/250]  acc 0.287705 (0.355431)  loss 1.531184 (1.424548)
GPU memory consumption  GPU Memory: Allocated: 60.3 MB, Reserved: 10048.0 MB
2025-08-16 12:38:32,425 - WARNING - Epoch [9/25] Step [111/250]  acc 0.397500 (0.354179)  loss 1.362704 (1.425015)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 10048.0 MB
2025-08-16 12:38:36,899 - WARNING - Epoch [9/25] Step [121/250]  acc 0.362924 (0.354312)  loss 1.457902 (1.424908)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 10048.0 MB
2025-08-16 12:38:41,626 - WARNING - Epoch [9/25] Step [131/250]  acc 0.363586 (0.355379)  loss 1.415548 (1.422759)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:38:46,119 - WARNING - Epoch [9/25] Step [141/250]  acc 0.341202 (0.356942)  loss 1.419300 (1.419494)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 10048.0 MB
2025-08-16 12:38:50,590 - WARNING - Epoch [9/25] Step [151/250]  acc 0.360231 (0.357603)  loss 1.377597 (1.418520)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 10048.0 MB
2025-08-16 12:38:55,067 - WARNING - Epoch [9/25] Step [161/250]  acc 0.380655 (0.358041)  loss 1.411588 (1.417380)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 10048.0 MB
2025-08-16 12:38:59,562 - WARNING - Epoch [9/25] Step [171/250]  acc 0.352592 (0.358430)  loss 1.462405 (1.416644)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 10048.0 MB
2025-08-16 12:39:04,053 - WARNING - Epoch [9/25] Step [181/250]  acc 0.386069 (0.358891)  loss 1.424657 (1.417938)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 10048.0 MB
2025-08-16 12:39:08,539 - WARNING - Epoch [9/25] Step [191/250]  acc 0.344262 (0.359572)  loss 1.406660 (1.416987)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 10048.0 MB
2025-08-16 12:39:13,027 - WARNING - Epoch [9/25] Step [201/250]  acc 0.333677 (0.359431)  loss 1.516548 (1.418335)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10048.0 MB
2025-08-16 12:39:17,532 - WARNING - Epoch [9/25] Step [211/250]  acc 0.365037 (0.358526)  loss 1.429261 (1.419544)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10048.0 MB
2025-08-16 12:39:22,034 - WARNING - Epoch [9/25] Step [221/250]  acc 0.393089 (0.358556)  loss 1.350141 (1.418216)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 10048.0 MB
2025-08-16 12:39:26,547 - WARNING - Epoch [9/25] Step [231/250]  acc 0.346035 (0.358501)  loss 1.477322 (1.418269)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:39:31,041 - WARNING - Epoch [9/25] Step [241/250]  acc 0.375875 (0.359147)  loss 1.410382 (1.418148)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 10048.0 MB
Epoch 9 completed in 0:01:51.992872
2025-08-16 12:40:02,538 - WARNING - Epoch [10/25] Step [1/250]  acc 0.315789 (0.315789)  loss 1.439101 (1.439101)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 10048.0 MB
2025-08-16 12:40:07,043 - WARNING - Epoch [10/25] Step [11/250]  acc 0.340278 (0.350558)  loss 1.519387 (1.425148)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 10048.0 MB
2025-08-16 12:40:11,515 - WARNING - Epoch [10/25] Step [21/250]  acc 0.339821 (0.354365)  loss 1.422424 (1.426747)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10048.0 MB
2025-08-16 12:40:16,264 - WARNING - Epoch [10/25] Step [31/250]  acc 0.372290 (0.355379)  loss 1.379757 (1.421037)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 10048.0 MB
2025-08-16 12:40:20,782 - WARNING - Epoch [10/25] Step [41/250]  acc 0.382833 (0.359000)  loss 1.379256 (1.414503)
GPU memory consumption  GPU Memory: Allocated: 60.8 MB, Reserved: 10048.0 MB
2025-08-16 12:40:25,270 - WARNING - Epoch [10/25] Step [51/250]  acc 0.337349 (0.362128)  loss 1.524755 (1.413395)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 10048.0 MB
2025-08-16 12:40:29,752 - WARNING - Epoch [10/25] Step [61/250]  acc 0.373255 (0.364107)  loss 1.402074 (1.410678)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 10048.0 MB
2025-08-16 12:40:34,235 - WARNING - Epoch [10/25] Step [71/250]  acc 0.386039 (0.363799)  loss 1.351429 (1.409814)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 10048.0 MB
2025-08-16 12:40:38,723 - WARNING - Epoch [10/25] Step [81/250]  acc 0.302860 (0.362087)  loss 1.474737 (1.412719)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10048.0 MB
2025-08-16 12:40:43,213 - WARNING - Epoch [10/25] Step [91/250]  acc 0.406475 (0.362480)  loss 1.375950 (1.416379)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
2025-08-16 12:40:47,718 - WARNING - Epoch [10/25] Step [101/250]  acc 0.355841 (0.361970)  loss 1.471202 (1.417349)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 10048.0 MB
2025-08-16 12:40:52,199 - WARNING - Epoch [10/25] Step [111/250]  acc 0.341204 (0.361185)  loss 1.428775 (1.417039)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 10048.0 MB
2025-08-16 12:40:56,689 - WARNING - Epoch [10/25] Step [121/250]  acc 0.341599 (0.361817)  loss 1.335321 (1.417572)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10048.0 MB
2025-08-16 12:41:01,182 - WARNING - Epoch [10/25] Step [131/250]  acc 0.348642 (0.362012)  loss 1.423885 (1.418224)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 10048.0 MB
2025-08-16 12:41:05,656 - WARNING - Epoch [10/25] Step [141/250]  acc 0.371781 (0.363176)  loss 1.410442 (1.418184)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 10048.0 MB
2025-08-16 12:41:10,148 - WARNING - Epoch [10/25] Step [151/250]  acc 0.363288 (0.362645)  loss 1.418469 (1.418323)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10048.0 MB
2025-08-16 12:41:14,632 - WARNING - Epoch [10/25] Step [161/250]  acc 0.350815 (0.362155)  loss 1.398492 (1.418997)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 10048.0 MB
2025-08-16 12:41:19,125 - WARNING - Epoch [10/25] Step [171/250]  acc 0.347439 (0.361263)  loss 1.411311 (1.419609)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:41:23,614 - WARNING - Epoch [10/25] Step [181/250]  acc 0.296102 (0.361474)  loss 1.450520 (1.419269)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 10048.0 MB
2025-08-16 12:41:28,371 - WARNING - Epoch [10/25] Step [191/250]  acc 0.354506 (0.361229)  loss 1.432291 (1.419665)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 10048.0 MB
2025-08-16 12:41:32,862 - WARNING - Epoch [10/25] Step [201/250]  acc 0.355330 (0.361939)  loss 1.401481 (1.418222)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 10048.0 MB
2025-08-16 12:41:37,374 - WARNING - Epoch [10/25] Step [211/250]  acc 0.339591 (0.362041)  loss 1.429621 (1.417518)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:41:41,862 - WARNING - Epoch [10/25] Step [221/250]  acc 0.330285 (0.361599)  loss 1.501802 (1.417668)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 10048.0 MB
2025-08-16 12:41:46,350 - WARNING - Epoch [10/25] Step [231/250]  acc 0.370112 (0.361226)  loss 1.410941 (1.417972)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 10048.0 MB
2025-08-16 12:41:50,859 - WARNING - Epoch [10/25] Step [241/250]  acc 0.350572 (0.361170)  loss 1.425073 (1.417775)
GPU memory consumption  GPU Memory: Allocated: 60.2 MB, Reserved: 10048.0 MB
Epoch 10 completed in 0:01:52.825167
2025-08-16 12:42:22,253 - WARNING - Epoch [11/25] Step [1/250]  acc 0.373340 (0.373340)  loss 1.348210 (1.348210)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
2025-08-16 12:42:26,792 - WARNING - Epoch [11/25] Step [11/250]  acc 0.326768 (0.348194)  loss 1.437855 (1.421161)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
2025-08-16 12:42:31,302 - WARNING - Epoch [11/25] Step [21/250]  acc 0.319832 (0.354702)  loss 1.444882 (1.416791)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 10048.0 MB
2025-08-16 12:42:35,809 - WARNING - Epoch [11/25] Step [31/250]  acc 0.382096 (0.355079)  loss 1.397419 (1.413087)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 10048.0 MB
2025-08-16 12:42:40,314 - WARNING - Epoch [11/25] Step [41/250]  acc 0.321690 (0.358711)  loss 1.466113 (1.408712)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10048.0 MB
2025-08-16 12:42:44,797 - WARNING - Epoch [11/25] Step [51/250]  acc 0.424396 (0.361321)  loss 1.354579 (1.406985)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:42:49,295 - WARNING - Epoch [11/25] Step [61/250]  acc 0.366038 (0.360591)  loss 1.404437 (1.411107)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 10048.0 MB
2025-08-16 12:42:53,779 - WARNING - Epoch [11/25] Step [71/250]  acc 0.367470 (0.360979)  loss 1.397680 (1.411776)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:42:58,281 - WARNING - Epoch [11/25] Step [81/250]  acc 0.347734 (0.360005)  loss 1.485586 (1.415162)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10048.0 MB
2025-08-16 12:43:03,055 - WARNING - Epoch [11/25] Step [91/250]  acc 0.371968 (0.361132)  loss 1.362884 (1.415286)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 10048.0 MB
2025-08-16 12:43:07,538 - WARNING - Epoch [11/25] Step [101/250]  acc 0.369786 (0.360719)  loss 1.329132 (1.413087)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
2025-08-16 12:43:12,028 - WARNING - Epoch [11/25] Step [111/250]  acc 0.367277 (0.361117)  loss 1.426163 (1.414001)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:43:16,510 - WARNING - Epoch [11/25] Step [121/250]  acc 0.403996 (0.360397)  loss 1.377087 (1.415853)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:43:20,993 - WARNING - Epoch [11/25] Step [131/250]  acc 0.409318 (0.360688)  loss 1.338885 (1.415120)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:43:25,477 - WARNING - Epoch [11/25] Step [141/250]  acc 0.315931 (0.360288)  loss 1.406792 (1.416099)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 10048.0 MB
2025-08-16 12:43:29,940 - WARNING - Epoch [11/25] Step [151/250]  acc 0.435484 (0.360643)  loss 1.342824 (1.417488)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 10048.0 MB
2025-08-16 12:43:34,462 - WARNING - Epoch [11/25] Step [161/250]  acc 0.364919 (0.360623)  loss 1.378656 (1.417091)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 10048.0 MB
2025-08-16 12:43:38,953 - WARNING - Epoch [11/25] Step [171/250]  acc 0.351106 (0.359585)  loss 1.431570 (1.418049)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 10048.0 MB
2025-08-16 12:43:43,447 - WARNING - Epoch [11/25] Step [181/250]  acc 0.366232 (0.360019)  loss 1.381516 (1.417431)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 10048.0 MB
2025-08-16 12:43:47,926 - WARNING - Epoch [11/25] Step [191/250]  acc 0.363687 (0.360427)  loss 1.443244 (1.416851)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:43:52,430 - WARNING - Epoch [11/25] Step [201/250]  acc 0.369691 (0.360136)  loss 1.507043 (1.416631)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:43:56,924 - WARNING - Epoch [11/25] Step [211/250]  acc 0.324194 (0.359434)  loss 1.456036 (1.417057)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 10048.0 MB
2025-08-16 12:44:01,420 - WARNING - Epoch [11/25] Step [221/250]  acc 0.331042 (0.358992)  loss 1.379441 (1.416945)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 10048.0 MB
2025-08-16 12:44:05,929 - WARNING - Epoch [11/25] Step [231/250]  acc 0.321429 (0.358829)  loss 1.454500 (1.416800)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:44:10,686 - WARNING - Epoch [11/25] Step [241/250]  acc 0.389005 (0.358687)  loss 1.396160 (1.416774)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10048.0 MB
Epoch 11 completed in 0:01:52.948521
2025-08-16 12:44:42,221 - WARNING - Epoch [12/25] Step [1/250]  acc 0.373361 (0.373361)  loss 1.355776 (1.355776)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 10048.0 MB
2025-08-16 12:44:46,743 - WARNING - Epoch [12/25] Step [11/250]  acc 0.377049 (0.359104)  loss 1.358191 (1.396708)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 10048.0 MB
2025-08-16 12:44:51,237 - WARNING - Epoch [12/25] Step [21/250]  acc 0.358672 (0.362857)  loss 1.405092 (1.395912)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10048.0 MB
2025-08-16 12:44:55,723 - WARNING - Epoch [12/25] Step [31/250]  acc 0.368059 (0.362865)  loss 1.389352 (1.403895)
GPU memory consumption  GPU Memory: Allocated: 59.5 MB, Reserved: 10048.0 MB
2025-08-16 12:45:00,232 - WARNING - Epoch [12/25] Step [41/250]  acc 0.298548 (0.364554)  loss 1.570939 (1.404580)
GPU memory consumption  GPU Memory: Allocated: 60.3 MB, Reserved: 10048.0 MB
2025-08-16 12:45:04,880 - WARNING - Epoch [12/25] Step [51/250]  acc 0.410723 (0.365746)  loss 1.345124 (1.406669)
GPU memory consumption  GPU Memory: Allocated: 60.5 MB, Reserved: 10048.0 MB
2025-08-16 12:45:09,569 - WARNING - Epoch [12/25] Step [61/250]  acc 0.368937 (0.364821)  loss 1.354014 (1.403742)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
2025-08-16 12:45:14,044 - WARNING - Epoch [12/25] Step [71/250]  acc 0.389913 (0.365168)  loss 1.402390 (1.408122)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 10048.0 MB
2025-08-16 12:45:18,536 - WARNING - Epoch [12/25] Step [81/250]  acc 0.354280 (0.364435)  loss 1.389297 (1.406580)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 10048.0 MB
2025-08-16 12:45:23,054 - WARNING - Epoch [12/25] Step [91/250]  acc 0.327194 (0.364403)  loss 1.473692 (1.408796)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 10048.0 MB
2025-08-16 12:45:27,554 - WARNING - Epoch [12/25] Step [101/250]  acc 0.369041 (0.363774)  loss 1.410621 (1.411171)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 10048.0 MB
2025-08-16 12:45:32,051 - WARNING - Epoch [12/25] Step [111/250]  acc 0.348485 (0.363496)  loss 1.394794 (1.410153)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 10048.0 MB
2025-08-16 12:45:36,521 - WARNING - Epoch [12/25] Step [121/250]  acc 0.332408 (0.363462)  loss 1.372534 (1.409351)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:45:41,008 - WARNING - Epoch [12/25] Step [131/250]  acc 0.401615 (0.363691)  loss 1.357792 (1.407773)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
2025-08-16 12:45:45,514 - WARNING - Epoch [12/25] Step [141/250]  acc 0.320958 (0.363868)  loss 1.426887 (1.407761)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 10048.0 MB
2025-08-16 12:45:50,262 - WARNING - Epoch [12/25] Step [151/250]  acc 0.331986 (0.363194)  loss 1.433284 (1.408133)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10048.0 MB
2025-08-16 12:45:54,739 - WARNING - Epoch [12/25] Step [161/250]  acc 0.343561 (0.362709)  loss 1.431895 (1.409257)
GPU memory consumption  GPU Memory: Allocated: 60.3 MB, Reserved: 10048.0 MB
2025-08-16 12:45:59,228 - WARNING - Epoch [12/25] Step [171/250]  acc 0.396332 (0.362361)  loss 1.422984 (1.410664)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
2025-08-16 12:46:03,721 - WARNING - Epoch [12/25] Step [181/250]  acc 0.318261 (0.363015)  loss 1.434638 (1.409890)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 10048.0 MB
2025-08-16 12:46:08,196 - WARNING - Epoch [12/25] Step [191/250]  acc 0.380795 (0.363039)  loss 1.417159 (1.410387)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 10048.0 MB
2025-08-16 12:46:12,663 - WARNING - Epoch [12/25] Step [201/250]  acc 0.379824 (0.363094)  loss 1.410987 (1.409886)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 10048.0 MB
2025-08-16 12:46:17,160 - WARNING - Epoch [12/25] Step [211/250]  acc 0.366347 (0.362743)  loss 1.463633 (1.410392)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10048.0 MB
2025-08-16 12:46:21,689 - WARNING - Epoch [12/25] Step [221/250]  acc 0.370750 (0.362322)  loss 1.405448 (1.410997)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 10048.0 MB
2025-08-16 12:46:26,172 - WARNING - Epoch [12/25] Step [231/250]  acc 0.390029 (0.362293)  loss 1.413496 (1.411363)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 10048.0 MB
2025-08-16 12:46:30,665 - WARNING - Epoch [12/25] Step [241/250]  acc 0.399036 (0.362492)  loss 1.358770 (1.411171)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 10048.0 MB
Epoch 12 completed in 0:01:52.947367
2025-08-16 12:47:02,187 - WARNING - Epoch [13/25] Step [1/250]  acc 0.420575 (0.420575)  loss 1.405545 (1.405545)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
2025-08-16 12:47:06,714 - WARNING - Epoch [13/25] Step [11/250]  acc 0.395082 (0.369999)  loss 1.399367 (1.401675)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:47:11,219 - WARNING - Epoch [13/25] Step [21/250]  acc 0.364294 (0.373633)  loss 1.397254 (1.400004)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
2025-08-16 12:47:15,702 - WARNING - Epoch [13/25] Step [31/250]  acc 0.340733 (0.365953)  loss 1.390912 (1.406447)
GPU memory consumption  GPU Memory: Allocated: 60.6 MB, Reserved: 10048.0 MB
2025-08-16 12:47:20,189 - WARNING - Epoch [13/25] Step [41/250]  acc 0.330733 (0.361569)  loss 1.399914 (1.411792)
GPU memory consumption  GPU Memory: Allocated: 61.8 MB, Reserved: 10048.0 MB
2025-08-16 12:47:24,954 - WARNING - Epoch [13/25] Step [51/250]  acc 0.350746 (0.364034)  loss 1.495832 (1.406822)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 10048.0 MB
2025-08-16 12:47:29,431 - WARNING - Epoch [13/25] Step [61/250]  acc 0.333498 (0.363420)  loss 1.413323 (1.408421)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 10048.0 MB
2025-08-16 12:47:33,916 - WARNING - Epoch [13/25] Step [71/250]  acc 0.347188 (0.361572)  loss 1.414257 (1.412051)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 10048.0 MB
2025-08-16 12:47:38,395 - WARNING - Epoch [13/25] Step [81/250]  acc 0.384456 (0.360885)  loss 1.415990 (1.413768)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10048.0 MB
2025-08-16 12:47:42,899 - WARNING - Epoch [13/25] Step [91/250]  acc 0.372145 (0.360385)  loss 1.410875 (1.415320)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:47:47,404 - WARNING - Epoch [13/25] Step [101/250]  acc 0.376892 (0.360399)  loss 1.323628 (1.414425)
GPU memory consumption  GPU Memory: Allocated: 59.9 MB, Reserved: 10048.0 MB
2025-08-16 12:47:51,880 - WARNING - Epoch [13/25] Step [111/250]  acc 0.379820 (0.362761)  loss 1.352091 (1.411172)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 10048.0 MB
2025-08-16 12:47:56,351 - WARNING - Epoch [13/25] Step [121/250]  acc 0.368597 (0.362883)  loss 1.406303 (1.412264)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:48:00,836 - WARNING - Epoch [13/25] Step [131/250]  acc 0.380558 (0.362948)  loss 1.424742 (1.414719)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
2025-08-16 12:48:05,343 - WARNING - Epoch [13/25] Step [141/250]  acc 0.346249 (0.361316)  loss 1.380459 (1.417445)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 10048.0 MB
2025-08-16 12:48:09,820 - WARNING - Epoch [13/25] Step [151/250]  acc 0.387588 (0.360534)  loss 1.427169 (1.417792)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10048.0 MB
2025-08-16 12:48:14,298 - WARNING - Epoch [13/25] Step [161/250]  acc 0.321975 (0.360524)  loss 1.418521 (1.417636)
GPU memory consumption  GPU Memory: Allocated: 60.5 MB, Reserved: 10048.0 MB
2025-08-16 12:48:18,805 - WARNING - Epoch [13/25] Step [171/250]  acc 0.369691 (0.360699)  loss 1.447433 (1.417687)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:48:23,311 - WARNING - Epoch [13/25] Step [181/250]  acc 0.364547 (0.361071)  loss 1.392505 (1.417415)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 10048.0 MB
2025-08-16 12:48:27,802 - WARNING - Epoch [13/25] Step [191/250]  acc 0.414080 (0.361563)  loss 1.365604 (1.417678)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:48:32,531 - WARNING - Epoch [13/25] Step [201/250]  acc 0.369355 (0.361449)  loss 1.375715 (1.417142)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 10048.0 MB
2025-08-16 12:48:37,040 - WARNING - Epoch [13/25] Step [211/250]  acc 0.337536 (0.361174)  loss 1.445982 (1.417349)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 10048.0 MB
2025-08-16 12:48:41,529 - WARNING - Epoch [13/25] Step [221/250]  acc 0.365524 (0.360655)  loss 1.378609 (1.416944)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10048.0 MB
2025-08-16 12:48:45,999 - WARNING - Epoch [13/25] Step [231/250]  acc 0.393288 (0.360604)  loss 1.319671 (1.416115)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 10048.0 MB
2025-08-16 12:48:50,519 - WARNING - Epoch [13/25] Step [241/250]  acc 0.369312 (0.360852)  loss 1.452227 (1.415025)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 10048.0 MB
Epoch 13 completed in 0:01:52.852461
2025-08-16 12:49:22,023 - WARNING - Epoch [14/25] Step [1/250]  acc 0.421320 (0.421320)  loss 1.304441 (1.304441)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10048.0 MB
2025-08-16 12:49:26,528 - WARNING - Epoch [14/25] Step [11/250]  acc 0.337165 (0.362581)  loss 1.491008 (1.412014)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:49:31,023 - WARNING - Epoch [14/25] Step [21/250]  acc 0.383960 (0.360456)  loss 1.336450 (1.411609)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 10048.0 MB
2025-08-16 12:49:35,521 - WARNING - Epoch [14/25] Step [31/250]  acc 0.364259 (0.366484)  loss 1.414283 (1.404050)
GPU memory consumption  GPU Memory: Allocated: 60.6 MB, Reserved: 10048.0 MB
2025-08-16 12:49:40,029 - WARNING - Epoch [14/25] Step [41/250]  acc 0.350858 (0.365162)  loss 1.459653 (1.409029)
GPU memory consumption  GPU Memory: Allocated: 60.2 MB, Reserved: 10048.0 MB
2025-08-16 12:49:44,538 - WARNING - Epoch [14/25] Step [51/250]  acc 0.357033 (0.363670)  loss 1.473450 (1.412382)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10048.0 MB
2025-08-16 12:49:49,055 - WARNING - Epoch [14/25] Step [61/250]  acc 0.384530 (0.366164)  loss 1.422516 (1.408914)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10048.0 MB
2025-08-16 12:49:53,555 - WARNING - Epoch [14/25] Step [71/250]  acc 0.329494 (0.364710)  loss 1.426435 (1.410456)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 10050.0 MB
2025-08-16 12:49:58,062 - WARNING - Epoch [14/25] Step [81/250]  acc 0.385655 (0.365493)  loss 1.364094 (1.407392)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10050.0 MB
2025-08-16 12:50:02,562 - WARNING - Epoch [14/25] Step [91/250]  acc 0.356148 (0.364595)  loss 1.499118 (1.409704)
GPU memory consumption  GPU Memory: Allocated: 53.0 MB, Reserved: 10050.0 MB
2025-08-16 12:50:07,317 - WARNING - Epoch [14/25] Step [101/250]  acc 0.334764 (0.363476)  loss 1.437527 (1.411811)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 10050.0 MB
2025-08-16 12:50:11,818 - WARNING - Epoch [14/25] Step [111/250]  acc 0.385662 (0.363821)  loss 1.366138 (1.412412)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10050.0 MB
2025-08-16 12:50:16,293 - WARNING - Epoch [14/25] Step [121/250]  acc 0.411601 (0.363735)  loss 1.397008 (1.412247)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 12:50:20,782 - WARNING - Epoch [14/25] Step [131/250]  acc 0.364692 (0.363570)  loss 1.393468 (1.413461)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 10050.0 MB
2025-08-16 12:50:25,272 - WARNING - Epoch [14/25] Step [141/250]  acc 0.314255 (0.363106)  loss 1.537549 (1.415967)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 10050.0 MB
2025-08-16 12:50:29,757 - WARNING - Epoch [14/25] Step [151/250]  acc 0.345612 (0.362967)  loss 1.458802 (1.416650)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 10050.0 MB
2025-08-16 12:50:34,258 - WARNING - Epoch [14/25] Step [161/250]  acc 0.346624 (0.362816)  loss 1.401738 (1.415730)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 10050.0 MB
2025-08-16 12:50:38,743 - WARNING - Epoch [14/25] Step [171/250]  acc 0.381579 (0.363204)  loss 1.400984 (1.414742)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 10050.0 MB
2025-08-16 12:50:43,237 - WARNING - Epoch [14/25] Step [181/250]  acc 0.368078 (0.362552)  loss 1.379776 (1.414943)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 10050.0 MB
2025-08-16 12:50:47,735 - WARNING - Epoch [14/25] Step [191/250]  acc 0.323996 (0.362712)  loss 1.492346 (1.414862)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10050.0 MB
2025-08-16 12:50:52,239 - WARNING - Epoch [14/25] Step [201/250]  acc 0.355431 (0.362306)  loss 1.403505 (1.413761)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 10050.0 MB
2025-08-16 12:50:56,739 - WARNING - Epoch [14/25] Step [211/250]  acc 0.365257 (0.362554)  loss 1.357820 (1.413032)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10050.0 MB
2025-08-16 12:51:01,240 - WARNING - Epoch [14/25] Step [221/250]  acc 0.306489 (0.362476)  loss 1.521697 (1.413241)
GPU memory consumption  GPU Memory: Allocated: 53.0 MB, Reserved: 10050.0 MB
2025-08-16 12:51:05,733 - WARNING - Epoch [14/25] Step [231/250]  acc 0.372727 (0.362529)  loss 1.445917 (1.412814)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 10050.0 MB
2025-08-16 12:51:10,223 - WARNING - Epoch [14/25] Step [241/250]  acc 0.345639 (0.363288)  loss 1.504148 (1.411974)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 10050.0 MB
Epoch 14 completed in 0:01:52.669159
2025-08-16 12:51:41,792 - WARNING - Epoch [15/25] Step [1/250]  acc 0.372671 (0.372671)  loss 1.420055 (1.420055)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 12:51:46,533 - WARNING - Epoch [15/25] Step [11/250]  acc 0.415272 (0.371677)  loss 1.366926 (1.409741)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 12:51:50,978 - WARNING - Epoch [15/25] Step [21/250]  acc 0.362951 (0.371189)  loss 1.396253 (1.407588)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10050.0 MB
2025-08-16 12:51:55,466 - WARNING - Epoch [15/25] Step [31/250]  acc 0.336338 (0.371345)  loss 1.435827 (1.402278)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 10050.0 MB
2025-08-16 12:51:59,964 - WARNING - Epoch [15/25] Step [41/250]  acc 0.330619 (0.369873)  loss 1.464779 (1.405087)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 10050.0 MB
2025-08-16 12:52:04,475 - WARNING - Epoch [15/25] Step [51/250]  acc 0.351555 (0.369832)  loss 1.385068 (1.402153)
GPU memory consumption  GPU Memory: Allocated: 60.2 MB, Reserved: 10050.0 MB
2025-08-16 12:52:09,050 - WARNING - Epoch [15/25] Step [61/250]  acc 0.369266 (0.368169)  loss 1.422698 (1.405919)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 10050.0 MB
2025-08-16 12:52:13,594 - WARNING - Epoch [15/25] Step [71/250]  acc 0.371003 (0.367844)  loss 1.322087 (1.405191)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 12:52:18,153 - WARNING - Epoch [15/25] Step [81/250]  acc 0.385250 (0.364159)  loss 1.388712 (1.408128)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 10050.0 MB
2025-08-16 12:52:22,690 - WARNING - Epoch [15/25] Step [91/250]  acc 0.295782 (0.363759)  loss 1.532672 (1.407121)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 12:52:27,273 - WARNING - Epoch [15/25] Step [101/250]  acc 0.326223 (0.362431)  loss 1.425489 (1.407175)
GPU memory consumption  GPU Memory: Allocated: 59.9 MB, Reserved: 10050.0 MB
2025-08-16 12:52:31,849 - WARNING - Epoch [15/25] Step [111/250]  acc 0.368891 (0.363812)  loss 1.332177 (1.406534)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10050.0 MB
2025-08-16 12:52:36,564 - WARNING - Epoch [15/25] Step [121/250]  acc 0.365473 (0.364060)  loss 1.361149 (1.405216)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10050.0 MB
2025-08-16 12:52:41,120 - WARNING - Epoch [15/25] Step [131/250]  acc 0.374651 (0.365207)  loss 1.407874 (1.404642)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 12:52:45,644 - WARNING - Epoch [15/25] Step [141/250]  acc 0.364814 (0.366553)  loss 1.480411 (1.403741)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10050.0 MB
2025-08-16 12:52:50,147 - WARNING - Epoch [15/25] Step [151/250]  acc 0.368564 (0.366528)  loss 1.384834 (1.404775)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 10050.0 MB
2025-08-16 12:52:54,883 - WARNING - Epoch [15/25] Step [161/250]  acc 0.359697 (0.366514)  loss 1.453169 (1.405407)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 10050.0 MB
2025-08-16 12:52:59,362 - WARNING - Epoch [15/25] Step [171/250]  acc 0.392321 (0.366130)  loss 1.357143 (1.404870)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 12:53:03,830 - WARNING - Epoch [15/25] Step [181/250]  acc 0.431435 (0.367367)  loss 1.281532 (1.402894)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 10050.0 MB
2025-08-16 12:53:08,379 - WARNING - Epoch [15/25] Step [191/250]  acc 0.348108 (0.367442)  loss 1.506133 (1.403294)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 10050.0 MB
2025-08-16 12:53:12,881 - WARNING - Epoch [15/25] Step [201/250]  acc 0.337622 (0.366905)  loss 1.475245 (1.403209)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 10050.0 MB
2025-08-16 12:53:17,387 - WARNING - Epoch [15/25] Step [211/250]  acc 0.340671 (0.365954)  loss 1.429202 (1.403864)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10050.0 MB
2025-08-16 12:53:21,886 - WARNING - Epoch [15/25] Step [221/250]  acc 0.416504 (0.367128)  loss 1.313004 (1.401426)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10050.0 MB
2025-08-16 12:53:26,336 - WARNING - Epoch [15/25] Step [231/250]  acc 0.344492 (0.367148)  loss 1.518318 (1.402621)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 10050.0 MB
2025-08-16 12:53:30,768 - WARNING - Epoch [15/25] Step [241/250]  acc 0.344917 (0.366686)  loss 1.407431 (1.403985)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10050.0 MB
Epoch 15 completed in 0:01:53.438747
2025-08-16 12:54:02,105 - WARNING - Epoch [16/25] Step [1/250]  acc 0.339730 (0.339730)  loss 1.408962 (1.408962)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 12:54:06,575 - WARNING - Epoch [16/25] Step [11/250]  acc 0.403209 (0.372974)  loss 1.345946 (1.372416)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 10050.0 MB
2025-08-16 12:54:11,009 - WARNING - Epoch [16/25] Step [21/250]  acc 0.347229 (0.372760)  loss 1.444785 (1.383109)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10050.0 MB
2025-08-16 12:54:15,461 - WARNING - Epoch [16/25] Step [31/250]  acc 0.379328 (0.371117)  loss 1.432738 (1.386771)
GPU memory consumption  GPU Memory: Allocated: 60.6 MB, Reserved: 10050.0 MB
2025-08-16 12:54:19,959 - WARNING - Epoch [16/25] Step [41/250]  acc 0.355076 (0.369356)  loss 1.411105 (1.395795)
GPU memory consumption  GPU Memory: Allocated: 60.8 MB, Reserved: 10050.0 MB
2025-08-16 12:54:24,442 - WARNING - Epoch [16/25] Step [51/250]  acc 0.338830 (0.365293)  loss 1.468490 (1.403677)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 10050.0 MB
2025-08-16 12:54:28,883 - WARNING - Epoch [16/25] Step [61/250]  acc 0.387966 (0.365060)  loss 1.342193 (1.404542)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 10050.0 MB
2025-08-16 12:54:33,583 - WARNING - Epoch [16/25] Step [71/250]  acc 0.367152 (0.367222)  loss 1.379305 (1.403742)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 10050.0 MB
2025-08-16 12:54:38,048 - WARNING - Epoch [16/25] Step [81/250]  acc 0.375685 (0.369853)  loss 1.327721 (1.399700)
GPU memory consumption  GPU Memory: Allocated: 60.3 MB, Reserved: 10050.0 MB
2025-08-16 12:54:42,546 - WARNING - Epoch [16/25] Step [91/250]  acc 0.341605 (0.370491)  loss 1.435972 (1.400342)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10050.0 MB
2025-08-16 12:54:47,048 - WARNING - Epoch [16/25] Step [101/250]  acc 0.387317 (0.369410)  loss 1.310776 (1.400450)
GPU memory consumption  GPU Memory: Allocated: 60.5 MB, Reserved: 10050.0 MB
2025-08-16 12:54:51,526 - WARNING - Epoch [16/25] Step [111/250]  acc 0.361839 (0.369372)  loss 1.360681 (1.401264)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10050.0 MB
2025-08-16 12:54:55,981 - WARNING - Epoch [16/25] Step [121/250]  acc 0.338530 (0.368958)  loss 1.477644 (1.401069)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 12:55:00,467 - WARNING - Epoch [16/25] Step [131/250]  acc 0.393726 (0.369033)  loss 1.411276 (1.402609)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 10050.0 MB
2025-08-16 12:55:04,949 - WARNING - Epoch [16/25] Step [141/250]  acc 0.381882 (0.368735)  loss 1.401001 (1.404076)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 10050.0 MB
2025-08-16 12:55:09,397 - WARNING - Epoch [16/25] Step [151/250]  acc 0.315361 (0.367864)  loss 1.457428 (1.405597)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10050.0 MB
2025-08-16 12:55:13,860 - WARNING - Epoch [16/25] Step [161/250]  acc 0.371322 (0.368898)  loss 1.389171 (1.403553)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 10050.0 MB
2025-08-16 12:55:18,322 - WARNING - Epoch [16/25] Step [171/250]  acc 0.345766 (0.368116)  loss 1.362363 (1.403883)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 12:55:22,796 - WARNING - Epoch [16/25] Step [181/250]  acc 0.332260 (0.368004)  loss 1.423158 (1.403725)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 10050.0 MB
2025-08-16 12:55:27,230 - WARNING - Epoch [16/25] Step [191/250]  acc 0.425664 (0.368731)  loss 1.389215 (1.403186)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 12:55:31,711 - WARNING - Epoch [16/25] Step [201/250]  acc 0.409283 (0.369448)  loss 1.274655 (1.401932)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 10050.0 MB
2025-08-16 12:55:36,174 - WARNING - Epoch [16/25] Step [211/250]  acc 0.344367 (0.369879)  loss 1.451132 (1.401529)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 10050.0 MB
2025-08-16 12:55:40,897 - WARNING - Epoch [16/25] Step [221/250]  acc 0.380076 (0.370111)  loss 1.354234 (1.400995)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 10050.0 MB
2025-08-16 12:55:45,339 - WARNING - Epoch [16/25] Step [231/250]  acc 0.388314 (0.370463)  loss 1.386736 (1.400995)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 12:55:49,793 - WARNING - Epoch [16/25] Step [241/250]  acc 0.342501 (0.369719)  loss 1.515869 (1.402430)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10050.0 MB
Epoch 16 completed in 0:01:52.144447
2025-08-16 12:56:20,869 - WARNING - Epoch [17/25] Step [1/250]  acc 0.332233 (0.332233)  loss 1.483942 (1.483942)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 12:56:25,338 - WARNING - Epoch [17/25] Step [11/250]  acc 0.393653 (0.376196)  loss 1.348894 (1.383621)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 12:56:29,764 - WARNING - Epoch [17/25] Step [21/250]  acc 0.341023 (0.366688)  loss 1.377634 (1.399470)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 10050.0 MB
2025-08-16 12:56:34,205 - WARNING - Epoch [17/25] Step [31/250]  acc 0.343552 (0.369171)  loss 1.431098 (1.395456)
GPU memory consumption  GPU Memory: Allocated: 61.5 MB, Reserved: 10050.0 MB
2025-08-16 12:56:38,654 - WARNING - Epoch [17/25] Step [41/250]  acc 0.344280 (0.368056)  loss 1.410972 (1.400346)
GPU memory consumption  GPU Memory: Allocated: 60.6 MB, Reserved: 10050.0 MB
2025-08-16 12:56:43,102 - WARNING - Epoch [17/25] Step [51/250]  acc 0.349404 (0.369979)  loss 1.461893 (1.398113)
GPU memory consumption  GPU Memory: Allocated: 60.1 MB, Reserved: 10050.0 MB
2025-08-16 12:56:47,536 - WARNING - Epoch [17/25] Step [61/250]  acc 0.425917 (0.373216)  loss 1.349985 (1.392030)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 12:56:51,982 - WARNING - Epoch [17/25] Step [71/250]  acc 0.389595 (0.374096)  loss 1.415614 (1.389126)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 10050.0 MB
2025-08-16 12:56:56,409 - WARNING - Epoch [17/25] Step [81/250]  acc 0.378723 (0.376016)  loss 1.353177 (1.386265)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 10050.0 MB
2025-08-16 12:57:00,848 - WARNING - Epoch [17/25] Step [91/250]  acc 0.373228 (0.375235)  loss 1.425569 (1.391312)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 12:57:05,288 - WARNING - Epoch [17/25] Step [101/250]  acc 0.350477 (0.375231)  loss 1.343170 (1.390086)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 10050.0 MB
2025-08-16 12:57:09,698 - WARNING - Epoch [17/25] Step [111/250]  acc 0.388889 (0.374057)  loss 1.415059 (1.391423)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10050.0 MB
2025-08-16 12:57:14,344 - WARNING - Epoch [17/25] Step [121/250]  acc 0.325888 (0.372840)  loss 1.450701 (1.393090)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 10050.0 MB
2025-08-16 12:57:18,772 - WARNING - Epoch [17/25] Step [131/250]  acc 0.380261 (0.372685)  loss 1.349051 (1.393879)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 10050.0 MB
2025-08-16 12:57:23,209 - WARNING - Epoch [17/25] Step [141/250]  acc 0.347368 (0.372712)  loss 1.415367 (1.395742)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 10050.0 MB
2025-08-16 12:57:27,641 - WARNING - Epoch [17/25] Step [151/250]  acc 0.373749 (0.372348)  loss 1.352861 (1.395496)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10050.0 MB
2025-08-16 12:57:32,054 - WARNING - Epoch [17/25] Step [161/250]  acc 0.363089 (0.372099)  loss 1.421832 (1.397224)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 10050.0 MB
2025-08-16 12:57:36,504 - WARNING - Epoch [17/25] Step [171/250]  acc 0.394707 (0.371402)  loss 1.362596 (1.398286)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 12:57:40,927 - WARNING - Epoch [17/25] Step [181/250]  acc 0.352745 (0.371271)  loss 1.448132 (1.398582)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 10050.0 MB
2025-08-16 12:57:45,351 - WARNING - Epoch [17/25] Step [191/250]  acc 0.363261 (0.371028)  loss 1.412185 (1.399440)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 12:57:49,779 - WARNING - Epoch [17/25] Step [201/250]  acc 0.396000 (0.371098)  loss 1.364172 (1.400288)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 10050.0 MB
2025-08-16 12:57:54,205 - WARNING - Epoch [17/25] Step [211/250]  acc 0.381837 (0.371267)  loss 1.436404 (1.400330)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10050.0 MB
2025-08-16 12:57:58,621 - WARNING - Epoch [17/25] Step [221/250]  acc 0.374929 (0.371282)  loss 1.399816 (1.400660)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 10050.0 MB
2025-08-16 12:58:03,045 - WARNING - Epoch [17/25] Step [231/250]  acc 0.373531 (0.371826)  loss 1.418108 (1.399339)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 12:58:07,468 - WARNING - Epoch [17/25] Step [241/250]  acc 0.382321 (0.371996)  loss 1.391127 (1.399148)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 10050.0 MB
Epoch 17 completed in 0:01:51.034028
2025-08-16 12:58:38,166 - WARNING - Epoch [18/25] Step [1/250]  acc 0.379310 (0.379310)  loss 1.339630 (1.339630)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 12:58:42,573 - WARNING - Epoch [18/25] Step [11/250]  acc 0.394558 (0.382124)  loss 1.349910 (1.394662)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 10050.0 MB
2025-08-16 12:58:46,949 - WARNING - Epoch [18/25] Step [21/250]  acc 0.343531 (0.378945)  loss 1.413979 (1.395462)
GPU memory consumption  GPU Memory: Allocated: 60.2 MB, Reserved: 10050.0 MB
2025-08-16 12:58:51,598 - WARNING - Epoch [18/25] Step [31/250]  acc 0.363267 (0.379793)  loss 1.470490 (1.393580)
GPU memory consumption  GPU Memory: Allocated: 60.6 MB, Reserved: 10050.0 MB
2025-08-16 12:58:56,001 - WARNING - Epoch [18/25] Step [41/250]  acc 0.346723 (0.369969)  loss 1.481324 (1.406836)
GPU memory consumption  GPU Memory: Allocated: 61.8 MB, Reserved: 10050.0 MB
2025-08-16 12:59:00,380 - WARNING - Epoch [18/25] Step [51/250]  acc 0.398883 (0.372257)  loss 1.355230 (1.405499)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 12:59:04,759 - WARNING - Epoch [18/25] Step [61/250]  acc 0.376712 (0.372268)  loss 1.419494 (1.405897)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 10050.0 MB
2025-08-16 12:59:09,130 - WARNING - Epoch [18/25] Step [71/250]  acc 0.371854 (0.371917)  loss 1.422010 (1.409146)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 12:59:13,518 - WARNING - Epoch [18/25] Step [81/250]  acc 0.381818 (0.372171)  loss 1.353990 (1.408946)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 10050.0 MB
2025-08-16 12:59:17,917 - WARNING - Epoch [18/25] Step [91/250]  acc 0.423658 (0.372026)  loss 1.297349 (1.406005)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 12:59:22,316 - WARNING - Epoch [18/25] Step [101/250]  acc 0.371828 (0.372472)  loss 1.394928 (1.404919)
GPU memory consumption  GPU Memory: Allocated: 59.9 MB, Reserved: 10050.0 MB
2025-08-16 12:59:26,701 - WARNING - Epoch [18/25] Step [111/250]  acc 0.423365 (0.373135)  loss 1.335396 (1.403080)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 10050.0 MB
2025-08-16 12:59:31,083 - WARNING - Epoch [18/25] Step [121/250]  acc 0.381156 (0.374066)  loss 1.339135 (1.400437)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10050.0 MB
2025-08-16 12:59:35,452 - WARNING - Epoch [18/25] Step [131/250]  acc 0.392694 (0.375459)  loss 1.339049 (1.397074)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 10050.0 MB
2025-08-16 12:59:39,833 - WARNING - Epoch [18/25] Step [141/250]  acc 0.326638 (0.375201)  loss 1.405618 (1.396266)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 10050.0 MB
2025-08-16 12:59:44,199 - WARNING - Epoch [18/25] Step [151/250]  acc 0.351158 (0.375048)  loss 1.454107 (1.396215)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10050.0 MB
2025-08-16 12:59:48,658 - WARNING - Epoch [18/25] Step [161/250]  acc 0.407849 (0.374622)  loss 1.321897 (1.395920)
GPU memory consumption  GPU Memory: Allocated: 60.3 MB, Reserved: 10050.0 MB
2025-08-16 12:59:53,072 - WARNING - Epoch [18/25] Step [171/250]  acc 0.407466 (0.374460)  loss 1.379467 (1.397525)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 10050.0 MB
2025-08-16 12:59:57,656 - WARNING - Epoch [18/25] Step [181/250]  acc 0.308983 (0.375438)  loss 1.498708 (1.395484)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 10050.0 MB
2025-08-16 13:00:02,081 - WARNING - Epoch [18/25] Step [191/250]  acc 0.326389 (0.374788)  loss 1.440004 (1.395892)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 10050.0 MB
2025-08-16 13:00:06,649 - WARNING - Epoch [18/25] Step [201/250]  acc 0.399007 (0.375005)  loss 1.320280 (1.395161)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 10050.0 MB
2025-08-16 13:00:11,328 - WARNING - Epoch [18/25] Step [211/250]  acc 0.396374 (0.374772)  loss 1.378707 (1.395102)
GPU memory consumption  GPU Memory: Allocated: 60.5 MB, Reserved: 10050.0 MB
2025-08-16 13:00:15,705 - WARNING - Epoch [18/25] Step [221/250]  acc 0.326437 (0.374997)  loss 1.542961 (1.394989)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 10050.0 MB
2025-08-16 13:00:20,103 - WARNING - Epoch [18/25] Step [231/250]  acc 0.347139 (0.374970)  loss 1.419349 (1.394146)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 10050.0 MB
2025-08-16 13:00:24,495 - WARNING - Epoch [18/25] Step [241/250]  acc 0.429064 (0.375354)  loss 1.390474 (1.394162)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
Epoch 18 completed in 0:01:50.711537
2025-08-16 13:00:55,044 - WARNING - Epoch [19/25] Step [1/250]  acc 0.366699 (0.366699)  loss 1.336475 (1.336475)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10050.0 MB
2025-08-16 13:00:59,447 - WARNING - Epoch [19/25] Step [11/250]  acc 0.374728 (0.389049)  loss 1.420390 (1.378960)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 10050.0 MB
2025-08-16 13:01:03,846 - WARNING - Epoch [19/25] Step [21/250]  acc 0.403564 (0.380610)  loss 1.404927 (1.385080)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10050.0 MB
2025-08-16 13:01:08,228 - WARNING - Epoch [19/25] Step [31/250]  acc 0.352490 (0.376661)  loss 1.384599 (1.387765)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10050.0 MB
2025-08-16 13:01:12,630 - WARNING - Epoch [19/25] Step [41/250]  acc 0.366892 (0.376366)  loss 1.444730 (1.392916)
GPU memory consumption  GPU Memory: Allocated: 61.8 MB, Reserved: 10050.0 MB
2025-08-16 13:01:16,987 - WARNING - Epoch [19/25] Step [51/250]  acc 0.415825 (0.376979)  loss 1.348070 (1.396129)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 13:01:21,381 - WARNING - Epoch [19/25] Step [61/250]  acc 0.406852 (0.376873)  loss 1.352580 (1.394552)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 10050.0 MB
2025-08-16 13:01:25,768 - WARNING - Epoch [19/25] Step [71/250]  acc 0.348461 (0.377047)  loss 1.455515 (1.393546)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 13:01:30,352 - WARNING - Epoch [19/25] Step [81/250]  acc 0.363636 (0.376054)  loss 1.395884 (1.394963)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10050.0 MB
2025-08-16 13:01:34,732 - WARNING - Epoch [19/25] Step [91/250]  acc 0.359076 (0.375400)  loss 1.360904 (1.395972)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 13:01:39,115 - WARNING - Epoch [19/25] Step [101/250]  acc 0.415094 (0.376270)  loss 1.294482 (1.393051)
GPU memory consumption  GPU Memory: Allocated: 59.9 MB, Reserved: 10050.0 MB
2025-08-16 13:01:43,506 - WARNING - Epoch [19/25] Step [111/250]  acc 0.358142 (0.375770)  loss 1.418832 (1.393623)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 10050.0 MB
2025-08-16 13:01:48,007 - WARNING - Epoch [19/25] Step [121/250]  acc 0.379690 (0.376856)  loss 1.400373 (1.394482)
GPU memory consumption  GPU Memory: Allocated: 60.2 MB, Reserved: 10050.0 MB
2025-08-16 13:01:52,453 - WARNING - Epoch [19/25] Step [131/250]  acc 0.357536 (0.376671)  loss 1.368218 (1.396234)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 13:01:56,879 - WARNING - Epoch [19/25] Step [141/250]  acc 0.366183 (0.375975)  loss 1.410757 (1.397036)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 10050.0 MB
2025-08-16 13:02:01,338 - WARNING - Epoch [19/25] Step [151/250]  acc 0.356392 (0.375524)  loss 1.424702 (1.397000)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10050.0 MB
2025-08-16 13:02:05,765 - WARNING - Epoch [19/25] Step [161/250]  acc 0.369532 (0.375557)  loss 1.474920 (1.396359)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 10050.0 MB
2025-08-16 13:02:10,177 - WARNING - Epoch [19/25] Step [171/250]  acc 0.355354 (0.375736)  loss 1.357036 (1.396176)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 10050.0 MB
2025-08-16 13:02:14,584 - WARNING - Epoch [19/25] Step [181/250]  acc 0.386895 (0.376008)  loss 1.357721 (1.394959)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 10050.0 MB
2025-08-16 13:02:18,993 - WARNING - Epoch [19/25] Step [191/250]  acc 0.436422 (0.376192)  loss 1.306026 (1.393185)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 10050.0 MB
2025-08-16 13:02:23,398 - WARNING - Epoch [19/25] Step [201/250]  acc 0.380411 (0.376412)  loss 1.429050 (1.393462)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 10050.0 MB
2025-08-16 13:02:27,794 - WARNING - Epoch [19/25] Step [211/250]  acc 0.384499 (0.376368)  loss 1.328674 (1.392910)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10050.0 MB
2025-08-16 13:02:32,189 - WARNING - Epoch [19/25] Step [221/250]  acc 0.397832 (0.375963)  loss 1.362286 (1.393220)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 10050.0 MB
2025-08-16 13:02:37,705 - WARNING - Epoch [19/25] Step [231/250]  acc 0.396620 (0.376764)  loss 1.331248 (1.391032)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 10050.0 MB
2025-08-16 13:02:42,256 - WARNING - Epoch [19/25] Step [241/250]  acc 0.339777 (0.376661)  loss 1.483797 (1.391433)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 10050.0 MB
Epoch 19 completed in 0:01:51.563908
2025-08-16 13:03:10,908 - WARNING - Epoch [20/25] Step [1/250]  acc 0.367200 (0.367200)  loss 1.357151 (1.357151)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 13:03:15,102 - WARNING - Epoch [20/25] Step [11/250]  acc 0.383811 (0.388296)  loss 1.353910 (1.382503)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 13:03:19,244 - WARNING - Epoch [20/25] Step [21/250]  acc 0.380182 (0.384872)  loss 1.393115 (1.395604)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10050.0 MB
2025-08-16 13:03:23,314 - WARNING - Epoch [20/25] Step [31/250]  acc 0.419733 (0.387146)  loss 1.326225 (1.392448)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 10050.0 MB
2025-08-16 13:03:27,397 - WARNING - Epoch [20/25] Step [41/250]  acc 0.420910 (0.389866)  loss 1.308985 (1.388754)
GPU memory consumption  GPU Memory: Allocated: 60.3 MB, Reserved: 10050.0 MB
2025-08-16 13:03:31,483 - WARNING - Epoch [20/25] Step [51/250]  acc 0.405150 (0.391544)  loss 1.330106 (1.377751)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10050.0 MB
2025-08-16 13:03:35,546 - WARNING - Epoch [20/25] Step [61/250]  acc 0.405561 (0.389529)  loss 1.361496 (1.373502)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 10050.0 MB
2025-08-16 13:03:39,561 - WARNING - Epoch [20/25] Step [71/250]  acc 0.372022 (0.389204)  loss 1.347724 (1.371425)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 13:03:43,624 - WARNING - Epoch [20/25] Step [81/250]  acc 0.358645 (0.389505)  loss 1.535977 (1.371144)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 10050.0 MB
2025-08-16 13:03:47,646 - WARNING - Epoch [20/25] Step [91/250]  acc 0.337209 (0.389210)  loss 1.377084 (1.372084)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 13:03:51,724 - WARNING - Epoch [20/25] Step [101/250]  acc 0.373467 (0.388711)  loss 1.459068 (1.372814)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 13:03:55,791 - WARNING - Epoch [20/25] Step [111/250]  acc 0.381422 (0.388973)  loss 1.383166 (1.371731)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10050.0 MB
2025-08-16 13:03:59,806 - WARNING - Epoch [20/25] Step [121/250]  acc 0.403010 (0.389158)  loss 1.400479 (1.373160)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 13:04:03,839 - WARNING - Epoch [20/25] Step [131/250]  acc 0.517413 (0.392389)  loss 1.256187 (1.369624)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 13:04:08,116 - WARNING - Epoch [20/25] Step [141/250]  acc 0.390005 (0.393436)  loss 1.421455 (1.370933)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 10050.0 MB
2025-08-16 13:04:12,153 - WARNING - Epoch [20/25] Step [151/250]  acc 0.370850 (0.393197)  loss 1.376457 (1.371806)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10050.0 MB
2025-08-16 13:04:16,184 - WARNING - Epoch [20/25] Step [161/250]  acc 0.413362 (0.394302)  loss 1.291465 (1.370408)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 10050.0 MB
2025-08-16 13:04:20,219 - WARNING - Epoch [20/25] Step [171/250]  acc 0.386243 (0.394924)  loss 1.396310 (1.370178)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 10050.0 MB
2025-08-16 13:04:24,238 - WARNING - Epoch [20/25] Step [181/250]  acc 0.440295 (0.397153)  loss 1.304660 (1.368412)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 10050.0 MB
2025-08-16 13:04:28,272 - WARNING - Epoch [20/25] Step [191/250]  acc 0.385729 (0.398774)  loss 1.471444 (1.366892)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 13:04:32,320 - WARNING - Epoch [20/25] Step [201/250]  acc 0.457247 (0.399981)  loss 1.340380 (1.366948)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 13:04:36,341 - WARNING - Epoch [20/25] Step [211/250]  acc 0.451863 (0.401045)  loss 1.334517 (1.366296)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10050.0 MB
2025-08-16 13:04:40,344 - WARNING - Epoch [20/25] Step [221/250]  acc 0.441368 (0.402275)  loss 1.340736 (1.365825)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 10050.0 MB
2025-08-16 13:04:44,372 - WARNING - Epoch [20/25] Step [231/250]  acc 0.435986 (0.403596)  loss 1.340101 (1.364428)
GPU memory consumption  GPU Memory: Allocated: 53.0 MB, Reserved: 10050.0 MB
2025-08-16 13:04:48,407 - WARNING - Epoch [20/25] Step [241/250]  acc 0.428648 (0.404920)  loss 1.313027 (1.362767)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 10050.0 MB
Epoch 20 completed in 0:01:41.588071
2025-08-16 13:05:16,415 - WARNING - Epoch [21/25] Step [1/250]  acc 0.471038 (0.471038)  loss 1.287593 (1.287593)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 10050.0 MB
2025-08-16 13:05:20,451 - WARNING - Epoch [21/25] Step [11/250]  acc 0.414856 (0.438218)  loss 1.290752 (1.334541)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 10050.0 MB
2025-08-16 13:05:24,494 - WARNING - Epoch [21/25] Step [21/250]  acc 0.445378 (0.438149)  loss 1.299918 (1.318772)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10050.0 MB
2025-08-16 13:05:28,523 - WARNING - Epoch [21/25] Step [31/250]  acc 0.412584 (0.439864)  loss 1.309108 (1.307452)
GPU memory consumption  GPU Memory: Allocated: 60.6 MB, Reserved: 10050.0 MB
2025-08-16 13:05:32,781 - WARNING - Epoch [21/25] Step [41/250]  acc 0.452461 (0.442794)  loss 1.337312 (1.300408)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10050.0 MB
2025-08-16 13:05:36,795 - WARNING - Epoch [21/25] Step [51/250]  acc 0.430074 (0.441656)  loss 1.303196 (1.306092)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10050.0 MB
2025-08-16 13:05:40,833 - WARNING - Epoch [21/25] Step [61/250]  acc 0.402928 (0.438028)  loss 1.318686 (1.313221)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 10050.0 MB
2025-08-16 13:05:44,967 - WARNING - Epoch [21/25] Step [71/250]  acc 0.458225 (0.437174)  loss 1.311159 (1.315644)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 13:05:49,119 - WARNING - Epoch [21/25] Step [81/250]  acc 0.433138 (0.437176)  loss 1.390090 (1.317906)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 10050.0 MB
2025-08-16 13:05:53,295 - WARNING - Epoch [21/25] Step [91/250]  acc 0.472669 (0.437247)  loss 1.234499 (1.318687)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 10050.0 MB
2025-08-16 13:05:57,433 - WARNING - Epoch [21/25] Step [101/250]  acc 0.423941 (0.436412)  loss 1.325868 (1.321288)
GPU memory consumption  GPU Memory: Allocated: 59.9 MB, Reserved: 10050.0 MB
2025-08-16 13:06:01,603 - WARNING - Epoch [21/25] Step [111/250]  acc 0.477433 (0.438576)  loss 1.252960 (1.315812)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 13:06:05,761 - WARNING - Epoch [21/25] Step [121/250]  acc 0.443188 (0.439400)  loss 1.284984 (1.312391)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 10050.0 MB
2025-08-16 13:06:09,900 - WARNING - Epoch [21/25] Step [131/250]  acc 0.480616 (0.438915)  loss 1.286648 (1.310474)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 10050.0 MB
2025-08-16 13:06:14,055 - WARNING - Epoch [21/25] Step [141/250]  acc 0.386456 (0.438590)  loss 1.423080 (1.312538)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 10050.0 MB
2025-08-16 13:06:18,195 - WARNING - Epoch [21/25] Step [151/250]  acc 0.469054 (0.439730)  loss 1.257366 (1.310552)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10050.0 MB
2025-08-16 13:06:22,387 - WARNING - Epoch [21/25] Step [161/250]  acc 0.467164 (0.439399)  loss 1.271546 (1.310986)
GPU memory consumption  GPU Memory: Allocated: 60.3 MB, Reserved: 10050.0 MB
2025-08-16 13:06:26,539 - WARNING - Epoch [21/25] Step [171/250]  acc 0.421900 (0.439401)  loss 1.293402 (1.310139)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 10050.0 MB
2025-08-16 13:06:30,691 - WARNING - Epoch [21/25] Step [181/250]  acc 0.426361 (0.438984)  loss 1.311276 (1.310699)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10050.0 MB
2025-08-16 13:06:35,011 - WARNING - Epoch [21/25] Step [191/250]  acc 0.419246 (0.438862)  loss 1.291931 (1.309928)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 13:06:39,130 - WARNING - Epoch [21/25] Step [201/250]  acc 0.466737 (0.438952)  loss 1.316169 (1.308702)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10050.0 MB
2025-08-16 13:06:43,177 - WARNING - Epoch [21/25] Step [211/250]  acc 0.436074 (0.438539)  loss 1.294193 (1.309426)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 10050.0 MB
2025-08-16 13:06:47,188 - WARNING - Epoch [21/25] Step [221/250]  acc 0.433623 (0.438815)  loss 1.366269 (1.309423)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 13:06:51,186 - WARNING - Epoch [21/25] Step [231/250]  acc 0.451509 (0.439386)  loss 1.244226 (1.307859)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 10050.0 MB
2025-08-16 13:06:55,214 - WARNING - Epoch [21/25] Step [241/250]  acc 0.423711 (0.439467)  loss 1.290914 (1.306887)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 10050.0 MB
Epoch 21 completed in 0:01:42.852174
2025-08-16 13:07:24,369 - WARNING - Epoch [22/25] Step [1/250]  acc 0.434537 (0.434537)  loss 1.386825 (1.386825)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 10050.0 MB
2025-08-16 13:07:28,568 - WARNING - Epoch [22/25] Step [11/250]  acc 0.433787 (0.444532)  loss 1.225578 (1.305948)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 10050.0 MB
2025-08-16 13:07:32,786 - WARNING - Epoch [22/25] Step [21/250]  acc 0.428816 (0.447089)  loss 1.324367 (1.297392)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 13:07:36,982 - WARNING - Epoch [22/25] Step [31/250]  acc 0.427912 (0.448396)  loss 1.254267 (1.288603)
GPU memory consumption  GPU Memory: Allocated: 60.6 MB, Reserved: 10050.0 MB
2025-08-16 13:07:41,198 - WARNING - Epoch [22/25] Step [41/250]  acc 0.470011 (0.444496)  loss 1.259314 (1.296359)
GPU memory consumption  GPU Memory: Allocated: 59.9 MB, Reserved: 10050.0 MB
2025-08-16 13:07:45,390 - WARNING - Epoch [22/25] Step [51/250]  acc 0.440630 (0.444037)  loss 1.285984 (1.295833)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 13:07:49,573 - WARNING - Epoch [22/25] Step [61/250]  acc 0.459061 (0.442702)  loss 1.263220 (1.299277)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 13:07:53,612 - WARNING - Epoch [22/25] Step [71/250]  acc 0.471800 (0.442843)  loss 1.283201 (1.299184)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 10050.0 MB
2025-08-16 13:07:57,669 - WARNING - Epoch [22/25] Step [81/250]  acc 0.414723 (0.442746)  loss 1.291052 (1.295362)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10050.0 MB
2025-08-16 13:08:01,868 - WARNING - Epoch [22/25] Step [91/250]  acc 0.444886 (0.442375)  loss 1.321494 (1.292827)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 10050.0 MB
2025-08-16 13:08:06,264 - WARNING - Epoch [22/25] Step [101/250]  acc 0.456187 (0.443794)  loss 1.296845 (1.293151)
GPU memory consumption  GPU Memory: Allocated: 59.9 MB, Reserved: 10050.0 MB
2025-08-16 13:08:10,351 - WARNING - Epoch [22/25] Step [111/250]  acc 0.437800 (0.444066)  loss 1.361847 (1.292123)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 10050.0 MB
2025-08-16 13:08:14,343 - WARNING - Epoch [22/25] Step [121/250]  acc 0.461659 (0.443426)  loss 1.252246 (1.292345)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10050.0 MB
2025-08-16 13:08:18,338 - WARNING - Epoch [22/25] Step [131/250]  acc 0.465299 (0.443341)  loss 1.306031 (1.290711)
GPU memory consumption  GPU Memory: Allocated: 52.2 MB, Reserved: 10050.0 MB
2025-08-16 13:08:22,338 - WARNING - Epoch [22/25] Step [141/250]  acc 0.438457 (0.444322)  loss 1.346192 (1.288590)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 10050.0 MB
2025-08-16 13:08:26,362 - WARNING - Epoch [22/25] Step [151/250]  acc 0.416800 (0.443953)  loss 1.325485 (1.288750)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 10050.0 MB
2025-08-16 13:08:30,403 - WARNING - Epoch [22/25] Step [161/250]  acc 0.422463 (0.443335)  loss 1.227892 (1.288940)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 10050.0 MB
2025-08-16 13:08:34,437 - WARNING - Epoch [22/25] Step [171/250]  acc 0.485814 (0.444561)  loss 1.290211 (1.287584)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 10050.0 MB
2025-08-16 13:08:38,443 - WARNING - Epoch [22/25] Step [181/250]  acc 0.448082 (0.444897)  loss 1.229604 (1.287913)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 10050.0 MB
2025-08-16 13:08:42,457 - WARNING - Epoch [22/25] Step [191/250]  acc 0.421473 (0.444564)  loss 1.362203 (1.289340)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 10050.0 MB
2025-08-16 13:08:46,472 - WARNING - Epoch [22/25] Step [201/250]  acc 0.417258 (0.444768)  loss 1.279939 (1.287413)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 10050.0 MB
2025-08-16 13:08:50,511 - WARNING - Epoch [22/25] Step [211/250]  acc 0.500000 (0.444978)  loss 1.248986 (1.287663)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 13:08:54,575 - WARNING - Epoch [22/25] Step [221/250]  acc 0.441224 (0.444873)  loss 1.281584 (1.287355)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 10050.0 MB
2025-08-16 13:08:58,580 - WARNING - Epoch [22/25] Step [231/250]  acc 0.401464 (0.443982)  loss 1.319253 (1.287923)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 13:09:02,629 - WARNING - Epoch [22/25] Step [241/250]  acc 0.469963 (0.444234)  loss 1.207714 (1.286693)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 10050.0 MB
Epoch 22 completed in 0:01:42.498281
2025-08-16 13:09:30,694 - WARNING - Epoch [23/25] Step [1/250]  acc 0.491375 (0.491375)  loss 1.198065 (1.198065)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 13:09:34,733 - WARNING - Epoch [23/25] Step [11/250]  acc 0.517315 (0.452994)  loss 1.197762 (1.253449)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 10050.0 MB
2025-08-16 13:09:38,742 - WARNING - Epoch [23/25] Step [21/250]  acc 0.410799 (0.447434)  loss 1.291557 (1.272669)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 10050.0 MB
2025-08-16 13:09:42,773 - WARNING - Epoch [23/25] Step [31/250]  acc 0.441127 (0.446249)  loss 1.282107 (1.279810)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 10050.0 MB
2025-08-16 13:09:46,795 - WARNING - Epoch [23/25] Step [41/250]  acc 0.409091 (0.445125)  loss 1.391329 (1.287334)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10050.0 MB
2025-08-16 13:09:50,831 - WARNING - Epoch [23/25] Step [51/250]  acc 0.467540 (0.444674)  loss 1.294537 (1.291679)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 10050.0 MB
2025-08-16 13:09:54,847 - WARNING - Epoch [23/25] Step [61/250]  acc 0.419664 (0.446888)  loss 1.268930 (1.287894)
GPU memory consumption  GPU Memory: Allocated: 52.2 MB, Reserved: 10050.0 MB
2025-08-16 13:09:58,850 - WARNING - Epoch [23/25] Step [71/250]  acc 0.406105 (0.448126)  loss 1.301448 (1.284287)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 13:10:02,961 - WARNING - Epoch [23/25] Step [81/250]  acc 0.468939 (0.449229)  loss 1.278983 (1.280559)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 13:10:06,972 - WARNING - Epoch [23/25] Step [91/250]  acc 0.426960 (0.448232)  loss 1.348447 (1.279603)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 13:10:11,019 - WARNING - Epoch [23/25] Step [101/250]  acc 0.463597 (0.447568)  loss 1.212930 (1.278484)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10050.0 MB
2025-08-16 13:10:15,055 - WARNING - Epoch [23/25] Step [111/250]  acc 0.402210 (0.446778)  loss 1.332658 (1.278031)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 13:10:19,066 - WARNING - Epoch [23/25] Step [121/250]  acc 0.500562 (0.447316)  loss 1.246955 (1.276694)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 13:10:23,126 - WARNING - Epoch [23/25] Step [131/250]  acc 0.421644 (0.446729)  loss 1.307164 (1.276743)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 13:10:27,166 - WARNING - Epoch [23/25] Step [141/250]  acc 0.408726 (0.445988)  loss 1.324888 (1.278506)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 10050.0 MB
2025-08-16 13:10:31,412 - WARNING - Epoch [23/25] Step [151/250]  acc 0.500278 (0.446207)  loss 1.194071 (1.279311)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10050.0 MB
2025-08-16 13:10:35,441 - WARNING - Epoch [23/25] Step [161/250]  acc 0.431310 (0.445917)  loss 1.222678 (1.279010)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10050.0 MB
2025-08-16 13:10:39,486 - WARNING - Epoch [23/25] Step [171/250]  acc 0.403445 (0.445255)  loss 1.319336 (1.280124)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 13:10:43,521 - WARNING - Epoch [23/25] Step [181/250]  acc 0.412181 (0.445446)  loss 1.388841 (1.280864)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 10050.0 MB
2025-08-16 13:10:47,551 - WARNING - Epoch [23/25] Step [191/250]  acc 0.378238 (0.444714)  loss 1.383180 (1.281954)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 13:10:51,603 - WARNING - Epoch [23/25] Step [201/250]  acc 0.504367 (0.445157)  loss 1.156262 (1.280046)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 10050.0 MB
2025-08-16 13:10:55,682 - WARNING - Epoch [23/25] Step [211/250]  acc 0.457783 (0.445546)  loss 1.306405 (1.279481)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 10050.0 MB
2025-08-16 13:10:59,737 - WARNING - Epoch [23/25] Step [221/250]  acc 0.493580 (0.445943)  loss 1.164363 (1.278471)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 13:11:03,817 - WARNING - Epoch [23/25] Step [231/250]  acc 0.442895 (0.447490)  loss 1.381978 (1.276731)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 10050.0 MB
2025-08-16 13:11:07,865 - WARNING - Epoch [23/25] Step [241/250]  acc 0.445844 (0.447799)  loss 1.282560 (1.277028)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 10050.0 MB
Epoch 23 completed in 0:01:41.253917
2025-08-16 13:11:36,212 - WARNING - Epoch [24/25] Step [1/250]  acc 0.492494 (0.492494)  loss 1.207278 (1.207278)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 10050.0 MB
2025-08-16 13:11:40,280 - WARNING - Epoch [24/25] Step [11/250]  acc 0.464917 (0.457149)  loss 1.288739 (1.250716)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 10050.0 MB
2025-08-16 13:11:44,365 - WARNING - Epoch [24/25] Step [21/250]  acc 0.449184 (0.456661)  loss 1.318409 (1.262339)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 10050.0 MB
2025-08-16 13:11:48,430 - WARNING - Epoch [24/25] Step [31/250]  acc 0.450820 (0.454960)  loss 1.284336 (1.267488)
GPU memory consumption  GPU Memory: Allocated: 60.6 MB, Reserved: 10050.0 MB
2025-08-16 13:11:52,539 - WARNING - Epoch [24/25] Step [41/250]  acc 0.434263 (0.452265)  loss 1.326897 (1.273516)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10050.0 MB
2025-08-16 13:11:56,604 - WARNING - Epoch [24/25] Step [51/250]  acc 0.418933 (0.452072)  loss 1.370017 (1.276441)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10050.0 MB
2025-08-16 13:12:00,867 - WARNING - Epoch [24/25] Step [61/250]  acc 0.432590 (0.449523)  loss 1.235473 (1.278510)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 10050.0 MB
2025-08-16 13:12:04,903 - WARNING - Epoch [24/25] Step [71/250]  acc 0.420516 (0.449103)  loss 1.257406 (1.277153)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 10050.0 MB
2025-08-16 13:12:08,976 - WARNING - Epoch [24/25] Step [81/250]  acc 0.451722 (0.448031)  loss 1.191544 (1.274839)
GPU memory consumption  GPU Memory: Allocated: 60.8 MB, Reserved: 10050.0 MB
2025-08-16 13:12:13,026 - WARNING - Epoch [24/25] Step [91/250]  acc 0.451148 (0.446211)  loss 1.278510 (1.275777)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 10050.0 MB
2025-08-16 13:12:17,071 - WARNING - Epoch [24/25] Step [101/250]  acc 0.480800 (0.446627)  loss 1.202494 (1.275655)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 10050.0 MB
2025-08-16 13:12:21,105 - WARNING - Epoch [24/25] Step [111/250]  acc 0.431155 (0.446617)  loss 1.327955 (1.276250)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 10050.0 MB
2025-08-16 13:12:25,154 - WARNING - Epoch [24/25] Step [121/250]  acc 0.466093 (0.445699)  loss 1.235669 (1.276714)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10050.0 MB
2025-08-16 13:12:29,165 - WARNING - Epoch [24/25] Step [131/250]  acc 0.405449 (0.446444)  loss 1.420270 (1.277286)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 10050.0 MB
2025-08-16 13:12:33,235 - WARNING - Epoch [24/25] Step [141/250]  acc 0.464322 (0.447548)  loss 1.237578 (1.274108)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 10050.0 MB
2025-08-16 13:12:37,279 - WARNING - Epoch [24/25] Step [151/250]  acc 0.474779 (0.448364)  loss 1.165312 (1.273500)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10050.0 MB
2025-08-16 13:12:41,345 - WARNING - Epoch [24/25] Step [161/250]  acc 0.477964 (0.449287)  loss 1.195638 (1.270704)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 10050.0 MB
2025-08-16 13:12:45,438 - WARNING - Epoch [24/25] Step [171/250]  acc 0.469608 (0.449879)  loss 1.233325 (1.270162)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 10050.0 MB
2025-08-16 13:12:49,496 - WARNING - Epoch [24/25] Step [181/250]  acc 0.441223 (0.450475)  loss 1.190771 (1.269082)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 10050.0 MB
2025-08-16 13:12:53,590 - WARNING - Epoch [24/25] Step [191/250]  acc 0.457886 (0.450741)  loss 1.314718 (1.268243)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 10050.0 MB
2025-08-16 13:12:57,639 - WARNING - Epoch [24/25] Step [201/250]  acc 0.449919 (0.450341)  loss 1.225418 (1.269442)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 10050.0 MB
2025-08-16 13:13:01,912 - WARNING - Epoch [24/25] Step [211/250]  acc 0.415221 (0.449762)  loss 1.304154 (1.269774)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 13:13:05,965 - WARNING - Epoch [24/25] Step [221/250]  acc 0.423749 (0.449633)  loss 1.316680 (1.270238)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 10050.0 MB
2025-08-16 13:13:10,016 - WARNING - Epoch [24/25] Step [231/250]  acc 0.420561 (0.449261)  loss 1.320076 (1.269627)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 10050.0 MB
2025-08-16 13:13:14,054 - WARNING - Epoch [24/25] Step [241/250]  acc 0.401809 (0.449283)  loss 1.380925 (1.269809)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10050.0 MB
Epoch 24 completed in 0:01:41.892365
2025-08-16 13:13:42,343 - WARNING - Epoch [25/25] Step [1/250]  acc 0.453901 (0.453901)  loss 1.234632 (1.234632)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 10050.0 MB
2025-08-16 13:13:46,413 - WARNING - Epoch [25/25] Step [11/250]  acc 0.508731 (0.457429)  loss 1.311152 (1.265224)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 10050.0 MB
2025-08-16 13:13:50,486 - WARNING - Epoch [25/25] Step [21/250]  acc 0.472799 (0.458949)  loss 1.130067 (1.249049)
GPU memory consumption  GPU Memory: Allocated: 60.3 MB, Reserved: 10050.0 MB
2025-08-16 13:13:54,615 - WARNING - Epoch [25/25] Step [31/250]  acc 0.455032 (0.454551)  loss 1.255315 (1.253788)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 10050.0 MB
2025-08-16 13:13:58,682 - WARNING - Epoch [25/25] Step [41/250]  acc 0.423802 (0.455928)  loss 1.317117 (1.253828)
GPU memory consumption  GPU Memory: Allocated: 60.3 MB, Reserved: 10050.0 MB
2025-08-16 13:14:02,705 - WARNING - Epoch [25/25] Step [51/250]  acc 0.419391 (0.454642)  loss 1.368283 (1.258304)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 13:14:06,729 - WARNING - Epoch [25/25] Step [61/250]  acc 0.420601 (0.453295)  loss 1.278803 (1.260637)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 10050.0 MB
2025-08-16 13:14:10,783 - WARNING - Epoch [25/25] Step [71/250]  acc 0.457016 (0.451724)  loss 1.321810 (1.267341)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 10050.0 MB
2025-08-16 13:14:14,835 - WARNING - Epoch [25/25] Step [81/250]  acc 0.431302 (0.450538)  loss 1.234472 (1.267548)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 10050.0 MB
2025-08-16 13:14:18,907 - WARNING - Epoch [25/25] Step [91/250]  acc 0.449470 (0.450360)  loss 1.310332 (1.269668)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 13:14:22,958 - WARNING - Epoch [25/25] Step [101/250]  acc 0.466910 (0.447980)  loss 1.268447 (1.272667)
GPU memory consumption  GPU Memory: Allocated: 59.9 MB, Reserved: 10050.0 MB
2025-08-16 13:14:27,013 - WARNING - Epoch [25/25] Step [111/250]  acc 0.479365 (0.447517)  loss 1.170962 (1.272040)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 10050.0 MB
2025-08-16 13:14:31,285 - WARNING - Epoch [25/25] Step [121/250]  acc 0.439724 (0.447810)  loss 1.273495 (1.270637)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10050.0 MB
2025-08-16 13:14:35,321 - WARNING - Epoch [25/25] Step [131/250]  acc 0.443038 (0.448995)  loss 1.361881 (1.269125)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 10050.0 MB
2025-08-16 13:14:39,361 - WARNING - Epoch [25/25] Step [141/250]  acc 0.435430 (0.448472)  loss 1.303054 (1.269395)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 10050.0 MB
2025-08-16 13:14:43,544 - WARNING - Epoch [25/25] Step [151/250]  acc 0.390389 (0.448192)  loss 1.331413 (1.269018)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 10050.0 MB
2025-08-16 13:14:47,620 - WARNING - Epoch [25/25] Step [161/250]  acc 0.426523 (0.447599)  loss 1.321786 (1.269626)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 10050.0 MB
2025-08-16 13:14:51,709 - WARNING - Epoch [25/25] Step [171/250]  acc 0.460662 (0.447052)  loss 1.276792 (1.271146)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 10050.0 MB
2025-08-16 13:14:55,756 - WARNING - Epoch [25/25] Step [181/250]  acc 0.463074 (0.447519)  loss 1.215943 (1.270544)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 10050.0 MB
2025-08-16 13:14:59,785 - WARNING - Epoch [25/25] Step [191/250]  acc 0.440678 (0.446915)  loss 1.310387 (1.271516)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 13:15:03,881 - WARNING - Epoch [25/25] Step [201/250]  acc 0.436499 (0.447807)  loss 1.308566 (1.270277)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 10050.0 MB
2025-08-16 13:15:07,967 - WARNING - Epoch [25/25] Step [211/250]  acc 0.467615 (0.448387)  loss 1.245935 (1.269359)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 10050.0 MB
2025-08-16 13:15:12,066 - WARNING - Epoch [25/25] Step [221/250]  acc 0.429009 (0.448285)  loss 1.261469 (1.268592)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
2025-08-16 13:15:16,128 - WARNING - Epoch [25/25] Step [231/250]  acc 0.410868 (0.448424)  loss 1.285386 (1.268998)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 10050.0 MB
2025-08-16 13:15:20,164 - WARNING - Epoch [25/25] Step [241/250]  acc 0.465738 (0.448479)  loss 1.212017 (1.268192)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 10050.0 MB
Epoch 25 completed in 0:01:41.875181
2025-08-16 13:15:47,819 - INFO - DARTS search completed in 3396.53s
2025-08-16 13:15:47,819 - INFO - 
============================================================
2025-08-16 13:15:47,820 - INFO - Layer layer_0 Expert Selection:
2025-08-16 13:15:47,820 - INFO -   Expert 0: GINE (α=0.2350)
2025-08-16 13:15:47,820 - INFO -   Expert 1: CustomGatedGCN (α=0.3780)
2025-08-16 13:15:47,820 - INFO -   Expert 2: GATV2 (α=0.3870) ← SELECTED
2025-08-16 13:15:47,820 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-16 13:15:47,820 - INFO - ============================================================

2025-08-16 13:15:47,820 - INFO - 
============================================================
2025-08-16 13:15:47,820 - INFO - Layer layer_1 Expert Selection:
2025-08-16 13:15:47,820 - INFO -   Expert 0: GINE (α=0.2311)
2025-08-16 13:15:47,820 - INFO -   Expert 1: CustomGatedGCN (α=0.3013)
2025-08-16 13:15:47,820 - INFO -   Expert 2: GATV2 (α=0.4676) ← SELECTED
2025-08-16 13:15:47,820 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-16 13:15:47,820 - INFO - ============================================================

2025-08-16 13:15:47,820 - INFO - 
============================================================
2025-08-16 13:15:47,820 - INFO - Layer layer_2 Expert Selection:
2025-08-16 13:15:47,820 - INFO -   Expert 0: GINE (α=0.2177)
2025-08-16 13:15:47,820 - INFO -   Expert 1: CustomGatedGCN (α=0.3016)
2025-08-16 13:15:47,820 - INFO -   Expert 2: GATV2 (α=0.4808) ← SELECTED
2025-08-16 13:15:47,820 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-16 13:15:47,820 - INFO - ============================================================

2025-08-16 13:15:47,820 - INFO - 
============================================================
2025-08-16 13:15:47,820 - INFO - Layer layer_3 Expert Selection:
2025-08-16 13:15:47,820 - INFO -   Expert 0: GINE (α=0.2739)
2025-08-16 13:15:47,820 - INFO -   Expert 1: CustomGatedGCN (α=0.4147) ← SELECTED
2025-08-16 13:15:47,820 - INFO -   Expert 2: GATV2 (α=0.3114)
2025-08-16 13:15:47,820 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 13:15:47,821 - INFO - ============================================================

2025-08-16 13:15:47,821 - INFO - 
============================================================
2025-08-16 13:15:47,821 - INFO - Layer layer_4 Expert Selection:
2025-08-16 13:15:47,821 - INFO -   Expert 0: GINE (α=0.2949)
2025-08-16 13:15:47,821 - INFO -   Expert 1: CustomGatedGCN (α=0.3708) ← SELECTED
2025-08-16 13:15:47,821 - INFO -   Expert 2: GATV2 (α=0.3343)
2025-08-16 13:15:47,821 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 13:15:47,821 - INFO - ============================================================

2025-08-16 13:15:47,821 - INFO - 
============================================================
2025-08-16 13:15:47,821 - INFO - Layer layer_5 Expert Selection:
2025-08-16 13:15:47,821 - INFO -   Expert 0: GINE (α=0.3142)
2025-08-16 13:15:47,821 - INFO -   Expert 1: CustomGatedGCN (α=0.3657) ← SELECTED
2025-08-16 13:15:47,821 - INFO -   Expert 2: GATV2 (α=0.3201)
2025-08-16 13:15:47,821 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 13:15:47,821 - INFO - ============================================================

2025-08-16 13:15:47,821 - INFO - 
============================================================
2025-08-16 13:15:47,821 - INFO - Layer layer_6 Expert Selection:
2025-08-16 13:15:47,821 - INFO -   Expert 0: GINE (α=0.3315)
2025-08-16 13:15:47,821 - INFO -   Expert 1: CustomGatedGCN (α=0.3403) ← SELECTED
2025-08-16 13:15:47,821 - INFO -   Expert 2: GATV2 (α=0.3281)
2025-08-16 13:15:47,821 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 13:15:47,821 - INFO - ============================================================

2025-08-16 13:15:47,821 - INFO - 
============================================================
2025-08-16 13:15:47,821 - INFO - Layer layer_7 Expert Selection:
2025-08-16 13:15:47,821 - INFO -   Expert 0: GINE (α=0.2552)
2025-08-16 13:15:47,821 - INFO -   Expert 1: CustomGatedGCN (α=0.4531) ← SELECTED
2025-08-16 13:15:47,822 - INFO -   Expert 2: GATV2 (α=0.2917)
2025-08-16 13:15:47,822 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 13:15:47,822 - INFO - ============================================================

2025-08-16 13:15:47,822 - INFO - 
============================================================
2025-08-16 13:15:47,822 - INFO - Layer layer_8 Expert Selection:
2025-08-16 13:15:47,822 - INFO -   Expert 0: GINE (α=0.3019)
2025-08-16 13:15:47,822 - INFO -   Expert 1: CustomGatedGCN (α=0.3883) ← SELECTED
2025-08-16 13:15:47,822 - INFO -   Expert 2: GATV2 (α=0.3099)
2025-08-16 13:15:47,822 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 13:15:47,822 - INFO - ============================================================

2025-08-16 13:15:47,822 - INFO - 
============================================================
2025-08-16 13:15:47,822 - INFO - Layer layer_9 Expert Selection:
2025-08-16 13:15:47,822 - INFO -   Expert 0: GINE (α=0.3606) ← SELECTED
2025-08-16 13:15:47,822 - INFO -   Expert 1: CustomGatedGCN (α=0.3520)
2025-08-16 13:15:47,822 - INFO -   Expert 2: GATV2 (α=0.2874)
2025-08-16 13:15:47,822 - INFO - Selected Expert Index: 0 (GINE)
2025-08-16 13:15:47,822 - INFO - ============================================================

2025-08-16 13:15:47,822 - INFO - 
============================================================
2025-08-16 13:15:47,822 - INFO - Layer layer_10 Expert Selection:
2025-08-16 13:15:47,822 - INFO -   Expert 0: GINE (α=0.3363)
2025-08-16 13:15:47,822 - INFO -   Expert 1: CustomGatedGCN (α=0.3904) ← SELECTED
2025-08-16 13:15:47,822 - INFO -   Expert 2: GATV2 (α=0.2734)
2025-08-16 13:15:47,822 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 13:15:47,822 - INFO - ============================================================

2025-08-16 13:15:47,822 - INFO - 
============================================================
2025-08-16 13:15:47,822 - INFO - Layer layer_11 Expert Selection:
2025-08-16 13:15:47,822 - INFO -   Expert 0: GINE (α=0.2510)
2025-08-16 13:15:47,823 - INFO -   Expert 1: CustomGatedGCN (α=0.4852) ← SELECTED
2025-08-16 13:15:47,823 - INFO -   Expert 2: GATV2 (α=0.2638)
2025-08-16 13:15:47,823 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 13:15:47,823 - INFO - ============================================================

2025-08-16 13:15:47,823 - INFO - 
============================================================
2025-08-16 13:15:47,823 - INFO - Layer layer_12 Expert Selection:
2025-08-16 13:15:47,823 - INFO -   Expert 0: GINE (α=0.2160)
2025-08-16 13:15:47,823 - INFO -   Expert 1: CustomGatedGCN (α=0.5610) ← SELECTED
2025-08-16 13:15:47,823 - INFO -   Expert 2: GATV2 (α=0.2230)
2025-08-16 13:15:47,823 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 13:15:47,823 - INFO - ============================================================

2025-08-16 13:15:47,823 - INFO - 
============================================================
2025-08-16 13:15:47,823 - INFO - Layer layer_13 Expert Selection:
2025-08-16 13:15:47,823 - INFO -   Expert 0: GINE (α=0.2684)
2025-08-16 13:15:47,823 - INFO -   Expert 1: CustomGatedGCN (α=0.5013) ← SELECTED
2025-08-16 13:15:47,823 - INFO -   Expert 2: GATV2 (α=0.2303)
2025-08-16 13:15:47,823 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 13:15:47,823 - INFO - ============================================================

2025-08-16 13:15:47,823 - INFO - 
============================================================
2025-08-16 13:15:47,823 - INFO - Layer layer_14 Expert Selection:
2025-08-16 13:15:47,823 - INFO -   Expert 0: GINE (α=0.2219)
2025-08-16 13:15:47,823 - INFO -   Expert 1: CustomGatedGCN (α=0.4787) ← SELECTED
2025-08-16 13:15:47,823 - INFO -   Expert 2: GATV2 (α=0.2993)
2025-08-16 13:15:47,823 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 13:15:47,823 - INFO - ============================================================

2025-08-16 13:15:47,823 - INFO - 
============================================================
2025-08-16 13:15:47,823 - INFO - Layer layer_15 Expert Selection:
2025-08-16 13:15:47,824 - INFO -   Expert 0: GINE (α=0.2198)
2025-08-16 13:15:47,824 - INFO -   Expert 1: CustomGatedGCN (α=0.4818) ← SELECTED
2025-08-16 13:15:47,824 - INFO -   Expert 2: GATV2 (α=0.2984)
2025-08-16 13:15:47,824 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 13:15:47,824 - INFO - ============================================================

=== MODEL PARAMETER COMPARISON ===
Original DARTS model parameters: 728,678
2025-08-16 13:15:47,927 - INFO - Layer 0: Using ONLY Expert 2 (GATV2)
2025-08-16 13:15:47,928 - INFO - DiscreteNASLayer 0: Using ONLY Expert 2 (GATV2)
2025-08-16 13:15:47,931 - INFO - Layer 1: Using ONLY Expert 2 (GATV2)
2025-08-16 13:15:47,931 - INFO - DiscreteNASLayer 1: Using ONLY Expert 2 (GATV2)
2025-08-16 13:15:47,934 - INFO - Layer 2: Using ONLY Expert 2 (GATV2)
2025-08-16 13:15:47,934 - INFO - DiscreteNASLayer 2: Using ONLY Expert 2 (GATV2)
2025-08-16 13:15:47,936 - INFO - Layer 3: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,936 - INFO - DiscreteNASLayer 3: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,938 - INFO - Layer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,938 - INFO - DiscreteNASLayer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,941 - INFO - Layer 5: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,941 - INFO - DiscreteNASLayer 5: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,943 - INFO - Layer 6: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,944 - INFO - DiscreteNASLayer 6: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,946 - INFO - Layer 7: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,946 - INFO - DiscreteNASLayer 7: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,949 - INFO - Layer 8: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,949 - INFO - DiscreteNASLayer 8: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,951 - INFO - Layer 9: Using ONLY Expert 0 (GINE)
2025-08-16 13:15:47,951 - INFO - DiscreteNASLayer 9: Using ONLY Expert 0 (GINE)
2025-08-16 13:15:47,953 - INFO - Layer 10: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,954 - INFO - DiscreteNASLayer 10: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,956 - INFO - Layer 11: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,956 - INFO - DiscreteNASLayer 11: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,958 - INFO - Layer 12: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,959 - INFO - DiscreteNASLayer 12: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,961 - INFO - Layer 13: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,961 - INFO - DiscreteNASLayer 13: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,964 - INFO - Layer 14: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,964 - INFO - DiscreteNASLayer 14: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,967 - INFO - Layer 15: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 13:15:47,967 - INFO - DiscreteNASLayer 15: Using ONLY Expert 1 (CustomGatedGCN)
Fresh discrete model parameters: 517,910
Parameter difference: -210,768
✓ Used cfg.share.dim_in (raw input) instead of self.encoder.dim_in (processed)
✓ Fresh discrete model with correct input dimensions
2025-08-16 13:15:47,990 - INFO - Replaced inner model with discrete version
2025-08-16 13:15:47,991 - INFO - Creating fresh optimizer/scheduler for discrete model...
2025-08-16 13:15:47,995 - INFO - Fresh optimizer created: AdamW
2025-08-16 13:15:47,995 - INFO - Fresh scheduler created: LambdaLR
2025-08-16 13:15:47,995 - INFO - Discrete model parameters: 517,910
2025-08-16 13:15:47,995 - INFO - ============================================================
2025-08-16 13:15:47,995 - INFO - PHASE 2: DISCRETE TRAINING WITH UNCERTAINTY
2025-08-16 13:15:47,995 - INFO - ============================================================
2025-08-16 13:15:47,995 - INFO - === Epoch 0 ===
2025-08-16 13:17:09,423 - INFO - train: {'epoch': 0, 'time_epoch': 80.91963, 'eta': 8011.04356, 'eta_hours': 2.22529, 'loss': 1.79701244, 'lr': 0.0, 'params': 517910, 'time_iter': 0.12947, 'accuracy': 0.16631, 'f1': 0.08414, 'accuracy-SBM': 0.16609, 'auc': 0.49932}
2025-08-16 13:17:09,502 - INFO - ...computing epoch stats took: 0.57s
2025-08-16 13:17:13,764 - INFO - val: {'epoch': 0, 'time_epoch': 4.22717, 'loss': 1.79687082, 'lr': 0, 'params': 517910, 'time_iter': 0.0671, 'accuracy': 0.17051, 'f1': 0.0815, 'accuracy-SBM': 0.16686, 'auc': 0.49823}
2025-08-16 13:17:13,864 - INFO - ...computing epoch stats took: 0.13s
2025-08-16 13:17:23,141 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:17:23,179 - INFO - test: {'epoch': 0, 'time_epoch': 4.48104, 'loss': 1.79687437, 'lr': 0, 'params': 517910, 'time_iter': 0.07113, 'accuracy': 0.16764, 'f1': 0.08133, 'accuracy-SBM': 0.16688, 'auc': 0.50024}
2025-08-16 13:17:23,322 - INFO - ...computing epoch stats took: 0.17s
2025-08-16 13:17:23,322 - INFO - > Epoch 0: took 95.3s (avg 95.3s) | Best so far: epoch 0	train_loss: 1.7970 train_accuracy-SBM: 0.1661	val_loss: 1.7969 val_accuracy-SBM: 0.1669	test_loss: 1.7969 test_accuracy-SBM: 0.1669
2025-08-16 13:17:23,322 - INFO - === Epoch 1 ===
2025-08-16 13:18:44,312 - INFO - train: {'epoch': 1, 'time_epoch': 80.76496, 'eta': 7922.54483, 'eta_hours': 2.20071, 'loss': 1.61561546, 'lr': 0.0002, 'params': 517910, 'time_iter': 0.12922, 'accuracy': 0.40066, 'f1': 0.3901, 'accuracy-SBM': 0.40058, 'auc': 0.73561}
2025-08-16 13:18:44,318 - INFO - ...computing epoch stats took: 0.22s
2025-08-16 13:18:48,449 - INFO - val: {'epoch': 1, 'time_epoch': 4.07759, 'loss': 1.71065344, 'lr': 0, 'params': 517910, 'time_iter': 0.06472, 'accuracy': 0.28457, 'f1': 0.21968, 'accuracy-SBM': 0.28467, 'auc': 0.7527}
2025-08-16 13:18:48,451 - INFO - ...computing epoch stats took: 0.05s
2025-08-16 13:18:54,196 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:18:54,251 - INFO - test: {'epoch': 1, 'time_epoch': 4.34931, 'loss': 1.70978623, 'lr': 0, 'params': 517910, 'time_iter': 0.06904, 'accuracy': 0.28769, 'f1': 0.22525, 'accuracy-SBM': 0.28906, 'auc': 0.753}
2025-08-16 13:18:54,253 - INFO - ...computing epoch stats took: 0.05s
2025-08-16 13:18:54,253 - INFO - > Epoch 1: took 90.9s (avg 93.1s) | Best so far: epoch 1	train_loss: 1.6156 train_accuracy-SBM: 0.4006	val_loss: 1.7107 val_accuracy-SBM: 0.2847	test_loss: 1.7098 test_accuracy-SBM: 0.2891
2025-08-16 13:18:54,253 - INFO - === Epoch 2 ===
2025-08-16 13:20:15,022 - INFO - train: {'epoch': 2, 'time_epoch': 80.44651, 'eta': 7828.90546, 'eta_hours': 2.1747, 'loss': 1.29896368, 'lr': 0.0004, 'params': 517910, 'time_iter': 0.12871, 'accuracy': 0.55553, 'f1': 0.55243, 'accuracy-SBM': 0.55551, 'auc': 0.83715}
2025-08-16 13:20:15,027 - INFO - ...computing epoch stats took: 0.31s
2025-08-16 13:20:19,165 - INFO - val: {'epoch': 2, 'time_epoch': 4.08717, 'loss': 1.55444039, 'lr': 0, 'params': 517910, 'time_iter': 0.06488, 'accuracy': 0.40428, 'f1': 0.37348, 'accuracy-SBM': 0.40375, 'auc': 0.78817}
2025-08-16 13:20:19,167 - INFO - ...computing epoch stats took: 0.05s
2025-08-16 13:20:24,965 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:20:25,003 - INFO - test: {'epoch': 2, 'time_epoch': 4.41207, 'loss': 1.53886506, 'lr': 0, 'params': 517910, 'time_iter': 0.07003, 'accuracy': 0.4122, 'f1': 0.38345, 'accuracy-SBM': 0.41243, 'auc': 0.79226}
2025-08-16 13:20:25,005 - INFO - ...computing epoch stats took: 0.03s
2025-08-16 13:20:25,005 - INFO - > Epoch 2: took 90.8s (avg 92.3s) | Best so far: epoch 2	train_loss: 1.2990 train_accuracy-SBM: 0.5555	val_loss: 1.5544 val_accuracy-SBM: 0.4037	test_loss: 1.5389 test_accuracy-SBM: 0.4124
2025-08-16 13:20:25,005 - INFO - === Epoch 3 ===
2025-08-16 13:21:45,965 - INFO - train: {'epoch': 3, 'time_epoch': 80.73229, 'eta': 7748.72117, 'eta_hours': 2.15242, 'loss': 1.06508338, 'lr': 0.0006, 'params': 517910, 'time_iter': 0.12917, 'accuracy': 0.63584, 'f1': 0.63551, 'accuracy-SBM': 0.63583, 'auc': 0.89185}
2025-08-16 13:21:50,135 - INFO - val: {'epoch': 3, 'time_epoch': 4.12531, 'loss': 1.11356607, 'lr': 0, 'params': 517910, 'time_iter': 0.06548, 'accuracy': 0.6034, 'f1': 0.59831, 'accuracy-SBM': 0.60317, 'auc': 0.88991}
2025-08-16 13:21:55,980 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:21:56,018 - INFO - test: {'epoch': 3, 'time_epoch': 4.39285, 'loss': 1.10628353, 'lr': 0, 'params': 517910, 'time_iter': 0.06973, 'accuracy': 0.60564, 'f1': 0.60093, 'accuracy-SBM': 0.60522, 'auc': 0.892}
2025-08-16 13:21:56,020 - INFO - > Epoch 3: took 91.0s (avg 92.0s) | Best so far: epoch 3	train_loss: 1.0651 train_accuracy-SBM: 0.6358	val_loss: 1.1136 val_accuracy-SBM: 0.6032	test_loss: 1.1063 test_accuracy-SBM: 0.6052
2025-08-16 13:21:56,020 - INFO - === Epoch 4 ===
2025-08-16 13:23:16,840 - INFO - train: {'epoch': 4, 'time_epoch': 80.58281, 'eta': 7665.47764, 'eta_hours': 2.1293, 'loss': 0.90779661, 'lr': 0.0008, 'params': 517910, 'time_iter': 0.12893, 'accuracy': 0.68309, 'f1': 0.68309, 'accuracy-SBM': 0.68309, 'auc': 0.9211}
2025-08-16 13:23:20,880 - INFO - val: {'epoch': 4, 'time_epoch': 3.98983, 'loss': 1.07192142, 'lr': 0, 'params': 517910, 'time_iter': 0.06333, 'accuracy': 0.61511, 'f1': 0.61182, 'accuracy-SBM': 0.61535, 'auc': 0.89618}
2025-08-16 13:23:26,505 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:23:26,545 - INFO - test: {'epoch': 4, 'time_epoch': 4.25692, 'loss': 1.05530806, 'lr': 0, 'params': 517910, 'time_iter': 0.06757, 'accuracy': 0.62008, 'f1': 0.61695, 'accuracy-SBM': 0.62027, 'auc': 0.89982}
2025-08-16 13:23:26,547 - INFO - > Epoch 4: took 90.5s (avg 91.7s) | Best so far: epoch 4	train_loss: 0.9078 train_accuracy-SBM: 0.6831	val_loss: 1.0719 val_accuracy-SBM: 0.6153	test_loss: 1.0553 test_accuracy-SBM: 0.6203
2025-08-16 13:23:26,547 - INFO - === Epoch 5 ===
2025-08-16 13:24:47,910 - INFO - train: {'epoch': 5, 'time_epoch': 81.03351, 'eta': 7590.18203, 'eta_hours': 2.10838, 'loss': 0.84185763, 'lr': 0.001, 'params': 517910, 'time_iter': 0.12965, 'accuracy': 0.70099, 'f1': 0.70099, 'accuracy-SBM': 0.70098, 'auc': 0.93073}
2025-08-16 13:24:52,040 - INFO - val: {'epoch': 5, 'time_epoch': 4.0862, 'loss': 1.01683994, 'lr': 0, 'params': 517910, 'time_iter': 0.06486, 'accuracy': 0.63251, 'f1': 0.6269, 'accuracy-SBM': 0.63408, 'auc': 0.90069}
2025-08-16 13:24:57,735 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:24:57,773 - INFO - test: {'epoch': 5, 'time_epoch': 4.37233, 'loss': 0.98185845, 'lr': 0, 'params': 517910, 'time_iter': 0.0694, 'accuracy': 0.64561, 'f1': 0.64021, 'accuracy-SBM': 0.64603, 'auc': 0.90884}
2025-08-16 13:24:57,775 - INFO - > Epoch 5: took 91.2s (avg 91.6s) | Best so far: epoch 5	train_loss: 0.8419 train_accuracy-SBM: 0.7010	val_loss: 1.0168 val_accuracy-SBM: 0.6341	test_loss: 0.9819 test_accuracy-SBM: 0.6460
2025-08-16 13:24:57,775 - INFO - === Epoch 6 ===
2025-08-16 13:26:18,986 - INFO - train: {'epoch': 6, 'time_epoch': 80.87182, 'eta': 7511.09882, 'eta_hours': 2.08642, 'loss': 0.79932429, 'lr': 0.00099973, 'params': 517910, 'time_iter': 0.12939, 'accuracy': 0.71439, 'f1': 0.71439, 'accuracy-SBM': 0.71439, 'auc': 0.9369}
2025-08-16 13:26:23,119 - INFO - val: {'epoch': 6, 'time_epoch': 4.08966, 'loss': 0.76533836, 'lr': 0, 'params': 517910, 'time_iter': 0.06492, 'accuracy': 0.72978, 'f1': 0.72976, 'accuracy-SBM': 0.72981, 'auc': 0.94544}
2025-08-16 13:26:29,078 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:26:29,116 - INFO - test: {'epoch': 6, 'time_epoch': 4.40683, 'loss': 0.75896477, 'lr': 0, 'params': 517910, 'time_iter': 0.06995, 'accuracy': 0.73226, 'f1': 0.73223, 'accuracy-SBM': 0.73219, 'auc': 0.94642}
2025-08-16 13:26:29,118 - INFO - > Epoch 6: took 91.3s (avg 91.6s) | Best so far: epoch 6	train_loss: 0.7993 train_accuracy-SBM: 0.7144	val_loss: 0.7653 val_accuracy-SBM: 0.7298	test_loss: 0.7590 test_accuracy-SBM: 0.7322
2025-08-16 13:26:29,118 - INFO - === Epoch 7 ===
2025-08-16 13:27:50,712 - INFO - train: {'epoch': 7, 'time_epoch': 81.35375, 'eta': 7437.11064, 'eta_hours': 2.06586, 'loss': 0.76874553, 'lr': 0.00099891, 'params': 517910, 'time_iter': 0.13017, 'accuracy': 0.72444, 'f1': 0.72444, 'accuracy-SBM': 0.72444, 'auc': 0.94142}
2025-08-16 13:27:54,941 - INFO - val: {'epoch': 7, 'time_epoch': 4.17699, 'loss': 0.7481721, 'lr': 0, 'params': 517910, 'time_iter': 0.0663, 'accuracy': 0.73218, 'f1': 0.73204, 'accuracy-SBM': 0.73208, 'auc': 0.94521}
2025-08-16 13:28:00,864 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:28:00,903 - INFO - test: {'epoch': 7, 'time_epoch': 4.45769, 'loss': 0.74785119, 'lr': 0, 'params': 517910, 'time_iter': 0.07076, 'accuracy': 0.73147, 'f1': 0.73153, 'accuracy-SBM': 0.7315, 'auc': 0.94537}
2025-08-16 13:28:00,905 - INFO - > Epoch 7: took 91.8s (avg 91.6s) | Best so far: epoch 7	train_loss: 0.7687 train_accuracy-SBM: 0.7244	val_loss: 0.7482 val_accuracy-SBM: 0.7321	test_loss: 0.7479 test_accuracy-SBM: 0.7315
2025-08-16 13:28:00,905 - INFO - === Epoch 8 ===
2025-08-16 13:29:24,128 - INFO - train: {'epoch': 8, 'time_epoch': 82.99148, 'eta': 7378.04495, 'eta_hours': 2.04946, 'loss': 0.75382232, 'lr': 0.00099754, 'params': 517910, 'time_iter': 0.13279, 'accuracy': 0.7294, 'f1': 0.7294, 'accuracy-SBM': 0.7294, 'auc': 0.94347}
2025-08-16 13:29:28,360 - INFO - val: {'epoch': 8, 'time_epoch': 4.18713, 'loss': 0.70373576, 'lr': 0, 'params': 517910, 'time_iter': 0.06646, 'accuracy': 0.74934, 'f1': 0.74924, 'accuracy-SBM': 0.74923, 'auc': 0.95128}
2025-08-16 13:29:34,245 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:29:34,284 - INFO - test: {'epoch': 8, 'time_epoch': 4.4567, 'loss': 0.70169987, 'lr': 0, 'params': 517910, 'time_iter': 0.07074, 'accuracy': 0.74854, 'f1': 0.74838, 'accuracy-SBM': 0.74843, 'auc': 0.95173}
2025-08-16 13:29:34,286 - INFO - > Epoch 8: took 93.4s (avg 91.8s) | Best so far: epoch 8	train_loss: 0.7538 train_accuracy-SBM: 0.7294	val_loss: 0.7037 val_accuracy-SBM: 0.7492	test_loss: 0.7017 test_accuracy-SBM: 0.7484
2025-08-16 13:29:34,286 - INFO - === Epoch 9 ===
2025-08-16 13:30:57,229 - INFO - train: {'epoch': 9, 'time_epoch': 82.70945, 'eta': 7311.65586, 'eta_hours': 2.03102, 'loss': 0.73803398, 'lr': 0.00099563, 'params': 517910, 'time_iter': 0.13234, 'accuracy': 0.73453, 'f1': 0.73453, 'accuracy-SBM': 0.73454, 'auc': 0.94576}
2025-08-16 13:31:01,451 - INFO - val: {'epoch': 9, 'time_epoch': 4.17784, 'loss': 0.70946357, 'lr': 0, 'params': 517910, 'time_iter': 0.06631, 'accuracy': 0.74718, 'f1': 0.74719, 'accuracy-SBM': 0.74734, 'auc': 0.95021}
2025-08-16 13:31:07,308 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:31:07,346 - INFO - test: {'epoch': 9, 'time_epoch': 4.44752, 'loss': 0.70562212, 'lr': 0, 'params': 517910, 'time_iter': 0.0706, 'accuracy': 0.7464, 'f1': 0.74638, 'accuracy-SBM': 0.74658, 'auc': 0.95086}
2025-08-16 13:31:07,348 - INFO - > Epoch 9: took 93.1s (avg 91.9s) | Best so far: epoch 8	train_loss: 0.7538 train_accuracy-SBM: 0.7294	val_loss: 0.7037 val_accuracy-SBM: 0.7492	test_loss: 0.7017 test_accuracy-SBM: 0.7484
2025-08-16 13:31:07,348 - INFO - === Epoch 10 ===
2025-08-16 13:32:30,123 - INFO - train: {'epoch': 10, 'time_epoch': 82.54084, 'eta': 7240.93523, 'eta_hours': 2.01137, 'loss': 0.72357419, 'lr': 0.00099318, 'params': 517910, 'time_iter': 0.13207, 'accuracy': 0.73927, 'f1': 0.73928, 'accuracy-SBM': 0.73927, 'auc': 0.9478}
2025-08-16 13:32:34,353 - INFO - val: {'epoch': 10, 'time_epoch': 4.18564, 'loss': 0.6937678, 'lr': 0, 'params': 517910, 'time_iter': 0.06644, 'accuracy': 0.75211, 'f1': 0.75199, 'accuracy-SBM': 0.75196, 'auc': 0.95262}
2025-08-16 13:32:40,232 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:32:40,271 - INFO - test: {'epoch': 10, 'time_epoch': 4.44093, 'loss': 0.70089785, 'lr': 0, 'params': 517910, 'time_iter': 0.07049, 'accuracy': 0.74694, 'f1': 0.74708, 'accuracy-SBM': 0.74709, 'auc': 0.9518}
2025-08-16 13:32:40,272 - INFO - > Epoch 10: took 92.9s (avg 92.0s) | Best so far: epoch 10	train_loss: 0.7236 train_accuracy-SBM: 0.7393	val_loss: 0.6938 val_accuracy-SBM: 0.7520	test_loss: 0.7009 test_accuracy-SBM: 0.7471
2025-08-16 13:32:40,273 - INFO - === Epoch 11 ===
2025-08-16 13:34:03,147 - INFO - train: {'epoch': 11, 'time_epoch': 82.64538, 'eta': 7169.01119, 'eta_hours': 1.99139, 'loss': 0.7223554, 'lr': 0.00099019, 'params': 517910, 'time_iter': 0.13223, 'accuracy': 0.73945, 'f1': 0.73945, 'accuracy-SBM': 0.73945, 'auc': 0.94788}
2025-08-16 13:34:07,372 - INFO - val: {'epoch': 11, 'time_epoch': 4.1817, 'loss': 0.67600489, 'lr': 0, 'params': 517910, 'time_iter': 0.06638, 'accuracy': 0.7568, 'f1': 0.7567, 'accuracy-SBM': 0.75668, 'auc': 0.95483}
2025-08-16 13:34:13,197 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:34:13,240 - INFO - test: {'epoch': 11, 'time_epoch': 4.43767, 'loss': 0.67362391, 'lr': 0, 'params': 517910, 'time_iter': 0.07044, 'accuracy': 0.75833, 'f1': 0.75824, 'accuracy-SBM': 0.75819, 'auc': 0.95505}
2025-08-16 13:34:13,243 - INFO - > Epoch 11: took 93.0s (avg 92.1s) | Best so far: epoch 11	train_loss: 0.7224 train_accuracy-SBM: 0.7395	val_loss: 0.6760 val_accuracy-SBM: 0.7567	test_loss: 0.6736 test_accuracy-SBM: 0.7582
2025-08-16 13:34:13,243 - INFO - === Epoch 12 ===
2025-08-16 13:35:36,240 - INFO - train: {'epoch': 12, 'time_epoch': 82.75913, 'eta': 7096.19891, 'eta_hours': 1.97117, 'loss': 0.70924656, 'lr': 0.00098666, 'params': 517910, 'time_iter': 0.13241, 'accuracy': 0.74494, 'f1': 0.74494, 'accuracy-SBM': 0.74495, 'auc': 0.94968}
2025-08-16 13:35:40,426 - INFO - val: {'epoch': 12, 'time_epoch': 4.14084, 'loss': 0.69697613, 'lr': 0, 'params': 517910, 'time_iter': 0.06573, 'accuracy': 0.75269, 'f1': 0.75242, 'accuracy-SBM': 0.75237, 'auc': 0.95159}
2025-08-16 13:35:52,044 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:35:52,086 - INFO - test: {'epoch': 12, 'time_epoch': 4.21163, 'loss': 0.68650049, 'lr': 0, 'params': 517910, 'time_iter': 0.06685, 'accuracy': 0.75325, 'f1': 0.75315, 'accuracy-SBM': 0.75322, 'auc': 0.95317}
2025-08-16 13:35:52,089 - INFO - > Epoch 12: took 98.8s (avg 92.6s) | Best so far: epoch 11	train_loss: 0.7224 train_accuracy-SBM: 0.7395	val_loss: 0.6760 val_accuracy-SBM: 0.7567	test_loss: 0.6736 test_accuracy-SBM: 0.7582
2025-08-16 13:35:52,089 - INFO - === Epoch 13 ===
2025-08-16 13:37:15,361 - INFO - train: {'epoch': 13, 'time_epoch': 83.03956, 'eta': 7023.6883, 'eta_hours': 1.95102, 'loss': 0.70364328, 'lr': 0.0009826, 'params': 517910, 'time_iter': 0.13286, 'accuracy': 0.74633, 'f1': 0.74633, 'accuracy-SBM': 0.74633, 'auc': 0.95051}
2025-08-16 13:37:19,641 - INFO - val: {'epoch': 13, 'time_epoch': 4.22576, 'loss': 0.69484418, 'lr': 0, 'params': 517910, 'time_iter': 0.06708, 'accuracy': 0.75264, 'f1': 0.75267, 'accuracy-SBM': 0.75265, 'auc': 0.95204}
2025-08-16 13:37:25,506 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:37:25,545 - INFO - test: {'epoch': 13, 'time_epoch': 4.50876, 'loss': 0.68130131, 'lr': 0, 'params': 517910, 'time_iter': 0.07157, 'accuracy': 0.755, 'f1': 0.75483, 'accuracy-SBM': 0.75501, 'auc': 0.95412}
2025-08-16 13:37:25,547 - INFO - > Epoch 13: took 93.5s (avg 92.7s) | Best so far: epoch 11	train_loss: 0.7224 train_accuracy-SBM: 0.7395	val_loss: 0.6760 val_accuracy-SBM: 0.7567	test_loss: 0.6736 test_accuracy-SBM: 0.7582
2025-08-16 13:37:25,547 - INFO - === Epoch 14 ===
2025-08-16 13:38:47,766 - INFO - train: {'epoch': 14, 'time_epoch': 81.89592, 'eta': 6943.29321, 'eta_hours': 1.92869, 'loss': 0.69725866, 'lr': 0.00097802, 'params': 517910, 'time_iter': 0.13103, 'accuracy': 0.7489, 'f1': 0.7489, 'accuracy-SBM': 0.7489, 'auc': 0.95136}
2025-08-16 13:38:51,883 - INFO - val: {'epoch': 14, 'time_epoch': 4.0738, 'loss': 0.66124875, 'lr': 0, 'params': 517910, 'time_iter': 0.06466, 'accuracy': 0.76253, 'f1': 0.76242, 'accuracy-SBM': 0.76244, 'auc': 0.95667}
2025-08-16 13:38:57,629 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:38:57,667 - INFO - test: {'epoch': 14, 'time_epoch': 4.33086, 'loss': 0.67270234, 'lr': 0, 'params': 517910, 'time_iter': 0.06874, 'accuracy': 0.75904, 'f1': 0.75905, 'accuracy-SBM': 0.75895, 'auc': 0.95516}
2025-08-16 13:38:57,669 - INFO - > Epoch 14: took 92.1s (avg 92.6s) | Best so far: epoch 14	train_loss: 0.6973 train_accuracy-SBM: 0.7489	val_loss: 0.6612 val_accuracy-SBM: 0.7624	test_loss: 0.6727 test_accuracy-SBM: 0.7590
2025-08-16 13:38:57,669 - INFO - === Epoch 15 ===
2025-08-16 13:40:18,205 - INFO - train: {'epoch': 15, 'time_epoch': 80.151, 'eta': 6853.54969, 'eta_hours': 1.90376, 'loss': 0.69363909, 'lr': 0.00097291, 'params': 517910, 'time_iter': 0.12824, 'accuracy': 0.74956, 'f1': 0.74956, 'accuracy-SBM': 0.74956, 'auc': 0.95188}
2025-08-16 13:40:22,313 - INFO - val: {'epoch': 15, 'time_epoch': 4.06394, 'loss': 0.66451446, 'lr': 0, 'params': 517910, 'time_iter': 0.06451, 'accuracy': 0.76172, 'f1': 0.76159, 'accuracy-SBM': 0.76156, 'auc': 0.95622}
2025-08-16 13:40:28,229 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:40:28,267 - INFO - test: {'epoch': 15, 'time_epoch': 4.30447, 'loss': 0.65911729, 'lr': 0, 'params': 517910, 'time_iter': 0.06832, 'accuracy': 0.7614, 'f1': 0.76129, 'accuracy-SBM': 0.7613, 'auc': 0.95693}
2025-08-16 13:40:28,269 - INFO - > Epoch 15: took 90.6s (avg 92.5s) | Best so far: epoch 14	train_loss: 0.6973 train_accuracy-SBM: 0.7489	val_loss: 0.6612 val_accuracy-SBM: 0.7624	test_loss: 0.6727 test_accuracy-SBM: 0.7590
2025-08-16 13:40:28,269 - INFO - === Epoch 16 ===
2025-08-16 13:41:49,272 - INFO - train: {'epoch': 16, 'time_epoch': 80.77302, 'eta': 6767.97162, 'eta_hours': 1.87999, 'loss': 0.68973208, 'lr': 0.00096728, 'params': 517910, 'time_iter': 0.12924, 'accuracy': 0.75165, 'f1': 0.75165, 'accuracy-SBM': 0.75165, 'auc': 0.9524}
2025-08-16 13:41:53,480 - INFO - val: {'epoch': 16, 'time_epoch': 4.15607, 'loss': 0.66905831, 'lr': 0, 'params': 517910, 'time_iter': 0.06597, 'accuracy': 0.76058, 'f1': 0.76056, 'accuracy-SBM': 0.7605, 'auc': 0.95584}
2025-08-16 13:41:59,798 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:41:59,837 - INFO - test: {'epoch': 16, 'time_epoch': 4.4413, 'loss': 0.67121191, 'lr': 0, 'params': 517910, 'time_iter': 0.0705, 'accuracy': 0.7588, 'f1': 0.75866, 'accuracy-SBM': 0.75876, 'auc': 0.95543}
2025-08-16 13:41:59,838 - INFO - > Epoch 16: took 91.6s (avg 92.5s) | Best so far: epoch 14	train_loss: 0.6973 train_accuracy-SBM: 0.7489	val_loss: 0.6612 val_accuracy-SBM: 0.7624	test_loss: 0.6727 test_accuracy-SBM: 0.7590
2025-08-16 13:41:59,839 - INFO - === Epoch 17 ===
2025-08-16 13:43:26,854 - INFO - train: {'epoch': 17, 'time_epoch': 86.77789, 'eta': 6710.28296, 'eta_hours': 1.86397, 'loss': 0.68647158, 'lr': 0.00096114, 'params': 517910, 'time_iter': 0.13884, 'accuracy': 0.75148, 'f1': 0.75147, 'accuracy-SBM': 0.75148, 'auc': 0.95288}
2025-08-16 13:43:31,165 - INFO - val: {'epoch': 17, 'time_epoch': 4.26481, 'loss': 0.66067579, 'lr': 0, 'params': 517910, 'time_iter': 0.0677, 'accuracy': 0.76412, 'f1': 0.76434, 'accuracy-SBM': 0.76428, 'auc': 0.95675}
2025-08-16 13:43:37,029 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:43:37,068 - INFO - test: {'epoch': 17, 'time_epoch': 4.28723, 'loss': 0.6561467, 'lr': 0, 'params': 517910, 'time_iter': 0.06805, 'accuracy': 0.76318, 'f1': 0.76319, 'accuracy-SBM': 0.76327, 'auc': 0.95748}
2025-08-16 13:43:37,070 - INFO - > Epoch 17: took 97.2s (avg 92.7s) | Best so far: epoch 17	train_loss: 0.6865 train_accuracy-SBM: 0.7515	val_loss: 0.6607 val_accuracy-SBM: 0.7643	test_loss: 0.6561 test_accuracy-SBM: 0.7633
2025-08-16 13:43:37,070 - INFO - === Epoch 18 ===
2025-08-16 13:45:02,699 - INFO - train: {'epoch': 18, 'time_epoch': 85.38846, 'eta': 6643.60892, 'eta_hours': 1.84545, 'loss': 0.67857875, 'lr': 0.0009545, 'params': 517910, 'time_iter': 0.13662, 'accuracy': 0.75509, 'f1': 0.75509, 'accuracy-SBM': 0.75509, 'auc': 0.9539}
2025-08-16 13:45:06,969 - INFO - val: {'epoch': 18, 'time_epoch': 4.22501, 'loss': 0.65211015, 'lr': 0, 'params': 517910, 'time_iter': 0.06706, 'accuracy': 0.76667, 'f1': 0.7667, 'accuracy-SBM': 0.76665, 'auc': 0.95769}
2025-08-16 13:45:30,124 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:45:30,165 - INFO - test: {'epoch': 18, 'time_epoch': 4.56182, 'loss': 0.65122083, 'lr': 0, 'params': 517910, 'time_iter': 0.07241, 'accuracy': 0.76426, 'f1': 0.76432, 'accuracy-SBM': 0.76444, 'auc': 0.95802}
2025-08-16 13:45:30,168 - INFO - > Epoch 18: took 113.1s (avg 93.8s) | Best so far: epoch 18	train_loss: 0.6786 train_accuracy-SBM: 0.7551	val_loss: 0.6521 val_accuracy-SBM: 0.7667	test_loss: 0.6512 test_accuracy-SBM: 0.7644
2025-08-16 13:45:30,168 - INFO - === Epoch 19 ===
2025-08-16 13:46:55,340 - INFO - train: {'epoch': 19, 'time_epoch': 84.82735, 'eta': 6572.81901, 'eta_hours': 1.82578, 'loss': 0.67633599, 'lr': 0.00094736, 'params': 517910, 'time_iter': 0.13572, 'accuracy': 0.75557, 'f1': 0.75557, 'accuracy-SBM': 0.75557, 'auc': 0.95423}
2025-08-16 13:46:59,520 - INFO - val: {'epoch': 19, 'time_epoch': 4.13508, 'loss': 0.66192078, 'lr': 0, 'params': 517910, 'time_iter': 0.06564, 'accuracy': 0.76333, 'f1': 0.7632, 'accuracy-SBM': 0.76314, 'auc': 0.95633}
2025-08-16 13:47:05,302 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:47:05,340 - INFO - test: {'epoch': 19, 'time_epoch': 4.44467, 'loss': 0.66026956, 'lr': 0, 'params': 517910, 'time_iter': 0.07055, 'accuracy': 0.76446, 'f1': 0.76447, 'accuracy-SBM': 0.76442, 'auc': 0.95659}
2025-08-16 13:47:05,342 - INFO - > Epoch 19: took 95.2s (avg 93.9s) | Best so far: epoch 18	train_loss: 0.6786 train_accuracy-SBM: 0.7551	val_loss: 0.6521 val_accuracy-SBM: 0.7667	test_loss: 0.6512 test_accuracy-SBM: 0.7644
2025-08-16 13:47:05,342 - INFO - === Epoch 20 ===
2025-08-16 13:48:32,083 - INFO - train: {'epoch': 20, 'time_epoch': 86.46905, 'eta': 6506.8681, 'eta_hours': 1.80746, 'loss': 0.67299371, 'lr': 0.00093974, 'params': 517910, 'time_iter': 0.13835, 'accuracy': 0.75696, 'f1': 0.75696, 'accuracy-SBM': 0.75696, 'auc': 0.95467}
2025-08-16 13:48:36,234 - INFO - val: {'epoch': 20, 'time_epoch': 4.106, 'loss': 0.64958151, 'lr': 0, 'params': 517910, 'time_iter': 0.06517, 'accuracy': 0.76598, 'f1': 0.76576, 'accuracy-SBM': 0.76565, 'auc': 0.95815}
2025-08-16 13:48:41,928 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:48:41,968 - INFO - test: {'epoch': 20, 'time_epoch': 4.42365, 'loss': 0.64739334, 'lr': 0, 'params': 517910, 'time_iter': 0.07022, 'accuracy': 0.76537, 'f1': 0.76533, 'accuracy-SBM': 0.76529, 'auc': 0.95856}
2025-08-16 13:48:41,970 - INFO - > Epoch 20: took 96.6s (avg 94.0s) | Best so far: epoch 18	train_loss: 0.6786 train_accuracy-SBM: 0.7551	val_loss: 0.6521 val_accuracy-SBM: 0.7667	test_loss: 0.6512 test_accuracy-SBM: 0.7644
2025-08-16 13:48:41,970 - INFO - === Epoch 21 ===
2025-08-16 13:50:08,374 - INFO - train: {'epoch': 21, 'time_epoch': 86.01264, 'eta': 6437.43375, 'eta_hours': 1.78818, 'loss': 0.66949751, 'lr': 0.00093163, 'params': 517910, 'time_iter': 0.13762, 'accuracy': 0.75884, 'f1': 0.75884, 'accuracy-SBM': 0.75884, 'auc': 0.95511}
2025-08-16 13:50:12,634 - INFO - val: {'epoch': 21, 'time_epoch': 4.21266, 'loss': 0.64560465, 'lr': 0, 'params': 517910, 'time_iter': 0.06687, 'accuracy': 0.76978, 'f1': 0.76978, 'accuracy-SBM': 0.76977, 'auc': 0.9584}
2025-08-16 13:50:20,163 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:50:20,203 - INFO - test: {'epoch': 21, 'time_epoch': 4.39685, 'loss': 0.63887787, 'lr': 0, 'params': 517910, 'time_iter': 0.06979, 'accuracy': 0.76926, 'f1': 0.76917, 'accuracy-SBM': 0.76925, 'auc': 0.95931}
2025-08-16 13:50:20,206 - INFO - > Epoch 21: took 98.2s (avg 94.2s) | Best so far: epoch 21	train_loss: 0.6695 train_accuracy-SBM: 0.7588	val_loss: 0.6456 val_accuracy-SBM: 0.7698	test_loss: 0.6389 test_accuracy-SBM: 0.7692
2025-08-16 13:50:20,206 - INFO - === Epoch 22 ===
2025-08-16 13:51:46,571 - INFO - train: {'epoch': 22, 'time_epoch': 86.12685, 'eta': 6366.94015, 'eta_hours': 1.76859, 'loss': 0.66536934, 'lr': 0.00092305, 'params': 517910, 'time_iter': 0.1378, 'accuracy': 0.75991, 'f1': 0.75991, 'accuracy-SBM': 0.75991, 'auc': 0.95568}
2025-08-16 13:51:50,872 - INFO - val: {'epoch': 22, 'time_epoch': 4.25171, 'loss': 0.64810541, 'lr': 0, 'params': 517910, 'time_iter': 0.06749, 'accuracy': 0.76988, 'f1': 0.76965, 'accuracy-SBM': 0.76962, 'auc': 0.95822}
2025-08-16 13:51:56,822 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:51:56,866 - INFO - test: {'epoch': 22, 'time_epoch': 4.64655, 'loss': 0.64729484, 'lr': 0, 'params': 517910, 'time_iter': 0.07375, 'accuracy': 0.767, 'f1': 0.76695, 'accuracy-SBM': 0.76685, 'auc': 0.95836}
2025-08-16 13:51:56,872 - INFO - > Epoch 22: took 96.7s (avg 94.3s) | Best so far: epoch 21	train_loss: 0.6695 train_accuracy-SBM: 0.7588	val_loss: 0.6456 val_accuracy-SBM: 0.7698	test_loss: 0.6389 test_accuracy-SBM: 0.7692
2025-08-16 13:51:56,872 - INFO - === Epoch 23 ===
2025-08-16 13:53:26,772 - INFO - train: {'epoch': 23, 'time_epoch': 89.61974, 'eta': 6306.20458, 'eta_hours': 1.75172, 'loss': 0.6657467, 'lr': 0.000914, 'params': 517910, 'time_iter': 0.14339, 'accuracy': 0.75954, 'f1': 0.75954, 'accuracy-SBM': 0.75954, 'auc': 0.95561}
2025-08-16 13:53:30,957 - INFO - val: {'epoch': 23, 'time_epoch': 4.11793, 'loss': 0.65956828, 'lr': 0, 'params': 517910, 'time_iter': 0.06536, 'accuracy': 0.76445, 'f1': 0.7645, 'accuracy-SBM': 0.76455, 'auc': 0.95667}
2025-08-16 13:53:36,668 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:53:36,707 - INFO - test: {'epoch': 23, 'time_epoch': 4.40138, 'loss': 0.65584077, 'lr': 0, 'params': 517910, 'time_iter': 0.06986, 'accuracy': 0.76327, 'f1': 0.76327, 'accuracy-SBM': 0.76336, 'auc': 0.95725}
2025-08-16 13:53:36,709 - INFO - > Epoch 23: took 99.8s (avg 94.5s) | Best so far: epoch 21	train_loss: 0.6695 train_accuracy-SBM: 0.7588	val_loss: 0.6456 val_accuracy-SBM: 0.7698	test_loss: 0.6389 test_accuracy-SBM: 0.7692
2025-08-16 13:53:36,709 - INFO - === Epoch 24 ===
2025-08-16 13:55:05,063 - INFO - train: {'epoch': 24, 'time_epoch': 88.08879, 'eta': 6238.56545, 'eta_hours': 1.73293, 'loss': 0.65754837, 'lr': 0.00090451, 'params': 517910, 'time_iter': 0.14094, 'accuracy': 0.7621, 'f1': 0.76209, 'accuracy-SBM': 0.7621, 'auc': 0.95672}
2025-08-16 13:55:09,302 - INFO - val: {'epoch': 24, 'time_epoch': 4.19305, 'loss': 0.64673195, 'lr': 0, 'params': 517910, 'time_iter': 0.06656, 'accuracy': 0.76992, 'f1': 0.76974, 'accuracy-SBM': 0.76963, 'auc': 0.95849}
2025-08-16 13:55:15,068 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:55:15,107 - INFO - test: {'epoch': 24, 'time_epoch': 4.47249, 'loss': 0.64183411, 'lr': 0, 'params': 517910, 'time_iter': 0.07099, 'accuracy': 0.7709, 'f1': 0.77089, 'accuracy-SBM': 0.77075, 'auc': 0.95918}
2025-08-16 13:55:15,109 - INFO - > Epoch 24: took 98.4s (avg 94.7s) | Best so far: epoch 21	train_loss: 0.6695 train_accuracy-SBM: 0.7588	val_loss: 0.6456 val_accuracy-SBM: 0.7698	test_loss: 0.6389 test_accuracy-SBM: 0.7692
2025-08-16 13:55:15,109 - INFO - === Epoch 25 ===
2025-08-16 13:56:42,891 - INFO - train: {'epoch': 25, 'time_epoch': 87.54293, 'eta': 6167.79966, 'eta_hours': 1.71328, 'loss': 0.65555465, 'lr': 0.00089457, 'params': 517910, 'time_iter': 0.14007, 'accuracy': 0.76288, 'f1': 0.76288, 'accuracy-SBM': 0.76288, 'auc': 0.95698}
2025-08-16 13:56:47,142 - INFO - val: {'epoch': 25, 'time_epoch': 4.20593, 'loss': 0.63943268, 'lr': 0, 'params': 517910, 'time_iter': 0.06676, 'accuracy': 0.77289, 'f1': 0.77267, 'accuracy-SBM': 0.77271, 'auc': 0.95928}
2025-08-16 13:56:53,097 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:56:53,136 - INFO - test: {'epoch': 25, 'time_epoch': 4.4616, 'loss': 0.6407969, 'lr': 0, 'params': 517910, 'time_iter': 0.07082, 'accuracy': 0.76957, 'f1': 0.76959, 'accuracy-SBM': 0.76952, 'auc': 0.95924}
2025-08-16 13:56:53,138 - INFO - > Epoch 25: took 98.0s (avg 94.8s) | Best so far: epoch 25	train_loss: 0.6556 train_accuracy-SBM: 0.7629	val_loss: 0.6394 val_accuracy-SBM: 0.7727	test_loss: 0.6408 test_accuracy-SBM: 0.7695
2025-08-16 13:56:53,138 - INFO - === Epoch 26 ===
2025-08-16 13:58:20,114 - INFO - train: {'epoch': 26, 'time_epoch': 86.73029, 'eta': 6093.59398, 'eta_hours': 1.69266, 'loss': 0.65341338, 'lr': 0.0008842, 'params': 517910, 'time_iter': 0.13877, 'accuracy': 0.76387, 'f1': 0.76386, 'accuracy-SBM': 0.76387, 'auc': 0.95725}
2025-08-16 13:58:24,389 - INFO - val: {'epoch': 26, 'time_epoch': 4.22908, 'loss': 0.63872371, 'lr': 0, 'params': 517910, 'time_iter': 0.06713, 'accuracy': 0.77399, 'f1': 0.7737, 'accuracy-SBM': 0.77365, 'auc': 0.95938}
2025-08-16 13:58:31,305 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 13:58:31,351 - INFO - test: {'epoch': 26, 'time_epoch': 4.49578, 'loss': 0.63001293, 'lr': 0, 'params': 517910, 'time_iter': 0.07136, 'accuracy': 0.77274, 'f1': 0.77272, 'accuracy-SBM': 0.77261, 'auc': 0.96052}
2025-08-16 13:58:31,353 - INFO - > Epoch 26: took 98.2s (avg 94.9s) | Best so far: epoch 26	train_loss: 0.6534 train_accuracy-SBM: 0.7639	val_loss: 0.6387 val_accuracy-SBM: 0.7736	test_loss: 0.6300 test_accuracy-SBM: 0.7726
2025-08-16 13:58:31,353 - INFO - === Epoch 27 ===
2025-08-16 13:59:56,121 - INFO - train: {'epoch': 27, 'time_epoch': 84.52914, 'eta': 6012.83358, 'eta_hours': 1.67023, 'loss': 0.64693429, 'lr': 0.00087341, 'params': 517910, 'time_iter': 0.13525, 'accuracy': 0.76667, 'f1': 0.76667, 'accuracy-SBM': 0.76667, 'auc': 0.95806}
2025-08-16 14:00:00,347 - INFO - val: {'epoch': 27, 'time_epoch': 4.18106, 'loss': 0.64087632, 'lr': 0, 'params': 517910, 'time_iter': 0.06637, 'accuracy': 0.77202, 'f1': 0.77196, 'accuracy-SBM': 0.77193, 'auc': 0.95913}
2025-08-16 14:00:06,130 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:00:06,169 - INFO - test: {'epoch': 27, 'time_epoch': 4.28817, 'loss': 0.63016688, 'lr': 0, 'params': 517910, 'time_iter': 0.06807, 'accuracy': 0.77175, 'f1': 0.77169, 'accuracy-SBM': 0.77168, 'auc': 0.9606}
2025-08-16 14:00:06,171 - INFO - > Epoch 27: took 94.8s (avg 94.9s) | Best so far: epoch 26	train_loss: 0.6534 train_accuracy-SBM: 0.7639	val_loss: 0.6387 val_accuracy-SBM: 0.7736	test_loss: 0.6300 test_accuracy-SBM: 0.7726
2025-08-16 14:00:06,171 - INFO - === Epoch 28 ===
2025-08-16 14:01:30,764 - INFO - train: {'epoch': 28, 'time_epoch': 84.34312, 'eta': 5931.35785, 'eta_hours': 1.6476, 'loss': 0.64402518, 'lr': 0.00086221, 'params': 517910, 'time_iter': 0.13495, 'accuracy': 0.767, 'f1': 0.767, 'accuracy-SBM': 0.767, 'auc': 0.95846}
2025-08-16 14:01:35,068 - INFO - val: {'epoch': 28, 'time_epoch': 4.2584, 'loss': 0.64400926, 'lr': 0, 'params': 517910, 'time_iter': 0.06759, 'accuracy': 0.77105, 'f1': 0.77089, 'accuracy-SBM': 0.77086, 'auc': 0.95865}
2025-08-16 14:01:40,981 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:01:41,019 - INFO - test: {'epoch': 28, 'time_epoch': 4.55703, 'loss': 0.63395706, 'lr': 0, 'params': 517910, 'time_iter': 0.07233, 'accuracy': 0.77151, 'f1': 0.77139, 'accuracy-SBM': 0.77147, 'auc': 0.96011}
2025-08-16 14:01:41,149 - INFO - > Epoch 28: took 95.0s (avg 94.9s) | Best so far: epoch 26	train_loss: 0.6534 train_accuracy-SBM: 0.7639	val_loss: 0.6387 val_accuracy-SBM: 0.7736	test_loss: 0.6300 test_accuracy-SBM: 0.7726
2025-08-16 14:01:41,149 - INFO - === Epoch 29 ===
2025-08-16 14:03:06,513 - INFO - train: {'epoch': 29, 'time_epoch': 85.10926, 'eta': 5851.47862, 'eta_hours': 1.62541, 'loss': 0.64137637, 'lr': 0.00085062, 'params': 517910, 'time_iter': 0.13617, 'accuracy': 0.76821, 'f1': 0.76821, 'accuracy-SBM': 0.76821, 'auc': 0.95879}
2025-08-16 14:03:10,792 - INFO - val: {'epoch': 29, 'time_epoch': 4.23458, 'loss': 0.63105899, 'lr': 0, 'params': 517910, 'time_iter': 0.06722, 'accuracy': 0.77429, 'f1': 0.7742, 'accuracy-SBM': 0.77432, 'auc': 0.96026}
2025-08-16 14:03:18,105 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:03:18,144 - INFO - test: {'epoch': 29, 'time_epoch': 4.51679, 'loss': 0.63376454, 'lr': 0, 'params': 517910, 'time_iter': 0.0717, 'accuracy': 0.77435, 'f1': 0.77444, 'accuracy-SBM': 0.77436, 'auc': 0.95999}
2025-08-16 14:03:18,146 - INFO - > Epoch 29: took 97.0s (avg 95.0s) | Best so far: epoch 29	train_loss: 0.6414 train_accuracy-SBM: 0.7682	val_loss: 0.6311 val_accuracy-SBM: 0.7743	test_loss: 0.6338 test_accuracy-SBM: 0.7744
2025-08-16 14:03:18,146 - INFO - === Epoch 30 ===
2025-08-16 14:04:41,340 - INFO - train: {'epoch': 30, 'time_epoch': 82.93724, 'eta': 5766.42746, 'eta_hours': 1.60179, 'loss': 0.63695005, 'lr': 0.00083864, 'params': 517910, 'time_iter': 0.1327, 'accuracy': 0.7704, 'f1': 0.7704, 'accuracy-SBM': 0.7704, 'auc': 0.95936}
2025-08-16 14:04:45,432 - INFO - val: {'epoch': 30, 'time_epoch': 4.04821, 'loss': 0.63455503, 'lr': 0, 'params': 517910, 'time_iter': 0.06426, 'accuracy': 0.77272, 'f1': 0.7725, 'accuracy-SBM': 0.77244, 'auc': 0.95985}
2025-08-16 14:04:51,237 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:04:51,275 - INFO - test: {'epoch': 30, 'time_epoch': 4.41749, 'loss': 0.62012937, 'lr': 0, 'params': 517910, 'time_iter': 0.07012, 'accuracy': 0.77469, 'f1': 0.7747, 'accuracy-SBM': 0.7746, 'auc': 0.96184}
2025-08-16 14:04:51,277 - INFO - > Epoch 30: took 93.1s (avg 94.9s) | Best so far: epoch 29	train_loss: 0.6414 train_accuracy-SBM: 0.7682	val_loss: 0.6311 val_accuracy-SBM: 0.7743	test_loss: 0.6338 test_accuracy-SBM: 0.7744
2025-08-16 14:04:51,277 - INFO - === Epoch 31 ===
2025-08-16 14:06:13,355 - INFO - train: {'epoch': 31, 'time_epoch': 81.81224, 'eta': 5679.11781, 'eta_hours': 1.57753, 'loss': 0.63451984, 'lr': 0.00082629, 'params': 517910, 'time_iter': 0.1309, 'accuracy': 0.77011, 'f1': 0.77011, 'accuracy-SBM': 0.77011, 'auc': 0.9597}
2025-08-16 14:06:17,643 - INFO - val: {'epoch': 31, 'time_epoch': 4.24276, 'loss': 0.63733957, 'lr': 0, 'params': 517910, 'time_iter': 0.06735, 'accuracy': 0.7739, 'f1': 0.7739, 'accuracy-SBM': 0.77393, 'auc': 0.95965}
2025-08-16 14:06:23,948 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:06:23,993 - INFO - test: {'epoch': 31, 'time_epoch': 4.53872, 'loss': 0.63007576, 'lr': 0, 'params': 517910, 'time_iter': 0.07204, 'accuracy': 0.77222, 'f1': 0.77239, 'accuracy-SBM': 0.77234, 'auc': 0.96079}
2025-08-16 14:06:23,996 - INFO - > Epoch 31: took 92.7s (avg 94.9s) | Best so far: epoch 29	train_loss: 0.6414 train_accuracy-SBM: 0.7682	val_loss: 0.6311 val_accuracy-SBM: 0.7743	test_loss: 0.6338 test_accuracy-SBM: 0.7744
2025-08-16 14:06:23,996 - INFO - === Epoch 32 ===
2025-08-16 14:07:47,628 - INFO - train: {'epoch': 32, 'time_epoch': 83.39055, 'eta': 5595.34577, 'eta_hours': 1.55426, 'loss': 0.63572911, 'lr': 0.00081359, 'params': 517910, 'time_iter': 0.13342, 'accuracy': 0.77031, 'f1': 0.77031, 'accuracy-SBM': 0.77031, 'auc': 0.95953}
2025-08-16 14:07:51,901 - INFO - val: {'epoch': 32, 'time_epoch': 4.2267, 'loss': 0.63233662, 'lr': 0, 'params': 517910, 'time_iter': 0.06709, 'accuracy': 0.77393, 'f1': 0.7738, 'accuracy-SBM': 0.77371, 'auc': 0.96011}
2025-08-16 14:07:58,144 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:07:58,182 - INFO - test: {'epoch': 32, 'time_epoch': 4.33859, 'loss': 0.62974781, 'lr': 0, 'params': 517910, 'time_iter': 0.06887, 'accuracy': 0.77412, 'f1': 0.77422, 'accuracy-SBM': 0.77407, 'auc': 0.96046}
2025-08-16 14:07:58,184 - INFO - > Epoch 32: took 94.2s (avg 94.9s) | Best so far: epoch 29	train_loss: 0.6414 train_accuracy-SBM: 0.7682	val_loss: 0.6311 val_accuracy-SBM: 0.7743	test_loss: 0.6338 test_accuracy-SBM: 0.7744
2025-08-16 14:07:58,184 - INFO - === Epoch 33 ===
2025-08-16 14:09:20,174 - INFO - train: {'epoch': 33, 'time_epoch': 81.75354, 'eta': 5508.41846, 'eta_hours': 1.53012, 'loss': 0.62851196, 'lr': 0.00080054, 'params': 517910, 'time_iter': 0.13081, 'accuracy': 0.77273, 'f1': 0.77273, 'accuracy-SBM': 0.77273, 'auc': 0.96044}
2025-08-16 14:09:24,439 - INFO - val: {'epoch': 33, 'time_epoch': 4.21937, 'loss': 0.63220404, 'lr': 0, 'params': 517910, 'time_iter': 0.06697, 'accuracy': 0.77526, 'f1': 0.7751, 'accuracy-SBM': 0.77504, 'auc': 0.9604}
2025-08-16 14:09:30,806 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:09:30,846 - INFO - test: {'epoch': 33, 'time_epoch': 4.48367, 'loss': 0.61984393, 'lr': 0, 'params': 517910, 'time_iter': 0.07117, 'accuracy': 0.7769, 'f1': 0.77692, 'accuracy-SBM': 0.77687, 'auc': 0.9619}
2025-08-16 14:09:30,849 - INFO - > Epoch 33: took 92.7s (avg 94.8s) | Best so far: epoch 33	train_loss: 0.6285 train_accuracy-SBM: 0.7727	val_loss: 0.6322 val_accuracy-SBM: 0.7750	test_loss: 0.6198 test_accuracy-SBM: 0.7769
2025-08-16 14:09:30,849 - INFO - === Epoch 34 ===
2025-08-16 14:10:53,543 - INFO - train: {'epoch': 34, 'time_epoch': 82.457, 'eta': 5423.09323, 'eta_hours': 1.50641, 'loss': 0.62562213, 'lr': 0.00078716, 'params': 517910, 'time_iter': 0.13193, 'accuracy': 0.77346, 'f1': 0.77346, 'accuracy-SBM': 0.77346, 'auc': 0.96081}
2025-08-16 14:10:57,765 - INFO - val: {'epoch': 34, 'time_epoch': 4.17781, 'loss': 0.63199992, 'lr': 0, 'params': 517910, 'time_iter': 0.06631, 'accuracy': 0.77435, 'f1': 0.7743, 'accuracy-SBM': 0.77423, 'auc': 0.96023}
2025-08-16 14:11:04,522 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:11:04,562 - INFO - test: {'epoch': 34, 'time_epoch': 4.42176, 'loss': 0.62790485, 'lr': 0, 'params': 517910, 'time_iter': 0.07019, 'accuracy': 0.77523, 'f1': 0.77527, 'accuracy-SBM': 0.77527, 'auc': 0.96089}
2025-08-16 14:11:04,590 - INFO - > Epoch 34: took 93.7s (avg 94.8s) | Best so far: epoch 33	train_loss: 0.6285 train_accuracy-SBM: 0.7727	val_loss: 0.6322 val_accuracy-SBM: 0.7750	test_loss: 0.6198 test_accuracy-SBM: 0.7769
2025-08-16 14:11:04,590 - INFO - === Epoch 35 ===
2025-08-16 14:12:27,286 - INFO - train: {'epoch': 35, 'time_epoch': 82.46204, 'eta': 5337.93629, 'eta_hours': 1.48276, 'loss': 0.62350244, 'lr': 0.00077347, 'params': 517910, 'time_iter': 0.13194, 'accuracy': 0.77446, 'f1': 0.77446, 'accuracy-SBM': 0.77446, 'auc': 0.96106}
2025-08-16 14:12:31,524 - INFO - val: {'epoch': 35, 'time_epoch': 4.19304, 'loss': 0.62888641, 'lr': 0, 'params': 517910, 'time_iter': 0.06656, 'accuracy': 0.7741, 'f1': 0.77392, 'accuracy-SBM': 0.77393, 'auc': 0.96051}
2025-08-16 14:12:37,604 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:12:37,650 - INFO - test: {'epoch': 35, 'time_epoch': 4.43387, 'loss': 0.62771511, 'lr': 0, 'params': 517910, 'time_iter': 0.07038, 'accuracy': 0.77339, 'f1': 0.77331, 'accuracy-SBM': 0.77329, 'auc': 0.96063}
2025-08-16 14:12:37,652 - INFO - > Epoch 35: took 93.1s (avg 94.7s) | Best so far: epoch 33	train_loss: 0.6285 train_accuracy-SBM: 0.7727	val_loss: 0.6322 val_accuracy-SBM: 0.7750	test_loss: 0.6198 test_accuracy-SBM: 0.7769
2025-08-16 14:12:37,652 - INFO - === Epoch 36 ===
2025-08-16 14:14:02,032 - INFO - train: {'epoch': 36, 'time_epoch': 84.14446, 'eta': 5255.78968, 'eta_hours': 1.45994, 'loss': 0.62304449, 'lr': 0.00075948, 'params': 517910, 'time_iter': 0.13463, 'accuracy': 0.77435, 'f1': 0.77435, 'accuracy-SBM': 0.77435, 'auc': 0.96115}
2025-08-16 14:14:06,277 - INFO - val: {'epoch': 36, 'time_epoch': 4.19286, 'loss': 0.63950468, 'lr': 0, 'params': 517910, 'time_iter': 0.06655, 'accuracy': 0.77255, 'f1': 0.77235, 'accuracy-SBM': 0.77227, 'auc': 0.95946}
2025-08-16 14:14:12,037 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:14:12,075 - INFO - test: {'epoch': 36, 'time_epoch': 4.43775, 'loss': 0.62636841, 'lr': 0, 'params': 517910, 'time_iter': 0.07044, 'accuracy': 0.77373, 'f1': 0.7738, 'accuracy-SBM': 0.77372, 'auc': 0.96105}
2025-08-16 14:14:12,077 - INFO - > Epoch 36: took 94.4s (avg 94.7s) | Best so far: epoch 33	train_loss: 0.6285 train_accuracy-SBM: 0.7727	val_loss: 0.6322 val_accuracy-SBM: 0.7750	test_loss: 0.6198 test_accuracy-SBM: 0.7769
2025-08-16 14:14:12,077 - INFO - === Epoch 37 ===
2025-08-16 14:15:36,600 - INFO - train: {'epoch': 37, 'time_epoch': 84.28513, 'eta': 5173.76743, 'eta_hours': 1.43716, 'loss': 0.61869359, 'lr': 0.00074521, 'params': 517910, 'time_iter': 0.13486, 'accuracy': 0.77564, 'f1': 0.77564, 'accuracy-SBM': 0.77564, 'auc': 0.96169}
2025-08-16 14:15:40,764 - INFO - val: {'epoch': 37, 'time_epoch': 4.10365, 'loss': 0.63406892, 'lr': 0, 'params': 517910, 'time_iter': 0.06514, 'accuracy': 0.77378, 'f1': 0.77389, 'accuracy-SBM': 0.7739, 'auc': 0.96004}
2025-08-16 14:15:46,563 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:15:46,599 - INFO - test: {'epoch': 37, 'time_epoch': 4.0193, 'loss': 0.62059758, 'lr': 0, 'params': 517910, 'time_iter': 0.0638, 'accuracy': 0.7782, 'f1': 0.77818, 'accuracy-SBM': 0.77823, 'auc': 0.96171}
2025-08-16 14:15:46,601 - INFO - > Epoch 37: took 94.5s (avg 94.7s) | Best so far: epoch 33	train_loss: 0.6285 train_accuracy-SBM: 0.7727	val_loss: 0.6322 val_accuracy-SBM: 0.7750	test_loss: 0.6198 test_accuracy-SBM: 0.7769
2025-08-16 14:15:46,601 - INFO - === Epoch 38 ===
2025-08-16 14:17:08,726 - INFO - train: {'epoch': 38, 'time_epoch': 81.89715, 'eta': 5087.8941, 'eta_hours': 1.4133, 'loss': 0.61566717, 'lr': 0.00073067, 'params': 517910, 'time_iter': 0.13104, 'accuracy': 0.77665, 'f1': 0.77665, 'accuracy-SBM': 0.77665, 'auc': 0.96207}
2025-08-16 14:17:12,975 - INFO - val: {'epoch': 38, 'time_epoch': 4.19606, 'loss': 0.64120238, 'lr': 0, 'params': 517910, 'time_iter': 0.0666, 'accuracy': 0.7723, 'f1': 0.7723, 'accuracy-SBM': 0.77236, 'auc': 0.95947}
2025-08-16 14:17:18,789 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:17:18,827 - INFO - test: {'epoch': 38, 'time_epoch': 4.46623, 'loss': 0.64176369, 'lr': 0, 'params': 517910, 'time_iter': 0.07089, 'accuracy': 0.77173, 'f1': 0.77169, 'accuracy-SBM': 0.77171, 'auc': 0.95931}
2025-08-16 14:17:18,829 - INFO - > Epoch 38: took 92.2s (avg 94.6s) | Best so far: epoch 33	train_loss: 0.6285 train_accuracy-SBM: 0.7727	val_loss: 0.6322 val_accuracy-SBM: 0.7750	test_loss: 0.6198 test_accuracy-SBM: 0.7769
2025-08-16 14:17:18,829 - INFO - === Epoch 39 ===
2025-08-16 14:18:42,422 - INFO - train: {'epoch': 39, 'time_epoch': 83.2691, 'eta': 5004.27749, 'eta_hours': 1.39008, 'loss': 0.612056, 'lr': 0.00071588, 'params': 517910, 'time_iter': 0.13323, 'accuracy': 0.77851, 'f1': 0.77851, 'accuracy-SBM': 0.77851, 'auc': 0.96247}
2025-08-16 14:18:46,574 - INFO - val: {'epoch': 39, 'time_epoch': 4.1076, 'loss': 0.62698493, 'lr': 0, 'params': 517910, 'time_iter': 0.0652, 'accuracy': 0.77599, 'f1': 0.77584, 'accuracy-SBM': 0.7759, 'auc': 0.96078}
2025-08-16 14:18:52,336 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:18:52,384 - INFO - test: {'epoch': 39, 'time_epoch': 4.38522, 'loss': 0.62299002, 'lr': 0, 'params': 517910, 'time_iter': 0.06961, 'accuracy': 0.77542, 'f1': 0.77538, 'accuracy-SBM': 0.77541, 'auc': 0.9614}
2025-08-16 14:18:52,386 - INFO - > Epoch 39: took 93.6s (avg 94.6s) | Best so far: epoch 39	train_loss: 0.6121 train_accuracy-SBM: 0.7785	val_loss: 0.6270 val_accuracy-SBM: 0.7759	test_loss: 0.6230 test_accuracy-SBM: 0.7754
2025-08-16 14:18:52,386 - INFO - === Epoch 40 ===
2025-08-16 14:20:17,015 - INFO - train: {'epoch': 40, 'time_epoch': 84.40161, 'eta': 4922.30755, 'eta_hours': 1.36731, 'loss': 0.60907977, 'lr': 0.00070085, 'params': 517910, 'time_iter': 0.13504, 'accuracy': 0.77956, 'f1': 0.77956, 'accuracy-SBM': 0.77956, 'auc': 0.96286}
2025-08-16 14:20:21,269 - INFO - val: {'epoch': 40, 'time_epoch': 4.1949, 'loss': 0.62741125, 'lr': 0, 'params': 517910, 'time_iter': 0.06659, 'accuracy': 0.77902, 'f1': 0.77883, 'accuracy-SBM': 0.7788, 'auc': 0.96096}
2025-08-16 14:20:28,070 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:20:28,109 - INFO - test: {'epoch': 40, 'time_epoch': 4.44117, 'loss': 0.61212692, 'lr': 0, 'params': 517910, 'time_iter': 0.07049, 'accuracy': 0.77979, 'f1': 0.77977, 'accuracy-SBM': 0.77974, 'auc': 0.96295}
2025-08-16 14:20:28,111 - INFO - > Epoch 40: took 95.7s (avg 94.6s) | Best so far: epoch 40	train_loss: 0.6091 train_accuracy-SBM: 0.7796	val_loss: 0.6274 val_accuracy-SBM: 0.7788	test_loss: 0.6121 test_accuracy-SBM: 0.7797
2025-08-16 14:20:28,111 - INFO - === Epoch 41 ===
2025-08-16 14:21:51,541 - INFO - train: {'epoch': 41, 'time_epoch': 83.20066, 'eta': 4838.56336, 'eta_hours': 1.34405, 'loss': 0.60804941, 'lr': 0.0006856, 'params': 517910, 'time_iter': 0.13312, 'accuracy': 0.78005, 'f1': 0.78005, 'accuracy-SBM': 0.78006, 'auc': 0.96297}
2025-08-16 14:21:55,663 - INFO - val: {'epoch': 41, 'time_epoch': 4.07788, 'loss': 0.61490048, 'lr': 0, 'params': 517910, 'time_iter': 0.06473, 'accuracy': 0.7804, 'f1': 0.78026, 'accuracy-SBM': 0.78026, 'auc': 0.96235}
2025-08-16 14:22:01,374 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:22:01,412 - INFO - test: {'epoch': 41, 'time_epoch': 4.30033, 'loss': 0.61793961, 'lr': 0, 'params': 517910, 'time_iter': 0.06826, 'accuracy': 0.77765, 'f1': 0.77763, 'accuracy-SBM': 0.7776, 'auc': 0.96197}
2025-08-16 14:22:01,414 - INFO - > Epoch 41: took 93.3s (avg 94.6s) | Best so far: epoch 41	train_loss: 0.6080 train_accuracy-SBM: 0.7801	val_loss: 0.6149 val_accuracy-SBM: 0.7803	test_loss: 0.6179 test_accuracy-SBM: 0.7776
2025-08-16 14:22:01,414 - INFO - === Epoch 42 ===
2025-08-16 14:23:23,356 - INFO - train: {'epoch': 42, 'time_epoch': 81.61992, 'eta': 4752.74906, 'eta_hours': 1.32021, 'loss': 0.60621804, 'lr': 0.00067015, 'params': 517910, 'time_iter': 0.13059, 'accuracy': 0.78053, 'f1': 0.78053, 'accuracy-SBM': 0.78053, 'auc': 0.9632}
2025-08-16 14:23:27,488 - INFO - val: {'epoch': 42, 'time_epoch': 4.09011, 'loss': 0.61894448, 'lr': 0, 'params': 517910, 'time_iter': 0.06492, 'accuracy': 0.7788, 'f1': 0.77865, 'accuracy-SBM': 0.77873, 'auc': 0.96163}
2025-08-16 14:23:34,047 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:23:34,083 - INFO - test: {'epoch': 42, 'time_epoch': 4.31542, 'loss': 0.61901359, 'lr': 0, 'params': 517910, 'time_iter': 0.0685, 'accuracy': 0.77706, 'f1': 0.77706, 'accuracy-SBM': 0.77702, 'auc': 0.96174}
2025-08-16 14:23:34,088 - INFO - > Epoch 42: took 92.7s (avg 94.6s) | Best so far: epoch 41	train_loss: 0.6080 train_accuracy-SBM: 0.7801	val_loss: 0.6149 val_accuracy-SBM: 0.7803	test_loss: 0.6179 test_accuracy-SBM: 0.7776
2025-08-16 14:23:34,088 - INFO - === Epoch 43 ===
2025-08-16 14:24:54,182 - INFO - train: {'epoch': 43, 'time_epoch': 79.86496, 'eta': 4664.89181, 'eta_hours': 1.2958, 'loss': 0.60078642, 'lr': 0.00065451, 'params': 517910, 'time_iter': 0.12778, 'accuracy': 0.78191, 'f1': 0.78191, 'accuracy-SBM': 0.78191, 'auc': 0.96387}
2025-08-16 14:24:58,231 - INFO - val: {'epoch': 43, 'time_epoch': 4.00601, 'loss': 0.63196873, 'lr': 0, 'params': 517910, 'time_iter': 0.06359, 'accuracy': 0.7755, 'f1': 0.77546, 'accuracy-SBM': 0.77548, 'auc': 0.96029}
2025-08-16 14:25:03,723 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:25:03,760 - INFO - test: {'epoch': 43, 'time_epoch': 4.05228, 'loss': 0.62132422, 'lr': 0, 'params': 517910, 'time_iter': 0.06432, 'accuracy': 0.78021, 'f1': 0.78018, 'accuracy-SBM': 0.78023, 'auc': 0.96147}
2025-08-16 14:25:03,762 - INFO - > Epoch 43: took 89.7s (avg 94.4s) | Best so far: epoch 41	train_loss: 0.6080 train_accuracy-SBM: 0.7801	val_loss: 0.6149 val_accuracy-SBM: 0.7803	test_loss: 0.6179 test_accuracy-SBM: 0.7776
2025-08-16 14:25:03,762 - INFO - === Epoch 44 ===
2025-08-16 14:26:24,559 - INFO - train: {'epoch': 44, 'time_epoch': 80.17966, 'eta': 4577.77442, 'eta_hours': 1.2716, 'loss': 0.60153768, 'lr': 0.0006387, 'params': 517910, 'time_iter': 0.12829, 'accuracy': 0.7824, 'f1': 0.7824, 'accuracy-SBM': 0.7824, 'auc': 0.96377}
2025-08-16 14:26:28,608 - INFO - val: {'epoch': 44, 'time_epoch': 4.00597, 'loss': 0.62906605, 'lr': 0, 'params': 517910, 'time_iter': 0.06359, 'accuracy': 0.77802, 'f1': 0.77786, 'accuracy-SBM': 0.77779, 'auc': 0.96056}
2025-08-16 14:26:34,037 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:26:34,074 - INFO - test: {'epoch': 44, 'time_epoch': 4.10669, 'loss': 0.62413673, 'lr': 0, 'params': 517910, 'time_iter': 0.06519, 'accuracy': 0.77838, 'f1': 0.77833, 'accuracy-SBM': 0.77835, 'auc': 0.96116}
2025-08-16 14:26:34,076 - INFO - > Epoch 44: took 90.3s (avg 94.4s) | Best so far: epoch 41	train_loss: 0.6080 train_accuracy-SBM: 0.7801	val_loss: 0.6149 val_accuracy-SBM: 0.7803	test_loss: 0.6179 test_accuracy-SBM: 0.7776
2025-08-16 14:26:34,076 - INFO - === Epoch 45 ===
2025-08-16 14:27:54,147 - INFO - train: {'epoch': 45, 'time_epoch': 79.84658, 'eta': 4490.56767, 'eta_hours': 1.24738, 'loss': 0.59691776, 'lr': 0.00062274, 'params': 517910, 'time_iter': 0.12775, 'accuracy': 0.78379, 'f1': 0.78379, 'accuracy-SBM': 0.78379, 'auc': 0.96433}
2025-08-16 14:27:58,211 - INFO - val: {'epoch': 45, 'time_epoch': 4.02119, 'loss': 0.62772305, 'lr': 0, 'params': 517910, 'time_iter': 0.06383, 'accuracy': 0.77789, 'f1': 0.77771, 'accuracy-SBM': 0.77767, 'auc': 0.96084}
2025-08-16 14:28:03,769 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:28:03,806 - INFO - test: {'epoch': 45, 'time_epoch': 4.25304, 'loss': 0.62008651, 'lr': 0, 'params': 517910, 'time_iter': 0.06751, 'accuracy': 0.77805, 'f1': 0.77801, 'accuracy-SBM': 0.77798, 'auc': 0.9618}
2025-08-16 14:28:03,808 - INFO - > Epoch 45: took 89.7s (avg 94.3s) | Best so far: epoch 41	train_loss: 0.6080 train_accuracy-SBM: 0.7801	val_loss: 0.6149 val_accuracy-SBM: 0.7803	test_loss: 0.6179 test_accuracy-SBM: 0.7776
2025-08-16 14:28:03,808 - INFO - === Epoch 46 ===
2025-08-16 14:29:27,423 - INFO - train: {'epoch': 46, 'time_epoch': 83.38478, 'eta': 4407.664, 'eta_hours': 1.22435, 'loss': 0.59361344, 'lr': 0.00060665, 'params': 517910, 'time_iter': 0.13342, 'accuracy': 0.78479, 'f1': 0.78478, 'accuracy-SBM': 0.78479, 'auc': 0.96472}
2025-08-16 14:29:31,672 - INFO - val: {'epoch': 46, 'time_epoch': 4.20303, 'loss': 0.61829813, 'lr': 0, 'params': 517910, 'time_iter': 0.06671, 'accuracy': 0.77842, 'f1': 0.77833, 'accuracy-SBM': 0.77836, 'auc': 0.96177}
2025-08-16 14:29:37,455 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:29:37,494 - INFO - test: {'epoch': 46, 'time_epoch': 4.48617, 'loss': 0.60896857, 'lr': 0, 'params': 517910, 'time_iter': 0.07121, 'accuracy': 0.7799, 'f1': 0.77981, 'accuracy-SBM': 0.77982, 'auc': 0.96296}
2025-08-16 14:29:37,495 - INFO - > Epoch 46: took 93.7s (avg 94.2s) | Best so far: epoch 41	train_loss: 0.6080 train_accuracy-SBM: 0.7801	val_loss: 0.6149 val_accuracy-SBM: 0.7803	test_loss: 0.6179 test_accuracy-SBM: 0.7776
2025-08-16 14:29:37,496 - INFO - === Epoch 47 ===
2025-08-16 14:30:58,259 - INFO - train: {'epoch': 47, 'time_epoch': 80.53554, 'eta': 4321.6536, 'eta_hours': 1.20046, 'loss': 0.59282513, 'lr': 0.00059044, 'params': 517910, 'time_iter': 0.12886, 'accuracy': 0.78521, 'f1': 0.78521, 'accuracy-SBM': 0.78521, 'auc': 0.96483}
2025-08-16 14:31:02,347 - INFO - val: {'epoch': 47, 'time_epoch': 4.04466, 'loss': 0.6123739, 'lr': 0, 'params': 517910, 'time_iter': 0.0642, 'accuracy': 0.7812, 'f1': 0.7813, 'accuracy-SBM': 0.78109, 'auc': 0.96255}
2025-08-16 14:31:09,251 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:31:09,288 - INFO - test: {'epoch': 47, 'time_epoch': 4.28181, 'loss': 0.60971786, 'lr': 0, 'params': 517910, 'time_iter': 0.06797, 'accuracy': 0.78182, 'f1': 0.7819, 'accuracy-SBM': 0.7819, 'auc': 0.96292}
2025-08-16 14:31:09,290 - INFO - > Epoch 47: took 91.8s (avg 94.2s) | Best so far: epoch 47	train_loss: 0.5928 train_accuracy-SBM: 0.7852	val_loss: 0.6124 val_accuracy-SBM: 0.7811	test_loss: 0.6097 test_accuracy-SBM: 0.7819
2025-08-16 14:31:09,290 - INFO - === Epoch 48 ===
2025-08-16 14:32:29,440 - INFO - train: {'epoch': 48, 'time_epoch': 79.92484, 'eta': 4235.23104, 'eta_hours': 1.17645, 'loss': 0.58652427, 'lr': 0.00057413, 'params': 517910, 'time_iter': 0.12788, 'accuracy': 0.78698, 'f1': 0.78698, 'accuracy-SBM': 0.78698, 'auc': 0.96558}
2025-08-16 14:32:33,540 - INFO - val: {'epoch': 48, 'time_epoch': 4.05662, 'loss': 0.6230779, 'lr': 0, 'params': 517910, 'time_iter': 0.06439, 'accuracy': 0.77971, 'f1': 0.77965, 'accuracy-SBM': 0.7795, 'auc': 0.96166}
2025-08-16 14:32:39,162 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:32:39,200 - INFO - test: {'epoch': 48, 'time_epoch': 4.31219, 'loss': 0.61370775, 'lr': 0, 'params': 517910, 'time_iter': 0.06845, 'accuracy': 0.78012, 'f1': 0.78017, 'accuracy-SBM': 0.78011, 'auc': 0.96275}
2025-08-16 14:32:39,202 - INFO - > Epoch 48: took 89.9s (avg 94.1s) | Best so far: epoch 47	train_loss: 0.5928 train_accuracy-SBM: 0.7852	val_loss: 0.6124 val_accuracy-SBM: 0.7811	test_loss: 0.6097 test_accuracy-SBM: 0.7819
2025-08-16 14:32:39,202 - INFO - === Epoch 49 ===
2025-08-16 14:34:00,537 - INFO - train: {'epoch': 49, 'time_epoch': 81.10662, 'eta': 4150.25017, 'eta_hours': 1.15285, 'loss': 0.58474463, 'lr': 0.00055774, 'params': 517910, 'time_iter': 0.12977, 'accuracy': 0.78773, 'f1': 0.78773, 'accuracy-SBM': 0.78773, 'auc': 0.96578}
2025-08-16 14:34:04,701 - INFO - val: {'epoch': 49, 'time_epoch': 4.11204, 'loss': 0.62107718, 'lr': 0, 'params': 517910, 'time_iter': 0.06527, 'accuracy': 0.77884, 'f1': 0.77868, 'accuracy-SBM': 0.77865, 'auc': 0.96165}
2025-08-16 14:34:10,430 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:34:10,467 - INFO - test: {'epoch': 49, 'time_epoch': 4.36602, 'loss': 0.61397917, 'lr': 0, 'params': 517910, 'time_iter': 0.0693, 'accuracy': 0.78091, 'f1': 0.78093, 'accuracy-SBM': 0.78091, 'auc': 0.96246}
2025-08-16 14:34:10,469 - INFO - > Epoch 49: took 91.3s (avg 94.0s) | Best so far: epoch 47	train_loss: 0.5928 train_accuracy-SBM: 0.7852	val_loss: 0.6124 val_accuracy-SBM: 0.7811	test_loss: 0.6097 test_accuracy-SBM: 0.7819
2025-08-16 14:34:10,469 - INFO - === Epoch 50 ===
2025-08-16 14:35:31,618 - INFO - train: {'epoch': 50, 'time_epoch': 80.9212, 'eta': 4065.24308, 'eta_hours': 1.12923, 'loss': 0.58265137, 'lr': 0.00054129, 'params': 517910, 'time_iter': 0.12947, 'accuracy': 0.78898, 'f1': 0.78898, 'accuracy-SBM': 0.78898, 'auc': 0.96602}
2025-08-16 14:35:35,713 - INFO - val: {'epoch': 50, 'time_epoch': 4.05046, 'loss': 0.62900865, 'lr': 0, 'params': 517910, 'time_iter': 0.06429, 'accuracy': 0.77891, 'f1': 0.77879, 'accuracy-SBM': 0.77878, 'auc': 0.96076}
2025-08-16 14:35:41,791 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:35:41,828 - INFO - test: {'epoch': 50, 'time_epoch': 4.30084, 'loss': 0.61145757, 'lr': 0, 'params': 517910, 'time_iter': 0.06827, 'accuracy': 0.78017, 'f1': 0.78015, 'accuracy-SBM': 0.78016, 'auc': 0.96286}
2025-08-16 14:35:41,830 - INFO - > Epoch 50: took 91.4s (avg 94.0s) | Best so far: epoch 47	train_loss: 0.5928 train_accuracy-SBM: 0.7852	val_loss: 0.6124 val_accuracy-SBM: 0.7811	test_loss: 0.6097 test_accuracy-SBM: 0.7819
2025-08-16 14:35:41,830 - INFO - === Epoch 51 ===
2025-08-16 14:37:02,217 - INFO - train: {'epoch': 51, 'time_epoch': 80.15701, 'eta': 3979.68773, 'eta_hours': 1.10547, 'loss': 0.57969908, 'lr': 0.00052479, 'params': 517910, 'time_iter': 0.12825, 'accuracy': 0.78935, 'f1': 0.78935, 'accuracy-SBM': 0.78935, 'auc': 0.96637}
2025-08-16 14:37:06,395 - INFO - val: {'epoch': 51, 'time_epoch': 4.13402, 'loss': 0.61956638, 'lr': 0, 'params': 517910, 'time_iter': 0.06562, 'accuracy': 0.78194, 'f1': 0.78181, 'accuracy-SBM': 0.78178, 'auc': 0.96202}
2025-08-16 14:37:12,048 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:37:12,085 - INFO - test: {'epoch': 51, 'time_epoch': 4.41113, 'loss': 0.61692444, 'lr': 0, 'params': 517910, 'time_iter': 0.07002, 'accuracy': 0.78158, 'f1': 0.78153, 'accuracy-SBM': 0.78151, 'auc': 0.96225}
2025-08-16 14:37:12,087 - INFO - > Epoch 51: took 90.3s (avg 93.9s) | Best so far: epoch 51	train_loss: 0.5797 train_accuracy-SBM: 0.7893	val_loss: 0.6196 val_accuracy-SBM: 0.7818	test_loss: 0.6169 test_accuracy-SBM: 0.7815
2025-08-16 14:37:12,087 - INFO - === Epoch 52 ===
2025-08-16 14:38:32,665 - INFO - train: {'epoch': 52, 'time_epoch': 80.35359, 'eta': 3894.51042, 'eta_hours': 1.08181, 'loss': 0.57759153, 'lr': 0.00050827, 'params': 517910, 'time_iter': 0.12857, 'accuracy': 0.79061, 'f1': 0.79061, 'accuracy-SBM': 0.79061, 'auc': 0.96661}
2025-08-16 14:38:36,739 - INFO - val: {'epoch': 52, 'time_epoch': 4.03101, 'loss': 0.62687997, 'lr': 0, 'params': 517910, 'time_iter': 0.06398, 'accuracy': 0.78011, 'f1': 0.7801, 'accuracy-SBM': 0.7801, 'auc': 0.96089}
2025-08-16 14:38:42,088 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:38:42,132 - INFO - test: {'epoch': 52, 'time_epoch': 4.0486, 'loss': 0.61611501, 'lr': 0, 'params': 517910, 'time_iter': 0.06426, 'accuracy': 0.77987, 'f1': 0.77986, 'accuracy-SBM': 0.77991, 'auc': 0.96221}
2025-08-16 14:38:42,134 - INFO - > Epoch 52: took 90.0s (avg 93.9s) | Best so far: epoch 51	train_loss: 0.5797 train_accuracy-SBM: 0.7893	val_loss: 0.6196 val_accuracy-SBM: 0.7818	test_loss: 0.6169 test_accuracy-SBM: 0.7815
2025-08-16 14:38:42,135 - INFO - === Epoch 53 ===
2025-08-16 14:40:05,752 - INFO - train: {'epoch': 53, 'time_epoch': 83.37967, 'eta': 3812.08954, 'eta_hours': 1.05891, 'loss': 0.57649305, 'lr': 0.00049173, 'params': 517910, 'time_iter': 0.13341, 'accuracy': 0.79109, 'f1': 0.79109, 'accuracy-SBM': 0.79109, 'auc': 0.96673}
2025-08-16 14:40:09,992 - INFO - val: {'epoch': 53, 'time_epoch': 4.18836, 'loss': 0.62312918, 'lr': 0, 'params': 517910, 'time_iter': 0.06648, 'accuracy': 0.77865, 'f1': 0.77865, 'accuracy-SBM': 0.77859, 'auc': 0.96127}
2025-08-16 14:40:15,778 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:40:15,817 - INFO - test: {'epoch': 53, 'time_epoch': 4.49198, 'loss': 0.61361196, 'lr': 0, 'params': 517910, 'time_iter': 0.0713, 'accuracy': 0.78072, 'f1': 0.78072, 'accuracy-SBM': 0.78078, 'auc': 0.9624}
2025-08-16 14:40:15,819 - INFO - > Epoch 53: took 93.7s (avg 93.8s) | Best so far: epoch 51	train_loss: 0.5797 train_accuracy-SBM: 0.7893	val_loss: 0.6196 val_accuracy-SBM: 0.7818	test_loss: 0.6169 test_accuracy-SBM: 0.7815
2025-08-16 14:40:15,819 - INFO - === Epoch 54 ===
2025-08-16 14:41:39,391 - INFO - train: {'epoch': 54, 'time_epoch': 83.34229, 'eta': 3729.6032, 'eta_hours': 1.036, 'loss': 0.57471263, 'lr': 0.00047521, 'params': 517910, 'time_iter': 0.13335, 'accuracy': 0.79078, 'f1': 0.79078, 'accuracy-SBM': 0.79078, 'auc': 0.96695}
2025-08-16 14:41:43,612 - INFO - val: {'epoch': 54, 'time_epoch': 4.16909, 'loss': 0.62238921, 'lr': 0, 'params': 517910, 'time_iter': 0.06618, 'accuracy': 0.78097, 'f1': 0.78088, 'accuracy-SBM': 0.78086, 'auc': 0.9617}
2025-08-16 14:41:49,654 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:41:49,691 - INFO - test: {'epoch': 54, 'time_epoch': 4.44905, 'loss': 0.60558167, 'lr': 0, 'params': 517910, 'time_iter': 0.07062, 'accuracy': 0.78334, 'f1': 0.78326, 'accuracy-SBM': 0.78322, 'auc': 0.96352}
2025-08-16 14:41:49,693 - INFO - > Epoch 54: took 93.9s (avg 93.8s) | Best so far: epoch 51	train_loss: 0.5797 train_accuracy-SBM: 0.7893	val_loss: 0.6196 val_accuracy-SBM: 0.7818	test_loss: 0.6169 test_accuracy-SBM: 0.7815
2025-08-16 14:41:49,693 - INFO - === Epoch 55 ===
2025-08-16 14:43:09,772 - INFO - train: {'epoch': 55, 'time_epoch': 79.75144, 'eta': 3644.26492, 'eta_hours': 1.0123, 'loss': 0.56815001, 'lr': 0.00045871, 'params': 517910, 'time_iter': 0.1276, 'accuracy': 0.79389, 'f1': 0.79389, 'accuracy-SBM': 0.79389, 'auc': 0.96769}
2025-08-16 14:43:13,856 - INFO - val: {'epoch': 55, 'time_epoch': 4.034, 'loss': 0.61513817, 'lr': 0, 'params': 517910, 'time_iter': 0.06403, 'accuracy': 0.78201, 'f1': 0.78193, 'accuracy-SBM': 0.78184, 'auc': 0.96237}
2025-08-16 14:43:19,648 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:43:19,684 - INFO - test: {'epoch': 55, 'time_epoch': 4.27442, 'loss': 0.60824253, 'lr': 0, 'params': 517910, 'time_iter': 0.06785, 'accuracy': 0.78279, 'f1': 0.78276, 'accuracy-SBM': 0.78279, 'auc': 0.96312}
2025-08-16 14:43:19,686 - INFO - > Epoch 55: took 90.0s (avg 93.8s) | Best so far: epoch 55	train_loss: 0.5682 train_accuracy-SBM: 0.7939	val_loss: 0.6151 val_accuracy-SBM: 0.7818	test_loss: 0.6082 test_accuracy-SBM: 0.7828
2025-08-16 14:43:19,686 - INFO - === Epoch 56 ===
2025-08-16 14:44:39,939 - INFO - train: {'epoch': 56, 'time_epoch': 80.02306, 'eta': 3559.32758, 'eta_hours': 0.9887, 'loss': 0.565929, 'lr': 0.00044226, 'params': 517910, 'time_iter': 0.12804, 'accuracy': 0.79413, 'f1': 0.79413, 'accuracy-SBM': 0.79413, 'auc': 0.96795}
2025-08-16 14:44:44,019 - INFO - val: {'epoch': 56, 'time_epoch': 4.03685, 'loss': 0.61914242, 'lr': 0, 'params': 517910, 'time_iter': 0.06408, 'accuracy': 0.78098, 'f1': 0.78091, 'accuracy-SBM': 0.78089, 'auc': 0.96175}
2025-08-16 14:44:49,688 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:44:49,725 - INFO - test: {'epoch': 56, 'time_epoch': 4.30064, 'loss': 0.60669873, 'lr': 0, 'params': 517910, 'time_iter': 0.06826, 'accuracy': 0.78327, 'f1': 0.78327, 'accuracy-SBM': 0.7833, 'auc': 0.9632}
2025-08-16 14:44:49,727 - INFO - > Epoch 56: took 90.0s (avg 93.7s) | Best so far: epoch 55	train_loss: 0.5682 train_accuracy-SBM: 0.7939	val_loss: 0.6151 val_accuracy-SBM: 0.7818	test_loss: 0.6082 test_accuracy-SBM: 0.7828
2025-08-16 14:44:49,728 - INFO - === Epoch 57 ===
2025-08-16 14:46:10,672 - INFO - train: {'epoch': 57, 'time_epoch': 80.70671, 'eta': 3475.05475, 'eta_hours': 0.96529, 'loss': 0.5667819, 'lr': 0.00042587, 'params': 517910, 'time_iter': 0.12913, 'accuracy': 0.7944, 'f1': 0.7944, 'accuracy-SBM': 0.7944, 'auc': 0.96784}
2025-08-16 14:46:14,787 - INFO - val: {'epoch': 57, 'time_epoch': 4.07042, 'loss': 0.61608097, 'lr': 0, 'params': 517910, 'time_iter': 0.06461, 'accuracy': 0.78155, 'f1': 0.78148, 'accuracy-SBM': 0.78142, 'auc': 0.96218}
2025-08-16 14:46:20,320 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:46:20,357 - INFO - test: {'epoch': 57, 'time_epoch': 4.08585, 'loss': 0.61282155, 'lr': 0, 'params': 517910, 'time_iter': 0.06485, 'accuracy': 0.78219, 'f1': 0.78217, 'accuracy-SBM': 0.78216, 'auc': 0.96246}
2025-08-16 14:46:20,359 - INFO - > Epoch 57: took 90.6s (avg 93.7s) | Best so far: epoch 55	train_loss: 0.5682 train_accuracy-SBM: 0.7939	val_loss: 0.6151 val_accuracy-SBM: 0.7818	test_loss: 0.6082 test_accuracy-SBM: 0.7828
2025-08-16 14:46:20,359 - INFO - === Epoch 58 ===
2025-08-16 14:47:41,280 - INFO - train: {'epoch': 58, 'time_epoch': 80.6919, 'eta': 3390.89251, 'eta_hours': 0.94191, 'loss': 0.56295377, 'lr': 0.00040956, 'params': 517910, 'time_iter': 0.12911, 'accuracy': 0.79532, 'f1': 0.79532, 'accuracy-SBM': 0.79532, 'auc': 0.96829}
2025-08-16 14:47:45,374 - INFO - val: {'epoch': 58, 'time_epoch': 4.04268, 'loss': 0.62696881, 'lr': 0, 'params': 517910, 'time_iter': 0.06417, 'accuracy': 0.78302, 'f1': 0.78296, 'accuracy-SBM': 0.78296, 'auc': 0.96143}
2025-08-16 14:47:51,228 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:47:51,265 - INFO - test: {'epoch': 58, 'time_epoch': 4.3246, 'loss': 0.61980143, 'lr': 0, 'params': 517910, 'time_iter': 0.06864, 'accuracy': 0.78086, 'f1': 0.78084, 'accuracy-SBM': 0.78079, 'auc': 0.96215}
2025-08-16 14:47:51,267 - INFO - > Epoch 58: took 90.9s (avg 93.6s) | Best so far: epoch 58	train_loss: 0.5630 train_accuracy-SBM: 0.7953	val_loss: 0.6270 val_accuracy-SBM: 0.7830	test_loss: 0.6198 test_accuracy-SBM: 0.7808
2025-08-16 14:47:51,267 - INFO - === Epoch 59 ===
2025-08-16 14:49:12,655 - INFO - train: {'epoch': 59, 'time_epoch': 81.15368, 'eta': 3307.1538, 'eta_hours': 0.91865, 'loss': 0.56033465, 'lr': 0.00039335, 'params': 517910, 'time_iter': 0.12985, 'accuracy': 0.79652, 'f1': 0.79651, 'accuracy-SBM': 0.79652, 'auc': 0.96859}
2025-08-16 14:49:16,745 - INFO - val: {'epoch': 59, 'time_epoch': 4.04031, 'loss': 0.62205309, 'lr': 0, 'params': 517910, 'time_iter': 0.06413, 'accuracy': 0.78027, 'f1': 0.78017, 'accuracy-SBM': 0.78012, 'auc': 0.96151}
2025-08-16 14:49:22,470 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:49:22,507 - INFO - test: {'epoch': 59, 'time_epoch': 4.37278, 'loss': 0.60555689, 'lr': 0, 'params': 517910, 'time_iter': 0.06941, 'accuracy': 0.78384, 'f1': 0.78377, 'accuracy-SBM': 0.78377, 'auc': 0.96342}
2025-08-16 14:49:22,508 - INFO - > Epoch 59: took 91.2s (avg 93.6s) | Best so far: epoch 58	train_loss: 0.5630 train_accuracy-SBM: 0.7953	val_loss: 0.6270 val_accuracy-SBM: 0.7830	test_loss: 0.6198 test_accuracy-SBM: 0.7808
2025-08-16 14:49:22,508 - INFO - === Epoch 60 ===
2025-08-16 14:50:42,948 - INFO - train: {'epoch': 60, 'time_epoch': 80.10821, 'eta': 3222.83144, 'eta_hours': 0.89523, 'loss': 0.55921377, 'lr': 0.00037726, 'params': 517910, 'time_iter': 0.12817, 'accuracy': 0.79681, 'f1': 0.79681, 'accuracy-SBM': 0.79681, 'auc': 0.96871}
2025-08-16 14:50:47,045 - INFO - val: {'epoch': 60, 'time_epoch': 4.05423, 'loss': 0.6301636, 'lr': 0, 'params': 517910, 'time_iter': 0.06435, 'accuracy': 0.78018, 'f1': 0.78011, 'accuracy-SBM': 0.78007, 'auc': 0.96055}
2025-08-16 14:50:52,747 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:50:52,784 - INFO - test: {'epoch': 60, 'time_epoch': 4.30994, 'loss': 0.60689234, 'lr': 0, 'params': 517910, 'time_iter': 0.06841, 'accuracy': 0.78434, 'f1': 0.78429, 'accuracy-SBM': 0.78429, 'auc': 0.96319}
2025-08-16 14:50:52,786 - INFO - > Epoch 60: took 90.3s (avg 93.5s) | Best so far: epoch 58	train_loss: 0.5630 train_accuracy-SBM: 0.7953	val_loss: 0.6270 val_accuracy-SBM: 0.7830	test_loss: 0.6198 test_accuracy-SBM: 0.7808
2025-08-16 14:50:52,786 - INFO - === Epoch 61 ===
2025-08-16 14:52:13,478 - INFO - train: {'epoch': 61, 'time_epoch': 80.11425, 'eta': 3138.64871, 'eta_hours': 0.87185, 'loss': 0.5555353, 'lr': 0.0003613, 'params': 517910, 'time_iter': 0.12818, 'accuracy': 0.79787, 'f1': 0.79787, 'accuracy-SBM': 0.79787, 'auc': 0.96913}
2025-08-16 14:52:17,532 - INFO - val: {'epoch': 61, 'time_epoch': 4.011, 'loss': 0.61883999, 'lr': 0, 'params': 517910, 'time_iter': 0.06367, 'accuracy': 0.78376, 'f1': 0.78365, 'accuracy-SBM': 0.78358, 'auc': 0.96175}
2025-08-16 14:52:23,268 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:52:23,305 - INFO - test: {'epoch': 61, 'time_epoch': 4.26235, 'loss': 0.61085136, 'lr': 0, 'params': 517910, 'time_iter': 0.06766, 'accuracy': 0.78363, 'f1': 0.78357, 'accuracy-SBM': 0.78358, 'auc': 0.96269}
2025-08-16 14:52:23,307 - INFO - > Epoch 61: took 90.5s (avg 93.5s) | Best so far: epoch 61	train_loss: 0.5555 train_accuracy-SBM: 0.7979	val_loss: 0.6188 val_accuracy-SBM: 0.7836	test_loss: 0.6109 test_accuracy-SBM: 0.7836
2025-08-16 14:52:23,307 - INFO - === Epoch 62 ===
2025-08-16 14:53:42,995 - INFO - train: {'epoch': 62, 'time_epoch': 79.46293, 'eta': 3054.21263, 'eta_hours': 0.84839, 'loss': 0.55170406, 'lr': 0.00034549, 'params': 517910, 'time_iter': 0.12714, 'accuracy': 0.79906, 'f1': 0.79906, 'accuracy-SBM': 0.79906, 'auc': 0.96955}
2025-08-16 14:53:47,078 - INFO - val: {'epoch': 62, 'time_epoch': 4.04027, 'loss': 0.62200908, 'lr': 0, 'params': 517910, 'time_iter': 0.06413, 'accuracy': 0.78109, 'f1': 0.78093, 'accuracy-SBM': 0.78089, 'auc': 0.96164}
2025-08-16 14:53:52,733 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:53:52,770 - INFO - test: {'epoch': 62, 'time_epoch': 4.31065, 'loss': 0.60377727, 'lr': 0, 'params': 517910, 'time_iter': 0.06842, 'accuracy': 0.78481, 'f1': 0.78477, 'accuracy-SBM': 0.78474, 'auc': 0.96366}
2025-08-16 14:53:52,772 - INFO - > Epoch 62: took 89.5s (avg 93.4s) | Best so far: epoch 61	train_loss: 0.5555 train_accuracy-SBM: 0.7979	val_loss: 0.6188 val_accuracy-SBM: 0.7836	test_loss: 0.6109 test_accuracy-SBM: 0.7836
2025-08-16 14:53:52,772 - INFO - === Epoch 63 ===
2025-08-16 14:55:12,801 - INFO - train: {'epoch': 63, 'time_epoch': 79.806, 'eta': 2970.12492, 'eta_hours': 0.82503, 'loss': 0.55035215, 'lr': 0.00032985, 'params': 517910, 'time_iter': 0.12769, 'accuracy': 0.80029, 'f1': 0.80029, 'accuracy-SBM': 0.80029, 'auc': 0.96969}
2025-08-16 14:55:16,874 - INFO - val: {'epoch': 63, 'time_epoch': 4.03036, 'loss': 0.62101299, 'lr': 0, 'params': 517910, 'time_iter': 0.06397, 'accuracy': 0.78287, 'f1': 0.78279, 'accuracy-SBM': 0.78273, 'auc': 0.96217}
2025-08-16 14:55:22,312 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:55:22,349 - INFO - test: {'epoch': 63, 'time_epoch': 4.07072, 'loss': 0.6129623, 'lr': 0, 'params': 517910, 'time_iter': 0.06461, 'accuracy': 0.78357, 'f1': 0.78356, 'accuracy-SBM': 0.78358, 'auc': 0.96304}
2025-08-16 14:55:22,351 - INFO - > Epoch 63: took 89.6s (avg 93.3s) | Best so far: epoch 61	train_loss: 0.5555 train_accuracy-SBM: 0.7979	val_loss: 0.6188 val_accuracy-SBM: 0.7836	test_loss: 0.6109 test_accuracy-SBM: 0.7836
2025-08-16 14:55:22,351 - INFO - === Epoch 64 ===
2025-08-16 14:56:42,259 - INFO - train: {'epoch': 64, 'time_epoch': 79.67558, 'eta': 2886.09875, 'eta_hours': 0.80169, 'loss': 0.54580624, 'lr': 0.0003144, 'params': 517910, 'time_iter': 0.12748, 'accuracy': 0.80161, 'f1': 0.80161, 'accuracy-SBM': 0.80161, 'auc': 0.97018}
2025-08-16 14:56:46,315 - INFO - val: {'epoch': 64, 'time_epoch': 4.01387, 'loss': 0.61953335, 'lr': 0, 'params': 517910, 'time_iter': 0.06371, 'accuracy': 0.78238, 'f1': 0.78237, 'accuracy-SBM': 0.78225, 'auc': 0.96201}
2025-08-16 14:56:51,767 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:56:51,806 - INFO - test: {'epoch': 64, 'time_epoch': 4.06481, 'loss': 0.60883658, 'lr': 0, 'params': 517910, 'time_iter': 0.06452, 'accuracy': 0.78424, 'f1': 0.78419, 'accuracy-SBM': 0.78423, 'auc': 0.96324}
2025-08-16 14:56:51,808 - INFO - > Epoch 64: took 89.5s (avg 93.3s) | Best so far: epoch 61	train_loss: 0.5555 train_accuracy-SBM: 0.7979	val_loss: 0.6188 val_accuracy-SBM: 0.7836	test_loss: 0.6109 test_accuracy-SBM: 0.7836
2025-08-16 14:56:51,808 - INFO - === Epoch 65 ===
2025-08-16 14:58:12,362 - INFO - train: {'epoch': 65, 'time_epoch': 80.32169, 'eta': 2802.53725, 'eta_hours': 0.77848, 'loss': 0.54616881, 'lr': 0.00029915, 'params': 517910, 'time_iter': 0.12851, 'accuracy': 0.80159, 'f1': 0.80159, 'accuracy-SBM': 0.80159, 'auc': 0.97014}
2025-08-16 14:58:16,467 - INFO - val: {'epoch': 65, 'time_epoch': 4.06207, 'loss': 0.61814873, 'lr': 0, 'params': 517910, 'time_iter': 0.06448, 'accuracy': 0.78439, 'f1': 0.78428, 'accuracy-SBM': 0.78428, 'auc': 0.96219}
2025-08-16 14:58:23,344 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:58:23,381 - INFO - test: {'epoch': 65, 'time_epoch': 4.2918, 'loss': 0.60747579, 'lr': 0, 'params': 517910, 'time_iter': 0.06812, 'accuracy': 0.78368, 'f1': 0.78367, 'accuracy-SBM': 0.78366, 'auc': 0.96341}
2025-08-16 14:58:23,383 - INFO - > Epoch 65: took 91.6s (avg 93.3s) | Best so far: epoch 65	train_loss: 0.5462 train_accuracy-SBM: 0.8016	val_loss: 0.6181 val_accuracy-SBM: 0.7843	test_loss: 0.6075 test_accuracy-SBM: 0.7837
2025-08-16 14:58:23,383 - INFO - === Epoch 66 ===
2025-08-16 14:59:43,401 - INFO - train: {'epoch': 66, 'time_epoch': 79.79442, 'eta': 2718.81276, 'eta_hours': 0.75523, 'loss': 0.54279171, 'lr': 0.00028412, 'params': 517910, 'time_iter': 0.12767, 'accuracy': 0.80298, 'f1': 0.80298, 'accuracy-SBM': 0.80298, 'auc': 0.97052}
2025-08-16 14:59:47,450 - INFO - val: {'epoch': 66, 'time_epoch': 4.00613, 'loss': 0.61938202, 'lr': 0, 'params': 517910, 'time_iter': 0.06359, 'accuracy': 0.78414, 'f1': 0.78392, 'accuracy-SBM': 0.78389, 'auc': 0.96206}
2025-08-16 14:59:53,134 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 14:59:53,173 - INFO - test: {'epoch': 66, 'time_epoch': 4.30316, 'loss': 0.61412454, 'lr': 0, 'params': 517910, 'time_iter': 0.0683, 'accuracy': 0.78149, 'f1': 0.7815, 'accuracy-SBM': 0.78145, 'auc': 0.9626}
2025-08-16 14:59:53,175 - INFO - > Epoch 66: took 89.8s (avg 93.2s) | Best so far: epoch 65	train_loss: 0.5462 train_accuracy-SBM: 0.8016	val_loss: 0.6181 val_accuracy-SBM: 0.7843	test_loss: 0.6075 test_accuracy-SBM: 0.7837
2025-08-16 14:59:53,175 - INFO - === Epoch 67 ===
2025-08-16 15:01:13,242 - INFO - train: {'epoch': 67, 'time_epoch': 79.83895, 'eta': 2635.22481, 'eta_hours': 0.73201, 'loss': 0.54135011, 'lr': 0.00026933, 'params': 517910, 'time_iter': 0.12774, 'accuracy': 0.80298, 'f1': 0.80298, 'accuracy-SBM': 0.80298, 'auc': 0.97068}
2025-08-16 15:01:17,336 - INFO - val: {'epoch': 67, 'time_epoch': 4.05046, 'loss': 0.61451728, 'lr': 0, 'params': 517910, 'time_iter': 0.06429, 'accuracy': 0.78511, 'f1': 0.78501, 'accuracy-SBM': 0.78503, 'auc': 0.96253}
2025-08-16 15:01:23,038 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:01:23,075 - INFO - test: {'epoch': 67, 'time_epoch': 4.3072, 'loss': 0.60342873, 'lr': 0, 'params': 517910, 'time_iter': 0.06837, 'accuracy': 0.78438, 'f1': 0.7844, 'accuracy-SBM': 0.78442, 'auc': 0.96381}
2025-08-16 15:01:23,077 - INFO - > Epoch 67: took 89.9s (avg 93.2s) | Best so far: epoch 67	train_loss: 0.5414 train_accuracy-SBM: 0.8030	val_loss: 0.6145 val_accuracy-SBM: 0.7850	test_loss: 0.6034 test_accuracy-SBM: 0.7844
2025-08-16 15:01:23,077 - INFO - === Epoch 68 ===
2025-08-16 15:02:42,810 - INFO - train: {'epoch': 68, 'time_epoch': 79.50614, 'eta': 2551.59602, 'eta_hours': 0.70878, 'loss': 0.53997011, 'lr': 0.00025479, 'params': 517910, 'time_iter': 0.12721, 'accuracy': 0.80347, 'f1': 0.80347, 'accuracy-SBM': 0.80347, 'auc': 0.97084}
2025-08-16 15:02:46,910 - INFO - val: {'epoch': 68, 'time_epoch': 4.05621, 'loss': 0.62045474, 'lr': 0, 'params': 517910, 'time_iter': 0.06438, 'accuracy': 0.78548, 'f1': 0.78536, 'accuracy-SBM': 0.78538, 'auc': 0.96212}
2025-08-16 15:02:52,602 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:02:52,653 - INFO - test: {'epoch': 68, 'time_epoch': 4.30528, 'loss': 0.60791929, 'lr': 0, 'params': 517910, 'time_iter': 0.06834, 'accuracy': 0.7825, 'f1': 0.78251, 'accuracy-SBM': 0.78247, 'auc': 0.96357}
2025-08-16 15:02:52,655 - INFO - > Epoch 68: took 89.6s (avg 93.1s) | Best so far: epoch 68	train_loss: 0.5400 train_accuracy-SBM: 0.8035	val_loss: 0.6205 val_accuracy-SBM: 0.7854	test_loss: 0.6079 test_accuracy-SBM: 0.7825
2025-08-16 15:02:52,655 - INFO - === Epoch 69 ===
2025-08-16 15:04:14,190 - INFO - train: {'epoch': 69, 'time_epoch': 81.21078, 'eta': 2468.81557, 'eta_hours': 0.68578, 'loss': 0.53660362, 'lr': 0.00024052, 'params': 517910, 'time_iter': 0.12994, 'accuracy': 0.80503, 'f1': 0.80503, 'accuracy-SBM': 0.80503, 'auc': 0.9712}
2025-08-16 15:04:18,407 - INFO - val: {'epoch': 69, 'time_epoch': 4.17286, 'loss': 0.61614013, 'lr': 0, 'params': 517910, 'time_iter': 0.06624, 'accuracy': 0.78492, 'f1': 0.7848, 'accuracy-SBM': 0.78483, 'auc': 0.96241}
2025-08-16 15:04:24,299 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:04:24,336 - INFO - test: {'epoch': 69, 'time_epoch': 4.45532, 'loss': 0.60902606, 'lr': 0, 'params': 517910, 'time_iter': 0.07072, 'accuracy': 0.78291, 'f1': 0.78292, 'accuracy-SBM': 0.78287, 'auc': 0.9632}
2025-08-16 15:04:24,338 - INFO - > Epoch 69: took 91.7s (avg 93.1s) | Best so far: epoch 68	train_loss: 0.5400 train_accuracy-SBM: 0.8035	val_loss: 0.6205 val_accuracy-SBM: 0.7854	test_loss: 0.6079 test_accuracy-SBM: 0.7825
2025-08-16 15:04:24,338 - INFO - === Epoch 70 ===
2025-08-16 15:05:49,537 - INFO - train: {'epoch': 70, 'time_epoch': 84.85459, 'eta': 2387.56765, 'eta_hours': 0.66321, 'loss': 0.53594143, 'lr': 0.00022653, 'params': 517910, 'time_iter': 0.13577, 'accuracy': 0.80525, 'f1': 0.80525, 'accuracy-SBM': 0.80525, 'auc': 0.97125}
2025-08-16 15:05:53,841 - INFO - val: {'epoch': 70, 'time_epoch': 4.25727, 'loss': 0.62784717, 'lr': 0, 'params': 517910, 'time_iter': 0.06758, 'accuracy': 0.78296, 'f1': 0.78292, 'accuracy-SBM': 0.78285, 'auc': 0.96144}
2025-08-16 15:06:01,283 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:06:01,322 - INFO - test: {'epoch': 70, 'time_epoch': 4.41837, 'loss': 0.61213773, 'lr': 0, 'params': 517910, 'time_iter': 0.07013, 'accuracy': 0.78385, 'f1': 0.78384, 'accuracy-SBM': 0.78389, 'auc': 0.96312}
2025-08-16 15:06:01,325 - INFO - > Epoch 70: took 97.0s (avg 93.1s) | Best so far: epoch 68	train_loss: 0.5400 train_accuracy-SBM: 0.8035	val_loss: 0.6205 val_accuracy-SBM: 0.7854	test_loss: 0.6079 test_accuracy-SBM: 0.7825
2025-08-16 15:06:01,325 - INFO - === Epoch 71 ===
2025-08-16 15:07:26,550 - INFO - train: {'epoch': 71, 'time_epoch': 84.89391, 'eta': 2306.23484, 'eta_hours': 0.64062, 'loss': 0.53517982, 'lr': 0.00021284, 'params': 517910, 'time_iter': 0.13583, 'accuracy': 0.80548, 'f1': 0.80548, 'accuracy-SBM': 0.80548, 'auc': 0.97133}
2025-08-16 15:07:30,845 - INFO - val: {'epoch': 71, 'time_epoch': 4.24701, 'loss': 0.62675424, 'lr': 0, 'params': 517910, 'time_iter': 0.06741, 'accuracy': 0.78354, 'f1': 0.78339, 'accuracy-SBM': 0.78335, 'auc': 0.96164}
2025-08-16 15:07:37,098 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:07:37,144 - INFO - test: {'epoch': 71, 'time_epoch': 4.45133, 'loss': 0.61335664, 'lr': 0, 'params': 517910, 'time_iter': 0.07066, 'accuracy': 0.78405, 'f1': 0.78403, 'accuracy-SBM': 0.78399, 'auc': 0.96315}
2025-08-16 15:07:37,146 - INFO - > Epoch 71: took 95.8s (avg 93.2s) | Best so far: epoch 68	train_loss: 0.5400 train_accuracy-SBM: 0.8035	val_loss: 0.6205 val_accuracy-SBM: 0.7854	test_loss: 0.6079 test_accuracy-SBM: 0.7825
2025-08-16 15:07:37,146 - INFO - === Epoch 72 ===
2025-08-16 15:09:00,703 - INFO - train: {'epoch': 72, 'time_epoch': 83.33023, 'eta': 2224.22612, 'eta_hours': 0.61784, 'loss': 0.53053219, 'lr': 0.00019946, 'params': 517910, 'time_iter': 0.13333, 'accuracy': 0.80739, 'f1': 0.80739, 'accuracy-SBM': 0.80739, 'auc': 0.97184}
2025-08-16 15:09:04,926 - INFO - val: {'epoch': 72, 'time_epoch': 4.17048, 'loss': 0.6260383, 'lr': 0, 'params': 517910, 'time_iter': 0.0662, 'accuracy': 0.78405, 'f1': 0.78396, 'accuracy-SBM': 0.78391, 'auc': 0.96131}
2025-08-16 15:09:11,231 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:09:11,269 - INFO - test: {'epoch': 72, 'time_epoch': 4.20647, 'loss': 0.60457521, 'lr': 0, 'params': 517910, 'time_iter': 0.06677, 'accuracy': 0.78545, 'f1': 0.78543, 'accuracy-SBM': 0.78543, 'auc': 0.96372}
2025-08-16 15:09:11,271 - INFO - > Epoch 72: took 94.1s (avg 93.2s) | Best so far: epoch 68	train_loss: 0.5400 train_accuracy-SBM: 0.8035	val_loss: 0.6205 val_accuracy-SBM: 0.7854	test_loss: 0.6079 test_accuracy-SBM: 0.7825
2025-08-16 15:09:11,271 - INFO - === Epoch 73 ===
2025-08-16 15:10:34,461 - INFO - train: {'epoch': 73, 'time_epoch': 82.87055, 'eta': 2142.02017, 'eta_hours': 0.59501, 'loss': 0.5297099, 'lr': 0.00018641, 'params': 517910, 'time_iter': 0.13259, 'accuracy': 0.80745, 'f1': 0.80745, 'accuracy-SBM': 0.80745, 'auc': 0.97192}
2025-08-16 15:10:38,651 - INFO - val: {'epoch': 73, 'time_epoch': 4.14718, 'loss': 0.62414283, 'lr': 0, 'params': 517910, 'time_iter': 0.06583, 'accuracy': 0.78423, 'f1': 0.78418, 'accuracy-SBM': 0.78418, 'auc': 0.96164}
2025-08-16 15:10:46,119 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:10:46,156 - INFO - test: {'epoch': 73, 'time_epoch': 4.41223, 'loss': 0.60829718, 'lr': 0, 'params': 517910, 'time_iter': 0.07004, 'accuracy': 0.7857, 'f1': 0.78571, 'accuracy-SBM': 0.78574, 'auc': 0.96338}
2025-08-16 15:10:46,158 - INFO - > Epoch 73: took 94.9s (avg 93.2s) | Best so far: epoch 68	train_loss: 0.5400 train_accuracy-SBM: 0.8035	val_loss: 0.6205 val_accuracy-SBM: 0.7854	test_loss: 0.6079 test_accuracy-SBM: 0.7825
2025-08-16 15:10:46,158 - INFO - === Epoch 74 ===
2025-08-16 15:12:07,849 - INFO - train: {'epoch': 74, 'time_epoch': 81.46239, 'eta': 2059.32711, 'eta_hours': 0.57204, 'loss': 0.52690121, 'lr': 0.00017371, 'params': 517910, 'time_iter': 0.13034, 'accuracy': 0.80829, 'f1': 0.80829, 'accuracy-SBM': 0.80829, 'auc': 0.97222}
2025-08-16 15:12:12,051 - INFO - val: {'epoch': 74, 'time_epoch': 4.15172, 'loss': 0.62496689, 'lr': 0, 'params': 517910, 'time_iter': 0.0659, 'accuracy': 0.78447, 'f1': 0.78437, 'accuracy-SBM': 0.78438, 'auc': 0.96162}
2025-08-16 15:12:18,347 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:12:18,386 - INFO - test: {'epoch': 74, 'time_epoch': 4.35556, 'loss': 0.61534066, 'lr': 0, 'params': 517910, 'time_iter': 0.06914, 'accuracy': 0.78306, 'f1': 0.78307, 'accuracy-SBM': 0.78305, 'auc': 0.96267}
2025-08-16 15:12:18,388 - INFO - > Epoch 74: took 92.2s (avg 93.2s) | Best so far: epoch 68	train_loss: 0.5400 train_accuracy-SBM: 0.8035	val_loss: 0.6205 val_accuracy-SBM: 0.7854	test_loss: 0.6079 test_accuracy-SBM: 0.7825
2025-08-16 15:12:18,388 - INFO - === Epoch 75 ===
2025-08-16 15:13:40,041 - INFO - train: {'epoch': 75, 'time_epoch': 81.42704, 'eta': 1976.65528, 'eta_hours': 0.54907, 'loss': 0.52615588, 'lr': 0.00016136, 'params': 517910, 'time_iter': 0.13028, 'accuracy': 0.80871, 'f1': 0.80871, 'accuracy-SBM': 0.80871, 'auc': 0.9723}
2025-08-16 15:13:44,255 - INFO - val: {'epoch': 75, 'time_epoch': 4.16313, 'loss': 0.62508832, 'lr': 0, 'params': 517910, 'time_iter': 0.06608, 'accuracy': 0.78386, 'f1': 0.78373, 'accuracy-SBM': 0.78369, 'auc': 0.96129}
2025-08-16 15:13:50,595 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:13:50,632 - INFO - test: {'epoch': 75, 'time_epoch': 4.40911, 'loss': 0.59859002, 'lr': 0, 'params': 517910, 'time_iter': 0.06999, 'accuracy': 0.78741, 'f1': 0.78735, 'accuracy-SBM': 0.78738, 'auc': 0.96423}
2025-08-16 15:13:50,634 - INFO - > Epoch 75: took 92.2s (avg 93.2s) | Best so far: epoch 68	train_loss: 0.5400 train_accuracy-SBM: 0.8035	val_loss: 0.6205 val_accuracy-SBM: 0.7854	test_loss: 0.6079 test_accuracy-SBM: 0.7825
2025-08-16 15:13:50,634 - INFO - === Epoch 76 ===
2025-08-16 15:15:12,778 - INFO - train: {'epoch': 76, 'time_epoch': 81.92131, 'eta': 1894.16341, 'eta_hours': 0.52616, 'loss': 0.52349871, 'lr': 0.00014938, 'params': 517910, 'time_iter': 0.13107, 'accuracy': 0.80972, 'f1': 0.80972, 'accuracy-SBM': 0.80972, 'auc': 0.97258}
2025-08-16 15:15:17,020 - INFO - val: {'epoch': 76, 'time_epoch': 4.16454, 'loss': 0.62814956, 'lr': 0, 'params': 517910, 'time_iter': 0.0661, 'accuracy': 0.78566, 'f1': 0.78559, 'accuracy-SBM': 0.78553, 'auc': 0.96141}
2025-08-16 15:15:22,856 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:15:22,893 - INFO - test: {'epoch': 76, 'time_epoch': 4.39375, 'loss': 0.60848106, 'lr': 0, 'params': 517910, 'time_iter': 0.06974, 'accuracy': 0.78602, 'f1': 0.786, 'accuracy-SBM': 0.78602, 'auc': 0.96361}
2025-08-16 15:15:22,895 - INFO - > Epoch 76: took 92.3s (avg 93.2s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:15:22,895 - INFO - === Epoch 77 ===
2025-08-16 15:16:48,617 - INFO - train: {'epoch': 77, 'time_epoch': 85.49159, 'eta': 1812.69318, 'eta_hours': 0.50353, 'loss': 0.52473418, 'lr': 0.00013779, 'params': 517910, 'time_iter': 0.13679, 'accuracy': 0.80935, 'f1': 0.80935, 'accuracy-SBM': 0.80935, 'auc': 0.97245}
2025-08-16 15:16:53,035 - INFO - val: {'epoch': 77, 'time_epoch': 4.36696, 'loss': 0.62756833, 'lr': 0, 'params': 517910, 'time_iter': 0.06932, 'accuracy': 0.78526, 'f1': 0.78516, 'accuracy-SBM': 0.78511, 'auc': 0.96126}
2025-08-16 15:17:07,940 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:17:08,033 - INFO - test: {'epoch': 77, 'time_epoch': 4.30814, 'loss': 0.60860897, 'lr': 0, 'params': 517910, 'time_iter': 0.06838, 'accuracy': 0.78545, 'f1': 0.78544, 'accuracy-SBM': 0.78546, 'auc': 0.96341}
2025-08-16 15:17:08,037 - INFO - > Epoch 77: took 105.1s (avg 93.3s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:17:08,037 - INFO - === Epoch 78 ===
2025-08-16 15:18:33,869 - INFO - train: {'epoch': 78, 'time_epoch': 85.51504, 'eta': 1731.12737, 'eta_hours': 0.48087, 'loss': 0.52010671, 'lr': 0.00012659, 'params': 517910, 'time_iter': 0.13682, 'accuracy': 0.81068, 'f1': 0.81068, 'accuracy-SBM': 0.81068, 'auc': 0.97293}
2025-08-16 15:18:38,168 - INFO - val: {'epoch': 78, 'time_epoch': 4.24853, 'loss': 0.63085178, 'lr': 0, 'params': 517910, 'time_iter': 0.06744, 'accuracy': 0.78431, 'f1': 0.78425, 'accuracy-SBM': 0.78421, 'auc': 0.96087}
2025-08-16 15:18:44,375 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:18:44,414 - INFO - test: {'epoch': 78, 'time_epoch': 4.52064, 'loss': 0.61291806, 'lr': 0, 'params': 517910, 'time_iter': 0.07176, 'accuracy': 0.78438, 'f1': 0.78437, 'accuracy-SBM': 0.78439, 'auc': 0.96288}
2025-08-16 15:18:44,416 - INFO - > Epoch 78: took 96.4s (avg 93.4s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:18:44,416 - INFO - === Epoch 79 ===
2025-08-16 15:20:10,984 - INFO - train: {'epoch': 79, 'time_epoch': 86.21807, 'eta': 1649.6386, 'eta_hours': 0.45823, 'loss': 0.52014027, 'lr': 0.0001158, 'params': 517910, 'time_iter': 0.13795, 'accuracy': 0.81046, 'f1': 0.81046, 'accuracy-SBM': 0.81046, 'auc': 0.97294}
2025-08-16 15:20:15,293 - INFO - val: {'epoch': 79, 'time_epoch': 4.26431, 'loss': 0.63245235, 'lr': 0, 'params': 517910, 'time_iter': 0.06769, 'accuracy': 0.7847, 'f1': 0.78462, 'accuracy-SBM': 0.78457, 'auc': 0.9609}
2025-08-16 15:20:24,506 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:20:24,544 - INFO - test: {'epoch': 79, 'time_epoch': 4.53886, 'loss': 0.6136599, 'lr': 0, 'params': 517910, 'time_iter': 0.07205, 'accuracy': 0.78447, 'f1': 0.78442, 'accuracy-SBM': 0.78447, 'auc': 0.96301}
2025-08-16 15:20:24,576 - INFO - > Epoch 79: took 100.2s (avg 93.5s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:20:24,576 - INFO - === Epoch 80 ===
2025-08-16 15:21:50,563 - INFO - train: {'epoch': 80, 'time_epoch': 85.64771, 'eta': 1567.89926, 'eta_hours': 0.43553, 'loss': 0.5177855, 'lr': 0.00010543, 'params': 517910, 'time_iter': 0.13704, 'accuracy': 0.81161, 'f1': 0.81161, 'accuracy-SBM': 0.81161, 'auc': 0.97318}
2025-08-16 15:21:54,888 - INFO - val: {'epoch': 80, 'time_epoch': 4.2801, 'loss': 0.62660898, 'lr': 0, 'params': 517910, 'time_iter': 0.06794, 'accuracy': 0.78543, 'f1': 0.78534, 'accuracy-SBM': 0.78532, 'auc': 0.96137}
2025-08-16 15:22:04,314 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:22:04,354 - INFO - test: {'epoch': 80, 'time_epoch': 4.52743, 'loss': 0.6139145, 'lr': 0, 'params': 517910, 'time_iter': 0.07186, 'accuracy': 0.78506, 'f1': 0.78506, 'accuracy-SBM': 0.78507, 'auc': 0.96283}
2025-08-16 15:22:04,356 - INFO - > Epoch 80: took 99.8s (avg 93.5s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:22:04,356 - INFO - === Epoch 81 ===
2025-08-16 15:23:30,882 - INFO - train: {'epoch': 81, 'time_epoch': 86.29152, 'eta': 1486.20591, 'eta_hours': 0.41283, 'loss': 0.51603719, 'lr': 9.549e-05, 'params': 517910, 'time_iter': 0.13807, 'accuracy': 0.81227, 'f1': 0.81227, 'accuracy-SBM': 0.81227, 'auc': 0.97335}
2025-08-16 15:23:35,146 - INFO - val: {'epoch': 81, 'time_epoch': 4.21888, 'loss': 0.62780529, 'lr': 0, 'params': 517910, 'time_iter': 0.06697, 'accuracy': 0.7844, 'f1': 0.7843, 'accuracy-SBM': 0.78425, 'auc': 0.96118}
2025-08-16 15:23:44,083 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:23:44,121 - INFO - test: {'epoch': 81, 'time_epoch': 4.50597, 'loss': 0.6093379, 'lr': 0, 'params': 517910, 'time_iter': 0.07152, 'accuracy': 0.7863, 'f1': 0.78628, 'accuracy-SBM': 0.7863, 'auc': 0.96322}
2025-08-16 15:23:44,123 - INFO - > Epoch 81: took 99.8s (avg 93.6s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:23:44,123 - INFO - === Epoch 82 ===
2025-08-16 15:25:10,176 - INFO - train: {'epoch': 82, 'time_epoch': 85.8105, 'eta': 1404.30325, 'eta_hours': 0.39008, 'loss': 0.51469231, 'lr': 8.6e-05, 'params': 517910, 'time_iter': 0.1373, 'accuracy': 0.81308, 'f1': 0.81308, 'accuracy-SBM': 0.81308, 'auc': 0.9735}
2025-08-16 15:25:14,468 - INFO - val: {'epoch': 82, 'time_epoch': 4.23934, 'loss': 0.63042548, 'lr': 0, 'params': 517910, 'time_iter': 0.06729, 'accuracy': 0.78449, 'f1': 0.78433, 'accuracy-SBM': 0.78431, 'auc': 0.96124}
2025-08-16 15:25:23,807 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:25:23,845 - INFO - test: {'epoch': 82, 'time_epoch': 4.53273, 'loss': 0.61401077, 'lr': 0, 'params': 517910, 'time_iter': 0.07195, 'accuracy': 0.78564, 'f1': 0.7856, 'accuracy-SBM': 0.78558, 'auc': 0.96301}
2025-08-16 15:25:23,847 - INFO - > Epoch 82: took 99.7s (avg 93.7s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:25:23,847 - INFO - === Epoch 83 ===
2025-08-16 15:26:49,130 - INFO - train: {'epoch': 83, 'time_epoch': 85.04435, 'eta': 1322.16161, 'eta_hours': 0.36727, 'loss': 0.51480961, 'lr': 7.695e-05, 'params': 517910, 'time_iter': 0.13607, 'accuracy': 0.81256, 'f1': 0.81256, 'accuracy-SBM': 0.81256, 'auc': 0.97349}
2025-08-16 15:26:53,405 - INFO - val: {'epoch': 83, 'time_epoch': 4.22544, 'loss': 0.6323742, 'lr': 0, 'params': 517910, 'time_iter': 0.06707, 'accuracy': 0.78481, 'f1': 0.78471, 'accuracy-SBM': 0.78466, 'auc': 0.96095}
2025-08-16 15:27:00,332 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:27:00,372 - INFO - test: {'epoch': 83, 'time_epoch': 4.22617, 'loss': 0.61011029, 'lr': 0, 'params': 517910, 'time_iter': 0.06708, 'accuracy': 0.78586, 'f1': 0.78582, 'accuracy-SBM': 0.78583, 'auc': 0.96339}
2025-08-16 15:27:00,374 - INFO - > Epoch 83: took 96.5s (avg 93.7s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:27:00,374 - INFO - === Epoch 84 ===
2025-08-16 15:28:26,088 - INFO - train: {'epoch': 84, 'time_epoch': 85.46847, 'eta': 1240.02651, 'eta_hours': 0.34445, 'loss': 0.51443503, 'lr': 6.837e-05, 'params': 517910, 'time_iter': 0.13675, 'accuracy': 0.813, 'f1': 0.813, 'accuracy-SBM': 0.813, 'auc': 0.97353}
2025-08-16 15:28:30,411 - INFO - val: {'epoch': 84, 'time_epoch': 4.27426, 'loss': 0.63169088, 'lr': 0, 'params': 517910, 'time_iter': 0.06785, 'accuracy': 0.78489, 'f1': 0.78479, 'accuracy-SBM': 0.78474, 'auc': 0.96104}
2025-08-16 15:28:39,399 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:28:39,439 - INFO - test: {'epoch': 84, 'time_epoch': 4.226, 'loss': 0.61270947, 'lr': 0, 'params': 517910, 'time_iter': 0.06708, 'accuracy': 0.78545, 'f1': 0.7854, 'accuracy-SBM': 0.78542, 'auc': 0.96312}
2025-08-16 15:28:39,441 - INFO - > Epoch 84: took 99.1s (avg 93.8s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:28:39,441 - INFO - === Epoch 85 ===
2025-08-16 15:30:04,396 - INFO - train: {'epoch': 85, 'time_epoch': 84.62605, 'eta': 1157.67676, 'eta_hours': 0.32158, 'loss': 0.5114751, 'lr': 6.026e-05, 'params': 517910, 'time_iter': 0.1354, 'accuracy': 0.81417, 'f1': 0.81417, 'accuracy-SBM': 0.81417, 'auc': 0.97383}
2025-08-16 15:30:08,524 - INFO - val: {'epoch': 85, 'time_epoch': 4.08116, 'loss': 0.63171133, 'lr': 0, 'params': 517910, 'time_iter': 0.06478, 'accuracy': 0.78502, 'f1': 0.78493, 'accuracy-SBM': 0.78489, 'auc': 0.96105}
2025-08-16 15:30:15,642 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:30:15,679 - INFO - test: {'epoch': 85, 'time_epoch': 4.43189, 'loss': 0.61411349, 'lr': 0, 'params': 517910, 'time_iter': 0.07035, 'accuracy': 0.78513, 'f1': 0.78511, 'accuracy-SBM': 0.78513, 'auc': 0.96302}
2025-08-16 15:30:15,681 - INFO - > Epoch 85: took 96.2s (avg 93.8s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:30:15,681 - INFO - === Epoch 86 ===
2025-08-16 15:31:39,803 - INFO - train: {'epoch': 86, 'time_epoch': 83.87889, 'eta': 1075.16304, 'eta_hours': 0.29866, 'loss': 0.5111952, 'lr': 5.264e-05, 'params': 517910, 'time_iter': 0.13421, 'accuracy': 0.81411, 'f1': 0.81411, 'accuracy-SBM': 0.81411, 'auc': 0.97385}
2025-08-16 15:31:44,079 - INFO - val: {'epoch': 86, 'time_epoch': 4.23208, 'loss': 0.63101302, 'lr': 0, 'params': 517910, 'time_iter': 0.06718, 'accuracy': 0.78444, 'f1': 0.78434, 'accuracy-SBM': 0.78433, 'auc': 0.96118}
2025-08-16 15:31:51,579 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:31:51,625 - INFO - test: {'epoch': 86, 'time_epoch': 4.48218, 'loss': 0.61223942, 'lr': 0, 'params': 517910, 'time_iter': 0.07115, 'accuracy': 0.78574, 'f1': 0.78571, 'accuracy-SBM': 0.7857, 'auc': 0.96318}
2025-08-16 15:31:51,627 - INFO - > Epoch 86: took 95.9s (avg 93.8s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:31:51,627 - INFO - === Epoch 87 ===
2025-08-16 15:33:15,839 - INFO - train: {'epoch': 87, 'time_epoch': 83.98211, 'eta': 992.63236, 'eta_hours': 0.27573, 'loss': 0.51105925, 'lr': 4.55e-05, 'params': 517910, 'time_iter': 0.13437, 'accuracy': 0.81366, 'f1': 0.81366, 'accuracy-SBM': 0.81366, 'auc': 0.97387}
2025-08-16 15:33:20,087 - INFO - val: {'epoch': 87, 'time_epoch': 4.20389, 'loss': 0.63008608, 'lr': 0, 'params': 517910, 'time_iter': 0.06673, 'accuracy': 0.78552, 'f1': 0.78543, 'accuracy-SBM': 0.7854, 'auc': 0.96119}
2025-08-16 15:33:29,177 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:33:29,215 - INFO - test: {'epoch': 87, 'time_epoch': 4.47582, 'loss': 0.61428482, 'lr': 0, 'params': 517910, 'time_iter': 0.07104, 'accuracy': 0.7855, 'f1': 0.78547, 'accuracy-SBM': 0.78548, 'auc': 0.96292}
2025-08-16 15:33:29,217 - INFO - > Epoch 87: took 97.6s (avg 93.9s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:33:29,217 - INFO - === Epoch 88 ===
2025-08-16 15:34:53,116 - INFO - train: {'epoch': 88, 'time_epoch': 83.66413, 'eta': 910.02977, 'eta_hours': 0.25279, 'loss': 0.50855289, 'lr': 3.886e-05, 'params': 517910, 'time_iter': 0.13386, 'accuracy': 0.81488, 'f1': 0.81488, 'accuracy-SBM': 0.81488, 'auc': 0.97412}
2025-08-16 15:34:57,353 - INFO - val: {'epoch': 88, 'time_epoch': 4.19197, 'loss': 0.63388854, 'lr': 0, 'params': 517910, 'time_iter': 0.06654, 'accuracy': 0.78475, 'f1': 0.78466, 'accuracy-SBM': 0.78463, 'auc': 0.96087}
2025-08-16 15:35:03,126 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:35:03,163 - INFO - test: {'epoch': 88, 'time_epoch': 4.47603, 'loss': 0.61801958, 'lr': 0, 'params': 517910, 'time_iter': 0.07105, 'accuracy': 0.78537, 'f1': 0.78534, 'accuracy-SBM': 0.78536, 'auc': 0.96258}
2025-08-16 15:35:03,165 - INFO - > Epoch 88: took 93.9s (avg 93.9s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:35:03,165 - INFO - === Epoch 89 ===
2025-08-16 15:36:27,087 - INFO - train: {'epoch': 89, 'time_epoch': 83.68786, 'eta': 827.40622, 'eta_hours': 0.22984, 'loss': 0.51039965, 'lr': 3.272e-05, 'params': 517910, 'time_iter': 0.1339, 'accuracy': 0.81434, 'f1': 0.81434, 'accuracy-SBM': 0.81434, 'auc': 0.97392}
2025-08-16 15:36:31,367 - INFO - val: {'epoch': 89, 'time_epoch': 4.23339, 'loss': 0.63213441, 'lr': 0, 'params': 517910, 'time_iter': 0.0672, 'accuracy': 0.78397, 'f1': 0.78386, 'accuracy-SBM': 0.78384, 'auc': 0.96104}
2025-08-16 15:36:37,144 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:36:37,182 - INFO - test: {'epoch': 89, 'time_epoch': 4.49167, 'loss': 0.6144554, 'lr': 0, 'params': 517910, 'time_iter': 0.0713, 'accuracy': 0.78596, 'f1': 0.78594, 'accuracy-SBM': 0.78595, 'auc': 0.96296}
2025-08-16 15:36:37,184 - INFO - > Epoch 89: took 94.0s (avg 93.9s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:36:37,184 - INFO - === Epoch 90 ===
2025-08-16 15:38:01,151 - INFO - train: {'epoch': 90, 'time_epoch': 83.73345, 'eta': 744.76379, 'eta_hours': 0.20688, 'loss': 0.50768108, 'lr': 2.709e-05, 'params': 517910, 'time_iter': 0.13397, 'accuracy': 0.81515, 'f1': 0.81514, 'accuracy-SBM': 0.81514, 'auc': 0.97421}
2025-08-16 15:38:05,375 - INFO - val: {'epoch': 90, 'time_epoch': 4.18004, 'loss': 0.63072196, 'lr': 0, 'params': 517910, 'time_iter': 0.06635, 'accuracy': 0.78486, 'f1': 0.78473, 'accuracy-SBM': 0.78473, 'auc': 0.96114}
2025-08-16 15:38:11,125 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:38:11,162 - INFO - test: {'epoch': 90, 'time_epoch': 4.45775, 'loss': 0.61544652, 'lr': 0, 'params': 517910, 'time_iter': 0.07076, 'accuracy': 0.78553, 'f1': 0.78551, 'accuracy-SBM': 0.78551, 'auc': 0.96282}
2025-08-16 15:38:11,165 - INFO - > Epoch 90: took 94.0s (avg 93.9s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:38:11,165 - INFO - === Epoch 91 ===
2025-08-16 15:39:35,227 - INFO - train: {'epoch': 91, 'time_epoch': 83.83052, 'eta': 662.10608, 'eta_hours': 0.18392, 'loss': 0.50816265, 'lr': 2.198e-05, 'params': 517910, 'time_iter': 0.13413, 'accuracy': 0.81515, 'f1': 0.81515, 'accuracy-SBM': 0.81515, 'auc': 0.97418}
2025-08-16 15:39:39,431 - INFO - val: {'epoch': 91, 'time_epoch': 4.15921, 'loss': 0.63606384, 'lr': 0, 'params': 517910, 'time_iter': 0.06602, 'accuracy': 0.78562, 'f1': 0.7855, 'accuracy-SBM': 0.78548, 'auc': 0.96065}
2025-08-16 15:39:45,235 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:39:45,272 - INFO - test: {'epoch': 91, 'time_epoch': 4.43882, 'loss': 0.61676613, 'lr': 0, 'params': 517910, 'time_iter': 0.07046, 'accuracy': 0.78527, 'f1': 0.78524, 'accuracy-SBM': 0.78523, 'auc': 0.96271}
2025-08-16 15:39:45,274 - INFO - > Epoch 91: took 94.1s (avg 93.9s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:39:45,275 - INFO - === Epoch 92 ===
2025-08-16 15:41:07,155 - INFO - train: {'epoch': 92, 'time_epoch': 81.64239, 'eta': 579.25845, 'eta_hours': 0.16091, 'loss': 0.5072998, 'lr': 1.74e-05, 'params': 517910, 'time_iter': 0.13063, 'accuracy': 0.8153, 'f1': 0.8153, 'accuracy-SBM': 0.8153, 'auc': 0.97425}
2025-08-16 15:41:11,371 - INFO - val: {'epoch': 92, 'time_epoch': 4.1715, 'loss': 0.63620719, 'lr': 0, 'params': 517910, 'time_iter': 0.06621, 'accuracy': 0.7847, 'f1': 0.78458, 'accuracy-SBM': 0.78456, 'auc': 0.96068}
2025-08-16 15:41:16,866 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:41:16,903 - INFO - test: {'epoch': 92, 'time_epoch': 4.18867, 'loss': 0.61579941, 'lr': 0, 'params': 517910, 'time_iter': 0.06649, 'accuracy': 0.78563, 'f1': 0.78561, 'accuracy-SBM': 0.78561, 'auc': 0.96288}
2025-08-16 15:41:16,904 - INFO - > Epoch 92: took 91.6s (avg 93.9s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:41:16,905 - INFO - === Epoch 93 ===
2025-08-16 15:42:41,051 - INFO - train: {'epoch': 93, 'time_epoch': 83.81172, 'eta': 496.57494, 'eta_hours': 0.13794, 'loss': 0.50686314, 'lr': 1.334e-05, 'params': 517910, 'time_iter': 0.1341, 'accuracy': 0.81555, 'f1': 0.81554, 'accuracy-SBM': 0.81554, 'auc': 0.9743}
2025-08-16 15:42:45,304 - INFO - val: {'epoch': 93, 'time_epoch': 4.19984, 'loss': 0.63468037, 'lr': 0, 'params': 517910, 'time_iter': 0.06666, 'accuracy': 0.78437, 'f1': 0.78426, 'accuracy-SBM': 0.78424, 'auc': 0.96072}
2025-08-16 15:42:51,094 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:42:51,139 - INFO - test: {'epoch': 93, 'time_epoch': 4.47523, 'loss': 0.61456347, 'lr': 0, 'params': 517910, 'time_iter': 0.07104, 'accuracy': 0.78515, 'f1': 0.78514, 'accuracy-SBM': 0.78515, 'auc': 0.96293}
2025-08-16 15:42:51,141 - INFO - > Epoch 93: took 94.2s (avg 93.9s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:42:51,141 - INFO - === Epoch 94 ===
2025-08-16 15:44:17,559 - INFO - train: {'epoch': 94, 'time_epoch': 86.12336, 'eta': 413.98934, 'eta_hours': 0.115, 'loss': 0.50718437, 'lr': 9.81e-06, 'params': 517910, 'time_iter': 0.1378, 'accuracy': 0.81543, 'f1': 0.81543, 'accuracy-SBM': 0.81543, 'auc': 0.97426}
2025-08-16 15:44:21,935 - INFO - val: {'epoch': 94, 'time_epoch': 4.32793, 'loss': 0.63343576, 'lr': 0, 'params': 517910, 'time_iter': 0.0687, 'accuracy': 0.78483, 'f1': 0.78474, 'accuracy-SBM': 0.78471, 'auc': 0.96083}
2025-08-16 15:44:27,827 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:44:27,872 - INFO - test: {'epoch': 94, 'time_epoch': 4.64421, 'loss': 0.61596213, 'lr': 0, 'params': 517910, 'time_iter': 0.07372, 'accuracy': 0.78514, 'f1': 0.78512, 'accuracy-SBM': 0.78513, 'auc': 0.96275}
2025-08-16 15:44:27,874 - INFO - > Epoch 94: took 96.7s (avg 93.9s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:44:27,874 - INFO - === Epoch 95 ===
2025-08-16 15:45:56,653 - INFO - train: {'epoch': 95, 'time_epoch': 88.5038, 'eta': 331.42922, 'eta_hours': 0.09206, 'loss': 0.50580412, 'lr': 6.82e-06, 'params': 517910, 'time_iter': 0.14161, 'accuracy': 0.81556, 'f1': 0.81556, 'accuracy-SBM': 0.81556, 'auc': 0.97441}
2025-08-16 15:46:01,021 - INFO - val: {'epoch': 95, 'time_epoch': 4.31314, 'loss': 0.6342725, 'lr': 0, 'params': 517910, 'time_iter': 0.06846, 'accuracy': 0.78501, 'f1': 0.78492, 'accuracy-SBM': 0.7849, 'auc': 0.96086}
2025-08-16 15:46:06,914 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:46:06,961 - INFO - test: {'epoch': 95, 'time_epoch': 4.65416, 'loss': 0.61519984, 'lr': 0, 'params': 517910, 'time_iter': 0.07388, 'accuracy': 0.78468, 'f1': 0.78466, 'accuracy-SBM': 0.78467, 'auc': 0.96292}
2025-08-16 15:46:06,963 - INFO - > Epoch 95: took 99.1s (avg 93.9s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:46:06,963 - INFO - === Epoch 96 ===
2025-08-16 15:47:35,613 - INFO - train: {'epoch': 96, 'time_epoch': 88.39381, 'eta': 248.74314, 'eta_hours': 0.0691, 'loss': 0.50591119, 'lr': 4.37e-06, 'params': 517910, 'time_iter': 0.14143, 'accuracy': 0.81589, 'f1': 0.81589, 'accuracy-SBM': 0.81589, 'auc': 0.97439}
2025-08-16 15:47:39,955 - INFO - val: {'epoch': 96, 'time_epoch': 4.29569, 'loss': 0.63337133, 'lr': 0, 'params': 517910, 'time_iter': 0.06819, 'accuracy': 0.78541, 'f1': 0.78531, 'accuracy-SBM': 0.78528, 'auc': 0.96092}
2025-08-16 15:47:45,806 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:47:45,853 - INFO - test: {'epoch': 96, 'time_epoch': 4.57225, 'loss': 0.6161532, 'lr': 0, 'params': 517910, 'time_iter': 0.07258, 'accuracy': 0.78497, 'f1': 0.78496, 'accuracy-SBM': 0.78497, 'auc': 0.96282}
2025-08-16 15:47:45,855 - INFO - > Epoch 96: took 98.9s (avg 94.0s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:47:45,855 - INFO - === Epoch 97 ===
2025-08-16 15:49:11,455 - INFO - train: {'epoch': 97, 'time_epoch': 85.3373, 'eta': 165.87821, 'eta_hours': 0.04608, 'loss': 0.50563584, 'lr': 2.46e-06, 'params': 517910, 'time_iter': 0.13654, 'accuracy': 0.8158, 'f1': 0.8158, 'accuracy-SBM': 0.8158, 'auc': 0.97443}
2025-08-16 15:49:15,835 - INFO - val: {'epoch': 97, 'time_epoch': 4.33357, 'loss': 0.63450861, 'lr': 0, 'params': 517910, 'time_iter': 0.06879, 'accuracy': 0.78522, 'f1': 0.78511, 'accuracy-SBM': 0.78508, 'auc': 0.96078}
2025-08-16 15:49:23,375 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:49:23,413 - INFO - test: {'epoch': 97, 'time_epoch': 4.31472, 'loss': 0.61379261, 'lr': 0, 'params': 517910, 'time_iter': 0.06849, 'accuracy': 0.78603, 'f1': 0.786, 'accuracy-SBM': 0.78602, 'auc': 0.96306}
2025-08-16 15:49:23,415 - INFO - > Epoch 97: took 97.6s (avg 94.0s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:49:23,415 - INFO - === Epoch 98 ===
2025-08-16 15:50:48,832 - INFO - train: {'epoch': 98, 'time_epoch': 85.16379, 'eta': 82.96158, 'eta_hours': 0.02304, 'loss': 0.50549112, 'lr': 1.09e-06, 'params': 517910, 'time_iter': 0.13626, 'accuracy': 0.81613, 'f1': 0.81613, 'accuracy-SBM': 0.81613, 'auc': 0.97445}
2025-08-16 15:50:53,136 - INFO - val: {'epoch': 98, 'time_epoch': 4.2555, 'loss': 0.63604028, 'lr': 0, 'params': 517910, 'time_iter': 0.06755, 'accuracy': 0.78538, 'f1': 0.78526, 'accuracy-SBM': 0.78523, 'auc': 0.96069}
2025-08-16 15:50:59,035 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:50:59,075 - INFO - test: {'epoch': 98, 'time_epoch': 4.53088, 'loss': 0.6161528, 'lr': 0, 'params': 517910, 'time_iter': 0.07192, 'accuracy': 0.78596, 'f1': 0.78594, 'accuracy-SBM': 0.78594, 'auc': 0.96286}
2025-08-16 15:50:59,077 - INFO - > Epoch 98: took 95.7s (avg 94.1s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:50:59,078 - INFO - === Epoch 99 ===
2025-08-16 15:52:24,178 - INFO - train: {'epoch': 99, 'time_epoch': 84.8373, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.50586395, 'lr': 2.7e-07, 'params': 517910, 'time_iter': 0.13574, 'accuracy': 0.81607, 'f1': 0.81607, 'accuracy-SBM': 0.81607, 'auc': 0.9744}
2025-08-16 15:52:28,468 - INFO - val: {'epoch': 99, 'time_epoch': 4.24338, 'loss': 0.63402625, 'lr': 0, 'params': 517910, 'time_iter': 0.06736, 'accuracy': 0.7848, 'f1': 0.78469, 'accuracy-SBM': 0.78466, 'auc': 0.96082}
2025-08-16 15:52:34,257 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-45/test_results
2025-08-16 15:52:34,296 - INFO - test: {'epoch': 99, 'time_epoch': 4.52306, 'loss': 0.61456295, 'lr': 0, 'params': 517910, 'time_iter': 0.07179, 'accuracy': 0.78555, 'f1': 0.78552, 'accuracy-SBM': 0.78553, 'auc': 0.96296}
2025-08-16 15:52:34,596 - INFO - > Epoch 99: took 95.2s (avg 94.1s) | Best so far: epoch 76	train_loss: 0.5235 train_accuracy-SBM: 0.8097	val_loss: 0.6281 val_accuracy-SBM: 0.7855	test_loss: 0.6085 test_accuracy-SBM: 0.7860
2025-08-16 15:52:34,597 - INFO - ================================================================================
2025-08-16 15:52:34,597 - INFO - NAS TRAINING COMPLETED SUCCESSFULLY
2025-08-16 15:52:34,597 - INFO - ================================================================================
2025-08-16 15:52:34,597 - INFO - Avg time per epoch: 94.06s
2025-08-16 15:52:34,597 - INFO - Total train loop time: 2.61h
2025-08-16 15:52:34,597 - INFO - Routing mode: nas
2025-08-16 15:52:34,597 - INFO - Final optimal weights: {'layer_0': 2, 'layer_1': 2, 'layer_2': 2, 'layer_3': 1, 'layer_4': 1, 'layer_5': 1, 'layer_6': 1, 'layer_7': 1, 'layer_8': 1, 'layer_9': 0, 'layer_10': 1, 'layer_11': 1, 'layer_12': 1, 'layer_13': 1, 'layer_14': 1, 'layer_15': 1}
2025-08-16 15:52:34,597 - INFO - Results include routing uncertainty (test only, NO variance)
