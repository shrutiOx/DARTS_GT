Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          376Gi        26Gi       298Gi       1.7Gi        51Gi       345Gi
Swap:         1.9Gi       3.0Mi       1.9Gi
Sat Jul  5 04:23:14 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:1D:00.0 Off |                    0 |
| N/A   33C    P0             42W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 41
Starting training for seed 41...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E/confignas.yaml
Using device: cuda
2025-07-05 04:23:44,197 - INFO - GPU Mem: 34.1GB
2025-07-05 04:23:44,198 - INFO - Run directory: results/Cluster/Cluster-SparseE-41
2025-07-05 04:23:44,198 - INFO - Seed: 41
2025-07-05 04:23:44,198 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-07-05 04:23:44,198 - INFO - Routing mode: nas
2025-07-05 04:23:44,198 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-07-05 04:23:44,198 - INFO - Number of layers: 16
2025-07-05 04:23:44,198 - INFO - Uncertainty enabled: False
2025-07-05 04:23:44,198 - INFO - Training mode: NoMixNas_uncertainty_train
2025-07-05 04:23:44,198 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-07-05 04:23:44,198 - INFO - Additional features: Router weights logging + JSON export
2025-07-05 04:23:58,252 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-05 04:23:58,255 - INFO -   Data(x=[1406436, 7], edge_index=[2, 51620680], y=[1406436])
2025-07-05 04:23:58,273 - INFO -   undirected: True
2025-07-05 04:23:58,273 - INFO -   num graphs: 12000
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-05 04:23:58,273 - INFO -   avg num_nodes/graph: 117
2025-07-05 04:23:58,274 - INFO -   num node features: 7
2025-07-05 04:23:58,274 - INFO -   num edge features: 0
2025-07-05 04:23:58,275 - INFO -   num classes: 6
2025-07-05 04:23:58,276 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 4, 8, 16]
2025-07-05 04:23:58,276 - INFO - Precomputing Positional Encoding statistics: ['LapPE', 'RWSE'] for all graphs...
2025-07-05 04:23:58,284 - INFO -   ...estimated to be undirected: True
  0%|          | 0/12000 [00:00<?, ?it/s] 16%|█▌        | 1866/12000 [00:10<00:54, 186.53it/s] 32%|███▏      | 3787/12000 [00:20<00:43, 189.73it/s] 47%|████▋     | 5637/12000 [00:30<00:33, 187.55it/s] 64%|██████▎   | 7649/12000 [00:40<00:22, 192.92it/s] 80%|████████  | 9613/12000 [00:50<00:12, 194.15it/s] 97%|█████████▋| 11623/12000 [01:00<00:01, 196.46it/s]100%|██████████| 12000/12000 [01:01<00:00, 193.75it/s]
2025-07-05 04:25:00,981 - INFO - Done! Took 00:01:02.70
2025-07-05 04:25:01,003 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset'
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/nni/nas/nn/pytorch/choice.py:252: UserWarning: "key" is deprecated. Assuming label.
  warnings.warn(f'"key" is deprecated. Assuming label.')
2025-07-05 04:25:01,415 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-07-05 04:25:01,415 - INFO - Inner model type: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-07-05 04:25:01,415 - INFO - Inner model has get_darts_model: True
2025-07-05 04:25:01,420 - INFO - GraphGymModule(
  (model): NASModelEdge(
    (encoder): FeatureEncoder(
      (node_encoder): LapPENodeEncoder(
        (linear_x): Linear(in_features=7, out_features=32, bias=True)
        (linear_A): Linear(in_features=2, out_features=32, bias=True)
        (pe_encoder): Sequential(
          (0): ReLU()
          (1): Linear(in_features=32, out_features=16, bias=True)
          (2): ReLU()
        )
      )
      (edge_encoder): DummyEdgeEncoder(
        (encoder): Embedding(1, 48)
      )
    )
    (darts_layers): ModuleList(
      (0): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (6): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_6')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (7): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_7')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (8): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_8')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (9): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_9')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (10): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_10')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (11): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_11')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (12): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_12')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (13): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_13')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (14): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_14')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (15): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_15')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (darts_sequential): Sequential(
      (0): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (6): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_6')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (7): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_7')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (8): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_8')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (9): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_9')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (10): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_10')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (11): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_11')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (12): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_12')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (13): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_13')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (14): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_14')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (15): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_15')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(48, 48, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(48, 48, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(48, 6, bias=True)
          )
        )
      )
    )
  )
)
2025-07-05 04:25:01,431 - INFO - Number of parameters: 728,630
2025-07-05 04:25:01,431 - INFO - Starting optimized training: 2025-07-05 04:25:01.431487
2025-07-05 04:25:07,034 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset':
2025-07-05 04:25:07,034 - INFO -   Data(x=[1406436, 7], edge_index=[2, 51620680], y=[1406436])
2025-07-05 04:25:07,035 - INFO -   undirected: True
2025-07-05 04:25:07,035 - INFO -   num graphs: 12000
2025-07-05 04:25:07,035 - INFO -   avg num_nodes/graph: 117
2025-07-05 04:25:07,036 - INFO -   num node features: 7
2025-07-05 04:25:07,036 - INFO -   num edge features: 0
2025-07-05 04:25:07,037 - INFO -   num classes: 6
2025-07-05 04:25:07,037 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 4, 8, 16]
2025-07-05 04:25:07,037 - INFO - Precomputing Positional Encoding statistics: ['LapPE', 'RWSE'] for all graphs...
2025-07-05 04:25:07,045 - INFO -   ...estimated to be undirected: True
  0%|          | 0/12000 [00:00<?, ?it/s] 17%|█▋        | 2045/12000 [00:10<00:48, 204.48it/s] 34%|███▎      | 4025/12000 [00:20<00:39, 200.63it/s] 50%|█████     | 6049/12000 [00:30<00:29, 201.41it/s] 66%|██████▌   | 7917/12000 [00:40<00:20, 195.61it/s] 82%|████████▏ | 9864/12000 [00:50<00:10, 195.28it/s] 99%|█████████▊| 11838/12000 [01:00<00:00, 195.99it/s]100%|██████████| 12000/12000 [01:00<00:00, 197.30it/s]
2025-07-05 04:26:08,588 - INFO - Done! Took 00:01:01.55
2025-07-05 04:26:08,612 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset'
2025-07-05 04:26:08,617 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-07-05 04:26:08,618 - INFO - Start from epoch 0
2025-07-05 04:26:08,618 - INFO - ================================================================================
2025-07-05 04:26:08,618 - INFO - STARTING TWO-PHASE NAS TRAINING
2025-07-05 04:26:08,618 - INFO - ================================================================================
2025-07-05 04:26:08,618 - INFO - Routing mode: nas
2025-07-05 04:26:08,618 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-07-05 04:26:08,618 - INFO - Phase 1: Architecture search/initialization
2025-07-05 04:26:08,618 - INFO - Phase 2: Discrete training with uncertainty (NO variance)
2025-07-05 04:26:08,618 - INFO - ============================================================
2025-07-05 04:26:08,618 - INFO - PHASE 1: ARCHITECTURE SEARCH/INITIALIZATION
2025-07-05 04:26:08,618 - INFO - ============================================================
2025-07-05 04:26:08,618 - INFO - Splitting dataset for DARTS:
2025-07-05 04:26:08,618 - INFO -   Original train size: 10000
2025-07-05 04:26:08,619 - INFO -   DARTS train size: 6000 (60.0%)
2025-07-05 04:26:08,619 - INFO -   DARTS val size: 4000 (40.0%)
2025-07-05 04:26:08,620 - INFO - Found GraphGym wrapper, using inner model: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-07-05 04:26:08,620 - INFO - Successfully configured model for DARTS training
2025-07-05 04:26:08,620 - INFO - NAS MODE: Running 25 epochs with DARTS
2025-07-05 04:26:08,620 - INFO - DARTS Configuration:
2025-07-05 04:26:08,620 - INFO -   Epochs: 25
2025-07-05 04:26:08,620 - INFO -   Architecture LR: 0.0004
2025-07-05 04:26:08,620 - INFO -   Grad clip: 5.0
2025-07-05 04:26:08,624 - INFO - Starting DARTS architecture search
2025-07-05 04:26:12,131 - WARNING - Epoch [1/25] Step [1/250]  acc 0.153727 (0.153727)  loss 1.802190 (1.802190)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 3358.0 MB
2025-07-05 04:26:16,634 - WARNING - Epoch [1/25] Step [11/250]  acc 0.169653 (0.165663)  loss 1.794445 (1.795403)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 3460.0 MB
2025-07-05 04:26:21,024 - WARNING - Epoch [1/25] Step [21/250]  acc 0.162842 (0.165337)  loss 1.792124 (1.794015)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 3540.0 MB
2025-07-05 04:26:25,429 - WARNING - Epoch [1/25] Step [31/250]  acc 0.179650 (0.164720)  loss 1.790394 (1.793532)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6798.0 MB
2025-07-05 04:26:29,813 - WARNING - Epoch [1/25] Step [41/250]  acc 0.154004 (0.165338)  loss 1.792412 (1.793169)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6798.0 MB
2025-07-05 04:26:34,161 - WARNING - Epoch [1/25] Step [51/250]  acc 0.186695 (0.165453)  loss 1.791060 (1.793013)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6798.0 MB
2025-07-05 04:26:38,722 - WARNING - Epoch [1/25] Step [61/250]  acc 0.161164 (0.166183)  loss 1.792581 (1.792877)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6798.0 MB
2025-07-05 04:26:43,088 - WARNING - Epoch [1/25] Step [71/250]  acc 0.156267 (0.165733)  loss 1.793139 (1.792850)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6798.0 MB
2025-07-05 04:26:47,459 - WARNING - Epoch [1/25] Step [81/250]  acc 0.166063 (0.165966)  loss 1.792028 (1.792772)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6800.0 MB
2025-07-05 04:26:51,899 - WARNING - Epoch [1/25] Step [91/250]  acc 0.189349 (0.167103)  loss 1.790330 (1.792615)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 6800.0 MB
2025-07-05 04:26:56,338 - WARNING - Epoch [1/25] Step [101/250]  acc 0.204117 (0.170045)  loss 1.782506 (1.792187)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6800.0 MB
2025-07-05 04:27:00,937 - WARNING - Epoch [1/25] Step [111/250]  acc 0.203515 (0.172120)  loss 1.786107 (1.791664)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6800.0 MB
2025-07-05 04:27:05,313 - WARNING - Epoch [1/25] Step [121/250]  acc 0.226293 (0.176073)  loss 1.777821 (1.790791)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 6800.0 MB
2025-07-05 04:27:09,873 - WARNING - Epoch [1/25] Step [131/250]  acc 0.217169 (0.178291)  loss 1.773376 (1.789816)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6800.0 MB
2025-07-05 04:27:14,518 - WARNING - Epoch [1/25] Step [141/250]  acc 0.189009 (0.180597)  loss 1.775308 (1.788698)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6802.0 MB
2025-07-05 04:27:18,904 - WARNING - Epoch [1/25] Step [151/250]  acc 0.252935 (0.182484)  loss 1.761313 (1.787383)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6802.0 MB
2025-07-05 04:27:23,340 - WARNING - Epoch [1/25] Step [161/250]  acc 0.205766 (0.184170)  loss 1.756474 (1.785911)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 6802.0 MB
2025-07-05 04:27:27,758 - WARNING - Epoch [1/25] Step [171/250]  acc 0.225659 (0.186532)  loss 1.750288 (1.784270)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6802.0 MB
2025-07-05 04:27:32,125 - WARNING - Epoch [1/25] Step [181/250]  acc 0.250632 (0.189543)  loss 1.743130 (1.782305)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6802.0 MB
2025-07-05 04:27:36,475 - WARNING - Epoch [1/25] Step [191/250]  acc 0.237922 (0.192870)  loss 1.737617 (1.779817)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6802.0 MB
2025-07-05 04:27:40,931 - WARNING - Epoch [1/25] Step [201/250]  acc 0.271263 (0.196390)  loss 1.723242 (1.777423)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 6802.0 MB
2025-07-05 04:27:45,295 - WARNING - Epoch [1/25] Step [211/250]  acc 0.328224 (0.200762)  loss 1.681965 (1.774153)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 6802.0 MB
2025-07-05 04:27:49,695 - WARNING - Epoch [1/25] Step [221/250]  acc 0.271375 (0.205159)  loss 1.711048 (1.770472)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6802.0 MB
2025-07-05 04:27:54,379 - WARNING - Epoch [1/25] Step [231/250]  acc 0.317009 (0.208859)  loss 1.678790 (1.767293)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6802.0 MB
2025-07-05 04:27:58,823 - WARNING - Epoch [1/25] Step [241/250]  acc 0.358613 (0.213570)  loss 1.620823 (1.762870)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6802.0 MB
Epoch 1 completed in 0:01:54.196568
2025-07-05 04:28:29,958 - WARNING - Epoch [2/25] Step [1/250]  acc 0.319205 (0.319205)  loss 1.646286 (1.646286)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6802.0 MB
2025-07-05 04:28:34,356 - WARNING - Epoch [2/25] Step [11/250]  acc 0.372468 (0.339720)  loss 1.606326 (1.638430)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6802.0 MB
2025-07-05 04:28:38,684 - WARNING - Epoch [2/25] Step [21/250]  acc 0.392202 (0.350916)  loss 1.574693 (1.621259)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 6802.0 MB
2025-07-05 04:28:43,032 - WARNING - Epoch [2/25] Step [31/250]  acc 0.362392 (0.352821)  loss 1.590601 (1.616463)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6802.0 MB
2025-07-05 04:28:47,360 - WARNING - Epoch [2/25] Step [41/250]  acc 0.378773 (0.359045)  loss 1.582069 (1.605717)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6804.0 MB
2025-07-05 04:28:51,661 - WARNING - Epoch [2/25] Step [51/250]  acc 0.392488 (0.361238)  loss 1.542838 (1.599756)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6804.0 MB
2025-07-05 04:28:56,038 - WARNING - Epoch [2/25] Step [61/250]  acc 0.396618 (0.366257)  loss 1.537529 (1.591944)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6804.0 MB
2025-07-05 04:29:00,433 - WARNING - Epoch [2/25] Step [71/250]  acc 0.392523 (0.371871)  loss 1.520227 (1.581337)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 6804.0 MB
2025-07-05 04:29:04,939 - WARNING - Epoch [2/25] Step [81/250]  acc 0.422841 (0.375485)  loss 1.477139 (1.574141)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 6804.0 MB
2025-07-05 04:29:09,560 - WARNING - Epoch [2/25] Step [91/250]  acc 0.388464 (0.379711)  loss 1.499109 (1.565357)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6804.0 MB
2025-07-05 04:29:13,889 - WARNING - Epoch [2/25] Step [101/250]  acc 0.424893 (0.383160)  loss 1.501652 (1.558693)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6804.0 MB
2025-07-05 04:29:18,218 - WARNING - Epoch [2/25] Step [111/250]  acc 0.401869 (0.388491)  loss 1.477800 (1.549234)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 6804.0 MB
2025-07-05 04:29:22,573 - WARNING - Epoch [2/25] Step [121/250]  acc 0.467700 (0.392895)  loss 1.405731 (1.540660)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6804.0 MB
2025-07-05 04:29:26,926 - WARNING - Epoch [2/25] Step [131/250]  acc 0.477238 (0.396963)  loss 1.385746 (1.532499)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6804.0 MB
2025-07-05 04:29:31,215 - WARNING - Epoch [2/25] Step [141/250]  acc 0.457253 (0.400538)  loss 1.410978 (1.525102)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6804.0 MB
2025-07-05 04:29:35,560 - WARNING - Epoch [2/25] Step [151/250]  acc 0.453101 (0.403643)  loss 1.412799 (1.518272)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6804.0 MB
2025-07-05 04:29:39,907 - WARNING - Epoch [2/25] Step [161/250]  acc 0.483403 (0.407292)  loss 1.389455 (1.511564)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6804.0 MB
2025-07-05 04:29:44,366 - WARNING - Epoch [2/25] Step [171/250]  acc 0.429384 (0.409866)  loss 1.436560 (1.506184)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6804.0 MB
2025-07-05 04:29:48,856 - WARNING - Epoch [2/25] Step [181/250]  acc 0.431909 (0.412367)  loss 1.451539 (1.500855)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6804.0 MB
2025-07-05 04:29:53,373 - WARNING - Epoch [2/25] Step [191/250]  acc 0.427686 (0.414708)  loss 1.454596 (1.496145)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6804.0 MB
2025-07-05 04:29:57,696 - WARNING - Epoch [2/25] Step [201/250]  acc 0.467610 (0.417352)  loss 1.388751 (1.490248)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 6804.0 MB
2025-07-05 04:30:02,030 - WARNING - Epoch [2/25] Step [211/250]  acc 0.472626 (0.420456)  loss 1.393641 (1.484018)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6804.0 MB
2025-07-05 04:30:06,725 - WARNING - Epoch [2/25] Step [221/250]  acc 0.463588 (0.423243)  loss 1.378121 (1.477993)
GPU memory consumption  GPU Memory: Allocated: 52.6 MB, Reserved: 6804.0 MB
2025-07-05 04:30:11,275 - WARNING - Epoch [2/25] Step [231/250]  acc 0.519117 (0.426291)  loss 1.299186 (1.471459)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6804.0 MB
2025-07-05 04:30:15,626 - WARNING - Epoch [2/25] Step [241/250]  acc 0.484006 (0.428565)  loss 1.343309 (1.466757)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6804.0 MB
Epoch 2 completed in 0:01:50.052263
2025-07-05 04:30:46,836 - WARNING - Epoch [3/25] Step [1/250]  acc 0.493213 (0.493213)  loss 1.342623 (1.342623)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6804.0 MB
2025-07-05 04:30:51,165 - WARNING - Epoch [3/25] Step [11/250]  acc 0.489103 (0.465783)  loss 1.335709 (1.374110)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6804.0 MB
2025-07-05 04:30:55,518 - WARNING - Epoch [3/25] Step [21/250]  acc 0.509021 (0.483025)  loss 1.291421 (1.346000)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6804.0 MB
2025-07-05 04:30:59,850 - WARNING - Epoch [3/25] Step [31/250]  acc 0.526064 (0.485284)  loss 1.269723 (1.343336)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6804.0 MB
2025-07-05 04:31:04,335 - WARNING - Epoch [3/25] Step [41/250]  acc 0.481582 (0.488945)  loss 1.334887 (1.335267)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6804.0 MB
2025-07-05 04:31:08,840 - WARNING - Epoch [3/25] Step [51/250]  acc 0.504717 (0.491637)  loss 1.316447 (1.328775)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6804.0 MB
2025-07-05 04:31:13,273 - WARNING - Epoch [3/25] Step [61/250]  acc 0.505606 (0.495683)  loss 1.285614 (1.320056)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6804.0 MB
2025-07-05 04:31:17,682 - WARNING - Epoch [3/25] Step [71/250]  acc 0.494038 (0.499510)  loss 1.337552 (1.313531)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 6804.0 MB
2025-07-05 04:31:22,022 - WARNING - Epoch [3/25] Step [81/250]  acc 0.503767 (0.499160)  loss 1.311658 (1.313994)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6804.0 MB
2025-07-05 04:31:26,455 - WARNING - Epoch [3/25] Step [91/250]  acc 0.493159 (0.500362)  loss 1.307643 (1.311015)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 6804.0 MB
2025-07-05 04:31:31,002 - WARNING - Epoch [3/25] Step [101/250]  acc 0.547347 (0.502501)  loss 1.207271 (1.305437)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6804.0 MB
2025-07-05 04:31:35,386 - WARNING - Epoch [3/25] Step [111/250]  acc 0.531083 (0.504243)  loss 1.218872 (1.301734)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6804.0 MB
2025-07-05 04:31:39,778 - WARNING - Epoch [3/25] Step [121/250]  acc 0.526316 (0.507090)  loss 1.260901 (1.296046)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 6804.0 MB
2025-07-05 04:31:44,205 - WARNING - Epoch [3/25] Step [131/250]  acc 0.529620 (0.508838)  loss 1.234956 (1.292349)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6804.0 MB
2025-07-05 04:31:48,577 - WARNING - Epoch [3/25] Step [141/250]  acc 0.520189 (0.510458)  loss 1.282093 (1.288423)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6804.0 MB
2025-07-05 04:31:52,949 - WARNING - Epoch [3/25] Step [151/250]  acc 0.482292 (0.512059)  loss 1.357046 (1.284663)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6804.0 MB
2025-07-05 04:31:57,297 - WARNING - Epoch [3/25] Step [161/250]  acc 0.574627 (0.514171)  loss 1.150687 (1.279693)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6804.0 MB
2025-07-05 04:32:01,652 - WARNING - Epoch [3/25] Step [171/250]  acc 0.538545 (0.514759)  loss 1.237426 (1.278034)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6804.0 MB
2025-07-05 04:32:06,244 - WARNING - Epoch [3/25] Step [181/250]  acc 0.587935 (0.516036)  loss 1.129156 (1.274852)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6804.0 MB
2025-07-05 04:32:10,678 - WARNING - Epoch [3/25] Step [191/250]  acc 0.502405 (0.517404)  loss 1.292518 (1.271606)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6804.0 MB
2025-07-05 04:32:15,083 - WARNING - Epoch [3/25] Step [201/250]  acc 0.555906 (0.518981)  loss 1.182485 (1.268449)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6804.0 MB
2025-07-05 04:32:19,525 - WARNING - Epoch [3/25] Step [211/250]  acc 0.561554 (0.520412)  loss 1.175039 (1.264952)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 6804.0 MB
2025-07-05 04:32:24,020 - WARNING - Epoch [3/25] Step [221/250]  acc 0.543028 (0.521493)  loss 1.201521 (1.262727)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6804.0 MB
2025-07-05 04:32:28,769 - WARNING - Epoch [3/25] Step [231/250]  acc 0.543803 (0.522594)  loss 1.210960 (1.260044)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6804.0 MB
2025-07-05 04:32:33,546 - WARNING - Epoch [3/25] Step [241/250]  acc 0.493678 (0.523195)  loss 1.328603 (1.257996)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6804.0 MB
Epoch 3 completed in 0:01:51.232480
2025-07-05 04:33:05,007 - WARNING - Epoch [4/25] Step [1/250]  acc 0.579088 (0.579088)  loss 1.159813 (1.159813)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6804.0 MB
2025-07-05 04:33:09,486 - WARNING - Epoch [4/25] Step [11/250]  acc 0.534148 (0.561937)  loss 1.225586 (1.166738)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6804.0 MB
2025-07-05 04:33:13,914 - WARNING - Epoch [4/25] Step [21/250]  acc 0.558838 (0.557844)  loss 1.169102 (1.176937)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6804.0 MB
2025-07-05 04:33:18,382 - WARNING - Epoch [4/25] Step [31/250]  acc 0.569005 (0.559688)  loss 1.159361 (1.172863)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 6804.0 MB
2025-07-05 04:33:22,749 - WARNING - Epoch [4/25] Step [41/250]  acc 0.550843 (0.558843)  loss 1.200819 (1.173817)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 6804.0 MB
2025-07-05 04:33:27,219 - WARNING - Epoch [4/25] Step [51/250]  acc 0.538504 (0.558354)  loss 1.186369 (1.176306)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6804.0 MB
2025-07-05 04:33:31,650 - WARNING - Epoch [4/25] Step [61/250]  acc 0.575221 (0.557640)  loss 1.156838 (1.176997)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6804.0 MB
2025-07-05 04:33:36,110 - WARNING - Epoch [4/25] Step [71/250]  acc 0.554733 (0.555432)  loss 1.195972 (1.182297)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6804.0 MB
2025-07-05 04:33:40,443 - WARNING - Epoch [4/25] Step [81/250]  acc 0.541144 (0.553834)  loss 1.178861 (1.184052)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 6804.0 MB
2025-07-05 04:33:44,880 - WARNING - Epoch [4/25] Step [91/250]  acc 0.537645 (0.552390)  loss 1.236218 (1.187141)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 6804.0 MB
2025-07-05 04:33:49,310 - WARNING - Epoch [4/25] Step [101/250]  acc 0.586366 (0.551888)  loss 1.128985 (1.187844)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6804.0 MB
2025-07-05 04:33:53,741 - WARNING - Epoch [4/25] Step [111/250]  acc 0.568649 (0.551948)  loss 1.153924 (1.188069)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6804.0 MB
2025-07-05 04:33:58,293 - WARNING - Epoch [4/25] Step [121/250]  acc 0.567683 (0.553218)  loss 1.156941 (1.185035)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6804.0 MB
2025-07-05 04:34:02,983 - WARNING - Epoch [4/25] Step [131/250]  acc 0.620133 (0.554281)  loss 1.037320 (1.182914)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6804.0 MB
2025-07-05 04:34:07,395 - WARNING - Epoch [4/25] Step [141/250]  acc 0.609539 (0.555199)  loss 1.075262 (1.181096)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6804.0 MB
2025-07-05 04:34:11,725 - WARNING - Epoch [4/25] Step [151/250]  acc 0.595376 (0.555932)  loss 1.075550 (1.179392)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6804.0 MB
2025-07-05 04:34:16,128 - WARNING - Epoch [4/25] Step [161/250]  acc 0.561765 (0.556564)  loss 1.193410 (1.178265)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6804.0 MB
2025-07-05 04:34:20,498 - WARNING - Epoch [4/25] Step [171/250]  acc 0.565442 (0.556978)  loss 1.166227 (1.177233)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6804.0 MB
2025-07-05 04:34:24,917 - WARNING - Epoch [4/25] Step [181/250]  acc 0.546550 (0.556966)  loss 1.204301 (1.177033)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6804.0 MB
2025-07-05 04:34:29,317 - WARNING - Epoch [4/25] Step [191/250]  acc 0.522632 (0.556184)  loss 1.276003 (1.178831)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6804.0 MB
2025-07-05 04:34:33,783 - WARNING - Epoch [4/25] Step [201/250]  acc 0.561188 (0.556903)  loss 1.154258 (1.176827)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6804.0 MB
2025-07-05 04:34:38,220 - WARNING - Epoch [4/25] Step [211/250]  acc 0.574769 (0.557508)  loss 1.153409 (1.175876)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6804.0 MB
2025-07-05 04:34:42,633 - WARNING - Epoch [4/25] Step [221/250]  acc 0.589295 (0.558042)  loss 1.107990 (1.175388)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6804.0 MB
2025-07-05 04:34:47,044 - WARNING - Epoch [4/25] Step [231/250]  acc 0.544463 (0.558332)  loss 1.224815 (1.174990)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6804.0 MB
2025-07-05 04:34:51,360 - WARNING - Epoch [4/25] Step [241/250]  acc 0.578888 (0.558969)  loss 1.121167 (1.173127)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6804.0 MB
Epoch 4 completed in 0:01:50.753892
2025-07-05 04:35:22,451 - WARNING - Epoch [5/25] Step [1/250]  acc 0.512514 (0.512514)  loss 1.267387 (1.267387)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6804.0 MB
2025-07-05 04:35:26,987 - WARNING - Epoch [5/25] Step [11/250]  acc 0.585831 (0.567614)  loss 1.114128 (1.161508)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6804.0 MB
2025-07-05 04:35:31,424 - WARNING - Epoch [5/25] Step [21/250]  acc 0.605372 (0.573323)  loss 1.081257 (1.146432)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6804.0 MB
2025-07-05 04:35:36,091 - WARNING - Epoch [5/25] Step [31/250]  acc 0.581649 (0.576464)  loss 1.139165 (1.139298)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6804.0 MB
2025-07-05 04:35:40,588 - WARNING - Epoch [5/25] Step [41/250]  acc 0.556030 (0.580471)  loss 1.183650 (1.129642)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6804.0 MB
2025-07-05 04:35:45,028 - WARNING - Epoch [5/25] Step [51/250]  acc 0.598572 (0.575916)  loss 1.107523 (1.139665)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6804.0 MB
2025-07-05 04:35:49,670 - WARNING - Epoch [5/25] Step [61/250]  acc 0.580695 (0.576108)  loss 1.118981 (1.140550)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6804.0 MB
2025-07-05 04:35:54,186 - WARNING - Epoch [5/25] Step [71/250]  acc 0.636829 (0.578777)  loss 1.015523 (1.135036)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 6804.0 MB
2025-07-05 04:35:58,774 - WARNING - Epoch [5/25] Step [81/250]  acc 0.544627 (0.579475)  loss 1.236885 (1.133116)
GPU memory consumption  GPU Memory: Allocated: 51.1 MB, Reserved: 6804.0 MB
2025-07-05 04:36:03,276 - WARNING - Epoch [5/25] Step [91/250]  acc 0.619877 (0.582263)  loss 1.056741 (1.129005)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6804.0 MB
2025-07-05 04:36:07,780 - WARNING - Epoch [5/25] Step [101/250]  acc 0.566272 (0.582984)  loss 1.176661 (1.127908)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6804.0 MB
2025-07-05 04:36:12,282 - WARNING - Epoch [5/25] Step [111/250]  acc 0.614328 (0.585379)  loss 1.065022 (1.122326)
GPU memory consumption  GPU Memory: Allocated: 59.4 MB, Reserved: 6804.0 MB
2025-07-05 04:36:16,801 - WARNING - Epoch [5/25] Step [121/250]  acc 0.595640 (0.585219)  loss 1.124548 (1.123303)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 6804.0 MB
2025-07-05 04:36:21,261 - WARNING - Epoch [5/25] Step [131/250]  acc 0.603694 (0.586481)  loss 1.078867 (1.120828)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6804.0 MB
2025-07-05 04:36:25,654 - WARNING - Epoch [5/25] Step [141/250]  acc 0.589457 (0.587542)  loss 1.119941 (1.118277)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6804.0 MB
2025-07-05 04:36:30,039 - WARNING - Epoch [5/25] Step [151/250]  acc 0.570650 (0.588602)  loss 1.129282 (1.115742)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6804.0 MB
2025-07-05 04:36:34,536 - WARNING - Epoch [5/25] Step [161/250]  acc 0.634945 (0.589032)  loss 1.017889 (1.115199)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6804.0 MB
2025-07-05 04:36:39,402 - WARNING - Epoch [5/25] Step [171/250]  acc 0.620365 (0.590404)  loss 1.051698 (1.112260)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6804.0 MB
2025-07-05 04:36:43,884 - WARNING - Epoch [5/25] Step [181/250]  acc 0.643082 (0.591198)  loss 1.006839 (1.110423)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6804.0 MB
2025-07-05 04:36:48,409 - WARNING - Epoch [5/25] Step [191/250]  acc 0.629897 (0.592045)  loss 1.054624 (1.108636)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6804.0 MB
2025-07-05 04:36:52,772 - WARNING - Epoch [5/25] Step [201/250]  acc 0.622363 (0.593776)  loss 1.039378 (1.104877)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6804.0 MB
2025-07-05 04:36:57,190 - WARNING - Epoch [5/25] Step [211/250]  acc 0.627971 (0.595755)  loss 1.031537 (1.100421)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6804.0 MB
2025-07-05 04:37:01,550 - WARNING - Epoch [5/25] Step [221/250]  acc 0.634403 (0.596623)  loss 1.020314 (1.098564)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6804.0 MB
2025-07-05 04:37:05,964 - WARNING - Epoch [5/25] Step [231/250]  acc 0.604055 (0.597644)  loss 1.095196 (1.096512)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6804.0 MB
2025-07-05 04:37:10,426 - WARNING - Epoch [5/25] Step [241/250]  acc 0.645653 (0.598506)  loss 0.983846 (1.094327)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 6804.0 MB
Epoch 5 completed in 0:01:52.374310
2025-07-05 04:37:41,391 - WARNING - Epoch [6/25] Step [1/250]  acc 0.561706 (0.561706)  loss 1.195133 (1.195133)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6804.0 MB
2025-07-05 04:37:45,818 - WARNING - Epoch [6/25] Step [11/250]  acc 0.608388 (0.614869)  loss 1.041510 (1.058645)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6804.0 MB
2025-07-05 04:37:50,167 - WARNING - Epoch [6/25] Step [21/250]  acc 0.586820 (0.622018)  loss 1.103158 (1.039465)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6804.0 MB
2025-07-05 04:37:54,507 - WARNING - Epoch [6/25] Step [31/250]  acc 0.595173 (0.619291)  loss 1.127503 (1.047677)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6804.0 MB
2025-07-05 04:37:59,123 - WARNING - Epoch [6/25] Step [41/250]  acc 0.679266 (0.625899)  loss 0.922158 (1.034217)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6804.0 MB
2025-07-05 04:38:03,684 - WARNING - Epoch [6/25] Step [51/250]  acc 0.645075 (0.626724)  loss 0.997021 (1.031343)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6804.0 MB
2025-07-05 04:38:08,371 - WARNING - Epoch [6/25] Step [61/250]  acc 0.601259 (0.625198)  loss 1.095018 (1.033550)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6804.0 MB
2025-07-05 04:38:12,749 - WARNING - Epoch [6/25] Step [71/250]  acc 0.665016 (0.627905)  loss 0.958659 (1.027517)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6804.0 MB
2025-07-05 04:38:17,209 - WARNING - Epoch [6/25] Step [81/250]  acc 0.619857 (0.629534)  loss 1.021302 (1.023635)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6804.0 MB
2025-07-05 04:38:21,529 - WARNING - Epoch [6/25] Step [91/250]  acc 0.661601 (0.630104)  loss 0.954860 (1.022205)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6804.0 MB
2025-07-05 04:38:26,016 - WARNING - Epoch [6/25] Step [101/250]  acc 0.638591 (0.631623)  loss 1.006540 (1.018825)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6804.0 MB
2025-07-05 04:38:30,401 - WARNING - Epoch [6/25] Step [111/250]  acc 0.648438 (0.632075)  loss 0.983718 (1.017959)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6804.0 MB
2025-07-05 04:38:34,754 - WARNING - Epoch [6/25] Step [121/250]  acc 0.606540 (0.632184)  loss 1.068777 (1.017498)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6804.0 MB
2025-07-05 04:38:39,183 - WARNING - Epoch [6/25] Step [131/250]  acc 0.623218 (0.632035)  loss 1.016262 (1.017087)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 6804.0 MB
2025-07-05 04:38:43,598 - WARNING - Epoch [6/25] Step [141/250]  acc 0.621236 (0.631584)  loss 1.047512 (1.018197)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6806.0 MB
2025-07-05 04:38:48,104 - WARNING - Epoch [6/25] Step [151/250]  acc 0.634308 (0.631750)  loss 1.011960 (1.018241)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6806.0 MB
2025-07-05 04:38:52,656 - WARNING - Epoch [6/25] Step [161/250]  acc 0.641396 (0.631694)  loss 0.981842 (1.017906)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6806.0 MB
2025-07-05 04:38:57,195 - WARNING - Epoch [6/25] Step [171/250]  acc 0.598992 (0.631558)  loss 1.093836 (1.018146)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 6806.0 MB
2025-07-05 04:39:01,722 - WARNING - Epoch [6/25] Step [181/250]  acc 0.641553 (0.631115)  loss 0.973119 (1.018487)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6806.0 MB
2025-07-05 04:39:06,147 - WARNING - Epoch [6/25] Step [191/250]  acc 0.624265 (0.631458)  loss 1.039014 (1.017885)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6806.0 MB
2025-07-05 04:39:10,782 - WARNING - Epoch [6/25] Step [201/250]  acc 0.665422 (0.632025)  loss 0.939995 (1.016132)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6806.0 MB
2025-07-05 04:39:15,232 - WARNING - Epoch [6/25] Step [211/250]  acc 0.602740 (0.631379)  loss 1.070809 (1.016882)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6806.0 MB
2025-07-05 04:39:19,704 - WARNING - Epoch [6/25] Step [221/250]  acc 0.657600 (0.631908)  loss 0.955909 (1.015290)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6806.0 MB
2025-07-05 04:39:24,289 - WARNING - Epoch [6/25] Step [231/250]  acc 0.666106 (0.632787)  loss 0.942448 (1.013098)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6806.0 MB
2025-07-05 04:39:28,696 - WARNING - Epoch [6/25] Step [241/250]  acc 0.643799 (0.632458)  loss 0.996311 (1.013806)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6806.0 MB
Epoch 6 completed in 0:01:51.700643
2025-07-05 04:39:59,663 - WARNING - Epoch [7/25] Step [1/250]  acc 0.677938 (0.677938)  loss 0.904679 (0.904679)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6806.0 MB
2025-07-05 04:40:04,037 - WARNING - Epoch [7/25] Step [11/250]  acc 0.617834 (0.633362)  loss 1.044733 (1.013895)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6806.0 MB
2025-07-05 04:40:08,396 - WARNING - Epoch [7/25] Step [21/250]  acc 0.626905 (0.644923)  loss 1.013219 (0.986430)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6806.0 MB
2025-07-05 04:40:12,804 - WARNING - Epoch [7/25] Step [31/250]  acc 0.701062 (0.649001)  loss 0.834056 (0.974120)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6806.0 MB
2025-07-05 04:40:17,201 - WARNING - Epoch [7/25] Step [41/250]  acc 0.693727 (0.647628)  loss 0.872053 (0.976228)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6806.0 MB
2025-07-05 04:40:21,569 - WARNING - Epoch [7/25] Step [51/250]  acc 0.667737 (0.645637)  loss 0.941501 (0.980821)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6806.0 MB
2025-07-05 04:40:25,910 - WARNING - Epoch [7/25] Step [61/250]  acc 0.657306 (0.646808)  loss 0.984583 (0.978373)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6806.0 MB
2025-07-05 04:40:30,270 - WARNING - Epoch [7/25] Step [71/250]  acc 0.642781 (0.647375)  loss 1.014996 (0.976705)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6806.0 MB
2025-07-05 04:40:34,680 - WARNING - Epoch [7/25] Step [81/250]  acc 0.585991 (0.645836)  loss 1.096079 (0.978623)
GPU memory consumption  GPU Memory: Allocated: 52.8 MB, Reserved: 6806.0 MB
2025-07-05 04:40:39,271 - WARNING - Epoch [7/25] Step [91/250]  acc 0.675730 (0.645947)  loss 0.927673 (0.977525)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6806.0 MB
2025-07-05 04:40:43,899 - WARNING - Epoch [7/25] Step [101/250]  acc 0.635465 (0.645025)  loss 0.985435 (0.979083)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6806.0 MB
2025-07-05 04:40:48,260 - WARNING - Epoch [7/25] Step [111/250]  acc 0.626874 (0.646096)  loss 1.005673 (0.976592)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6806.0 MB
2025-07-05 04:40:52,640 - WARNING - Epoch [7/25] Step [121/250]  acc 0.627474 (0.644846)  loss 1.045514 (0.979789)
GPU memory consumption  GPU Memory: Allocated: 52.6 MB, Reserved: 6806.0 MB
2025-07-05 04:40:57,020 - WARNING - Epoch [7/25] Step [131/250]  acc 0.655816 (0.644428)  loss 0.953903 (0.980419)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6806.0 MB
2025-07-05 04:41:01,369 - WARNING - Epoch [7/25] Step [141/250]  acc 0.657288 (0.644709)  loss 0.957684 (0.979869)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 6806.0 MB
2025-07-05 04:41:05,772 - WARNING - Epoch [7/25] Step [151/250]  acc 0.674588 (0.645341)  loss 0.899790 (0.978761)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6806.0 MB
2025-07-05 04:41:10,222 - WARNING - Epoch [7/25] Step [161/250]  acc 0.601087 (0.645134)  loss 1.094794 (0.979235)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 6806.0 MB
2025-07-05 04:41:14,628 - WARNING - Epoch [7/25] Step [171/250]  acc 0.632391 (0.644627)  loss 1.024705 (0.980630)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6806.0 MB
2025-07-05 04:41:19,060 - WARNING - Epoch [7/25] Step [181/250]  acc 0.657173 (0.644441)  loss 0.931190 (0.981417)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6806.0 MB
2025-07-05 04:41:23,452 - WARNING - Epoch [7/25] Step [191/250]  acc 0.641926 (0.644748)  loss 0.995648 (0.980719)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6806.0 MB
2025-07-05 04:41:27,855 - WARNING - Epoch [7/25] Step [201/250]  acc 0.647619 (0.644854)  loss 0.971490 (0.980307)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6806.0 MB
2025-07-05 04:41:32,210 - WARNING - Epoch [7/25] Step [211/250]  acc 0.682234 (0.645330)  loss 0.884933 (0.979002)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6806.0 MB
2025-07-05 04:41:36,588 - WARNING - Epoch [7/25] Step [221/250]  acc 0.679245 (0.645956)  loss 0.898982 (0.977585)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6806.0 MB
2025-07-05 04:41:40,968 - WARNING - Epoch [7/25] Step [231/250]  acc 0.702606 (0.645746)  loss 0.853031 (0.977984)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6806.0 MB
2025-07-05 04:41:45,577 - WARNING - Epoch [7/25] Step [241/250]  acc 0.675375 (0.646036)  loss 0.902559 (0.976998)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6806.0 MB
Epoch 7 completed in 0:01:50.221424
2025-07-05 04:42:16,595 - WARNING - Epoch [8/25] Step [1/250]  acc 0.659195 (0.659195)  loss 0.930370 (0.930370)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6806.0 MB
2025-07-05 04:42:20,983 - WARNING - Epoch [8/25] Step [11/250]  acc 0.627137 (0.636942)  loss 1.004579 (0.987804)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6806.0 MB
2025-07-05 04:42:25,373 - WARNING - Epoch [8/25] Step [21/250]  acc 0.695243 (0.656729)  loss 0.840934 (0.944149)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6806.0 MB
2025-07-05 04:42:29,710 - WARNING - Epoch [8/25] Step [31/250]  acc 0.648780 (0.661838)  loss 0.982161 (0.935264)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6806.0 MB
2025-07-05 04:42:34,109 - WARNING - Epoch [8/25] Step [41/250]  acc 0.632727 (0.654536)  loss 0.985660 (0.953664)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6806.0 MB
2025-07-05 04:42:38,497 - WARNING - Epoch [8/25] Step [51/250]  acc 0.623628 (0.654835)  loss 1.032362 (0.953417)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6806.0 MB
2025-07-05 04:42:42,906 - WARNING - Epoch [8/25] Step [61/250]  acc 0.680068 (0.654250)  loss 0.907998 (0.956515)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6806.0 MB
2025-07-05 04:42:47,315 - WARNING - Epoch [8/25] Step [71/250]  acc 0.668592 (0.654863)  loss 0.915847 (0.954372)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 6806.0 MB
2025-07-05 04:42:51,741 - WARNING - Epoch [8/25] Step [81/250]  acc 0.710295 (0.655888)  loss 0.824392 (0.951953)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6806.0 MB
2025-07-05 04:42:56,164 - WARNING - Epoch [8/25] Step [91/250]  acc 0.600112 (0.654636)  loss 1.093290 (0.954666)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6806.0 MB
2025-07-05 04:43:00,557 - WARNING - Epoch [8/25] Step [101/250]  acc 0.668217 (0.655447)  loss 0.920952 (0.953012)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 6806.0 MB
2025-07-05 04:43:05,024 - WARNING - Epoch [8/25] Step [111/250]  acc 0.691053 (0.654916)  loss 0.857261 (0.954450)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6806.0 MB
2025-07-05 04:43:09,498 - WARNING - Epoch [8/25] Step [121/250]  acc 0.647026 (0.654701)  loss 0.983094 (0.955255)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6806.0 MB
2025-07-05 04:43:14,185 - WARNING - Epoch [8/25] Step [131/250]  acc 0.692503 (0.654507)  loss 0.883194 (0.955731)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 6806.0 MB
2025-07-05 04:43:18,694 - WARNING - Epoch [8/25] Step [141/250]  acc 0.613953 (0.653131)  loss 1.032134 (0.958814)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6806.0 MB
2025-07-05 04:43:23,365 - WARNING - Epoch [8/25] Step [151/250]  acc 0.672600 (0.652564)  loss 0.956003 (0.960620)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6806.0 MB
2025-07-05 04:43:27,836 - WARNING - Epoch [8/25] Step [161/250]  acc 0.623974 (0.652564)  loss 0.996367 (0.960709)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6806.0 MB
2025-07-05 04:43:32,211 - WARNING - Epoch [8/25] Step [171/250]  acc 0.646032 (0.653037)  loss 0.978815 (0.959602)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6806.0 MB
2025-07-05 04:43:36,607 - WARNING - Epoch [8/25] Step [181/250]  acc 0.680726 (0.653009)  loss 0.887295 (0.959399)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6806.0 MB
2025-07-05 04:43:41,001 - WARNING - Epoch [8/25] Step [191/250]  acc 0.671018 (0.653006)  loss 0.904370 (0.959515)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 6806.0 MB
2025-07-05 04:43:45,412 - WARNING - Epoch [8/25] Step [201/250]  acc 0.642641 (0.653633)  loss 0.968896 (0.958327)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6806.0 MB
2025-07-05 04:43:49,699 - WARNING - Epoch [8/25] Step [211/250]  acc 0.709877 (0.654687)  loss 0.820784 (0.955792)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6806.0 MB
2025-07-05 04:43:54,105 - WARNING - Epoch [8/25] Step [221/250]  acc 0.675926 (0.654686)  loss 0.907174 (0.955577)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6806.0 MB
2025-07-05 04:43:58,545 - WARNING - Epoch [8/25] Step [231/250]  acc 0.664603 (0.654851)  loss 0.917672 (0.955173)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6806.0 MB
2025-07-05 04:44:02,999 - WARNING - Epoch [8/25] Step [241/250]  acc 0.680336 (0.655298)  loss 0.917106 (0.954099)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6806.0 MB
Epoch 8 completed in 0:01:50.799213
2025-07-05 04:44:34,003 - WARNING - Epoch [9/25] Step [1/250]  acc 0.609647 (0.609647)  loss 1.039015 (1.039015)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6806.0 MB
2025-07-05 04:44:38,492 - WARNING - Epoch [9/25] Step [11/250]  acc 0.603995 (0.666039)  loss 1.056989 (0.924920)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6806.0 MB
2025-07-05 04:44:43,312 - WARNING - Epoch [9/25] Step [21/250]  acc 0.641096 (0.657392)  loss 0.986094 (0.948310)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6806.0 MB
2025-07-05 04:44:47,785 - WARNING - Epoch [9/25] Step [31/250]  acc 0.691326 (0.655473)  loss 0.844868 (0.947564)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6806.0 MB
2025-07-05 04:44:52,185 - WARNING - Epoch [9/25] Step [41/250]  acc 0.681509 (0.658571)  loss 0.894872 (0.940556)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6806.0 MB
2025-07-05 04:44:56,568 - WARNING - Epoch [9/25] Step [51/250]  acc 0.663317 (0.662110)  loss 0.932019 (0.932436)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6806.0 MB
2025-07-05 04:45:00,965 - WARNING - Epoch [9/25] Step [61/250]  acc 0.667330 (0.663947)  loss 0.899433 (0.928125)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6806.0 MB
2025-07-05 04:45:05,594 - WARNING - Epoch [9/25] Step [71/250]  acc 0.657267 (0.662662)  loss 0.935100 (0.933101)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6806.0 MB
2025-07-05 04:45:10,199 - WARNING - Epoch [9/25] Step [81/250]  acc 0.676064 (0.662754)  loss 0.888816 (0.931945)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6806.0 MB
2025-07-05 04:45:14,649 - WARNING - Epoch [9/25] Step [91/250]  acc 0.661720 (0.662509)  loss 0.921932 (0.932043)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 6806.0 MB
2025-07-05 04:45:19,011 - WARNING - Epoch [9/25] Step [101/250]  acc 0.692428 (0.664892)  loss 0.847302 (0.926090)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6806.0 MB
2025-07-05 04:45:23,408 - WARNING - Epoch [9/25] Step [111/250]  acc 0.692529 (0.664786)  loss 0.878635 (0.926721)
GPU memory consumption  GPU Memory: Allocated: 60.8 MB, Reserved: 6806.0 MB
2025-07-05 04:45:27,681 - WARNING - Epoch [9/25] Step [121/250]  acc 0.667619 (0.663717)  loss 0.930764 (0.929129)
GPU memory consumption  GPU Memory: Allocated: 52.9 MB, Reserved: 6806.0 MB
2025-07-05 04:45:32,055 - WARNING - Epoch [9/25] Step [131/250]  acc 0.571938 (0.661873)  loss 1.182617 (0.933203)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6806.0 MB
2025-07-05 04:45:36,429 - WARNING - Epoch [9/25] Step [141/250]  acc 0.675101 (0.661737)  loss 0.891718 (0.933776)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6806.0 MB
2025-07-05 04:45:40,889 - WARNING - Epoch [9/25] Step [151/250]  acc 0.662998 (0.662171)  loss 0.933266 (0.933374)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6806.0 MB
2025-07-05 04:45:45,285 - WARNING - Epoch [9/25] Step [161/250]  acc 0.675591 (0.662052)  loss 0.898760 (0.933766)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6806.0 MB
2025-07-05 04:45:49,876 - WARNING - Epoch [9/25] Step [171/250]  acc 0.739130 (0.662164)  loss 0.759266 (0.933225)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6806.0 MB
2025-07-05 04:45:54,290 - WARNING - Epoch [9/25] Step [181/250]  acc 0.647541 (0.661687)  loss 0.965462 (0.934438)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6806.0 MB
2025-07-05 04:45:58,729 - WARNING - Epoch [9/25] Step [191/250]  acc 0.647192 (0.661587)  loss 0.969722 (0.935049)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 6806.0 MB
2025-07-05 04:46:03,229 - WARNING - Epoch [9/25] Step [201/250]  acc 0.656489 (0.660300)  loss 0.929102 (0.938119)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6806.0 MB
2025-07-05 04:46:07,687 - WARNING - Epoch [9/25] Step [211/250]  acc 0.633422 (0.661001)  loss 0.977803 (0.936327)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6806.0 MB
2025-07-05 04:46:12,150 - WARNING - Epoch [9/25] Step [221/250]  acc 0.682335 (0.661175)  loss 0.888573 (0.936170)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6806.0 MB
2025-07-05 04:46:16,517 - WARNING - Epoch [9/25] Step [231/250]  acc 0.675132 (0.661883)  loss 0.909233 (0.934430)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6806.0 MB
2025-07-05 04:46:20,972 - WARNING - Epoch [9/25] Step [241/250]  acc 0.638677 (0.661277)  loss 0.996483 (0.935925)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6806.0 MB
Epoch 9 completed in 0:01:51.424022
2025-07-05 04:46:51,854 - WARNING - Epoch [10/25] Step [1/250]  acc 0.702278 (0.702278)  loss 0.832264 (0.832264)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6806.0 MB
2025-07-05 04:46:56,250 - WARNING - Epoch [10/25] Step [11/250]  acc 0.651066 (0.674282)  loss 0.950310 (0.902488)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6806.0 MB
2025-07-05 04:47:00,699 - WARNING - Epoch [10/25] Step [21/250]  acc 0.627854 (0.671594)  loss 1.008580 (0.908738)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 6806.0 MB
2025-07-05 04:47:05,135 - WARNING - Epoch [10/25] Step [31/250]  acc 0.678003 (0.670484)  loss 0.916589 (0.912058)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6806.0 MB
2025-07-05 04:47:09,538 - WARNING - Epoch [10/25] Step [41/250]  acc 0.650689 (0.665031)  loss 0.939989 (0.924355)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6806.0 MB
2025-07-05 04:47:13,955 - WARNING - Epoch [10/25] Step [51/250]  acc 0.692961 (0.666038)  loss 0.852350 (0.922602)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6806.0 MB
2025-07-05 04:47:18,602 - WARNING - Epoch [10/25] Step [61/250]  acc 0.655096 (0.667265)  loss 0.949377 (0.922354)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6806.0 MB
2025-07-05 04:47:23,184 - WARNING - Epoch [10/25] Step [71/250]  acc 0.726269 (0.668318)  loss 0.772992 (0.918389)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6806.0 MB
2025-07-05 04:47:27,693 - WARNING - Epoch [10/25] Step [81/250]  acc 0.707615 (0.671020)  loss 0.831111 (0.912110)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 6806.0 MB
2025-07-05 04:47:32,187 - WARNING - Epoch [10/25] Step [91/250]  acc 0.711356 (0.673156)  loss 0.827434 (0.907197)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6806.0 MB
2025-07-05 04:47:36,544 - WARNING - Epoch [10/25] Step [101/250]  acc 0.675483 (0.672320)  loss 0.888858 (0.909363)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6806.0 MB
2025-07-05 04:47:40,925 - WARNING - Epoch [10/25] Step [111/250]  acc 0.658248 (0.672574)  loss 0.942437 (0.908561)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6806.0 MB
2025-07-05 04:47:45,371 - WARNING - Epoch [10/25] Step [121/250]  acc 0.692547 (0.672457)  loss 0.823143 (0.908813)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6806.0 MB
2025-07-05 04:47:49,718 - WARNING - Epoch [10/25] Step [131/250]  acc 0.642606 (0.671485)  loss 0.986437 (0.911887)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6806.0 MB
2025-07-05 04:47:54,177 - WARNING - Epoch [10/25] Step [141/250]  acc 0.693735 (0.672339)  loss 0.821611 (0.909746)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 6806.0 MB
2025-07-05 04:47:58,638 - WARNING - Epoch [10/25] Step [151/250]  acc 0.641350 (0.671860)  loss 0.979351 (0.911068)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6806.0 MB
2025-07-05 04:48:03,163 - WARNING - Epoch [10/25] Step [161/250]  acc 0.685959 (0.671588)  loss 0.853529 (0.911075)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6806.0 MB
2025-07-05 04:48:07,660 - WARNING - Epoch [10/25] Step [171/250]  acc 0.686304 (0.671541)  loss 0.860744 (0.910667)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 6806.0 MB
2025-07-05 04:48:12,158 - WARNING - Epoch [10/25] Step [181/250]  acc 0.722481 (0.671592)  loss 0.805867 (0.910860)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6806.0 MB
2025-07-05 04:48:16,564 - WARNING - Epoch [10/25] Step [191/250]  acc 0.684924 (0.672379)  loss 0.894198 (0.909188)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6806.0 MB
2025-07-05 04:48:21,287 - WARNING - Epoch [10/25] Step [201/250]  acc 0.662632 (0.672312)  loss 0.932412 (0.908918)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6806.0 MB
2025-07-05 04:48:25,790 - WARNING - Epoch [10/25] Step [211/250]  acc 0.616849 (0.672174)  loss 1.069103 (0.909668)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 6806.0 MB
2025-07-05 04:48:30,228 - WARNING - Epoch [10/25] Step [221/250]  acc 0.710526 (0.671676)  loss 0.814026 (0.910925)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6806.0 MB
2025-07-05 04:48:34,667 - WARNING - Epoch [10/25] Step [231/250]  acc 0.678089 (0.671082)  loss 0.891179 (0.912680)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6806.0 MB
2025-07-05 04:48:39,064 - WARNING - Epoch [10/25] Step [241/250]  acc 0.638095 (0.670689)  loss 0.980257 (0.913458)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6806.0 MB
Epoch 10 completed in 0:01:51.810396
2025-07-05 04:49:10,890 - WARNING - Epoch [11/25] Step [1/250]  acc 0.648256 (0.648256)  loss 0.981089 (0.981089)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6806.0 MB
2025-07-05 04:49:15,312 - WARNING - Epoch [11/25] Step [11/250]  acc 0.673570 (0.664241)  loss 0.882289 (0.928794)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 6806.0 MB
2025-07-05 04:49:19,655 - WARNING - Epoch [11/25] Step [21/250]  acc 0.656034 (0.665945)  loss 0.931813 (0.923821)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6806.0 MB
2025-07-05 04:49:24,070 - WARNING - Epoch [11/25] Step [31/250]  acc 0.693176 (0.669673)  loss 0.859908 (0.910984)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6806.0 MB
2025-07-05 04:49:28,416 - WARNING - Epoch [11/25] Step [41/250]  acc 0.642588 (0.668205)  loss 0.961549 (0.911538)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6806.0 MB
2025-07-05 04:49:32,869 - WARNING - Epoch [11/25] Step [51/250]  acc 0.644397 (0.664206)  loss 0.980536 (0.924420)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6806.0 MB
2025-07-05 04:49:37,272 - WARNING - Epoch [11/25] Step [61/250]  acc 0.699507 (0.668147)  loss 0.808460 (0.915911)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6806.0 MB
2025-07-05 04:49:41,738 - WARNING - Epoch [11/25] Step [71/250]  acc 0.727891 (0.669193)  loss 0.780035 (0.914150)
GPU memory consumption  GPU Memory: Allocated: 62.0 MB, Reserved: 6806.0 MB
2025-07-05 04:49:46,135 - WARNING - Epoch [11/25] Step [81/250]  acc 0.644358 (0.667930)  loss 0.931659 (0.916637)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6806.0 MB
2025-07-05 04:49:50,471 - WARNING - Epoch [11/25] Step [91/250]  acc 0.684586 (0.669130)  loss 0.903663 (0.914950)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6806.0 MB
2025-07-05 04:49:55,240 - WARNING - Epoch [11/25] Step [101/250]  acc 0.665135 (0.668678)  loss 0.928969 (0.916366)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 6806.0 MB
2025-07-05 04:49:59,575 - WARNING - Epoch [11/25] Step [111/250]  acc 0.687928 (0.670975)  loss 0.883308 (0.910859)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6806.0 MB
2025-07-05 04:50:04,179 - WARNING - Epoch [11/25] Step [121/250]  acc 0.651624 (0.669894)  loss 0.938612 (0.913153)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 6806.0 MB
2025-07-05 04:50:08,658 - WARNING - Epoch [11/25] Step [131/250]  acc 0.665744 (0.670360)  loss 0.909451 (0.912495)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6806.0 MB
2025-07-05 04:50:13,236 - WARNING - Epoch [11/25] Step [141/250]  acc 0.700430 (0.670130)  loss 0.865662 (0.912843)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6806.0 MB
2025-07-05 04:50:17,837 - WARNING - Epoch [11/25] Step [151/250]  acc 0.675538 (0.670523)  loss 0.876852 (0.911119)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 6806.0 MB
2025-07-05 04:50:22,322 - WARNING - Epoch [11/25] Step [161/250]  acc 0.698789 (0.670510)  loss 0.870819 (0.911345)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6806.0 MB
2025-07-05 04:50:26,771 - WARNING - Epoch [11/25] Step [171/250]  acc 0.680652 (0.670142)  loss 0.894090 (0.911890)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6806.0 MB
2025-07-05 04:50:31,160 - WARNING - Epoch [11/25] Step [181/250]  acc 0.634546 (0.670168)  loss 1.001935 (0.912022)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6806.0 MB
2025-07-05 04:50:35,554 - WARNING - Epoch [11/25] Step [191/250]  acc 0.677708 (0.670225)  loss 0.890431 (0.912346)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 6806.0 MB
2025-07-05 04:50:39,878 - WARNING - Epoch [11/25] Step [201/250]  acc 0.601030 (0.670551)  loss 1.068452 (0.911069)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6806.0 MB
2025-07-05 04:50:44,316 - WARNING - Epoch [11/25] Step [211/250]  acc 0.652596 (0.669975)  loss 0.932152 (0.911813)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6806.0 MB
2025-07-05 04:50:48,646 - WARNING - Epoch [11/25] Step [221/250]  acc 0.654066 (0.669750)  loss 0.923655 (0.912109)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 6806.0 MB
2025-07-05 04:50:53,006 - WARNING - Epoch [11/25] Step [231/250]  acc 0.640890 (0.669698)  loss 0.994592 (0.912483)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6806.0 MB
2025-07-05 04:50:57,697 - WARNING - Epoch [11/25] Step [241/250]  acc 0.635389 (0.668459)  loss 0.989914 (0.915274)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6806.0 MB
Epoch 11 completed in 0:01:51.272085
2025-07-05 04:51:29,021 - WARNING - Epoch [12/25] Step [1/250]  acc 0.717949 (0.717949)  loss 0.811224 (0.811224)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6806.0 MB
2025-07-05 04:51:33,665 - WARNING - Epoch [12/25] Step [11/250]  acc 0.677065 (0.677464)  loss 0.946770 (0.898129)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 6806.0 MB
2025-07-05 04:51:38,177 - WARNING - Epoch [12/25] Step [21/250]  acc 0.638415 (0.676069)  loss 0.991075 (0.894983)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 6806.0 MB
2025-07-05 04:51:42,525 - WARNING - Epoch [12/25] Step [31/250]  acc 0.676441 (0.676476)  loss 0.914199 (0.894539)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6806.0 MB
2025-07-05 04:51:46,835 - WARNING - Epoch [12/25] Step [41/250]  acc 0.675998 (0.674858)  loss 0.915092 (0.899696)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6806.0 MB
2025-07-05 04:51:51,268 - WARNING - Epoch [12/25] Step [51/250]  acc 0.704409 (0.676967)  loss 0.850101 (0.895472)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6806.0 MB
2025-07-05 04:51:55,829 - WARNING - Epoch [12/25] Step [61/250]  acc 0.684812 (0.675406)  loss 0.859003 (0.898611)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6806.0 MB
2025-07-05 04:52:00,347 - WARNING - Epoch [12/25] Step [71/250]  acc 0.669363 (0.674779)  loss 0.928581 (0.899030)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6806.0 MB
2025-07-05 04:52:04,750 - WARNING - Epoch [12/25] Step [81/250]  acc 0.751806 (0.676531)  loss 0.720953 (0.895330)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6806.0 MB
2025-07-05 04:52:09,154 - WARNING - Epoch [12/25] Step [91/250]  acc 0.680518 (0.674958)  loss 0.884538 (0.899005)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6806.0 MB
2025-07-05 04:52:13,538 - WARNING - Epoch [12/25] Step [101/250]  acc 0.662939 (0.674990)  loss 0.935534 (0.899645)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6806.0 MB
2025-07-05 04:52:17,922 - WARNING - Epoch [12/25] Step [111/250]  acc 0.668645 (0.675565)  loss 0.895597 (0.897550)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6806.0 MB
2025-07-05 04:52:22,301 - WARNING - Epoch [12/25] Step [121/250]  acc 0.714359 (0.675841)  loss 0.794487 (0.896805)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6806.0 MB
2025-07-05 04:52:26,953 - WARNING - Epoch [12/25] Step [131/250]  acc 0.694142 (0.674665)  loss 0.898475 (0.900568)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6806.0 MB
2025-07-05 04:52:31,317 - WARNING - Epoch [12/25] Step [141/250]  acc 0.671271 (0.674742)  loss 0.885967 (0.900452)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6806.0 MB
2025-07-05 04:52:35,775 - WARNING - Epoch [12/25] Step [151/250]  acc 0.695767 (0.674537)  loss 0.862623 (0.900971)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6806.0 MB
2025-07-05 04:52:40,190 - WARNING - Epoch [12/25] Step [161/250]  acc 0.676956 (0.675914)  loss 0.884784 (0.897487)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6806.0 MB
2025-07-05 04:52:44,571 - WARNING - Epoch [12/25] Step [171/250]  acc 0.637829 (0.676133)  loss 0.968018 (0.897634)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6806.0 MB
2025-07-05 04:52:49,028 - WARNING - Epoch [12/25] Step [181/250]  acc 0.673378 (0.675151)  loss 0.890531 (0.900231)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6806.0 MB
2025-07-05 04:52:53,476 - WARNING - Epoch [12/25] Step [191/250]  acc 0.740993 (0.674819)  loss 0.736328 (0.900949)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 6806.0 MB
2025-07-05 04:52:57,919 - WARNING - Epoch [12/25] Step [201/250]  acc 0.632664 (0.675109)  loss 1.016487 (0.899785)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6806.0 MB
2025-07-05 04:53:02,411 - WARNING - Epoch [12/25] Step [211/250]  acc 0.710168 (0.675652)  loss 0.795851 (0.898344)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6806.0 MB
2025-07-05 04:53:06,914 - WARNING - Epoch [12/25] Step [221/250]  acc 0.677262 (0.676507)  loss 0.879030 (0.896027)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6806.0 MB
2025-07-05 04:53:11,328 - WARNING - Epoch [12/25] Step [231/250]  acc 0.685759 (0.675929)  loss 0.886806 (0.897185)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6806.0 MB
2025-07-05 04:53:15,755 - WARNING - Epoch [12/25] Step [241/250]  acc 0.610614 (0.675186)  loss 1.072824 (0.899325)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6806.0 MB
Epoch 12 completed in 0:01:51.219713
2025-07-05 04:53:46,262 - WARNING - Epoch [13/25] Step [1/250]  acc 0.678969 (0.678969)  loss 0.883278 (0.883278)
GPU memory consumption  GPU Memory: Allocated: 59.4 MB, Reserved: 6806.0 MB
2025-07-05 04:53:50,620 - WARNING - Epoch [13/25] Step [11/250]  acc 0.673309 (0.680634)  loss 0.891599 (0.886086)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6806.0 MB
2025-07-05 04:53:55,109 - WARNING - Epoch [13/25] Step [21/250]  acc 0.696835 (0.681115)  loss 0.854042 (0.883043)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6806.0 MB
2025-07-05 04:53:59,813 - WARNING - Epoch [13/25] Step [31/250]  acc 0.667205 (0.682032)  loss 0.886017 (0.884379)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6806.0 MB
2025-07-05 04:54:04,296 - WARNING - Epoch [13/25] Step [41/250]  acc 0.692653 (0.683349)  loss 0.875714 (0.880842)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6806.0 MB
2025-07-05 04:54:08,741 - WARNING - Epoch [13/25] Step [51/250]  acc 0.609428 (0.677430)  loss 1.037110 (0.894935)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6806.0 MB
2025-07-05 04:54:13,284 - WARNING - Epoch [13/25] Step [61/250]  acc 0.650660 (0.679220)  loss 0.963883 (0.891312)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6806.0 MB
2025-07-05 04:54:18,003 - WARNING - Epoch [13/25] Step [71/250]  acc 0.667760 (0.678928)  loss 0.876695 (0.890641)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6806.0 MB
2025-07-05 04:54:22,617 - WARNING - Epoch [13/25] Step [81/250]  acc 0.689080 (0.677599)  loss 0.888042 (0.894857)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 6806.0 MB
2025-07-05 04:54:27,182 - WARNING - Epoch [13/25] Step [91/250]  acc 0.651708 (0.676962)  loss 0.954140 (0.897239)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6806.0 MB
2025-07-05 04:54:31,655 - WARNING - Epoch [13/25] Step [101/250]  acc 0.702870 (0.675646)  loss 0.832657 (0.899781)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6806.0 MB
2025-07-05 04:54:36,047 - WARNING - Epoch [13/25] Step [111/250]  acc 0.670958 (0.675346)  loss 0.881570 (0.900664)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6806.0 MB
2025-07-05 04:54:40,601 - WARNING - Epoch [13/25] Step [121/250]  acc 0.646966 (0.676423)  loss 0.950813 (0.898434)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6806.0 MB
2025-07-05 04:54:45,150 - WARNING - Epoch [13/25] Step [131/250]  acc 0.632004 (0.676727)  loss 0.988799 (0.897251)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6806.0 MB
2025-07-05 04:54:49,802 - WARNING - Epoch [13/25] Step [141/250]  acc 0.637131 (0.677117)  loss 0.994975 (0.896210)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6806.0 MB
2025-07-05 04:54:54,534 - WARNING - Epoch [13/25] Step [151/250]  acc 0.655896 (0.677319)  loss 0.985799 (0.895110)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 6806.0 MB
2025-07-05 04:54:59,177 - WARNING - Epoch [13/25] Step [161/250]  acc 0.673983 (0.677441)  loss 0.901206 (0.894518)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6806.0 MB
2025-07-05 04:55:04,106 - WARNING - Epoch [13/25] Step [171/250]  acc 0.666667 (0.677624)  loss 0.905744 (0.894166)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6806.0 MB
2025-07-05 04:55:08,518 - WARNING - Epoch [13/25] Step [181/250]  acc 0.673192 (0.677509)  loss 0.904505 (0.893795)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6806.0 MB
2025-07-05 04:55:12,998 - WARNING - Epoch [13/25] Step [191/250]  acc 0.727945 (0.677484)  loss 0.784270 (0.893871)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6806.0 MB
2025-07-05 04:55:17,463 - WARNING - Epoch [13/25] Step [201/250]  acc 0.651249 (0.677541)  loss 0.926123 (0.893471)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6806.0 MB
2025-07-05 04:55:21,868 - WARNING - Epoch [13/25] Step [211/250]  acc 0.660685 (0.677669)  loss 0.924443 (0.893085)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6806.0 MB
2025-07-05 04:55:26,268 - WARNING - Epoch [13/25] Step [221/250]  acc 0.724705 (0.678127)  loss 0.781309 (0.892297)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6806.0 MB
2025-07-05 04:55:30,540 - WARNING - Epoch [13/25] Step [231/250]  acc 0.657506 (0.677943)  loss 1.002792 (0.893140)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 6806.0 MB
2025-07-05 04:55:34,987 - WARNING - Epoch [13/25] Step [241/250]  acc 0.679426 (0.677934)  loss 0.848577 (0.893005)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6806.0 MB
Epoch 13 completed in 0:01:53.242243
2025-07-05 04:56:06,151 - WARNING - Epoch [14/25] Step [1/250]  acc 0.669704 (0.669704)  loss 0.873569 (0.873569)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6806.0 MB
2025-07-05 04:56:10,574 - WARNING - Epoch [14/25] Step [11/250]  acc 0.650475 (0.673930)  loss 0.950489 (0.901346)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6806.0 MB
2025-07-05 04:56:14,884 - WARNING - Epoch [14/25] Step [21/250]  acc 0.693333 (0.677192)  loss 0.830723 (0.893890)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6806.0 MB
2025-07-05 04:56:19,339 - WARNING - Epoch [14/25] Step [31/250]  acc 0.676155 (0.681823)  loss 0.914038 (0.884276)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6806.0 MB
2025-07-05 04:56:23,830 - WARNING - Epoch [14/25] Step [41/250]  acc 0.700309 (0.679871)  loss 0.806315 (0.890647)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6806.0 MB
2025-07-05 04:56:28,236 - WARNING - Epoch [14/25] Step [51/250]  acc 0.689402 (0.681684)  loss 0.864504 (0.885115)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6806.0 MB
2025-07-05 04:56:33,005 - WARNING - Epoch [14/25] Step [61/250]  acc 0.672489 (0.681797)  loss 0.911445 (0.885137)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6806.0 MB
2025-07-05 04:56:37,391 - WARNING - Epoch [14/25] Step [71/250]  acc 0.676104 (0.684065)  loss 0.901245 (0.879089)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6806.0 MB
2025-07-05 04:56:41,707 - WARNING - Epoch [14/25] Step [81/250]  acc 0.643360 (0.685376)  loss 0.979247 (0.875634)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6806.0 MB
2025-07-05 04:56:46,198 - WARNING - Epoch [14/25] Step [91/250]  acc 0.720637 (0.687247)  loss 0.800422 (0.870836)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6806.0 MB
2025-07-05 04:56:50,648 - WARNING - Epoch [14/25] Step [101/250]  acc 0.624519 (0.685845)  loss 0.993801 (0.874034)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6806.0 MB
2025-07-05 04:56:55,111 - WARNING - Epoch [14/25] Step [111/250]  acc 0.602925 (0.683488)  loss 1.089087 (0.878634)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6806.0 MB
2025-07-05 04:56:59,695 - WARNING - Epoch [14/25] Step [121/250]  acc 0.675255 (0.681107)  loss 0.900383 (0.884736)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 6806.0 MB
2025-07-05 04:57:04,242 - WARNING - Epoch [14/25] Step [131/250]  acc 0.703911 (0.681388)  loss 0.836654 (0.883412)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6806.0 MB
2025-07-05 04:57:08,623 - WARNING - Epoch [14/25] Step [141/250]  acc 0.714286 (0.681033)  loss 0.801250 (0.884541)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6806.0 MB
2025-07-05 04:57:12,965 - WARNING - Epoch [14/25] Step [151/250]  acc 0.713603 (0.681114)  loss 0.797089 (0.883661)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6806.0 MB
2025-07-05 04:57:17,285 - WARNING - Epoch [14/25] Step [161/250]  acc 0.666836 (0.680195)  loss 0.919566 (0.886117)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6806.0 MB
2025-07-05 04:57:21,788 - WARNING - Epoch [14/25] Step [171/250]  acc 0.712823 (0.680783)  loss 0.811465 (0.884550)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6806.0 MB
2025-07-05 04:57:26,115 - WARNING - Epoch [14/25] Step [181/250]  acc 0.684461 (0.681349)  loss 0.865494 (0.883081)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6810.0 MB
2025-07-05 04:57:30,431 - WARNING - Epoch [14/25] Step [191/250]  acc 0.700496 (0.681459)  loss 0.808057 (0.882154)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6810.0 MB
2025-07-05 04:57:34,808 - WARNING - Epoch [14/25] Step [201/250]  acc 0.702442 (0.680976)  loss 0.867197 (0.883275)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 6810.0 MB
2025-07-05 04:57:39,426 - WARNING - Epoch [14/25] Step [211/250]  acc 0.610130 (0.680920)  loss 1.048300 (0.883697)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 6810.0 MB
2025-07-05 04:57:43,898 - WARNING - Epoch [14/25] Step [221/250]  acc 0.718919 (0.680765)  loss 0.801324 (0.884165)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6810.0 MB
2025-07-05 04:57:48,324 - WARNING - Epoch [14/25] Step [231/250]  acc 0.680129 (0.680564)  loss 0.897691 (0.884557)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6810.0 MB
2025-07-05 04:57:52,677 - WARNING - Epoch [14/25] Step [241/250]  acc 0.703426 (0.680554)  loss 0.853609 (0.884670)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6810.0 MB
Epoch 14 completed in 0:01:50.842959
2025-07-05 04:58:23,739 - WARNING - Epoch [15/25] Step [1/250]  acc 0.683983 (0.683983)  loss 0.919099 (0.919099)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6810.0 MB
2025-07-05 04:58:28,201 - WARNING - Epoch [15/25] Step [11/250]  acc 0.719124 (0.694910)  loss 0.795607 (0.849374)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 6810.0 MB
2025-07-05 04:58:32,594 - WARNING - Epoch [15/25] Step [21/250]  acc 0.673289 (0.688504)  loss 0.896131 (0.864355)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6810.0 MB
2025-07-05 04:58:37,023 - WARNING - Epoch [15/25] Step [31/250]  acc 0.699794 (0.683446)  loss 0.828504 (0.877738)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6810.0 MB
2025-07-05 04:58:41,463 - WARNING - Epoch [15/25] Step [41/250]  acc 0.679651 (0.682393)  loss 0.870467 (0.879696)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6810.0 MB
2025-07-05 04:58:45,917 - WARNING - Epoch [15/25] Step [51/250]  acc 0.629032 (0.682342)  loss 1.004439 (0.879194)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6810.0 MB
2025-07-05 04:58:50,326 - WARNING - Epoch [15/25] Step [61/250]  acc 0.675028 (0.683570)  loss 0.899374 (0.875645)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6810.0 MB
2025-07-05 04:58:54,665 - WARNING - Epoch [15/25] Step [71/250]  acc 0.681794 (0.683157)  loss 0.884970 (0.876953)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6810.0 MB
2025-07-05 04:58:59,067 - WARNING - Epoch [15/25] Step [81/250]  acc 0.601162 (0.680890)  loss 1.080935 (0.882992)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6810.0 MB
2025-07-05 04:59:03,523 - WARNING - Epoch [15/25] Step [91/250]  acc 0.733990 (0.681410)  loss 0.745158 (0.882044)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6810.0 MB
2025-07-05 04:59:08,110 - WARNING - Epoch [15/25] Step [101/250]  acc 0.720769 (0.681222)  loss 0.802125 (0.881984)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6810.0 MB
2025-07-05 04:59:12,497 - WARNING - Epoch [15/25] Step [111/250]  acc 0.760476 (0.681911)  loss 0.724020 (0.880724)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6810.0 MB
2025-07-05 04:59:16,889 - WARNING - Epoch [15/25] Step [121/250]  acc 0.665591 (0.682022)  loss 0.927442 (0.882113)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 6810.0 MB
2025-07-05 04:59:21,270 - WARNING - Epoch [15/25] Step [131/250]  acc 0.704720 (0.681746)  loss 0.808378 (0.881828)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6810.0 MB
2025-07-05 04:59:25,601 - WARNING - Epoch [15/25] Step [141/250]  acc 0.679871 (0.681389)  loss 0.860756 (0.881685)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6810.0 MB
2025-07-05 04:59:29,966 - WARNING - Epoch [15/25] Step [151/250]  acc 0.591415 (0.681595)  loss 1.138072 (0.881921)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6810.0 MB
2025-07-05 04:59:34,331 - WARNING - Epoch [15/25] Step [161/250]  acc 0.675916 (0.681348)  loss 0.888794 (0.882147)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 6810.0 MB
2025-07-05 04:59:38,732 - WARNING - Epoch [15/25] Step [171/250]  acc 0.711177 (0.681595)  loss 0.806215 (0.881506)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 6810.0 MB
2025-07-05 04:59:43,224 - WARNING - Epoch [15/25] Step [181/250]  acc 0.656782 (0.681539)  loss 0.913047 (0.881127)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6810.0 MB
2025-07-05 04:59:47,766 - WARNING - Epoch [15/25] Step [191/250]  acc 0.666118 (0.680507)  loss 0.914263 (0.883502)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6810.0 MB
2025-07-05 04:59:52,238 - WARNING - Epoch [15/25] Step [201/250]  acc 0.675799 (0.681662)  loss 0.924488 (0.880900)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6810.0 MB
2025-07-05 04:59:56,629 - WARNING - Epoch [15/25] Step [211/250]  acc 0.668508 (0.681800)  loss 0.969151 (0.880928)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6810.0 MB
2025-07-05 05:00:01,030 - WARNING - Epoch [15/25] Step [221/250]  acc 0.712632 (0.682254)  loss 0.799880 (0.879794)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6810.0 MB
2025-07-05 05:00:05,598 - WARNING - Epoch [15/25] Step [231/250]  acc 0.638660 (0.682084)  loss 0.996524 (0.880347)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6810.0 MB
2025-07-05 05:00:10,439 - WARNING - Epoch [15/25] Step [241/250]  acc 0.695415 (0.682007)  loss 0.833696 (0.880133)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6810.0 MB
Epoch 15 completed in 0:01:51.074046
2025-07-05 05:00:41,128 - WARNING - Epoch [16/25] Step [1/250]  acc 0.660989 (0.660989)  loss 0.931177 (0.931177)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6810.0 MB
2025-07-05 05:00:45,581 - WARNING - Epoch [16/25] Step [11/250]  acc 0.645912 (0.676355)  loss 0.973704 (0.886157)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6810.0 MB
2025-07-05 05:00:49,990 - WARNING - Epoch [16/25] Step [21/250]  acc 0.690089 (0.678935)  loss 0.863275 (0.888095)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6810.0 MB
2025-07-05 05:00:54,342 - WARNING - Epoch [16/25] Step [31/250]  acc 0.666300 (0.679938)  loss 0.913827 (0.881629)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6810.0 MB
2025-07-05 05:00:58,687 - WARNING - Epoch [16/25] Step [41/250]  acc 0.712480 (0.683372)  loss 0.830271 (0.873909)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6810.0 MB
2025-07-05 05:01:03,332 - WARNING - Epoch [16/25] Step [51/250]  acc 0.676282 (0.687660)  loss 0.905417 (0.865135)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6810.0 MB
2025-07-05 05:01:07,991 - WARNING - Epoch [16/25] Step [61/250]  acc 0.728556 (0.687539)  loss 0.746074 (0.865562)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6810.0 MB
2025-07-05 05:01:12,658 - WARNING - Epoch [16/25] Step [71/250]  acc 0.734801 (0.687739)  loss 0.728494 (0.864264)
GPU memory consumption  GPU Memory: Allocated: 62.0 MB, Reserved: 6810.0 MB
2025-07-05 05:01:17,081 - WARNING - Epoch [16/25] Step [81/250]  acc 0.696259 (0.686793)  loss 0.823819 (0.867222)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 6810.0 MB
2025-07-05 05:01:21,518 - WARNING - Epoch [16/25] Step [91/250]  acc 0.672576 (0.686644)  loss 0.898313 (0.866785)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6810.0 MB
2025-07-05 05:01:25,991 - WARNING - Epoch [16/25] Step [101/250]  acc 0.665069 (0.686559)  loss 0.940029 (0.867498)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6810.0 MB
2025-07-05 05:01:30,378 - WARNING - Epoch [16/25] Step [111/250]  acc 0.691484 (0.687403)  loss 0.853983 (0.865908)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6810.0 MB
2025-07-05 05:01:34,780 - WARNING - Epoch [16/25] Step [121/250]  acc 0.659425 (0.686490)  loss 0.898724 (0.867938)
GPU memory consumption  GPU Memory: Allocated: 52.2 MB, Reserved: 6810.0 MB
2025-07-05 05:01:39,149 - WARNING - Epoch [16/25] Step [131/250]  acc 0.642229 (0.686644)  loss 1.001887 (0.868666)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6810.0 MB
2025-07-05 05:01:43,856 - WARNING - Epoch [16/25] Step [141/250]  acc 0.640951 (0.685233)  loss 1.037246 (0.873046)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 6810.0 MB
2025-07-05 05:01:48,252 - WARNING - Epoch [16/25] Step [151/250]  acc 0.692186 (0.685766)  loss 0.841841 (0.871558)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6810.0 MB
2025-07-05 05:01:52,614 - WARNING - Epoch [16/25] Step [161/250]  acc 0.689810 (0.685612)  loss 0.873446 (0.872030)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6810.0 MB
2025-07-05 05:01:56,961 - WARNING - Epoch [16/25] Step [171/250]  acc 0.726847 (0.685407)  loss 0.785480 (0.872692)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6810.0 MB
2025-07-05 05:02:01,366 - WARNING - Epoch [16/25] Step [181/250]  acc 0.721893 (0.685459)  loss 0.797983 (0.872841)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6810.0 MB
2025-07-05 05:02:05,797 - WARNING - Epoch [16/25] Step [191/250]  acc 0.715477 (0.686043)  loss 0.790799 (0.871314)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6810.0 MB
2025-07-05 05:02:10,213 - WARNING - Epoch [16/25] Step [201/250]  acc 0.659622 (0.685976)  loss 0.917330 (0.871450)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6810.0 MB
2025-07-05 05:02:14,585 - WARNING - Epoch [16/25] Step [211/250]  acc 0.719238 (0.686109)  loss 0.789550 (0.871371)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 6810.0 MB
2025-07-05 05:02:18,963 - WARNING - Epoch [16/25] Step [221/250]  acc 0.618671 (0.684971)  loss 0.984230 (0.874096)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6810.0 MB
2025-07-05 05:02:23,515 - WARNING - Epoch [16/25] Step [231/250]  acc 0.725791 (0.685316)  loss 0.767920 (0.872985)
GPU memory consumption  GPU Memory: Allocated: 59.8 MB, Reserved: 6810.0 MB
2025-07-05 05:02:28,166 - WARNING - Epoch [16/25] Step [241/250]  acc 0.630666 (0.685110)  loss 1.031706 (0.873328)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6810.0 MB
Epoch 16 completed in 0:01:51.561007
2025-07-05 05:02:59,197 - WARNING - Epoch [17/25] Step [1/250]  acc 0.682081 (0.682081)  loss 0.896909 (0.896909)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 6810.0 MB
2025-07-05 05:03:03,598 - WARNING - Epoch [17/25] Step [11/250]  acc 0.706682 (0.694709)  loss 0.812671 (0.852744)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6810.0 MB
2025-07-05 05:03:07,912 - WARNING - Epoch [17/25] Step [21/250]  acc 0.684874 (0.690326)  loss 0.904988 (0.864665)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6810.0 MB
2025-07-05 05:03:12,572 - WARNING - Epoch [17/25] Step [31/250]  acc 0.703549 (0.695275)  loss 0.823351 (0.848893)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6810.0 MB
2025-07-05 05:03:16,882 - WARNING - Epoch [17/25] Step [41/250]  acc 0.692230 (0.691880)  loss 0.833233 (0.856758)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6810.0 MB
2025-07-05 05:03:21,304 - WARNING - Epoch [17/25] Step [51/250]  acc 0.662248 (0.689430)  loss 0.937536 (0.862421)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6810.0 MB
2025-07-05 05:03:25,800 - WARNING - Epoch [17/25] Step [61/250]  acc 0.688947 (0.690405)  loss 0.863615 (0.860303)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6810.0 MB
2025-07-05 05:03:30,277 - WARNING - Epoch [17/25] Step [71/250]  acc 0.641807 (0.691866)  loss 0.987625 (0.858089)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6810.0 MB
2025-07-05 05:03:34,640 - WARNING - Epoch [17/25] Step [81/250]  acc 0.685195 (0.690340)  loss 0.842869 (0.861136)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 6810.0 MB
2025-07-05 05:03:39,042 - WARNING - Epoch [17/25] Step [91/250]  acc 0.689672 (0.689775)  loss 0.861026 (0.863074)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 6810.0 MB
2025-07-05 05:03:43,569 - WARNING - Epoch [17/25] Step [101/250]  acc 0.633592 (0.688672)  loss 1.008148 (0.866491)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 6810.0 MB
2025-07-05 05:03:48,180 - WARNING - Epoch [17/25] Step [111/250]  acc 0.715034 (0.689203)  loss 0.809989 (0.866060)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6810.0 MB
2025-07-05 05:03:52,703 - WARNING - Epoch [17/25] Step [121/250]  acc 0.656399 (0.689797)  loss 0.955164 (0.863917)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 6810.0 MB
2025-07-05 05:03:57,133 - WARNING - Epoch [17/25] Step [131/250]  acc 0.662637 (0.689593)  loss 0.942691 (0.863489)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6810.0 MB
2025-07-05 05:04:01,553 - WARNING - Epoch [17/25] Step [141/250]  acc 0.722689 (0.689191)  loss 0.787201 (0.864189)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 6810.0 MB
2025-07-05 05:04:06,058 - WARNING - Epoch [17/25] Step [151/250]  acc 0.733130 (0.689458)  loss 0.751631 (0.863435)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6810.0 MB
2025-07-05 05:04:10,512 - WARNING - Epoch [17/25] Step [161/250]  acc 0.687987 (0.689397)  loss 0.846975 (0.863211)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 6810.0 MB
2025-07-05 05:04:15,096 - WARNING - Epoch [17/25] Step [171/250]  acc 0.677796 (0.687909)  loss 0.878489 (0.866519)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6810.0 MB
2025-07-05 05:04:19,459 - WARNING - Epoch [17/25] Step [181/250]  acc 0.642930 (0.687109)  loss 0.938670 (0.868014)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6810.0 MB
2025-07-05 05:04:23,949 - WARNING - Epoch [17/25] Step [191/250]  acc 0.678474 (0.686601)  loss 0.915453 (0.869619)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6810.0 MB
2025-07-05 05:04:28,362 - WARNING - Epoch [17/25] Step [201/250]  acc 0.662095 (0.686343)  loss 0.954681 (0.870728)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6810.0 MB
2025-07-05 05:04:32,804 - WARNING - Epoch [17/25] Step [211/250]  acc 0.710181 (0.685076)  loss 0.804970 (0.873825)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6810.0 MB
2025-07-05 05:04:37,199 - WARNING - Epoch [17/25] Step [221/250]  acc 0.643127 (0.684927)  loss 0.958089 (0.874166)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6810.0 MB
2025-07-05 05:04:41,654 - WARNING - Epoch [17/25] Step [231/250]  acc 0.699397 (0.685592)  loss 0.855561 (0.872633)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6810.0 MB
2025-07-05 05:04:46,119 - WARNING - Epoch [17/25] Step [241/250]  acc 0.732230 (0.685107)  loss 0.757543 (0.873756)
GPU memory consumption  GPU Memory: Allocated: 59.4 MB, Reserved: 6810.0 MB
Epoch 17 completed in 0:01:51.367731
2025-07-05 05:05:17,555 - WARNING - Epoch [18/25] Step [1/250]  acc 0.684067 (0.684067)  loss 0.842209 (0.842209)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6810.0 MB
2025-07-05 05:05:21,977 - WARNING - Epoch [18/25] Step [11/250]  acc 0.714789 (0.706147)  loss 0.787562 (0.820602)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6810.0 MB
2025-07-05 05:05:26,315 - WARNING - Epoch [18/25] Step [21/250]  acc 0.662381 (0.709621)  loss 0.909985 (0.807094)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 6810.0 MB
2025-07-05 05:05:30,668 - WARNING - Epoch [18/25] Step [31/250]  acc 0.633621 (0.700117)  loss 1.005311 (0.833250)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6810.0 MB
2025-07-05 05:05:35,020 - WARNING - Epoch [18/25] Step [41/250]  acc 0.680795 (0.697318)  loss 0.847497 (0.838692)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6810.0 MB
2025-07-05 05:05:39,316 - WARNING - Epoch [18/25] Step [51/250]  acc 0.640616 (0.696125)  loss 0.961895 (0.842855)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 6810.0 MB
2025-07-05 05:05:43,747 - WARNING - Epoch [18/25] Step [61/250]  acc 0.712532 (0.693153)  loss 0.797053 (0.849343)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6810.0 MB
2025-07-05 05:05:48,297 - WARNING - Epoch [18/25] Step [71/250]  acc 0.734190 (0.693685)  loss 0.741487 (0.848210)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 6810.0 MB
2025-07-05 05:05:52,685 - WARNING - Epoch [18/25] Step [81/250]  acc 0.681623 (0.692913)  loss 0.874979 (0.849623)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6810.0 MB
2025-07-05 05:05:57,054 - WARNING - Epoch [18/25] Step [91/250]  acc 0.739130 (0.691001)  loss 0.740594 (0.854187)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 6810.0 MB
2025-07-05 05:06:01,505 - WARNING - Epoch [18/25] Step [101/250]  acc 0.667625 (0.690444)  loss 0.910762 (0.856672)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6810.0 MB
2025-07-05 05:06:05,844 - WARNING - Epoch [18/25] Step [111/250]  acc 0.707979 (0.688968)  loss 0.825990 (0.860570)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6810.0 MB
2025-07-05 05:06:10,139 - WARNING - Epoch [18/25] Step [121/250]  acc 0.668583 (0.687750)  loss 0.869246 (0.864479)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6810.0 MB
2025-07-05 05:06:14,535 - WARNING - Epoch [18/25] Step [131/250]  acc 0.680874 (0.686821)  loss 0.866771 (0.866697)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6810.0 MB
2025-07-05 05:06:18,880 - WARNING - Epoch [18/25] Step [141/250]  acc 0.675969 (0.686111)  loss 0.902125 (0.868096)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6810.0 MB
2025-07-05 05:06:23,385 - WARNING - Epoch [18/25] Step [151/250]  acc 0.607057 (0.685461)  loss 1.095723 (0.870642)
GPU memory consumption  GPU Memory: Allocated: 52.8 MB, Reserved: 6810.0 MB
2025-07-05 05:06:27,868 - WARNING - Epoch [18/25] Step [161/250]  acc 0.676974 (0.685628)  loss 0.906567 (0.869938)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6810.0 MB
2025-07-05 05:06:32,258 - WARNING - Epoch [18/25] Step [171/250]  acc 0.650338 (0.685665)  loss 0.948013 (0.870036)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6810.0 MB
2025-07-05 05:06:36,774 - WARNING - Epoch [18/25] Step [181/250]  acc 0.714734 (0.685811)  loss 0.800147 (0.870209)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6810.0 MB
2025-07-05 05:06:41,247 - WARNING - Epoch [18/25] Step [191/250]  acc 0.657809 (0.685013)  loss 0.968522 (0.872550)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6810.0 MB
2025-07-05 05:06:45,672 - WARNING - Epoch [18/25] Step [201/250]  acc 0.717415 (0.686225)  loss 0.800715 (0.869395)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6810.0 MB
2025-07-05 05:06:50,176 - WARNING - Epoch [18/25] Step [211/250]  acc 0.687465 (0.685778)  loss 0.884964 (0.870784)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6810.0 MB
2025-07-05 05:06:54,522 - WARNING - Epoch [18/25] Step [221/250]  acc 0.654196 (0.685264)  loss 0.937755 (0.871873)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6810.0 MB
2025-07-05 05:06:58,809 - WARNING - Epoch [18/25] Step [231/250]  acc 0.660874 (0.685279)  loss 0.914559 (0.871556)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6810.0 MB
2025-07-05 05:07:03,163 - WARNING - Epoch [18/25] Step [241/250]  acc 0.688786 (0.685398)  loss 0.871204 (0.871266)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6810.0 MB
Epoch 18 completed in 0:01:50.060200
2025-07-05 05:07:33,865 - WARNING - Epoch [19/25] Step [1/250]  acc 0.659341 (0.659341)  loss 0.923509 (0.923509)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6810.0 MB
2025-07-05 05:07:38,282 - WARNING - Epoch [19/25] Step [11/250]  acc 0.645434 (0.672997)  loss 0.970429 (0.902809)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 6810.0 MB
2025-07-05 05:07:42,617 - WARNING - Epoch [19/25] Step [21/250]  acc 0.720497 (0.678350)  loss 0.792181 (0.897026)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6810.0 MB
2025-07-05 05:07:47,382 - WARNING - Epoch [19/25] Step [31/250]  acc 0.674481 (0.681700)  loss 0.907822 (0.887425)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6810.0 MB
2025-07-05 05:07:52,133 - WARNING - Epoch [19/25] Step [41/250]  acc 0.676301 (0.683930)  loss 0.868901 (0.878888)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 6810.0 MB
2025-07-05 05:07:56,704 - WARNING - Epoch [19/25] Step [51/250]  acc 0.691346 (0.686806)  loss 0.829022 (0.871803)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6810.0 MB
2025-07-05 05:08:01,091 - WARNING - Epoch [19/25] Step [61/250]  acc 0.639478 (0.688075)  loss 1.011328 (0.869258)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6810.0 MB
2025-07-05 05:08:05,456 - WARNING - Epoch [19/25] Step [71/250]  acc 0.619589 (0.687636)  loss 1.046823 (0.870344)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6810.0 MB
2025-07-05 05:08:09,894 - WARNING - Epoch [19/25] Step [81/250]  acc 0.746177 (0.690414)  loss 0.725851 (0.862515)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6810.0 MB
2025-07-05 05:08:14,356 - WARNING - Epoch [19/25] Step [91/250]  acc 0.661884 (0.690006)  loss 0.915236 (0.863845)
GPU memory consumption  GPU Memory: Allocated: 60.7 MB, Reserved: 6810.0 MB
2025-07-05 05:08:18,827 - WARNING - Epoch [19/25] Step [101/250]  acc 0.690816 (0.688842)  loss 0.846352 (0.865536)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6810.0 MB
2025-07-05 05:08:23,460 - WARNING - Epoch [19/25] Step [111/250]  acc 0.643167 (0.687698)  loss 0.985974 (0.867844)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6810.0 MB
2025-07-05 05:08:27,902 - WARNING - Epoch [19/25] Step [121/250]  acc 0.679480 (0.687108)  loss 0.831850 (0.868571)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6810.0 MB
2025-07-05 05:08:32,300 - WARNING - Epoch [19/25] Step [131/250]  acc 0.696823 (0.686654)  loss 0.856024 (0.869815)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6810.0 MB
2025-07-05 05:08:36,751 - WARNING - Epoch [19/25] Step [141/250]  acc 0.638427 (0.685927)  loss 1.003022 (0.871452)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 6810.0 MB
2025-07-05 05:08:41,175 - WARNING - Epoch [19/25] Step [151/250]  acc 0.684099 (0.685238)  loss 0.867042 (0.872550)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6810.0 MB
2025-07-05 05:08:45,636 - WARNING - Epoch [19/25] Step [161/250]  acc 0.676375 (0.685708)  loss 0.883347 (0.871024)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 6810.0 MB
2025-07-05 05:08:49,931 - WARNING - Epoch [19/25] Step [171/250]  acc 0.742857 (0.686943)  loss 0.740927 (0.868254)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6810.0 MB
2025-07-05 05:08:54,232 - WARNING - Epoch [19/25] Step [181/250]  acc 0.706069 (0.687336)  loss 0.823553 (0.867104)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6810.0 MB
2025-07-05 05:08:58,627 - WARNING - Epoch [19/25] Step [191/250]  acc 0.735143 (0.687446)  loss 0.740393 (0.866892)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6810.0 MB
2025-07-05 05:09:03,069 - WARNING - Epoch [19/25] Step [201/250]  acc 0.708511 (0.687341)  loss 0.843430 (0.867829)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6810.0 MB
2025-07-05 05:09:07,536 - WARNING - Epoch [19/25] Step [211/250]  acc 0.687500 (0.687753)  loss 0.871896 (0.866630)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6810.0 MB
2025-07-05 05:09:11,884 - WARNING - Epoch [19/25] Step [221/250]  acc 0.692308 (0.687667)  loss 0.841232 (0.866944)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6810.0 MB
2025-07-05 05:09:16,349 - WARNING - Epoch [19/25] Step [231/250]  acc 0.691771 (0.687670)  loss 0.856124 (0.866827)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 6810.0 MB
2025-07-05 05:09:20,676 - WARNING - Epoch [19/25] Step [241/250]  acc 0.676181 (0.688508)  loss 0.905451 (0.864668)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6810.0 MB
Epoch 19 completed in 0:01:51.360835
2025-07-05 05:09:51,503 - WARNING - Epoch [20/25] Step [1/250]  acc 0.679173 (0.679173)  loss 0.850977 (0.850977)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6810.0 MB
2025-07-05 05:09:55,846 - WARNING - Epoch [20/25] Step [11/250]  acc 0.750000 (0.705913)  loss 0.715456 (0.824086)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6810.0 MB
2025-07-05 05:10:00,335 - WARNING - Epoch [20/25] Step [21/250]  acc 0.638453 (0.685812)  loss 1.014765 (0.873422)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6810.0 MB
2025-07-05 05:10:04,826 - WARNING - Epoch [20/25] Step [31/250]  acc 0.685685 (0.692463)  loss 0.876462 (0.856748)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 6810.0 MB
2025-07-05 05:10:09,268 - WARNING - Epoch [20/25] Step [41/250]  acc 0.644432 (0.689156)  loss 0.959397 (0.867205)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6810.0 MB
2025-07-05 05:10:13,682 - WARNING - Epoch [20/25] Step [51/250]  acc 0.687884 (0.691149)  loss 0.890299 (0.862094)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6810.0 MB
2025-07-05 05:10:18,129 - WARNING - Epoch [20/25] Step [61/250]  acc 0.642254 (0.688686)  loss 0.940799 (0.866225)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 6810.0 MB
2025-07-05 05:10:22,559 - WARNING - Epoch [20/25] Step [71/250]  acc 0.700265 (0.688923)  loss 0.814548 (0.864219)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6810.0 MB
2025-07-05 05:10:27,075 - WARNING - Epoch [20/25] Step [81/250]  acc 0.683878 (0.690625)  loss 0.866248 (0.859758)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6810.0 MB
2025-07-05 05:10:31,772 - WARNING - Epoch [20/25] Step [91/250]  acc 0.673701 (0.692313)  loss 0.897909 (0.855004)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6810.0 MB
2025-07-05 05:10:36,473 - WARNING - Epoch [20/25] Step [101/250]  acc 0.599891 (0.690600)  loss 1.081774 (0.859515)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6810.0 MB
2025-07-05 05:10:41,000 - WARNING - Epoch [20/25] Step [111/250]  acc 0.721868 (0.690150)  loss 0.796406 (0.861081)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6810.0 MB
2025-07-05 05:10:45,342 - WARNING - Epoch [20/25] Step [121/250]  acc 0.670330 (0.690315)  loss 0.924402 (0.861417)
GPU memory consumption  GPU Memory: Allocated: 52.5 MB, Reserved: 6810.0 MB
2025-07-05 05:10:49,751 - WARNING - Epoch [20/25] Step [131/250]  acc 0.680480 (0.690672)  loss 0.872625 (0.859443)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 6810.0 MB
2025-07-05 05:10:54,639 - WARNING - Epoch [20/25] Step [141/250]  acc 0.664989 (0.690032)  loss 0.896268 (0.859928)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 6810.0 MB
2025-07-05 05:10:59,274 - WARNING - Epoch [20/25] Step [151/250]  acc 0.694232 (0.689394)  loss 0.846146 (0.860396)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 6810.0 MB
2025-07-05 05:11:03,817 - WARNING - Epoch [20/25] Step [161/250]  acc 0.677646 (0.689959)  loss 0.906434 (0.858780)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6810.0 MB
2025-07-05 05:11:08,509 - WARNING - Epoch [20/25] Step [171/250]  acc 0.704059 (0.689222)  loss 0.830518 (0.860351)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6810.0 MB
2025-07-05 05:11:13,010 - WARNING - Epoch [20/25] Step [181/250]  acc 0.659649 (0.688801)  loss 0.925575 (0.861651)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6810.0 MB
2025-07-05 05:11:17,771 - WARNING - Epoch [20/25] Step [191/250]  acc 0.719424 (0.689317)  loss 0.788269 (0.861019)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6810.0 MB
2025-07-05 05:11:22,429 - WARNING - Epoch [20/25] Step [201/250]  acc 0.638333 (0.689845)  loss 0.992179 (0.859722)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 6810.0 MB
2025-07-05 05:11:27,301 - WARNING - Epoch [20/25] Step [211/250]  acc 0.692865 (0.689285)  loss 0.859083 (0.861493)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6810.0 MB
2025-07-05 05:11:31,981 - WARNING - Epoch [20/25] Step [221/250]  acc 0.751664 (0.690189)  loss 0.701703 (0.859404)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6810.0 MB
2025-07-05 05:11:36,622 - WARNING - Epoch [20/25] Step [231/250]  acc 0.727273 (0.690357)  loss 0.749774 (0.859011)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6810.0 MB
2025-07-05 05:11:41,156 - WARNING - Epoch [20/25] Step [241/250]  acc 0.669435 (0.691227)  loss 0.904180 (0.856935)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6810.0 MB
Epoch 20 completed in 0:01:54.164644
2025-07-05 05:12:12,253 - WARNING - Epoch [21/25] Step [1/250]  acc 0.663392 (0.663392)  loss 0.938211 (0.938211)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 6810.0 MB
2025-07-05 05:12:16,774 - WARNING - Epoch [21/25] Step [11/250]  acc 0.667730 (0.690311)  loss 0.851435 (0.855741)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6810.0 MB
2025-07-05 05:12:21,025 - WARNING - Epoch [21/25] Step [21/250]  acc 0.696300 (0.690847)  loss 0.832732 (0.856386)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6810.0 MB
2025-07-05 05:12:25,692 - WARNING - Epoch [21/25] Step [31/250]  acc 0.686427 (0.692999)  loss 0.863524 (0.847888)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6810.0 MB
2025-07-05 05:12:30,117 - WARNING - Epoch [21/25] Step [41/250]  acc 0.676884 (0.689829)  loss 0.896551 (0.855257)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6810.0 MB
2025-07-05 05:12:34,541 - WARNING - Epoch [21/25] Step [51/250]  acc 0.625573 (0.686872)  loss 1.016299 (0.864540)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6810.0 MB
2025-07-05 05:12:38,914 - WARNING - Epoch [21/25] Step [61/250]  acc 0.692142 (0.688442)  loss 0.873322 (0.863947)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6810.0 MB
2025-07-05 05:12:43,339 - WARNING - Epoch [21/25] Step [71/250]  acc 0.749505 (0.690513)  loss 0.696265 (0.858063)
GPU memory consumption  GPU Memory: Allocated: 60.5 MB, Reserved: 6810.0 MB
2025-07-05 05:12:47,774 - WARNING - Epoch [21/25] Step [81/250]  acc 0.685270 (0.690447)  loss 0.864549 (0.858138)
GPU memory consumption  GPU Memory: Allocated: 52.4 MB, Reserved: 6810.0 MB
2025-07-05 05:12:52,217 - WARNING - Epoch [21/25] Step [91/250]  acc 0.659386 (0.689794)  loss 0.970820 (0.860936)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6810.0 MB
2025-07-05 05:12:56,518 - WARNING - Epoch [21/25] Step [101/250]  acc 0.679070 (0.689785)  loss 0.882892 (0.860115)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6810.0 MB
2025-07-05 05:13:00,890 - WARNING - Epoch [21/25] Step [111/250]  acc 0.695897 (0.689489)  loss 0.852260 (0.860898)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 6810.0 MB
2025-07-05 05:13:05,342 - WARNING - Epoch [21/25] Step [121/250]  acc 0.714813 (0.688452)  loss 0.802992 (0.863225)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 6810.0 MB
2025-07-05 05:13:09,804 - WARNING - Epoch [21/25] Step [131/250]  acc 0.679215 (0.689111)  loss 0.872492 (0.862474)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6810.0 MB
2025-07-05 05:13:14,336 - WARNING - Epoch [21/25] Step [141/250]  acc 0.699406 (0.690201)  loss 0.844051 (0.859875)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6810.0 MB
2025-07-05 05:13:18,671 - WARNING - Epoch [21/25] Step [151/250]  acc 0.704981 (0.689113)  loss 0.802007 (0.862444)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6810.0 MB
2025-07-05 05:13:23,503 - WARNING - Epoch [21/25] Step [161/250]  acc 0.719437 (0.689905)  loss 0.804475 (0.860890)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 6810.0 MB
2025-07-05 05:13:28,342 - WARNING - Epoch [21/25] Step [171/250]  acc 0.727368 (0.690355)  loss 0.766122 (0.859777)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6810.0 MB
2025-07-05 05:13:33,185 - WARNING - Epoch [21/25] Step [181/250]  acc 0.712230 (0.690373)  loss 0.821518 (0.859550)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6810.0 MB
2025-07-05 05:13:37,421 - WARNING - Epoch [21/25] Step [191/250]  acc 0.691345 (0.690710)  loss 0.853748 (0.858705)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6810.0 MB
2025-07-05 05:13:41,652 - WARNING - Epoch [21/25] Step [201/250]  acc 0.716441 (0.690615)  loss 0.761378 (0.858325)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6810.0 MB
2025-07-05 05:13:45,987 - WARNING - Epoch [21/25] Step [211/250]  acc 0.693069 (0.690978)  loss 0.850660 (0.857627)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 6810.0 MB
2025-07-05 05:13:50,210 - WARNING - Epoch [21/25] Step [221/250]  acc 0.682994 (0.690173)  loss 0.861241 (0.859863)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 6810.0 MB
2025-07-05 05:13:54,550 - WARNING - Epoch [21/25] Step [231/250]  acc 0.684129 (0.689749)  loss 0.894784 (0.860514)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 6810.0 MB
2025-07-05 05:13:58,939 - WARNING - Epoch [21/25] Step [241/250]  acc 0.727000 (0.690161)  loss 0.778974 (0.859267)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 6810.0 MB
Epoch 21 completed in 0:01:51.070457
2025-07-05 05:14:28,706 - WARNING - Epoch [22/25] Step [1/250]  acc 0.696223 (0.696223)  loss 0.825435 (0.825435)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 6810.0 MB
2025-07-05 05:14:33,022 - WARNING - Epoch [22/25] Step [11/250]  acc 0.687400 (0.694047)  loss 0.879678 (0.851916)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6810.0 MB
2025-07-05 05:14:37,464 - WARNING - Epoch [22/25] Step [21/250]  acc 0.659232 (0.685513)  loss 0.912277 (0.868505)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6810.0 MB
2025-07-05 05:14:41,776 - WARNING - Epoch [22/25] Step [31/250]  acc 0.647895 (0.687654)  loss 0.928282 (0.862360)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6810.0 MB
2025-07-05 05:14:46,190 - WARNING - Epoch [22/25] Step [41/250]  acc 0.721070 (0.690991)  loss 0.789624 (0.854416)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6810.0 MB
2025-07-05 05:14:50,587 - WARNING - Epoch [22/25] Step [51/250]  acc 0.733728 (0.690654)  loss 0.724724 (0.855818)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6810.0 MB
2025-07-05 05:14:54,922 - WARNING - Epoch [22/25] Step [61/250]  acc 0.708555 (0.692191)  loss 0.818641 (0.851762)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6810.0 MB
2025-07-05 05:14:59,590 - WARNING - Epoch [22/25] Step [71/250]  acc 0.750240 (0.694719)  loss 0.743273 (0.845877)
GPU memory consumption  GPU Memory: Allocated: 62.0 MB, Reserved: 6810.0 MB
2025-07-05 05:15:03,992 - WARNING - Epoch [22/25] Step [81/250]  acc 0.681247 (0.693997)  loss 0.874647 (0.847099)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 6810.0 MB
2025-07-05 05:15:08,260 - WARNING - Epoch [22/25] Step [91/250]  acc 0.674176 (0.693519)  loss 0.851873 (0.847869)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6810.0 MB
2025-07-05 05:15:12,626 - WARNING - Epoch [22/25] Step [101/250]  acc 0.670595 (0.693412)  loss 0.918773 (0.848722)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6810.0 MB
2025-07-05 05:15:16,933 - WARNING - Epoch [22/25] Step [111/250]  acc 0.706246 (0.692755)  loss 0.816367 (0.849990)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6810.0 MB
2025-07-05 05:15:21,232 - WARNING - Epoch [22/25] Step [121/250]  acc 0.660101 (0.691793)  loss 0.934137 (0.852001)
GPU memory consumption  GPU Memory: Allocated: 53.0 MB, Reserved: 6810.0 MB
2025-07-05 05:15:25,490 - WARNING - Epoch [22/25] Step [131/250]  acc 0.686529 (0.693085)  loss 0.845417 (0.848613)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6810.0 MB
2025-07-05 05:15:29,711 - WARNING - Epoch [22/25] Step [141/250]  acc 0.701084 (0.694133)  loss 0.839332 (0.846347)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6810.0 MB
2025-07-05 05:15:34,065 - WARNING - Epoch [22/25] Step [151/250]  acc 0.666150 (0.694294)  loss 0.952134 (0.846414)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 6810.0 MB
2025-07-05 05:15:38,346 - WARNING - Epoch [22/25] Step [161/250]  acc 0.664808 (0.693556)  loss 0.908723 (0.847984)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 6810.0 MB
2025-07-05 05:15:42,761 - WARNING - Epoch [22/25] Step [171/250]  acc 0.677453 (0.692504)  loss 0.899759 (0.850886)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6810.0 MB
2025-07-05 05:15:47,224 - WARNING - Epoch [22/25] Step [181/250]  acc 0.681394 (0.692319)  loss 0.860933 (0.850945)
GPU memory consumption  GPU Memory: Allocated: 58.5 MB, Reserved: 6810.0 MB
2025-07-05 05:15:51,674 - WARNING - Epoch [22/25] Step [191/250]  acc 0.677189 (0.692325)  loss 0.899233 (0.850950)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6810.0 MB
2025-07-05 05:15:56,146 - WARNING - Epoch [22/25] Step [201/250]  acc 0.706596 (0.692069)  loss 0.814840 (0.851380)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6810.0 MB
2025-07-05 05:16:00,934 - WARNING - Epoch [22/25] Step [211/250]  acc 0.695804 (0.692238)  loss 0.837376 (0.850786)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 6810.0 MB
2025-07-05 05:16:05,378 - WARNING - Epoch [22/25] Step [221/250]  acc 0.712078 (0.691825)  loss 0.785845 (0.851652)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 6810.0 MB
2025-07-05 05:16:09,826 - WARNING - Epoch [22/25] Step [231/250]  acc 0.702311 (0.692193)  loss 0.800297 (0.850503)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6810.0 MB
2025-07-05 05:16:14,281 - WARNING - Epoch [22/25] Step [241/250]  acc 0.681067 (0.692864)  loss 0.899982 (0.849262)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 6810.0 MB
Epoch 22 completed in 0:01:49.778301
2025-07-05 05:16:44,097 - WARNING - Epoch [23/25] Step [1/250]  acc 0.687822 (0.687822)  loss 0.873124 (0.873124)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6810.0 MB
2025-07-05 05:16:48,494 - WARNING - Epoch [23/25] Step [11/250]  acc 0.722455 (0.687740)  loss 0.804464 (0.865544)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 6810.0 MB
2025-07-05 05:16:52,893 - WARNING - Epoch [23/25] Step [21/250]  acc 0.678490 (0.689792)  loss 0.877105 (0.861888)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 6810.0 MB
2025-07-05 05:16:57,310 - WARNING - Epoch [23/25] Step [31/250]  acc 0.699588 (0.688744)  loss 0.851748 (0.866850)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6810.0 MB
2025-07-05 05:17:01,695 - WARNING - Epoch [23/25] Step [41/250]  acc 0.719243 (0.687468)  loss 0.796717 (0.867821)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6810.0 MB
2025-07-05 05:17:06,127 - WARNING - Epoch [23/25] Step [51/250]  acc 0.705171 (0.688349)  loss 0.841836 (0.865606)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6810.0 MB
2025-07-05 05:17:10,519 - WARNING - Epoch [23/25] Step [61/250]  acc 0.680579 (0.692365)  loss 0.918133 (0.857459)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6810.0 MB
2025-07-05 05:17:14,958 - WARNING - Epoch [23/25] Step [71/250]  acc 0.750832 (0.695368)  loss 0.710267 (0.849656)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6810.0 MB
2025-07-05 05:17:19,353 - WARNING - Epoch [23/25] Step [81/250]  acc 0.734319 (0.695852)  loss 0.746689 (0.847252)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6810.0 MB
2025-07-05 05:17:23,763 - WARNING - Epoch [23/25] Step [91/250]  acc 0.758430 (0.697590)  loss 0.675529 (0.841902)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6810.0 MB
2025-07-05 05:17:28,174 - WARNING - Epoch [23/25] Step [101/250]  acc 0.662609 (0.695791)  loss 0.894258 (0.845967)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6810.0 MB
2025-07-05 05:17:32,810 - WARNING - Epoch [23/25] Step [111/250]  acc 0.712866 (0.697901)  loss 0.801374 (0.840548)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6810.0 MB
2025-07-05 05:17:37,215 - WARNING - Epoch [23/25] Step [121/250]  acc 0.605826 (0.696121)  loss 1.038893 (0.844034)
GPU memory consumption  GPU Memory: Allocated: 51.9 MB, Reserved: 6810.0 MB
2025-07-05 05:17:41,548 - WARNING - Epoch [23/25] Step [131/250]  acc 0.680178 (0.694468)  loss 0.869962 (0.847659)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6810.0 MB
2025-07-05 05:17:45,869 - WARNING - Epoch [23/25] Step [141/250]  acc 0.698645 (0.694397)  loss 0.853125 (0.848209)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6810.0 MB
2025-07-05 05:17:50,108 - WARNING - Epoch [23/25] Step [151/250]  acc 0.678778 (0.694681)  loss 0.873505 (0.847727)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6810.0 MB
2025-07-05 05:17:54,335 - WARNING - Epoch [23/25] Step [161/250]  acc 0.706745 (0.695375)  loss 0.802259 (0.845743)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 6810.0 MB
2025-07-05 05:17:58,770 - WARNING - Epoch [23/25] Step [171/250]  acc 0.715455 (0.695724)  loss 0.797817 (0.845443)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 6810.0 MB
2025-07-05 05:18:03,182 - WARNING - Epoch [23/25] Step [181/250]  acc 0.701020 (0.696233)  loss 0.859510 (0.844374)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 6810.0 MB
2025-07-05 05:18:07,623 - WARNING - Epoch [23/25] Step [191/250]  acc 0.722904 (0.695565)  loss 0.741516 (0.845835)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6810.0 MB
2025-07-05 05:18:12,088 - WARNING - Epoch [23/25] Step [201/250]  acc 0.715155 (0.695177)  loss 0.781773 (0.846883)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6810.0 MB
2025-07-05 05:18:16,540 - WARNING - Epoch [23/25] Step [211/250]  acc 0.736422 (0.695055)  loss 0.743910 (0.846983)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 6810.0 MB
2025-07-05 05:18:20,891 - WARNING - Epoch [23/25] Step [221/250]  acc 0.712050 (0.694328)  loss 0.801176 (0.848968)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 6810.0 MB
2025-07-05 05:18:25,300 - WARNING - Epoch [23/25] Step [231/250]  acc 0.705468 (0.694108)  loss 0.814839 (0.848970)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6810.0 MB
2025-07-05 05:18:29,605 - WARNING - Epoch [23/25] Step [241/250]  acc 0.636421 (0.694238)  loss 1.003363 (0.848473)
GPU memory consumption  GPU Memory: Allocated: 53.0 MB, Reserved: 6810.0 MB
Epoch 23 completed in 0:01:49.962575
2025-07-05 05:18:59,301 - WARNING - Epoch [24/25] Step [1/250]  acc 0.722252 (0.722252)  loss 0.746131 (0.746131)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 6810.0 MB
2025-07-05 05:19:03,633 - WARNING - Epoch [24/25] Step [11/250]  acc 0.700337 (0.691116)  loss 0.826383 (0.849102)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6810.0 MB
2025-07-05 05:19:08,081 - WARNING - Epoch [24/25] Step [21/250]  acc 0.683565 (0.694712)  loss 0.878329 (0.842375)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6810.0 MB
2025-07-05 05:19:12,542 - WARNING - Epoch [24/25] Step [31/250]  acc 0.755189 (0.696446)  loss 0.687705 (0.839783)
GPU memory consumption  GPU Memory: Allocated: 59.6 MB, Reserved: 6810.0 MB
2025-07-05 05:19:16,859 - WARNING - Epoch [24/25] Step [41/250]  acc 0.645161 (0.692730)  loss 0.979003 (0.847715)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 6810.0 MB
2025-07-05 05:19:21,213 - WARNING - Epoch [24/25] Step [51/250]  acc 0.683196 (0.694038)  loss 0.893277 (0.847859)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 6810.0 MB
2025-07-05 05:19:25,609 - WARNING - Epoch [24/25] Step [61/250]  acc 0.726436 (0.690359)  loss 0.754014 (0.856385)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6810.0 MB
2025-07-05 05:19:30,007 - WARNING - Epoch [24/25] Step [71/250]  acc 0.692146 (0.687427)  loss 0.835497 (0.863404)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 6810.0 MB
2025-07-05 05:19:34,435 - WARNING - Epoch [24/25] Step [81/250]  acc 0.678043 (0.687940)  loss 0.853702 (0.862148)
GPU memory consumption  GPU Memory: Allocated: 52.9 MB, Reserved: 6810.0 MB
2025-07-05 05:19:38,811 - WARNING - Epoch [24/25] Step [91/250]  acc 0.735662 (0.689635)  loss 0.729230 (0.857309)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6810.0 MB
2025-07-05 05:19:43,052 - WARNING - Epoch [24/25] Step [101/250]  acc 0.740759 (0.690449)  loss 0.728398 (0.855796)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 6810.0 MB
2025-07-05 05:19:47,377 - WARNING - Epoch [24/25] Step [111/250]  acc 0.690711 (0.689793)  loss 0.813315 (0.856388)
GPU memory consumption  GPU Memory: Allocated: 59.5 MB, Reserved: 6810.0 MB
2025-07-05 05:19:51,565 - WARNING - Epoch [24/25] Step [121/250]  acc 0.769509 (0.691901)  loss 0.676867 (0.851435)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6810.0 MB
2025-07-05 05:19:55,871 - WARNING - Epoch [24/25] Step [131/250]  acc 0.721526 (0.692332)  loss 0.766337 (0.850794)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6810.0 MB
2025-07-05 05:20:00,544 - WARNING - Epoch [24/25] Step [141/250]  acc 0.677765 (0.692270)  loss 0.871987 (0.851132)
GPU memory consumption  GPU Memory: Allocated: 52.3 MB, Reserved: 6810.0 MB
2025-07-05 05:20:05,015 - WARNING - Epoch [24/25] Step [151/250]  acc 0.706860 (0.691776)  loss 0.844344 (0.852253)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6810.0 MB
2025-07-05 05:20:09,385 - WARNING - Epoch [24/25] Step [161/250]  acc 0.699946 (0.691858)  loss 0.839749 (0.852222)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 6810.0 MB
2025-07-05 05:20:13,793 - WARNING - Epoch [24/25] Step [171/250]  acc 0.673055 (0.693150)  loss 0.883618 (0.849361)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 6810.0 MB
2025-07-05 05:20:18,247 - WARNING - Epoch [24/25] Step [181/250]  acc 0.653269 (0.693024)  loss 0.911796 (0.849507)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6810.0 MB
2025-07-05 05:20:22,602 - WARNING - Epoch [24/25] Step [191/250]  acc 0.673567 (0.693577)  loss 0.875697 (0.847844)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6810.0 MB
2025-07-05 05:20:27,022 - WARNING - Epoch [24/25] Step [201/250]  acc 0.653403 (0.693705)  loss 0.987396 (0.848088)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 6810.0 MB
2025-07-05 05:20:31,407 - WARNING - Epoch [24/25] Step [211/250]  acc 0.707823 (0.693811)  loss 0.811022 (0.847709)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 6810.0 MB
2025-07-05 05:20:35,814 - WARNING - Epoch [24/25] Step [221/250]  acc 0.692013 (0.693721)  loss 0.892794 (0.848209)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 6810.0 MB
2025-07-05 05:20:40,161 - WARNING - Epoch [24/25] Step [231/250]  acc 0.671374 (0.694478)  loss 0.882495 (0.846677)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6810.0 MB
2025-07-05 05:20:44,456 - WARNING - Epoch [24/25] Step [241/250]  acc 0.750248 (0.695345)  loss 0.720177 (0.844756)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 6810.0 MB
Epoch 24 completed in 0:01:49.504146
2025-07-05 05:21:14,943 - WARNING - Epoch [25/25] Step [1/250]  acc 0.735390 (0.735390)  loss 0.738902 (0.738902)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 6810.0 MB
2025-07-05 05:21:19,285 - WARNING - Epoch [25/25] Step [11/250]  acc 0.711207 (0.709823)  loss 0.805565 (0.809032)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 6810.0 MB
2025-07-05 05:21:23,752 - WARNING - Epoch [25/25] Step [21/250]  acc 0.683882 (0.705371)  loss 0.890352 (0.813470)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 6810.0 MB
2025-07-05 05:21:28,221 - WARNING - Epoch [25/25] Step [31/250]  acc 0.729760 (0.709979)  loss 0.752730 (0.803753)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 6810.0 MB
2025-07-05 05:21:32,979 - WARNING - Epoch [25/25] Step [41/250]  acc 0.737534 (0.709211)  loss 0.766957 (0.807118)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 6810.0 MB
2025-07-05 05:21:37,434 - WARNING - Epoch [25/25] Step [51/250]  acc 0.707109 (0.709127)  loss 0.795511 (0.805330)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 6810.0 MB
2025-07-05 05:21:42,071 - WARNING - Epoch [25/25] Step [61/250]  acc 0.666466 (0.709743)  loss 0.919230 (0.804430)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 6810.0 MB
2025-07-05 05:21:46,905 - WARNING - Epoch [25/25] Step [71/250]  acc 0.704072 (0.708117)  loss 0.838971 (0.808854)
GPU memory consumption  GPU Memory: Allocated: 60.2 MB, Reserved: 6810.0 MB
2025-07-05 05:21:51,434 - WARNING - Epoch [25/25] Step [81/250]  acc 0.703285 (0.707362)  loss 0.828960 (0.811111)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 6810.0 MB
2025-07-05 05:21:55,541 - WARNING - Epoch [25/25] Step [91/250]  acc 0.701876 (0.706988)  loss 0.803955 (0.811574)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 6810.0 MB
2025-07-05 05:21:59,727 - WARNING - Epoch [25/25] Step [101/250]  acc 0.749618 (0.707469)  loss 0.710626 (0.810553)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 6810.0 MB
2025-07-05 05:22:04,205 - WARNING - Epoch [25/25] Step [111/250]  acc 0.701079 (0.708911)  loss 0.818291 (0.806650)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 6810.0 MB
2025-07-05 05:22:08,638 - WARNING - Epoch [25/25] Step [121/250]  acc 0.683843 (0.708353)  loss 0.909154 (0.808492)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 6810.0 MB
2025-07-05 05:22:13,056 - WARNING - Epoch [25/25] Step [131/250]  acc 0.665509 (0.708293)  loss 0.912650 (0.809489)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 6810.0 MB
2025-07-05 05:22:17,341 - WARNING - Epoch [25/25] Step [141/250]  acc 0.696269 (0.708118)  loss 0.824438 (0.809286)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 6810.0 MB
2025-07-05 05:22:21,660 - WARNING - Epoch [25/25] Step [151/250]  acc 0.656088 (0.707986)  loss 0.920756 (0.809734)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 6810.0 MB
2025-07-05 05:22:26,098 - WARNING - Epoch [25/25] Step [161/250]  acc 0.742432 (0.708449)  loss 0.737633 (0.808660)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 6810.0 MB
2025-07-05 05:22:30,501 - WARNING - Epoch [25/25] Step [171/250]  acc 0.732184 (0.708353)  loss 0.756159 (0.809450)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 6810.0 MB
2025-07-05 05:22:35,213 - WARNING - Epoch [25/25] Step [181/250]  acc 0.699591 (0.707730)  loss 0.847600 (0.811037)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 6810.0 MB
2025-07-05 05:22:39,381 - WARNING - Epoch [25/25] Step [191/250]  acc 0.716776 (0.708940)  loss 0.789367 (0.808270)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 6810.0 MB
2025-07-05 05:22:43,731 - WARNING - Epoch [25/25] Step [201/250]  acc 0.742887 (0.709595)  loss 0.715327 (0.806342)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 6810.0 MB
2025-07-05 05:22:48,044 - WARNING - Epoch [25/25] Step [211/250]  acc 0.686394 (0.709565)  loss 0.881156 (0.806247)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 6810.0 MB
2025-07-05 05:22:52,351 - WARNING - Epoch [25/25] Step [221/250]  acc 0.668487 (0.709131)  loss 0.869795 (0.806603)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 6810.0 MB
2025-07-05 05:22:56,795 - WARNING - Epoch [25/25] Step [231/250]  acc 0.712008 (0.708963)  loss 0.769061 (0.807243)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 6810.0 MB
2025-07-05 05:23:01,244 - WARNING - Epoch [25/25] Step [241/250]  acc 0.703376 (0.708357)  loss 0.799824 (0.808686)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 6810.0 MB
Epoch 25 completed in 0:01:50.611243
2025-07-05 05:23:31,256 - INFO - DARTS search completed in 3442.64s
2025-07-05 05:23:31,258 - INFO - 
============================================================
2025-07-05 05:23:31,258 - INFO - Layer layer_0 Expert Selection:
2025-07-05 05:23:31,258 - INFO -   Expert 0: GINE (α=0.2462)
2025-07-05 05:23:31,258 - INFO -   Expert 1: CustomGatedGCN (α=0.3601)
2025-07-05 05:23:31,258 - INFO -   Expert 2: GATV2 (α=0.3936) ← SELECTED
2025-07-05 05:23:31,258 - INFO - Selected Expert Index: 2 (GATV2)
2025-07-05 05:23:31,258 - INFO - ============================================================

2025-07-05 05:23:31,258 - INFO - 
============================================================
2025-07-05 05:23:31,258 - INFO - Layer layer_1 Expert Selection:
2025-07-05 05:23:31,258 - INFO -   Expert 0: GINE (α=0.3444) ← SELECTED
2025-07-05 05:23:31,258 - INFO -   Expert 1: CustomGatedGCN (α=0.3362)
2025-07-05 05:23:31,258 - INFO -   Expert 2: GATV2 (α=0.3194)
2025-07-05 05:23:31,258 - INFO - Selected Expert Index: 0 (GINE)
2025-07-05 05:23:31,258 - INFO - ============================================================

2025-07-05 05:23:31,258 - INFO - 
============================================================
2025-07-05 05:23:31,258 - INFO - Layer layer_2 Expert Selection:
2025-07-05 05:23:31,258 - INFO -   Expert 0: GINE (α=0.3259)
2025-07-05 05:23:31,259 - INFO -   Expert 1: CustomGatedGCN (α=0.3416) ← SELECTED
2025-07-05 05:23:31,259 - INFO -   Expert 2: GATV2 (α=0.3325)
2025-07-05 05:23:31,259 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 05:23:31,259 - INFO - ============================================================

2025-07-05 05:23:31,259 - INFO - 
============================================================
2025-07-05 05:23:31,259 - INFO - Layer layer_3 Expert Selection:
2025-07-05 05:23:31,259 - INFO -   Expert 0: GINE (α=0.3612) ← SELECTED
2025-07-05 05:23:31,259 - INFO -   Expert 1: CustomGatedGCN (α=0.3083)
2025-07-05 05:23:31,259 - INFO -   Expert 2: GATV2 (α=0.3304)
2025-07-05 05:23:31,259 - INFO - Selected Expert Index: 0 (GINE)
2025-07-05 05:23:31,259 - INFO - ============================================================

2025-07-05 05:23:31,259 - INFO - 
============================================================
2025-07-05 05:23:31,259 - INFO - Layer layer_4 Expert Selection:
2025-07-05 05:23:31,259 - INFO -   Expert 0: GINE (α=0.2993)
2025-07-05 05:23:31,259 - INFO -   Expert 1: CustomGatedGCN (α=0.3119)
2025-07-05 05:23:31,259 - INFO -   Expert 2: GATV2 (α=0.3888) ← SELECTED
2025-07-05 05:23:31,259 - INFO - Selected Expert Index: 2 (GATV2)
2025-07-05 05:23:31,259 - INFO - ============================================================

2025-07-05 05:23:31,259 - INFO - 
============================================================
2025-07-05 05:23:31,259 - INFO - Layer layer_5 Expert Selection:
2025-07-05 05:23:31,259 - INFO -   Expert 0: GINE (α=0.2559)
2025-07-05 05:23:31,259 - INFO -   Expert 1: CustomGatedGCN (α=0.2483)
2025-07-05 05:23:31,259 - INFO -   Expert 2: GATV2 (α=0.4958) ← SELECTED
2025-07-05 05:23:31,259 - INFO - Selected Expert Index: 2 (GATV2)
2025-07-05 05:23:31,259 - INFO - ============================================================

2025-07-05 05:23:31,259 - INFO - 
============================================================
2025-07-05 05:23:31,260 - INFO - Layer layer_6 Expert Selection:
2025-07-05 05:23:31,260 - INFO -   Expert 0: GINE (α=0.2192)
2025-07-05 05:23:31,260 - INFO -   Expert 1: CustomGatedGCN (α=0.3469)
2025-07-05 05:23:31,260 - INFO -   Expert 2: GATV2 (α=0.4340) ← SELECTED
2025-07-05 05:23:31,260 - INFO - Selected Expert Index: 2 (GATV2)
2025-07-05 05:23:31,260 - INFO - ============================================================

2025-07-05 05:23:31,260 - INFO - 
============================================================
2025-07-05 05:23:31,260 - INFO - Layer layer_7 Expert Selection:
2025-07-05 05:23:31,260 - INFO -   Expert 0: GINE (α=0.2004)
2025-07-05 05:23:31,260 - INFO -   Expert 1: CustomGatedGCN (α=0.5444) ← SELECTED
2025-07-05 05:23:31,260 - INFO -   Expert 2: GATV2 (α=0.2552)
2025-07-05 05:23:31,260 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 05:23:31,260 - INFO - ============================================================

2025-07-05 05:23:31,260 - INFO - 
============================================================
2025-07-05 05:23:31,260 - INFO - Layer layer_8 Expert Selection:
2025-07-05 05:23:31,260 - INFO -   Expert 0: GINE (α=0.1942)
2025-07-05 05:23:31,260 - INFO -   Expert 1: CustomGatedGCN (α=0.4132) ← SELECTED
2025-07-05 05:23:31,260 - INFO -   Expert 2: GATV2 (α=0.3926)
2025-07-05 05:23:31,260 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 05:23:31,260 - INFO - ============================================================

2025-07-05 05:23:31,260 - INFO - 
============================================================
2025-07-05 05:23:31,260 - INFO - Layer layer_9 Expert Selection:
2025-07-05 05:23:31,260 - INFO -   Expert 0: GINE (α=0.1934)
2025-07-05 05:23:31,260 - INFO -   Expert 1: CustomGatedGCN (α=0.4432) ← SELECTED
2025-07-05 05:23:31,260 - INFO -   Expert 2: GATV2 (α=0.3634)
2025-07-05 05:23:31,261 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 05:23:31,261 - INFO - ============================================================

2025-07-05 05:23:31,261 - INFO - 
============================================================
2025-07-05 05:23:31,261 - INFO - Layer layer_10 Expert Selection:
2025-07-05 05:23:31,261 - INFO -   Expert 0: GINE (α=0.1994)
2025-07-05 05:23:31,261 - INFO -   Expert 1: CustomGatedGCN (α=0.4888) ← SELECTED
2025-07-05 05:23:31,261 - INFO -   Expert 2: GATV2 (α=0.3118)
2025-07-05 05:23:31,261 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 05:23:31,261 - INFO - ============================================================

2025-07-05 05:23:31,261 - INFO - 
============================================================
2025-07-05 05:23:31,261 - INFO - Layer layer_11 Expert Selection:
2025-07-05 05:23:31,261 - INFO -   Expert 0: GINE (α=0.2276)
2025-07-05 05:23:31,261 - INFO -   Expert 1: CustomGatedGCN (α=0.4984) ← SELECTED
2025-07-05 05:23:31,261 - INFO -   Expert 2: GATV2 (α=0.2740)
2025-07-05 05:23:31,261 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 05:23:31,261 - INFO - ============================================================

2025-07-05 05:23:31,261 - INFO - 
============================================================
2025-07-05 05:23:31,261 - INFO - Layer layer_12 Expert Selection:
2025-07-05 05:23:31,261 - INFO -   Expert 0: GINE (α=0.2092)
2025-07-05 05:23:31,261 - INFO -   Expert 1: CustomGatedGCN (α=0.5261) ← SELECTED
2025-07-05 05:23:31,261 - INFO -   Expert 2: GATV2 (α=0.2648)
2025-07-05 05:23:31,261 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 05:23:31,261 - INFO - ============================================================

2025-07-05 05:23:31,261 - INFO - 
============================================================
2025-07-05 05:23:31,261 - INFO - Layer layer_13 Expert Selection:
2025-07-05 05:23:31,261 - INFO -   Expert 0: GINE (α=0.1456)
2025-07-05 05:23:31,262 - INFO -   Expert 1: CustomGatedGCN (α=0.6726) ← SELECTED
2025-07-05 05:23:31,262 - INFO -   Expert 2: GATV2 (α=0.1817)
2025-07-05 05:23:31,262 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 05:23:31,262 - INFO - ============================================================

2025-07-05 05:23:31,262 - INFO - 
============================================================
2025-07-05 05:23:31,262 - INFO - Layer layer_14 Expert Selection:
2025-07-05 05:23:31,262 - INFO -   Expert 0: GINE (α=0.1635)
2025-07-05 05:23:31,262 - INFO -   Expert 1: CustomGatedGCN (α=0.6420) ← SELECTED
2025-07-05 05:23:31,262 - INFO -   Expert 2: GATV2 (α=0.1945)
2025-07-05 05:23:31,262 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 05:23:31,262 - INFO - ============================================================

2025-07-05 05:23:31,262 - INFO - 
============================================================
2025-07-05 05:23:31,262 - INFO - Layer layer_15 Expert Selection:
2025-07-05 05:23:31,262 - INFO -   Expert 0: GINE (α=0.1820)
2025-07-05 05:23:31,262 - INFO -   Expert 1: CustomGatedGCN (α=0.5125) ← SELECTED
2025-07-05 05:23:31,262 - INFO -   Expert 2: GATV2 (α=0.3055)
2025-07-05 05:23:31,262 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 05:23:31,262 - INFO - ============================================================

=== MODEL PARAMETER COMPARISON ===
Original DARTS model parameters: 728,678
2025-07-05 05:23:31,335 - INFO - Layer 0: Using ONLY Expert 2 (GATV2)
2025-07-05 05:23:31,335 - INFO - DiscreteNASLayer 0: Using ONLY Expert 2 (GATV2)
2025-07-05 05:23:31,339 - INFO - Layer 1: Using ONLY Expert 0 (GINE)
2025-07-05 05:23:31,339 - INFO - DiscreteNASLayer 1: Using ONLY Expert 0 (GINE)
2025-07-05 05:23:31,341 - INFO - Layer 2: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,341 - INFO - DiscreteNASLayer 2: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,344 - INFO - Layer 3: Using ONLY Expert 0 (GINE)
2025-07-05 05:23:31,344 - INFO - DiscreteNASLayer 3: Using ONLY Expert 0 (GINE)
2025-07-05 05:23:31,346 - INFO - Layer 4: Using ONLY Expert 2 (GATV2)
2025-07-05 05:23:31,346 - INFO - DiscreteNASLayer 4: Using ONLY Expert 2 (GATV2)
2025-07-05 05:23:31,348 - INFO - Layer 5: Using ONLY Expert 2 (GATV2)
2025-07-05 05:23:31,348 - INFO - DiscreteNASLayer 5: Using ONLY Expert 2 (GATV2)
2025-07-05 05:23:31,351 - INFO - Layer 6: Using ONLY Expert 2 (GATV2)
2025-07-05 05:23:31,351 - INFO - DiscreteNASLayer 6: Using ONLY Expert 2 (GATV2)
2025-07-05 05:23:31,354 - INFO - Layer 7: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,354 - INFO - DiscreteNASLayer 7: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,356 - INFO - Layer 8: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,356 - INFO - DiscreteNASLayer 8: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,359 - INFO - Layer 9: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,359 - INFO - DiscreteNASLayer 9: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,362 - INFO - Layer 10: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,362 - INFO - DiscreteNASLayer 10: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,364 - INFO - Layer 11: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,364 - INFO - DiscreteNASLayer 11: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,367 - INFO - Layer 12: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,367 - INFO - DiscreteNASLayer 12: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,369 - INFO - Layer 13: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,370 - INFO - DiscreteNASLayer 13: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,372 - INFO - Layer 14: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,372 - INFO - DiscreteNASLayer 14: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,375 - INFO - Layer 15: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:23:31,375 - INFO - DiscreteNASLayer 15: Using ONLY Expert 1 (CustomGatedGCN)
Fresh discrete model parameters: 505,814
Parameter difference: -222,864
✓ Used cfg.share.dim_in (raw input) instead of self.encoder.dim_in (processed)
✓ Fresh discrete model with correct input dimensions
2025-07-05 05:23:31,399 - INFO - Replaced inner model with discrete version
2025-07-05 05:23:31,400 - INFO - Creating fresh optimizer/scheduler for discrete model...
2025-07-05 05:23:31,404 - INFO - Fresh optimizer created: AdamW
2025-07-05 05:23:31,404 - INFO - Fresh scheduler created: LambdaLR
2025-07-05 05:23:31,404 - INFO - Discrete model parameters: 505,814
2025-07-05 05:23:31,404 - INFO - ============================================================
2025-07-05 05:23:31,404 - INFO - PHASE 2: DISCRETE TRAINING WITH UNCERTAINTY
2025-07-05 05:23:31,404 - INFO - ============================================================
2025-07-05 05:23:31,404 - INFO - === Epoch 0 ===
2025-07-05 05:25:00,090 - INFO - train: {'epoch': 0, 'time_epoch': 87.7954, 'eta': 8691.74428, 'eta_hours': 2.41437, 'loss': 1.79657154, 'lr': 0.0, 'params': 505814, 'time_iter': 0.14047, 'accuracy': 0.16695, 'f1': 0.05483, 'accuracy-SBM': 0.16683, 'auc': 0.49916}
2025-07-05 05:25:00,122 - INFO - ...computing epoch stats took: 0.90s
2025-07-05 05:25:04,639 - INFO - val: {'epoch': 0, 'time_epoch': 4.46197, 'loss': 1.79627662, 'lr': 0, 'params': 505814, 'time_iter': 0.07082, 'accuracy': 0.1647, 'f1': 0.05154, 'accuracy-SBM': 0.1665, 'auc': 0.49774}
2025-07-05 05:25:04,679 - INFO - ...computing epoch stats took: 0.09s
2025-07-05 05:25:11,432 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:25:11,487 - INFO - test: {'epoch': 0, 'time_epoch': 4.79593, 'loss': 1.79667906, 'lr': 0, 'params': 505814, 'time_iter': 0.07613, 'accuracy': 0.16551, 'f1': 0.05115, 'accuracy-SBM': 0.16667, 'auc': 0.49768}
2025-07-05 05:25:11,530 - INFO - ...computing epoch stats took: 0.09s
2025-07-05 05:25:11,530 - INFO - > Epoch 0: took 100.1s (avg 100.1s) | Best so far: epoch 0	train_loss: 1.7966 train_accuracy-SBM: 0.1668	val_loss: 1.7963 val_accuracy-SBM: 0.1665	test_loss: 1.7967 test_accuracy-SBM: 0.1667
2025-07-05 05:25:11,530 - INFO - === Epoch 1 ===
2025-07-05 05:26:38,637 - INFO - train: {'epoch': 1, 'time_epoch': 86.84447, 'eta': 8557.35335, 'eta_hours': 2.37704, 'loss': 1.71667289, 'lr': 0.0002, 'params': 505814, 'time_iter': 0.13895, 'accuracy': 0.32295, 'f1': 0.30911, 'accuracy-SBM': 0.32291, 'auc': 0.66217}
2025-07-05 05:26:38,643 - INFO - ...computing epoch stats took: 0.25s
2025-07-05 05:26:43,013 - INFO - val: {'epoch': 1, 'time_epoch': 4.31447, 'loss': 1.82604544, 'lr': 0, 'params': 505814, 'time_iter': 0.06848, 'accuracy': 0.16493, 'f1': 0.04746, 'accuracy-SBM': 0.16681, 'auc': 0.6078}
2025-07-05 05:26:43,015 - INFO - ...computing epoch stats took: 0.05s
2025-07-05 05:26:49,170 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:26:49,225 - INFO - test: {'epoch': 1, 'time_epoch': 4.60853, 'loss': 1.82674013, 'lr': 0, 'params': 505814, 'time_iter': 0.07315, 'accuracy': 0.16574, 'f1': 0.04794, 'accuracy-SBM': 0.16693, 'auc': 0.60796}
2025-07-05 05:26:49,228 - INFO - ...computing epoch stats took: 0.05s
2025-07-05 05:26:49,228 - INFO - > Epoch 1: took 97.7s (avg 98.9s) | Best so far: epoch 1	train_loss: 1.7167 train_accuracy-SBM: 0.3229	val_loss: 1.8260 val_accuracy-SBM: 0.1668	test_loss: 1.8267 test_accuracy-SBM: 0.1669
2025-07-05 05:26:49,228 - INFO - === Epoch 2 ===
2025-07-05 05:28:16,977 - INFO - train: {'epoch': 2, 'time_epoch': 87.50927, 'eta': 8476.15521, 'eta_hours': 2.35449, 'loss': 1.39190777, 'lr': 0.0004, 'params': 505814, 'time_iter': 0.14001, 'accuracy': 0.5261, 'f1': 0.52509, 'accuracy-SBM': 0.52612, 'auc': 0.81209}
2025-07-05 05:28:16,983 - INFO - ...computing epoch stats took: 0.22s
2025-07-05 05:28:21,184 - INFO - val: {'epoch': 2, 'time_epoch': 4.14932, 'loss': 1.78798149, 'lr': 0, 'params': 505814, 'time_iter': 0.06586, 'accuracy': 0.28881, 'f1': 0.23548, 'accuracy-SBM': 0.28992, 'auc': 0.68936}
2025-07-05 05:28:21,185 - INFO - ...computing epoch stats took: 0.05s
2025-07-05 05:28:27,221 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:28:27,292 - INFO - test: {'epoch': 2, 'time_epoch': 4.52596, 'loss': 1.78065837, 'lr': 0, 'params': 505814, 'time_iter': 0.07184, 'accuracy': 0.29342, 'f1': 0.24199, 'accuracy-SBM': 0.2942, 'auc': 0.69198}
2025-07-05 05:28:27,294 - INFO - ...computing epoch stats took: 0.06s
2025-07-05 05:28:27,294 - INFO - > Epoch 2: took 98.1s (avg 98.6s) | Best so far: epoch 2	train_loss: 1.3919 train_accuracy-SBM: 0.5261	val_loss: 1.7880 val_accuracy-SBM: 0.2899	test_loss: 1.7807 test_accuracy-SBM: 0.2942
2025-07-05 05:28:27,294 - INFO - === Epoch 3 ===
2025-07-05 05:29:54,501 - INFO - train: {'epoch': 3, 'time_epoch': 86.96298, 'eta': 8378.69073, 'eta_hours': 2.32741, 'loss': 1.01286967, 'lr': 0.0006, 'params': 505814, 'time_iter': 0.13914, 'accuracy': 0.6574, 'f1': 0.65737, 'accuracy-SBM': 0.6574, 'auc': 0.90328}
2025-07-05 05:29:58,686 - INFO - val: {'epoch': 3, 'time_epoch': 4.13248, 'loss': 1.23666069, 'lr': 0, 'params': 505814, 'time_iter': 0.06559, 'accuracy': 0.55716, 'f1': 0.5483, 'accuracy-SBM': 0.55668, 'auc': 0.85491}
2025-07-05 05:30:04,637 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:30:04,683 - INFO - test: {'epoch': 3, 'time_epoch': 4.43443, 'loss': 1.21110985, 'lr': 0, 'params': 505814, 'time_iter': 0.07039, 'accuracy': 0.56597, 'f1': 0.55817, 'accuracy-SBM': 0.56555, 'auc': 0.86144}
2025-07-05 05:30:04,685 - INFO - > Epoch 3: took 97.4s (avg 98.3s) | Best so far: epoch 3	train_loss: 1.0129 train_accuracy-SBM: 0.6574	val_loss: 1.2367 val_accuracy-SBM: 0.5567	test_loss: 1.2111 test_accuracy-SBM: 0.5655
2025-07-05 05:30:04,685 - INFO - === Epoch 4 ===
2025-07-05 05:31:32,272 - INFO - train: {'epoch': 4, 'time_epoch': 87.24644, 'eta': 8290.81243, 'eta_hours': 2.303, 'loss': 0.87173517, 'lr': 0.0008, 'params': 505814, 'time_iter': 0.13959, 'accuracy': 0.69441, 'f1': 0.69441, 'accuracy-SBM': 0.69441, 'auc': 0.92678}
2025-07-05 05:31:36,368 - INFO - val: {'epoch': 4, 'time_epoch': 4.05099, 'loss': 0.84086998, 'lr': 0, 'params': 505814, 'time_iter': 0.0643, 'accuracy': 0.70162, 'f1': 0.70092, 'accuracy-SBM': 0.70096, 'auc': 0.93293}
2025-07-05 05:31:42,217 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:31:42,257 - INFO - test: {'epoch': 4, 'time_epoch': 4.49088, 'loss': 0.83497006, 'lr': 0, 'params': 505814, 'time_iter': 0.07128, 'accuracy': 0.70305, 'f1': 0.70275, 'accuracy-SBM': 0.70299, 'auc': 0.9343}
2025-07-05 05:31:42,259 - INFO - > Epoch 4: took 97.6s (avg 98.2s) | Best so far: epoch 4	train_loss: 0.8717 train_accuracy-SBM: 0.6944	val_loss: 0.8409 val_accuracy-SBM: 0.7010	test_loss: 0.8350 test_accuracy-SBM: 0.7030
2025-07-05 05:31:42,259 - INFO - === Epoch 5 ===
2025-07-05 05:33:09,122 - INFO - train: {'epoch': 5, 'time_epoch': 86.61509, 'eta': 8193.25368, 'eta_hours': 2.2759, 'loss': 0.82747188, 'lr': 0.001, 'params': 505814, 'time_iter': 0.13858, 'accuracy': 0.70548, 'f1': 0.70548, 'accuracy-SBM': 0.70548, 'auc': 0.9327}
2025-07-05 05:33:13,307 - INFO - val: {'epoch': 5, 'time_epoch': 4.13523, 'loss': 0.94042817, 'lr': 0, 'params': 505814, 'time_iter': 0.06564, 'accuracy': 0.66635, 'f1': 0.66811, 'accuracy-SBM': 0.66657, 'auc': 0.91386}
2025-07-05 05:33:19,241 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:33:19,281 - INFO - test: {'epoch': 5, 'time_epoch': 4.59938, 'loss': 0.90625442, 'lr': 0, 'params': 505814, 'time_iter': 0.07301, 'accuracy': 0.67607, 'f1': 0.67717, 'accuracy-SBM': 0.67626, 'auc': 0.92074}
2025-07-05 05:33:19,283 - INFO - > Epoch 5: took 97.0s (avg 98.0s) | Best so far: epoch 4	train_loss: 0.8717 train_accuracy-SBM: 0.6944	val_loss: 0.8409 val_accuracy-SBM: 0.7010	test_loss: 0.8350 test_accuracy-SBM: 0.7030
2025-07-05 05:33:19,283 - INFO - === Epoch 6 ===
2025-07-05 05:34:51,355 - INFO - train: {'epoch': 6, 'time_epoch': 91.80859, 'eta': 8167.82103, 'eta_hours': 2.26884, 'loss': 0.79493999, 'lr': 0.00099973, 'params': 505814, 'time_iter': 0.14689, 'accuracy': 0.71591, 'f1': 0.71591, 'accuracy-SBM': 0.71591, 'auc': 0.93744}
2025-07-05 05:34:55,691 - INFO - val: {'epoch': 6, 'time_epoch': 4.28813, 'loss': 0.73479963, 'lr': 0, 'params': 505814, 'time_iter': 0.06807, 'accuracy': 0.73942, 'f1': 0.7393, 'accuracy-SBM': 0.73929, 'auc': 0.94745}
2025-07-05 05:35:03,729 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:35:03,780 - INFO - test: {'epoch': 6, 'time_epoch': 4.55489, 'loss': 0.72446169, 'lr': 0, 'params': 505814, 'time_iter': 0.0723, 'accuracy': 0.74038, 'f1': 0.74039, 'accuracy-SBM': 0.74036, 'auc': 0.94932}
2025-07-05 05:35:03,783 - INFO - > Epoch 6: took 104.5s (avg 98.9s) | Best so far: epoch 6	train_loss: 0.7949 train_accuracy-SBM: 0.7159	val_loss: 0.7348 val_accuracy-SBM: 0.7393	test_loss: 0.7245 test_accuracy-SBM: 0.7404
2025-07-05 05:35:03,784 - INFO - === Epoch 7 ===
2025-07-05 05:36:33,555 - INFO - train: {'epoch': 7, 'time_epoch': 89.51074, 'eta': 8099.36911, 'eta_hours': 2.24982, 'loss': 0.76591862, 'lr': 0.00099891, 'params': 505814, 'time_iter': 0.14322, 'accuracy': 0.7242, 'f1': 0.7242, 'accuracy-SBM': 0.7242, 'auc': 0.9418}
2025-07-05 05:36:37,652 - INFO - val: {'epoch': 7, 'time_epoch': 4.0517, 'loss': 0.74095382, 'lr': 0, 'params': 505814, 'time_iter': 0.06431, 'accuracy': 0.7353, 'f1': 0.73527, 'accuracy-SBM': 0.73512, 'auc': 0.94641}
2025-07-05 05:36:43,424 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:36:43,462 - INFO - test: {'epoch': 7, 'time_epoch': 4.36752, 'loss': 0.73549247, 'lr': 0, 'params': 505814, 'time_iter': 0.06933, 'accuracy': 0.73593, 'f1': 0.73593, 'accuracy-SBM': 0.73593, 'auc': 0.94767}
2025-07-05 05:36:43,464 - INFO - > Epoch 7: took 99.7s (avg 99.0s) | Best so far: epoch 6	train_loss: 0.7949 train_accuracy-SBM: 0.7159	val_loss: 0.7348 val_accuracy-SBM: 0.7393	test_loss: 0.7245 test_accuracy-SBM: 0.7404
2025-07-05 05:36:43,464 - INFO - === Epoch 8 ===
2025-07-05 05:38:09,786 - INFO - train: {'epoch': 8, 'time_epoch': 86.08508, 'eta': 7991.60028, 'eta_hours': 2.21989, 'loss': 0.7537683, 'lr': 0.00099754, 'params': 505814, 'time_iter': 0.13774, 'accuracy': 0.72866, 'f1': 0.72866, 'accuracy-SBM': 0.72866, 'auc': 0.94342}
2025-07-05 05:38:13,937 - INFO - val: {'epoch': 8, 'time_epoch': 4.09928, 'loss': 0.72092237, 'lr': 0, 'params': 505814, 'time_iter': 0.06507, 'accuracy': 0.74197, 'f1': 0.74185, 'accuracy-SBM': 0.74163, 'auc': 0.9487}
2025-07-05 05:38:19,855 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:38:19,900 - INFO - test: {'epoch': 8, 'time_epoch': 4.398, 'loss': 0.71212153, 'lr': 0, 'params': 505814, 'time_iter': 0.06981, 'accuracy': 0.74395, 'f1': 0.74389, 'accuracy-SBM': 0.74392, 'auc': 0.95005}
2025-07-05 05:38:19,916 - INFO - > Epoch 8: took 96.5s (avg 98.7s) | Best so far: epoch 8	train_loss: 0.7538 train_accuracy-SBM: 0.7287	val_loss: 0.7209 val_accuracy-SBM: 0.7416	test_loss: 0.7121 test_accuracy-SBM: 0.7439
2025-07-05 05:38:19,916 - INFO - === Epoch 9 ===
2025-07-05 05:39:41,950 - INFO - train: {'epoch': 9, 'time_epoch': 81.70493, 'eta': 7848.74678, 'eta_hours': 2.18021, 'loss': 0.74145018, 'lr': 0.00099563, 'params': 505814, 'time_iter': 0.13073, 'accuracy': 0.73285, 'f1': 0.73285, 'accuracy-SBM': 0.73285, 'auc': 0.94519}
2025-07-05 05:39:46,051 - INFO - val: {'epoch': 9, 'time_epoch': 4.03482, 'loss': 0.71994956, 'lr': 0, 'params': 505814, 'time_iter': 0.06404, 'accuracy': 0.74169, 'f1': 0.74175, 'accuracy-SBM': 0.74182, 'auc': 0.94909}
2025-07-05 05:39:51,872 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:39:51,910 - INFO - test: {'epoch': 9, 'time_epoch': 4.35207, 'loss': 0.71386219, 'lr': 0, 'params': 505814, 'time_iter': 0.06908, 'accuracy': 0.74234, 'f1': 0.74246, 'accuracy-SBM': 0.7424, 'auc': 0.95001}
2025-07-05 05:39:51,912 - INFO - > Epoch 9: took 92.0s (avg 98.1s) | Best so far: epoch 9	train_loss: 0.7415 train_accuracy-SBM: 0.7329	val_loss: 0.7199 val_accuracy-SBM: 0.7418	test_loss: 0.7139 test_accuracy-SBM: 0.7424
2025-07-05 05:39:51,912 - INFO - === Epoch 10 ===
2025-07-05 05:41:17,483 - INFO - train: {'epoch': 10, 'time_epoch': 85.12271, 'eta': 7744.6642, 'eta_hours': 2.1513, 'loss': 0.73207907, 'lr': 0.00099318, 'params': 505814, 'time_iter': 0.1362, 'accuracy': 0.73596, 'f1': 0.73596, 'accuracy-SBM': 0.73596, 'auc': 0.94652}
2025-07-05 05:41:21,831 - INFO - val: {'epoch': 10, 'time_epoch': 4.24866, 'loss': 0.71319551, 'lr': 0, 'params': 505814, 'time_iter': 0.06744, 'accuracy': 0.74649, 'f1': 0.74617, 'accuracy-SBM': 0.74605, 'auc': 0.95044}
2025-07-05 05:41:27,761 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:41:27,801 - INFO - test: {'epoch': 10, 'time_epoch': 4.56885, 'loss': 0.70667662, 'lr': 0, 'params': 505814, 'time_iter': 0.07252, 'accuracy': 0.74592, 'f1': 0.74587, 'accuracy-SBM': 0.74575, 'auc': 0.95134}
2025-07-05 05:41:27,803 - INFO - > Epoch 10: took 95.9s (avg 97.9s) | Best so far: epoch 10	train_loss: 0.7321 train_accuracy-SBM: 0.7360	val_loss: 0.7132 val_accuracy-SBM: 0.7460	test_loss: 0.7067 test_accuracy-SBM: 0.7458
2025-07-05 05:41:27,803 - INFO - === Epoch 11 ===
2025-07-05 05:42:55,908 - INFO - train: {'epoch': 11, 'time_epoch': 87.86526, 'eta': 7663.85361, 'eta_hours': 2.12885, 'loss': 0.72412203, 'lr': 0.00099019, 'params': 505814, 'time_iter': 0.14058, 'accuracy': 0.73878, 'f1': 0.73878, 'accuracy-SBM': 0.73878, 'auc': 0.94763}
2025-07-05 05:43:00,137 - INFO - val: {'epoch': 11, 'time_epoch': 4.18149, 'loss': 0.68689542, 'lr': 0, 'params': 505814, 'time_iter': 0.06637, 'accuracy': 0.75626, 'f1': 0.75609, 'accuracy-SBM': 0.75605, 'auc': 0.95311}
2025-07-05 05:43:06,149 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:43:06,191 - INFO - test: {'epoch': 11, 'time_epoch': 4.52834, 'loss': 0.68537702, 'lr': 0, 'params': 505814, 'time_iter': 0.07188, 'accuracy': 0.75325, 'f1': 0.75312, 'accuracy-SBM': 0.75313, 'auc': 0.95352}
2025-07-05 05:43:06,194 - INFO - > Epoch 11: took 98.4s (avg 97.9s) | Best so far: epoch 11	train_loss: 0.7241 train_accuracy-SBM: 0.7388	val_loss: 0.6869 val_accuracy-SBM: 0.7560	test_loss: 0.6854 test_accuracy-SBM: 0.7531
2025-07-05 05:43:06,194 - INFO - === Epoch 12 ===
2025-07-05 05:44:32,887 - INFO - train: {'epoch': 12, 'time_epoch': 86.45087, 'eta': 7572.49217, 'eta_hours': 2.10347, 'loss': 0.71724432, 'lr': 0.00098666, 'params': 505814, 'time_iter': 0.13832, 'accuracy': 0.741, 'f1': 0.741, 'accuracy-SBM': 0.741, 'auc': 0.94858}
2025-07-05 05:44:37,155 - INFO - val: {'epoch': 12, 'time_epoch': 4.2118, 'loss': 0.67577326, 'lr': 0, 'params': 505814, 'time_iter': 0.06685, 'accuracy': 0.75649, 'f1': 0.75647, 'accuracy-SBM': 0.75645, 'auc': 0.9549}
2025-07-05 05:44:53,661 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:44:53,708 - INFO - test: {'epoch': 12, 'time_epoch': 4.48585, 'loss': 0.66980462, 'lr': 0, 'params': 505814, 'time_iter': 0.0712, 'accuracy': 0.75849, 'f1': 0.75852, 'accuracy-SBM': 0.75858, 'auc': 0.95564}
2025-07-05 05:44:53,711 - INFO - > Epoch 12: took 107.5s (avg 98.6s) | Best so far: epoch 12	train_loss: 0.7172 train_accuracy-SBM: 0.7410	val_loss: 0.6758 val_accuracy-SBM: 0.7564	test_loss: 0.6698 test_accuracy-SBM: 0.7586
2025-07-05 05:44:53,711 - INFO - === Epoch 13 ===
2025-07-05 05:46:23,879 - INFO - train: {'epoch': 13, 'time_epoch': 89.90879, 'eta': 7503.07373, 'eta_hours': 2.08419, 'loss': 0.71162617, 'lr': 0.0009826, 'params': 505814, 'time_iter': 0.14385, 'accuracy': 0.74291, 'f1': 0.74291, 'accuracy-SBM': 0.74291, 'auc': 0.94938}
2025-07-05 05:46:28,153 - INFO - val: {'epoch': 13, 'time_epoch': 4.22395, 'loss': 0.67997596, 'lr': 0, 'params': 505814, 'time_iter': 0.06705, 'accuracy': 0.75825, 'f1': 0.75805, 'accuracy-SBM': 0.75793, 'auc': 0.95431}
2025-07-05 05:46:39,610 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:46:39,656 - INFO - test: {'epoch': 13, 'time_epoch': 4.57843, 'loss': 0.68613689, 'lr': 0, 'params': 505814, 'time_iter': 0.07267, 'accuracy': 0.75343, 'f1': 0.75352, 'accuracy-SBM': 0.75345, 'auc': 0.95357}
2025-07-05 05:46:39,662 - INFO - > Epoch 13: took 106.0s (avg 99.2s) | Best so far: epoch 13	train_loss: 0.7116 train_accuracy-SBM: 0.7429	val_loss: 0.6800 val_accuracy-SBM: 0.7579	test_loss: 0.6861 test_accuracy-SBM: 0.7534
2025-07-05 05:46:39,663 - INFO - === Epoch 14 ===
2025-07-05 05:48:10,312 - INFO - train: {'epoch': 14, 'time_epoch': 90.38597, 'eta': 7433.62727, 'eta_hours': 2.0649, 'loss': 0.70574887, 'lr': 0.00097802, 'params': 505814, 'time_iter': 0.14462, 'accuracy': 0.74434, 'f1': 0.74434, 'accuracy-SBM': 0.74434, 'auc': 0.95022}
2025-07-05 05:48:14,637 - INFO - val: {'epoch': 14, 'time_epoch': 4.27662, 'loss': 0.69069375, 'lr': 0, 'params': 505814, 'time_iter': 0.06788, 'accuracy': 0.75396, 'f1': 0.75363, 'accuracy-SBM': 0.75378, 'auc': 0.9525}
2025-07-05 05:48:29,160 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:48:29,198 - INFO - test: {'epoch': 14, 'time_epoch': 4.69657, 'loss': 0.6787915, 'lr': 0, 'params': 505814, 'time_iter': 0.07455, 'accuracy': 0.7537, 'f1': 0.75361, 'accuracy-SBM': 0.75366, 'auc': 0.95422}
2025-07-05 05:48:29,200 - INFO - > Epoch 14: took 109.5s (avg 99.9s) | Best so far: epoch 13	train_loss: 0.7116 train_accuracy-SBM: 0.7429	val_loss: 0.6800 val_accuracy-SBM: 0.7579	test_loss: 0.6861 test_accuracy-SBM: 0.7534
2025-07-05 05:48:29,201 - INFO - === Epoch 15 ===
2025-07-05 05:49:58,640 - INFO - train: {'epoch': 15, 'time_epoch': 89.18607, 'eta': 7355.2639, 'eta_hours': 2.04313, 'loss': 0.70661799, 'lr': 0.00097291, 'params': 505814, 'time_iter': 0.1427, 'accuracy': 0.74455, 'f1': 0.74455, 'accuracy-SBM': 0.74455, 'auc': 0.95007}
2025-07-05 05:50:03,052 - INFO - val: {'epoch': 15, 'time_epoch': 4.36211, 'loss': 0.66887949, 'lr': 0, 'params': 505814, 'time_iter': 0.06924, 'accuracy': 0.75877, 'f1': 0.75858, 'accuracy-SBM': 0.75859, 'auc': 0.95554}
2025-07-05 05:50:16,703 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:50:16,754 - INFO - test: {'epoch': 15, 'time_epoch': 4.75401, 'loss': 0.66813155, 'lr': 0, 'params': 505814, 'time_iter': 0.07546, 'accuracy': 0.75949, 'f1': 0.75945, 'accuracy-SBM': 0.75944, 'auc': 0.95568}
2025-07-05 05:50:16,940 - INFO - > Epoch 15: took 107.7s (avg 100.3s) | Best so far: epoch 15	train_loss: 0.7066 train_accuracy-SBM: 0.7446	val_loss: 0.6689 val_accuracy-SBM: 0.7586	test_loss: 0.6681 test_accuracy-SBM: 0.7594
2025-07-05 05:50:16,941 - INFO - === Epoch 16 ===
2025-07-05 05:51:47,107 - INFO - train: {'epoch': 16, 'time_epoch': 89.90115, 'eta': 7279.11854, 'eta_hours': 2.02198, 'loss': 0.69716825, 'lr': 0.00096728, 'params': 505814, 'time_iter': 0.14384, 'accuracy': 0.74804, 'f1': 0.74804, 'accuracy-SBM': 0.74804, 'auc': 0.95134}
2025-07-05 05:51:51,554 - INFO - val: {'epoch': 16, 'time_epoch': 4.38791, 'loss': 0.66552426, 'lr': 0, 'params': 505814, 'time_iter': 0.06965, 'accuracy': 0.76056, 'f1': 0.76047, 'accuracy-SBM': 0.7603, 'auc': 0.95608}
2025-07-05 05:51:58,799 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:51:58,844 - INFO - test: {'epoch': 16, 'time_epoch': 4.95217, 'loss': 0.6617069, 'lr': 0, 'params': 505814, 'time_iter': 0.07861, 'accuracy': 0.76064, 'f1': 0.76078, 'accuracy-SBM': 0.76069, 'auc': 0.95668}
2025-07-05 05:51:58,847 - INFO - > Epoch 16: took 101.9s (avg 100.4s) | Best so far: epoch 16	train_loss: 0.6972 train_accuracy-SBM: 0.7480	val_loss: 0.6655 val_accuracy-SBM: 0.7603	test_loss: 0.6617 test_accuracy-SBM: 0.7607
2025-07-05 05:51:58,847 - INFO - === Epoch 17 ===
2025-07-05 05:53:31,864 - INFO - train: {'epoch': 17, 'time_epoch': 92.73342, 'eta': 7214.34733, 'eta_hours': 2.00399, 'loss': 0.69506271, 'lr': 0.00096114, 'params': 505814, 'time_iter': 0.14837, 'accuracy': 0.7482, 'f1': 0.74819, 'accuracy-SBM': 0.7482, 'auc': 0.95167}
2025-07-05 05:53:36,077 - INFO - val: {'epoch': 17, 'time_epoch': 4.16324, 'loss': 0.67248119, 'lr': 0, 'params': 505814, 'time_iter': 0.06608, 'accuracy': 0.75753, 'f1': 0.75746, 'accuracy-SBM': 0.75742, 'auc': 0.95499}
2025-07-05 05:53:43,593 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:53:43,633 - INFO - test: {'epoch': 17, 'time_epoch': 4.57275, 'loss': 0.66085453, 'lr': 0, 'params': 505814, 'time_iter': 0.07258, 'accuracy': 0.76146, 'f1': 0.76148, 'accuracy-SBM': 0.76154, 'auc': 0.95659}
2025-07-05 05:53:43,635 - INFO - > Epoch 17: took 104.8s (avg 100.7s) | Best so far: epoch 16	train_loss: 0.6972 train_accuracy-SBM: 0.7480	val_loss: 0.6655 val_accuracy-SBM: 0.7603	test_loss: 0.6617 test_accuracy-SBM: 0.7607
2025-07-05 05:53:43,635 - INFO - === Epoch 18 ===
2025-07-05 05:55:14,570 - INFO - train: {'epoch': 18, 'time_epoch': 90.66428, 'eta': 7137.81166, 'eta_hours': 1.98273, 'loss': 0.69048161, 'lr': 0.0009545, 'params': 505814, 'time_iter': 0.14506, 'accuracy': 0.75092, 'f1': 0.75092, 'accuracy-SBM': 0.75092, 'auc': 0.95227}
2025-07-05 05:55:18,936 - INFO - val: {'epoch': 18, 'time_epoch': 4.30685, 'loss': 0.68879679, 'lr': 0, 'params': 505814, 'time_iter': 0.06836, 'accuracy': 0.75071, 'f1': 0.75062, 'accuracy-SBM': 0.75078, 'auc': 0.953}
2025-07-05 05:55:26,258 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:55:26,301 - INFO - test: {'epoch': 18, 'time_epoch': 4.70761, 'loss': 0.67724373, 'lr': 0, 'params': 505814, 'time_iter': 0.07472, 'accuracy': 0.75646, 'f1': 0.7564, 'accuracy-SBM': 0.75638, 'auc': 0.95447}
2025-07-05 05:55:26,303 - INFO - > Epoch 18: took 102.7s (avg 100.8s) | Best so far: epoch 16	train_loss: 0.6972 train_accuracy-SBM: 0.7480	val_loss: 0.6655 val_accuracy-SBM: 0.7603	test_loss: 0.6617 test_accuracy-SBM: 0.7607
2025-07-05 05:55:26,304 - INFO - === Epoch 19 ===
2025-07-05 05:56:51,915 - INFO - train: {'epoch': 19, 'time_epoch': 85.36042, 'eta': 7038.64767, 'eta_hours': 1.95518, 'loss': 0.68650855, 'lr': 0.00094736, 'params': 505814, 'time_iter': 0.13658, 'accuracy': 0.75121, 'f1': 0.75121, 'accuracy-SBM': 0.75121, 'auc': 0.95282}
2025-07-05 05:56:56,129 - INFO - val: {'epoch': 19, 'time_epoch': 4.04213, 'loss': 0.66564492, 'lr': 0, 'params': 505814, 'time_iter': 0.06416, 'accuracy': 0.76424, 'f1': 0.76393, 'accuracy-SBM': 0.76391, 'auc': 0.9558}
2025-07-05 05:57:02,655 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:57:02,694 - INFO - test: {'epoch': 19, 'time_epoch': 4.47087, 'loss': 0.65861449, 'lr': 0, 'params': 505814, 'time_iter': 0.07097, 'accuracy': 0.76174, 'f1': 0.76157, 'accuracy-SBM': 0.76161, 'auc': 0.95683}
2025-07-05 05:57:02,696 - INFO - > Epoch 19: took 96.4s (avg 100.6s) | Best so far: epoch 19	train_loss: 0.6865 train_accuracy-SBM: 0.7512	val_loss: 0.6656 val_accuracy-SBM: 0.7639	test_loss: 0.6586 test_accuracy-SBM: 0.7616
2025-07-05 05:57:02,696 - INFO - === Epoch 20 ===
2025-07-05 05:58:29,229 - INFO - train: {'epoch': 20, 'time_epoch': 86.07311, 'eta': 6943.4794, 'eta_hours': 1.92874, 'loss': 0.68077434, 'lr': 0.00093974, 'params': 505814, 'time_iter': 0.13772, 'accuracy': 0.75365, 'f1': 0.75365, 'accuracy-SBM': 0.75365, 'auc': 0.95361}
2025-07-05 05:58:33,681 - INFO - val: {'epoch': 20, 'time_epoch': 4.39291, 'loss': 0.65478067, 'lr': 0, 'params': 505814, 'time_iter': 0.06973, 'accuracy': 0.76522, 'f1': 0.7651, 'accuracy-SBM': 0.76501, 'auc': 0.95738}
2025-07-05 05:58:40,552 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 05:58:40,600 - INFO - test: {'epoch': 20, 'time_epoch': 5.02333, 'loss': 0.65535062, 'lr': 0, 'params': 505814, 'time_iter': 0.07974, 'accuracy': 0.76273, 'f1': 0.76277, 'accuracy-SBM': 0.76267, 'auc': 0.95735}
2025-07-05 05:58:40,604 - INFO - > Epoch 20: took 97.9s (avg 100.4s) | Best so far: epoch 20	train_loss: 0.6808 train_accuracy-SBM: 0.7537	val_loss: 0.6548 val_accuracy-SBM: 0.7650	test_loss: 0.6554 test_accuracy-SBM: 0.7627
2025-07-05 05:58:40,604 - INFO - === Epoch 21 ===
2025-07-05 06:00:12,783 - INFO - train: {'epoch': 21, 'time_epoch': 91.81881, 'eta': 6869.50907, 'eta_hours': 1.9082, 'loss': 0.67868623, 'lr': 0.00093163, 'params': 505814, 'time_iter': 0.14691, 'accuracy': 0.75428, 'f1': 0.75428, 'accuracy-SBM': 0.75428, 'auc': 0.95389}
2025-07-05 06:00:16,935 - INFO - val: {'epoch': 21, 'time_epoch': 4.10334, 'loss': 0.66981521, 'lr': 0, 'params': 505814, 'time_iter': 0.06513, 'accuracy': 0.76239, 'f1': 0.7624, 'accuracy-SBM': 0.76252, 'auc': 0.95541}
2025-07-05 06:00:22,881 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:00:22,921 - INFO - test: {'epoch': 21, 'time_epoch': 4.43281, 'loss': 0.65295199, 'lr': 0, 'params': 505814, 'time_iter': 0.07036, 'accuracy': 0.76439, 'f1': 0.76435, 'accuracy-SBM': 0.76445, 'auc': 0.95766}
2025-07-05 06:00:22,924 - INFO - > Epoch 21: took 102.3s (avg 100.5s) | Best so far: epoch 20	train_loss: 0.6808 train_accuracy-SBM: 0.7537	val_loss: 0.6548 val_accuracy-SBM: 0.7650	test_loss: 0.6554 test_accuracy-SBM: 0.7627
2025-07-05 06:00:22,924 - INFO - === Epoch 22 ===
2025-07-05 06:01:51,831 - INFO - train: {'epoch': 22, 'time_epoch': 88.65134, 'eta': 6783.38255, 'eta_hours': 1.88427, 'loss': 0.67767666, 'lr': 0.00092305, 'params': 505814, 'time_iter': 0.14184, 'accuracy': 0.75477, 'f1': 0.75478, 'accuracy-SBM': 0.75477, 'auc': 0.954}
2025-07-05 06:01:55,971 - INFO - val: {'epoch': 22, 'time_epoch': 4.09034, 'loss': 0.66094038, 'lr': 0, 'params': 505814, 'time_iter': 0.06493, 'accuracy': 0.76169, 'f1': 0.76161, 'accuracy-SBM': 0.76148, 'auc': 0.95665}
2025-07-05 06:02:01,848 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:02:01,889 - INFO - test: {'epoch': 22, 'time_epoch': 4.45381, 'loss': 0.66004012, 'lr': 0, 'params': 505814, 'time_iter': 0.0707, 'accuracy': 0.76182, 'f1': 0.76176, 'accuracy-SBM': 0.76175, 'auc': 0.9567}
2025-07-05 06:02:01,891 - INFO - > Epoch 22: took 99.0s (avg 100.5s) | Best so far: epoch 20	train_loss: 0.6808 train_accuracy-SBM: 0.7537	val_loss: 0.6548 val_accuracy-SBM: 0.7650	test_loss: 0.6554 test_accuracy-SBM: 0.7627
2025-07-05 06:02:01,891 - INFO - === Epoch 23 ===
2025-07-05 06:03:28,919 - INFO - train: {'epoch': 23, 'time_epoch': 86.77923, 'eta': 6691.11729, 'eta_hours': 1.85864, 'loss': 0.67425638, 'lr': 0.000914, 'params': 505814, 'time_iter': 0.13885, 'accuracy': 0.75525, 'f1': 0.75525, 'accuracy-SBM': 0.75525, 'auc': 0.95451}
2025-07-05 06:03:32,977 - INFO - val: {'epoch': 23, 'time_epoch': 4.012, 'loss': 0.64896694, 'lr': 0, 'params': 505814, 'time_iter': 0.06368, 'accuracy': 0.76961, 'f1': 0.76948, 'accuracy-SBM': 0.7694, 'auc': 0.95795}
2025-07-05 06:03:38,773 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:03:38,814 - INFO - test: {'epoch': 23, 'time_epoch': 4.36047, 'loss': 0.63349517, 'lr': 0, 'params': 505814, 'time_iter': 0.06921, 'accuracy': 0.77149, 'f1': 0.7715, 'accuracy-SBM': 0.77149, 'auc': 0.96012}
2025-07-05 06:03:38,816 - INFO - > Epoch 23: took 96.9s (avg 100.3s) | Best so far: epoch 23	train_loss: 0.6743 train_accuracy-SBM: 0.7552	val_loss: 0.6490 val_accuracy-SBM: 0.7694	test_loss: 0.6335 test_accuracy-SBM: 0.7715
2025-07-05 06:03:38,817 - INFO - === Epoch 24 ===
2025-07-05 06:05:04,072 - INFO - train: {'epoch': 24, 'time_epoch': 84.98748, 'eta': 6593.91567, 'eta_hours': 1.83164, 'loss': 0.66880964, 'lr': 0.00090451, 'params': 505814, 'time_iter': 0.13598, 'accuracy': 0.75774, 'f1': 0.75774, 'accuracy-SBM': 0.75774, 'auc': 0.9552}
2025-07-05 06:05:08,261 - INFO - val: {'epoch': 24, 'time_epoch': 4.14311, 'loss': 0.65780432, 'lr': 0, 'params': 505814, 'time_iter': 0.06576, 'accuracy': 0.76529, 'f1': 0.76516, 'accuracy-SBM': 0.76515, 'auc': 0.95678}
2025-07-05 06:05:14,337 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:05:14,375 - INFO - test: {'epoch': 24, 'time_epoch': 4.38143, 'loss': 0.65823972, 'lr': 0, 'params': 505814, 'time_iter': 0.06955, 'accuracy': 0.76305, 'f1': 0.76308, 'accuracy-SBM': 0.76301, 'auc': 0.95673}
2025-07-05 06:05:14,377 - INFO - > Epoch 24: took 95.6s (avg 100.1s) | Best so far: epoch 23	train_loss: 0.6743 train_accuracy-SBM: 0.7552	val_loss: 0.6490 val_accuracy-SBM: 0.7694	test_loss: 0.6335 test_accuracy-SBM: 0.7715
2025-07-05 06:05:14,377 - INFO - === Epoch 25 ===
2025-07-05 06:06:40,406 - INFO - train: {'epoch': 25, 'time_epoch': 85.76097, 'eta': 6499.85507, 'eta_hours': 1.80552, 'loss': 0.66680693, 'lr': 0.00089457, 'params': 505814, 'time_iter': 0.13722, 'accuracy': 0.75791, 'f1': 0.75792, 'accuracy-SBM': 0.75791, 'auc': 0.9555}
2025-07-05 06:06:44,747 - INFO - val: {'epoch': 25, 'time_epoch': 4.28724, 'loss': 0.65124266, 'lr': 0, 'params': 505814, 'time_iter': 0.06805, 'accuracy': 0.76655, 'f1': 0.76641, 'accuracy-SBM': 0.76633, 'auc': 0.95779}
2025-07-05 06:06:50,892 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:06:50,933 - INFO - test: {'epoch': 25, 'time_epoch': 4.56161, 'loss': 0.64162191, 'lr': 0, 'params': 505814, 'time_iter': 0.07241, 'accuracy': 0.76887, 'f1': 0.76888, 'accuracy-SBM': 0.76878, 'auc': 0.95919}
2025-07-05 06:06:50,935 - INFO - > Epoch 25: took 96.6s (avg 100.0s) | Best so far: epoch 23	train_loss: 0.6743 train_accuracy-SBM: 0.7552	val_loss: 0.6490 val_accuracy-SBM: 0.7694	test_loss: 0.6335 test_accuracy-SBM: 0.7715
2025-07-05 06:06:50,935 - INFO - === Epoch 26 ===
2025-07-05 06:08:18,111 - INFO - train: {'epoch': 26, 'time_epoch': 86.92114, 'eta': 6409.54601, 'eta_hours': 1.78043, 'loss': 0.66455652, 'lr': 0.0008842, 'params': 505814, 'time_iter': 0.13907, 'accuracy': 0.75883, 'f1': 0.75883, 'accuracy-SBM': 0.75883, 'auc': 0.95579}
2025-07-05 06:08:22,408 - INFO - val: {'epoch': 26, 'time_epoch': 4.24921, 'loss': 0.6556914, 'lr': 0, 'params': 505814, 'time_iter': 0.06745, 'accuracy': 0.76536, 'f1': 0.7653, 'accuracy-SBM': 0.76526, 'auc': 0.95714}
2025-07-05 06:08:28,648 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:08:28,689 - INFO - test: {'epoch': 26, 'time_epoch': 4.48772, 'loss': 0.64686037, 'lr': 0, 'params': 505814, 'time_iter': 0.07123, 'accuracy': 0.76734, 'f1': 0.76744, 'accuracy-SBM': 0.76746, 'auc': 0.9584}
2025-07-05 06:08:28,691 - INFO - > Epoch 26: took 97.8s (avg 99.9s) | Best so far: epoch 23	train_loss: 0.6743 train_accuracy-SBM: 0.7552	val_loss: 0.6490 val_accuracy-SBM: 0.7694	test_loss: 0.6335 test_accuracy-SBM: 0.7715
2025-07-05 06:08:28,691 - INFO - === Epoch 27 ===
2025-07-05 06:09:56,115 - INFO - train: {'epoch': 27, 'time_epoch': 87.15157, 'eta': 6320.07147, 'eta_hours': 1.75558, 'loss': 0.66351018, 'lr': 0.00087341, 'params': 505814, 'time_iter': 0.13944, 'accuracy': 0.75963, 'f1': 0.75963, 'accuracy-SBM': 0.75963, 'auc': 0.95593}
2025-07-05 06:10:00,309 - INFO - val: {'epoch': 27, 'time_epoch': 4.1456, 'loss': 0.65517376, 'lr': 0, 'params': 505814, 'time_iter': 0.0658, 'accuracy': 0.76491, 'f1': 0.76494, 'accuracy-SBM': 0.76486, 'auc': 0.95727}
2025-07-05 06:10:06,574 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:10:06,613 - INFO - test: {'epoch': 27, 'time_epoch': 4.49887, 'loss': 0.64235409, 'lr': 0, 'params': 505814, 'time_iter': 0.07141, 'accuracy': 0.76884, 'f1': 0.76878, 'accuracy-SBM': 0.76891, 'auc': 0.95893}
2025-07-05 06:10:06,615 - INFO - > Epoch 27: took 97.9s (avg 99.8s) | Best so far: epoch 23	train_loss: 0.6743 train_accuracy-SBM: 0.7552	val_loss: 0.6490 val_accuracy-SBM: 0.7694	test_loss: 0.6335 test_accuracy-SBM: 0.7715
2025-07-05 06:10:06,615 - INFO - === Epoch 28 ===
2025-07-05 06:11:33,000 - INFO - train: {'epoch': 28, 'time_epoch': 86.129, 'eta': 6228.25361, 'eta_hours': 1.73007, 'loss': 0.6602566, 'lr': 0.00086221, 'params': 505814, 'time_iter': 0.13781, 'accuracy': 0.76065, 'f1': 0.76065, 'accuracy-SBM': 0.76065, 'auc': 0.95635}
2025-07-05 06:11:37,085 - INFO - val: {'epoch': 28, 'time_epoch': 4.03832, 'loss': 0.64321306, 'lr': 0, 'params': 505814, 'time_iter': 0.0641, 'accuracy': 0.76842, 'f1': 0.76839, 'accuracy-SBM': 0.76847, 'auc': 0.95872}
2025-07-05 06:11:43,754 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:11:43,792 - INFO - test: {'epoch': 28, 'time_epoch': 4.39694, 'loss': 0.63883042, 'lr': 0, 'params': 505814, 'time_iter': 0.06979, 'accuracy': 0.77069, 'f1': 0.77064, 'accuracy-SBM': 0.77069, 'auc': 0.9593}
2025-07-05 06:11:43,795 - INFO - > Epoch 28: took 97.2s (avg 99.7s) | Best so far: epoch 23	train_loss: 0.6743 train_accuracy-SBM: 0.7552	val_loss: 0.6490 val_accuracy-SBM: 0.7694	test_loss: 0.6335 test_accuracy-SBM: 0.7715
2025-07-05 06:11:43,795 - INFO - === Epoch 29 ===
2025-07-05 06:13:09,148 - INFO - train: {'epoch': 29, 'time_epoch': 85.10276, 'eta': 6134.42046, 'eta_hours': 1.70401, 'loss': 0.65729506, 'lr': 0.00085062, 'params': 505814, 'time_iter': 0.13616, 'accuracy': 0.76161, 'f1': 0.76161, 'accuracy-SBM': 0.76161, 'auc': 0.95676}
2025-07-05 06:13:13,235 - INFO - val: {'epoch': 29, 'time_epoch': 4.03308, 'loss': 0.64635929, 'lr': 0, 'params': 505814, 'time_iter': 0.06402, 'accuracy': 0.76933, 'f1': 0.7691, 'accuracy-SBM': 0.76903, 'auc': 0.95853}
2025-07-05 06:13:19,108 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:13:19,146 - INFO - test: {'epoch': 29, 'time_epoch': 4.27999, 'loss': 0.6400721, 'lr': 0, 'params': 505814, 'time_iter': 0.06794, 'accuracy': 0.76919, 'f1': 0.76916, 'accuracy-SBM': 0.76907, 'auc': 0.9593}
2025-07-05 06:13:19,148 - INFO - > Epoch 29: took 95.4s (avg 99.6s) | Best so far: epoch 23	train_loss: 0.6743 train_accuracy-SBM: 0.7552	val_loss: 0.6490 val_accuracy-SBM: 0.7694	test_loss: 0.6335 test_accuracy-SBM: 0.7715
2025-07-05 06:13:19,148 - INFO - === Epoch 30 ===
2025-07-05 06:14:45,178 - INFO - train: {'epoch': 30, 'time_epoch': 85.77807, 'eta': 6042.65365, 'eta_hours': 1.67851, 'loss': 0.65180137, 'lr': 0.00083864, 'params': 505814, 'time_iter': 0.13724, 'accuracy': 0.76402, 'f1': 0.76402, 'accuracy-SBM': 0.76402, 'auc': 0.95747}
2025-07-05 06:14:49,395 - INFO - val: {'epoch': 30, 'time_epoch': 4.17024, 'loss': 0.64764025, 'lr': 0, 'params': 505814, 'time_iter': 0.06619, 'accuracy': 0.76715, 'f1': 0.76715, 'accuracy-SBM': 0.76721, 'auc': 0.95819}
2025-07-05 06:14:55,417 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:14:55,456 - INFO - test: {'epoch': 30, 'time_epoch': 4.59907, 'loss': 0.63300071, 'lr': 0, 'params': 505814, 'time_iter': 0.073, 'accuracy': 0.77213, 'f1': 0.7722, 'accuracy-SBM': 0.77224, 'auc': 0.96022}
2025-07-05 06:14:55,459 - INFO - > Epoch 30: took 96.3s (avg 99.5s) | Best so far: epoch 23	train_loss: 0.6743 train_accuracy-SBM: 0.7552	val_loss: 0.6490 val_accuracy-SBM: 0.7694	test_loss: 0.6335 test_accuracy-SBM: 0.7715
2025-07-05 06:14:55,459 - INFO - === Epoch 31 ===
2025-07-05 06:16:21,696 - INFO - train: {'epoch': 31, 'time_epoch': 85.9665, 'eta': 5951.66155, 'eta_hours': 1.65324, 'loss': 0.65291471, 'lr': 0.00082629, 'params': 505814, 'time_iter': 0.13755, 'accuracy': 0.76251, 'f1': 0.7625, 'accuracy-SBM': 0.76251, 'auc': 0.95734}
2025-07-05 06:16:25,815 - INFO - val: {'epoch': 31, 'time_epoch': 4.05755, 'loss': 0.63563356, 'lr': 0, 'params': 505814, 'time_iter': 0.06441, 'accuracy': 0.77263, 'f1': 0.7725, 'accuracy-SBM': 0.77248, 'auc': 0.95969}
2025-07-05 06:16:32,378 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:16:32,418 - INFO - test: {'epoch': 31, 'time_epoch': 4.34843, 'loss': 0.63216627, 'lr': 0, 'params': 505814, 'time_iter': 0.06902, 'accuracy': 0.77213, 'f1': 0.77212, 'accuracy-SBM': 0.7721, 'auc': 0.96008}
2025-07-05 06:16:32,420 - INFO - > Epoch 31: took 97.0s (avg 99.4s) | Best so far: epoch 31	train_loss: 0.6529 train_accuracy-SBM: 0.7625	val_loss: 0.6356 val_accuracy-SBM: 0.7725	test_loss: 0.6322 test_accuracy-SBM: 0.7721
2025-07-05 06:16:32,420 - INFO - === Epoch 32 ===
2025-07-05 06:17:59,281 - INFO - train: {'epoch': 32, 'time_epoch': 86.5986, 'eta': 5862.25739, 'eta_hours': 1.6284, 'loss': 0.64676688, 'lr': 0.00081359, 'params': 505814, 'time_iter': 0.13856, 'accuracy': 0.76566, 'f1': 0.76566, 'accuracy-SBM': 0.76566, 'auc': 0.95812}
2025-07-05 06:18:03,496 - INFO - val: {'epoch': 32, 'time_epoch': 4.1671, 'loss': 0.64222752, 'lr': 0, 'params': 505814, 'time_iter': 0.06614, 'accuracy': 0.7704, 'f1': 0.77047, 'accuracy-SBM': 0.77055, 'auc': 0.95884}
2025-07-05 06:18:09,783 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:18:09,822 - INFO - test: {'epoch': 32, 'time_epoch': 4.49402, 'loss': 0.63138156, 'lr': 0, 'params': 505814, 'time_iter': 0.07133, 'accuracy': 0.77169, 'f1': 0.77174, 'accuracy-SBM': 0.77181, 'auc': 0.96031}
2025-07-05 06:18:09,824 - INFO - > Epoch 32: took 97.4s (avg 99.3s) | Best so far: epoch 31	train_loss: 0.6529 train_accuracy-SBM: 0.7625	val_loss: 0.6356 val_accuracy-SBM: 0.7725	test_loss: 0.6322 test_accuracy-SBM: 0.7721
2025-07-05 06:18:09,825 - INFO - === Epoch 33 ===
2025-07-05 06:19:40,960 - INFO - train: {'epoch': 33, 'time_epoch': 90.8708, 'eta': 5781.31136, 'eta_hours': 1.60592, 'loss': 0.64645602, 'lr': 0.00080054, 'params': 505814, 'time_iter': 0.14539, 'accuracy': 0.76518, 'f1': 0.76518, 'accuracy-SBM': 0.76518, 'auc': 0.95817}
2025-07-05 06:19:45,253 - INFO - val: {'epoch': 33, 'time_epoch': 4.2445, 'loss': 0.63415624, 'lr': 0, 'params': 505814, 'time_iter': 0.06737, 'accuracy': 0.77275, 'f1': 0.77261, 'accuracy-SBM': 0.77262, 'auc': 0.9597}
2025-07-05 06:19:51,032 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:19:51,070 - INFO - test: {'epoch': 33, 'time_epoch': 4.45976, 'loss': 0.62541884, 'lr': 0, 'params': 505814, 'time_iter': 0.07079, 'accuracy': 0.77349, 'f1': 0.77346, 'accuracy-SBM': 0.77346, 'auc': 0.96092}
2025-07-05 06:19:51,072 - INFO - > Epoch 33: took 101.2s (avg 99.4s) | Best so far: epoch 33	train_loss: 0.6465 train_accuracy-SBM: 0.7652	val_loss: 0.6342 val_accuracy-SBM: 0.7726	test_loss: 0.6254 test_accuracy-SBM: 0.7735
2025-07-05 06:19:51,072 - INFO - === Epoch 34 ===
2025-07-05 06:21:22,169 - INFO - train: {'epoch': 34, 'time_epoch': 90.83065, 'eta': 5699.72364, 'eta_hours': 1.58326, 'loss': 0.6436601, 'lr': 0.00078716, 'params': 505814, 'time_iter': 0.14533, 'accuracy': 0.76631, 'f1': 0.76632, 'accuracy-SBM': 0.76631, 'auc': 0.95852}
2025-07-05 06:21:26,358 - INFO - val: {'epoch': 34, 'time_epoch': 4.14215, 'loss': 0.65590804, 'lr': 0, 'params': 505814, 'time_iter': 0.06575, 'accuracy': 0.76682, 'f1': 0.7667, 'accuracy-SBM': 0.76676, 'auc': 0.95711}
2025-07-05 06:21:32,437 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:21:32,480 - INFO - test: {'epoch': 34, 'time_epoch': 4.5551, 'loss': 0.64059934, 'lr': 0, 'params': 505814, 'time_iter': 0.0723, 'accuracy': 0.76896, 'f1': 0.76901, 'accuracy-SBM': 0.76905, 'auc': 0.95913}
2025-07-05 06:21:32,482 - INFO - > Epoch 34: took 101.4s (avg 99.5s) | Best so far: epoch 33	train_loss: 0.6465 train_accuracy-SBM: 0.7652	val_loss: 0.6342 val_accuracy-SBM: 0.7726	test_loss: 0.6254 test_accuracy-SBM: 0.7735
2025-07-05 06:21:32,482 - INFO - === Epoch 35 ===
2025-07-05 06:23:03,894 - INFO - train: {'epoch': 35, 'time_epoch': 91.15241, 'eta': 5618.19442, 'eta_hours': 1.56061, 'loss': 0.64323601, 'lr': 0.00077347, 'params': 505814, 'time_iter': 0.14584, 'accuracy': 0.76661, 'f1': 0.76661, 'accuracy-SBM': 0.76661, 'auc': 0.95859}
2025-07-05 06:23:07,990 - INFO - val: {'epoch': 35, 'time_epoch': 4.04103, 'loss': 0.64192103, 'lr': 0, 'params': 505814, 'time_iter': 0.06414, 'accuracy': 0.77382, 'f1': 0.77374, 'accuracy-SBM': 0.77372, 'auc': 0.959}
2025-07-05 06:23:13,826 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:23:13,864 - INFO - test: {'epoch': 35, 'time_epoch': 4.42843, 'loss': 0.62770519, 'lr': 0, 'params': 505814, 'time_iter': 0.07029, 'accuracy': 0.77336, 'f1': 0.77338, 'accuracy-SBM': 0.77337, 'auc': 0.96087}
2025-07-05 06:23:13,866 - INFO - > Epoch 35: took 101.4s (avg 99.5s) | Best so far: epoch 35	train_loss: 0.6432 train_accuracy-SBM: 0.7666	val_loss: 0.6419 val_accuracy-SBM: 0.7737	test_loss: 0.6277 test_accuracy-SBM: 0.7734
2025-07-05 06:23:13,866 - INFO - === Epoch 36 ===
2025-07-05 06:24:45,900 - INFO - train: {'epoch': 36, 'time_epoch': 91.69447, 'eta': 5537.06802, 'eta_hours': 1.53807, 'loss': 0.63824815, 'lr': 0.00075948, 'params': 505814, 'time_iter': 0.14671, 'accuracy': 0.76834, 'f1': 0.76834, 'accuracy-SBM': 0.76834, 'auc': 0.95922}
2025-07-05 06:24:50,025 - INFO - val: {'epoch': 36, 'time_epoch': 4.07671, 'loss': 0.640104, 'lr': 0, 'params': 505814, 'time_iter': 0.06471, 'accuracy': 0.77142, 'f1': 0.77134, 'accuracy-SBM': 0.77131, 'auc': 0.95904}
2025-07-05 06:24:56,097 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:24:56,141 - INFO - test: {'epoch': 36, 'time_epoch': 4.2827, 'loss': 0.63264733, 'lr': 0, 'params': 505814, 'time_iter': 0.06798, 'accuracy': 0.77133, 'f1': 0.77119, 'accuracy-SBM': 0.77129, 'auc': 0.96002}
2025-07-05 06:24:56,143 - INFO - > Epoch 36: took 102.3s (avg 99.6s) | Best so far: epoch 35	train_loss: 0.6432 train_accuracy-SBM: 0.7666	val_loss: 0.6419 val_accuracy-SBM: 0.7737	test_loss: 0.6277 test_accuracy-SBM: 0.7734
2025-07-05 06:24:56,144 - INFO - === Epoch 37 ===
2025-07-05 06:26:26,543 - INFO - train: {'epoch': 37, 'time_epoch': 90.13259, 'eta': 5452.83706, 'eta_hours': 1.51468, 'loss': 0.63434815, 'lr': 0.00074521, 'params': 505814, 'time_iter': 0.14421, 'accuracy': 0.76979, 'f1': 0.76979, 'accuracy-SBM': 0.76979, 'auc': 0.95971}
2025-07-05 06:26:30,787 - INFO - val: {'epoch': 37, 'time_epoch': 4.19722, 'loss': 0.65109821, 'lr': 0, 'params': 505814, 'time_iter': 0.06662, 'accuracy': 0.76746, 'f1': 0.76738, 'accuracy-SBM': 0.76745, 'auc': 0.95766}
2025-07-05 06:26:37,073 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:26:37,116 - INFO - test: {'epoch': 37, 'time_epoch': 4.30228, 'loss': 0.64033264, 'lr': 0, 'params': 505814, 'time_iter': 0.06829, 'accuracy': 0.77071, 'f1': 0.77066, 'accuracy-SBM': 0.77067, 'auc': 0.95904}
2025-07-05 06:26:37,119 - INFO - > Epoch 37: took 101.0s (avg 99.6s) | Best so far: epoch 35	train_loss: 0.6432 train_accuracy-SBM: 0.7666	val_loss: 0.6419 val_accuracy-SBM: 0.7737	test_loss: 0.6277 test_accuracy-SBM: 0.7734
2025-07-05 06:26:37,119 - INFO - === Epoch 38 ===
2025-07-05 06:28:06,328 - INFO - train: {'epoch': 38, 'time_epoch': 88.94168, 'eta': 5366.44075, 'eta_hours': 1.49068, 'loss': 0.63226773, 'lr': 0.00073067, 'params': 505814, 'time_iter': 0.14231, 'accuracy': 0.77033, 'f1': 0.77033, 'accuracy-SBM': 0.77033, 'auc': 0.95999}
2025-07-05 06:28:10,617 - INFO - val: {'epoch': 38, 'time_epoch': 4.24023, 'loss': 0.64228143, 'lr': 0, 'params': 505814, 'time_iter': 0.06731, 'accuracy': 0.76926, 'f1': 0.76917, 'accuracy-SBM': 0.76916, 'auc': 0.95865}
2025-07-05 06:28:16,806 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:28:16,846 - INFO - test: {'epoch': 38, 'time_epoch': 4.52831, 'loss': 0.62649619, 'lr': 0, 'params': 505814, 'time_iter': 0.07188, 'accuracy': 0.77527, 'f1': 0.7752, 'accuracy-SBM': 0.77523, 'auc': 0.96075}
2025-07-05 06:28:16,849 - INFO - > Epoch 38: took 99.7s (avg 99.6s) | Best so far: epoch 35	train_loss: 0.6432 train_accuracy-SBM: 0.7666	val_loss: 0.6419 val_accuracy-SBM: 0.7737	test_loss: 0.6277 test_accuracy-SBM: 0.7734
2025-07-05 06:28:16,849 - INFO - === Epoch 39 ===
2025-07-05 06:29:42,750 - INFO - train: {'epoch': 39, 'time_epoch': 85.55556, 'eta': 5274.83799, 'eta_hours': 1.46523, 'loss': 0.63060084, 'lr': 0.00071588, 'params': 505814, 'time_iter': 0.13689, 'accuracy': 0.77154, 'f1': 0.77154, 'accuracy-SBM': 0.77154, 'auc': 0.96018}
2025-07-05 06:29:46,940 - INFO - val: {'epoch': 39, 'time_epoch': 4.12883, 'loss': 0.63167207, 'lr': 0, 'params': 505814, 'time_iter': 0.06554, 'accuracy': 0.77425, 'f1': 0.77421, 'accuracy-SBM': 0.77423, 'auc': 0.96019}
2025-07-05 06:29:52,969 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:29:53,008 - INFO - test: {'epoch': 39, 'time_epoch': 4.51459, 'loss': 0.62195473, 'lr': 0, 'params': 505814, 'time_iter': 0.07166, 'accuracy': 0.77593, 'f1': 0.77585, 'accuracy-SBM': 0.77591, 'auc': 0.96138}
2025-07-05 06:29:53,010 - INFO - > Epoch 39: took 96.2s (avg 99.5s) | Best so far: epoch 39	train_loss: 0.6306 train_accuracy-SBM: 0.7715	val_loss: 0.6317 val_accuracy-SBM: 0.7742	test_loss: 0.6220 test_accuracy-SBM: 0.7759
2025-07-05 06:29:53,010 - INFO - === Epoch 40 ===
2025-07-05 06:31:18,167 - INFO - train: {'epoch': 40, 'time_epoch': 84.90258, 'eta': 5182.59056, 'eta_hours': 1.43961, 'loss': 0.62725866, 'lr': 0.00070085, 'params': 505814, 'time_iter': 0.13584, 'accuracy': 0.77173, 'f1': 0.77173, 'accuracy-SBM': 0.77173, 'auc': 0.96062}
2025-07-05 06:31:22,401 - INFO - val: {'epoch': 40, 'time_epoch': 4.18757, 'loss': 0.64056659, 'lr': 0, 'params': 505814, 'time_iter': 0.06647, 'accuracy': 0.77446, 'f1': 0.77433, 'accuracy-SBM': 0.77435, 'auc': 0.95944}
2025-07-05 06:31:28,466 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:31:28,503 - INFO - test: {'epoch': 40, 'time_epoch': 4.53147, 'loss': 0.62635947, 'lr': 0, 'params': 505814, 'time_iter': 0.07193, 'accuracy': 0.77551, 'f1': 0.77548, 'accuracy-SBM': 0.77543, 'auc': 0.96104}
2025-07-05 06:31:28,505 - INFO - > Epoch 40: took 95.5s (avg 99.4s) | Best so far: epoch 40	train_loss: 0.6273 train_accuracy-SBM: 0.7717	val_loss: 0.6406 val_accuracy-SBM: 0.7743	test_loss: 0.6264 test_accuracy-SBM: 0.7754
2025-07-05 06:31:28,505 - INFO - === Epoch 41 ===
2025-07-05 06:32:53,626 - INFO - train: {'epoch': 41, 'time_epoch': 84.76524, 'eta': 5090.50324, 'eta_hours': 1.41403, 'loss': 0.62318097, 'lr': 0.0006856, 'params': 505814, 'time_iter': 0.13562, 'accuracy': 0.77384, 'f1': 0.77384, 'accuracy-SBM': 0.77384, 'auc': 0.96113}
2025-07-05 06:32:57,951 - INFO - val: {'epoch': 41, 'time_epoch': 4.23865, 'loss': 0.63596861, 'lr': 0, 'params': 505814, 'time_iter': 0.06728, 'accuracy': 0.77266, 'f1': 0.77271, 'accuracy-SBM': 0.77273, 'auc': 0.95965}
2025-07-05 06:33:04,056 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:33:04,094 - INFO - test: {'epoch': 41, 'time_epoch': 4.45912, 'loss': 0.63015994, 'lr': 0, 'params': 505814, 'time_iter': 0.07078, 'accuracy': 0.77315, 'f1': 0.77308, 'accuracy-SBM': 0.77314, 'auc': 0.96043}
2025-07-05 06:33:04,096 - INFO - > Epoch 41: took 95.6s (avg 99.3s) | Best so far: epoch 40	train_loss: 0.6273 train_accuracy-SBM: 0.7717	val_loss: 0.6406 val_accuracy-SBM: 0.7743	test_loss: 0.6264 test_accuracy-SBM: 0.7754
2025-07-05 06:33:04,096 - INFO - === Epoch 42 ===
2025-07-05 06:34:28,874 - INFO - train: {'epoch': 42, 'time_epoch': 84.53735, 'eta': 4998.45438, 'eta_hours': 1.38846, 'loss': 0.620663, 'lr': 0.00067015, 'params': 505814, 'time_iter': 0.13526, 'accuracy': 0.77474, 'f1': 0.77474, 'accuracy-SBM': 0.77474, 'auc': 0.96143}
2025-07-05 06:34:33,158 - INFO - val: {'epoch': 42, 'time_epoch': 4.23644, 'loss': 0.63014157, 'lr': 0, 'params': 505814, 'time_iter': 0.06725, 'accuracy': 0.77552, 'f1': 0.77549, 'accuracy-SBM': 0.77542, 'auc': 0.9602}
2025-07-05 06:34:39,340 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:34:39,384 - INFO - test: {'epoch': 42, 'time_epoch': 4.51319, 'loss': 0.62771843, 'lr': 0, 'params': 505814, 'time_iter': 0.07164, 'accuracy': 0.776, 'f1': 0.776, 'accuracy-SBM': 0.77608, 'auc': 0.96063}
2025-07-05 06:34:39,390 - INFO - > Epoch 42: took 95.3s (avg 99.3s) | Best so far: epoch 42	train_loss: 0.6207 train_accuracy-SBM: 0.7747	val_loss: 0.6301 val_accuracy-SBM: 0.7754	test_loss: 0.6277 test_accuracy-SBM: 0.7761
2025-07-05 06:34:39,390 - INFO - === Epoch 43 ===
2025-07-05 06:36:04,727 - INFO - train: {'epoch': 43, 'time_epoch': 85.10112, 'eta': 4907.46448, 'eta_hours': 1.36318, 'loss': 0.62139912, 'lr': 0.00065451, 'params': 505814, 'time_iter': 0.13616, 'accuracy': 0.77413, 'f1': 0.77413, 'accuracy-SBM': 0.77413, 'auc': 0.96135}
2025-07-05 06:36:08,957 - INFO - val: {'epoch': 43, 'time_epoch': 4.18436, 'loss': 0.63791877, 'lr': 0, 'params': 505814, 'time_iter': 0.06642, 'accuracy': 0.77311, 'f1': 0.77297, 'accuracy-SBM': 0.77319, 'auc': 0.95988}
2025-07-05 06:36:14,907 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:36:14,945 - INFO - test: {'epoch': 43, 'time_epoch': 4.5291, 'loss': 0.62567477, 'lr': 0, 'params': 505814, 'time_iter': 0.07189, 'accuracy': 0.77561, 'f1': 0.77556, 'accuracy-SBM': 0.77557, 'auc': 0.96122}
2025-07-05 06:36:14,947 - INFO - > Epoch 43: took 95.6s (avg 99.2s) | Best so far: epoch 42	train_loss: 0.6207 train_accuracy-SBM: 0.7747	val_loss: 0.6301 val_accuracy-SBM: 0.7754	test_loss: 0.6277 test_accuracy-SBM: 0.7761
2025-07-05 06:36:14,947 - INFO - === Epoch 44 ===
2025-07-05 06:37:40,229 - INFO - train: {'epoch': 44, 'time_epoch': 85.04887, 'eta': 4816.67244, 'eta_hours': 1.33796, 'loss': 0.61700541, 'lr': 0.0006387, 'params': 505814, 'time_iter': 0.13608, 'accuracy': 0.7757, 'f1': 0.7757, 'accuracy-SBM': 0.77571, 'auc': 0.9619}
2025-07-05 06:37:44,446 - INFO - val: {'epoch': 44, 'time_epoch': 4.17324, 'loss': 0.63905347, 'lr': 0, 'params': 505814, 'time_iter': 0.06624, 'accuracy': 0.77292, 'f1': 0.77285, 'accuracy-SBM': 0.77276, 'auc': 0.95929}
2025-07-05 06:37:50,568 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:37:50,616 - INFO - test: {'epoch': 44, 'time_epoch': 4.48502, 'loss': 0.62333728, 'lr': 0, 'params': 505814, 'time_iter': 0.07119, 'accuracy': 0.77624, 'f1': 0.77625, 'accuracy-SBM': 0.77625, 'auc': 0.96123}
2025-07-05 06:37:50,624 - INFO - > Epoch 44: took 95.7s (avg 99.1s) | Best so far: epoch 42	train_loss: 0.6207 train_accuracy-SBM: 0.7747	val_loss: 0.6301 val_accuracy-SBM: 0.7754	test_loss: 0.6277 test_accuracy-SBM: 0.7761
2025-07-05 06:37:50,624 - INFO - === Epoch 45 ===
2025-07-05 06:39:15,054 - INFO - train: {'epoch': 45, 'time_epoch': 84.19877, 'eta': 4725.13216, 'eta_hours': 1.31254, 'loss': 0.61666138, 'lr': 0.00062274, 'params': 505814, 'time_iter': 0.13472, 'accuracy': 0.77617, 'f1': 0.77617, 'accuracy-SBM': 0.77617, 'auc': 0.96193}
2025-07-05 06:39:19,263 - INFO - val: {'epoch': 45, 'time_epoch': 4.15678, 'loss': 0.64160075, 'lr': 0, 'params': 505814, 'time_iter': 0.06598, 'accuracy': 0.77036, 'f1': 0.77028, 'accuracy-SBM': 0.77032, 'auc': 0.95888}
2025-07-05 06:39:25,817 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:39:25,854 - INFO - test: {'epoch': 45, 'time_epoch': 4.49163, 'loss': 0.62542066, 'lr': 0, 'params': 505814, 'time_iter': 0.0713, 'accuracy': 0.77599, 'f1': 0.77595, 'accuracy-SBM': 0.77593, 'auc': 0.96087}
2025-07-05 06:39:25,856 - INFO - > Epoch 45: took 95.2s (avg 99.0s) | Best so far: epoch 42	train_loss: 0.6207 train_accuracy-SBM: 0.7747	val_loss: 0.6301 val_accuracy-SBM: 0.7754	test_loss: 0.6277 test_accuracy-SBM: 0.7761
2025-07-05 06:39:25,856 - INFO - === Epoch 46 ===
2025-07-05 06:40:50,911 - INFO - train: {'epoch': 46, 'time_epoch': 84.82078, 'eta': 4634.60571, 'eta_hours': 1.28739, 'loss': 0.61266212, 'lr': 0.00060665, 'params': 505814, 'time_iter': 0.13571, 'accuracy': 0.77741, 'f1': 0.77741, 'accuracy-SBM': 0.77741, 'auc': 0.96242}
2025-07-05 06:40:55,204 - INFO - val: {'epoch': 46, 'time_epoch': 4.24736, 'loss': 0.64119292, 'lr': 0, 'params': 505814, 'time_iter': 0.06742, 'accuracy': 0.77225, 'f1': 0.77216, 'accuracy-SBM': 0.77215, 'auc': 0.95915}
2025-07-05 06:41:01,061 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:41:01,099 - INFO - test: {'epoch': 46, 'time_epoch': 4.48279, 'loss': 0.6218703, 'lr': 0, 'params': 505814, 'time_iter': 0.07116, 'accuracy': 0.77922, 'f1': 0.77922, 'accuracy-SBM': 0.77921, 'auc': 0.96138}
2025-07-05 06:41:01,101 - INFO - > Epoch 46: took 95.2s (avg 98.9s) | Best so far: epoch 42	train_loss: 0.6207 train_accuracy-SBM: 0.7747	val_loss: 0.6301 val_accuracy-SBM: 0.7754	test_loss: 0.6277 test_accuracy-SBM: 0.7761
2025-07-05 06:41:01,102 - INFO - === Epoch 47 ===
2025-07-05 06:42:26,343 - INFO - train: {'epoch': 47, 'time_epoch': 84.99179, 'eta': 4544.50225, 'eta_hours': 1.26236, 'loss': 0.6131004, 'lr': 0.00059044, 'params': 505814, 'time_iter': 0.13599, 'accuracy': 0.77709, 'f1': 0.77709, 'accuracy-SBM': 0.77709, 'auc': 0.96237}
2025-07-05 06:42:30,620 - INFO - val: {'epoch': 47, 'time_epoch': 4.22809, 'loss': 0.63708678, 'lr': 0, 'params': 505814, 'time_iter': 0.06711, 'accuracy': 0.77494, 'f1': 0.77491, 'accuracy-SBM': 0.77489, 'auc': 0.95973}
2025-07-05 06:42:36,532 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:42:36,572 - INFO - test: {'epoch': 47, 'time_epoch': 4.48737, 'loss': 0.6189216, 'lr': 0, 'params': 505814, 'time_iter': 0.07123, 'accuracy': 0.77933, 'f1': 0.77928, 'accuracy-SBM': 0.77933, 'auc': 0.96188}
2025-07-05 06:42:36,574 - INFO - > Epoch 47: took 95.5s (avg 98.9s) | Best so far: epoch 42	train_loss: 0.6207 train_accuracy-SBM: 0.7747	val_loss: 0.6301 val_accuracy-SBM: 0.7754	test_loss: 0.6277 test_accuracy-SBM: 0.7761
2025-07-05 06:42:36,574 - INFO - === Epoch 48 ===
2025-07-05 06:44:01,561 - INFO - train: {'epoch': 48, 'time_epoch': 84.75448, 'eta': 4454.36044, 'eta_hours': 1.23732, 'loss': 0.60654272, 'lr': 0.00057413, 'params': 505814, 'time_iter': 0.13561, 'accuracy': 0.77908, 'f1': 0.77908, 'accuracy-SBM': 0.77908, 'auc': 0.96319}
2025-07-05 06:44:05,719 - INFO - val: {'epoch': 48, 'time_epoch': 4.11342, 'loss': 0.62872935, 'lr': 0, 'params': 505814, 'time_iter': 0.06529, 'accuracy': 0.77568, 'f1': 0.77554, 'accuracy-SBM': 0.77557, 'auc': 0.96072}
2025-07-05 06:44:11,536 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:44:11,573 - INFO - test: {'epoch': 48, 'time_epoch': 4.28712, 'loss': 0.61768921, 'lr': 0, 'params': 505814, 'time_iter': 0.06805, 'accuracy': 0.77965, 'f1': 0.77963, 'accuracy-SBM': 0.77956, 'auc': 0.96197}
2025-07-05 06:44:11,575 - INFO - > Epoch 48: took 95.0s (avg 98.8s) | Best so far: epoch 48	train_loss: 0.6065 train_accuracy-SBM: 0.7791	val_loss: 0.6287 val_accuracy-SBM: 0.7756	test_loss: 0.6177 test_accuracy-SBM: 0.7796
2025-07-05 06:44:11,575 - INFO - === Epoch 49 ===
2025-07-05 06:45:37,131 - INFO - train: {'epoch': 49, 'time_epoch': 85.20764, 'eta': 4364.88728, 'eta_hours': 1.21247, 'loss': 0.60482199, 'lr': 0.00055774, 'params': 505814, 'time_iter': 0.13633, 'accuracy': 0.78006, 'f1': 0.78006, 'accuracy-SBM': 0.78006, 'auc': 0.96339}
2025-07-05 06:45:41,405 - INFO - val: {'epoch': 49, 'time_epoch': 4.22907, 'loss': 0.63365656, 'lr': 0, 'params': 505814, 'time_iter': 0.06713, 'accuracy': 0.77483, 'f1': 0.77476, 'accuracy-SBM': 0.77468, 'auc': 0.95995}
2025-07-05 06:45:47,535 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:45:47,572 - INFO - test: {'epoch': 49, 'time_epoch': 4.51495, 'loss': 0.62141502, 'lr': 0, 'params': 505814, 'time_iter': 0.07167, 'accuracy': 0.77649, 'f1': 0.77647, 'accuracy-SBM': 0.77643, 'auc': 0.96142}
2025-07-05 06:45:47,574 - INFO - > Epoch 49: took 96.0s (avg 98.7s) | Best so far: epoch 48	train_loss: 0.6065 train_accuracy-SBM: 0.7791	val_loss: 0.6287 val_accuracy-SBM: 0.7756	test_loss: 0.6177 test_accuracy-SBM: 0.7796
2025-07-05 06:45:47,574 - INFO - === Epoch 50 ===
2025-07-05 06:47:12,182 - INFO - train: {'epoch': 50, 'time_epoch': 84.36408, 'eta': 4274.77091, 'eta_hours': 1.18744, 'loss': 0.60190306, 'lr': 0.00054129, 'params': 505814, 'time_iter': 0.13498, 'accuracy': 0.7813, 'f1': 0.7813, 'accuracy-SBM': 0.7813, 'auc': 0.96375}
2025-07-05 06:47:16,420 - INFO - val: {'epoch': 50, 'time_epoch': 4.19164, 'loss': 0.63207847, 'lr': 0, 'params': 505814, 'time_iter': 0.06653, 'accuracy': 0.77532, 'f1': 0.7752, 'accuracy-SBM': 0.77514, 'auc': 0.96016}
2025-07-05 06:47:22,543 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:47:22,580 - INFO - test: {'epoch': 50, 'time_epoch': 4.43159, 'loss': 0.622874, 'lr': 0, 'params': 505814, 'time_iter': 0.07034, 'accuracy': 0.77698, 'f1': 0.77697, 'accuracy-SBM': 0.77697, 'auc': 0.96128}
2025-07-05 06:47:22,583 - INFO - > Epoch 50: took 95.0s (avg 98.7s) | Best so far: epoch 48	train_loss: 0.6065 train_accuracy-SBM: 0.7791	val_loss: 0.6287 val_accuracy-SBM: 0.7756	test_loss: 0.6177 test_accuracy-SBM: 0.7796
2025-07-05 06:47:22,583 - INFO - === Epoch 51 ===
2025-07-05 06:48:47,905 - INFO - train: {'epoch': 51, 'time_epoch': 84.97615, 'eta': 4185.44078, 'eta_hours': 1.16262, 'loss': 0.6017251, 'lr': 0.00052479, 'params': 505814, 'time_iter': 0.13596, 'accuracy': 0.78108, 'f1': 0.78108, 'accuracy-SBM': 0.78109, 'auc': 0.96377}
2025-07-05 06:48:52,162 - INFO - val: {'epoch': 51, 'time_epoch': 4.20997, 'loss': 0.63009998, 'lr': 0, 'params': 505814, 'time_iter': 0.06682, 'accuracy': 0.77675, 'f1': 0.7766, 'accuracy-SBM': 0.77656, 'auc': 0.96049}
2025-07-05 06:48:58,382 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:48:58,432 - INFO - test: {'epoch': 51, 'time_epoch': 4.48907, 'loss': 0.61388846, 'lr': 0, 'params': 505814, 'time_iter': 0.07126, 'accuracy': 0.78061, 'f1': 0.78055, 'accuracy-SBM': 0.78055, 'auc': 0.96246}
2025-07-05 06:48:58,434 - INFO - > Epoch 51: took 95.9s (avg 98.6s) | Best so far: epoch 51	train_loss: 0.6017 train_accuracy-SBM: 0.7811	val_loss: 0.6301 val_accuracy-SBM: 0.7766	test_loss: 0.6139 test_accuracy-SBM: 0.7805
2025-07-05 06:48:58,434 - INFO - === Epoch 52 ===
2025-07-05 06:50:23,288 - INFO - train: {'epoch': 52, 'time_epoch': 84.61823, 'eta': 4095.95754, 'eta_hours': 1.13777, 'loss': 0.59701569, 'lr': 0.00050827, 'params': 505814, 'time_iter': 0.13539, 'accuracy': 0.78288, 'f1': 0.78288, 'accuracy-SBM': 0.78288, 'auc': 0.96432}
2025-07-05 06:50:27,491 - INFO - val: {'epoch': 52, 'time_epoch': 4.15779, 'loss': 0.63763302, 'lr': 0, 'params': 505814, 'time_iter': 0.066, 'accuracy': 0.77463, 'f1': 0.77447, 'accuracy-SBM': 0.77443, 'auc': 0.95974}
2025-07-05 06:50:33,563 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:50:33,601 - INFO - test: {'epoch': 52, 'time_epoch': 4.4403, 'loss': 0.6236913, 'lr': 0, 'params': 505814, 'time_iter': 0.07048, 'accuracy': 0.7781, 'f1': 0.7781, 'accuracy-SBM': 0.7781, 'auc': 0.96136}
2025-07-05 06:50:33,603 - INFO - > Epoch 52: took 95.2s (avg 98.5s) | Best so far: epoch 51	train_loss: 0.6017 train_accuracy-SBM: 0.7811	val_loss: 0.6301 val_accuracy-SBM: 0.7766	test_loss: 0.6139 test_accuracy-SBM: 0.7805
2025-07-05 06:50:33,603 - INFO - === Epoch 53 ===
2025-07-05 06:51:59,462 - INFO - train: {'epoch': 53, 'time_epoch': 85.61348, 'eta': 4007.5023, 'eta_hours': 1.1132, 'loss': 0.59584932, 'lr': 0.00049173, 'params': 505814, 'time_iter': 0.13698, 'accuracy': 0.78339, 'f1': 0.78339, 'accuracy-SBM': 0.78339, 'auc': 0.96447}
2025-07-05 06:52:03,861 - INFO - val: {'epoch': 53, 'time_epoch': 4.34946, 'loss': 0.63163904, 'lr': 0, 'params': 505814, 'time_iter': 0.06904, 'accuracy': 0.77707, 'f1': 0.77697, 'accuracy-SBM': 0.7769, 'auc': 0.96017}
2025-07-05 06:52:09,984 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:52:10,062 - INFO - test: {'epoch': 53, 'time_epoch': 4.50046, 'loss': 0.61567403, 'lr': 0, 'params': 505814, 'time_iter': 0.07144, 'accuracy': 0.78077, 'f1': 0.78072, 'accuracy-SBM': 0.78076, 'auc': 0.96211}
2025-07-05 06:52:10,076 - INFO - > Epoch 53: took 96.5s (avg 98.5s) | Best so far: epoch 53	train_loss: 0.5958 train_accuracy-SBM: 0.7834	val_loss: 0.6316 val_accuracy-SBM: 0.7769	test_loss: 0.6157 test_accuracy-SBM: 0.7808
2025-07-05 06:52:10,076 - INFO - === Epoch 54 ===
2025-07-05 06:53:34,124 - INFO - train: {'epoch': 54, 'time_epoch': 83.80521, 'eta': 3917.6709, 'eta_hours': 1.08824, 'loss': 0.59229096, 'lr': 0.00047521, 'params': 505814, 'time_iter': 0.13409, 'accuracy': 0.7846, 'f1': 0.7846, 'accuracy-SBM': 0.78461, 'auc': 0.96489}
2025-07-05 06:53:38,294 - INFO - val: {'epoch': 54, 'time_epoch': 4.12616, 'loss': 0.62905082, 'lr': 0, 'params': 505814, 'time_iter': 0.06549, 'accuracy': 0.77786, 'f1': 0.77787, 'accuracy-SBM': 0.77791, 'auc': 0.96081}
2025-07-05 06:53:44,364 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:53:44,402 - INFO - test: {'epoch': 54, 'time_epoch': 4.33221, 'loss': 0.61695663, 'lr': 0, 'params': 505814, 'time_iter': 0.06877, 'accuracy': 0.78124, 'f1': 0.78126, 'accuracy-SBM': 0.78129, 'auc': 0.96215}
2025-07-05 06:53:44,455 - INFO - > Epoch 54: took 94.4s (avg 98.4s) | Best so far: epoch 54	train_loss: 0.5923 train_accuracy-SBM: 0.7846	val_loss: 0.6291 val_accuracy-SBM: 0.7779	test_loss: 0.6170 test_accuracy-SBM: 0.7813
2025-07-05 06:53:44,455 - INFO - === Epoch 55 ===
2025-07-05 06:55:08,619 - INFO - train: {'epoch': 55, 'time_epoch': 83.91595, 'eta': 3828.14172, 'eta_hours': 1.06337, 'loss': 0.58921603, 'lr': 0.00045871, 'params': 505814, 'time_iter': 0.13427, 'accuracy': 0.78538, 'f1': 0.78538, 'accuracy-SBM': 0.78538, 'auc': 0.96527}
2025-07-05 06:55:12,796 - INFO - val: {'epoch': 55, 'time_epoch': 4.13231, 'loss': 0.63111512, 'lr': 0, 'params': 505814, 'time_iter': 0.06559, 'accuracy': 0.77839, 'f1': 0.77831, 'accuracy-SBM': 0.77835, 'auc': 0.96033}
2025-07-05 06:55:18,754 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:55:18,791 - INFO - test: {'epoch': 55, 'time_epoch': 4.28997, 'loss': 0.61496606, 'lr': 0, 'params': 505814, 'time_iter': 0.06809, 'accuracy': 0.78211, 'f1': 0.7821, 'accuracy-SBM': 0.78213, 'auc': 0.96223}
2025-07-05 06:55:18,793 - INFO - > Epoch 55: took 94.3s (avg 98.3s) | Best so far: epoch 55	train_loss: 0.5892 train_accuracy-SBM: 0.7854	val_loss: 0.6311 val_accuracy-SBM: 0.7783	test_loss: 0.6150 test_accuracy-SBM: 0.7821
2025-07-05 06:55:18,793 - INFO - === Epoch 56 ===
2025-07-05 06:56:42,753 - INFO - train: {'epoch': 56, 'time_epoch': 83.71935, 'eta': 3738.6612, 'eta_hours': 1.03852, 'loss': 0.58851538, 'lr': 0.00044226, 'params': 505814, 'time_iter': 0.13395, 'accuracy': 0.78625, 'f1': 0.78625, 'accuracy-SBM': 0.78626, 'auc': 0.96534}
2025-07-05 06:56:46,915 - INFO - val: {'epoch': 56, 'time_epoch': 4.11773, 'loss': 0.63067225, 'lr': 0, 'params': 505814, 'time_iter': 0.06536, 'accuracy': 0.77792, 'f1': 0.77775, 'accuracy-SBM': 0.77782, 'auc': 0.96048}
2025-07-05 06:56:52,985 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:56:53,029 - INFO - test: {'epoch': 56, 'time_epoch': 4.43626, 'loss': 0.61637084, 'lr': 0, 'params': 505814, 'time_iter': 0.07042, 'accuracy': 0.78011, 'f1': 0.78007, 'accuracy-SBM': 0.77999, 'auc': 0.96214}
2025-07-05 06:56:53,031 - INFO - > Epoch 56: took 94.2s (avg 98.3s) | Best so far: epoch 55	train_loss: 0.5892 train_accuracy-SBM: 0.7854	val_loss: 0.6311 val_accuracy-SBM: 0.7783	test_loss: 0.6150 test_accuracy-SBM: 0.7821
2025-07-05 06:56:53,031 - INFO - === Epoch 57 ===
2025-07-05 06:58:18,526 - INFO - train: {'epoch': 57, 'time_epoch': 85.25762, 'eta': 3650.49325, 'eta_hours': 1.01403, 'loss': 0.58515273, 'lr': 0.00042587, 'params': 505814, 'time_iter': 0.13641, 'accuracy': 0.78737, 'f1': 0.78737, 'accuracy-SBM': 0.78737, 'auc': 0.96573}
2025-07-05 06:58:22,683 - INFO - val: {'epoch': 57, 'time_epoch': 4.11186, 'loss': 0.63666798, 'lr': 0, 'params': 505814, 'time_iter': 0.06527, 'accuracy': 0.77596, 'f1': 0.77588, 'accuracy-SBM': 0.77586, 'auc': 0.95989}
2025-07-05 06:58:28,527 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 06:58:28,564 - INFO - test: {'epoch': 57, 'time_epoch': 4.33765, 'loss': 0.61495172, 'lr': 0, 'params': 505814, 'time_iter': 0.06885, 'accuracy': 0.77908, 'f1': 0.7791, 'accuracy-SBM': 0.77913, 'auc': 0.96244}
2025-07-05 06:58:28,566 - INFO - > Epoch 57: took 95.5s (avg 98.2s) | Best so far: epoch 55	train_loss: 0.5892 train_accuracy-SBM: 0.7854	val_loss: 0.6311 val_accuracy-SBM: 0.7783	test_loss: 0.6150 test_accuracy-SBM: 0.7821
2025-07-05 06:58:28,566 - INFO - === Epoch 58 ===
2025-07-05 06:59:52,762 - INFO - train: {'epoch': 58, 'time_epoch': 83.93737, 'eta': 3561.5065, 'eta_hours': 0.98931, 'loss': 0.58295979, 'lr': 0.00040956, 'params': 505814, 'time_iter': 0.1343, 'accuracy': 0.7875, 'f1': 0.7875, 'accuracy-SBM': 0.7875, 'auc': 0.96601}
2025-07-05 06:59:57,336 - INFO - val: {'epoch': 58, 'time_epoch': 4.51277, 'loss': 0.63545771, 'lr': 0, 'params': 505814, 'time_iter': 0.07163, 'accuracy': 0.77713, 'f1': 0.77704, 'accuracy-SBM': 0.77696, 'auc': 0.96008}
2025-07-05 07:00:04,027 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:00:04,073 - INFO - test: {'epoch': 58, 'time_epoch': 4.79701, 'loss': 0.62101854, 'lr': 0, 'params': 505814, 'time_iter': 0.07614, 'accuracy': 0.77877, 'f1': 0.7788, 'accuracy-SBM': 0.77875, 'auc': 0.96173}
2025-07-05 07:00:04,076 - INFO - > Epoch 58: took 95.5s (avg 98.2s) | Best so far: epoch 55	train_loss: 0.5892 train_accuracy-SBM: 0.7854	val_loss: 0.6311 val_accuracy-SBM: 0.7783	test_loss: 0.6150 test_accuracy-SBM: 0.7821
2025-07-05 07:00:04,076 - INFO - === Epoch 59 ===
2025-07-05 07:01:39,849 - INFO - train: {'epoch': 59, 'time_epoch': 95.51022, 'eta': 3480.40329, 'eta_hours': 0.96678, 'loss': 0.58177467, 'lr': 0.00039335, 'params': 505814, 'time_iter': 0.15282, 'accuracy': 0.78791, 'f1': 0.78791, 'accuracy-SBM': 0.78791, 'auc': 0.96614}
2025-07-05 07:01:44,397 - INFO - val: {'epoch': 59, 'time_epoch': 4.49454, 'loss': 0.6366152, 'lr': 0, 'params': 505814, 'time_iter': 0.07134, 'accuracy': 0.77683, 'f1': 0.77672, 'accuracy-SBM': 0.77672, 'auc': 0.95967}
2025-07-05 07:01:51,723 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:01:51,772 - INFO - test: {'epoch': 59, 'time_epoch': 4.83863, 'loss': 0.61759211, 'lr': 0, 'params': 505814, 'time_iter': 0.0768, 'accuracy': 0.77943, 'f1': 0.77938, 'accuracy-SBM': 0.77936, 'auc': 0.96189}
2025-07-05 07:01:51,775 - INFO - > Epoch 59: took 107.7s (avg 98.3s) | Best so far: epoch 55	train_loss: 0.5892 train_accuracy-SBM: 0.7854	val_loss: 0.6311 val_accuracy-SBM: 0.7783	test_loss: 0.6150 test_accuracy-SBM: 0.7821
2025-07-05 07:01:51,775 - INFO - === Epoch 60 ===
2025-07-05 07:03:28,391 - INFO - train: {'epoch': 60, 'time_epoch': 96.35147, 'eta': 3399.36557, 'eta_hours': 0.94427, 'loss': 0.57617031, 'lr': 0.00037726, 'params': 505814, 'time_iter': 0.15416, 'accuracy': 0.79028, 'f1': 0.79028, 'accuracy-SBM': 0.79028, 'auc': 0.96679}
2025-07-05 07:03:32,943 - INFO - val: {'epoch': 60, 'time_epoch': 4.49642, 'loss': 0.63559402, 'lr': 0, 'params': 505814, 'time_iter': 0.07137, 'accuracy': 0.77814, 'f1': 0.77803, 'accuracy-SBM': 0.77798, 'auc': 0.95994}
2025-07-05 07:03:39,672 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:03:39,720 - INFO - test: {'epoch': 60, 'time_epoch': 4.76214, 'loss': 0.61596004, 'lr': 0, 'params': 505814, 'time_iter': 0.07559, 'accuracy': 0.78105, 'f1': 0.78104, 'accuracy-SBM': 0.78106, 'auc': 0.9622}
2025-07-05 07:03:39,723 - INFO - > Epoch 60: took 107.9s (avg 98.5s) | Best so far: epoch 55	train_loss: 0.5892 train_accuracy-SBM: 0.7854	val_loss: 0.6311 val_accuracy-SBM: 0.7783	test_loss: 0.6150 test_accuracy-SBM: 0.7821
2025-07-05 07:03:39,723 - INFO - === Epoch 61 ===
2025-07-05 07:05:06,782 - INFO - train: {'epoch': 61, 'time_epoch': 86.82509, 'eta': 3311.99511, 'eta_hours': 0.92, 'loss': 0.5770624, 'lr': 0.0003613, 'params': 505814, 'time_iter': 0.13892, 'accuracy': 0.79023, 'f1': 0.79023, 'accuracy-SBM': 0.79024, 'auc': 0.96669}
2025-07-05 07:05:10,840 - INFO - val: {'epoch': 61, 'time_epoch': 4.00943, 'loss': 0.64687598, 'lr': 0, 'params': 505814, 'time_iter': 0.06364, 'accuracy': 0.77348, 'f1': 0.77333, 'accuracy-SBM': 0.77327, 'auc': 0.95885}
2025-07-05 07:05:18,053 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:05:18,098 - INFO - test: {'epoch': 61, 'time_epoch': 4.3612, 'loss': 0.6225477, 'lr': 0, 'params': 505814, 'time_iter': 0.06923, 'accuracy': 0.78026, 'f1': 0.78021, 'accuracy-SBM': 0.78015, 'auc': 0.96153}
2025-07-05 07:05:18,311 - INFO - > Epoch 61: took 98.6s (avg 98.5s) | Best so far: epoch 55	train_loss: 0.5892 train_accuracy-SBM: 0.7854	val_loss: 0.6311 val_accuracy-SBM: 0.7783	test_loss: 0.6150 test_accuracy-SBM: 0.7821
2025-07-05 07:05:18,312 - INFO - === Epoch 62 ===
2025-07-05 07:06:45,898 - INFO - train: {'epoch': 62, 'time_epoch': 87.29742, 'eta': 3224.91936, 'eta_hours': 0.89581, 'loss': 0.57458773, 'lr': 0.00034549, 'params': 505814, 'time_iter': 0.13968, 'accuracy': 0.79096, 'f1': 0.79096, 'accuracy-SBM': 0.79096, 'auc': 0.96697}
2025-07-05 07:06:50,186 - INFO - val: {'epoch': 62, 'time_epoch': 4.241, 'loss': 0.63157567, 'lr': 0, 'params': 505814, 'time_iter': 0.06732, 'accuracy': 0.77829, 'f1': 0.7782, 'accuracy-SBM': 0.77819, 'auc': 0.96041}
2025-07-05 07:06:56,201 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:06:56,241 - INFO - test: {'epoch': 62, 'time_epoch': 4.54918, 'loss': 0.61613665, 'lr': 0, 'params': 505814, 'time_iter': 0.07221, 'accuracy': 0.78055, 'f1': 0.78055, 'accuracy-SBM': 0.78053, 'auc': 0.96217}
2025-07-05 07:06:56,243 - INFO - > Epoch 62: took 97.9s (avg 98.5s) | Best so far: epoch 55	train_loss: 0.5892 train_accuracy-SBM: 0.7854	val_loss: 0.6311 val_accuracy-SBM: 0.7783	test_loss: 0.6150 test_accuracy-SBM: 0.7821
2025-07-05 07:06:56,243 - INFO - === Epoch 63 ===
2025-07-05 07:08:22,679 - INFO - train: {'epoch': 63, 'time_epoch': 86.15633, 'eta': 3137.19483, 'eta_hours': 0.87144, 'loss': 0.57166146, 'lr': 0.00032985, 'params': 505814, 'time_iter': 0.13785, 'accuracy': 0.79226, 'f1': 0.79225, 'accuracy-SBM': 0.79226, 'auc': 0.96731}
2025-07-05 07:08:27,141 - INFO - val: {'epoch': 63, 'time_epoch': 4.39438, 'loss': 0.63309853, 'lr': 0, 'params': 505814, 'time_iter': 0.06975, 'accuracy': 0.77758, 'f1': 0.77745, 'accuracy-SBM': 0.7775, 'auc': 0.96031}
2025-07-05 07:08:35,700 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:08:35,755 - INFO - test: {'epoch': 63, 'time_epoch': 4.73594, 'loss': 0.61480573, 'lr': 0, 'params': 505814, 'time_iter': 0.07517, 'accuracy': 0.7838, 'f1': 0.7838, 'accuracy-SBM': 0.7838, 'auc': 0.96231}
2025-07-05 07:08:35,768 - INFO - > Epoch 63: took 99.5s (avg 98.5s) | Best so far: epoch 55	train_loss: 0.5892 train_accuracy-SBM: 0.7854	val_loss: 0.6311 val_accuracy-SBM: 0.7783	test_loss: 0.6150 test_accuracy-SBM: 0.7821
2025-07-05 07:08:35,768 - INFO - === Epoch 64 ===
2025-07-05 07:10:04,867 - INFO - train: {'epoch': 64, 'time_epoch': 88.82483, 'eta': 3050.95543, 'eta_hours': 0.84749, 'loss': 0.56993171, 'lr': 0.0003144, 'params': 505814, 'time_iter': 0.14212, 'accuracy': 0.79256, 'f1': 0.79256, 'accuracy-SBM': 0.79256, 'auc': 0.9675}
2025-07-05 07:10:09,284 - INFO - val: {'epoch': 64, 'time_epoch': 4.36622, 'loss': 0.63016243, 'lr': 0, 'params': 505814, 'time_iter': 0.06931, 'accuracy': 0.77871, 'f1': 0.77858, 'accuracy-SBM': 0.77859, 'auc': 0.96063}
2025-07-05 07:10:18,124 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:10:18,166 - INFO - test: {'epoch': 64, 'time_epoch': 4.4419, 'loss': 0.6179629, 'lr': 0, 'params': 505814, 'time_iter': 0.07051, 'accuracy': 0.77986, 'f1': 0.77985, 'accuracy-SBM': 0.77983, 'auc': 0.96202}
2025-07-05 07:10:18,170 - INFO - > Epoch 64: took 102.4s (avg 98.6s) | Best so far: epoch 64	train_loss: 0.5699 train_accuracy-SBM: 0.7926	val_loss: 0.6302 val_accuracy-SBM: 0.7786	test_loss: 0.6180 test_accuracy-SBM: 0.7798
2025-07-05 07:10:18,170 - INFO - === Epoch 65 ===
2025-07-05 07:11:46,697 - INFO - train: {'epoch': 65, 'time_epoch': 88.0269, 'eta': 2964.22663, 'eta_hours': 0.8234, 'loss': 0.56670046, 'lr': 0.00029915, 'params': 505814, 'time_iter': 0.14084, 'accuracy': 0.79344, 'f1': 0.79344, 'accuracy-SBM': 0.79344, 'auc': 0.96789}
2025-07-05 07:11:51,259 - INFO - val: {'epoch': 65, 'time_epoch': 4.38326, 'loss': 0.63361306, 'lr': 0, 'params': 505814, 'time_iter': 0.06958, 'accuracy': 0.77789, 'f1': 0.77782, 'accuracy-SBM': 0.77775, 'auc': 0.96013}
2025-07-05 07:12:00,787 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:12:00,829 - INFO - test: {'epoch': 65, 'time_epoch': 4.7017, 'loss': 0.61290621, 'lr': 0, 'params': 505814, 'time_iter': 0.07463, 'accuracy': 0.78172, 'f1': 0.78173, 'accuracy-SBM': 0.78176, 'auc': 0.96256}
2025-07-05 07:12:00,833 - INFO - > Epoch 65: took 102.7s (avg 98.6s) | Best so far: epoch 64	train_loss: 0.5699 train_accuracy-SBM: 0.7926	val_loss: 0.6302 val_accuracy-SBM: 0.7786	test_loss: 0.6180 test_accuracy-SBM: 0.7798
2025-07-05 07:12:00,833 - INFO - === Epoch 66 ===
2025-07-05 07:13:30,077 - INFO - train: {'epoch': 66, 'time_epoch': 88.97422, 'eta': 2877.92566, 'eta_hours': 0.79942, 'loss': 0.56326929, 'lr': 0.00028412, 'params': 505814, 'time_iter': 0.14236, 'accuracy': 0.79507, 'f1': 0.79507, 'accuracy-SBM': 0.79507, 'auc': 0.96825}
2025-07-05 07:13:34,528 - INFO - val: {'epoch': 66, 'time_epoch': 4.39702, 'loss': 0.63475102, 'lr': 0, 'params': 505814, 'time_iter': 0.06979, 'accuracy': 0.77772, 'f1': 0.77761, 'accuracy-SBM': 0.77757, 'auc': 0.95995}
2025-07-05 07:13:42,532 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:13:42,574 - INFO - test: {'epoch': 66, 'time_epoch': 4.62326, 'loss': 0.6159926, 'lr': 0, 'params': 505814, 'time_iter': 0.07339, 'accuracy': 0.77926, 'f1': 0.77923, 'accuracy-SBM': 0.77923, 'auc': 0.96217}
2025-07-05 07:13:42,588 - INFO - > Epoch 66: took 101.8s (avg 98.7s) | Best so far: epoch 64	train_loss: 0.5699 train_accuracy-SBM: 0.7926	val_loss: 0.6302 val_accuracy-SBM: 0.7786	test_loss: 0.6180 test_accuracy-SBM: 0.7798
2025-07-05 07:13:42,588 - INFO - === Epoch 67 ===
2025-07-05 07:15:11,132 - INFO - train: {'epoch': 67, 'time_epoch': 88.27352, 'eta': 2791.21634, 'eta_hours': 0.77534, 'loss': 0.56386029, 'lr': 0.00026933, 'params': 505814, 'time_iter': 0.14124, 'accuracy': 0.79508, 'f1': 0.79508, 'accuracy-SBM': 0.79508, 'auc': 0.96818}
2025-07-05 07:15:15,604 - INFO - val: {'epoch': 67, 'time_epoch': 4.40431, 'loss': 0.6326825, 'lr': 0, 'params': 505814, 'time_iter': 0.06991, 'accuracy': 0.7787, 'f1': 0.77861, 'accuracy-SBM': 0.77864, 'auc': 0.96034}
2025-07-05 07:15:24,795 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:15:24,838 - INFO - test: {'epoch': 67, 'time_epoch': 4.65285, 'loss': 0.61519445, 'lr': 0, 'params': 505814, 'time_iter': 0.07385, 'accuracy': 0.78094, 'f1': 0.78096, 'accuracy-SBM': 0.78096, 'auc': 0.96231}
2025-07-05 07:15:24,859 - INFO - > Epoch 67: took 102.3s (avg 98.7s) | Best so far: epoch 67	train_loss: 0.5639 train_accuracy-SBM: 0.7951	val_loss: 0.6327 val_accuracy-SBM: 0.7786	test_loss: 0.6152 test_accuracy-SBM: 0.7810
2025-07-05 07:15:24,859 - INFO - === Epoch 68 ===
2025-07-05 07:16:53,449 - INFO - train: {'epoch': 68, 'time_epoch': 88.32395, 'eta': 2704.48433, 'eta_hours': 0.75125, 'loss': 0.56107462, 'lr': 0.00025479, 'params': 505814, 'time_iter': 0.14132, 'accuracy': 0.79565, 'f1': 0.79565, 'accuracy-SBM': 0.79565, 'auc': 0.96851}
2025-07-05 07:16:57,783 - INFO - val: {'epoch': 68, 'time_epoch': 4.28661, 'loss': 0.63301493, 'lr': 0, 'params': 505814, 'time_iter': 0.06804, 'accuracy': 0.77959, 'f1': 0.77945, 'accuracy-SBM': 0.77944, 'auc': 0.9606}
2025-07-05 07:17:06,377 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:17:06,422 - INFO - test: {'epoch': 68, 'time_epoch': 4.63314, 'loss': 0.6134162, 'lr': 0, 'params': 505814, 'time_iter': 0.07354, 'accuracy': 0.78167, 'f1': 0.78167, 'accuracy-SBM': 0.78168, 'auc': 0.96279}
2025-07-05 07:17:06,425 - INFO - > Epoch 68: took 101.6s (avg 98.8s) | Best so far: epoch 68	train_loss: 0.5611 train_accuracy-SBM: 0.7956	val_loss: 0.6330 val_accuracy-SBM: 0.7794	test_loss: 0.6134 test_accuracy-SBM: 0.7817
2025-07-05 07:17:06,425 - INFO - === Epoch 69 ===
2025-07-05 07:18:33,612 - INFO - train: {'epoch': 69, 'time_epoch': 86.92601, 'eta': 2617.10772, 'eta_hours': 0.72697, 'loss': 0.56023975, 'lr': 0.00024052, 'params': 505814, 'time_iter': 0.13908, 'accuracy': 0.79637, 'f1': 0.79638, 'accuracy-SBM': 0.79637, 'auc': 0.9686}
2025-07-05 07:18:37,989 - INFO - val: {'epoch': 69, 'time_epoch': 4.3148, 'loss': 0.63723612, 'lr': 0, 'params': 505814, 'time_iter': 0.06849, 'accuracy': 0.78001, 'f1': 0.7799, 'accuracy-SBM': 0.77992, 'auc': 0.96009}
2025-07-05 07:18:46,616 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:18:46,656 - INFO - test: {'epoch': 69, 'time_epoch': 4.59653, 'loss': 0.61789872, 'lr': 0, 'params': 505814, 'time_iter': 0.07296, 'accuracy': 0.78138, 'f1': 0.78138, 'accuracy-SBM': 0.78138, 'auc': 0.96227}
2025-07-05 07:18:46,658 - INFO - > Epoch 69: took 100.2s (avg 98.8s) | Best so far: epoch 69	train_loss: 0.5602 train_accuracy-SBM: 0.7964	val_loss: 0.6372 val_accuracy-SBM: 0.7799	test_loss: 0.6179 test_accuracy-SBM: 0.7814
2025-07-05 07:18:46,658 - INFO - === Epoch 70 ===
2025-07-05 07:20:14,103 - INFO - train: {'epoch': 70, 'time_epoch': 87.18221, 'eta': 2529.84844, 'eta_hours': 0.70274, 'loss': 0.556375, 'lr': 0.00022653, 'params': 505814, 'time_iter': 0.13949, 'accuracy': 0.7977, 'f1': 0.7977, 'accuracy-SBM': 0.7977, 'auc': 0.96903}
2025-07-05 07:20:18,393 - INFO - val: {'epoch': 70, 'time_epoch': 4.21963, 'loss': 0.6353214, 'lr': 0, 'params': 505814, 'time_iter': 0.06698, 'accuracy': 0.77911, 'f1': 0.77894, 'accuracy-SBM': 0.77898, 'auc': 0.96026}
2025-07-05 07:20:26,556 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:20:26,602 - INFO - test: {'epoch': 70, 'time_epoch': 4.65243, 'loss': 0.61534654, 'lr': 0, 'params': 505814, 'time_iter': 0.07385, 'accuracy': 0.78121, 'f1': 0.78119, 'accuracy-SBM': 0.78118, 'auc': 0.96255}
2025-07-05 07:20:26,606 - INFO - > Epoch 70: took 99.9s (avg 98.8s) | Best so far: epoch 69	train_loss: 0.5602 train_accuracy-SBM: 0.7964	val_loss: 0.6372 val_accuracy-SBM: 0.7799	test_loss: 0.6179 test_accuracy-SBM: 0.7814
2025-07-05 07:20:26,607 - INFO - === Epoch 71 ===
2025-07-05 07:21:56,379 - INFO - train: {'epoch': 71, 'time_epoch': 89.49212, 'eta': 2443.48961, 'eta_hours': 0.67875, 'loss': 0.55346122, 'lr': 0.00021284, 'params': 505814, 'time_iter': 0.14319, 'accuracy': 0.79851, 'f1': 0.7985, 'accuracy-SBM': 0.79851, 'auc': 0.96935}
2025-07-05 07:22:00,878 - INFO - val: {'epoch': 71, 'time_epoch': 4.44211, 'loss': 0.63925631, 'lr': 0, 'params': 505814, 'time_iter': 0.07051, 'accuracy': 0.77931, 'f1': 0.77916, 'accuracy-SBM': 0.77916, 'auc': 0.95974}
2025-07-05 07:22:07,580 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:22:07,619 - INFO - test: {'epoch': 71, 'time_epoch': 4.69636, 'loss': 0.62083287, 'lr': 0, 'params': 505814, 'time_iter': 0.07455, 'accuracy': 0.78026, 'f1': 0.78025, 'accuracy-SBM': 0.78024, 'auc': 0.96189}
2025-07-05 07:22:07,621 - INFO - > Epoch 71: took 101.0s (avg 98.8s) | Best so far: epoch 69	train_loss: 0.5602 train_accuracy-SBM: 0.7964	val_loss: 0.6372 val_accuracy-SBM: 0.7799	test_loss: 0.6179 test_accuracy-SBM: 0.7814
2025-07-05 07:22:07,621 - INFO - === Epoch 72 ===
2025-07-05 07:23:36,693 - INFO - train: {'epoch': 72, 'time_epoch': 88.80966, 'eta': 2356.79252, 'eta_hours': 0.65466, 'loss': 0.55337596, 'lr': 0.00019946, 'params': 505814, 'time_iter': 0.1421, 'accuracy': 0.79851, 'f1': 0.79851, 'accuracy-SBM': 0.79851, 'auc': 0.96936}
2025-07-05 07:23:41,093 - INFO - val: {'epoch': 72, 'time_epoch': 4.34767, 'loss': 0.64107661, 'lr': 0, 'params': 505814, 'time_iter': 0.06901, 'accuracy': 0.77859, 'f1': 0.77852, 'accuracy-SBM': 0.77855, 'auc': 0.95965}
2025-07-05 07:23:49,000 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:23:49,044 - INFO - test: {'epoch': 72, 'time_epoch': 4.63628, 'loss': 0.62655239, 'lr': 0, 'params': 505814, 'time_iter': 0.07359, 'accuracy': 0.77958, 'f1': 0.77955, 'accuracy-SBM': 0.77957, 'auc': 0.96123}
2025-07-05 07:23:49,053 - INFO - > Epoch 72: took 101.4s (avg 98.9s) | Best so far: epoch 69	train_loss: 0.5602 train_accuracy-SBM: 0.7964	val_loss: 0.6372 val_accuracy-SBM: 0.7799	test_loss: 0.6179 test_accuracy-SBM: 0.7814
2025-07-05 07:23:49,053 - INFO - === Epoch 73 ===
2025-07-05 07:25:18,078 - INFO - train: {'epoch': 73, 'time_epoch': 88.75795, 'eta': 2270.02016, 'eta_hours': 0.63056, 'loss': 0.55120501, 'lr': 0.00018641, 'params': 505814, 'time_iter': 0.14201, 'accuracy': 0.79929, 'f1': 0.79929, 'accuracy-SBM': 0.79929, 'auc': 0.96961}
2025-07-05 07:25:22,554 - INFO - val: {'epoch': 73, 'time_epoch': 4.41017, 'loss': 0.64173478, 'lr': 0, 'params': 505814, 'time_iter': 0.07, 'accuracy': 0.77803, 'f1': 0.77791, 'accuracy-SBM': 0.77791, 'auc': 0.95954}
2025-07-05 07:25:28,496 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:25:28,539 - INFO - test: {'epoch': 73, 'time_epoch': 4.65108, 'loss': 0.62236057, 'lr': 0, 'params': 505814, 'time_iter': 0.07383, 'accuracy': 0.78227, 'f1': 0.78229, 'accuracy-SBM': 0.7823, 'auc': 0.96171}
2025-07-05 07:25:28,541 - INFO - > Epoch 73: took 99.5s (avg 98.9s) | Best so far: epoch 69	train_loss: 0.5602 train_accuracy-SBM: 0.7964	val_loss: 0.6372 val_accuracy-SBM: 0.7799	test_loss: 0.6179 test_accuracy-SBM: 0.7814
2025-07-05 07:25:28,541 - INFO - === Epoch 74 ===
2025-07-05 07:26:58,118 - INFO - train: {'epoch': 74, 'time_epoch': 89.2988, 'eta': 2183.37514, 'eta_hours': 0.60649, 'loss': 0.54746433, 'lr': 0.00017371, 'params': 505814, 'time_iter': 0.14288, 'accuracy': 0.80048, 'f1': 0.80048, 'accuracy-SBM': 0.80048, 'auc': 0.97002}
2025-07-05 07:27:02,559 - INFO - val: {'epoch': 74, 'time_epoch': 4.37318, 'loss': 0.64332806, 'lr': 0, 'params': 505814, 'time_iter': 0.06942, 'accuracy': 0.77931, 'f1': 0.77923, 'accuracy-SBM': 0.77918, 'auc': 0.95969}
2025-07-05 07:27:11,310 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:27:11,360 - INFO - test: {'epoch': 74, 'time_epoch': 4.63307, 'loss': 0.62212083, 'lr': 0, 'params': 505814, 'time_iter': 0.07354, 'accuracy': 0.78136, 'f1': 0.78138, 'accuracy-SBM': 0.78139, 'auc': 0.96205}
2025-07-05 07:27:11,362 - INFO - > Epoch 74: took 102.8s (avg 98.9s) | Best so far: epoch 69	train_loss: 0.5602 train_accuracy-SBM: 0.7964	val_loss: 0.6372 val_accuracy-SBM: 0.7799	test_loss: 0.6179 test_accuracy-SBM: 0.7814
2025-07-05 07:27:11,362 - INFO - === Epoch 75 ===
2025-07-05 07:28:38,749 - INFO - train: {'epoch': 75, 'time_epoch': 87.1279, 'eta': 2095.97473, 'eta_hours': 0.58222, 'loss': 0.54818412, 'lr': 0.00016136, 'params': 505814, 'time_iter': 0.1394, 'accuracy': 0.80044, 'f1': 0.80044, 'accuracy-SBM': 0.80044, 'auc': 0.96995}
2025-07-05 07:28:43,173 - INFO - val: {'epoch': 75, 'time_epoch': 4.36367, 'loss': 0.63744062, 'lr': 0, 'params': 505814, 'time_iter': 0.06926, 'accuracy': 0.77995, 'f1': 0.77987, 'accuracy-SBM': 0.77988, 'auc': 0.96016}
2025-07-05 07:28:50,505 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:28:50,548 - INFO - test: {'epoch': 75, 'time_epoch': 4.46985, 'loss': 0.62231006, 'lr': 0, 'params': 505814, 'time_iter': 0.07095, 'accuracy': 0.78164, 'f1': 0.78163, 'accuracy-SBM': 0.78164, 'auc': 0.96184}
2025-07-05 07:28:50,555 - INFO - > Epoch 75: took 99.2s (avg 98.9s) | Best so far: epoch 69	train_loss: 0.5602 train_accuracy-SBM: 0.7964	val_loss: 0.6372 val_accuracy-SBM: 0.7799	test_loss: 0.6179 test_accuracy-SBM: 0.7814
2025-07-05 07:28:50,555 - INFO - === Epoch 76 ===
2025-07-05 07:30:18,827 - INFO - train: {'epoch': 76, 'time_epoch': 88.00531, 'eta': 2008.84348, 'eta_hours': 0.55801, 'loss': 0.5438491, 'lr': 0.00014938, 'params': 505814, 'time_iter': 0.14081, 'accuracy': 0.80205, 'f1': 0.80205, 'accuracy-SBM': 0.80205, 'auc': 0.97042}
2025-07-05 07:30:23,283 - INFO - val: {'epoch': 76, 'time_epoch': 4.38847, 'loss': 0.64465077, 'lr': 0, 'params': 505814, 'time_iter': 0.06966, 'accuracy': 0.77894, 'f1': 0.77878, 'accuracy-SBM': 0.7788, 'auc': 0.95962}
2025-07-05 07:30:32,299 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:30:32,343 - INFO - test: {'epoch': 76, 'time_epoch': 4.66187, 'loss': 0.62243016, 'lr': 0, 'params': 505814, 'time_iter': 0.074, 'accuracy': 0.78251, 'f1': 0.78253, 'accuracy-SBM': 0.78249, 'auc': 0.96204}
2025-07-05 07:30:32,345 - INFO - > Epoch 76: took 101.8s (avg 99.0s) | Best so far: epoch 69	train_loss: 0.5602 train_accuracy-SBM: 0.7964	val_loss: 0.6372 val_accuracy-SBM: 0.7799	test_loss: 0.6179 test_accuracy-SBM: 0.7814
2025-07-05 07:30:32,345 - INFO - === Epoch 77 ===
2025-07-05 07:32:01,205 - INFO - train: {'epoch': 77, 'time_epoch': 88.58542, 'eta': 1921.85345, 'eta_hours': 0.53385, 'loss': 0.54395056, 'lr': 0.00013779, 'params': 505814, 'time_iter': 0.14174, 'accuracy': 0.80228, 'f1': 0.80228, 'accuracy-SBM': 0.80228, 'auc': 0.9704}
2025-07-05 07:32:05,641 - INFO - val: {'epoch': 77, 'time_epoch': 4.37428, 'loss': 0.6387074, 'lr': 0, 'params': 505814, 'time_iter': 0.06943, 'accuracy': 0.77828, 'f1': 0.77815, 'accuracy-SBM': 0.77815, 'auc': 0.95971}
2025-07-05 07:32:14,078 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:32:14,123 - INFO - test: {'epoch': 77, 'time_epoch': 4.49247, 'loss': 0.61985714, 'lr': 0, 'params': 505814, 'time_iter': 0.07131, 'accuracy': 0.78281, 'f1': 0.78281, 'accuracy-SBM': 0.7828, 'auc': 0.96183}
2025-07-05 07:32:14,126 - INFO - > Epoch 77: took 101.8s (avg 99.0s) | Best so far: epoch 69	train_loss: 0.5602 train_accuracy-SBM: 0.7964	val_loss: 0.6372 val_accuracy-SBM: 0.7799	test_loss: 0.6179 test_accuracy-SBM: 0.7814
2025-07-05 07:32:14,126 - INFO - === Epoch 78 ===
2025-07-05 07:33:38,332 - INFO - train: {'epoch': 78, 'time_epoch': 83.9584, 'eta': 1833.59306, 'eta_hours': 0.50933, 'loss': 0.54088905, 'lr': 0.00012659, 'params': 505814, 'time_iter': 0.13433, 'accuracy': 0.80281, 'f1': 0.80281, 'accuracy-SBM': 0.80281, 'auc': 0.97074}
2025-07-05 07:33:42,479 - INFO - val: {'epoch': 78, 'time_epoch': 4.10221, 'loss': 0.63982514, 'lr': 0, 'params': 505814, 'time_iter': 0.06511, 'accuracy': 0.78025, 'f1': 0.78009, 'accuracy-SBM': 0.7801, 'auc': 0.96009}
2025-07-05 07:33:48,260 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:33:48,298 - INFO - test: {'epoch': 78, 'time_epoch': 4.3719, 'loss': 0.6248727, 'lr': 0, 'params': 505814, 'time_iter': 0.0694, 'accuracy': 0.78245, 'f1': 0.78243, 'accuracy-SBM': 0.78244, 'auc': 0.96165}
2025-07-05 07:33:48,300 - INFO - > Epoch 78: took 94.2s (avg 98.9s) | Best so far: epoch 78	train_loss: 0.5409 train_accuracy-SBM: 0.8028	val_loss: 0.6398 val_accuracy-SBM: 0.7801	test_loss: 0.6249 test_accuracy-SBM: 0.7824
2025-07-05 07:33:48,300 - INFO - === Epoch 79 ===
2025-07-05 07:35:17,176 - INFO - train: {'epoch': 79, 'time_epoch': 88.48574, 'eta': 1746.57205, 'eta_hours': 0.48516, 'loss': 0.53975195, 'lr': 0.0001158, 'params': 505814, 'time_iter': 0.14158, 'accuracy': 0.80352, 'f1': 0.80352, 'accuracy-SBM': 0.80352, 'auc': 0.97087}
2025-07-05 07:35:21,702 - INFO - val: {'epoch': 79, 'time_epoch': 4.46102, 'loss': 0.63796815, 'lr': 0, 'params': 505814, 'time_iter': 0.07081, 'accuracy': 0.77986, 'f1': 0.77975, 'accuracy-SBM': 0.77973, 'auc': 0.95991}
2025-07-05 07:35:32,137 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:35:32,181 - INFO - test: {'epoch': 79, 'time_epoch': 4.67173, 'loss': 0.61607743, 'lr': 0, 'params': 505814, 'time_iter': 0.07415, 'accuracy': 0.78232, 'f1': 0.78233, 'accuracy-SBM': 0.78235, 'auc': 0.96241}
2025-07-05 07:35:32,188 - INFO - > Epoch 79: took 103.9s (avg 99.0s) | Best so far: epoch 78	train_loss: 0.5409 train_accuracy-SBM: 0.8028	val_loss: 0.6398 val_accuracy-SBM: 0.7801	test_loss: 0.6249 test_accuracy-SBM: 0.7824
2025-07-05 07:35:32,188 - INFO - === Epoch 80 ===
2025-07-05 07:37:01,840 - INFO - train: {'epoch': 80, 'time_epoch': 89.38057, 'eta': 1659.72477, 'eta_hours': 0.46103, 'loss': 0.54096964, 'lr': 0.00010543, 'params': 505814, 'time_iter': 0.14301, 'accuracy': 0.80296, 'f1': 0.80296, 'accuracy-SBM': 0.80296, 'auc': 0.97074}
2025-07-05 07:37:06,390 - INFO - val: {'epoch': 80, 'time_epoch': 4.48466, 'loss': 0.6419092, 'lr': 0, 'params': 505814, 'time_iter': 0.07119, 'accuracy': 0.7803, 'f1': 0.78019, 'accuracy-SBM': 0.78018, 'auc': 0.95973}
2025-07-05 07:37:15,249 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:37:15,297 - INFO - test: {'epoch': 80, 'time_epoch': 4.7325, 'loss': 0.62034812, 'lr': 0, 'params': 505814, 'time_iter': 0.07512, 'accuracy': 0.78335, 'f1': 0.78335, 'accuracy-SBM': 0.78336, 'auc': 0.96213}
2025-07-05 07:37:15,300 - INFO - > Epoch 80: took 103.1s (avg 99.1s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 07:37:15,300 - INFO - === Epoch 81 ===
2025-07-05 07:38:40,072 - INFO - train: {'epoch': 81, 'time_epoch': 84.52764, 'eta': 1571.75043, 'eta_hours': 0.4366, 'loss': 0.537293, 'lr': 9.549e-05, 'params': 505814, 'time_iter': 0.13524, 'accuracy': 0.80406, 'f1': 0.80407, 'accuracy-SBM': 0.80407, 'auc': 0.97113}
2025-07-05 07:38:44,264 - INFO - val: {'epoch': 81, 'time_epoch': 4.14801, 'loss': 0.6414524, 'lr': 0, 'params': 505814, 'time_iter': 0.06584, 'accuracy': 0.77898, 'f1': 0.77883, 'accuracy-SBM': 0.77884, 'auc': 0.95983}
2025-07-05 07:38:50,210 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:38:50,249 - INFO - test: {'epoch': 81, 'time_epoch': 4.35748, 'loss': 0.62299129, 'lr': 0, 'params': 505814, 'time_iter': 0.06917, 'accuracy': 0.78365, 'f1': 0.78363, 'accuracy-SBM': 0.78361, 'auc': 0.96181}
2025-07-05 07:38:50,251 - INFO - > Epoch 81: took 95.0s (avg 99.0s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 07:38:50,251 - INFO - === Epoch 82 ===
2025-07-05 07:40:16,924 - INFO - train: {'epoch': 82, 'time_epoch': 86.28879, 'eta': 1484.21986, 'eta_hours': 0.41228, 'loss': 0.53744847, 'lr': 8.6e-05, 'params': 505814, 'time_iter': 0.13806, 'accuracy': 0.80425, 'f1': 0.80425, 'accuracy-SBM': 0.80425, 'auc': 0.9711}
2025-07-05 07:40:21,363 - INFO - val: {'epoch': 82, 'time_epoch': 4.37266, 'loss': 0.64016691, 'lr': 0, 'params': 505814, 'time_iter': 0.06941, 'accuracy': 0.77985, 'f1': 0.77974, 'accuracy-SBM': 0.77975, 'auc': 0.95978}
2025-07-05 07:40:30,028 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:40:30,073 - INFO - test: {'epoch': 82, 'time_epoch': 4.63507, 'loss': 0.61989718, 'lr': 0, 'params': 505814, 'time_iter': 0.07357, 'accuracy': 0.7828, 'f1': 0.7828, 'accuracy-SBM': 0.78279, 'auc': 0.96208}
2025-07-05 07:40:30,075 - INFO - > Epoch 82: took 99.8s (avg 99.0s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 07:40:30,075 - INFO - === Epoch 83 ===
2025-07-05 07:42:00,230 - INFO - train: {'epoch': 83, 'time_epoch': 89.77133, 'eta': 1397.3822, 'eta_hours': 0.38816, 'loss': 0.53710208, 'lr': 7.695e-05, 'params': 505814, 'time_iter': 0.14363, 'accuracy': 0.80423, 'f1': 0.80423, 'accuracy-SBM': 0.80423, 'auc': 0.97115}
2025-07-05 07:42:04,620 - INFO - val: {'epoch': 83, 'time_epoch': 4.32305, 'loss': 0.64542424, 'lr': 0, 'params': 505814, 'time_iter': 0.06862, 'accuracy': 0.77915, 'f1': 0.77905, 'accuracy-SBM': 0.77904, 'auc': 0.95934}
2025-07-05 07:42:13,229 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:42:13,275 - INFO - test: {'epoch': 83, 'time_epoch': 4.67668, 'loss': 0.6213781, 'lr': 0, 'params': 505814, 'time_iter': 0.07423, 'accuracy': 0.78296, 'f1': 0.78296, 'accuracy-SBM': 0.78296, 'auc': 0.96198}
2025-07-05 07:42:13,280 - INFO - > Epoch 83: took 103.2s (avg 99.1s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 07:42:13,280 - INFO - === Epoch 84 ===
2025-07-05 07:43:45,283 - INFO - train: {'epoch': 84, 'time_epoch': 91.72334, 'eta': 1310.81998, 'eta_hours': 0.36412, 'loss': 0.53457131, 'lr': 6.837e-05, 'params': 505814, 'time_iter': 0.14676, 'accuracy': 0.80539, 'f1': 0.80539, 'accuracy-SBM': 0.80539, 'auc': 0.97141}
2025-07-05 07:43:49,831 - INFO - val: {'epoch': 84, 'time_epoch': 4.46427, 'loss': 0.64289611, 'lr': 0, 'params': 505814, 'time_iter': 0.07086, 'accuracy': 0.78003, 'f1': 0.77995, 'accuracy-SBM': 0.77996, 'auc': 0.95963}
2025-07-05 07:43:56,735 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:43:56,786 - INFO - test: {'epoch': 84, 'time_epoch': 4.7855, 'loss': 0.6196986, 'lr': 0, 'params': 505814, 'time_iter': 0.07596, 'accuracy': 0.78274, 'f1': 0.78274, 'accuracy-SBM': 0.78274, 'auc': 0.96222}
2025-07-05 07:43:56,788 - INFO - > Epoch 84: took 103.5s (avg 99.1s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 07:43:56,788 - INFO - === Epoch 85 ===
2025-07-05 07:45:26,918 - INFO - train: {'epoch': 85, 'time_epoch': 89.86016, 'eta': 1223.83442, 'eta_hours': 0.33995, 'loss': 0.53248468, 'lr': 6.026e-05, 'params': 505814, 'time_iter': 0.14378, 'accuracy': 0.80593, 'f1': 0.80593, 'accuracy-SBM': 0.80593, 'auc': 0.97165}
2025-07-05 07:45:31,356 - INFO - val: {'epoch': 85, 'time_epoch': 4.38761, 'loss': 0.64498015, 'lr': 0, 'params': 505814, 'time_iter': 0.06964, 'accuracy': 0.77872, 'f1': 0.77861, 'accuracy-SBM': 0.77858, 'auc': 0.95921}
2025-07-05 07:45:39,720 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:45:39,762 - INFO - test: {'epoch': 85, 'time_epoch': 4.6849, 'loss': 0.61956134, 'lr': 0, 'params': 505814, 'time_iter': 0.07436, 'accuracy': 0.7828, 'f1': 0.78277, 'accuracy-SBM': 0.78278, 'auc': 0.96206}
2025-07-05 07:45:39,764 - INFO - > Epoch 85: took 103.0s (avg 99.2s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 07:45:39,764 - INFO - === Epoch 86 ===
2025-07-05 07:47:09,193 - INFO - train: {'epoch': 86, 'time_epoch': 89.1616, 'eta': 1136.6784, 'eta_hours': 0.31574, 'loss': 0.53201038, 'lr': 5.264e-05, 'params': 505814, 'time_iter': 0.14266, 'accuracy': 0.80635, 'f1': 0.80635, 'accuracy-SBM': 0.80635, 'auc': 0.97169}
2025-07-05 07:47:13,654 - INFO - val: {'epoch': 86, 'time_epoch': 4.39899, 'loss': 0.64082264, 'lr': 0, 'params': 505814, 'time_iter': 0.06983, 'accuracy': 0.78001, 'f1': 0.77991, 'accuracy-SBM': 0.77991, 'auc': 0.95972}
2025-07-05 07:47:21,461 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:47:21,502 - INFO - test: {'epoch': 86, 'time_epoch': 4.63194, 'loss': 0.62317127, 'lr': 0, 'params': 505814, 'time_iter': 0.07352, 'accuracy': 0.78215, 'f1': 0.78215, 'accuracy-SBM': 0.78215, 'auc': 0.96169}
2025-07-05 07:47:21,504 - INFO - > Epoch 86: took 101.7s (avg 99.2s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 07:47:21,504 - INFO - === Epoch 87 ===
2025-07-05 07:48:50,198 - INFO - train: {'epoch': 87, 'time_epoch': 88.42626, 'eta': 1049.37653, 'eta_hours': 0.29149, 'loss': 0.53262829, 'lr': 4.55e-05, 'params': 505814, 'time_iter': 0.14148, 'accuracy': 0.80627, 'f1': 0.80627, 'accuracy-SBM': 0.80627, 'auc': 0.97163}
2025-07-05 07:48:54,667 - INFO - val: {'epoch': 87, 'time_epoch': 4.4059, 'loss': 0.64401976, 'lr': 0, 'params': 505814, 'time_iter': 0.06993, 'accuracy': 0.77949, 'f1': 0.77941, 'accuracy-SBM': 0.77939, 'auc': 0.95949}
2025-07-05 07:49:05,067 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:49:05,111 - INFO - test: {'epoch': 87, 'time_epoch': 4.62322, 'loss': 0.62177605, 'lr': 0, 'params': 505814, 'time_iter': 0.07338, 'accuracy': 0.7821, 'f1': 0.78209, 'accuracy-SBM': 0.78211, 'auc': 0.96193}
2025-07-05 07:49:05,121 - INFO - > Epoch 87: took 103.6s (avg 99.2s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 07:49:05,121 - INFO - === Epoch 88 ===
2025-07-05 07:50:31,810 - INFO - train: {'epoch': 88, 'time_epoch': 86.31387, 'eta': 961.78831, 'eta_hours': 0.26716, 'loss': 0.53175548, 'lr': 3.886e-05, 'params': 505814, 'time_iter': 0.1381, 'accuracy': 0.80661, 'f1': 0.80661, 'accuracy-SBM': 0.80661, 'auc': 0.97171}
2025-07-05 07:50:36,203 - INFO - val: {'epoch': 88, 'time_epoch': 4.33122, 'loss': 0.64032278, 'lr': 0, 'params': 505814, 'time_iter': 0.06875, 'accuracy': 0.77976, 'f1': 0.77965, 'accuracy-SBM': 0.77965, 'auc': 0.95991}
2025-07-05 07:50:45,184 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:50:45,229 - INFO - test: {'epoch': 88, 'time_epoch': 4.48256, 'loss': 0.62113057, 'lr': 0, 'params': 505814, 'time_iter': 0.07115, 'accuracy': 0.78289, 'f1': 0.78288, 'accuracy-SBM': 0.78289, 'auc': 0.96201}
2025-07-05 07:50:45,235 - INFO - > Epoch 88: took 100.1s (avg 99.3s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 07:50:45,235 - INFO - === Epoch 89 ===
2025-07-05 07:52:12,713 - INFO - train: {'epoch': 89, 'time_epoch': 87.21354, 'eta': 874.32837, 'eta_hours': 0.24287, 'loss': 0.53023491, 'lr': 3.272e-05, 'params': 505814, 'time_iter': 0.13954, 'accuracy': 0.80639, 'f1': 0.80639, 'accuracy-SBM': 0.80639, 'auc': 0.97188}
2025-07-05 07:52:17,138 - INFO - val: {'epoch': 89, 'time_epoch': 4.37078, 'loss': 0.64667723, 'lr': 0, 'params': 505814, 'time_iter': 0.06938, 'accuracy': 0.77882, 'f1': 0.77872, 'accuracy-SBM': 0.77873, 'auc': 0.95919}
2025-07-05 07:52:26,171 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:52:26,210 - INFO - test: {'epoch': 89, 'time_epoch': 4.63037, 'loss': 0.62216947, 'lr': 0, 'params': 505814, 'time_iter': 0.0735, 'accuracy': 0.78321, 'f1': 0.78321, 'accuracy-SBM': 0.78321, 'auc': 0.9619}
2025-07-05 07:52:26,230 - INFO - > Epoch 89: took 101.0s (avg 99.3s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 07:52:26,230 - INFO - === Epoch 90 ===
2025-07-05 07:53:52,816 - INFO - train: {'epoch': 90, 'time_epoch': 86.32139, 'eta': 786.78561, 'eta_hours': 0.21855, 'loss': 0.53021436, 'lr': 2.709e-05, 'params': 505814, 'time_iter': 0.13811, 'accuracy': 0.80689, 'f1': 0.80689, 'accuracy-SBM': 0.80689, 'auc': 0.97189}
2025-07-05 07:53:57,102 - INFO - val: {'epoch': 90, 'time_epoch': 4.23408, 'loss': 0.64099376, 'lr': 0, 'params': 505814, 'time_iter': 0.06721, 'accuracy': 0.78011, 'f1': 0.78002, 'accuracy-SBM': 0.78003, 'auc': 0.9598}
2025-07-05 07:54:05,916 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:54:05,961 - INFO - test: {'epoch': 90, 'time_epoch': 4.58718, 'loss': 0.62335228, 'lr': 0, 'params': 505814, 'time_iter': 0.07281, 'accuracy': 0.78181, 'f1': 0.78182, 'accuracy-SBM': 0.78183, 'auc': 0.96177}
2025-07-05 07:54:05,967 - INFO - > Epoch 90: took 99.7s (avg 99.3s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 07:54:05,967 - INFO - === Epoch 91 ===
2025-07-05 07:55:32,919 - INFO - train: {'epoch': 91, 'time_epoch': 86.67835, 'eta': 699.30044, 'eta_hours': 0.19425, 'loss': 0.52882149, 'lr': 2.198e-05, 'params': 505814, 'time_iter': 0.13869, 'accuracy': 0.80716, 'f1': 0.80716, 'accuracy-SBM': 0.80716, 'auc': 0.97204}
2025-07-05 07:55:37,293 - INFO - val: {'epoch': 91, 'time_epoch': 4.32391, 'loss': 0.6416362, 'lr': 0, 'params': 505814, 'time_iter': 0.06863, 'accuracy': 0.7794, 'f1': 0.7793, 'accuracy-SBM': 0.7793, 'auc': 0.95976}
2025-07-05 07:55:43,739 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:55:43,776 - INFO - test: {'epoch': 91, 'time_epoch': 4.62772, 'loss': 0.61996919, 'lr': 0, 'params': 505814, 'time_iter': 0.07346, 'accuracy': 0.78301, 'f1': 0.783, 'accuracy-SBM': 0.783, 'auc': 0.96214}
2025-07-05 07:55:43,778 - INFO - > Epoch 91: took 97.8s (avg 99.3s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 07:55:43,778 - INFO - === Epoch 92 ===
2025-07-05 07:57:10,100 - INFO - train: {'epoch': 92, 'time_epoch': 86.08513, 'eta': 611.78797, 'eta_hours': 0.16994, 'loss': 0.53015698, 'lr': 1.74e-05, 'params': 505814, 'time_iter': 0.13774, 'accuracy': 0.8068, 'f1': 0.8068, 'accuracy-SBM': 0.8068, 'auc': 0.97188}
2025-07-05 07:57:14,482 - INFO - val: {'epoch': 92, 'time_epoch': 4.24119, 'loss': 0.64515472, 'lr': 0, 'params': 505814, 'time_iter': 0.06732, 'accuracy': 0.77865, 'f1': 0.77853, 'accuracy-SBM': 0.77854, 'auc': 0.95941}
2025-07-05 07:57:23,394 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:57:23,436 - INFO - test: {'epoch': 92, 'time_epoch': 4.58063, 'loss': 0.62312127, 'lr': 0, 'params': 505814, 'time_iter': 0.07271, 'accuracy': 0.78251, 'f1': 0.7825, 'accuracy-SBM': 0.7825, 'auc': 0.96182}
2025-07-05 07:57:23,446 - INFO - > Epoch 92: took 99.7s (avg 99.3s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 07:57:23,446 - INFO - === Epoch 93 ===
2025-07-05 07:58:50,504 - INFO - train: {'epoch': 93, 'time_epoch': 86.79142, 'eta': 524.35095, 'eta_hours': 0.14565, 'loss': 0.5273846, 'lr': 1.334e-05, 'params': 505814, 'time_iter': 0.13887, 'accuracy': 0.80751, 'f1': 0.80751, 'accuracy-SBM': 0.80751, 'auc': 0.97219}
2025-07-05 07:58:54,928 - INFO - val: {'epoch': 93, 'time_epoch': 4.35827, 'loss': 0.64060821, 'lr': 0, 'params': 505814, 'time_iter': 0.06918, 'accuracy': 0.77913, 'f1': 0.77901, 'accuracy-SBM': 0.779, 'auc': 0.95973}
2025-07-05 07:59:02,620 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 07:59:02,665 - INFO - test: {'epoch': 93, 'time_epoch': 4.54338, 'loss': 0.62127646, 'lr': 0, 'params': 505814, 'time_iter': 0.07212, 'accuracy': 0.78276, 'f1': 0.78274, 'accuracy-SBM': 0.78276, 'auc': 0.96188}
2025-07-05 07:59:02,672 - INFO - > Epoch 93: took 99.2s (avg 99.3s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 07:59:02,672 - INFO - === Epoch 94 ===
2025-07-05 08:00:29,808 - INFO - train: {'epoch': 94, 'time_epoch': 86.85616, 'eta': 436.93093, 'eta_hours': 0.12137, 'loss': 0.52774203, 'lr': 9.81e-06, 'params': 505814, 'time_iter': 0.13897, 'accuracy': 0.80756, 'f1': 0.80756, 'accuracy-SBM': 0.80756, 'auc': 0.97215}
2025-07-05 08:00:34,211 - INFO - val: {'epoch': 94, 'time_epoch': 4.33958, 'loss': 0.64370721, 'lr': 0, 'params': 505814, 'time_iter': 0.06888, 'accuracy': 0.77894, 'f1': 0.77881, 'accuracy-SBM': 0.7788, 'auc': 0.95953}
2025-07-05 08:00:44,252 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 08:00:44,291 - INFO - test: {'epoch': 94, 'time_epoch': 4.63502, 'loss': 0.62288272, 'lr': 0, 'params': 505814, 'time_iter': 0.07357, 'accuracy': 0.78264, 'f1': 0.78263, 'accuracy-SBM': 0.78262, 'auc': 0.96182}
2025-07-05 08:00:44,293 - INFO - > Epoch 94: took 101.6s (avg 99.3s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 08:00:44,293 - INFO - === Epoch 95 ===
2025-07-05 08:02:11,086 - INFO - train: {'epoch': 95, 'time_epoch': 86.52919, 'eta': 349.50904, 'eta_hours': 0.09709, 'loss': 0.52761899, 'lr': 6.82e-06, 'params': 505814, 'time_iter': 0.13845, 'accuracy': 0.80753, 'f1': 0.80753, 'accuracy-SBM': 0.80754, 'auc': 0.97216}
2025-07-05 08:02:15,271 - INFO - val: {'epoch': 95, 'time_epoch': 4.13698, 'loss': 0.64281479, 'lr': 0, 'params': 505814, 'time_iter': 0.06567, 'accuracy': 0.77954, 'f1': 0.77943, 'accuracy-SBM': 0.77943, 'auc': 0.95964}
2025-07-05 08:02:23,481 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 08:02:23,526 - INFO - test: {'epoch': 95, 'time_epoch': 4.58657, 'loss': 0.62205634, 'lr': 0, 'params': 505814, 'time_iter': 0.0728, 'accuracy': 0.78237, 'f1': 0.78235, 'accuracy-SBM': 0.78235, 'auc': 0.96192}
2025-07-05 08:02:23,537 - INFO - > Epoch 95: took 99.2s (avg 99.3s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 08:02:23,537 - INFO - === Epoch 96 ===
2025-07-05 08:03:50,509 - INFO - train: {'epoch': 96, 'time_epoch': 86.70461, 'eta': 262.11098, 'eta_hours': 0.07281, 'loss': 0.52680026, 'lr': 4.37e-06, 'params': 505814, 'time_iter': 0.13873, 'accuracy': 0.80792, 'f1': 0.80792, 'accuracy-SBM': 0.80792, 'auc': 0.97225}
2025-07-05 08:03:54,859 - INFO - val: {'epoch': 96, 'time_epoch': 4.29987, 'loss': 0.64407396, 'lr': 0, 'params': 505814, 'time_iter': 0.06825, 'accuracy': 0.7791, 'f1': 0.77898, 'accuracy-SBM': 0.77898, 'auc': 0.95954}
2025-07-05 08:04:02,480 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 08:04:02,520 - INFO - test: {'epoch': 96, 'time_epoch': 4.64796, 'loss': 0.62365477, 'lr': 0, 'params': 505814, 'time_iter': 0.07378, 'accuracy': 0.78232, 'f1': 0.7823, 'accuracy-SBM': 0.7823, 'auc': 0.96177}
2025-07-05 08:04:02,522 - INFO - > Epoch 96: took 99.0s (avg 99.3s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 08:04:02,522 - INFO - === Epoch 97 ===
2025-07-05 08:05:28,874 - INFO - train: {'epoch': 97, 'time_epoch': 86.08286, 'eta': 174.71438, 'eta_hours': 0.04853, 'loss': 0.52717047, 'lr': 2.46e-06, 'params': 505814, 'time_iter': 0.13773, 'accuracy': 0.80776, 'f1': 0.80776, 'accuracy-SBM': 0.80776, 'auc': 0.9722}
2025-07-05 08:05:33,131 - INFO - val: {'epoch': 97, 'time_epoch': 4.20236, 'loss': 0.64463919, 'lr': 0, 'params': 505814, 'time_iter': 0.0667, 'accuracy': 0.77893, 'f1': 0.77881, 'accuracy-SBM': 0.77881, 'auc': 0.95944}
2025-07-05 08:05:42,492 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 08:05:42,531 - INFO - test: {'epoch': 97, 'time_epoch': 4.58214, 'loss': 0.62465252, 'lr': 0, 'params': 505814, 'time_iter': 0.07273, 'accuracy': 0.78224, 'f1': 0.78224, 'accuracy-SBM': 0.78223, 'auc': 0.96163}
2025-07-05 08:05:42,629 - INFO - > Epoch 97: took 100.1s (avg 99.3s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 08:05:42,629 - INFO - === Epoch 98 ===
2025-07-05 08:07:09,338 - INFO - train: {'epoch': 98, 'time_epoch': 86.45062, 'eta': 87.34803, 'eta_hours': 0.02426, 'loss': 0.52708679, 'lr': 1.09e-06, 'params': 505814, 'time_iter': 0.13832, 'accuracy': 0.80823, 'f1': 0.80823, 'accuracy-SBM': 0.80823, 'auc': 0.97222}
2025-07-05 08:07:13,725 - INFO - val: {'epoch': 98, 'time_epoch': 4.32165, 'loss': 0.6433801, 'lr': 0, 'params': 505814, 'time_iter': 0.0686, 'accuracy': 0.77929, 'f1': 0.77918, 'accuracy-SBM': 0.77919, 'auc': 0.95957}
2025-07-05 08:07:20,918 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 08:07:20,959 - INFO - test: {'epoch': 98, 'time_epoch': 4.58863, 'loss': 0.62298213, 'lr': 0, 'params': 505814, 'time_iter': 0.07284, 'accuracy': 0.78213, 'f1': 0.78212, 'accuracy-SBM': 0.78213, 'auc': 0.96182}
2025-07-05 08:07:20,962 - INFO - > Epoch 98: took 98.3s (avg 99.3s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 08:07:20,962 - INFO - === Epoch 99 ===
2025-07-05 08:08:48,672 - INFO - train: {'epoch': 99, 'time_epoch': 87.45946, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.52775258, 'lr': 2.7e-07, 'params': 505814, 'time_iter': 0.13994, 'accuracy': 0.80763, 'f1': 0.80763, 'accuracy-SBM': 0.80763, 'auc': 0.97215}
2025-07-05 08:08:52,698 - INFO - val: {'epoch': 99, 'time_epoch': 3.97915, 'loss': 0.64353368, 'lr': 0, 'params': 505814, 'time_iter': 0.06316, 'accuracy': 0.77948, 'f1': 0.77937, 'accuracy-SBM': 0.77936, 'auc': 0.95959}
2025-07-05 08:09:01,727 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-41/test_results
2025-07-05 08:09:01,770 - INFO - test: {'epoch': 99, 'time_epoch': 4.56865, 'loss': 0.62398357, 'lr': 0, 'params': 505814, 'time_iter': 0.07252, 'accuracy': 0.78239, 'f1': 0.78239, 'accuracy-SBM': 0.78239, 'auc': 0.96175}
2025-07-05 08:09:01,985 - INFO - > Epoch 99: took 100.8s (avg 99.3s) | Best so far: epoch 80	train_loss: 0.5410 train_accuracy-SBM: 0.8030	val_loss: 0.6419 val_accuracy-SBM: 0.7802	test_loss: 0.6203 test_accuracy-SBM: 0.7834
2025-07-05 08:09:01,986 - INFO - ================================================================================
2025-07-05 08:09:01,986 - INFO - NAS TRAINING COMPLETED SUCCESSFULLY
2025-07-05 08:09:01,986 - INFO - ================================================================================
2025-07-05 08:09:01,986 - INFO - Avg time per epoch: 99.30s
2025-07-05 08:09:01,986 - INFO - Total train loop time: 2.76h
2025-07-05 08:09:01,986 - INFO - Routing mode: nas
2025-07-05 08:09:01,986 - INFO - Final optimal weights: {'layer_0': 2, 'layer_1': 0, 'layer_2': 1, 'layer_3': 0, 'layer_4': 2, 'layer_5': 2, 'layer_6': 2, 'layer_7': 1, 'layer_8': 1, 'layer_9': 1, 'layer_10': 1, 'layer_11': 1, 'layer_12': 1, 'layer_13': 1, 'layer_14': 1, 'layer_15': 1}
2025-07-05 08:09:01,986 - INFO - Results include routing uncertainty (test only, NO variance)
2025-07-05 08:09:01,992 - INFO - Task done, results saved in results/Cluster/Cluster-SparseE-41
2025-07-05 08:09:01,996 - INFO - Total time: 13440.56s (3.73h)
2025-07-05 08:09:02,072 - INFO - Results aggregated across runs saved in results/Cluster/Cluster-SparseE-41/agg
2025-07-05 08:09:02,072 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-07-05 08:09:02,072 - INFO - Results saved in: results/Cluster/Cluster-SparseE-41
2025-07-05 08:09:02,072 - INFO - Test results JSON files saved in: results/Cluster/Cluster-SparseE-41/test_results/
Completed seed 41. Results saved in results/Cluster/Cluster-SparseE-41
----------------------------------------
All experiments completed!
