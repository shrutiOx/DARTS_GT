Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          376Gi        14Gi       221Gi       1.3Gi       140Gi       357Gi
Swap:         1.9Gi       657Mi       1.2Gi
Sat Aug 16 17:52:53 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:1A:00.0 Off |                    0 |
| N/A   36C    P0             43W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 47
Starting training for seed 47...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/CLUSTER/FINAL_SINGLE/SPARSE_E/confignas.yaml
Using device: cuda
2025-08-16 17:55:18,658 - INFO - GPU Mem: 34.1GB
2025-08-16 17:55:18,658 - INFO - Run directory: results/Cluster/Cluster-SparseE-47
2025-08-16 17:55:18,658 - INFO - Seed: 47
2025-08-16 17:55:18,658 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-16 17:55:18,658 - INFO - Routing mode: nas
2025-08-16 17:55:18,658 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-16 17:55:18,659 - INFO - Number of layers: 16
2025-08-16 17:55:18,659 - INFO - Uncertainty enabled: False
2025-08-16 17:55:18,659 - INFO - Training mode: NoMixNas_uncertainty_train
2025-08-16 17:55:18,659 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-16 17:55:18,659 - INFO - Additional features: Router weights logging + JSON export
2025-08-16 17:55:45,528 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 17:55:45,535 - INFO -   Data(x=[1406436, 7], edge_index=[2, 51620680], y=[1406436])
2025-08-16 17:55:45,536 - INFO -   undirected: True
2025-08-16 17:55:45,536 - INFO -   num graphs: 12000
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 17:55:45,537 - INFO -   avg num_nodes/graph: 117
2025-08-16 17:55:45,537 - INFO -   num node features: 7
2025-08-16 17:55:45,537 - INFO -   num edge features: 0
2025-08-16 17:55:45,538 - INFO -   num classes: 6
2025-08-16 17:55:45,539 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 4, 8, 16]
2025-08-16 17:55:45,539 - INFO - Precomputing Positional Encoding statistics: ['LapPE', 'RWSE'] for all graphs...
2025-08-16 17:55:45,547 - INFO -   ...estimated to be undirected: True

  0%|          | 0/12000 [00:00<?, ?it/s]
 16%|█▌        | 1878/12000 [00:10<00:53, 187.72it/s]
 31%|███▏      | 3755/12000 [00:20<00:43, 187.66it/s]
 47%|████▋     | 5614/12000 [00:30<00:34, 186.83it/s]
 63%|██████▎   | 7536/12000 [00:40<00:23, 188.94it/s]
 79%|███████▉  | 9470/12000 [00:50<00:13, 190.53it/s]
 94%|█████████▍| 11325/12000 [01:00<00:03, 188.79it/s]
100%|██████████| 12000/12000 [01:03<00:00, 189.00it/s]
2025-08-16 17:56:49,756 - INFO - Done! Took 00:01:04.22
2025-08-16 17:56:49,778 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset'
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/nni/nas/nn/pytorch/choice.py:252: UserWarning: "key" is deprecated. Assuming label.
  warnings.warn(f'"key" is deprecated. Assuming label.')
2025-08-16 17:56:50,306 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-16 17:56:50,306 - INFO - Inner model type: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-08-16 17:56:50,306 - INFO - Inner model has get_darts_model: True
2025-08-16 17:56:50,314 - INFO - GraphGymModule(
  (model): NASModelEdge(
    (encoder): FeatureEncoder(
      (node_encoder): LapPENodeEncoder(
        (linear_x): Linear(in_features=7, out_features=32, bias=True)
        (linear_A): Linear(in_features=2, out_features=32, bias=True)
        (pe_encoder): Sequential(
          (0): ReLU()
          (1): Linear(in_features=32, out_features=16, bias=True)
          (2): ReLU()
        )
      )
      (edge_encoder): DummyEdgeEncoder(
        (encoder): Embedding(1, 48)
      )
    )
    (darts_layers): ModuleList(
      (0): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (6): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_6')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (7): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_7')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (8): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_8')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (9): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_9')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (10): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_10')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (11): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_11')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (12): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_12')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (13): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_13')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (14): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_14')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (15): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_15')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (darts_sequential): Sequential(
      (0): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (6): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_6')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (7): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_7')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (8): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_8')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (9): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_9')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (10): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_10')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (11): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_11')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (12): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_12')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (13): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_13')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (14): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_14')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (15): NASLayer(
        summary: dim_h=48, global_model_type=SparseTransformer, num_heads=8, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(48, 48, bias=True)
            (1): ReLU()
            (2): Linear(48, 48, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(48, 6, heads=8)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_15')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=48, out_features=48, bias=True)
          (W_v): Linear(in_features=48, out_features=48, bias=True)
          (W_o): Linear(in_features=48, out_features=48, bias=True)
        )
        (norm1_kv): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=48, out_features=96, bias=True)
        (ff_linear2): Linear(in_features=96, out_features=48, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=48, out_features=48, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=48, out_features=48, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(48, 48, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(48, 48, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(48, 6, bias=True)
          )
        )
      )
    )
  )
)
2025-08-16 17:56:50,324 - INFO - Number of parameters: 728,630
2025-08-16 17:56:50,324 - INFO - Starting optimized training: 2025-08-16 17:56:50.324930
2025-08-16 17:56:55,716 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset':
2025-08-16 17:56:55,716 - INFO -   Data(x=[1406436, 7], edge_index=[2, 51620680], y=[1406436])
2025-08-16 17:56:55,717 - INFO -   undirected: True
2025-08-16 17:56:55,717 - INFO -   num graphs: 12000
2025-08-16 17:56:55,718 - INFO -   avg num_nodes/graph: 117
2025-08-16 17:56:55,718 - INFO -   num node features: 7
2025-08-16 17:56:55,718 - INFO -   num edge features: 0
2025-08-16 17:56:55,719 - INFO -   num classes: 6
2025-08-16 17:56:55,720 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 4, 8, 16]
2025-08-16 17:56:55,720 - INFO - Precomputing Positional Encoding statistics: ['LapPE', 'RWSE'] for all graphs...
2025-08-16 17:56:55,728 - INFO -   ...estimated to be undirected: True

  0%|          | 0/12000 [00:00<?, ?it/s]
 16%|█▌        | 1876/12000 [00:10<00:54, 187.48it/s]
 32%|███▏      | 3784/12000 [00:20<00:43, 189.39it/s]
 48%|████▊     | 5709/12000 [00:30<00:32, 190.80it/s]
 63%|██████▎   | 7618/12000 [00:40<00:22, 190.82it/s]
 79%|███████▉  | 9514/12000 [00:50<00:13, 190.37it/s]
 95%|█████████▌| 11412/12000 [01:00<00:03, 190.17it/s]
100%|██████████| 12000/12000 [01:03<00:00, 190.33it/s]
2025-08-16 17:57:59,516 - INFO - Done! Took 00:01:03.80
2025-08-16 17:57:59,542 - INFO - [*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset'
2025-08-16 17:57:59,662 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-16 17:57:59,662 - INFO - Start from epoch 0
2025-08-16 17:57:59,662 - INFO - ================================================================================
2025-08-16 17:57:59,662 - INFO - STARTING TWO-PHASE NAS TRAINING
2025-08-16 17:57:59,662 - INFO - ================================================================================
2025-08-16 17:57:59,662 - INFO - Routing mode: nas
2025-08-16 17:57:59,662 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-16 17:57:59,663 - INFO - Phase 1: Architecture search/initialization
2025-08-16 17:57:59,663 - INFO - Phase 2: Discrete training with uncertainty (NO variance)
2025-08-16 17:57:59,663 - INFO - ============================================================
2025-08-16 17:57:59,663 - INFO - PHASE 1: ARCHITECTURE SEARCH/INITIALIZATION
2025-08-16 17:57:59,663 - INFO - ============================================================
2025-08-16 17:57:59,663 - INFO - Splitting dataset for DARTS:
2025-08-16 17:57:59,663 - INFO -   Original train size: 10000
2025-08-16 17:57:59,663 - INFO -   DARTS train size: 6000 (60.0%)
2025-08-16 17:57:59,663 - INFO -   DARTS val size: 4000 (40.0%)
2025-08-16 17:57:59,664 - INFO - Found GraphGym wrapper, using inner model: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-08-16 17:57:59,664 - INFO - Successfully configured model for DARTS training
2025-08-16 17:57:59,664 - INFO - NAS MODE: Running 25 epochs with DARTS
2025-08-16 17:57:59,664 - INFO - DARTS Configuration:
2025-08-16 17:57:59,664 - INFO -   Epochs: 25
2025-08-16 17:57:59,665 - INFO -   Architecture LR: 0.0004
2025-08-16 17:57:59,665 - INFO -   Grad clip: 5.0
2025-08-16 17:57:59,677 - INFO - Starting DARTS architecture search
2025-08-16 17:58:06,998 - WARNING - Epoch [1/25] Step [1/250]  acc 0.162047 (0.162047)  loss 1.802170 (1.802170)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 3182.0 MB
2025-08-16 17:58:11,288 - WARNING - Epoch [1/25] Step [11/250]  acc 0.143787 (0.172219)  loss 1.796881 (1.793988)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 3306.0 MB
2025-08-16 17:58:15,739 - WARNING - Epoch [1/25] Step [21/250]  acc 0.158467 (0.175431)  loss 1.793237 (1.792119)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 4522.0 MB
2025-08-16 17:58:20,261 - WARNING - Epoch [1/25] Step [31/250]  acc 0.180624 (0.176052)  loss 1.786951 (1.790913)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 4522.0 MB
2025-08-16 17:58:25,210 - WARNING - Epoch [1/25] Step [41/250]  acc 0.178821 (0.179805)  loss 1.785800 (1.789382)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 5744.0 MB
2025-08-16 17:58:29,964 - WARNING - Epoch [1/25] Step [51/250]  acc 0.192434 (0.180719)  loss 1.780330 (1.788488)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 5744.0 MB
2025-08-16 17:58:34,901 - WARNING - Epoch [1/25] Step [61/250]  acc 0.208701 (0.182168)  loss 1.780047 (1.787205)
GPU memory consumption  GPU Memory: Allocated: 52.5 MB, Reserved: 5744.0 MB
2025-08-16 17:58:39,931 - WARNING - Epoch [1/25] Step [71/250]  acc 0.214249 (0.184788)  loss 1.765057 (1.785294)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 5744.0 MB
2025-08-16 17:58:44,823 - WARNING - Epoch [1/25] Step [81/250]  acc 0.224341 (0.188264)  loss 1.754973 (1.783155)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 5744.0 MB
2025-08-16 17:58:49,895 - WARNING - Epoch [1/25] Step [91/250]  acc 0.227349 (0.191494)  loss 1.740676 (1.780409)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 5744.0 MB
2025-08-16 17:58:54,975 - WARNING - Epoch [1/25] Step [101/250]  acc 0.255487 (0.195827)  loss 1.722248 (1.775808)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 5744.0 MB
2025-08-16 17:58:59,835 - WARNING - Epoch [1/25] Step [111/250]  acc 0.230147 (0.200846)  loss 1.732291 (1.770371)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 5744.0 MB
2025-08-16 17:59:04,720 - WARNING - Epoch [1/25] Step [121/250]  acc 0.224898 (0.203984)  loss 1.700808 (1.764980)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 5744.0 MB
2025-08-16 17:59:09,309 - WARNING - Epoch [1/25] Step [131/250]  acc 0.243375 (0.207863)  loss 1.677184 (1.759238)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 5748.0 MB
2025-08-16 17:59:13,795 - WARNING - Epoch [1/25] Step [141/250]  acc 0.271084 (0.210338)  loss 1.679293 (1.753414)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 5748.0 MB
2025-08-16 17:59:18,220 - WARNING - Epoch [1/25] Step [151/250]  acc 0.245538 (0.213328)  loss 1.712942 (1.747960)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 5748.0 MB
2025-08-16 17:59:22,856 - WARNING - Epoch [1/25] Step [161/250]  acc 0.261530 (0.217104)  loss 1.629772 (1.742055)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 5748.0 MB
2025-08-16 17:59:27,494 - WARNING - Epoch [1/25] Step [171/250]  acc 0.242728 (0.220646)  loss 1.656358 (1.736503)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 5748.0 MB
2025-08-16 17:59:32,153 - WARNING - Epoch [1/25] Step [181/250]  acc 0.254204 (0.222921)  loss 1.648587 (1.732024)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 5748.0 MB
2025-08-16 17:59:36,742 - WARNING - Epoch [1/25] Step [191/250]  acc 0.274459 (0.225611)  loss 1.648974 (1.727775)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 5748.0 MB
2025-08-16 17:59:41,642 - WARNING - Epoch [1/25] Step [201/250]  acc 0.291139 (0.227611)  loss 1.661752 (1.723837)
GPU memory consumption  GPU Memory: Allocated: 53.0 MB, Reserved: 5748.0 MB
2025-08-16 17:59:46,351 - WARNING - Epoch [1/25] Step [211/250]  acc 0.240865 (0.229036)  loss 1.666986 (1.720192)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 5748.0 MB
2025-08-16 17:59:50,929 - WARNING - Epoch [1/25] Step [221/250]  acc 0.249738 (0.230705)  loss 1.664409 (1.716652)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 5748.0 MB
2025-08-16 17:59:55,577 - WARNING - Epoch [1/25] Step [231/250]  acc 0.250889 (0.232386)  loss 1.643963 (1.712995)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 5748.0 MB
2025-08-16 18:00:00,469 - WARNING - Epoch [1/25] Step [241/250]  acc 0.270833 (0.233384)  loss 1.609834 (1.710266)
GPU memory consumption  GPU Memory: Allocated: 58.3 MB, Reserved: 5748.0 MB
Epoch 1 completed in 0:02:05.024302
2025-08-16 18:00:33,701 - WARNING - Epoch [2/25] Step [1/250]  acc 0.261721 (0.261721)  loss 1.621764 (1.621764)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 5748.0 MB
2025-08-16 18:00:38,325 - WARNING - Epoch [2/25] Step [11/250]  acc 0.305793 (0.273265)  loss 1.609966 (1.637252)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 5748.0 MB
2025-08-16 18:00:42,948 - WARNING - Epoch [2/25] Step [21/250]  acc 0.281543 (0.266207)  loss 1.592380 (1.631169)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 5748.0 MB
2025-08-16 18:00:47,519 - WARNING - Epoch [2/25] Step [31/250]  acc 0.291277 (0.265946)  loss 1.588773 (1.629882)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 5748.0 MB
2025-08-16 18:00:52,151 - WARNING - Epoch [2/25] Step [41/250]  acc 0.299294 (0.267751)  loss 1.622278 (1.629383)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 5748.0 MB
2025-08-16 18:00:56,732 - WARNING - Epoch [2/25] Step [51/250]  acc 0.267765 (0.269367)  loss 1.564747 (1.625203)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 5750.0 MB
2025-08-16 18:01:01,613 - WARNING - Epoch [2/25] Step [61/250]  acc 0.280481 (0.270382)  loss 1.676936 (1.624664)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 5750.0 MB
2025-08-16 18:01:06,358 - WARNING - Epoch [2/25] Step [71/250]  acc 0.263420 (0.269833)  loss 1.623270 (1.625337)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 5750.0 MB
2025-08-16 18:01:11,346 - WARNING - Epoch [2/25] Step [81/250]  acc 0.257333 (0.269363)  loss 1.594391 (1.623827)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 5750.0 MB
2025-08-16 18:01:16,187 - WARNING - Epoch [2/25] Step [91/250]  acc 0.293521 (0.268296)  loss 1.579760 (1.622368)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 5750.0 MB
2025-08-16 18:01:21,005 - WARNING - Epoch [2/25] Step [101/250]  acc 0.286015 (0.269220)  loss 1.587007 (1.621405)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 5750.0 MB
2025-08-16 18:01:25,824 - WARNING - Epoch [2/25] Step [111/250]  acc 0.294742 (0.269164)  loss 1.597769 (1.621997)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 5750.0 MB
2025-08-16 18:01:30,537 - WARNING - Epoch [2/25] Step [121/250]  acc 0.314844 (0.270651)  loss 1.601419 (1.621374)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 5750.0 MB
2025-08-16 18:01:35,193 - WARNING - Epoch [2/25] Step [131/250]  acc 0.254620 (0.271398)  loss 1.613059 (1.621147)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 5750.0 MB
2025-08-16 18:01:39,847 - WARNING - Epoch [2/25] Step [141/250]  acc 0.255839 (0.271387)  loss 1.609739 (1.621762)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 5750.0 MB
2025-08-16 18:01:44,509 - WARNING - Epoch [2/25] Step [151/250]  acc 0.259341 (0.272303)  loss 1.708659 (1.620775)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 5750.0 MB
2025-08-16 18:01:49,147 - WARNING - Epoch [2/25] Step [161/250]  acc 0.299320 (0.272881)  loss 1.606309 (1.620033)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 5750.0 MB
2025-08-16 18:01:53,715 - WARNING - Epoch [2/25] Step [171/250]  acc 0.265362 (0.272818)  loss 1.650124 (1.619269)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 5750.0 MB
2025-08-16 18:01:58,380 - WARNING - Epoch [2/25] Step [181/250]  acc 0.265357 (0.272842)  loss 1.602794 (1.618678)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 5750.0 MB
2025-08-16 18:02:03,383 - WARNING - Epoch [2/25] Step [191/250]  acc 0.265285 (0.273013)  loss 1.586623 (1.618500)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 5750.0 MB
2025-08-16 18:02:08,075 - WARNING - Epoch [2/25] Step [201/250]  acc 0.267488 (0.273627)  loss 1.610661 (1.616817)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 5750.0 MB
2025-08-16 18:02:12,736 - WARNING - Epoch [2/25] Step [211/250]  acc 0.279412 (0.274817)  loss 1.626310 (1.615398)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 5750.0 MB
2025-08-16 18:02:17,448 - WARNING - Epoch [2/25] Step [221/250]  acc 0.233826 (0.275254)  loss 1.636173 (1.614310)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:02:22,097 - WARNING - Epoch [2/25] Step [231/250]  acc 0.277837 (0.275116)  loss 1.586023 (1.614045)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7802.0 MB
2025-08-16 18:02:26,490 - WARNING - Epoch [2/25] Step [241/250]  acc 0.261153 (0.275154)  loss 1.634164 (1.613083)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
Epoch 2 completed in 0:01:57.241660
2025-08-16 18:02:58,342 - WARNING - Epoch [3/25] Step [1/250]  acc 0.253428 (0.253428)  loss 1.633526 (1.633526)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:03:03,237 - WARNING - Epoch [3/25] Step [11/250]  acc 0.283970 (0.278921)  loss 1.571547 (1.585780)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7802.0 MB
2025-08-16 18:03:08,000 - WARNING - Epoch [3/25] Step [21/250]  acc 0.304865 (0.275093)  loss 1.594914 (1.597847)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:03:12,758 - WARNING - Epoch [3/25] Step [31/250]  acc 0.270752 (0.273913)  loss 1.615357 (1.600532)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7802.0 MB
2025-08-16 18:03:17,502 - WARNING - Epoch [3/25] Step [41/250]  acc 0.276585 (0.272925)  loss 1.584999 (1.597074)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 7802.0 MB
2025-08-16 18:03:22,340 - WARNING - Epoch [3/25] Step [51/250]  acc 0.271452 (0.274314)  loss 1.580932 (1.594641)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:03:27,035 - WARNING - Epoch [3/25] Step [61/250]  acc 0.272142 (0.275651)  loss 1.576397 (1.592244)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7802.0 MB
2025-08-16 18:03:31,744 - WARNING - Epoch [3/25] Step [71/250]  acc 0.267448 (0.275347)  loss 1.625713 (1.592631)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7802.0 MB
2025-08-16 18:03:36,439 - WARNING - Epoch [3/25] Step [81/250]  acc 0.268753 (0.276189)  loss 1.579035 (1.593695)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:03:41,306 - WARNING - Epoch [3/25] Step [91/250]  acc 0.253264 (0.276782)  loss 1.593086 (1.594303)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:03:46,035 - WARNING - Epoch [3/25] Step [101/250]  acc 0.284175 (0.276978)  loss 1.523756 (1.592420)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7802.0 MB
2025-08-16 18:03:50,909 - WARNING - Epoch [3/25] Step [111/250]  acc 0.277507 (0.276144)  loss 1.586899 (1.592409)
GPU memory consumption  GPU Memory: Allocated: 59.7 MB, Reserved: 7802.0 MB
2025-08-16 18:03:55,819 - WARNING - Epoch [3/25] Step [121/250]  acc 0.271169 (0.275821)  loss 1.571360 (1.592004)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:04:00,589 - WARNING - Epoch [3/25] Step [131/250]  acc 0.265564 (0.276999)  loss 1.577998 (1.590088)
GPU memory consumption  GPU Memory: Allocated: 59.1 MB, Reserved: 7802.0 MB
2025-08-16 18:04:05,343 - WARNING - Epoch [3/25] Step [141/250]  acc 0.296296 (0.276781)  loss 1.561020 (1.590384)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 7802.0 MB
2025-08-16 18:04:10,081 - WARNING - Epoch [3/25] Step [151/250]  acc 0.262997 (0.277476)  loss 1.586562 (1.589474)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:04:14,885 - WARNING - Epoch [3/25] Step [161/250]  acc 0.298600 (0.277925)  loss 1.517770 (1.588656)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:04:19,749 - WARNING - Epoch [3/25] Step [171/250]  acc 0.282912 (0.277797)  loss 1.568991 (1.588858)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:04:24,701 - WARNING - Epoch [3/25] Step [181/250]  acc 0.248227 (0.278093)  loss 1.573729 (1.587069)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:04:29,506 - WARNING - Epoch [3/25] Step [191/250]  acc 0.252156 (0.277621)  loss 1.585192 (1.586826)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7802.0 MB
2025-08-16 18:04:34,573 - WARNING - Epoch [3/25] Step [201/250]  acc 0.269191 (0.277672)  loss 1.594742 (1.587051)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:04:39,677 - WARNING - Epoch [3/25] Step [211/250]  acc 0.296017 (0.277768)  loss 1.559694 (1.587180)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7802.0 MB
2025-08-16 18:04:44,578 - WARNING - Epoch [3/25] Step [221/250]  acc 0.271195 (0.278084)  loss 1.567613 (1.586567)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:04:49,599 - WARNING - Epoch [3/25] Step [231/250]  acc 0.261840 (0.277792)  loss 1.618519 (1.587065)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7802.0 MB
2025-08-16 18:04:54,407 - WARNING - Epoch [3/25] Step [241/250]  acc 0.271723 (0.277578)  loss 1.577969 (1.586938)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 7802.0 MB
Epoch 3 completed in 0:02:00.852697
2025-08-16 18:05:27,799 - WARNING - Epoch [4/25] Step [1/250]  acc 0.273349 (0.273349)  loss 1.562158 (1.562158)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7802.0 MB
2025-08-16 18:05:32,565 - WARNING - Epoch [4/25] Step [11/250]  acc 0.255736 (0.274853)  loss 1.535078 (1.583507)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7802.0 MB
2025-08-16 18:05:37,393 - WARNING - Epoch [4/25] Step [21/250]  acc 0.278501 (0.280802)  loss 1.553119 (1.580753)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:05:42,177 - WARNING - Epoch [4/25] Step [31/250]  acc 0.277397 (0.283435)  loss 1.550399 (1.579703)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 7802.0 MB
2025-08-16 18:05:46,941 - WARNING - Epoch [4/25] Step [41/250]  acc 0.290217 (0.282596)  loss 1.577087 (1.579879)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7802.0 MB
2025-08-16 18:05:51,893 - WARNING - Epoch [4/25] Step [51/250]  acc 0.285642 (0.284503)  loss 1.631731 (1.578824)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 7802.0 MB
2025-08-16 18:05:56,751 - WARNING - Epoch [4/25] Step [61/250]  acc 0.245161 (0.283933)  loss 1.574828 (1.577172)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7802.0 MB
2025-08-16 18:06:01,580 - WARNING - Epoch [4/25] Step [71/250]  acc 0.300361 (0.283358)  loss 1.565187 (1.576946)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:06:06,418 - WARNING - Epoch [4/25] Step [81/250]  acc 0.314534 (0.284881)  loss 1.495751 (1.574874)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:06:11,119 - WARNING - Epoch [4/25] Step [91/250]  acc 0.289030 (0.283974)  loss 1.573771 (1.577235)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7802.0 MB
2025-08-16 18:06:15,775 - WARNING - Epoch [4/25] Step [101/250]  acc 0.295634 (0.284927)  loss 1.551790 (1.576028)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 7802.0 MB
2025-08-16 18:06:20,563 - WARNING - Epoch [4/25] Step [111/250]  acc 0.303045 (0.284630)  loss 1.538797 (1.573935)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 7802.0 MB
2025-08-16 18:06:25,312 - WARNING - Epoch [4/25] Step [121/250]  acc 0.283798 (0.284990)  loss 1.598490 (1.574904)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:06:29,945 - WARNING - Epoch [4/25] Step [131/250]  acc 0.294990 (0.285267)  loss 1.536561 (1.574109)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:06:35,034 - WARNING - Epoch [4/25] Step [141/250]  acc 0.265116 (0.285618)  loss 1.578920 (1.574631)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:06:39,780 - WARNING - Epoch [4/25] Step [151/250]  acc 0.288117 (0.285728)  loss 1.566375 (1.575199)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 7802.0 MB
2025-08-16 18:06:44,674 - WARNING - Epoch [4/25] Step [161/250]  acc 0.310685 (0.286575)  loss 1.555570 (1.575123)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:06:49,440 - WARNING - Epoch [4/25] Step [171/250]  acc 0.332609 (0.288193)  loss 1.485347 (1.573448)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
2025-08-16 18:06:54,177 - WARNING - Epoch [4/25] Step [181/250]  acc 0.371010 (0.289764)  loss 1.543530 (1.571098)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:06:58,901 - WARNING - Epoch [4/25] Step [191/250]  acc 0.331683 (0.291247)  loss 1.524670 (1.569752)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
2025-08-16 18:07:03,700 - WARNING - Epoch [4/25] Step [201/250]  acc 0.359295 (0.293337)  loss 1.476192 (1.567458)
GPU memory consumption  GPU Memory: Allocated: 52.0 MB, Reserved: 7802.0 MB
2025-08-16 18:07:08,472 - WARNING - Epoch [4/25] Step [211/250]  acc 0.336117 (0.294534)  loss 1.532688 (1.566107)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7802.0 MB
2025-08-16 18:07:13,248 - WARNING - Epoch [4/25] Step [221/250]  acc 0.310362 (0.296308)  loss 1.541362 (1.564272)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 7802.0 MB
2025-08-16 18:07:18,087 - WARNING - Epoch [4/25] Step [231/250]  acc 0.348729 (0.298648)  loss 1.469728 (1.561338)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7802.0 MB
2025-08-16 18:07:22,867 - WARNING - Epoch [4/25] Step [241/250]  acc 0.350410 (0.299852)  loss 1.533418 (1.559924)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7802.0 MB
Epoch 4 completed in 0:01:59.840992
2025-08-16 18:07:56,490 - WARNING - Epoch [5/25] Step [1/250]  acc 0.333678 (0.333678)  loss 1.558834 (1.558834)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:08:01,327 - WARNING - Epoch [5/25] Step [11/250]  acc 0.354521 (0.329981)  loss 1.502900 (1.529950)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:08:06,269 - WARNING - Epoch [5/25] Step [21/250]  acc 0.374860 (0.329769)  loss 1.502887 (1.539858)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 7802.0 MB
2025-08-16 18:08:11,090 - WARNING - Epoch [5/25] Step [31/250]  acc 0.323185 (0.332821)  loss 1.510871 (1.522522)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 7802.0 MB
2025-08-16 18:08:16,137 - WARNING - Epoch [5/25] Step [41/250]  acc 0.374933 (0.334959)  loss 1.446820 (1.521978)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:08:20,996 - WARNING - Epoch [5/25] Step [51/250]  acc 0.337049 (0.339327)  loss 1.490710 (1.514364)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7802.0 MB
2025-08-16 18:08:25,860 - WARNING - Epoch [5/25] Step [61/250]  acc 0.378689 (0.338775)  loss 1.461733 (1.512582)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7802.0 MB
2025-08-16 18:08:30,687 - WARNING - Epoch [5/25] Step [71/250]  acc 0.372490 (0.337414)  loss 1.464188 (1.512239)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7802.0 MB
2025-08-16 18:08:35,639 - WARNING - Epoch [5/25] Step [81/250]  acc 0.332603 (0.338104)  loss 1.536166 (1.510484)
GPU memory consumption  GPU Memory: Allocated: 56.9 MB, Reserved: 7802.0 MB
2025-08-16 18:08:40,635 - WARNING - Epoch [5/25] Step [91/250]  acc 0.328789 (0.337871)  loss 1.495080 (1.509414)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:08:45,366 - WARNING - Epoch [5/25] Step [101/250]  acc 0.354873 (0.339190)  loss 1.491005 (1.506156)
GPU memory consumption  GPU Memory: Allocated: 57.9 MB, Reserved: 7802.0 MB
2025-08-16 18:08:50,188 - WARNING - Epoch [5/25] Step [111/250]  acc 0.361993 (0.340780)  loss 1.498083 (1.502458)
GPU memory consumption  GPU Memory: Allocated: 58.6 MB, Reserved: 7802.0 MB
2025-08-16 18:08:55,187 - WARNING - Epoch [5/25] Step [121/250]  acc 0.355748 (0.342088)  loss 1.482857 (1.499815)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:08:59,993 - WARNING - Epoch [5/25] Step [131/250]  acc 0.373585 (0.344082)  loss 1.409761 (1.495614)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7802.0 MB
2025-08-16 18:09:04,904 - WARNING - Epoch [5/25] Step [141/250]  acc 0.352620 (0.345238)  loss 1.434713 (1.494638)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7802.0 MB
2025-08-16 18:09:09,825 - WARNING - Epoch [5/25] Step [151/250]  acc 0.318841 (0.345990)  loss 1.523219 (1.492937)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 7802.0 MB
2025-08-16 18:09:14,596 - WARNING - Epoch [5/25] Step [161/250]  acc 0.361199 (0.345520)  loss 1.477123 (1.493344)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:09:19,348 - WARNING - Epoch [5/25] Step [171/250]  acc 0.350569 (0.345357)  loss 1.473741 (1.492307)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:09:23,929 - WARNING - Epoch [5/25] Step [181/250]  acc 0.350490 (0.346353)  loss 1.452935 (1.491052)
GPU memory consumption  GPU Memory: Allocated: 58.1 MB, Reserved: 7802.0 MB
2025-08-16 18:09:28,832 - WARNING - Epoch [5/25] Step [191/250]  acc 0.321072 (0.346907)  loss 1.563877 (1.489433)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7802.0 MB
2025-08-16 18:09:33,592 - WARNING - Epoch [5/25] Step [201/250]  acc 0.381001 (0.347519)  loss 1.439114 (1.487548)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:09:38,170 - WARNING - Epoch [5/25] Step [211/250]  acc 0.368037 (0.348256)  loss 1.454768 (1.486004)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7802.0 MB
2025-08-16 18:09:42,810 - WARNING - Epoch [5/25] Step [221/250]  acc 0.333513 (0.348642)  loss 1.474990 (1.484355)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
2025-08-16 18:09:47,513 - WARNING - Epoch [5/25] Step [231/250]  acc 0.384153 (0.349294)  loss 1.429739 (1.482202)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7802.0 MB
2025-08-16 18:09:52,328 - WARNING - Epoch [5/25] Step [241/250]  acc 0.397895 (0.349956)  loss 1.440664 (1.481077)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7802.0 MB
Epoch 5 completed in 0:02:00.590821
2025-08-16 18:10:26,177 - WARNING - Epoch [6/25] Step [1/250]  acc 0.380224 (0.380224)  loss 1.415547 (1.415547)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:10:30,944 - WARNING - Epoch [6/25] Step [11/250]  acc 0.330894 (0.368350)  loss 1.528194 (1.453577)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:10:35,704 - WARNING - Epoch [6/25] Step [21/250]  acc 0.393410 (0.370365)  loss 1.354428 (1.445344)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:10:40,489 - WARNING - Epoch [6/25] Step [31/250]  acc 0.372247 (0.366618)  loss 1.466024 (1.444882)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
2025-08-16 18:10:45,078 - WARNING - Epoch [6/25] Step [41/250]  acc 0.375129 (0.367924)  loss 1.443641 (1.442454)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:10:49,681 - WARNING - Epoch [6/25] Step [51/250]  acc 0.353194 (0.366463)  loss 1.421709 (1.443701)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7802.0 MB
2025-08-16 18:10:54,446 - WARNING - Epoch [6/25] Step [61/250]  acc 0.343153 (0.367829)  loss 1.492033 (1.441466)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7802.0 MB
2025-08-16 18:10:59,212 - WARNING - Epoch [6/25] Step [71/250]  acc 0.387368 (0.368109)  loss 1.467950 (1.443323)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7802.0 MB
2025-08-16 18:11:03,922 - WARNING - Epoch [6/25] Step [81/250]  acc 0.347958 (0.368502)  loss 1.497026 (1.443910)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 7802.0 MB
2025-08-16 18:11:08,954 - WARNING - Epoch [6/25] Step [91/250]  acc 0.393663 (0.368646)  loss 1.461166 (1.442445)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7802.0 MB
2025-08-16 18:11:13,747 - WARNING - Epoch [6/25] Step [101/250]  acc 0.360360 (0.368802)  loss 1.427052 (1.440652)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:11:18,483 - WARNING - Epoch [6/25] Step [111/250]  acc 0.325069 (0.368470)  loss 1.598411 (1.440706)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
2025-08-16 18:11:23,284 - WARNING - Epoch [6/25] Step [121/250]  acc 0.388522 (0.367612)  loss 1.438925 (1.442401)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:11:28,175 - WARNING - Epoch [6/25] Step [131/250]  acc 0.351264 (0.366884)  loss 1.452371 (1.442909)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
2025-08-16 18:11:32,992 - WARNING - Epoch [6/25] Step [141/250]  acc 0.351728 (0.366637)  loss 1.478014 (1.442092)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:11:37,781 - WARNING - Epoch [6/25] Step [151/250]  acc 0.371562 (0.365651)  loss 1.460585 (1.443967)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:11:42,609 - WARNING - Epoch [6/25] Step [161/250]  acc 0.406710 (0.365962)  loss 1.378657 (1.444046)
GPU memory consumption  GPU Memory: Allocated: 52.9 MB, Reserved: 7802.0 MB
2025-08-16 18:11:47,439 - WARNING - Epoch [6/25] Step [171/250]  acc 0.316274 (0.366366)  loss 1.555906 (1.443228)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:11:52,193 - WARNING - Epoch [6/25] Step [181/250]  acc 0.326017 (0.366193)  loss 1.464538 (1.443533)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
2025-08-16 18:11:56,830 - WARNING - Epoch [6/25] Step [191/250]  acc 0.372374 (0.366357)  loss 1.418762 (1.442751)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7802.0 MB
2025-08-16 18:12:01,721 - WARNING - Epoch [6/25] Step [201/250]  acc 0.397422 (0.365974)  loss 1.435597 (1.443924)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 7802.0 MB
2025-08-16 18:12:06,669 - WARNING - Epoch [6/25] Step [211/250]  acc 0.375000 (0.365654)  loss 1.405285 (1.444444)
GPU memory consumption  GPU Memory: Allocated: 53.8 MB, Reserved: 7802.0 MB
2025-08-16 18:12:11,572 - WARNING - Epoch [6/25] Step [221/250]  acc 0.379274 (0.365879)  loss 1.371414 (1.443686)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 7802.0 MB
2025-08-16 18:12:16,517 - WARNING - Epoch [6/25] Step [231/250]  acc 0.375433 (0.365615)  loss 1.403701 (1.443247)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 7802.0 MB
2025-08-16 18:12:21,695 - WARNING - Epoch [6/25] Step [241/250]  acc 0.406314 (0.366031)  loss 1.358756 (1.441801)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7802.0 MB
Epoch 6 completed in 0:02:00.417295
2025-08-16 18:12:55,623 - WARNING - Epoch [7/25] Step [1/250]  acc 0.349818 (0.349818)  loss 1.503096 (1.503096)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:13:00,549 - WARNING - Epoch [7/25] Step [11/250]  acc 0.357066 (0.356592)  loss 1.425948 (1.458382)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:13:05,505 - WARNING - Epoch [7/25] Step [21/250]  acc 0.365731 (0.366908)  loss 1.420501 (1.446436)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:13:10,379 - WARNING - Epoch [7/25] Step [31/250]  acc 0.368876 (0.366821)  loss 1.406541 (1.437635)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 7802.0 MB
2025-08-16 18:13:15,292 - WARNING - Epoch [7/25] Step [41/250]  acc 0.369321 (0.369086)  loss 1.465838 (1.432951)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 7802.0 MB
2025-08-16 18:13:20,167 - WARNING - Epoch [7/25] Step [51/250]  acc 0.372508 (0.367839)  loss 1.405535 (1.437048)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:13:25,077 - WARNING - Epoch [7/25] Step [61/250]  acc 0.391328 (0.369629)  loss 1.409428 (1.432617)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7802.0 MB
2025-08-16 18:13:29,971 - WARNING - Epoch [7/25] Step [71/250]  acc 0.369279 (0.371158)  loss 1.371017 (1.429819)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7802.0 MB
2025-08-16 18:13:34,863 - WARNING - Epoch [7/25] Step [81/250]  acc 0.390571 (0.373110)  loss 1.387315 (1.426227)
GPU memory consumption  GPU Memory: Allocated: 59.4 MB, Reserved: 7802.0 MB
2025-08-16 18:13:39,758 - WARNING - Epoch [7/25] Step [91/250]  acc 0.369388 (0.372737)  loss 1.429015 (1.427285)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:13:44,630 - WARNING - Epoch [7/25] Step [101/250]  acc 0.366309 (0.373487)  loss 1.427687 (1.425179)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7802.0 MB
2025-08-16 18:13:49,525 - WARNING - Epoch [7/25] Step [111/250]  acc 0.351892 (0.372287)  loss 1.423581 (1.426251)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7802.0 MB
2025-08-16 18:13:54,433 - WARNING - Epoch [7/25] Step [121/250]  acc 0.387078 (0.371204)  loss 1.443955 (1.428602)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7802.0 MB
2025-08-16 18:13:59,335 - WARNING - Epoch [7/25] Step [131/250]  acc 0.381715 (0.371211)  loss 1.391592 (1.428657)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:14:04,295 - WARNING - Epoch [7/25] Step [141/250]  acc 0.367991 (0.371030)  loss 1.429349 (1.429496)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:14:09,581 - WARNING - Epoch [7/25] Step [151/250]  acc 0.362869 (0.371341)  loss 1.417530 (1.428305)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:14:14,430 - WARNING - Epoch [7/25] Step [161/250]  acc 0.345178 (0.371894)  loss 1.464730 (1.427637)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 7802.0 MB
2025-08-16 18:14:19,279 - WARNING - Epoch [7/25] Step [171/250]  acc 0.381352 (0.372044)  loss 1.393981 (1.427771)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7802.0 MB
2025-08-16 18:14:24,178 - WARNING - Epoch [7/25] Step [181/250]  acc 0.312661 (0.371990)  loss 1.521455 (1.427987)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:14:28,982 - WARNING - Epoch [7/25] Step [191/250]  acc 0.373134 (0.372537)  loss 1.371041 (1.426491)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7802.0 MB
2025-08-16 18:14:33,816 - WARNING - Epoch [7/25] Step [201/250]  acc 0.391409 (0.372443)  loss 1.413341 (1.425644)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 7802.0 MB
2025-08-16 18:14:38,622 - WARNING - Epoch [7/25] Step [211/250]  acc 0.373737 (0.372873)  loss 1.377058 (1.424706)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 7802.0 MB
2025-08-16 18:14:43,433 - WARNING - Epoch [7/25] Step [221/250]  acc 0.324566 (0.372465)  loss 1.461797 (1.426127)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:14:48,269 - WARNING - Epoch [7/25] Step [231/250]  acc 0.390321 (0.372518)  loss 1.423748 (1.425946)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:14:53,162 - WARNING - Epoch [7/25] Step [241/250]  acc 0.340000 (0.373216)  loss 1.492235 (1.424861)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7802.0 MB
Epoch 7 completed in 0:02:02.286250
2025-08-16 18:15:26,048 - WARNING - Epoch [8/25] Step [1/250]  acc 0.350783 (0.350783)  loss 1.447648 (1.447648)
GPU memory consumption  GPU Memory: Allocated: 59.6 MB, Reserved: 7802.0 MB
2025-08-16 18:15:30,414 - WARNING - Epoch [8/25] Step [11/250]  acc 0.358369 (0.377602)  loss 1.417563 (1.402956)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:15:34,734 - WARNING - Epoch [8/25] Step [21/250]  acc 0.373662 (0.375354)  loss 1.420144 (1.410691)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
2025-08-16 18:15:39,086 - WARNING - Epoch [8/25] Step [31/250]  acc 0.352201 (0.377337)  loss 1.449649 (1.413420)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7802.0 MB
2025-08-16 18:15:43,382 - WARNING - Epoch [8/25] Step [41/250]  acc 0.417391 (0.381001)  loss 1.361408 (1.408843)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:15:47,933 - WARNING - Epoch [8/25] Step [51/250]  acc 0.400872 (0.383973)  loss 1.405874 (1.406395)
GPU memory consumption  GPU Memory: Allocated: 61.0 MB, Reserved: 7802.0 MB
2025-08-16 18:15:52,226 - WARNING - Epoch [8/25] Step [61/250]  acc 0.340979 (0.384892)  loss 1.474368 (1.406562)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:15:56,694 - WARNING - Epoch [8/25] Step [71/250]  acc 0.411491 (0.386101)  loss 1.348934 (1.404903)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:16:01,098 - WARNING - Epoch [8/25] Step [81/250]  acc 0.416104 (0.388620)  loss 1.412761 (1.401015)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:16:05,561 - WARNING - Epoch [8/25] Step [91/250]  acc 0.350905 (0.390860)  loss 1.476873 (1.396754)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 7802.0 MB
2025-08-16 18:16:10,016 - WARNING - Epoch [8/25] Step [101/250]  acc 0.408346 (0.393238)  loss 1.432512 (1.394031)
GPU memory consumption  GPU Memory: Allocated: 59.5 MB, Reserved: 7802.0 MB
2025-08-16 18:16:14,545 - WARNING - Epoch [8/25] Step [111/250]  acc 0.429109 (0.395297)  loss 1.387601 (1.392579)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7802.0 MB
2025-08-16 18:16:19,060 - WARNING - Epoch [8/25] Step [121/250]  acc 0.409913 (0.397244)  loss 1.403462 (1.390784)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7802.0 MB
2025-08-16 18:16:23,464 - WARNING - Epoch [8/25] Step [131/250]  acc 0.453998 (0.398883)  loss 1.353753 (1.390172)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7802.0 MB
2025-08-16 18:16:27,929 - WARNING - Epoch [8/25] Step [141/250]  acc 0.403309 (0.399559)  loss 1.413037 (1.391077)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7802.0 MB
2025-08-16 18:16:32,356 - WARNING - Epoch [8/25] Step [151/250]  acc 0.445365 (0.400172)  loss 1.401226 (1.390836)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:16:37,020 - WARNING - Epoch [8/25] Step [161/250]  acc 0.377161 (0.400933)  loss 1.437840 (1.389167)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:16:41,448 - WARNING - Epoch [8/25] Step [171/250]  acc 0.417865 (0.401252)  loss 1.358791 (1.388776)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:16:45,845 - WARNING - Epoch [8/25] Step [181/250]  acc 0.448258 (0.402580)  loss 1.291217 (1.386171)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:16:50,332 - WARNING - Epoch [8/25] Step [191/250]  acc 0.405834 (0.403754)  loss 1.329133 (1.382624)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7802.0 MB
2025-08-16 18:16:54,723 - WARNING - Epoch [8/25] Step [201/250]  acc 0.423986 (0.404999)  loss 1.350842 (1.380212)
GPU memory consumption  GPU Memory: Allocated: 52.2 MB, Reserved: 7802.0 MB
2025-08-16 18:16:59,367 - WARNING - Epoch [8/25] Step [211/250]  acc 0.454693 (0.406478)  loss 1.268503 (1.378104)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 7802.0 MB
2025-08-16 18:17:04,168 - WARNING - Epoch [8/25] Step [221/250]  acc 0.409619 (0.407502)  loss 1.359827 (1.375978)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
2025-08-16 18:17:09,067 - WARNING - Epoch [8/25] Step [231/250]  acc 0.427000 (0.408801)  loss 1.400422 (1.372246)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7802.0 MB
2025-08-16 18:17:13,901 - WARNING - Epoch [8/25] Step [241/250]  acc 0.388634 (0.408961)  loss 1.442552 (1.372273)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7802.0 MB
Epoch 8 completed in 0:01:52.551261
2025-08-16 18:17:47,143 - WARNING - Epoch [9/25] Step [1/250]  acc 0.418693 (0.418693)  loss 1.299313 (1.299313)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:17:51,387 - WARNING - Epoch [9/25] Step [11/250]  acc 0.432418 (0.417573)  loss 1.360549 (1.345972)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7802.0 MB
2025-08-16 18:17:55,785 - WARNING - Epoch [9/25] Step [21/250]  acc 0.389714 (0.420605)  loss 1.395744 (1.342806)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7802.0 MB
2025-08-16 18:18:00,487 - WARNING - Epoch [9/25] Step [31/250]  acc 0.462527 (0.421037)  loss 1.292927 (1.336672)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7802.0 MB
2025-08-16 18:18:05,220 - WARNING - Epoch [9/25] Step [41/250]  acc 0.476600 (0.427461)  loss 1.264994 (1.326990)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:18:09,838 - WARNING - Epoch [9/25] Step [51/250]  acc 0.485699 (0.428802)  loss 1.313303 (1.328877)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:18:14,675 - WARNING - Epoch [9/25] Step [61/250]  acc 0.406625 (0.429480)  loss 1.330180 (1.327440)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 7802.0 MB
2025-08-16 18:18:19,515 - WARNING - Epoch [9/25] Step [71/250]  acc 0.470622 (0.431242)  loss 1.336209 (1.326486)
GPU memory consumption  GPU Memory: Allocated: 52.6 MB, Reserved: 7802.0 MB
2025-08-16 18:18:24,400 - WARNING - Epoch [9/25] Step [81/250]  acc 0.482866 (0.432851)  loss 1.232313 (1.320702)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:18:29,234 - WARNING - Epoch [9/25] Step [91/250]  acc 0.447769 (0.434933)  loss 1.283850 (1.318572)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 7802.0 MB
2025-08-16 18:18:34,063 - WARNING - Epoch [9/25] Step [101/250]  acc 0.446737 (0.435012)  loss 1.294480 (1.316788)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:18:39,149 - WARNING - Epoch [9/25] Step [111/250]  acc 0.486283 (0.434828)  loss 1.223053 (1.316645)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:18:43,828 - WARNING - Epoch [9/25] Step [121/250]  acc 0.402928 (0.432869)  loss 1.378866 (1.319129)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:18:48,314 - WARNING - Epoch [9/25] Step [131/250]  acc 0.449679 (0.432613)  loss 1.285664 (1.318632)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7802.0 MB
2025-08-16 18:18:52,940 - WARNING - Epoch [9/25] Step [141/250]  acc 0.444759 (0.433503)  loss 1.298243 (1.316392)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 7802.0 MB
2025-08-16 18:18:57,597 - WARNING - Epoch [9/25] Step [151/250]  acc 0.410285 (0.433039)  loss 1.316198 (1.316062)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 7802.0 MB
2025-08-16 18:19:02,288 - WARNING - Epoch [9/25] Step [161/250]  acc 0.438159 (0.433788)  loss 1.356374 (1.316143)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7802.0 MB
2025-08-16 18:19:06,902 - WARNING - Epoch [9/25] Step [171/250]  acc 0.463479 (0.433176)  loss 1.274559 (1.315857)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7802.0 MB
2025-08-16 18:19:11,884 - WARNING - Epoch [9/25] Step [181/250]  acc 0.456260 (0.434106)  loss 1.235437 (1.313157)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:19:16,543 - WARNING - Epoch [9/25] Step [191/250]  acc 0.424905 (0.434165)  loss 1.294408 (1.312257)
GPU memory consumption  GPU Memory: Allocated: 60.8 MB, Reserved: 7802.0 MB
2025-08-16 18:19:21,321 - WARNING - Epoch [9/25] Step [201/250]  acc 0.406267 (0.433942)  loss 1.334067 (1.312536)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7802.0 MB
2025-08-16 18:19:26,124 - WARNING - Epoch [9/25] Step [211/250]  acc 0.396867 (0.434119)  loss 1.370877 (1.312282)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7802.0 MB
2025-08-16 18:19:30,974 - WARNING - Epoch [9/25] Step [221/250]  acc 0.472160 (0.435524)  loss 1.228919 (1.309802)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
2025-08-16 18:19:35,880 - WARNING - Epoch [9/25] Step [231/250]  acc 0.453245 (0.435782)  loss 1.256335 (1.308503)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7802.0 MB
2025-08-16 18:19:40,706 - WARNING - Epoch [9/25] Step [241/250]  acc 0.434303 (0.435595)  loss 1.317078 (1.308220)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7802.0 MB
Epoch 9 completed in 0:01:58.369466
2025-08-16 18:20:14,860 - WARNING - Epoch [10/25] Step [1/250]  acc 0.442121 (0.442121)  loss 1.312128 (1.312128)
GPU memory consumption  GPU Memory: Allocated: 60.0 MB, Reserved: 7802.0 MB
2025-08-16 18:20:19,928 - WARNING - Epoch [10/25] Step [11/250]  acc 0.424194 (0.448964)  loss 1.325416 (1.284522)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7802.0 MB
2025-08-16 18:20:24,838 - WARNING - Epoch [10/25] Step [21/250]  acc 0.404835 (0.449765)  loss 1.325989 (1.278746)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:20:29,662 - WARNING - Epoch [10/25] Step [31/250]  acc 0.438110 (0.442327)  loss 1.236051 (1.277946)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7802.0 MB
2025-08-16 18:20:34,518 - WARNING - Epoch [10/25] Step [41/250]  acc 0.482299 (0.444180)  loss 1.269435 (1.275928)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:20:39,486 - WARNING - Epoch [10/25] Step [51/250]  acc 0.504231 (0.446516)  loss 1.147402 (1.273877)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7802.0 MB
2025-08-16 18:20:44,582 - WARNING - Epoch [10/25] Step [61/250]  acc 0.467024 (0.446162)  loss 1.272287 (1.275264)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7802.0 MB
2025-08-16 18:20:49,362 - WARNING - Epoch [10/25] Step [71/250]  acc 0.422174 (0.446641)  loss 1.325522 (1.275352)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 7802.0 MB
2025-08-16 18:20:54,192 - WARNING - Epoch [10/25] Step [81/250]  acc 0.486849 (0.447022)  loss 1.253970 (1.275366)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:20:58,976 - WARNING - Epoch [10/25] Step [91/250]  acc 0.479857 (0.447404)  loss 1.168526 (1.277225)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7802.0 MB
2025-08-16 18:21:03,855 - WARNING - Epoch [10/25] Step [101/250]  acc 0.481423 (0.447827)  loss 1.203417 (1.276538)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7802.0 MB
2025-08-16 18:21:08,705 - WARNING - Epoch [10/25] Step [111/250]  acc 0.448691 (0.446535)  loss 1.283466 (1.278351)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7802.0 MB
2025-08-16 18:21:13,422 - WARNING - Epoch [10/25] Step [121/250]  acc 0.440000 (0.446454)  loss 1.346190 (1.277557)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:21:18,178 - WARNING - Epoch [10/25] Step [131/250]  acc 0.482827 (0.445570)  loss 1.209975 (1.280026)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 7802.0 MB
2025-08-16 18:21:23,218 - WARNING - Epoch [10/25] Step [141/250]  acc 0.435102 (0.445556)  loss 1.255791 (1.279394)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:21:27,665 - WARNING - Epoch [10/25] Step [151/250]  acc 0.432526 (0.445684)  loss 1.359561 (1.279324)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 7802.0 MB
2025-08-16 18:21:32,208 - WARNING - Epoch [10/25] Step [161/250]  acc 0.481462 (0.445141)  loss 1.221822 (1.280608)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:21:37,012 - WARNING - Epoch [10/25] Step [171/250]  acc 0.364397 (0.444892)  loss 1.439690 (1.281302)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7802.0 MB
2025-08-16 18:21:41,473 - WARNING - Epoch [10/25] Step [181/250]  acc 0.466231 (0.444706)  loss 1.232306 (1.280884)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7802.0 MB
2025-08-16 18:21:45,976 - WARNING - Epoch [10/25] Step [191/250]  acc 0.461194 (0.444174)  loss 1.230538 (1.281766)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 7802.0 MB
2025-08-16 18:21:50,344 - WARNING - Epoch [10/25] Step [201/250]  acc 0.472294 (0.444744)  loss 1.206651 (1.281230)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:21:54,684 - WARNING - Epoch [10/25] Step [211/250]  acc 0.409569 (0.444075)  loss 1.328211 (1.283590)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7802.0 MB
2025-08-16 18:21:59,061 - WARNING - Epoch [10/25] Step [221/250]  acc 0.369354 (0.443035)  loss 1.414764 (1.283919)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7802.0 MB
2025-08-16 18:22:03,400 - WARNING - Epoch [10/25] Step [231/250]  acc 0.491402 (0.443554)  loss 1.190941 (1.283317)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7802.0 MB
2025-08-16 18:22:07,775 - WARNING - Epoch [10/25] Step [241/250]  acc 0.473363 (0.444539)  loss 1.266439 (1.281286)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
Epoch 10 completed in 0:01:57.404121
2025-08-16 18:22:39,775 - WARNING - Epoch [11/25] Step [1/250]  acc 0.458131 (0.458131)  loss 1.293202 (1.293202)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:22:44,532 - WARNING - Epoch [11/25] Step [11/250]  acc 0.441130 (0.442892)  loss 1.257188 (1.254622)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:22:49,371 - WARNING - Epoch [11/25] Step [21/250]  acc 0.449179 (0.448161)  loss 1.321888 (1.260750)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:22:54,109 - WARNING - Epoch [11/25] Step [31/250]  acc 0.432493 (0.444219)  loss 1.331807 (1.271441)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7802.0 MB
2025-08-16 18:22:59,239 - WARNING - Epoch [11/25] Step [41/250]  acc 0.443655 (0.441442)  loss 1.260614 (1.275952)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:23:04,081 - WARNING - Epoch [11/25] Step [51/250]  acc 0.428571 (0.439889)  loss 1.257297 (1.272940)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 7802.0 MB
2025-08-16 18:23:08,928 - WARNING - Epoch [11/25] Step [61/250]  acc 0.436836 (0.442564)  loss 1.313713 (1.274058)
GPU memory consumption  GPU Memory: Allocated: 52.7 MB, Reserved: 7802.0 MB
2025-08-16 18:23:13,967 - WARNING - Epoch [11/25] Step [71/250]  acc 0.433836 (0.443086)  loss 1.237429 (1.273267)
GPU memory consumption  GPU Memory: Allocated: 53.0 MB, Reserved: 7802.0 MB
2025-08-16 18:23:18,756 - WARNING - Epoch [11/25] Step [81/250]  acc 0.453842 (0.445794)  loss 1.271636 (1.267671)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:23:23,537 - WARNING - Epoch [11/25] Step [91/250]  acc 0.421919 (0.446326)  loss 1.277238 (1.269187)
GPU memory consumption  GPU Memory: Allocated: 52.8 MB, Reserved: 7802.0 MB
2025-08-16 18:23:28,399 - WARNING - Epoch [11/25] Step [101/250]  acc 0.423157 (0.447537)  loss 1.321264 (1.267609)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7802.0 MB
2025-08-16 18:23:33,329 - WARNING - Epoch [11/25] Step [111/250]  acc 0.468085 (0.448030)  loss 1.243500 (1.266576)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7802.0 MB
2025-08-16 18:23:38,182 - WARNING - Epoch [11/25] Step [121/250]  acc 0.469163 (0.449060)  loss 1.229684 (1.262953)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:23:42,962 - WARNING - Epoch [11/25] Step [131/250]  acc 0.424931 (0.448633)  loss 1.302419 (1.264640)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7802.0 MB
2025-08-16 18:23:47,709 - WARNING - Epoch [11/25] Step [141/250]  acc 0.407312 (0.447751)  loss 1.401577 (1.265356)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:23:52,480 - WARNING - Epoch [11/25] Step [151/250]  acc 0.440529 (0.448187)  loss 1.338832 (1.265686)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 7802.0 MB
2025-08-16 18:23:57,218 - WARNING - Epoch [11/25] Step [161/250]  acc 0.478512 (0.449216)  loss 1.178309 (1.264333)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:24:02,073 - WARNING - Epoch [11/25] Step [171/250]  acc 0.478782 (0.449540)  loss 1.195864 (1.262782)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7802.0 MB
2025-08-16 18:24:07,138 - WARNING - Epoch [11/25] Step [181/250]  acc 0.429683 (0.449837)  loss 1.322771 (1.264010)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 7802.0 MB
2025-08-16 18:24:12,005 - WARNING - Epoch [11/25] Step [191/250]  acc 0.475083 (0.451217)  loss 1.205438 (1.261165)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7802.0 MB
2025-08-16 18:24:16,843 - WARNING - Epoch [11/25] Step [201/250]  acc 0.441281 (0.451165)  loss 1.309036 (1.262007)
GPU memory consumption  GPU Memory: Allocated: 51.2 MB, Reserved: 7802.0 MB
2025-08-16 18:24:21,672 - WARNING - Epoch [11/25] Step [211/250]  acc 0.444793 (0.451128)  loss 1.252288 (1.261712)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7802.0 MB
2025-08-16 18:24:26,890 - WARNING - Epoch [11/25] Step [221/250]  acc 0.493726 (0.451169)  loss 1.180173 (1.261238)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:24:31,704 - WARNING - Epoch [11/25] Step [231/250]  acc 0.411205 (0.451075)  loss 1.324309 (1.260626)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7802.0 MB
2025-08-16 18:24:36,554 - WARNING - Epoch [11/25] Step [241/250]  acc 0.435669 (0.451135)  loss 1.196540 (1.259870)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7802.0 MB
Epoch 11 completed in 0:02:01.603461
2025-08-16 18:25:10,803 - WARNING - Epoch [12/25] Step [1/250]  acc 0.487442 (0.487442)  loss 1.147126 (1.147126)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:25:15,621 - WARNING - Epoch [12/25] Step [11/250]  acc 0.416255 (0.443844)  loss 1.318226 (1.272796)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 7802.0 MB
2025-08-16 18:25:20,553 - WARNING - Epoch [12/25] Step [21/250]  acc 0.390230 (0.450064)  loss 1.405475 (1.271407)
GPU memory consumption  GPU Memory: Allocated: 53.0 MB, Reserved: 7802.0 MB
2025-08-16 18:25:25,495 - WARNING - Epoch [12/25] Step [31/250]  acc 0.452431 (0.452646)  loss 1.201088 (1.261386)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 7802.0 MB
2025-08-16 18:25:30,302 - WARNING - Epoch [12/25] Step [41/250]  acc 0.456577 (0.451898)  loss 1.241175 (1.253764)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:25:35,146 - WARNING - Epoch [12/25] Step [51/250]  acc 0.528826 (0.456203)  loss 1.096372 (1.247120)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:25:39,979 - WARNING - Epoch [12/25] Step [61/250]  acc 0.451180 (0.456441)  loss 1.334848 (1.249214)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7802.0 MB
2025-08-16 18:25:44,873 - WARNING - Epoch [12/25] Step [71/250]  acc 0.454124 (0.456095)  loss 1.212945 (1.252780)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:25:49,790 - WARNING - Epoch [12/25] Step [81/250]  acc 0.418687 (0.454893)  loss 1.301651 (1.252918)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:25:54,675 - WARNING - Epoch [12/25] Step [91/250]  acc 0.444893 (0.455145)  loss 1.287623 (1.251306)
GPU memory consumption  GPU Memory: Allocated: 52.4 MB, Reserved: 7802.0 MB
2025-08-16 18:25:59,568 - WARNING - Epoch [12/25] Step [101/250]  acc 0.465598 (0.454387)  loss 1.281619 (1.252926)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7802.0 MB
2025-08-16 18:26:04,392 - WARNING - Epoch [12/25] Step [111/250]  acc 0.451681 (0.453607)  loss 1.283073 (1.253097)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7802.0 MB
2025-08-16 18:26:09,208 - WARNING - Epoch [12/25] Step [121/250]  acc 0.463087 (0.454446)  loss 1.204586 (1.251813)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:26:14,350 - WARNING - Epoch [12/25] Step [131/250]  acc 0.440854 (0.454559)  loss 1.224852 (1.250733)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:26:19,243 - WARNING - Epoch [12/25] Step [141/250]  acc 0.436794 (0.453789)  loss 1.319360 (1.252598)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7802.0 MB
2025-08-16 18:26:24,129 - WARNING - Epoch [12/25] Step [151/250]  acc 0.476410 (0.454506)  loss 1.210631 (1.251489)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:26:29,026 - WARNING - Epoch [12/25] Step [161/250]  acc 0.494888 (0.454899)  loss 1.130150 (1.250648)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:26:33,765 - WARNING - Epoch [12/25] Step [171/250]  acc 0.490395 (0.455720)  loss 1.218585 (1.249443)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7802.0 MB
2025-08-16 18:26:38,829 - WARNING - Epoch [12/25] Step [181/250]  acc 0.429867 (0.454741)  loss 1.318594 (1.251572)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
2025-08-16 18:26:43,646 - WARNING - Epoch [12/25] Step [191/250]  acc 0.398530 (0.454211)  loss 1.375058 (1.252409)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7802.0 MB
2025-08-16 18:26:48,445 - WARNING - Epoch [12/25] Step [201/250]  acc 0.442721 (0.454002)  loss 1.187696 (1.252517)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7802.0 MB
2025-08-16 18:26:53,297 - WARNING - Epoch [12/25] Step [211/250]  acc 0.488827 (0.453841)  loss 1.206131 (1.253161)
GPU memory consumption  GPU Memory: Allocated: 52.9 MB, Reserved: 7802.0 MB
2025-08-16 18:26:58,082 - WARNING - Epoch [12/25] Step [221/250]  acc 0.429971 (0.452976)  loss 1.280883 (1.255185)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7802.0 MB
2025-08-16 18:27:02,950 - WARNING - Epoch [12/25] Step [231/250]  acc 0.461945 (0.451786)  loss 1.228668 (1.256167)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7802.0 MB
2025-08-16 18:27:07,756 - WARNING - Epoch [12/25] Step [241/250]  acc 0.472070 (0.450906)  loss 1.242076 (1.257132)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7802.0 MB
Epoch 12 completed in 0:02:01.833891
2025-08-16 18:27:41,751 - WARNING - Epoch [13/25] Step [1/250]  acc 0.454545 (0.454545)  loss 1.329817 (1.329817)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:27:46,593 - WARNING - Epoch [13/25] Step [11/250]  acc 0.447222 (0.457989)  loss 1.246636 (1.256897)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:27:51,433 - WARNING - Epoch [13/25] Step [21/250]  acc 0.452381 (0.461034)  loss 1.328926 (1.261697)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:27:56,637 - WARNING - Epoch [13/25] Step [31/250]  acc 0.461912 (0.463245)  loss 1.186092 (1.248417)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:28:01,463 - WARNING - Epoch [13/25] Step [41/250]  acc 0.439806 (0.461132)  loss 1.252411 (1.242877)
GPU memory consumption  GPU Memory: Allocated: 58.8 MB, Reserved: 7802.0 MB
2025-08-16 18:28:06,429 - WARNING - Epoch [13/25] Step [51/250]  acc 0.433371 (0.459127)  loss 1.282828 (1.250226)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
2025-08-16 18:28:11,312 - WARNING - Epoch [13/25] Step [61/250]  acc 0.432599 (0.456341)  loss 1.315791 (1.250819)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:28:16,063 - WARNING - Epoch [13/25] Step [71/250]  acc 0.428947 (0.456791)  loss 1.345515 (1.250513)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7802.0 MB
2025-08-16 18:28:20,922 - WARNING - Epoch [13/25] Step [81/250]  acc 0.468413 (0.456703)  loss 1.177074 (1.250404)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:28:25,798 - WARNING - Epoch [13/25] Step [91/250]  acc 0.438249 (0.456333)  loss 1.330423 (1.249106)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:28:30,679 - WARNING - Epoch [13/25] Step [101/250]  acc 0.449318 (0.456096)  loss 1.219186 (1.246839)
GPU memory consumption  GPU Memory: Allocated: 61.4 MB, Reserved: 7802.0 MB
2025-08-16 18:28:35,548 - WARNING - Epoch [13/25] Step [111/250]  acc 0.473302 (0.455382)  loss 1.233212 (1.246538)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7802.0 MB
2025-08-16 18:28:40,504 - WARNING - Epoch [13/25] Step [121/250]  acc 0.402089 (0.454106)  loss 1.284081 (1.247719)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:28:45,293 - WARNING - Epoch [13/25] Step [131/250]  acc 0.465810 (0.453304)  loss 1.207728 (1.251449)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:28:50,165 - WARNING - Epoch [13/25] Step [141/250]  acc 0.469368 (0.453347)  loss 1.161797 (1.251141)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 7802.0 MB
2025-08-16 18:28:54,991 - WARNING - Epoch [13/25] Step [151/250]  acc 0.492553 (0.453851)  loss 1.163568 (1.249454)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:28:59,843 - WARNING - Epoch [13/25] Step [161/250]  acc 0.447604 (0.454285)  loss 1.247689 (1.247705)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
2025-08-16 18:29:04,857 - WARNING - Epoch [13/25] Step [171/250]  acc 0.506038 (0.454902)  loss 1.272154 (1.247278)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 7802.0 MB
2025-08-16 18:29:10,044 - WARNING - Epoch [13/25] Step [181/250]  acc 0.491444 (0.455024)  loss 1.227883 (1.248331)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:29:14,745 - WARNING - Epoch [13/25] Step [191/250]  acc 0.438017 (0.455480)  loss 1.291265 (1.247077)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7802.0 MB
2025-08-16 18:29:19,491 - WARNING - Epoch [13/25] Step [201/250]  acc 0.401306 (0.456130)  loss 1.357818 (1.245672)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
2025-08-16 18:29:24,233 - WARNING - Epoch [13/25] Step [211/250]  acc 0.451581 (0.456379)  loss 1.244278 (1.245074)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7802.0 MB
2025-08-16 18:29:29,079 - WARNING - Epoch [13/25] Step [221/250]  acc 0.412121 (0.455525)  loss 1.237974 (1.246874)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7802.0 MB
2025-08-16 18:29:34,180 - WARNING - Epoch [13/25] Step [231/250]  acc 0.452643 (0.455725)  loss 1.231119 (1.246448)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7802.0 MB
2025-08-16 18:29:39,259 - WARNING - Epoch [13/25] Step [241/250]  acc 0.485204 (0.455492)  loss 1.244896 (1.246833)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7802.0 MB
Epoch 13 completed in 0:02:02.413925
2025-08-16 18:30:13,117 - WARNING - Epoch [14/25] Step [1/250]  acc 0.451684 (0.451684)  loss 1.277877 (1.277877)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 7802.0 MB
2025-08-16 18:30:18,051 - WARNING - Epoch [14/25] Step [11/250]  acc 0.463280 (0.458737)  loss 1.269443 (1.252289)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 7802.0 MB
2025-08-16 18:30:22,791 - WARNING - Epoch [14/25] Step [21/250]  acc 0.418629 (0.463849)  loss 1.361210 (1.241204)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:30:27,496 - WARNING - Epoch [14/25] Step [31/250]  acc 0.406385 (0.460785)  loss 1.239527 (1.240058)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:30:32,285 - WARNING - Epoch [14/25] Step [41/250]  acc 0.523810 (0.461352)  loss 1.130102 (1.235474)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:30:36,970 - WARNING - Epoch [14/25] Step [51/250]  acc 0.437281 (0.461166)  loss 1.294827 (1.232741)
GPU memory consumption  GPU Memory: Allocated: 59.3 MB, Reserved: 7802.0 MB
2025-08-16 18:30:41,747 - WARNING - Epoch [14/25] Step [61/250]  acc 0.435998 (0.460815)  loss 1.270536 (1.233691)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:30:46,533 - WARNING - Epoch [14/25] Step [71/250]  acc 0.495238 (0.460659)  loss 1.216040 (1.232130)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7802.0 MB
2025-08-16 18:30:51,170 - WARNING - Epoch [14/25] Step [81/250]  acc 0.428412 (0.461664)  loss 1.186410 (1.229487)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7802.0 MB
2025-08-16 18:30:56,055 - WARNING - Epoch [14/25] Step [91/250]  acc 0.457267 (0.461581)  loss 1.177948 (1.227427)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 7802.0 MB
2025-08-16 18:31:00,869 - WARNING - Epoch [14/25] Step [101/250]  acc 0.451090 (0.463451)  loss 1.230347 (1.224900)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 7802.0 MB
2025-08-16 18:31:05,779 - WARNING - Epoch [14/25] Step [111/250]  acc 0.394945 (0.463330)  loss 1.408282 (1.224367)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:31:10,726 - WARNING - Epoch [14/25] Step [121/250]  acc 0.492913 (0.464199)  loss 1.137150 (1.222550)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:31:15,502 - WARNING - Epoch [14/25] Step [131/250]  acc 0.425885 (0.464547)  loss 1.236030 (1.222098)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7802.0 MB
2025-08-16 18:31:20,268 - WARNING - Epoch [14/25] Step [141/250]  acc 0.446924 (0.464877)  loss 1.246089 (1.220224)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7802.0 MB
2025-08-16 18:31:25,090 - WARNING - Epoch [14/25] Step [151/250]  acc 0.475490 (0.465169)  loss 1.171024 (1.218730)
GPU memory consumption  GPU Memory: Allocated: 51.7 MB, Reserved: 7802.0 MB
2025-08-16 18:31:30,009 - WARNING - Epoch [14/25] Step [161/250]  acc 0.489406 (0.465542)  loss 1.155991 (1.217426)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:31:35,083 - WARNING - Epoch [14/25] Step [171/250]  acc 0.438724 (0.465988)  loss 1.282234 (1.217567)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7802.0 MB
2025-08-16 18:31:39,865 - WARNING - Epoch [14/25] Step [181/250]  acc 0.497890 (0.466877)  loss 1.114981 (1.215178)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:31:44,737 - WARNING - Epoch [14/25] Step [191/250]  acc 0.483539 (0.467384)  loss 1.186156 (1.213947)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7802.0 MB
2025-08-16 18:31:49,536 - WARNING - Epoch [14/25] Step [201/250]  acc 0.455090 (0.468566)  loss 1.194868 (1.212743)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 7802.0 MB
2025-08-16 18:31:54,402 - WARNING - Epoch [14/25] Step [211/250]  acc 0.463326 (0.468016)  loss 1.193174 (1.213403)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7802.0 MB
2025-08-16 18:31:59,260 - WARNING - Epoch [14/25] Step [221/250]  acc 0.511604 (0.468218)  loss 1.112396 (1.213905)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:32:04,026 - WARNING - Epoch [14/25] Step [231/250]  acc 0.469720 (0.467862)  loss 1.236339 (1.213413)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7802.0 MB
2025-08-16 18:32:08,967 - WARNING - Epoch [14/25] Step [241/250]  acc 0.496220 (0.467629)  loss 1.136703 (1.214580)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
Epoch 14 completed in 0:02:00.559750
2025-08-16 18:32:41,754 - WARNING - Epoch [15/25] Step [1/250]  acc 0.521603 (0.521603)  loss 1.133180 (1.133180)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:32:46,540 - WARNING - Epoch [15/25] Step [11/250]  acc 0.466321 (0.482617)  loss 1.227999 (1.193956)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:32:51,447 - WARNING - Epoch [15/25] Step [21/250]  acc 0.415539 (0.476071)  loss 1.311309 (1.196830)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 7802.0 MB
2025-08-16 18:32:56,092 - WARNING - Epoch [15/25] Step [31/250]  acc 0.436176 (0.475524)  loss 1.379649 (1.204365)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7802.0 MB
2025-08-16 18:33:00,801 - WARNING - Epoch [15/25] Step [41/250]  acc 0.499469 (0.474396)  loss 1.217737 (1.207055)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:33:05,514 - WARNING - Epoch [15/25] Step [51/250]  acc 0.504496 (0.473283)  loss 1.170560 (1.206742)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 7802.0 MB
2025-08-16 18:33:10,220 - WARNING - Epoch [15/25] Step [61/250]  acc 0.513180 (0.473576)  loss 1.141619 (1.206908)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 7802.0 MB
2025-08-16 18:33:14,898 - WARNING - Epoch [15/25] Step [71/250]  acc 0.439759 (0.470923)  loss 1.222068 (1.210903)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7802.0 MB
2025-08-16 18:33:19,602 - WARNING - Epoch [15/25] Step [81/250]  acc 0.541667 (0.468846)  loss 1.164158 (1.213656)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:33:24,154 - WARNING - Epoch [15/25] Step [91/250]  acc 0.516279 (0.468423)  loss 1.225722 (1.216694)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:33:28,809 - WARNING - Epoch [15/25] Step [101/250]  acc 0.472176 (0.469581)  loss 1.227119 (1.218181)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 7802.0 MB
2025-08-16 18:33:33,425 - WARNING - Epoch [15/25] Step [111/250]  acc 0.452343 (0.469912)  loss 1.215781 (1.215618)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:33:38,054 - WARNING - Epoch [15/25] Step [121/250]  acc 0.456061 (0.469332)  loss 1.196967 (1.216795)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:33:42,744 - WARNING - Epoch [15/25] Step [131/250]  acc 0.501024 (0.468184)  loss 1.098256 (1.218745)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:33:47,771 - WARNING - Epoch [15/25] Step [141/250]  acc 0.443455 (0.468494)  loss 1.172648 (1.219259)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:33:52,576 - WARNING - Epoch [15/25] Step [151/250]  acc 0.472125 (0.468472)  loss 1.215268 (1.218641)
GPU memory consumption  GPU Memory: Allocated: 52.9 MB, Reserved: 7802.0 MB
2025-08-16 18:33:57,423 - WARNING - Epoch [15/25] Step [161/250]  acc 0.471585 (0.468466)  loss 1.196461 (1.217494)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 7802.0 MB
2025-08-16 18:34:02,266 - WARNING - Epoch [15/25] Step [171/250]  acc 0.417943 (0.467386)  loss 1.244858 (1.218966)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7802.0 MB
2025-08-16 18:34:07,098 - WARNING - Epoch [15/25] Step [181/250]  acc 0.495190 (0.468402)  loss 1.156218 (1.217214)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7802.0 MB
2025-08-16 18:34:11,787 - WARNING - Epoch [15/25] Step [191/250]  acc 0.444573 (0.468193)  loss 1.325264 (1.218455)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 7802.0 MB
2025-08-16 18:34:16,693 - WARNING - Epoch [15/25] Step [201/250]  acc 0.486895 (0.468287)  loss 1.155745 (1.218472)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
2025-08-16 18:34:21,388 - WARNING - Epoch [15/25] Step [211/250]  acc 0.448128 (0.467889)  loss 1.234628 (1.219559)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 7802.0 MB
2025-08-16 18:34:26,052 - WARNING - Epoch [15/25] Step [221/250]  acc 0.474160 (0.467974)  loss 1.214641 (1.219166)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:34:30,730 - WARNING - Epoch [15/25] Step [231/250]  acc 0.441312 (0.467525)  loss 1.232549 (1.219168)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7802.0 MB
2025-08-16 18:34:35,336 - WARNING - Epoch [15/25] Step [241/250]  acc 0.518933 (0.468019)  loss 1.127477 (1.218321)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7802.0 MB
Epoch 15 completed in 0:01:58.256698
2025-08-16 18:35:10,924 - WARNING - Epoch [16/25] Step [1/250]  acc 0.448181 (0.448181)  loss 1.299613 (1.299613)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 7802.0 MB
2025-08-16 18:35:15,740 - WARNING - Epoch [16/25] Step [11/250]  acc 0.464486 (0.468456)  loss 1.139282 (1.190602)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:35:20,405 - WARNING - Epoch [16/25] Step [21/250]  acc 0.472403 (0.475627)  loss 1.226748 (1.183926)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
2025-08-16 18:35:25,075 - WARNING - Epoch [16/25] Step [31/250]  acc 0.491192 (0.474870)  loss 1.116817 (1.184046)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7802.0 MB
2025-08-16 18:35:29,798 - WARNING - Epoch [16/25] Step [41/250]  acc 0.459459 (0.467120)  loss 1.192410 (1.205691)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
2025-08-16 18:35:34,563 - WARNING - Epoch [16/25] Step [51/250]  acc 0.448556 (0.466157)  loss 1.250834 (1.205708)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:35:39,163 - WARNING - Epoch [16/25] Step [61/250]  acc 0.480967 (0.465695)  loss 1.169376 (1.207192)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:35:43,770 - WARNING - Epoch [16/25] Step [71/250]  acc 0.498657 (0.466419)  loss 1.239103 (1.209507)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7802.0 MB
2025-08-16 18:35:48,310 - WARNING - Epoch [16/25] Step [81/250]  acc 0.480715 (0.464289)  loss 1.207026 (1.213715)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7802.0 MB
2025-08-16 18:35:52,861 - WARNING - Epoch [16/25] Step [91/250]  acc 0.393611 (0.466256)  loss 1.349296 (1.210852)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 7802.0 MB
2025-08-16 18:35:57,395 - WARNING - Epoch [16/25] Step [101/250]  acc 0.464730 (0.465765)  loss 1.260084 (1.212291)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7802.0 MB
2025-08-16 18:36:01,937 - WARNING - Epoch [16/25] Step [111/250]  acc 0.449797 (0.465589)  loss 1.186625 (1.212707)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7802.0 MB
2025-08-16 18:36:06,406 - WARNING - Epoch [16/25] Step [121/250]  acc 0.460668 (0.465528)  loss 1.251259 (1.213297)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 7802.0 MB
2025-08-16 18:36:10,991 - WARNING - Epoch [16/25] Step [131/250]  acc 0.491398 (0.466993)  loss 1.201602 (1.209565)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7802.0 MB
2025-08-16 18:36:15,536 - WARNING - Epoch [16/25] Step [141/250]  acc 0.447531 (0.468040)  loss 1.149873 (1.207554)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:36:19,891 - WARNING - Epoch [16/25] Step [151/250]  acc 0.522333 (0.467683)  loss 1.157832 (1.210470)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
2025-08-16 18:36:24,344 - WARNING - Epoch [16/25] Step [161/250]  acc 0.500549 (0.468083)  loss 1.157489 (1.209601)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7802.0 MB
2025-08-16 18:36:28,874 - WARNING - Epoch [16/25] Step [171/250]  acc 0.478073 (0.466717)  loss 1.223501 (1.212343)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7802.0 MB
2025-08-16 18:36:33,467 - WARNING - Epoch [16/25] Step [181/250]  acc 0.486111 (0.466429)  loss 1.125324 (1.212925)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:36:38,041 - WARNING - Epoch [16/25] Step [191/250]  acc 0.480106 (0.466358)  loss 1.192222 (1.213309)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:36:42,861 - WARNING - Epoch [16/25] Step [201/250]  acc 0.455947 (0.466801)  loss 1.269893 (1.213653)
GPU memory consumption  GPU Memory: Allocated: 52.8 MB, Reserved: 7802.0 MB
2025-08-16 18:36:47,504 - WARNING - Epoch [16/25] Step [211/250]  acc 0.477110 (0.466114)  loss 1.173427 (1.214315)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 7802.0 MB
2025-08-16 18:36:52,102 - WARNING - Epoch [16/25] Step [221/250]  acc 0.470961 (0.466715)  loss 1.269289 (1.213548)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 7802.0 MB
2025-08-16 18:36:56,657 - WARNING - Epoch [16/25] Step [231/250]  acc 0.457207 (0.466869)  loss 1.206679 (1.212879)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7802.0 MB
2025-08-16 18:37:01,254 - WARNING - Epoch [16/25] Step [241/250]  acc 0.504622 (0.467428)  loss 1.169680 (1.212511)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
Epoch 16 completed in 0:01:54.989129
2025-08-16 18:37:33,913 - WARNING - Epoch [17/25] Step [1/250]  acc 0.488009 (0.488009)  loss 1.167265 (1.167265)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7802.0 MB
2025-08-16 18:37:38,527 - WARNING - Epoch [17/25] Step [11/250]  acc 0.465027 (0.480493)  loss 1.246240 (1.215021)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 7802.0 MB
2025-08-16 18:37:43,075 - WARNING - Epoch [17/25] Step [21/250]  acc 0.487381 (0.471257)  loss 1.231968 (1.224918)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7802.0 MB
2025-08-16 18:37:47,917 - WARNING - Epoch [17/25] Step [31/250]  acc 0.496956 (0.471485)  loss 1.121986 (1.208910)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:37:52,632 - WARNING - Epoch [17/25] Step [41/250]  acc 0.447505 (0.469699)  loss 1.225724 (1.210247)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:37:57,256 - WARNING - Epoch [17/25] Step [51/250]  acc 0.514315 (0.471805)  loss 1.118813 (1.202514)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:38:01,949 - WARNING - Epoch [17/25] Step [61/250]  acc 0.520263 (0.474057)  loss 1.092249 (1.197113)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:38:06,458 - WARNING - Epoch [17/25] Step [71/250]  acc 0.442726 (0.473357)  loss 1.219998 (1.197033)
GPU memory consumption  GPU Memory: Allocated: 52.6 MB, Reserved: 7802.0 MB
2025-08-16 18:38:10,869 - WARNING - Epoch [17/25] Step [81/250]  acc 0.491588 (0.472367)  loss 1.198655 (1.199970)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:38:15,161 - WARNING - Epoch [17/25] Step [91/250]  acc 0.399023 (0.471298)  loss 1.285494 (1.203949)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7802.0 MB
2025-08-16 18:38:19,732 - WARNING - Epoch [17/25] Step [101/250]  acc 0.416279 (0.469993)  loss 1.317652 (1.205035)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7802.0 MB
2025-08-16 18:38:24,226 - WARNING - Epoch [17/25] Step [111/250]  acc 0.453048 (0.469835)  loss 1.261995 (1.206334)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7802.0 MB
2025-08-16 18:38:28,745 - WARNING - Epoch [17/25] Step [121/250]  acc 0.518687 (0.470882)  loss 1.139990 (1.204841)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:38:33,434 - WARNING - Epoch [17/25] Step [131/250]  acc 0.497861 (0.472248)  loss 1.138745 (1.202493)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
2025-08-16 18:38:37,974 - WARNING - Epoch [17/25] Step [141/250]  acc 0.513584 (0.472301)  loss 1.126674 (1.202022)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:38:42,401 - WARNING - Epoch [17/25] Step [151/250]  acc 0.496602 (0.472068)  loss 1.100163 (1.202139)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
2025-08-16 18:38:46,852 - WARNING - Epoch [17/25] Step [161/250]  acc 0.469957 (0.471295)  loss 1.114715 (1.204041)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7802.0 MB
2025-08-16 18:38:51,396 - WARNING - Epoch [17/25] Step [171/250]  acc 0.510992 (0.471310)  loss 1.173531 (1.204416)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 7802.0 MB
2025-08-16 18:38:55,825 - WARNING - Epoch [17/25] Step [181/250]  acc 0.484303 (0.471059)  loss 1.188180 (1.204593)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:39:00,314 - WARNING - Epoch [17/25] Step [191/250]  acc 0.460512 (0.470966)  loss 1.292374 (1.205972)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7802.0 MB
2025-08-16 18:39:04,582 - WARNING - Epoch [17/25] Step [201/250]  acc 0.504733 (0.469813)  loss 1.126347 (1.209125)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7802.0 MB
2025-08-16 18:39:09,003 - WARNING - Epoch [17/25] Step [211/250]  acc 0.447071 (0.469280)  loss 1.161795 (1.209010)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7802.0 MB
2025-08-16 18:39:13,329 - WARNING - Epoch [17/25] Step [221/250]  acc 0.498765 (0.468983)  loss 1.183885 (1.208735)
GPU memory consumption  GPU Memory: Allocated: 58.4 MB, Reserved: 7802.0 MB
2025-08-16 18:39:17,683 - WARNING - Epoch [17/25] Step [231/250]  acc 0.420395 (0.469366)  loss 1.235884 (1.208062)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7802.0 MB
2025-08-16 18:39:22,145 - WARNING - Epoch [17/25] Step [241/250]  acc 0.456000 (0.469111)  loss 1.232047 (1.208168)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7802.0 MB
Epoch 17 completed in 0:01:52.664675
2025-08-16 18:39:53,723 - WARNING - Epoch [18/25] Step [1/250]  acc 0.487500 (0.487500)  loss 1.210185 (1.210185)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7802.0 MB
2025-08-16 18:39:58,340 - WARNING - Epoch [18/25] Step [11/250]  acc 0.460200 (0.461838)  loss 1.185712 (1.222390)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7802.0 MB
2025-08-16 18:40:02,938 - WARNING - Epoch [18/25] Step [21/250]  acc 0.513265 (0.467034)  loss 1.111315 (1.208933)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
2025-08-16 18:40:07,410 - WARNING - Epoch [18/25] Step [31/250]  acc 0.467042 (0.471244)  loss 1.184162 (1.207120)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7802.0 MB
2025-08-16 18:40:11,855 - WARNING - Epoch [18/25] Step [41/250]  acc 0.486952 (0.468163)  loss 1.134541 (1.207405)
GPU memory consumption  GPU Memory: Allocated: 61.1 MB, Reserved: 7802.0 MB
2025-08-16 18:40:16,374 - WARNING - Epoch [18/25] Step [51/250]  acc 0.471892 (0.472258)  loss 1.212454 (1.209511)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:40:20,692 - WARNING - Epoch [18/25] Step [61/250]  acc 0.406670 (0.470829)  loss 1.253310 (1.205446)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7802.0 MB
2025-08-16 18:40:25,000 - WARNING - Epoch [18/25] Step [71/250]  acc 0.451488 (0.473555)  loss 1.288076 (1.202144)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 7802.0 MB
2025-08-16 18:40:29,320 - WARNING - Epoch [18/25] Step [81/250]  acc 0.472078 (0.469927)  loss 1.255714 (1.206516)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7802.0 MB
2025-08-16 18:40:33,648 - WARNING - Epoch [18/25] Step [91/250]  acc 0.513874 (0.469825)  loss 1.111832 (1.205881)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 7802.0 MB
2025-08-16 18:40:37,867 - WARNING - Epoch [18/25] Step [101/250]  acc 0.528239 (0.470135)  loss 1.145039 (1.205968)
GPU memory consumption  GPU Memory: Allocated: 56.8 MB, Reserved: 7802.0 MB
2025-08-16 18:40:42,102 - WARNING - Epoch [18/25] Step [111/250]  acc 0.459415 (0.471008)  loss 1.237820 (1.204225)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:40:46,571 - WARNING - Epoch [18/25] Step [121/250]  acc 0.549746 (0.471061)  loss 1.085608 (1.201041)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:40:51,016 - WARNING - Epoch [18/25] Step [131/250]  acc 0.449675 (0.470987)  loss 1.281115 (1.201366)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7802.0 MB
2025-08-16 18:40:55,659 - WARNING - Epoch [18/25] Step [141/250]  acc 0.482795 (0.470840)  loss 1.149887 (1.201834)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:41:00,098 - WARNING - Epoch [18/25] Step [151/250]  acc 0.492144 (0.470185)  loss 1.135701 (1.201965)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 7802.0 MB
2025-08-16 18:41:04,716 - WARNING - Epoch [18/25] Step [161/250]  acc 0.482152 (0.470163)  loss 1.146734 (1.201963)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7802.0 MB
2025-08-16 18:41:09,026 - WARNING - Epoch [18/25] Step [171/250]  acc 0.522039 (0.470483)  loss 1.172770 (1.201719)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:41:13,313 - WARNING - Epoch [18/25] Step [181/250]  acc 0.503712 (0.470401)  loss 1.166062 (1.202951)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7802.0 MB
2025-08-16 18:41:17,673 - WARNING - Epoch [18/25] Step [191/250]  acc 0.452136 (0.469996)  loss 1.141853 (1.202625)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7802.0 MB
2025-08-16 18:41:22,030 - WARNING - Epoch [18/25] Step [201/250]  acc 0.422730 (0.469990)  loss 1.186082 (1.201782)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7802.0 MB
2025-08-16 18:41:26,442 - WARNING - Epoch [18/25] Step [211/250]  acc 0.488655 (0.470514)  loss 1.260510 (1.201882)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 7802.0 MB
2025-08-16 18:41:30,880 - WARNING - Epoch [18/25] Step [221/250]  acc 0.454592 (0.470759)  loss 1.250429 (1.201367)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:41:35,368 - WARNING - Epoch [18/25] Step [231/250]  acc 0.477531 (0.470249)  loss 1.209969 (1.201970)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:41:39,839 - WARNING - Epoch [18/25] Step [241/250]  acc 0.487841 (0.470390)  loss 1.157812 (1.202447)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7802.0 MB
Epoch 18 completed in 0:01:50.643019
2025-08-16 18:42:14,541 - WARNING - Epoch [19/25] Step [1/250]  acc 0.440511 (0.440511)  loss 1.192364 (1.192364)
GPU memory consumption  GPU Memory: Allocated: 59.6 MB, Reserved: 7802.0 MB
2025-08-16 18:42:19,017 - WARNING - Epoch [19/25] Step [11/250]  acc 0.491259 (0.456360)  loss 1.257372 (1.226642)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7802.0 MB
2025-08-16 18:42:23,466 - WARNING - Epoch [19/25] Step [21/250]  acc 0.499734 (0.464960)  loss 1.096379 (1.214573)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7802.0 MB
2025-08-16 18:42:27,861 - WARNING - Epoch [19/25] Step [31/250]  acc 0.534324 (0.463757)  loss 1.132380 (1.215070)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7802.0 MB
2025-08-16 18:42:32,345 - WARNING - Epoch [19/25] Step [41/250]  acc 0.476521 (0.466578)  loss 1.171362 (1.206436)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7802.0 MB
2025-08-16 18:42:36,713 - WARNING - Epoch [19/25] Step [51/250]  acc 0.477500 (0.468080)  loss 1.193784 (1.203622)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 7802.0 MB
2025-08-16 18:42:41,495 - WARNING - Epoch [19/25] Step [61/250]  acc 0.419708 (0.466953)  loss 1.198332 (1.205653)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:42:46,105 - WARNING - Epoch [19/25] Step [71/250]  acc 0.415592 (0.467196)  loss 1.210975 (1.206058)
GPU memory consumption  GPU Memory: Allocated: 53.1 MB, Reserved: 7802.0 MB
2025-08-16 18:42:50,770 - WARNING - Epoch [19/25] Step [81/250]  acc 0.433644 (0.467787)  loss 1.307436 (1.207190)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7802.0 MB
2025-08-16 18:42:55,423 - WARNING - Epoch [19/25] Step [91/250]  acc 0.510747 (0.470084)  loss 1.090637 (1.201384)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:42:59,855 - WARNING - Epoch [19/25] Step [101/250]  acc 0.478402 (0.471384)  loss 1.182140 (1.201043)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7802.0 MB
2025-08-16 18:43:04,264 - WARNING - Epoch [19/25] Step [111/250]  acc 0.447511 (0.468928)  loss 1.161091 (1.205657)
GPU memory consumption  GPU Memory: Allocated: 58.2 MB, Reserved: 7802.0 MB
2025-08-16 18:43:08,559 - WARNING - Epoch [19/25] Step [121/250]  acc 0.489474 (0.469314)  loss 1.132872 (1.205568)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7802.0 MB
2025-08-16 18:43:12,768 - WARNING - Epoch [19/25] Step [131/250]  acc 0.452573 (0.470489)  loss 1.176208 (1.203650)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:43:16,927 - WARNING - Epoch [19/25] Step [141/250]  acc 0.464433 (0.471105)  loss 1.171206 (1.200524)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:43:21,079 - WARNING - Epoch [19/25] Step [151/250]  acc 0.422935 (0.471324)  loss 1.301108 (1.200852)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
2025-08-16 18:43:25,259 - WARNING - Epoch [19/25] Step [161/250]  acc 0.468202 (0.470255)  loss 1.199392 (1.203169)
GPU memory consumption  GPU Memory: Allocated: 56.7 MB, Reserved: 7802.0 MB
2025-08-16 18:43:29,428 - WARNING - Epoch [19/25] Step [171/250]  acc 0.418117 (0.469321)  loss 1.288173 (1.203298)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:43:34,232 - WARNING - Epoch [19/25] Step [181/250]  acc 0.475964 (0.469632)  loss 1.150553 (1.202330)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7802.0 MB
2025-08-16 18:43:39,185 - WARNING - Epoch [19/25] Step [191/250]  acc 0.473171 (0.469061)  loss 1.202412 (1.203169)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:43:43,708 - WARNING - Epoch [19/25] Step [201/250]  acc 0.464546 (0.469145)  loss 1.234411 (1.203242)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:43:48,181 - WARNING - Epoch [19/25] Step [211/250]  acc 0.503175 (0.469431)  loss 1.164615 (1.202966)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7802.0 MB
2025-08-16 18:43:52,909 - WARNING - Epoch [19/25] Step [221/250]  acc 0.532823 (0.469918)  loss 1.049317 (1.202000)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7802.0 MB
2025-08-16 18:43:57,385 - WARNING - Epoch [19/25] Step [231/250]  acc 0.495953 (0.470834)  loss 1.195463 (1.200895)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
2025-08-16 18:44:01,858 - WARNING - Epoch [19/25] Step [241/250]  acc 0.460428 (0.470629)  loss 1.221770 (1.202357)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7802.0 MB
Epoch 19 completed in 0:01:51.770377
2025-08-16 18:44:34,014 - WARNING - Epoch [20/25] Step [1/250]  acc 0.526515 (0.526515)  loss 1.096296 (1.096296)
GPU memory consumption  GPU Memory: Allocated: 62.0 MB, Reserved: 7802.0 MB
2025-08-16 18:44:38,456 - WARNING - Epoch [20/25] Step [11/250]  acc 0.511100 (0.483015)  loss 1.103845 (1.206132)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:44:42,905 - WARNING - Epoch [20/25] Step [21/250]  acc 0.412439 (0.477387)  loss 1.352924 (1.205701)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7802.0 MB
2025-08-16 18:44:47,454 - WARNING - Epoch [20/25] Step [31/250]  acc 0.481274 (0.472749)  loss 1.198725 (1.206859)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7802.0 MB
2025-08-16 18:44:51,979 - WARNING - Epoch [20/25] Step [41/250]  acc 0.467109 (0.467348)  loss 1.193490 (1.207322)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:44:56,348 - WARNING - Epoch [20/25] Step [51/250]  acc 0.446340 (0.465834)  loss 1.200053 (1.210876)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:45:01,118 - WARNING - Epoch [20/25] Step [61/250]  acc 0.472563 (0.466407)  loss 1.146109 (1.208988)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7802.0 MB
2025-08-16 18:45:05,748 - WARNING - Epoch [20/25] Step [71/250]  acc 0.494523 (0.467749)  loss 1.148723 (1.206178)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:45:10,333 - WARNING - Epoch [20/25] Step [81/250]  acc 0.465546 (0.468160)  loss 1.236367 (1.204749)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:45:14,929 - WARNING - Epoch [20/25] Step [91/250]  acc 0.437176 (0.466431)  loss 1.255986 (1.205806)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:45:19,501 - WARNING - Epoch [20/25] Step [101/250]  acc 0.534145 (0.468203)  loss 1.073632 (1.203607)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7802.0 MB
2025-08-16 18:45:23,934 - WARNING - Epoch [20/25] Step [111/250]  acc 0.507996 (0.467985)  loss 1.163007 (1.201897)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:45:28,494 - WARNING - Epoch [20/25] Step [121/250]  acc 0.470774 (0.468701)  loss 1.226571 (1.201764)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:45:32,874 - WARNING - Epoch [20/25] Step [131/250]  acc 0.496410 (0.468767)  loss 1.119907 (1.198570)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:45:37,282 - WARNING - Epoch [20/25] Step [141/250]  acc 0.455983 (0.468927)  loss 1.202126 (1.199134)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7802.0 MB
2025-08-16 18:45:41,585 - WARNING - Epoch [20/25] Step [151/250]  acc 0.440476 (0.468366)  loss 1.243854 (1.199010)
GPU memory consumption  GPU Memory: Allocated: 53.5 MB, Reserved: 7802.0 MB
2025-08-16 18:45:45,997 - WARNING - Epoch [20/25] Step [161/250]  acc 0.496362 (0.469240)  loss 1.095149 (1.198010)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
2025-08-16 18:45:50,583 - WARNING - Epoch [20/25] Step [171/250]  acc 0.394751 (0.469221)  loss 1.353854 (1.198843)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7802.0 MB
2025-08-16 18:45:54,977 - WARNING - Epoch [20/25] Step [181/250]  acc 0.463712 (0.468601)  loss 1.207560 (1.199362)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:45:59,477 - WARNING - Epoch [20/25] Step [191/250]  acc 0.438245 (0.468268)  loss 1.294895 (1.200101)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7802.0 MB
2025-08-16 18:46:03,783 - WARNING - Epoch [20/25] Step [201/250]  acc 0.462208 (0.468287)  loss 1.182636 (1.200107)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 7802.0 MB
2025-08-16 18:46:08,287 - WARNING - Epoch [20/25] Step [211/250]  acc 0.471173 (0.467992)  loss 1.195278 (1.200332)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7802.0 MB
2025-08-16 18:46:12,906 - WARNING - Epoch [20/25] Step [221/250]  acc 0.431844 (0.468167)  loss 1.240878 (1.200579)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:46:17,246 - WARNING - Epoch [20/25] Step [231/250]  acc 0.492275 (0.469458)  loss 1.179037 (1.198583)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7802.0 MB
2025-08-16 18:46:21,535 - WARNING - Epoch [20/25] Step [241/250]  acc 0.469149 (0.469809)  loss 1.168233 (1.198792)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
Epoch 20 completed in 0:01:51.924141
2025-08-16 18:46:50,892 - WARNING - Epoch [21/25] Step [1/250]  acc 0.441604 (0.441604)  loss 1.192424 (1.192424)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 7802.0 MB
2025-08-16 18:46:55,224 - WARNING - Epoch [21/25] Step [11/250]  acc 0.475565 (0.460023)  loss 1.187029 (1.234078)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:47:00,071 - WARNING - Epoch [21/25] Step [21/250]  acc 0.382920 (0.458631)  loss 1.390969 (1.227625)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7802.0 MB
2025-08-16 18:47:04,770 - WARNING - Epoch [21/25] Step [31/250]  acc 0.514516 (0.467599)  loss 1.079764 (1.205899)
GPU memory consumption  GPU Memory: Allocated: 56.1 MB, Reserved: 7802.0 MB
2025-08-16 18:47:09,426 - WARNING - Epoch [21/25] Step [41/250]  acc 0.446628 (0.470610)  loss 1.214810 (1.199158)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:47:13,829 - WARNING - Epoch [21/25] Step [51/250]  acc 0.457360 (0.469707)  loss 1.276440 (1.205713)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:47:18,384 - WARNING - Epoch [21/25] Step [61/250]  acc 0.459077 (0.467545)  loss 1.158420 (1.208839)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:47:22,803 - WARNING - Epoch [21/25] Step [71/250]  acc 0.471283 (0.468087)  loss 1.139626 (1.204664)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 7802.0 MB
2025-08-16 18:47:27,289 - WARNING - Epoch [21/25] Step [81/250]  acc 0.503321 (0.467785)  loss 1.140007 (1.205386)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:47:31,680 - WARNING - Epoch [21/25] Step [91/250]  acc 0.461253 (0.469327)  loss 1.191308 (1.202482)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7802.0 MB
2025-08-16 18:47:36,096 - WARNING - Epoch [21/25] Step [101/250]  acc 0.483403 (0.469600)  loss 1.175427 (1.203704)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7802.0 MB
2025-08-16 18:47:40,509 - WARNING - Epoch [21/25] Step [111/250]  acc 0.458848 (0.469846)  loss 1.151638 (1.202368)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7802.0 MB
2025-08-16 18:47:44,906 - WARNING - Epoch [21/25] Step [121/250]  acc 0.447665 (0.470525)  loss 1.275771 (1.201795)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:47:49,277 - WARNING - Epoch [21/25] Step [131/250]  acc 0.487869 (0.471980)  loss 1.200668 (1.202099)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7802.0 MB
2025-08-16 18:47:53,701 - WARNING - Epoch [21/25] Step [141/250]  acc 0.518689 (0.470868)  loss 1.093873 (1.203654)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:47:58,121 - WARNING - Epoch [21/25] Step [151/250]  acc 0.475862 (0.471707)  loss 1.226573 (1.201954)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 7802.0 MB
2025-08-16 18:48:02,578 - WARNING - Epoch [21/25] Step [161/250]  acc 0.511580 (0.471662)  loss 1.130684 (1.200905)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:48:07,063 - WARNING - Epoch [21/25] Step [171/250]  acc 0.438100 (0.470944)  loss 1.169784 (1.201827)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7802.0 MB
2025-08-16 18:48:11,745 - WARNING - Epoch [21/25] Step [181/250]  acc 0.473656 (0.471526)  loss 1.226881 (1.200386)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7802.0 MB
2025-08-16 18:48:16,213 - WARNING - Epoch [21/25] Step [191/250]  acc 0.441847 (0.471777)  loss 1.238384 (1.200287)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7802.0 MB
2025-08-16 18:48:20,733 - WARNING - Epoch [21/25] Step [201/250]  acc 0.432461 (0.471834)  loss 1.278052 (1.199956)
GPU memory consumption  GPU Memory: Allocated: 54.1 MB, Reserved: 7802.0 MB
2025-08-16 18:48:25,144 - WARNING - Epoch [21/25] Step [211/250]  acc 0.481127 (0.471652)  loss 1.193114 (1.200290)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7802.0 MB
2025-08-16 18:48:29,627 - WARNING - Epoch [21/25] Step [221/250]  acc 0.496084 (0.471892)  loss 1.142928 (1.198906)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:48:34,134 - WARNING - Epoch [21/25] Step [231/250]  acc 0.439288 (0.471192)  loss 1.239709 (1.199622)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:48:38,593 - WARNING - Epoch [21/25] Step [241/250]  acc 0.458973 (0.470901)  loss 1.219411 (1.200324)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
Epoch 21 completed in 0:01:52.189648
2025-08-16 18:49:09,975 - WARNING - Epoch [22/25] Step [1/250]  acc 0.470346 (0.470346)  loss 1.238989 (1.238989)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:49:14,360 - WARNING - Epoch [22/25] Step [11/250]  acc 0.444193 (0.456753)  loss 1.217148 (1.207144)
GPU memory consumption  GPU Memory: Allocated: 55.6 MB, Reserved: 7802.0 MB
2025-08-16 18:49:18,696 - WARNING - Epoch [22/25] Step [21/250]  acc 0.438153 (0.466642)  loss 1.275201 (1.204127)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 7802.0 MB
2025-08-16 18:49:23,017 - WARNING - Epoch [22/25] Step [31/250]  acc 0.450727 (0.468112)  loss 1.257461 (1.199539)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7802.0 MB
2025-08-16 18:49:27,365 - WARNING - Epoch [22/25] Step [41/250]  acc 0.481921 (0.470878)  loss 1.209225 (1.195171)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:49:31,794 - WARNING - Epoch [22/25] Step [51/250]  acc 0.436521 (0.471446)  loss 1.256514 (1.193515)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7802.0 MB
2025-08-16 18:49:36,237 - WARNING - Epoch [22/25] Step [61/250]  acc 0.450357 (0.468459)  loss 1.286848 (1.192913)
GPU memory consumption  GPU Memory: Allocated: 54.3 MB, Reserved: 7802.0 MB
2025-08-16 18:49:40,727 - WARNING - Epoch [22/25] Step [71/250]  acc 0.495868 (0.468699)  loss 1.177425 (1.193952)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:49:45,460 - WARNING - Epoch [22/25] Step [81/250]  acc 0.431640 (0.467624)  loss 1.250697 (1.198929)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:49:49,851 - WARNING - Epoch [22/25] Step [91/250]  acc 0.541485 (0.469050)  loss 1.063838 (1.195911)
GPU memory consumption  GPU Memory: Allocated: 54.0 MB, Reserved: 7802.0 MB
2025-08-16 18:49:54,273 - WARNING - Epoch [22/25] Step [101/250]  acc 0.507342 (0.470372)  loss 1.084425 (1.194746)
GPU memory consumption  GPU Memory: Allocated: 59.2 MB, Reserved: 7802.0 MB
2025-08-16 18:49:58,712 - WARNING - Epoch [22/25] Step [111/250]  acc 0.414404 (0.469872)  loss 1.341997 (1.197669)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7802.0 MB
2025-08-16 18:50:03,191 - WARNING - Epoch [22/25] Step [121/250]  acc 0.452199 (0.471031)  loss 1.331760 (1.196305)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7802.0 MB
2025-08-16 18:50:07,648 - WARNING - Epoch [22/25] Step [131/250]  acc 0.438960 (0.471432)  loss 1.341203 (1.195384)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7802.0 MB
2025-08-16 18:50:11,897 - WARNING - Epoch [22/25] Step [141/250]  acc 0.432331 (0.471568)  loss 1.249478 (1.195090)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7802.0 MB
2025-08-16 18:50:16,133 - WARNING - Epoch [22/25] Step [151/250]  acc 0.530738 (0.471831)  loss 1.149862 (1.194293)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:50:20,417 - WARNING - Epoch [22/25] Step [161/250]  acc 0.466884 (0.471195)  loss 1.261222 (1.197390)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7802.0 MB
2025-08-16 18:50:24,757 - WARNING - Epoch [22/25] Step [171/250]  acc 0.472727 (0.470697)  loss 1.194908 (1.198329)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 7802.0 MB
2025-08-16 18:50:29,111 - WARNING - Epoch [22/25] Step [181/250]  acc 0.490312 (0.470145)  loss 1.168484 (1.199446)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
2025-08-16 18:50:33,482 - WARNING - Epoch [22/25] Step [191/250]  acc 0.430159 (0.470581)  loss 1.278044 (1.200203)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:50:37,750 - WARNING - Epoch [22/25] Step [201/250]  acc 0.556585 (0.471134)  loss 1.083000 (1.199515)
GPU memory consumption  GPU Memory: Allocated: 57.4 MB, Reserved: 7802.0 MB
2025-08-16 18:50:41,937 - WARNING - Epoch [22/25] Step [211/250]  acc 0.434854 (0.471047)  loss 1.244277 (1.200521)
GPU memory consumption  GPU Memory: Allocated: 53.3 MB, Reserved: 7802.0 MB
2025-08-16 18:50:46,392 - WARNING - Epoch [22/25] Step [221/250]  acc 0.514451 (0.471315)  loss 1.178989 (1.200423)
GPU memory consumption  GPU Memory: Allocated: 57.8 MB, Reserved: 7802.0 MB
2025-08-16 18:50:51,389 - WARNING - Epoch [22/25] Step [231/250]  acc 0.483122 (0.471508)  loss 1.207353 (1.199333)
GPU memory consumption  GPU Memory: Allocated: 57.0 MB, Reserved: 7802.0 MB
2025-08-16 18:50:56,092 - WARNING - Epoch [22/25] Step [241/250]  acc 0.472576 (0.471563)  loss 1.233995 (1.199409)
GPU memory consumption  GPU Memory: Allocated: 54.8 MB, Reserved: 7802.0 MB
Epoch 22 completed in 0:01:50.562208
2025-08-16 18:51:28,520 - WARNING - Epoch [23/25] Step [1/250]  acc 0.448498 (0.448498)  loss 1.194587 (1.194587)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7802.0 MB
2025-08-16 18:51:33,036 - WARNING - Epoch [23/25] Step [11/250]  acc 0.449352 (0.463034)  loss 1.213444 (1.214563)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7802.0 MB
2025-08-16 18:51:37,537 - WARNING - Epoch [23/25] Step [21/250]  acc 0.472421 (0.467796)  loss 1.207440 (1.215384)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:51:42,207 - WARNING - Epoch [23/25] Step [31/250]  acc 0.477341 (0.466725)  loss 1.196691 (1.220264)
GPU memory consumption  GPU Memory: Allocated: 53.2 MB, Reserved: 7802.0 MB
2025-08-16 18:51:46,805 - WARNING - Epoch [23/25] Step [41/250]  acc 0.446628 (0.466509)  loss 1.288199 (1.220251)
GPU memory consumption  GPU Memory: Allocated: 56.6 MB, Reserved: 7802.0 MB
2025-08-16 18:51:51,274 - WARNING - Epoch [23/25] Step [51/250]  acc 0.456711 (0.468162)  loss 1.206910 (1.216039)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7802.0 MB
2025-08-16 18:51:55,658 - WARNING - Epoch [23/25] Step [61/250]  acc 0.493445 (0.468757)  loss 1.186134 (1.210828)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7802.0 MB
2025-08-16 18:52:00,004 - WARNING - Epoch [23/25] Step [71/250]  acc 0.443793 (0.470578)  loss 1.273731 (1.209211)
GPU memory consumption  GPU Memory: Allocated: 54.2 MB, Reserved: 7802.0 MB
2025-08-16 18:52:04,359 - WARNING - Epoch [23/25] Step [81/250]  acc 0.442328 (0.469437)  loss 1.139318 (1.211287)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7802.0 MB
2025-08-16 18:52:08,673 - WARNING - Epoch [23/25] Step [91/250]  acc 0.553063 (0.469208)  loss 1.084444 (1.209834)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7802.0 MB
2025-08-16 18:52:13,176 - WARNING - Epoch [23/25] Step [101/250]  acc 0.504278 (0.470833)  loss 1.200927 (1.206239)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7802.0 MB
2025-08-16 18:52:17,524 - WARNING - Epoch [23/25] Step [111/250]  acc 0.448640 (0.471627)  loss 1.168567 (1.201407)
GPU memory consumption  GPU Memory: Allocated: 55.0 MB, Reserved: 7802.0 MB
2025-08-16 18:52:21,994 - WARNING - Epoch [23/25] Step [121/250]  acc 0.482503 (0.470943)  loss 1.105810 (1.200859)
GPU memory consumption  GPU Memory: Allocated: 57.6 MB, Reserved: 7802.0 MB
2025-08-16 18:52:26,180 - WARNING - Epoch [23/25] Step [131/250]  acc 0.472890 (0.470971)  loss 1.264156 (1.200554)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7802.0 MB
2025-08-16 18:52:30,634 - WARNING - Epoch [23/25] Step [141/250]  acc 0.535114 (0.471844)  loss 1.057943 (1.198245)
GPU memory consumption  GPU Memory: Allocated: 57.5 MB, Reserved: 7802.0 MB
2025-08-16 18:52:35,062 - WARNING - Epoch [23/25] Step [151/250]  acc 0.485552 (0.471622)  loss 1.107439 (1.197467)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:52:39,800 - WARNING - Epoch [23/25] Step [161/250]  acc 0.500000 (0.471968)  loss 1.247358 (1.196628)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:52:44,445 - WARNING - Epoch [23/25] Step [171/250]  acc 0.480871 (0.471727)  loss 1.224832 (1.196077)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:52:48,733 - WARNING - Epoch [23/25] Step [181/250]  acc 0.490798 (0.472559)  loss 1.127519 (1.193824)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:52:53,138 - WARNING - Epoch [23/25] Step [191/250]  acc 0.455939 (0.473195)  loss 1.200863 (1.193878)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
2025-08-16 18:52:57,690 - WARNING - Epoch [23/25] Step [201/250]  acc 0.504951 (0.473116)  loss 1.168599 (1.195032)
GPU memory consumption  GPU Memory: Allocated: 51.3 MB, Reserved: 7802.0 MB
2025-08-16 18:53:02,505 - WARNING - Epoch [23/25] Step [211/250]  acc 0.504717 (0.473400)  loss 1.136243 (1.194007)
GPU memory consumption  GPU Memory: Allocated: 55.7 MB, Reserved: 7802.0 MB
2025-08-16 18:53:06,947 - WARNING - Epoch [23/25] Step [221/250]  acc 0.451351 (0.472993)  loss 1.185547 (1.193832)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 7802.0 MB
2025-08-16 18:53:11,577 - WARNING - Epoch [23/25] Step [231/250]  acc 0.442818 (0.472869)  loss 1.219004 (1.193517)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:53:16,180 - WARNING - Epoch [23/25] Step [241/250]  acc 0.524910 (0.472755)  loss 1.099072 (1.194101)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7802.0 MB
Epoch 23 completed in 0:01:52.323165
2025-08-16 18:53:48,350 - WARNING - Epoch [24/25] Step [1/250]  acc 0.475177 (0.475177)  loss 1.151270 (1.151270)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:53:52,871 - WARNING - Epoch [24/25] Step [11/250]  acc 0.442478 (0.468307)  loss 1.303784 (1.199741)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:53:57,235 - WARNING - Epoch [24/25] Step [21/250]  acc 0.503688 (0.467290)  loss 1.093790 (1.203653)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:54:01,671 - WARNING - Epoch [24/25] Step [31/250]  acc 0.473710 (0.467769)  loss 1.171190 (1.200455)
GPU memory consumption  GPU Memory: Allocated: 58.7 MB, Reserved: 7802.0 MB
2025-08-16 18:54:06,454 - WARNING - Epoch [24/25] Step [41/250]  acc 0.442371 (0.469067)  loss 1.298146 (1.198246)
GPU memory consumption  GPU Memory: Allocated: 55.5 MB, Reserved: 7802.0 MB
2025-08-16 18:54:10,974 - WARNING - Epoch [24/25] Step [51/250]  acc 0.451177 (0.469043)  loss 1.198431 (1.198834)
GPU memory consumption  GPU Memory: Allocated: 59.0 MB, Reserved: 7802.0 MB
2025-08-16 18:54:15,400 - WARNING - Epoch [24/25] Step [61/250]  acc 0.489888 (0.470659)  loss 1.233757 (1.197871)
GPU memory consumption  GPU Memory: Allocated: 53.6 MB, Reserved: 7802.0 MB
2025-08-16 18:54:19,935 - WARNING - Epoch [24/25] Step [71/250]  acc 0.514359 (0.473641)  loss 1.108533 (1.191562)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:54:24,318 - WARNING - Epoch [24/25] Step [81/250]  acc 0.515633 (0.473927)  loss 1.102709 (1.187899)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:54:28,831 - WARNING - Epoch [24/25] Step [91/250]  acc 0.439444 (0.473668)  loss 1.269739 (1.189573)
GPU memory consumption  GPU Memory: Allocated: 53.4 MB, Reserved: 7802.0 MB
2025-08-16 18:54:33,194 - WARNING - Epoch [24/25] Step [101/250]  acc 0.463557 (0.474880)  loss 1.184174 (1.187744)
GPU memory consumption  GPU Memory: Allocated: 61.3 MB, Reserved: 7802.0 MB
2025-08-16 18:54:37,609 - WARNING - Epoch [24/25] Step [111/250]  acc 0.492586 (0.475563)  loss 1.155518 (1.187936)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7802.0 MB
2025-08-16 18:54:41,997 - WARNING - Epoch [24/25] Step [121/250]  acc 0.484781 (0.475626)  loss 1.081805 (1.189051)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:54:46,361 - WARNING - Epoch [24/25] Step [131/250]  acc 0.480671 (0.474153)  loss 1.137138 (1.192078)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:54:50,703 - WARNING - Epoch [24/25] Step [141/250]  acc 0.419923 (0.474298)  loss 1.350579 (1.191774)
GPU memory consumption  GPU Memory: Allocated: 54.4 MB, Reserved: 7802.0 MB
2025-08-16 18:54:55,080 - WARNING - Epoch [24/25] Step [151/250]  acc 0.432785 (0.473835)  loss 1.329155 (1.192996)
GPU memory consumption  GPU Memory: Allocated: 53.7 MB, Reserved: 7802.0 MB
2025-08-16 18:54:59,536 - WARNING - Epoch [24/25] Step [161/250]  acc 0.452840 (0.474412)  loss 1.184839 (1.191951)
GPU memory consumption  GPU Memory: Allocated: 54.9 MB, Reserved: 7802.0 MB
2025-08-16 18:55:04,039 - WARNING - Epoch [24/25] Step [171/250]  acc 0.509071 (0.474666)  loss 1.125621 (1.191000)
GPU memory consumption  GPU Memory: Allocated: 55.2 MB, Reserved: 7802.0 MB
2025-08-16 18:55:08,475 - WARNING - Epoch [24/25] Step [181/250]  acc 0.473768 (0.474140)  loss 1.180566 (1.191822)
GPU memory consumption  GPU Memory: Allocated: 56.0 MB, Reserved: 7802.0 MB
2025-08-16 18:55:13,113 - WARNING - Epoch [24/25] Step [191/250]  acc 0.511974 (0.473913)  loss 1.122642 (1.192179)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:55:17,546 - WARNING - Epoch [24/25] Step [201/250]  acc 0.514222 (0.473808)  loss 1.155518 (1.190845)
GPU memory consumption  GPU Memory: Allocated: 52.8 MB, Reserved: 7802.0 MB
2025-08-16 18:55:21,924 - WARNING - Epoch [24/25] Step [211/250]  acc 0.514213 (0.473379)  loss 1.177512 (1.191646)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:55:26,280 - WARNING - Epoch [24/25] Step [221/250]  acc 0.481462 (0.473325)  loss 1.158369 (1.191961)
GPU memory consumption  GPU Memory: Allocated: 56.2 MB, Reserved: 7802.0 MB
2025-08-16 18:55:30,716 - WARNING - Epoch [24/25] Step [231/250]  acc 0.501319 (0.473598)  loss 1.229243 (1.191719)
GPU memory consumption  GPU Memory: Allocated: 55.8 MB, Reserved: 7802.0 MB
2025-08-16 18:55:35,182 - WARNING - Epoch [24/25] Step [241/250]  acc 0.476791 (0.473900)  loss 1.135360 (1.191130)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7802.0 MB
Epoch 24 completed in 0:01:51.262760
2025-08-16 18:56:06,412 - WARNING - Epoch [25/25] Step [1/250]  acc 0.521017 (0.521017)  loss 1.131639 (1.131639)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:56:10,911 - WARNING - Epoch [25/25] Step [11/250]  acc 0.508159 (0.491905)  loss 1.165653 (1.188268)
GPU memory consumption  GPU Memory: Allocated: 55.1 MB, Reserved: 7802.0 MB
2025-08-16 18:56:15,380 - WARNING - Epoch [25/25] Step [21/250]  acc 0.498953 (0.486667)  loss 1.166495 (1.185840)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:56:19,909 - WARNING - Epoch [25/25] Step [31/250]  acc 0.528753 (0.479882)  loss 1.108029 (1.195719)
GPU memory consumption  GPU Memory: Allocated: 57.7 MB, Reserved: 7802.0 MB
2025-08-16 18:56:24,532 - WARNING - Epoch [25/25] Step [41/250]  acc 0.479077 (0.478819)  loss 1.237935 (1.192946)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7802.0 MB
2025-08-16 18:56:29,187 - WARNING - Epoch [25/25] Step [51/250]  acc 0.466463 (0.473787)  loss 1.136759 (1.201069)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:56:33,663 - WARNING - Epoch [25/25] Step [61/250]  acc 0.494359 (0.471621)  loss 1.145653 (1.200487)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:56:38,117 - WARNING - Epoch [25/25] Step [71/250]  acc 0.424987 (0.472854)  loss 1.266527 (1.200982)
GPU memory consumption  GPU Memory: Allocated: 54.6 MB, Reserved: 7802.0 MB
2025-08-16 18:56:42,720 - WARNING - Epoch [25/25] Step [81/250]  acc 0.453637 (0.472782)  loss 1.219586 (1.201018)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:56:47,260 - WARNING - Epoch [25/25] Step [91/250]  acc 0.472039 (0.473027)  loss 1.239397 (1.197112)
GPU memory consumption  GPU Memory: Allocated: 53.9 MB, Reserved: 7802.0 MB
2025-08-16 18:56:52,040 - WARNING - Epoch [25/25] Step [101/250]  acc 0.463627 (0.473563)  loss 1.225109 (1.197170)
GPU memory consumption  GPU Memory: Allocated: 57.2 MB, Reserved: 7802.0 MB
2025-08-16 18:56:56,602 - WARNING - Epoch [25/25] Step [111/250]  acc 0.484603 (0.474676)  loss 1.199166 (1.193244)
GPU memory consumption  GPU Memory: Allocated: 55.9 MB, Reserved: 7802.0 MB
2025-08-16 18:57:01,113 - WARNING - Epoch [25/25] Step [121/250]  acc 0.484568 (0.474854)  loss 1.158939 (1.192365)
GPU memory consumption  GPU Memory: Allocated: 58.9 MB, Reserved: 7802.0 MB
2025-08-16 18:57:05,699 - WARNING - Epoch [25/25] Step [131/250]  acc 0.485686 (0.474383)  loss 1.105741 (1.191643)
GPU memory consumption  GPU Memory: Allocated: 57.3 MB, Reserved: 7802.0 MB
2025-08-16 18:57:10,242 - WARNING - Epoch [25/25] Step [141/250]  acc 0.486111 (0.474570)  loss 1.128042 (1.191228)
GPU memory consumption  GPU Memory: Allocated: 57.1 MB, Reserved: 7802.0 MB
2025-08-16 18:57:14,779 - WARNING - Epoch [25/25] Step [151/250]  acc 0.458227 (0.472676)  loss 1.230592 (1.195037)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:57:19,348 - WARNING - Epoch [25/25] Step [161/250]  acc 0.490107 (0.472753)  loss 1.146522 (1.195193)
GPU memory consumption  GPU Memory: Allocated: 56.4 MB, Reserved: 7802.0 MB
2025-08-16 18:57:23,919 - WARNING - Epoch [25/25] Step [171/250]  acc 0.451667 (0.472943)  loss 1.208587 (1.194368)
GPU memory consumption  GPU Memory: Allocated: 54.7 MB, Reserved: 7802.0 MB
2025-08-16 18:57:28,467 - WARNING - Epoch [25/25] Step [181/250]  acc 0.482359 (0.472936)  loss 1.086894 (1.194223)
GPU memory consumption  GPU Memory: Allocated: 54.5 MB, Reserved: 7802.0 MB
2025-08-16 18:57:33,144 - WARNING - Epoch [25/25] Step [191/250]  acc 0.463468 (0.472928)  loss 1.168732 (1.194175)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7802.0 MB
2025-08-16 18:57:37,693 - WARNING - Epoch [25/25] Step [201/250]  acc 0.485339 (0.471831)  loss 1.133257 (1.195302)
GPU memory consumption  GPU Memory: Allocated: 55.3 MB, Reserved: 7802.0 MB
2025-08-16 18:57:42,278 - WARNING - Epoch [25/25] Step [211/250]  acc 0.479187 (0.471631)  loss 1.106852 (1.194744)
GPU memory consumption  GPU Memory: Allocated: 56.5 MB, Reserved: 7802.0 MB
2025-08-16 18:57:46,796 - WARNING - Epoch [25/25] Step [221/250]  acc 0.459591 (0.471680)  loss 1.190797 (1.193223)
GPU memory consumption  GPU Memory: Allocated: 56.3 MB, Reserved: 7802.0 MB
2025-08-16 18:57:51,300 - WARNING - Epoch [25/25] Step [231/250]  acc 0.504315 (0.471587)  loss 1.137451 (1.193380)
GPU memory consumption  GPU Memory: Allocated: 55.4 MB, Reserved: 7802.0 MB
2025-08-16 18:57:55,976 - WARNING - Epoch [25/25] Step [241/250]  acc 0.495597 (0.471489)  loss 1.116392 (1.193504)
GPU memory consumption  GPU Memory: Allocated: 58.0 MB, Reserved: 7802.0 MB
Epoch 25 completed in 0:01:54.268043
2025-08-16 18:58:28,171 - INFO - DARTS search completed in 3628.51s
2025-08-16 18:58:28,172 - INFO - 
============================================================
2025-08-16 18:58:28,172 - INFO - Layer layer_0 Expert Selection:
2025-08-16 18:58:28,172 - INFO -   Expert 0: GINE (α=0.2411)
2025-08-16 18:58:28,172 - INFO -   Expert 1: CustomGatedGCN (α=0.3568)
2025-08-16 18:58:28,172 - INFO -   Expert 2: GATV2 (α=0.4021) ← SELECTED
2025-08-16 18:58:28,172 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-16 18:58:28,173 - INFO - ============================================================

2025-08-16 18:58:28,173 - INFO - 
============================================================
2025-08-16 18:58:28,173 - INFO - Layer layer_1 Expert Selection:
2025-08-16 18:58:28,173 - INFO -   Expert 0: GINE (α=0.1760)
2025-08-16 18:58:28,173 - INFO -   Expert 1: CustomGatedGCN (α=0.2854)
2025-08-16 18:58:28,173 - INFO -   Expert 2: GATV2 (α=0.5387) ← SELECTED
2025-08-16 18:58:28,173 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-16 18:58:28,173 - INFO - ============================================================

2025-08-16 18:58:28,173 - INFO - 
============================================================
2025-08-16 18:58:28,173 - INFO - Layer layer_2 Expert Selection:
2025-08-16 18:58:28,173 - INFO -   Expert 0: GINE (α=0.2516)
2025-08-16 18:58:28,173 - INFO -   Expert 1: CustomGatedGCN (α=0.4519) ← SELECTED
2025-08-16 18:58:28,173 - INFO -   Expert 2: GATV2 (α=0.2965)
2025-08-16 18:58:28,173 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 18:58:28,173 - INFO - ============================================================

2025-08-16 18:58:28,173 - INFO - 
============================================================
2025-08-16 18:58:28,173 - INFO - Layer layer_3 Expert Selection:
2025-08-16 18:58:28,173 - INFO -   Expert 0: GINE (α=0.2868)
2025-08-16 18:58:28,173 - INFO -   Expert 1: CustomGatedGCN (α=0.3819) ← SELECTED
2025-08-16 18:58:28,173 - INFO -   Expert 2: GATV2 (α=0.3313)
2025-08-16 18:58:28,173 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 18:58:28,174 - INFO - ============================================================

2025-08-16 18:58:28,174 - INFO - 
============================================================
2025-08-16 18:58:28,174 - INFO - Layer layer_4 Expert Selection:
2025-08-16 18:58:28,174 - INFO -   Expert 0: GINE (α=0.2884)
2025-08-16 18:58:28,174 - INFO -   Expert 1: CustomGatedGCN (α=0.3811) ← SELECTED
2025-08-16 18:58:28,174 - INFO -   Expert 2: GATV2 (α=0.3305)
2025-08-16 18:58:28,174 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 18:58:28,174 - INFO - ============================================================

2025-08-16 18:58:28,174 - INFO - 
============================================================
2025-08-16 18:58:28,174 - INFO - Layer layer_5 Expert Selection:
2025-08-16 18:58:28,174 - INFO -   Expert 0: GINE (α=0.3412) ← SELECTED
2025-08-16 18:58:28,174 - INFO -   Expert 1: CustomGatedGCN (α=0.3376)
2025-08-16 18:58:28,174 - INFO -   Expert 2: GATV2 (α=0.3213)
2025-08-16 18:58:28,174 - INFO - Selected Expert Index: 0 (GINE)
2025-08-16 18:58:28,174 - INFO - ============================================================

2025-08-16 18:58:28,174 - INFO - 
============================================================
2025-08-16 18:58:28,174 - INFO - Layer layer_6 Expert Selection:
2025-08-16 18:58:28,174 - INFO -   Expert 0: GINE (α=0.3754) ← SELECTED
2025-08-16 18:58:28,174 - INFO -   Expert 1: CustomGatedGCN (α=0.3145)
2025-08-16 18:58:28,174 - INFO -   Expert 2: GATV2 (α=0.3101)
2025-08-16 18:58:28,175 - INFO - Selected Expert Index: 0 (GINE)
2025-08-16 18:58:28,175 - INFO - ============================================================

2025-08-16 18:58:28,175 - INFO - 
============================================================
2025-08-16 18:58:28,175 - INFO - Layer layer_7 Expert Selection:
2025-08-16 18:58:28,175 - INFO -   Expert 0: GINE (α=0.3299)
2025-08-16 18:58:28,175 - INFO -   Expert 1: CustomGatedGCN (α=0.3719) ← SELECTED
2025-08-16 18:58:28,175 - INFO -   Expert 2: GATV2 (α=0.2982)
2025-08-16 18:58:28,175 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 18:58:28,175 - INFO - ============================================================

2025-08-16 18:58:28,175 - INFO - 
============================================================
2025-08-16 18:58:28,175 - INFO - Layer layer_8 Expert Selection:
2025-08-16 18:58:28,175 - INFO -   Expert 0: GINE (α=0.3142)
2025-08-16 18:58:28,175 - INFO -   Expert 1: CustomGatedGCN (α=0.4118) ← SELECTED
2025-08-16 18:58:28,175 - INFO -   Expert 2: GATV2 (α=0.2740)
2025-08-16 18:58:28,175 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 18:58:28,175 - INFO - ============================================================

2025-08-16 18:58:28,175 - INFO - 
============================================================
2025-08-16 18:58:28,175 - INFO - Layer layer_9 Expert Selection:
2025-08-16 18:58:28,175 - INFO -   Expert 0: GINE (α=0.2703)
2025-08-16 18:58:28,175 - INFO -   Expert 1: CustomGatedGCN (α=0.3906) ← SELECTED
2025-08-16 18:58:28,175 - INFO -   Expert 2: GATV2 (α=0.3391)
2025-08-16 18:58:28,176 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 18:58:28,176 - INFO - ============================================================

2025-08-16 18:58:28,176 - INFO - 
============================================================
2025-08-16 18:58:28,176 - INFO - Layer layer_10 Expert Selection:
2025-08-16 18:58:28,176 - INFO -   Expert 0: GINE (α=0.3146)
2025-08-16 18:58:28,176 - INFO -   Expert 1: CustomGatedGCN (α=0.4042) ← SELECTED
2025-08-16 18:58:28,176 - INFO -   Expert 2: GATV2 (α=0.2812)
2025-08-16 18:58:28,176 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 18:58:28,176 - INFO - ============================================================

2025-08-16 18:58:28,176 - INFO - 
============================================================
2025-08-16 18:58:28,176 - INFO - Layer layer_11 Expert Selection:
2025-08-16 18:58:28,176 - INFO -   Expert 0: GINE (α=0.2938)
2025-08-16 18:58:28,176 - INFO -   Expert 1: CustomGatedGCN (α=0.3750) ← SELECTED
2025-08-16 18:58:28,176 - INFO -   Expert 2: GATV2 (α=0.3312)
2025-08-16 18:58:28,176 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 18:58:28,176 - INFO - ============================================================

2025-08-16 18:58:28,176 - INFO - 
============================================================
2025-08-16 18:58:28,176 - INFO - Layer layer_12 Expert Selection:
2025-08-16 18:58:28,176 - INFO -   Expert 0: GINE (α=0.2390)
2025-08-16 18:58:28,176 - INFO -   Expert 1: CustomGatedGCN (α=0.4833) ← SELECTED
2025-08-16 18:58:28,176 - INFO -   Expert 2: GATV2 (α=0.2777)
2025-08-16 18:58:28,176 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 18:58:28,177 - INFO - ============================================================

2025-08-16 18:58:28,177 - INFO - 
============================================================
2025-08-16 18:58:28,177 - INFO - Layer layer_13 Expert Selection:
2025-08-16 18:58:28,177 - INFO -   Expert 0: GINE (α=0.2369)
2025-08-16 18:58:28,177 - INFO -   Expert 1: CustomGatedGCN (α=0.5222) ← SELECTED
2025-08-16 18:58:28,177 - INFO -   Expert 2: GATV2 (α=0.2409)
2025-08-16 18:58:28,177 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 18:58:28,177 - INFO - ============================================================

2025-08-16 18:58:28,177 - INFO - 
============================================================
2025-08-16 18:58:28,177 - INFO - Layer layer_14 Expert Selection:
2025-08-16 18:58:28,177 - INFO -   Expert 0: GINE (α=0.2071)
2025-08-16 18:58:28,177 - INFO -   Expert 1: CustomGatedGCN (α=0.5774) ← SELECTED
2025-08-16 18:58:28,177 - INFO -   Expert 2: GATV2 (α=0.2155)
2025-08-16 18:58:28,177 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 18:58:28,177 - INFO - ============================================================

2025-08-16 18:58:28,177 - INFO - 
============================================================
2025-08-16 18:58:28,177 - INFO - Layer layer_15 Expert Selection:
2025-08-16 18:58:28,177 - INFO -   Expert 0: GINE (α=0.2353)
2025-08-16 18:58:28,177 - INFO -   Expert 1: CustomGatedGCN (α=0.4425) ← SELECTED
2025-08-16 18:58:28,177 - INFO -   Expert 2: GATV2 (α=0.3222)
2025-08-16 18:58:28,177 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 18:58:28,177 - INFO - ============================================================

=== MODEL PARAMETER COMPARISON ===
Original DARTS model parameters: 728,678
2025-08-16 18:58:28,259 - INFO - Layer 0: Using ONLY Expert 2 (GATV2)
2025-08-16 18:58:28,260 - INFO - DiscreteNASLayer 0: Using ONLY Expert 2 (GATV2)
2025-08-16 18:58:28,266 - INFO - Layer 1: Using ONLY Expert 2 (GATV2)
2025-08-16 18:58:28,266 - INFO - DiscreteNASLayer 1: Using ONLY Expert 2 (GATV2)
2025-08-16 18:58:28,268 - INFO - Layer 2: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,269 - INFO - DiscreteNASLayer 2: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,271 - INFO - Layer 3: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,271 - INFO - DiscreteNASLayer 3: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,274 - INFO - Layer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,274 - INFO - DiscreteNASLayer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,277 - INFO - Layer 5: Using ONLY Expert 0 (GINE)
2025-08-16 18:58:28,277 - INFO - DiscreteNASLayer 5: Using ONLY Expert 0 (GINE)
2025-08-16 18:58:28,279 - INFO - Layer 6: Using ONLY Expert 0 (GINE)
2025-08-16 18:58:28,279 - INFO - DiscreteNASLayer 6: Using ONLY Expert 0 (GINE)
2025-08-16 18:58:28,282 - INFO - Layer 7: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,282 - INFO - DiscreteNASLayer 7: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,285 - INFO - Layer 8: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,285 - INFO - DiscreteNASLayer 8: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,287 - INFO - Layer 9: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,288 - INFO - DiscreteNASLayer 9: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,290 - INFO - Layer 10: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,291 - INFO - DiscreteNASLayer 10: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,293 - INFO - Layer 11: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,293 - INFO - DiscreteNASLayer 11: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,296 - INFO - Layer 12: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,296 - INFO - DiscreteNASLayer 12: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,299 - INFO - Layer 13: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,299 - INFO - DiscreteNASLayer 13: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,302 - INFO - Layer 14: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,302 - INFO - DiscreteNASLayer 14: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,305 - INFO - Layer 15: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 18:58:28,305 - INFO - DiscreteNASLayer 15: Using ONLY Expert 1 (CustomGatedGCN)
Fresh discrete model parameters: 515,510
Parameter difference: -213,168
✓ Used cfg.share.dim_in (raw input) instead of self.encoder.dim_in (processed)
✓ Fresh discrete model with correct input dimensions
2025-08-16 18:58:28,332 - INFO - Replaced inner model with discrete version
2025-08-16 18:58:28,334 - INFO - Creating fresh optimizer/scheduler for discrete model...
2025-08-16 18:58:28,338 - INFO - Fresh optimizer created: AdamW
2025-08-16 18:58:28,338 - INFO - Fresh scheduler created: LambdaLR
2025-08-16 18:58:28,338 - INFO - Discrete model parameters: 515,510
2025-08-16 18:58:28,338 - INFO - ============================================================
2025-08-16 18:58:28,338 - INFO - PHASE 2: DISCRETE TRAINING WITH UNCERTAINTY
2025-08-16 18:58:28,338 - INFO - ============================================================
2025-08-16 18:58:28,338 - INFO - === Epoch 0 ===
2025-08-16 19:00:01,538 - INFO - train: {'epoch': 0, 'time_epoch': 92.03462, 'eta': 9111.42772, 'eta_hours': 2.53095, 'loss': 1.79975414, 'lr': 0.0, 'params': 515510, 'time_iter': 0.14726, 'accuracy': 0.16636, 'f1': 0.09612, 'accuracy-SBM': 0.16627, 'auc': 0.50245}
2025-08-16 19:00:01,587 - INFO - ...computing epoch stats took: 1.19s
2025-08-16 19:00:06,504 - INFO - val: {'epoch': 0, 'time_epoch': 4.86218, 'loss': 1.79818983, 'lr': 0, 'params': 515510, 'time_iter': 0.07718, 'accuracy': 0.16712, 'f1': 0.0951, 'accuracy-SBM': 0.16499, 'auc': 0.50383}
2025-08-16 19:00:06,517 - INFO - ...computing epoch stats took: 0.06s
2025-08-16 19:00:15,240 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:00:15,294 - INFO - test: {'epoch': 0, 'time_epoch': 5.2211, 'loss': 1.79942577, 'lr': 0, 'params': 515510, 'time_iter': 0.08287, 'accuracy': 0.17057, 'f1': 0.09716, 'accuracy-SBM': 0.16991, 'auc': 0.50007}
2025-08-16 19:00:15,309 - INFO - ...computing epoch stats took: 0.06s
2025-08-16 19:00:15,309 - INFO - > Epoch 0: took 107.0s (avg 107.0s) | Best so far: epoch 0	train_loss: 1.7998 train_accuracy-SBM: 0.1663	val_loss: 1.7982 val_accuracy-SBM: 0.1650	test_loss: 1.7994 test_accuracy-SBM: 0.1699
2025-08-16 19:00:15,310 - INFO - === Epoch 1 ===
2025-08-16 19:01:48,436 - INFO - train: {'epoch': 1, 'time_epoch': 92.86282, 'eta': 9059.97496, 'eta_hours': 2.51666, 'loss': 1.6308824, 'lr': 0.0002, 'params': 515510, 'time_iter': 0.14858, 'accuracy': 0.3914, 'f1': 0.38694, 'accuracy-SBM': 0.39141, 'auc': 0.72427}
2025-08-16 19:01:48,448 - INFO - ...computing epoch stats took: 0.25s
2025-08-16 19:01:52,939 - INFO - val: {'epoch': 1, 'time_epoch': 4.44788, 'loss': 1.63093273, 'lr': 0, 'params': 515510, 'time_iter': 0.0706, 'accuracy': 0.3477, 'f1': 0.32864, 'accuracy-SBM': 0.34867, 'auc': 0.75888}
2025-08-16 19:01:52,941 - INFO - ...computing epoch stats took: 0.04s
2025-08-16 19:02:02,243 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:02:02,292 - INFO - test: {'epoch': 1, 'time_epoch': 4.92123, 'loss': 1.62554788, 'lr': 0, 'params': 515510, 'time_iter': 0.07811, 'accuracy': 0.35479, 'f1': 0.33867, 'accuracy-SBM': 0.35558, 'auc': 0.76261}
2025-08-16 19:02:02,294 - INFO - ...computing epoch stats took: 0.04s
2025-08-16 19:02:02,294 - INFO - > Epoch 1: took 107.0s (avg 107.0s) | Best so far: epoch 1	train_loss: 1.6309 train_accuracy-SBM: 0.3914	val_loss: 1.6309 val_accuracy-SBM: 0.3487	test_loss: 1.6255 test_accuracy-SBM: 0.3556
2025-08-16 19:02:02,294 - INFO - === Epoch 2 ===
2025-08-16 19:03:33,224 - INFO - train: {'epoch': 2, 'time_epoch': 90.66943, 'eta': 8909.99564, 'eta_hours': 2.475, 'loss': 1.33510389, 'lr': 0.0004, 'params': 515510, 'time_iter': 0.14507, 'accuracy': 0.55938, 'f1': 0.55843, 'accuracy-SBM': 0.55939, 'auc': 0.8334}
2025-08-16 19:03:33,235 - INFO - ...computing epoch stats took: 0.25s
2025-08-16 19:03:37,758 - INFO - val: {'epoch': 2, 'time_epoch': 4.45596, 'loss': 1.48361843, 'lr': 0, 'params': 515510, 'time_iter': 0.07073, 'accuracy': 0.44819, 'f1': 0.4278, 'accuracy-SBM': 0.44948, 'auc': 0.81955}
2025-08-16 19:03:37,763 - INFO - ...computing epoch stats took: 0.07s
2025-08-16 19:03:44,840 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:03:44,893 - INFO - test: {'epoch': 2, 'time_epoch': 4.84086, 'loss': 1.4694985, 'lr': 0, 'params': 515510, 'time_iter': 0.07684, 'accuracy': 0.4544, 'f1': 0.43597, 'accuracy-SBM': 0.45347, 'auc': 0.82146}
2025-08-16 19:03:44,905 - INFO - ...computing epoch stats took: 0.05s
2025-08-16 19:03:44,905 - INFO - > Epoch 2: took 102.6s (avg 105.5s) | Best so far: epoch 2	train_loss: 1.3351 train_accuracy-SBM: 0.5594	val_loss: 1.4836 val_accuracy-SBM: 0.4495	test_loss: 1.4695 test_accuracy-SBM: 0.4535
2025-08-16 19:03:44,905 - INFO - === Epoch 3 ===
2025-08-16 19:05:14,426 - INFO - train: {'epoch': 3, 'time_epoch': 89.25369, 'eta': 8755.69359, 'eta_hours': 2.43214, 'loss': 1.04576001, 'lr': 0.0006, 'params': 515510, 'time_iter': 0.14281, 'accuracy': 0.64997, 'f1': 0.64996, 'accuracy-SBM': 0.64997, 'auc': 0.89759}
2025-08-16 19:05:18,805 - INFO - val: {'epoch': 3, 'time_epoch': 4.31425, 'loss': 1.42480024, 'lr': 0, 'params': 515510, 'time_iter': 0.06848, 'accuracy': 0.49794, 'f1': 0.46185, 'accuracy-SBM': 0.4975, 'auc': 0.82344}
2025-08-16 19:05:27,776 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:05:27,834 - INFO - test: {'epoch': 3, 'time_epoch': 4.26416, 'loss': 1.40527855, 'lr': 0, 'params': 515510, 'time_iter': 0.06769, 'accuracy': 0.50227, 'f1': 0.46785, 'accuracy-SBM': 0.5023, 'auc': 0.82848}
2025-08-16 19:05:27,839 - INFO - > Epoch 3: took 102.9s (avg 104.9s) | Best so far: epoch 3	train_loss: 1.0458 train_accuracy-SBM: 0.6500	val_loss: 1.4248 val_accuracy-SBM: 0.4975	test_loss: 1.4053 test_accuracy-SBM: 0.5023
2025-08-16 19:05:27,839 - INFO - === Epoch 4 ===
2025-08-16 19:06:58,230 - INFO - train: {'epoch': 4, 'time_epoch': 90.10404, 'eta': 8643.5675, 'eta_hours': 2.40099, 'loss': 0.89983445, 'lr': 0.0008, 'params': 515510, 'time_iter': 0.14417, 'accuracy': 0.68685, 'f1': 0.68685, 'accuracy-SBM': 0.68685, 'auc': 0.92252}
2025-08-16 19:07:02,786 - INFO - val: {'epoch': 4, 'time_epoch': 4.49966, 'loss': 0.94898273, 'lr': 0, 'params': 515510, 'time_iter': 0.07142, 'accuracy': 0.66325, 'f1': 0.65911, 'accuracy-SBM': 0.66359, 'auc': 0.91766}
2025-08-16 19:07:11,672 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:07:11,723 - INFO - test: {'epoch': 4, 'time_epoch': 5.09505, 'loss': 0.93589067, 'lr': 0, 'params': 515510, 'time_iter': 0.08087, 'accuracy': 0.66719, 'f1': 0.66321, 'accuracy-SBM': 0.66798, 'auc': 0.92095}
2025-08-16 19:07:11,728 - INFO - > Epoch 4: took 103.9s (avg 104.7s) | Best so far: epoch 4	train_loss: 0.8998 train_accuracy-SBM: 0.6868	val_loss: 0.9490 val_accuracy-SBM: 0.6636	test_loss: 0.9359 test_accuracy-SBM: 0.6680
2025-08-16 19:07:11,728 - INFO - === Epoch 5 ===
2025-08-16 19:08:40,325 - INFO - train: {'epoch': 5, 'time_epoch': 88.33409, 'eta': 8511.05289, 'eta_hours': 2.36418, 'loss': 0.83734519, 'lr': 0.001, 'params': 515510, 'time_iter': 0.14133, 'accuracy': 0.70307, 'f1': 0.70307, 'accuracy-SBM': 0.70307, 'auc': 0.93145}
2025-08-16 19:08:44,770 - INFO - val: {'epoch': 5, 'time_epoch': 4.38984, 'loss': 0.84750803, 'lr': 0, 'params': 515510, 'time_iter': 0.06968, 'accuracy': 0.70052, 'f1': 0.70045, 'accuracy-SBM': 0.70065, 'auc': 0.93282}
2025-08-16 19:08:54,358 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:08:54,401 - INFO - test: {'epoch': 5, 'time_epoch': 4.7116, 'loss': 0.84998738, 'lr': 0, 'params': 515510, 'time_iter': 0.07479, 'accuracy': 0.6973, 'f1': 0.6973, 'accuracy-SBM': 0.6975, 'auc': 0.93248}
2025-08-16 19:08:54,406 - INFO - > Epoch 5: took 102.7s (avg 104.3s) | Best so far: epoch 5	train_loss: 0.8373 train_accuracy-SBM: 0.7031	val_loss: 0.8475 val_accuracy-SBM: 0.7006	test_loss: 0.8500 test_accuracy-SBM: 0.6975
2025-08-16 19:08:54,406 - INFO - === Epoch 6 ===
2025-08-16 19:10:24,414 - INFO - train: {'epoch': 6, 'time_epoch': 89.76052, 'eta': 8410.1124, 'eta_hours': 2.33614, 'loss': 0.79510763, 'lr': 0.00099973, 'params': 515510, 'time_iter': 0.14362, 'accuracy': 0.71658, 'f1': 0.71658, 'accuracy-SBM': 0.71658, 'auc': 0.93758}
2025-08-16 19:10:29,040 - INFO - val: {'epoch': 6, 'time_epoch': 4.4119, 'loss': 0.75807701, 'lr': 0, 'params': 515510, 'time_iter': 0.07003, 'accuracy': 0.73185, 'f1': 0.73178, 'accuracy-SBM': 0.73182, 'auc': 0.94364}
2025-08-16 19:10:38,030 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:10:38,076 - INFO - test: {'epoch': 6, 'time_epoch': 4.68833, 'loss': 0.75012582, 'lr': 0, 'params': 515510, 'time_iter': 0.07442, 'accuracy': 0.73153, 'f1': 0.73151, 'accuracy-SBM': 0.73153, 'auc': 0.94491}
2025-08-16 19:10:38,080 - INFO - > Epoch 6: took 103.7s (avg 104.2s) | Best so far: epoch 6	train_loss: 0.7951 train_accuracy-SBM: 0.7166	val_loss: 0.7581 val_accuracy-SBM: 0.7318	test_loss: 0.7501 test_accuracy-SBM: 0.7315
2025-08-16 19:10:38,080 - INFO - === Epoch 7 ===
2025-08-16 19:12:06,042 - INFO - train: {'epoch': 7, 'time_epoch': 87.69621, 'eta': 8288.22736, 'eta_hours': 2.30229, 'loss': 0.76347091, 'lr': 0.00099891, 'params': 515510, 'time_iter': 0.14031, 'accuracy': 0.72642, 'f1': 0.72642, 'accuracy-SBM': 0.72642, 'auc': 0.94221}
2025-08-16 19:12:10,574 - INFO - val: {'epoch': 7, 'time_epoch': 4.47965, 'loss': 0.72437742, 'lr': 0, 'params': 515510, 'time_iter': 0.07111, 'accuracy': 0.74061, 'f1': 0.74097, 'accuracy-SBM': 0.74079, 'auc': 0.94957}
2025-08-16 19:12:19,485 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:12:19,527 - INFO - test: {'epoch': 7, 'time_epoch': 4.82396, 'loss': 0.73058537, 'lr': 0, 'params': 515510, 'time_iter': 0.07657, 'accuracy': 0.73915, 'f1': 0.73934, 'accuracy-SBM': 0.73945, 'auc': 0.94849}
2025-08-16 19:12:19,531 - INFO - > Epoch 7: took 101.5s (avg 103.9s) | Best so far: epoch 7	train_loss: 0.7635 train_accuracy-SBM: 0.7264	val_loss: 0.7244 val_accuracy-SBM: 0.7408	test_loss: 0.7306 test_accuracy-SBM: 0.7395
2025-08-16 19:12:19,531 - INFO - === Epoch 8 ===
2025-08-16 19:13:49,998 - INFO - train: {'epoch': 8, 'time_epoch': 90.09517, 'eta': 8198.19601, 'eta_hours': 2.27728, 'loss': 0.74886529, 'lr': 0.00099754, 'params': 515510, 'time_iter': 0.14415, 'accuracy': 0.73092, 'f1': 0.73091, 'accuracy-SBM': 0.73092, 'auc': 0.94421}
2025-08-16 19:13:54,473 - INFO - val: {'epoch': 8, 'time_epoch': 4.42688, 'loss': 0.71087774, 'lr': 0, 'params': 515510, 'time_iter': 0.07027, 'accuracy': 0.74389, 'f1': 0.74337, 'accuracy-SBM': 0.74438, 'auc': 0.95086}
2025-08-16 19:14:04,331 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:14:04,373 - INFO - test: {'epoch': 8, 'time_epoch': 4.80334, 'loss': 0.70874515, 'lr': 0, 'params': 515510, 'time_iter': 0.07624, 'accuracy': 0.7411, 'f1': 0.74044, 'accuracy-SBM': 0.74108, 'auc': 0.9512}
2025-08-16 19:14:04,377 - INFO - > Epoch 8: took 104.8s (avg 104.0s) | Best so far: epoch 8	train_loss: 0.7489 train_accuracy-SBM: 0.7309	val_loss: 0.7109 val_accuracy-SBM: 0.7444	test_loss: 0.7087 test_accuracy-SBM: 0.7411
2025-08-16 19:14:04,377 - INFO - === Epoch 9 ===
2025-08-16 19:15:36,212 - INFO - train: {'epoch': 9, 'time_epoch': 91.57567, 'eta': 8121.47635, 'eta_hours': 2.25597, 'loss': 0.73518418, 'lr': 0.00099563, 'params': 515510, 'time_iter': 0.14652, 'accuracy': 0.73547, 'f1': 0.73547, 'accuracy-SBM': 0.73548, 'auc': 0.94615}
2025-08-16 19:15:40,830 - INFO - val: {'epoch': 9, 'time_epoch': 4.5673, 'loss': 0.7037977, 'lr': 0, 'params': 515510, 'time_iter': 0.0725, 'accuracy': 0.7473, 'f1': 0.74725, 'accuracy-SBM': 0.74728, 'auc': 0.95156}
2025-08-16 19:15:50,527 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:15:50,573 - INFO - test: {'epoch': 9, 'time_epoch': 4.78258, 'loss': 0.69775083, 'lr': 0, 'params': 515510, 'time_iter': 0.07591, 'accuracy': 0.74983, 'f1': 0.74981, 'accuracy-SBM': 0.74978, 'auc': 0.95236}
2025-08-16 19:15:50,578 - INFO - > Epoch 9: took 106.2s (avg 104.2s) | Best so far: epoch 9	train_loss: 0.7352 train_accuracy-SBM: 0.7355	val_loss: 0.7038 val_accuracy-SBM: 0.7473	test_loss: 0.6978 test_accuracy-SBM: 0.7498
2025-08-16 19:15:50,578 - INFO - === Epoch 10 ===
2025-08-16 19:17:21,666 - INFO - train: {'epoch': 10, 'time_epoch': 90.70055, 'eta': 8034.97507, 'eta_hours': 2.23194, 'loss': 0.72584237, 'lr': 0.00099318, 'params': 515510, 'time_iter': 0.14512, 'accuracy': 0.73922, 'f1': 0.73922, 'accuracy-SBM': 0.73922, 'auc': 0.94741}
2025-08-16 19:17:26,260 - INFO - val: {'epoch': 10, 'time_epoch': 4.53445, 'loss': 0.68838059, 'lr': 0, 'params': 515510, 'time_iter': 0.07198, 'accuracy': 0.75466, 'f1': 0.75456, 'accuracy-SBM': 0.75444, 'auc': 0.95301}
2025-08-16 19:17:35,297 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:17:35,339 - INFO - test: {'epoch': 10, 'time_epoch': 4.80111, 'loss': 0.68227968, 'lr': 0, 'params': 515510, 'time_iter': 0.07621, 'accuracy': 0.75468, 'f1': 0.75459, 'accuracy-SBM': 0.75451, 'auc': 0.95399}
2025-08-16 19:17:35,341 - INFO - > Epoch 10: took 104.8s (avg 104.3s) | Best so far: epoch 10	train_loss: 0.7258 train_accuracy-SBM: 0.7392	val_loss: 0.6884 val_accuracy-SBM: 0.7544	test_loss: 0.6823 test_accuracy-SBM: 0.7545
2025-08-16 19:17:35,341 - INFO - === Epoch 11 ===
2025-08-16 19:19:06,130 - INFO - train: {'epoch': 11, 'time_epoch': 90.49191, 'eta': 7946.24392, 'eta_hours': 2.20729, 'loss': 0.71758033, 'lr': 0.00099019, 'params': 515510, 'time_iter': 0.14479, 'accuracy': 0.74184, 'f1': 0.74184, 'accuracy-SBM': 0.74184, 'auc': 0.94854}
2025-08-16 19:19:11,175 - INFO - val: {'epoch': 11, 'time_epoch': 4.98497, 'loss': 0.67661892, 'lr': 0, 'params': 515510, 'time_iter': 0.07913, 'accuracy': 0.76041, 'f1': 0.76041, 'accuracy-SBM': 0.76038, 'auc': 0.95443}
2025-08-16 19:19:19,683 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:19:19,722 - INFO - test: {'epoch': 11, 'time_epoch': 5.26896, 'loss': 0.67184511, 'lr': 0, 'params': 515510, 'time_iter': 0.08363, 'accuracy': 0.75887, 'f1': 0.75887, 'accuracy-SBM': 0.7589, 'auc': 0.95531}
2025-08-16 19:19:19,724 - INFO - > Epoch 11: took 104.4s (avg 104.3s) | Best so far: epoch 11	train_loss: 0.7176 train_accuracy-SBM: 0.7418	val_loss: 0.6766 val_accuracy-SBM: 0.7604	test_loss: 0.6718 test_accuracy-SBM: 0.7589
2025-08-16 19:19:19,724 - INFO - === Epoch 12 ===
2025-08-16 19:20:44,624 - INFO - train: {'epoch': 12, 'time_epoch': 84.52108, 'eta': 7817.28323, 'eta_hours': 2.17147, 'loss': 0.71050199, 'lr': 0.00098666, 'params': 515510, 'time_iter': 0.13523, 'accuracy': 0.74324, 'f1': 0.74324, 'accuracy-SBM': 0.74324, 'auc': 0.94958}
2025-08-16 19:20:49,138 - INFO - val: {'epoch': 12, 'time_epoch': 4.46133, 'loss': 0.68714861, 'lr': 0, 'params': 515510, 'time_iter': 0.07081, 'accuracy': 0.75301, 'f1': 0.75297, 'accuracy-SBM': 0.75314, 'auc': 0.95317}
2025-08-16 19:20:57,857 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:20:57,899 - INFO - test: {'epoch': 12, 'time_epoch': 4.80199, 'loss': 0.66319077, 'lr': 0, 'params': 515510, 'time_iter': 0.07622, 'accuracy': 0.7588, 'f1': 0.75885, 'accuracy-SBM': 0.75883, 'auc': 0.95667}
2025-08-16 19:20:58,083 - INFO - > Epoch 12: took 98.4s (avg 103.8s) | Best so far: epoch 11	train_loss: 0.7176 train_accuracy-SBM: 0.7418	val_loss: 0.6766 val_accuracy-SBM: 0.7604	test_loss: 0.6718 test_accuracy-SBM: 0.7589
2025-08-16 19:20:58,083 - INFO - === Epoch 13 ===
2025-08-16 19:22:26,453 - INFO - train: {'epoch': 13, 'time_epoch': 88.07841, 'eta': 7716.52323, 'eta_hours': 2.14348, 'loss': 0.70695721, 'lr': 0.0009826, 'params': 515510, 'time_iter': 0.14093, 'accuracy': 0.74522, 'f1': 0.74522, 'accuracy-SBM': 0.74522, 'auc': 0.95003}
2025-08-16 19:22:30,949 - INFO - val: {'epoch': 13, 'time_epoch': 4.4347, 'loss': 0.65615453, 'lr': 0, 'params': 515510, 'time_iter': 0.07039, 'accuracy': 0.76384, 'f1': 0.76366, 'accuracy-SBM': 0.76367, 'auc': 0.95727}
2025-08-16 19:22:39,238 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:22:39,281 - INFO - test: {'epoch': 13, 'time_epoch': 4.4801, 'loss': 0.65951896, 'lr': 0, 'params': 515510, 'time_iter': 0.07111, 'accuracy': 0.76194, 'f1': 0.76191, 'accuracy-SBM': 0.76186, 'auc': 0.95675}
2025-08-16 19:22:39,286 - INFO - > Epoch 13: took 101.2s (avg 103.6s) | Best so far: epoch 13	train_loss: 0.7070 train_accuracy-SBM: 0.7452	val_loss: 0.6562 val_accuracy-SBM: 0.7637	test_loss: 0.6595 test_accuracy-SBM: 0.7619
2025-08-16 19:22:39,286 - INFO - === Epoch 14 ===
2025-08-16 19:24:08,241 - INFO - train: {'epoch': 14, 'time_epoch': 88.6553, 'eta': 7620.72317, 'eta_hours': 2.11687, 'loss': 0.69656339, 'lr': 0.00097802, 'params': 515510, 'time_iter': 0.14185, 'accuracy': 0.74868, 'f1': 0.74868, 'accuracy-SBM': 0.74868, 'auc': 0.95149}
2025-08-16 19:24:13,220 - INFO - val: {'epoch': 14, 'time_epoch': 4.91653, 'loss': 0.67774702, 'lr': 0, 'params': 515510, 'time_iter': 0.07804, 'accuracy': 0.758, 'f1': 0.75789, 'accuracy-SBM': 0.75786, 'auc': 0.95418}
2025-08-16 19:24:23,000 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:24:23,044 - INFO - test: {'epoch': 14, 'time_epoch': 5.18558, 'loss': 0.67219078, 'lr': 0, 'params': 515510, 'time_iter': 0.08231, 'accuracy': 0.75898, 'f1': 0.75895, 'accuracy-SBM': 0.75888, 'auc': 0.95495}
2025-08-16 19:24:23,049 - INFO - > Epoch 14: took 103.8s (avg 103.6s) | Best so far: epoch 13	train_loss: 0.7070 train_accuracy-SBM: 0.7452	val_loss: 0.6562 val_accuracy-SBM: 0.7637	test_loss: 0.6595 test_accuracy-SBM: 0.7619
2025-08-16 19:24:23,049 - INFO - === Epoch 15 ===
2025-08-16 19:25:52,602 - INFO - train: {'epoch': 15, 'time_epoch': 89.17356, 'eta': 7528.53707, 'eta_hours': 2.09126, 'loss': 0.68992872, 'lr': 0.00097291, 'params': 515510, 'time_iter': 0.14268, 'accuracy': 0.75079, 'f1': 0.75079, 'accuracy-SBM': 0.75079, 'auc': 0.95239}
2025-08-16 19:25:57,225 - INFO - val: {'epoch': 15, 'time_epoch': 4.57112, 'loss': 0.66960282, 'lr': 0, 'params': 515510, 'time_iter': 0.07256, 'accuracy': 0.75649, 'f1': 0.75602, 'accuracy-SBM': 0.75611, 'auc': 0.9555}
2025-08-16 19:26:06,392 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:26:06,436 - INFO - test: {'epoch': 15, 'time_epoch': 4.93475, 'loss': 0.67105486, 'lr': 0, 'params': 515510, 'time_iter': 0.07833, 'accuracy': 0.76024, 'f1': 0.76001, 'accuracy-SBM': 0.76012, 'auc': 0.95526}
2025-08-16 19:26:06,441 - INFO - > Epoch 15: took 103.4s (avg 103.6s) | Best so far: epoch 13	train_loss: 0.7070 train_accuracy-SBM: 0.7452	val_loss: 0.6562 val_accuracy-SBM: 0.7637	test_loss: 0.6595 test_accuracy-SBM: 0.7619
2025-08-16 19:26:06,441 - INFO - === Epoch 16 ===
2025-08-16 19:27:36,004 - INFO - train: {'epoch': 16, 'time_epoch': 89.26539, 'eta': 7437.15375, 'eta_hours': 2.06588, 'loss': 0.68933832, 'lr': 0.00096728, 'params': 515510, 'time_iter': 0.14282, 'accuracy': 0.75156, 'f1': 0.75155, 'accuracy-SBM': 0.75156, 'auc': 0.95242}
2025-08-16 19:27:40,733 - INFO - val: {'epoch': 16, 'time_epoch': 4.66828, 'loss': 0.65871276, 'lr': 0, 'params': 515510, 'time_iter': 0.0741, 'accuracy': 0.76283, 'f1': 0.76257, 'accuracy-SBM': 0.7625, 'auc': 0.95683}
2025-08-16 19:27:50,422 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:27:50,463 - INFO - test: {'epoch': 16, 'time_epoch': 4.86981, 'loss': 0.65060902, 'lr': 0, 'params': 515510, 'time_iter': 0.0773, 'accuracy': 0.76408, 'f1': 0.76404, 'accuracy-SBM': 0.76399, 'auc': 0.95796}
2025-08-16 19:27:50,467 - INFO - > Epoch 16: took 104.0s (avg 103.7s) | Best so far: epoch 13	train_loss: 0.7070 train_accuracy-SBM: 0.7452	val_loss: 0.6562 val_accuracy-SBM: 0.7637	test_loss: 0.6595 test_accuracy-SBM: 0.7619
2025-08-16 19:27:50,468 - INFO - === Epoch 17 ===
2025-08-16 19:29:22,860 - INFO - train: {'epoch': 17, 'time_epoch': 92.12054, 'eta': 7359.01253, 'eta_hours': 2.04417, 'loss': 0.68386557, 'lr': 0.00096114, 'params': 515510, 'time_iter': 0.14739, 'accuracy': 0.75304, 'f1': 0.75304, 'accuracy-SBM': 0.75304, 'auc': 0.95321}
2025-08-16 19:29:27,486 - INFO - val: {'epoch': 17, 'time_epoch': 4.56798, 'loss': 0.64950569, 'lr': 0, 'params': 515510, 'time_iter': 0.07251, 'accuracy': 0.76585, 'f1': 0.76586, 'accuracy-SBM': 0.76576, 'auc': 0.95811}
2025-08-16 19:29:35,894 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:29:35,943 - INFO - test: {'epoch': 17, 'time_epoch': 4.9113, 'loss': 0.65680193, 'lr': 0, 'params': 515510, 'time_iter': 0.07796, 'accuracy': 0.76234, 'f1': 0.76241, 'accuracy-SBM': 0.76241, 'auc': 0.95724}
2025-08-16 19:29:35,947 - INFO - > Epoch 17: took 105.5s (avg 103.8s) | Best so far: epoch 17	train_loss: 0.6839 train_accuracy-SBM: 0.7530	val_loss: 0.6495 val_accuracy-SBM: 0.7658	test_loss: 0.6568 test_accuracy-SBM: 0.7624
2025-08-16 19:29:35,948 - INFO - === Epoch 18 ===
2025-08-16 19:31:07,693 - INFO - train: {'epoch': 18, 'time_epoch': 91.47521, 'eta': 7276.64866, 'eta_hours': 2.02129, 'loss': 0.67875291, 'lr': 0.0009545, 'params': 515510, 'time_iter': 0.14636, 'accuracy': 0.75485, 'f1': 0.75485, 'accuracy-SBM': 0.75485, 'auc': 0.95389}
2025-08-16 19:31:12,318 - INFO - val: {'epoch': 18, 'time_epoch': 4.57665, 'loss': 0.65821716, 'lr': 0, 'params': 515510, 'time_iter': 0.07265, 'accuracy': 0.76209, 'f1': 0.76203, 'accuracy-SBM': 0.76206, 'auc': 0.95717}
2025-08-16 19:31:22,982 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:31:23,027 - INFO - test: {'epoch': 18, 'time_epoch': 4.51032, 'loss': 0.66027332, 'lr': 0, 'params': 515510, 'time_iter': 0.07159, 'accuracy': 0.76129, 'f1': 0.76132, 'accuracy-SBM': 0.76132, 'auc': 0.95704}
2025-08-16 19:31:23,031 - INFO - > Epoch 18: took 107.1s (avg 103.9s) | Best so far: epoch 17	train_loss: 0.6839 train_accuracy-SBM: 0.7530	val_loss: 0.6495 val_accuracy-SBM: 0.7658	test_loss: 0.6568 test_accuracy-SBM: 0.7624
2025-08-16 19:31:23,031 - INFO - === Epoch 19 ===
2025-08-16 19:32:53,989 - INFO - train: {'epoch': 19, 'time_epoch': 90.4994, 'eta': 7189.47041, 'eta_hours': 1.99708, 'loss': 0.67350622, 'lr': 0.00094736, 'params': 515510, 'time_iter': 0.1448, 'accuracy': 0.75648, 'f1': 0.75648, 'accuracy-SBM': 0.75648, 'auc': 0.95462}
2025-08-16 19:32:59,047 - INFO - val: {'epoch': 19, 'time_epoch': 4.99888, 'loss': 0.65462585, 'lr': 0, 'params': 515510, 'time_iter': 0.07935, 'accuracy': 0.765, 'f1': 0.76489, 'accuracy-SBM': 0.76496, 'auc': 0.9573}
2025-08-16 19:33:08,660 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:33:08,706 - INFO - test: {'epoch': 19, 'time_epoch': 5.51311, 'loss': 0.64326305, 'lr': 0, 'params': 515510, 'time_iter': 0.08751, 'accuracy': 0.76715, 'f1': 0.76719, 'accuracy-SBM': 0.76714, 'auc': 0.9589}
2025-08-16 19:33:08,711 - INFO - > Epoch 19: took 105.7s (avg 104.0s) | Best so far: epoch 17	train_loss: 0.6839 train_accuracy-SBM: 0.7530	val_loss: 0.6495 val_accuracy-SBM: 0.7658	test_loss: 0.6568 test_accuracy-SBM: 0.7624
2025-08-16 19:33:08,711 - INFO - === Epoch 20 ===
2025-08-16 19:34:39,815 - INFO - train: {'epoch': 20, 'time_epoch': 90.83446, 'eta': 7103.23631, 'eta_hours': 1.97312, 'loss': 0.6699955, 'lr': 0.00093974, 'params': 515510, 'time_iter': 0.14534, 'accuracy': 0.75843, 'f1': 0.75843, 'accuracy-SBM': 0.75843, 'auc': 0.95506}
2025-08-16 19:34:44,423 - INFO - val: {'epoch': 20, 'time_epoch': 4.55293, 'loss': 0.64974649, 'lr': 0, 'params': 515510, 'time_iter': 0.07227, 'accuracy': 0.76614, 'f1': 0.76607, 'accuracy-SBM': 0.76613, 'auc': 0.95811}
2025-08-16 19:34:53,055 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:34:53,094 - INFO - test: {'epoch': 20, 'time_epoch': 4.77967, 'loss': 0.64771149, 'lr': 0, 'params': 515510, 'time_iter': 0.07587, 'accuracy': 0.76612, 'f1': 0.7661, 'accuracy-SBM': 0.76605, 'auc': 0.95826}
2025-08-16 19:34:53,096 - INFO - > Epoch 20: took 104.4s (avg 104.0s) | Best so far: epoch 20	train_loss: 0.6700 train_accuracy-SBM: 0.7584	val_loss: 0.6497 val_accuracy-SBM: 0.7661	test_loss: 0.6477 test_accuracy-SBM: 0.7661
2025-08-16 19:34:53,096 - INFO - === Epoch 21 ===
2025-08-16 19:36:23,963 - INFO - train: {'epoch': 21, 'time_epoch': 90.59074, 'eta': 7015.7199, 'eta_hours': 1.94881, 'loss': 0.66852064, 'lr': 0.00093163, 'params': 515510, 'time_iter': 0.14495, 'accuracy': 0.75913, 'f1': 0.75913, 'accuracy-SBM': 0.75914, 'auc': 0.95523}
2025-08-16 19:36:28,596 - INFO - val: {'epoch': 21, 'time_epoch': 4.57391, 'loss': 0.65547701, 'lr': 0, 'params': 515510, 'time_iter': 0.0726, 'accuracy': 0.7639, 'f1': 0.76373, 'accuracy-SBM': 0.76378, 'auc': 0.9577}
2025-08-16 19:36:40,097 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:36:40,137 - INFO - test: {'epoch': 21, 'time_epoch': 4.91478, 'loss': 0.65769166, 'lr': 0, 'params': 515510, 'time_iter': 0.07801, 'accuracy': 0.76294, 'f1': 0.76282, 'accuracy-SBM': 0.76268, 'auc': 0.9574}
2025-08-16 19:36:40,139 - INFO - > Epoch 21: took 107.0s (avg 104.2s) | Best so far: epoch 20	train_loss: 0.6700 train_accuracy-SBM: 0.7584	val_loss: 0.6497 val_accuracy-SBM: 0.7661	test_loss: 0.6477 test_accuracy-SBM: 0.7661
2025-08-16 19:36:40,139 - INFO - === Epoch 22 ===
2025-08-16 19:38:12,629 - INFO - train: {'epoch': 22, 'time_epoch': 92.07545, 'eta': 6932.90672, 'eta_hours': 1.92581, 'loss': 0.6662579, 'lr': 0.00092305, 'params': 515510, 'time_iter': 0.14732, 'accuracy': 0.75967, 'f1': 0.75967, 'accuracy-SBM': 0.75967, 'auc': 0.95555}
2025-08-16 19:38:17,655 - INFO - val: {'epoch': 22, 'time_epoch': 4.95127, 'loss': 0.6413634, 'lr': 0, 'params': 515510, 'time_iter': 0.07859, 'accuracy': 0.7696, 'f1': 0.7694, 'accuracy-SBM': 0.7694, 'auc': 0.95893}
2025-08-16 19:38:27,058 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:38:27,107 - INFO - test: {'epoch': 22, 'time_epoch': 5.33044, 'loss': 0.6398884, 'lr': 0, 'params': 515510, 'time_iter': 0.08461, 'accuracy': 0.76973, 'f1': 0.76966, 'accuracy-SBM': 0.76967, 'auc': 0.95926}
2025-08-16 19:38:27,111 - INFO - > Epoch 22: took 107.0s (avg 104.3s) | Best so far: epoch 22	train_loss: 0.6663 train_accuracy-SBM: 0.7597	val_loss: 0.6414 val_accuracy-SBM: 0.7694	test_loss: 0.6399 test_accuracy-SBM: 0.7697
2025-08-16 19:38:27,112 - INFO - === Epoch 23 ===
2025-08-16 19:39:59,851 - INFO - train: {'epoch': 23, 'time_epoch': 92.34735, 'eta': 6850.18271, 'eta_hours': 1.90283, 'loss': 0.66021641, 'lr': 0.000914, 'params': 515510, 'time_iter': 0.14776, 'accuracy': 0.76123, 'f1': 0.76123, 'accuracy-SBM': 0.76123, 'auc': 0.95636}
2025-08-16 19:40:04,566 - INFO - val: {'epoch': 23, 'time_epoch': 4.63708, 'loss': 0.65105743, 'lr': 0, 'params': 515510, 'time_iter': 0.0736, 'accuracy': 0.76543, 'f1': 0.76519, 'accuracy-SBM': 0.76536, 'auc': 0.95796}
2025-08-16 19:40:14,392 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:40:14,435 - INFO - test: {'epoch': 23, 'time_epoch': 4.97056, 'loss': 0.64480222, 'lr': 0, 'params': 515510, 'time_iter': 0.0789, 'accuracy': 0.76661, 'f1': 0.76656, 'accuracy-SBM': 0.76647, 'auc': 0.95886}
2025-08-16 19:40:14,441 - INFO - > Epoch 23: took 107.3s (avg 104.4s) | Best so far: epoch 22	train_loss: 0.6663 train_accuracy-SBM: 0.7597	val_loss: 0.6414 val_accuracy-SBM: 0.7694	test_loss: 0.6399 test_accuracy-SBM: 0.7697
2025-08-16 19:40:14,441 - INFO - === Epoch 24 ===
2025-08-16 19:41:46,736 - INFO - train: {'epoch': 24, 'time_epoch': 92.01979, 'eta': 6765.70615, 'eta_hours': 1.87936, 'loss': 0.65501987, 'lr': 0.00090451, 'params': 515510, 'time_iter': 0.14723, 'accuracy': 0.76348, 'f1': 0.76348, 'accuracy-SBM': 0.76348, 'auc': 0.95704}
2025-08-16 19:41:51,360 - INFO - val: {'epoch': 24, 'time_epoch': 4.56783, 'loss': 0.64897222, 'lr': 0, 'params': 515510, 'time_iter': 0.07251, 'accuracy': 0.76698, 'f1': 0.7666, 'accuracy-SBM': 0.76661, 'auc': 0.95801}
2025-08-16 19:42:01,462 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:42:01,511 - INFO - test: {'epoch': 24, 'time_epoch': 4.93333, 'loss': 0.64939841, 'lr': 0, 'params': 515510, 'time_iter': 0.07831, 'accuracy': 0.76633, 'f1': 0.76625, 'accuracy-SBM': 0.76619, 'auc': 0.95806}
2025-08-16 19:42:01,516 - INFO - > Epoch 24: took 107.1s (avg 104.5s) | Best so far: epoch 22	train_loss: 0.6663 train_accuracy-SBM: 0.7597	val_loss: 0.6414 val_accuracy-SBM: 0.7694	test_loss: 0.6399 test_accuracy-SBM: 0.7697
2025-08-16 19:42:01,516 - INFO - === Epoch 25 ===
2025-08-16 19:43:34,852 - INFO - train: {'epoch': 25, 'time_epoch': 93.06943, 'eta': 6683.63676, 'eta_hours': 1.85657, 'loss': 0.65586534, 'lr': 0.00089457, 'params': 515510, 'time_iter': 0.14891, 'accuracy': 0.76346, 'f1': 0.76345, 'accuracy-SBM': 0.76346, 'auc': 0.95693}
2025-08-16 19:43:39,580 - INFO - val: {'epoch': 25, 'time_epoch': 4.6675, 'loss': 0.64165133, 'lr': 0, 'params': 515510, 'time_iter': 0.07409, 'accuracy': 0.77184, 'f1': 0.77165, 'accuracy-SBM': 0.7717, 'auc': 0.959}
2025-08-16 19:43:49,085 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:43:49,135 - INFO - test: {'epoch': 25, 'time_epoch': 5.041, 'loss': 0.63365041, 'lr': 0, 'params': 515510, 'time_iter': 0.08002, 'accuracy': 0.7717, 'f1': 0.77165, 'accuracy-SBM': 0.77169, 'auc': 0.96025}
2025-08-16 19:43:49,139 - INFO - > Epoch 25: took 107.6s (avg 104.6s) | Best so far: epoch 25	train_loss: 0.6559 train_accuracy-SBM: 0.7635	val_loss: 0.6417 val_accuracy-SBM: 0.7717	test_loss: 0.6337 test_accuracy-SBM: 0.7717
2025-08-16 19:43:49,139 - INFO - === Epoch 26 ===
2025-08-16 19:45:23,455 - INFO - train: {'epoch': 26, 'time_epoch': 94.02734, 'eta': 6603.34247, 'eta_hours': 1.83426, 'loss': 0.65133608, 'lr': 0.0008842, 'params': 515510, 'time_iter': 0.15044, 'accuracy': 0.76475, 'f1': 0.76475, 'accuracy-SBM': 0.76475, 'auc': 0.9575}
2025-08-16 19:45:28,236 - INFO - val: {'epoch': 26, 'time_epoch': 4.72002, 'loss': 0.63950014, 'lr': 0, 'params': 515510, 'time_iter': 0.07492, 'accuracy': 0.77062, 'f1': 0.77057, 'accuracy-SBM': 0.77058, 'auc': 0.95926}
2025-08-16 19:45:37,199 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:45:37,245 - INFO - test: {'epoch': 26, 'time_epoch': 5.02536, 'loss': 0.6407547, 'lr': 0, 'params': 515510, 'time_iter': 0.07977, 'accuracy': 0.76919, 'f1': 0.7692, 'accuracy-SBM': 0.76918, 'auc': 0.95916}
2025-08-16 19:45:37,249 - INFO - > Epoch 26: took 108.1s (avg 104.8s) | Best so far: epoch 25	train_loss: 0.6559 train_accuracy-SBM: 0.7635	val_loss: 0.6417 val_accuracy-SBM: 0.7717	test_loss: 0.6337 test_accuracy-SBM: 0.7717
2025-08-16 19:45:37,249 - INFO - === Epoch 27 ===
2025-08-16 19:47:13,749 - INFO - train: {'epoch': 27, 'time_epoch': 96.19273, 'eta': 6527.6354, 'eta_hours': 1.81323, 'loss': 0.6451413, 'lr': 0.00087341, 'params': 515510, 'time_iter': 0.15391, 'accuracy': 0.76689, 'f1': 0.76689, 'accuracy-SBM': 0.76689, 'auc': 0.95833}
2025-08-16 19:47:18,530 - INFO - val: {'epoch': 27, 'time_epoch': 4.72218, 'loss': 0.63102689, 'lr': 0, 'params': 515510, 'time_iter': 0.07496, 'accuracy': 0.77401, 'f1': 0.77385, 'accuracy-SBM': 0.77391, 'auc': 0.96022}
2025-08-16 19:47:29,441 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:47:29,483 - INFO - test: {'epoch': 27, 'time_epoch': 5.10444, 'loss': 0.63474655, 'lr': 0, 'params': 515510, 'time_iter': 0.08102, 'accuracy': 0.77203, 'f1': 0.77196, 'accuracy-SBM': 0.77199, 'auc': 0.95983}
2025-08-16 19:47:29,487 - INFO - > Epoch 27: took 112.2s (avg 105.0s) | Best so far: epoch 27	train_loss: 0.6451 train_accuracy-SBM: 0.7669	val_loss: 0.6310 val_accuracy-SBM: 0.7739	test_loss: 0.6347 test_accuracy-SBM: 0.7720
2025-08-16 19:47:29,487 - INFO - === Epoch 28 ===
2025-08-16 19:48:56,275 - INFO - train: {'epoch': 28, 'time_epoch': 86.51496, 'eta': 6426.82166, 'eta_hours': 1.78523, 'loss': 0.6435467, 'lr': 0.00086221, 'params': 515510, 'time_iter': 0.13842, 'accuracy': 0.76721, 'f1': 0.76721, 'accuracy-SBM': 0.76721, 'auc': 0.95852}
2025-08-16 19:49:00,335 - INFO - val: {'epoch': 28, 'time_epoch': 4.01242, 'loss': 0.64532701, 'lr': 0, 'params': 515510, 'time_iter': 0.06369, 'accuracy': 0.76941, 'f1': 0.76932, 'accuracy-SBM': 0.76924, 'auc': 0.95853}
2025-08-16 19:49:09,080 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:49:09,124 - INFO - test: {'epoch': 28, 'time_epoch': 4.02143, 'loss': 0.64022848, 'lr': 0, 'params': 515510, 'time_iter': 0.06383, 'accuracy': 0.76933, 'f1': 0.76928, 'accuracy-SBM': 0.76927, 'auc': 0.9592}
2025-08-16 19:49:09,128 - INFO - > Epoch 28: took 99.6s (avg 104.9s) | Best so far: epoch 27	train_loss: 0.6451 train_accuracy-SBM: 0.7669	val_loss: 0.6310 val_accuracy-SBM: 0.7739	test_loss: 0.6347 test_accuracy-SBM: 0.7720
2025-08-16 19:49:09,128 - INFO - === Epoch 29 ===
2025-08-16 19:50:29,671 - INFO - train: {'epoch': 29, 'time_epoch': 80.28061, 'eta': 6312.41437, 'eta_hours': 1.75345, 'loss': 0.63958289, 'lr': 0.00085062, 'params': 515510, 'time_iter': 0.12845, 'accuracy': 0.76886, 'f1': 0.76885, 'accuracy-SBM': 0.76886, 'auc': 0.95904}
2025-08-16 19:50:33,791 - INFO - val: {'epoch': 29, 'time_epoch': 4.06995, 'loss': 0.63694048, 'lr': 0, 'params': 515510, 'time_iter': 0.0646, 'accuracy': 0.77286, 'f1': 0.77267, 'accuracy-SBM': 0.7727, 'auc': 0.95947}
2025-08-16 19:50:42,960 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:50:42,998 - INFO - test: {'epoch': 29, 'time_epoch': 4.293, 'loss': 0.63342844, 'lr': 0, 'params': 515510, 'time_iter': 0.06814, 'accuracy': 0.77054, 'f1': 0.77056, 'accuracy-SBM': 0.77056, 'auc': 0.96007}
2025-08-16 19:50:43,003 - INFO - > Epoch 29: took 93.9s (avg 104.5s) | Best so far: epoch 27	train_loss: 0.6451 train_accuracy-SBM: 0.7669	val_loss: 0.6310 val_accuracy-SBM: 0.7739	test_loss: 0.6347 test_accuracy-SBM: 0.7720
2025-08-16 19:50:43,003 - INFO - === Epoch 30 ===
2025-08-16 19:52:07,173 - INFO - train: {'epoch': 30, 'time_epoch': 83.87698, 'eta': 6208.21362, 'eta_hours': 1.7245, 'loss': 0.63595308, 'lr': 0.00083864, 'params': 515510, 'time_iter': 0.1342, 'accuracy': 0.77016, 'f1': 0.77016, 'accuracy-SBM': 0.77016, 'auc': 0.9595}
2025-08-16 19:52:11,778 - INFO - val: {'epoch': 30, 'time_epoch': 4.54372, 'loss': 0.63456095, 'lr': 0, 'params': 515510, 'time_iter': 0.07212, 'accuracy': 0.77345, 'f1': 0.77341, 'accuracy-SBM': 0.77333, 'auc': 0.95982}
2025-08-16 19:52:21,548 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:52:21,591 - INFO - test: {'epoch': 30, 'time_epoch': 4.80358, 'loss': 0.63006241, 'lr': 0, 'params': 515510, 'time_iter': 0.07625, 'accuracy': 0.77327, 'f1': 0.77321, 'accuracy-SBM': 0.77328, 'auc': 0.96049}
2025-08-16 19:52:21,595 - INFO - > Epoch 30: took 98.6s (avg 104.3s) | Best so far: epoch 27	train_loss: 0.6451 train_accuracy-SBM: 0.7669	val_loss: 0.6310 val_accuracy-SBM: 0.7739	test_loss: 0.6347 test_accuracy-SBM: 0.7720
2025-08-16 19:52:21,595 - INFO - === Epoch 31 ===
2025-08-16 19:53:50,747 - INFO - train: {'epoch': 31, 'time_epoch': 88.86035, 'eta': 6115.87277, 'eta_hours': 1.69885, 'loss': 0.63643517, 'lr': 0.00082629, 'params': 515510, 'time_iter': 0.14218, 'accuracy': 0.76998, 'f1': 0.76998, 'accuracy-SBM': 0.76998, 'auc': 0.95944}
2025-08-16 19:53:55,297 - INFO - val: {'epoch': 31, 'time_epoch': 4.49619, 'loss': 0.63483864, 'lr': 0, 'params': 515510, 'time_iter': 0.07137, 'accuracy': 0.77332, 'f1': 0.77315, 'accuracy-SBM': 0.77336, 'auc': 0.96004}
2025-08-16 19:54:04,716 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:54:04,758 - INFO - test: {'epoch': 31, 'time_epoch': 4.88881, 'loss': 0.62762733, 'lr': 0, 'params': 515510, 'time_iter': 0.0776, 'accuracy': 0.77335, 'f1': 0.77347, 'accuracy-SBM': 0.77336, 'auc': 0.96109}
2025-08-16 19:54:04,760 - INFO - > Epoch 31: took 103.2s (avg 104.3s) | Best so far: epoch 27	train_loss: 0.6451 train_accuracy-SBM: 0.7669	val_loss: 0.6310 val_accuracy-SBM: 0.7739	test_loss: 0.6347 test_accuracy-SBM: 0.7720
2025-08-16 19:54:04,761 - INFO - === Epoch 32 ===
2025-08-16 19:55:32,785 - INFO - train: {'epoch': 32, 'time_epoch': 87.74658, 'eta': 6021.48156, 'eta_hours': 1.67263, 'loss': 0.63291117, 'lr': 0.00081359, 'params': 515510, 'time_iter': 0.14039, 'accuracy': 0.7709, 'f1': 0.7709, 'accuracy-SBM': 0.7709, 'auc': 0.9599}
2025-08-16 19:55:36,890 - INFO - val: {'epoch': 32, 'time_epoch': 4.06048, 'loss': 0.63335833, 'lr': 0, 'params': 515510, 'time_iter': 0.06445, 'accuracy': 0.77623, 'f1': 0.77615, 'accuracy-SBM': 0.77613, 'auc': 0.96015}
2025-08-16 19:55:42,583 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:55:42,624 - INFO - test: {'epoch': 32, 'time_epoch': 4.47537, 'loss': 0.6283518, 'lr': 0, 'params': 515510, 'time_iter': 0.07104, 'accuracy': 0.77376, 'f1': 0.77372, 'accuracy-SBM': 0.77376, 'auc': 0.96101}
2025-08-16 19:55:42,626 - INFO - > Epoch 32: took 97.9s (avg 104.1s) | Best so far: epoch 32	train_loss: 0.6329 train_accuracy-SBM: 0.7709	val_loss: 0.6334 val_accuracy-SBM: 0.7761	test_loss: 0.6284 test_accuracy-SBM: 0.7738
2025-08-16 19:55:42,626 - INFO - === Epoch 33 ===
2025-08-16 19:57:09,155 - INFO - train: {'epoch': 33, 'time_epoch': 86.15742, 'eta': 5924.39638, 'eta_hours': 1.64567, 'loss': 0.6317405, 'lr': 0.00080054, 'params': 515510, 'time_iter': 0.13785, 'accuracy': 0.77135, 'f1': 0.77134, 'accuracy-SBM': 0.77135, 'auc': 0.96003}
2025-08-16 19:57:13,264 - INFO - val: {'epoch': 33, 'time_epoch': 4.06432, 'loss': 0.6307803, 'lr': 0, 'params': 515510, 'time_iter': 0.06451, 'accuracy': 0.77698, 'f1': 0.77685, 'accuracy-SBM': 0.77682, 'auc': 0.96027}
2025-08-16 19:57:18,830 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:57:18,867 - INFO - test: {'epoch': 33, 'time_epoch': 4.36429, 'loss': 0.62104117, 'lr': 0, 'params': 515510, 'time_iter': 0.06927, 'accuracy': 0.77747, 'f1': 0.77741, 'accuracy-SBM': 0.77744, 'auc': 0.96162}
2025-08-16 19:57:18,870 - INFO - > Epoch 33: took 96.2s (avg 103.8s) | Best so far: epoch 33	train_loss: 0.6317 train_accuracy-SBM: 0.7713	val_loss: 0.6308 val_accuracy-SBM: 0.7768	test_loss: 0.6210 test_accuracy-SBM: 0.7774
2025-08-16 19:57:18,870 - INFO - === Epoch 34 ===
2025-08-16 19:58:44,389 - INFO - train: {'epoch': 34, 'time_epoch': 85.28568, 'eta': 5826.3167, 'eta_hours': 1.61842, 'loss': 0.62829748, 'lr': 0.00078716, 'params': 515510, 'time_iter': 0.13646, 'accuracy': 0.77293, 'f1': 0.77293, 'accuracy-SBM': 0.77293, 'auc': 0.96047}
2025-08-16 19:58:48,384 - INFO - val: {'epoch': 34, 'time_epoch': 3.95121, 'loss': 0.62762922, 'lr': 0, 'params': 515510, 'time_iter': 0.06272, 'accuracy': 0.77716, 'f1': 0.77706, 'accuracy-SBM': 0.77701, 'auc': 0.96055}
2025-08-16 19:58:54,455 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 19:58:54,501 - INFO - test: {'epoch': 34, 'time_epoch': 3.95353, 'loss': 0.61789454, 'lr': 0, 'params': 515510, 'time_iter': 0.06275, 'accuracy': 0.77706, 'f1': 0.77702, 'accuracy-SBM': 0.77701, 'auc': 0.96188}
2025-08-16 19:58:54,503 - INFO - > Epoch 34: took 95.6s (avg 103.6s) | Best so far: epoch 34	train_loss: 0.6283 train_accuracy-SBM: 0.7729	val_loss: 0.6276 val_accuracy-SBM: 0.7770	test_loss: 0.6179 test_accuracy-SBM: 0.7770
2025-08-16 19:58:54,503 - INFO - === Epoch 35 ===
2025-08-16 20:00:16,703 - INFO - train: {'epoch': 35, 'time_epoch': 81.72497, 'eta': 5722.61764, 'eta_hours': 1.58962, 'loss': 0.61999183, 'lr': 0.00077347, 'params': 515510, 'time_iter': 0.13076, 'accuracy': 0.77542, 'f1': 0.77542, 'accuracy-SBM': 0.77542, 'auc': 0.96153}
2025-08-16 20:00:20,630 - INFO - val: {'epoch': 35, 'time_epoch': 3.87751, 'loss': 0.63429414, 'lr': 0, 'params': 515510, 'time_iter': 0.06155, 'accuracy': 0.77173, 'f1': 0.77166, 'accuracy-SBM': 0.77166, 'auc': 0.95981}
2025-08-16 20:00:28,123 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:00:28,160 - INFO - test: {'epoch': 35, 'time_epoch': 3.91824, 'loss': 0.62700414, 'lr': 0, 'params': 515510, 'time_iter': 0.06219, 'accuracy': 0.77247, 'f1': 0.77252, 'accuracy-SBM': 0.77253, 'auc': 0.96076}
2025-08-16 20:00:28,165 - INFO - > Epoch 35: took 93.7s (avg 103.3s) | Best so far: epoch 34	train_loss: 0.6283 train_accuracy-SBM: 0.7729	val_loss: 0.6276 val_accuracy-SBM: 0.7770	test_loss: 0.6179 test_accuracy-SBM: 0.7770
2025-08-16 20:00:28,166 - INFO - === Epoch 36 ===
2025-08-16 20:01:47,034 - INFO - train: {'epoch': 36, 'time_epoch': 78.63378, 'eta': 5614.84299, 'eta_hours': 1.55968, 'loss': 0.62113187, 'lr': 0.00075948, 'params': 515510, 'time_iter': 0.12581, 'accuracy': 0.77515, 'f1': 0.77515, 'accuracy-SBM': 0.77515, 'auc': 0.96136}
2025-08-16 20:01:51,109 - INFO - val: {'epoch': 36, 'time_epoch': 4.02889, 'loss': 0.6308008, 'lr': 0, 'params': 515510, 'time_iter': 0.06395, 'accuracy': 0.77654, 'f1': 0.77634, 'accuracy-SBM': 0.77636, 'auc': 0.96045}
2025-08-16 20:02:01,438 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:02:01,476 - INFO - test: {'epoch': 36, 'time_epoch': 4.25322, 'loss': 0.61871148, 'lr': 0, 'params': 515510, 'time_iter': 0.06751, 'accuracy': 0.77625, 'f1': 0.7762, 'accuracy-SBM': 0.77615, 'auc': 0.96197}
2025-08-16 20:02:01,481 - INFO - > Epoch 36: took 93.3s (avg 103.1s) | Best so far: epoch 34	train_loss: 0.6283 train_accuracy-SBM: 0.7729	val_loss: 0.6276 val_accuracy-SBM: 0.7770	test_loss: 0.6179 test_accuracy-SBM: 0.7770
2025-08-16 20:02:01,481 - INFO - === Epoch 37 ===
2025-08-16 20:03:20,564 - INFO - train: {'epoch': 37, 'time_epoch': 78.84927, 'eta': 5508.95366, 'eta_hours': 1.53026, 'loss': 0.62172389, 'lr': 0.00074521, 'params': 515510, 'time_iter': 0.12616, 'accuracy': 0.77496, 'f1': 0.77496, 'accuracy-SBM': 0.77496, 'auc': 0.96129}
2025-08-16 20:03:24,563 - INFO - val: {'epoch': 37, 'time_epoch': 3.94898, 'loss': 0.63767887, 'lr': 0, 'params': 515510, 'time_iter': 0.06268, 'accuracy': 0.77555, 'f1': 0.77544, 'accuracy-SBM': 0.77551, 'auc': 0.95968}
2025-08-16 20:03:34,818 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:03:34,857 - INFO - test: {'epoch': 37, 'time_epoch': 4.17157, 'loss': 0.62026312, 'lr': 0, 'params': 515510, 'time_iter': 0.06622, 'accuracy': 0.77741, 'f1': 0.7774, 'accuracy-SBM': 0.77739, 'auc': 0.96181}
2025-08-16 20:03:34,862 - INFO - > Epoch 37: took 93.4s (avg 102.8s) | Best so far: epoch 34	train_loss: 0.6283 train_accuracy-SBM: 0.7729	val_loss: 0.6276 val_accuracy-SBM: 0.7770	test_loss: 0.6179 test_accuracy-SBM: 0.7770
2025-08-16 20:03:34,862 - INFO - === Epoch 38 ===
2025-08-16 20:04:53,232 - INFO - train: {'epoch': 38, 'time_epoch': 78.13056, 'eta': 5403.32687, 'eta_hours': 1.50092, 'loss': 0.61591789, 'lr': 0.00073067, 'params': 515510, 'time_iter': 0.12501, 'accuracy': 0.77694, 'f1': 0.77694, 'accuracy-SBM': 0.77694, 'auc': 0.96202}
2025-08-16 20:04:57,329 - INFO - val: {'epoch': 38, 'time_epoch': 4.04756, 'loss': 0.62206196, 'lr': 0, 'params': 515510, 'time_iter': 0.06425, 'accuracy': 0.777, 'f1': 0.7768, 'accuracy-SBM': 0.77682, 'auc': 0.96147}
2025-08-16 20:05:06,133 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:05:06,170 - INFO - test: {'epoch': 38, 'time_epoch': 4.28732, 'loss': 0.61237288, 'lr': 0, 'params': 515510, 'time_iter': 0.06805, 'accuracy': 0.77834, 'f1': 0.77837, 'accuracy-SBM': 0.77823, 'auc': 0.9628}
2025-08-16 20:05:06,175 - INFO - > Epoch 38: took 91.3s (avg 102.5s) | Best so far: epoch 34	train_loss: 0.6283 train_accuracy-SBM: 0.7729	val_loss: 0.6276 val_accuracy-SBM: 0.7770	test_loss: 0.6179 test_accuracy-SBM: 0.7770
2025-08-16 20:05:06,175 - INFO - === Epoch 39 ===
2025-08-16 20:06:23,574 - INFO - train: {'epoch': 39, 'time_epoch': 77.16462, 'eta': 5297.62597, 'eta_hours': 1.47156, 'loss': 0.61103339, 'lr': 0.00071588, 'params': 515510, 'time_iter': 0.12346, 'accuracy': 0.77813, 'f1': 0.77813, 'accuracy-SBM': 0.77813, 'auc': 0.96263}
2025-08-16 20:06:27,504 - INFO - val: {'epoch': 39, 'time_epoch': 3.88088, 'loss': 0.62924084, 'lr': 0, 'params': 515510, 'time_iter': 0.0616, 'accuracy': 0.7754, 'f1': 0.77524, 'accuracy-SBM': 0.7753, 'auc': 0.96049}
2025-08-16 20:06:36,567 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:06:36,604 - INFO - test: {'epoch': 39, 'time_epoch': 4.15494, 'loss': 0.61839339, 'lr': 0, 'params': 515510, 'time_iter': 0.06595, 'accuracy': 0.779, 'f1': 0.77894, 'accuracy-SBM': 0.7789, 'auc': 0.96183}
2025-08-16 20:06:36,608 - INFO - > Epoch 39: took 90.4s (avg 102.2s) | Best so far: epoch 34	train_loss: 0.6283 train_accuracy-SBM: 0.7729	val_loss: 0.6276 val_accuracy-SBM: 0.7770	test_loss: 0.6179 test_accuracy-SBM: 0.7770
2025-08-16 20:06:36,608 - INFO - === Epoch 40 ===
2025-08-16 20:07:55,266 - INFO - train: {'epoch': 40, 'time_epoch': 78.42339, 'eta': 5195.12849, 'eta_hours': 1.44309, 'loss': 0.60937616, 'lr': 0.00070085, 'params': 515510, 'time_iter': 0.12548, 'accuracy': 0.77946, 'f1': 0.77946, 'accuracy-SBM': 0.77946, 'auc': 0.9628}
2025-08-16 20:07:59,141 - INFO - val: {'epoch': 40, 'time_epoch': 3.82859, 'loss': 0.62355918, 'lr': 0, 'params': 515510, 'time_iter': 0.06077, 'accuracy': 0.77835, 'f1': 0.77827, 'accuracy-SBM': 0.77815, 'auc': 0.96142}
2025-08-16 20:08:08,289 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:08:08,326 - INFO - test: {'epoch': 40, 'time_epoch': 4.03097, 'loss': 0.61064346, 'lr': 0, 'params': 515510, 'time_iter': 0.06398, 'accuracy': 0.78015, 'f1': 0.78005, 'accuracy-SBM': 0.78005, 'auc': 0.96296}
2025-08-16 20:08:08,331 - INFO - > Epoch 40: took 91.7s (avg 102.0s) | Best so far: epoch 40	train_loss: 0.6094 train_accuracy-SBM: 0.7795	val_loss: 0.6236 val_accuracy-SBM: 0.7782	test_loss: 0.6106 test_accuracy-SBM: 0.7801
2025-08-16 20:08:08,332 - INFO - === Epoch 41 ===
2025-08-16 20:09:25,266 - INFO - train: {'epoch': 41, 'time_epoch': 76.70852, 'eta': 5091.40925, 'eta_hours': 1.41428, 'loss': 0.60987439, 'lr': 0.0006856, 'params': 515510, 'time_iter': 0.12273, 'accuracy': 0.77934, 'f1': 0.77934, 'accuracy-SBM': 0.77934, 'auc': 0.96276}
2025-08-16 20:09:29,109 - INFO - val: {'epoch': 41, 'time_epoch': 3.77054, 'loss': 0.62511073, 'lr': 0, 'params': 515510, 'time_iter': 0.05985, 'accuracy': 0.77608, 'f1': 0.77599, 'accuracy-SBM': 0.77599, 'auc': 0.9609}
2025-08-16 20:09:39,855 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:09:39,892 - INFO - test: {'epoch': 41, 'time_epoch': 4.02488, 'loss': 0.61729175, 'lr': 0, 'params': 515510, 'time_iter': 0.06389, 'accuracy': 0.77608, 'f1': 0.77608, 'accuracy-SBM': 0.77606, 'auc': 0.96195}
2025-08-16 20:09:39,896 - INFO - > Epoch 41: took 91.6s (avg 101.7s) | Best so far: epoch 40	train_loss: 0.6094 train_accuracy-SBM: 0.7795	val_loss: 0.6236 val_accuracy-SBM: 0.7782	test_loss: 0.6106 test_accuracy-SBM: 0.7801
2025-08-16 20:09:39,896 - INFO - === Epoch 42 ===
2025-08-16 20:10:56,365 - INFO - train: {'epoch': 42, 'time_epoch': 76.24163, 'eta': 4988.32741, 'eta_hours': 1.38565, 'loss': 0.60750456, 'lr': 0.00067015, 'params': 515510, 'time_iter': 0.12199, 'accuracy': 0.78004, 'f1': 0.78004, 'accuracy-SBM': 0.78004, 'auc': 0.96304}
2025-08-16 20:11:00,248 - INFO - val: {'epoch': 42, 'time_epoch': 3.83805, 'loss': 0.61692141, 'lr': 0, 'params': 515510, 'time_iter': 0.06092, 'accuracy': 0.77895, 'f1': 0.77881, 'accuracy-SBM': 0.77884, 'auc': 0.96219}
2025-08-16 20:11:09,951 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:11:09,990 - INFO - test: {'epoch': 42, 'time_epoch': 4.08361, 'loss': 0.6178886, 'lr': 0, 'params': 515510, 'time_iter': 0.06482, 'accuracy': 0.77945, 'f1': 0.77943, 'accuracy-SBM': 0.77942, 'auc': 0.96207}
2025-08-16 20:11:09,996 - INFO - > Epoch 42: took 90.1s (avg 101.4s) | Best so far: epoch 42	train_loss: 0.6075 train_accuracy-SBM: 0.7800	val_loss: 0.6169 val_accuracy-SBM: 0.7788	test_loss: 0.6179 test_accuracy-SBM: 0.7794
2025-08-16 20:11:09,996 - INFO - === Epoch 43 ===
2025-08-16 20:12:26,093 - INFO - train: {'epoch': 43, 'time_epoch': 75.86421, 'eta': 4885.98523, 'eta_hours': 1.35722, 'loss': 0.60035645, 'lr': 0.00065451, 'params': 515510, 'time_iter': 0.12138, 'accuracy': 0.78236, 'f1': 0.78236, 'accuracy-SBM': 0.78236, 'auc': 0.96391}
2025-08-16 20:12:30,004 - INFO - val: {'epoch': 43, 'time_epoch': 3.85389, 'loss': 0.62379484, 'lr': 0, 'params': 515510, 'time_iter': 0.06117, 'accuracy': 0.77802, 'f1': 0.77796, 'accuracy-SBM': 0.77797, 'auc': 0.96133}
2025-08-16 20:12:39,273 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:12:39,310 - INFO - test: {'epoch': 43, 'time_epoch': 3.89128, 'loss': 0.61650933, 'lr': 0, 'params': 515510, 'time_iter': 0.06177, 'accuracy': 0.77818, 'f1': 0.77821, 'accuracy-SBM': 0.77825, 'auc': 0.96219}
2025-08-16 20:12:39,315 - INFO - > Epoch 43: took 89.3s (avg 101.2s) | Best so far: epoch 42	train_loss: 0.6075 train_accuracy-SBM: 0.7800	val_loss: 0.6169 val_accuracy-SBM: 0.7788	test_loss: 0.6179 test_accuracy-SBM: 0.7794
2025-08-16 20:12:39,315 - INFO - === Epoch 44 ===
2025-08-16 20:13:55,963 - INFO - train: {'epoch': 44, 'time_epoch': 76.41656, 'eta': 4785.49494, 'eta_hours': 1.3293, 'loss': 0.60028051, 'lr': 0.0006387, 'params': 515510, 'time_iter': 0.12227, 'accuracy': 0.78267, 'f1': 0.78267, 'accuracy-SBM': 0.78267, 'auc': 0.96393}
2025-08-16 20:13:59,908 - INFO - val: {'epoch': 44, 'time_epoch': 3.89543, 'loss': 0.62516917, 'lr': 0, 'params': 515510, 'time_iter': 0.06183, 'accuracy': 0.77718, 'f1': 0.77715, 'accuracy-SBM': 0.7772, 'auc': 0.96098}
2025-08-16 20:14:09,777 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:14:09,814 - INFO - test: {'epoch': 44, 'time_epoch': 4.18713, 'loss': 0.61384647, 'lr': 0, 'params': 515510, 'time_iter': 0.06646, 'accuracy': 0.7806, 'f1': 0.78053, 'accuracy-SBM': 0.78049, 'auc': 0.96254}
2025-08-16 20:14:09,818 - INFO - > Epoch 44: took 90.5s (avg 100.9s) | Best so far: epoch 42	train_loss: 0.6075 train_accuracy-SBM: 0.7800	val_loss: 0.6169 val_accuracy-SBM: 0.7788	test_loss: 0.6179 test_accuracy-SBM: 0.7794
2025-08-16 20:14:09,819 - INFO - === Epoch 45 ===
2025-08-16 20:15:27,603 - INFO - train: {'epoch': 45, 'time_epoch': 77.5511, 'eta': 4687.38319, 'eta_hours': 1.30205, 'loss': 0.59703041, 'lr': 0.00062274, 'params': 515510, 'time_iter': 0.12408, 'accuracy': 0.78354, 'f1': 0.78354, 'accuracy-SBM': 0.78354, 'auc': 0.96431}
2025-08-16 20:15:31,522 - INFO - val: {'epoch': 45, 'time_epoch': 3.87652, 'loss': 0.61831285, 'lr': 0, 'params': 515510, 'time_iter': 0.06153, 'accuracy': 0.78116, 'f1': 0.78114, 'accuracy-SBM': 0.78109, 'auc': 0.96191}
2025-08-16 20:15:39,360 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:15:39,397 - INFO - test: {'epoch': 45, 'time_epoch': 4.13474, 'loss': 0.61189267, 'lr': 0, 'params': 515510, 'time_iter': 0.06563, 'accuracy': 0.78183, 'f1': 0.78177, 'accuracy-SBM': 0.7818, 'auc': 0.96265}
2025-08-16 20:15:39,399 - INFO - > Epoch 45: took 89.6s (avg 100.7s) | Best so far: epoch 45	train_loss: 0.5970 train_accuracy-SBM: 0.7835	val_loss: 0.6183 val_accuracy-SBM: 0.7811	test_loss: 0.6119 test_accuracy-SBM: 0.7818
2025-08-16 20:15:39,399 - INFO - === Epoch 46 ===
2025-08-16 20:16:56,333 - INFO - train: {'epoch': 46, 'time_epoch': 76.70138, 'eta': 4589.18817, 'eta_hours': 1.27477, 'loss': 0.59490903, 'lr': 0.00060665, 'params': 515510, 'time_iter': 0.12272, 'accuracy': 0.78454, 'f1': 0.78453, 'accuracy-SBM': 0.78454, 'auc': 0.96458}
2025-08-16 20:17:00,255 - INFO - val: {'epoch': 46, 'time_epoch': 3.87381, 'loss': 0.62401389, 'lr': 0, 'params': 515510, 'time_iter': 0.06149, 'accuracy': 0.78078, 'f1': 0.78055, 'accuracy-SBM': 0.78054, 'auc': 0.96136}
2025-08-16 20:17:08,172 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:17:08,209 - INFO - test: {'epoch': 46, 'time_epoch': 4.09933, 'loss': 0.61761037, 'lr': 0, 'params': 515510, 'time_iter': 0.06507, 'accuracy': 0.7797, 'f1': 0.77969, 'accuracy-SBM': 0.77966, 'auc': 0.96218}
2025-08-16 20:17:08,214 - INFO - > Epoch 46: took 88.8s (avg 100.4s) | Best so far: epoch 45	train_loss: 0.5970 train_accuracy-SBM: 0.7835	val_loss: 0.6183 val_accuracy-SBM: 0.7811	test_loss: 0.6119 test_accuracy-SBM: 0.7818
2025-08-16 20:17:08,214 - INFO - === Epoch 47 ===
2025-08-16 20:18:25,294 - INFO - train: {'epoch': 47, 'time_epoch': 76.84288, 'eta': 4492.042, 'eta_hours': 1.24779, 'loss': 0.59210757, 'lr': 0.00059044, 'params': 515510, 'time_iter': 0.12295, 'accuracy': 0.78549, 'f1': 0.78549, 'accuracy-SBM': 0.78549, 'auc': 0.96489}
2025-08-16 20:18:29,220 - INFO - val: {'epoch': 47, 'time_epoch': 3.87777, 'loss': 0.61781172, 'lr': 0, 'params': 515510, 'time_iter': 0.06155, 'accuracy': 0.78032, 'f1': 0.78022, 'accuracy-SBM': 0.78019, 'auc': 0.96196}
2025-08-16 20:18:38,428 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:18:38,465 - INFO - test: {'epoch': 47, 'time_epoch': 4.12452, 'loss': 0.609532, 'lr': 0, 'params': 515510, 'time_iter': 0.06547, 'accuracy': 0.78116, 'f1': 0.78107, 'accuracy-SBM': 0.7811, 'auc': 0.9629}
2025-08-16 20:18:38,470 - INFO - > Epoch 47: took 90.3s (avg 100.2s) | Best so far: epoch 45	train_loss: 0.5970 train_accuracy-SBM: 0.7835	val_loss: 0.6183 val_accuracy-SBM: 0.7811	test_loss: 0.6119 test_accuracy-SBM: 0.7818
2025-08-16 20:18:38,470 - INFO - === Epoch 48 ===
2025-08-16 20:19:56,956 - INFO - train: {'epoch': 48, 'time_epoch': 78.13963, 'eta': 4397.07422, 'eta_hours': 1.22141, 'loss': 0.59052575, 'lr': 0.00057413, 'params': 515510, 'time_iter': 0.12502, 'accuracy': 0.78649, 'f1': 0.78649, 'accuracy-SBM': 0.78649, 'auc': 0.96508}
2025-08-16 20:20:00,966 - INFO - val: {'epoch': 48, 'time_epoch': 3.95959, 'loss': 0.61430237, 'lr': 0, 'params': 515510, 'time_iter': 0.06285, 'accuracy': 0.78072, 'f1': 0.78075, 'accuracy-SBM': 0.78061, 'auc': 0.96221}
2025-08-16 20:20:12,004 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:20:12,041 - INFO - test: {'epoch': 48, 'time_epoch': 3.98371, 'loss': 0.61144212, 'lr': 0, 'params': 515510, 'time_iter': 0.06323, 'accuracy': 0.7803, 'f1': 0.78029, 'accuracy-SBM': 0.78041, 'auc': 0.96268}
2025-08-16 20:20:12,044 - INFO - > Epoch 48: took 93.6s (avg 100.1s) | Best so far: epoch 45	train_loss: 0.5970 train_accuracy-SBM: 0.7835	val_loss: 0.6183 val_accuracy-SBM: 0.7811	test_loss: 0.6119 test_accuracy-SBM: 0.7818
2025-08-16 20:20:12,044 - INFO - === Epoch 49 ===
2025-08-16 20:21:29,247 - INFO - train: {'epoch': 49, 'time_epoch': 76.96879, 'eta': 4301.60872, 'eta_hours': 1.19489, 'loss': 0.58608791, 'lr': 0.00055774, 'params': 515510, 'time_iter': 0.12315, 'accuracy': 0.78786, 'f1': 0.78786, 'accuracy-SBM': 0.78786, 'auc': 0.96559}
2025-08-16 20:21:33,167 - INFO - val: {'epoch': 49, 'time_epoch': 3.8717, 'loss': 0.62283442, 'lr': 0, 'params': 515510, 'time_iter': 0.06146, 'accuracy': 0.77871, 'f1': 0.77843, 'accuracy-SBM': 0.77839, 'auc': 0.96149}
2025-08-16 20:21:42,126 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:21:42,162 - INFO - test: {'epoch': 49, 'time_epoch': 4.12316, 'loss': 0.62362236, 'lr': 0, 'params': 515510, 'time_iter': 0.06545, 'accuracy': 0.77647, 'f1': 0.77638, 'accuracy-SBM': 0.77632, 'auc': 0.96139}
2025-08-16 20:21:42,167 - INFO - > Epoch 49: took 90.1s (avg 99.9s) | Best so far: epoch 45	train_loss: 0.5970 train_accuracy-SBM: 0.7835	val_loss: 0.6183 val_accuracy-SBM: 0.7811	test_loss: 0.6119 test_accuracy-SBM: 0.7818
2025-08-16 20:21:42,167 - INFO - === Epoch 50 ===
2025-08-16 20:23:00,527 - INFO - train: {'epoch': 50, 'time_epoch': 78.12709, 'eta': 4207.98147, 'eta_hours': 1.16888, 'loss': 0.5830655, 'lr': 0.00054129, 'params': 515510, 'time_iter': 0.125, 'accuracy': 0.78821, 'f1': 0.78821, 'accuracy-SBM': 0.78821, 'auc': 0.96599}
2025-08-16 20:23:04,509 - INFO - val: {'epoch': 50, 'time_epoch': 3.93343, 'loss': 0.61929168, 'lr': 0, 'params': 515510, 'time_iter': 0.06244, 'accuracy': 0.78128, 'f1': 0.78118, 'accuracy-SBM': 0.7812, 'auc': 0.96207}
2025-08-16 20:23:14,209 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:23:14,256 - INFO - test: {'epoch': 50, 'time_epoch': 4.15365, 'loss': 0.61575878, 'lr': 0, 'params': 515510, 'time_iter': 0.06593, 'accuracy': 0.78152, 'f1': 0.78157, 'accuracy-SBM': 0.78159, 'auc': 0.96254}
2025-08-16 20:23:14,260 - INFO - > Epoch 50: took 92.1s (avg 99.7s) | Best so far: epoch 50	train_loss: 0.5831 train_accuracy-SBM: 0.7882	val_loss: 0.6193 val_accuracy-SBM: 0.7812	test_loss: 0.6158 test_accuracy-SBM: 0.7816
2025-08-16 20:23:14,261 - INFO - === Epoch 51 ===
2025-08-16 20:24:32,829 - INFO - train: {'epoch': 51, 'time_epoch': 78.32771, 'eta': 4115.13556, 'eta_hours': 1.14309, 'loss': 0.58046919, 'lr': 0.00052479, 'params': 515510, 'time_iter': 0.12532, 'accuracy': 0.79018, 'f1': 0.79018, 'accuracy-SBM': 0.79018, 'auc': 0.96626}
2025-08-16 20:24:36,915 - INFO - val: {'epoch': 51, 'time_epoch': 4.04043, 'loss': 0.61433561, 'lr': 0, 'params': 515510, 'time_iter': 0.06413, 'accuracy': 0.78248, 'f1': 0.78247, 'accuracy-SBM': 0.78241, 'auc': 0.96238}
2025-08-16 20:24:45,125 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:24:45,163 - INFO - test: {'epoch': 51, 'time_epoch': 4.29364, 'loss': 0.60585924, 'lr': 0, 'params': 515510, 'time_iter': 0.06815, 'accuracy': 0.7818, 'f1': 0.78182, 'accuracy-SBM': 0.78187, 'auc': 0.96347}
2025-08-16 20:24:45,167 - INFO - > Epoch 51: took 90.9s (avg 99.6s) | Best so far: epoch 51	train_loss: 0.5805 train_accuracy-SBM: 0.7902	val_loss: 0.6143 val_accuracy-SBM: 0.7824	test_loss: 0.6059 test_accuracy-SBM: 0.7819
2025-08-16 20:24:45,167 - INFO - === Epoch 52 ===
2025-08-16 20:26:04,193 - INFO - train: {'epoch': 52, 'time_epoch': 78.78335, 'eta': 4023.24157, 'eta_hours': 1.11757, 'loss': 0.57901246, 'lr': 0.00050827, 'params': 515510, 'time_iter': 0.12605, 'accuracy': 0.78986, 'f1': 0.78986, 'accuracy-SBM': 0.78986, 'auc': 0.96645}
2025-08-16 20:26:08,198 - INFO - val: {'epoch': 52, 'time_epoch': 3.95507, 'loss': 0.61520276, 'lr': 0, 'params': 515510, 'time_iter': 0.06278, 'accuracy': 0.78067, 'f1': 0.78062, 'accuracy-SBM': 0.78058, 'auc': 0.9624}
2025-08-16 20:26:16,988 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:26:17,025 - INFO - test: {'epoch': 52, 'time_epoch': 4.1883, 'loss': 0.60702278, 'lr': 0, 'params': 515510, 'time_iter': 0.06648, 'accuracy': 0.78236, 'f1': 0.78227, 'accuracy-SBM': 0.78228, 'auc': 0.96335}
2025-08-16 20:26:17,030 - INFO - > Epoch 52: took 91.9s (avg 99.4s) | Best so far: epoch 51	train_loss: 0.5805 train_accuracy-SBM: 0.7902	val_loss: 0.6143 val_accuracy-SBM: 0.7824	test_loss: 0.6059 test_accuracy-SBM: 0.7819
2025-08-16 20:26:17,031 - INFO - === Epoch 53 ===
2025-08-16 20:27:34,890 - INFO - train: {'epoch': 53, 'time_epoch': 77.62629, 'eta': 3930.84751, 'eta_hours': 1.0919, 'loss': 0.57478556, 'lr': 0.00049173, 'params': 515510, 'time_iter': 0.1242, 'accuracy': 0.79144, 'f1': 0.79144, 'accuracy-SBM': 0.79144, 'auc': 0.96693}
2025-08-16 20:27:38,786 - INFO - val: {'epoch': 53, 'time_epoch': 3.84666, 'loss': 0.62019626, 'lr': 0, 'params': 515510, 'time_iter': 0.06106, 'accuracy': 0.78234, 'f1': 0.78228, 'accuracy-SBM': 0.78227, 'auc': 0.96212}
2025-08-16 20:27:47,781 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:27:47,817 - INFO - test: {'epoch': 53, 'time_epoch': 4.09221, 'loss': 0.60641702, 'lr': 0, 'params': 515510, 'time_iter': 0.06496, 'accuracy': 0.78362, 'f1': 0.78359, 'accuracy-SBM': 0.78357, 'auc': 0.96358}
2025-08-16 20:27:47,824 - INFO - > Epoch 53: took 90.8s (avg 99.2s) | Best so far: epoch 51	train_loss: 0.5805 train_accuracy-SBM: 0.7902	val_loss: 0.6143 val_accuracy-SBM: 0.7824	test_loss: 0.6059 test_accuracy-SBM: 0.7819
2025-08-16 20:27:47,824 - INFO - === Epoch 54 ===
2025-08-16 20:29:04,638 - INFO - train: {'epoch': 54, 'time_epoch': 76.58112, 'eta': 3838.13533, 'eta_hours': 1.06615, 'loss': 0.57278193, 'lr': 0.00047521, 'params': 515510, 'time_iter': 0.12253, 'accuracy': 0.79189, 'f1': 0.79189, 'accuracy-SBM': 0.79189, 'auc': 0.96717}
2025-08-16 20:29:08,548 - INFO - val: {'epoch': 54, 'time_epoch': 3.86144, 'loss': 0.60688249, 'lr': 0, 'params': 515510, 'time_iter': 0.06129, 'accuracy': 0.78494, 'f1': 0.78492, 'accuracy-SBM': 0.78482, 'auc': 0.96322}
2025-08-16 20:29:17,302 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:29:17,339 - INFO - test: {'epoch': 54, 'time_epoch': 3.86444, 'loss': 0.60485545, 'lr': 0, 'params': 515510, 'time_iter': 0.06134, 'accuracy': 0.78373, 'f1': 0.78371, 'accuracy-SBM': 0.78379, 'auc': 0.96363}
2025-08-16 20:29:17,343 - INFO - > Epoch 54: took 89.5s (avg 99.1s) | Best so far: epoch 54	train_loss: 0.5728 train_accuracy-SBM: 0.7919	val_loss: 0.6069 val_accuracy-SBM: 0.7848	test_loss: 0.6049 test_accuracy-SBM: 0.7838
2025-08-16 20:29:17,344 - INFO - === Epoch 55 ===
2025-08-16 20:30:34,593 - INFO - train: {'epoch': 55, 'time_epoch': 77.01942, 'eta': 3746.34363, 'eta_hours': 1.04065, 'loss': 0.56916879, 'lr': 0.00045871, 'params': 515510, 'time_iter': 0.12323, 'accuracy': 0.79314, 'f1': 0.79314, 'accuracy-SBM': 0.79314, 'auc': 0.96759}
2025-08-16 20:30:38,645 - INFO - val: {'epoch': 55, 'time_epoch': 3.89977, 'loss': 0.62376039, 'lr': 0, 'params': 515510, 'time_iter': 0.0619, 'accuracy': 0.78072, 'f1': 0.78063, 'accuracy-SBM': 0.78046, 'auc': 0.96152}
2025-08-16 20:30:48,222 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:30:48,259 - INFO - test: {'epoch': 55, 'time_epoch': 3.95474, 'loss': 0.61158111, 'lr': 0, 'params': 515510, 'time_iter': 0.06277, 'accuracy': 0.78153, 'f1': 0.78155, 'accuracy-SBM': 0.7815, 'auc': 0.96286}
2025-08-16 20:30:48,268 - INFO - > Epoch 55: took 90.9s (avg 98.9s) | Best so far: epoch 54	train_loss: 0.5728 train_accuracy-SBM: 0.7919	val_loss: 0.6069 val_accuracy-SBM: 0.7848	test_loss: 0.6049 test_accuracy-SBM: 0.7838
2025-08-16 20:30:48,268 - INFO - === Epoch 56 ===
2025-08-16 20:32:07,806 - INFO - train: {'epoch': 56, 'time_epoch': 79.29194, 'eta': 3656.78461, 'eta_hours': 1.01577, 'loss': 0.56988642, 'lr': 0.00044226, 'params': 515510, 'time_iter': 0.12687, 'accuracy': 0.79362, 'f1': 0.79362, 'accuracy-SBM': 0.79362, 'auc': 0.9675}
2025-08-16 20:32:11,803 - INFO - val: {'epoch': 56, 'time_epoch': 3.94239, 'loss': 0.61133565, 'lr': 0, 'params': 515510, 'time_iter': 0.06258, 'accuracy': 0.7836, 'f1': 0.78346, 'accuracy-SBM': 0.78344, 'auc': 0.96251}
2025-08-16 20:32:24,670 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:32:24,710 - INFO - test: {'epoch': 56, 'time_epoch': 4.10904, 'loss': 0.60149687, 'lr': 0, 'params': 515510, 'time_iter': 0.06522, 'accuracy': 0.7835, 'f1': 0.78349, 'accuracy-SBM': 0.78343, 'auc': 0.96377}
2025-08-16 20:32:24,715 - INFO - > Epoch 56: took 96.4s (avg 98.9s) | Best so far: epoch 54	train_loss: 0.5728 train_accuracy-SBM: 0.7919	val_loss: 0.6069 val_accuracy-SBM: 0.7848	test_loss: 0.6049 test_accuracy-SBM: 0.7838
2025-08-16 20:32:24,715 - INFO - === Epoch 57 ===
2025-08-16 20:33:49,637 - INFO - train: {'epoch': 57, 'time_epoch': 84.66096, 'eta': 3571.46755, 'eta_hours': 0.99207, 'loss': 0.5660233, 'lr': 0.00042587, 'params': 515510, 'time_iter': 0.13546, 'accuracy': 0.79457, 'f1': 0.79456, 'accuracy-SBM': 0.79457, 'auc': 0.96792}
2025-08-16 20:33:54,042 - INFO - val: {'epoch': 57, 'time_epoch': 4.35344, 'loss': 0.621464, 'lr': 0, 'params': 515510, 'time_iter': 0.0691, 'accuracy': 0.78283, 'f1': 0.78265, 'accuracy-SBM': 0.78255, 'auc': 0.96197}
2025-08-16 20:34:02,299 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:34:02,342 - INFO - test: {'epoch': 57, 'time_epoch': 4.59047, 'loss': 0.60945963, 'lr': 0, 'params': 515510, 'time_iter': 0.07286, 'accuracy': 0.78215, 'f1': 0.7821, 'accuracy-SBM': 0.78208, 'auc': 0.96331}
2025-08-16 20:34:02,359 - INFO - > Epoch 57: took 97.6s (avg 98.9s) | Best so far: epoch 54	train_loss: 0.5728 train_accuracy-SBM: 0.7919	val_loss: 0.6069 val_accuracy-SBM: 0.7848	test_loss: 0.6049 test_accuracy-SBM: 0.7838
2025-08-16 20:34:02,359 - INFO - === Epoch 58 ===
2025-08-16 20:35:29,400 - INFO - train: {'epoch': 58, 'time_epoch': 86.76404, 'eta': 3487.63418, 'eta_hours': 0.96879, 'loss': 0.56398225, 'lr': 0.00040956, 'params': 515510, 'time_iter': 0.13882, 'accuracy': 0.79484, 'f1': 0.79484, 'accuracy-SBM': 0.79484, 'auc': 0.96816}
2025-08-16 20:35:33,807 - INFO - val: {'epoch': 58, 'time_epoch': 4.32924, 'loss': 0.61170217, 'lr': 0, 'params': 515510, 'time_iter': 0.06872, 'accuracy': 0.78363, 'f1': 0.78351, 'accuracy-SBM': 0.78355, 'auc': 0.96274}
2025-08-16 20:35:42,597 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:35:42,638 - INFO - test: {'epoch': 58, 'time_epoch': 4.62366, 'loss': 0.61540917, 'lr': 0, 'params': 515510, 'time_iter': 0.07339, 'accuracy': 0.78101, 'f1': 0.78108, 'accuracy-SBM': 0.78103, 'auc': 0.96235}
2025-08-16 20:35:42,642 - INFO - > Epoch 58: took 100.3s (avg 98.9s) | Best so far: epoch 54	train_loss: 0.5728 train_accuracy-SBM: 0.7919	val_loss: 0.6069 val_accuracy-SBM: 0.7848	test_loss: 0.6049 test_accuracy-SBM: 0.7838
2025-08-16 20:35:42,642 - INFO - === Epoch 59 ===
2025-08-16 20:37:09,230 - INFO - train: {'epoch': 59, 'time_epoch': 86.33489, 'eta': 3403.41703, 'eta_hours': 0.94539, 'loss': 0.56231827, 'lr': 0.00039335, 'params': 515510, 'time_iter': 0.13814, 'accuracy': 0.7955, 'f1': 0.7955, 'accuracy-SBM': 0.7955, 'auc': 0.96835}
2025-08-16 20:37:13,646 - INFO - val: {'epoch': 59, 'time_epoch': 4.36102, 'loss': 0.61236968, 'lr': 0, 'params': 515510, 'time_iter': 0.06922, 'accuracy': 0.78345, 'f1': 0.78342, 'accuracy-SBM': 0.78336, 'auc': 0.96282}
2025-08-16 20:37:22,549 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:37:22,598 - INFO - test: {'epoch': 59, 'time_epoch': 4.60937, 'loss': 0.60990877, 'lr': 0, 'params': 515510, 'time_iter': 0.07316, 'accuracy': 0.7829, 'f1': 0.78286, 'accuracy-SBM': 0.78293, 'auc': 0.96306}
2025-08-16 20:37:22,603 - INFO - > Epoch 59: took 100.0s (avg 98.9s) | Best so far: epoch 54	train_loss: 0.5728 train_accuracy-SBM: 0.7919	val_loss: 0.6069 val_accuracy-SBM: 0.7848	test_loss: 0.6049 test_accuracy-SBM: 0.7838
2025-08-16 20:37:22,603 - INFO - === Epoch 60 ===
2025-08-16 20:38:55,662 - INFO - train: {'epoch': 60, 'time_epoch': 92.65833, 'eta': 3323.17329, 'eta_hours': 0.9231, 'loss': 0.55894095, 'lr': 0.00037726, 'params': 515510, 'time_iter': 0.14825, 'accuracy': 0.79702, 'f1': 0.79702, 'accuracy-SBM': 0.79702, 'auc': 0.96874}
2025-08-16 20:39:00,198 - INFO - val: {'epoch': 60, 'time_epoch': 4.47804, 'loss': 0.61977894, 'lr': 0, 'params': 515510, 'time_iter': 0.07108, 'accuracy': 0.78387, 'f1': 0.78378, 'accuracy-SBM': 0.78372, 'auc': 0.96234}
2025-08-16 20:39:09,000 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:39:09,040 - INFO - test: {'epoch': 60, 'time_epoch': 4.768, 'loss': 0.6048068, 'lr': 0, 'params': 515510, 'time_iter': 0.07568, 'accuracy': 0.78465, 'f1': 0.7846, 'accuracy-SBM': 0.78462, 'auc': 0.96398}
2025-08-16 20:39:09,045 - INFO - > Epoch 60: took 106.4s (avg 99.0s) | Best so far: epoch 54	train_loss: 0.5728 train_accuracy-SBM: 0.7919	val_loss: 0.6069 val_accuracy-SBM: 0.7848	test_loss: 0.6049 test_accuracy-SBM: 0.7838
2025-08-16 20:39:09,045 - INFO - === Epoch 61 ===
2025-08-16 20:40:38,221 - INFO - train: {'epoch': 61, 'time_epoch': 88.66794, 'eta': 3240.08337, 'eta_hours': 0.90002, 'loss': 0.55736765, 'lr': 0.0003613, 'params': 515510, 'time_iter': 0.14187, 'accuracy': 0.79759, 'f1': 0.79758, 'accuracy-SBM': 0.79758, 'auc': 0.96892}
2025-08-16 20:40:42,664 - INFO - val: {'epoch': 61, 'time_epoch': 4.3864, 'loss': 0.61246518, 'lr': 0, 'params': 515510, 'time_iter': 0.06963, 'accuracy': 0.78273, 'f1': 0.78264, 'accuracy-SBM': 0.78263, 'auc': 0.96258}
2025-08-16 20:40:50,954 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:40:50,995 - INFO - test: {'epoch': 61, 'time_epoch': 4.62831, 'loss': 0.60231735, 'lr': 0, 'params': 515510, 'time_iter': 0.07347, 'accuracy': 0.7845, 'f1': 0.78443, 'accuracy-SBM': 0.78445, 'auc': 0.96376}
2025-08-16 20:40:50,997 - INFO - > Epoch 61: took 102.0s (avg 99.1s) | Best so far: epoch 54	train_loss: 0.5728 train_accuracy-SBM: 0.7919	val_loss: 0.6069 val_accuracy-SBM: 0.7848	test_loss: 0.6049 test_accuracy-SBM: 0.7838
2025-08-16 20:40:50,997 - INFO - === Epoch 62 ===
2025-08-16 20:42:18,247 - INFO - train: {'epoch': 62, 'time_epoch': 86.95805, 'eta': 3155.81214, 'eta_hours': 0.87661, 'loss': 0.55245957, 'lr': 0.00034549, 'params': 515510, 'time_iter': 0.13913, 'accuracy': 0.7995, 'f1': 0.7995, 'accuracy-SBM': 0.7995, 'auc': 0.96946}
2025-08-16 20:42:22,988 - INFO - val: {'epoch': 62, 'time_epoch': 4.66049, 'loss': 0.61465524, 'lr': 0, 'params': 515510, 'time_iter': 0.07398, 'accuracy': 0.78335, 'f1': 0.78318, 'accuracy-SBM': 0.78322, 'auc': 0.96272}
2025-08-16 20:42:33,876 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:42:33,917 - INFO - test: {'epoch': 62, 'time_epoch': 4.9271, 'loss': 0.61359135, 'lr': 0, 'params': 515510, 'time_iter': 0.07821, 'accuracy': 0.7817, 'f1': 0.78169, 'accuracy-SBM': 0.78165, 'auc': 0.96291}
2025-08-16 20:42:33,919 - INFO - > Epoch 62: took 102.9s (avg 99.1s) | Best so far: epoch 54	train_loss: 0.5728 train_accuracy-SBM: 0.7919	val_loss: 0.6069 val_accuracy-SBM: 0.7848	test_loss: 0.6049 test_accuracy-SBM: 0.7838
2025-08-16 20:42:33,919 - INFO - === Epoch 63 ===
2025-08-16 20:44:00,830 - INFO - train: {'epoch': 63, 'time_epoch': 86.64033, 'eta': 3071.27823, 'eta_hours': 0.85313, 'loss': 0.55165252, 'lr': 0.00032985, 'params': 515510, 'time_iter': 0.13862, 'accuracy': 0.79927, 'f1': 0.79927, 'accuracy-SBM': 0.79927, 'auc': 0.96955}
2025-08-16 20:44:05,251 - INFO - val: {'epoch': 63, 'time_epoch': 4.36236, 'loss': 0.61168688, 'lr': 0, 'params': 515510, 'time_iter': 0.06924, 'accuracy': 0.78622, 'f1': 0.78609, 'accuracy-SBM': 0.78603, 'auc': 0.96264}
2025-08-16 20:44:12,941 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:44:12,981 - INFO - test: {'epoch': 63, 'time_epoch': 4.44169, 'loss': 0.60463139, 'lr': 0, 'params': 515510, 'time_iter': 0.0705, 'accuracy': 0.78416, 'f1': 0.78415, 'accuracy-SBM': 0.78414, 'auc': 0.96353}
2025-08-16 20:44:12,986 - INFO - > Epoch 63: took 99.1s (avg 99.1s) | Best so far: epoch 63	train_loss: 0.5517 train_accuracy-SBM: 0.7993	val_loss: 0.6117 val_accuracy-SBM: 0.7860	test_loss: 0.6046 test_accuracy-SBM: 0.7841
2025-08-16 20:44:12,986 - INFO - === Epoch 64 ===
2025-08-16 20:45:40,279 - INFO - train: {'epoch': 64, 'time_epoch': 87.03418, 'eta': 2986.89158, 'eta_hours': 0.82969, 'loss': 0.5482253, 'lr': 0.0003144, 'params': 515510, 'time_iter': 0.13925, 'accuracy': 0.80048, 'f1': 0.80048, 'accuracy-SBM': 0.80048, 'auc': 0.96992}
2025-08-16 20:45:44,639 - INFO - val: {'epoch': 64, 'time_epoch': 4.31383, 'loss': 0.61632201, 'lr': 0, 'params': 515510, 'time_iter': 0.06847, 'accuracy': 0.78542, 'f1': 0.7853, 'accuracy-SBM': 0.78527, 'auc': 0.96244}
2025-08-16 20:45:52,645 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:45:52,687 - INFO - test: {'epoch': 64, 'time_epoch': 4.62073, 'loss': 0.60395454, 'lr': 0, 'params': 515510, 'time_iter': 0.07334, 'accuracy': 0.7857, 'f1': 0.78568, 'accuracy-SBM': 0.78567, 'auc': 0.96393}
2025-08-16 20:45:52,691 - INFO - > Epoch 64: took 99.7s (avg 99.1s) | Best so far: epoch 63	train_loss: 0.5517 train_accuracy-SBM: 0.7993	val_loss: 0.6117 val_accuracy-SBM: 0.7860	test_loss: 0.6046 test_accuracy-SBM: 0.7841
2025-08-16 20:45:52,691 - INFO - === Epoch 65 ===
2025-08-16 20:47:20,742 - INFO - train: {'epoch': 65, 'time_epoch': 87.79968, 'eta': 2902.81905, 'eta_hours': 0.80634, 'loss': 0.54722444, 'lr': 0.00029915, 'params': 515510, 'time_iter': 0.14048, 'accuracy': 0.80122, 'f1': 0.80122, 'accuracy-SBM': 0.80122, 'auc': 0.97003}
2025-08-16 20:47:25,171 - INFO - val: {'epoch': 65, 'time_epoch': 4.37561, 'loss': 0.61311321, 'lr': 0, 'params': 515510, 'time_iter': 0.06945, 'accuracy': 0.78549, 'f1': 0.78544, 'accuracy-SBM': 0.78535, 'auc': 0.96271}
2025-08-16 20:47:33,919 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:47:33,958 - INFO - test: {'epoch': 65, 'time_epoch': 4.60693, 'loss': 0.61161647, 'lr': 0, 'params': 515510, 'time_iter': 0.07313, 'accuracy': 0.7835, 'f1': 0.7835, 'accuracy-SBM': 0.78352, 'auc': 0.96294}
2025-08-16 20:47:33,961 - INFO - > Epoch 65: took 101.3s (avg 99.2s) | Best so far: epoch 63	train_loss: 0.5517 train_accuracy-SBM: 0.7993	val_loss: 0.6117 val_accuracy-SBM: 0.7860	test_loss: 0.6046 test_accuracy-SBM: 0.7841
2025-08-16 20:47:33,961 - INFO - === Epoch 66 ===
2025-08-16 20:49:01,126 - INFO - train: {'epoch': 66, 'time_epoch': 86.80272, 'eta': 2818.14423, 'eta_hours': 0.78282, 'loss': 0.54483533, 'lr': 0.00028412, 'params': 515510, 'time_iter': 0.13888, 'accuracy': 0.80161, 'f1': 0.80161, 'accuracy-SBM': 0.80161, 'auc': 0.97031}
2025-08-16 20:49:05,547 - INFO - val: {'epoch': 66, 'time_epoch': 4.36362, 'loss': 0.61348688, 'lr': 0, 'params': 515510, 'time_iter': 0.06926, 'accuracy': 0.7857, 'f1': 0.7856, 'accuracy-SBM': 0.78562, 'auc': 0.96282}
2025-08-16 20:49:14,210 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:49:14,250 - INFO - test: {'epoch': 66, 'time_epoch': 4.6228, 'loss': 0.61301905, 'lr': 0, 'params': 515510, 'time_iter': 0.07338, 'accuracy': 0.78349, 'f1': 0.78348, 'accuracy-SBM': 0.78347, 'auc': 0.96288}
2025-08-16 20:49:14,255 - INFO - > Epoch 66: took 100.3s (avg 99.2s) | Best so far: epoch 63	train_loss: 0.5517 train_accuracy-SBM: 0.7993	val_loss: 0.6117 val_accuracy-SBM: 0.7860	test_loss: 0.6046 test_accuracy-SBM: 0.7841
2025-08-16 20:49:14,255 - INFO - === Epoch 67 ===
2025-08-16 20:50:35,028 - INFO - train: {'epoch': 67, 'time_epoch': 80.41327, 'eta': 2730.40002, 'eta_hours': 0.75844, 'loss': 0.54214826, 'lr': 0.00026933, 'params': 515510, 'time_iter': 0.12866, 'accuracy': 0.80281, 'f1': 0.80281, 'accuracy-SBM': 0.80281, 'auc': 0.97059}
2025-08-16 20:50:39,062 - INFO - val: {'epoch': 67, 'time_epoch': 3.98065, 'loss': 0.61938201, 'lr': 0, 'params': 515510, 'time_iter': 0.06318, 'accuracy': 0.78272, 'f1': 0.78259, 'accuracy-SBM': 0.78255, 'auc': 0.9622}
2025-08-16 20:50:47,950 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:50:47,994 - INFO - test: {'epoch': 67, 'time_epoch': 4.29503, 'loss': 0.60878741, 'lr': 0, 'params': 515510, 'time_iter': 0.06818, 'accuracy': 0.7838, 'f1': 0.78377, 'accuracy-SBM': 0.78379, 'auc': 0.96329}
2025-08-16 20:50:48,001 - INFO - > Epoch 67: took 93.7s (avg 99.1s) | Best so far: epoch 63	train_loss: 0.5517 train_accuracy-SBM: 0.7993	val_loss: 0.6117 val_accuracy-SBM: 0.7860	test_loss: 0.6046 test_accuracy-SBM: 0.7841
2025-08-16 20:50:48,002 - INFO - === Epoch 68 ===
2025-08-16 20:52:05,376 - INFO - train: {'epoch': 68, 'time_epoch': 77.12635, 'eta': 2641.39156, 'eta_hours': 0.73372, 'loss': 0.53915981, 'lr': 0.00025479, 'params': 515510, 'time_iter': 0.1234, 'accuracy': 0.80379, 'f1': 0.80379, 'accuracy-SBM': 0.80379, 'auc': 0.97091}
2025-08-16 20:52:09,410 - INFO - val: {'epoch': 68, 'time_epoch': 3.97854, 'loss': 0.61620817, 'lr': 0, 'params': 515510, 'time_iter': 0.06315, 'accuracy': 0.78542, 'f1': 0.7853, 'accuracy-SBM': 0.78528, 'auc': 0.96237}
2025-08-16 20:52:17,701 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:52:17,742 - INFO - test: {'epoch': 68, 'time_epoch': 4.0796, 'loss': 0.60565705, 'lr': 0, 'params': 515510, 'time_iter': 0.06476, 'accuracy': 0.78352, 'f1': 0.78347, 'accuracy-SBM': 0.78348, 'auc': 0.96363}
2025-08-16 20:52:17,748 - INFO - > Epoch 68: took 89.7s (avg 99.0s) | Best so far: epoch 63	train_loss: 0.5517 train_accuracy-SBM: 0.7993	val_loss: 0.6117 val_accuracy-SBM: 0.7860	test_loss: 0.6046 test_accuracy-SBM: 0.7841
2025-08-16 20:52:17,748 - INFO - === Epoch 69 ===
2025-08-16 20:53:35,937 - INFO - train: {'epoch': 69, 'time_epoch': 77.96382, 'eta': 2553.08152, 'eta_hours': 0.70919, 'loss': 0.53773062, 'lr': 0.00024052, 'params': 515510, 'time_iter': 0.12474, 'accuracy': 0.80451, 'f1': 0.80451, 'accuracy-SBM': 0.80451, 'auc': 0.97107}
2025-08-16 20:53:39,844 - INFO - val: {'epoch': 69, 'time_epoch': 3.85824, 'loss': 0.61228426, 'lr': 0, 'params': 515510, 'time_iter': 0.06124, 'accuracy': 0.78597, 'f1': 0.78582, 'accuracy-SBM': 0.78582, 'auc': 0.96275}
2025-08-16 20:53:49,096 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:53:49,133 - INFO - test: {'epoch': 69, 'time_epoch': 4.12726, 'loss': 0.60621206, 'lr': 0, 'params': 515510, 'time_iter': 0.06551, 'accuracy': 0.78465, 'f1': 0.78458, 'accuracy-SBM': 0.7846, 'auc': 0.96348}
2025-08-16 20:53:49,137 - INFO - > Epoch 69: took 91.4s (avg 98.9s) | Best so far: epoch 63	train_loss: 0.5517 train_accuracy-SBM: 0.7993	val_loss: 0.6117 val_accuracy-SBM: 0.7860	test_loss: 0.6046 test_accuracy-SBM: 0.7841
2025-08-16 20:53:49,137 - INFO - === Epoch 70 ===
2025-08-16 20:55:09,645 - INFO - train: {'epoch': 70, 'time_epoch': 80.27822, 'eta': 2466.00823, 'eta_hours': 0.685, 'loss': 0.53626483, 'lr': 0.00022653, 'params': 515510, 'time_iter': 0.12845, 'accuracy': 0.80499, 'f1': 0.80499, 'accuracy-SBM': 0.80499, 'auc': 0.97121}
2025-08-16 20:55:13,733 - INFO - val: {'epoch': 70, 'time_epoch': 4.03862, 'loss': 0.6192092, 'lr': 0, 'params': 515510, 'time_iter': 0.06411, 'accuracy': 0.7849, 'f1': 0.78487, 'accuracy-SBM': 0.78486, 'auc': 0.96218}
2025-08-16 20:55:19,141 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:55:19,178 - INFO - test: {'epoch': 70, 'time_epoch': 4.12198, 'loss': 0.61138331, 'lr': 0, 'params': 515510, 'time_iter': 0.06543, 'accuracy': 0.78432, 'f1': 0.78432, 'accuracy-SBM': 0.78437, 'auc': 0.96311}
2025-08-16 20:55:19,180 - INFO - > Epoch 70: took 90.0s (avg 98.7s) | Best so far: epoch 63	train_loss: 0.5517 train_accuracy-SBM: 0.7993	val_loss: 0.6117 val_accuracy-SBM: 0.7860	test_loss: 0.6046 test_accuracy-SBM: 0.7841
2025-08-16 20:55:19,181 - INFO - === Epoch 71 ===
2025-08-16 20:56:38,169 - INFO - train: {'epoch': 71, 'time_epoch': 78.75879, 'eta': 2378.53281, 'eta_hours': 0.6607, 'loss': 0.53454603, 'lr': 0.00021284, 'params': 515510, 'time_iter': 0.12601, 'accuracy': 0.8055, 'f1': 0.8055, 'accuracy-SBM': 0.8055, 'auc': 0.97141}
2025-08-16 20:56:42,107 - INFO - val: {'epoch': 71, 'time_epoch': 3.88958, 'loss': 0.61494435, 'lr': 0, 'params': 515510, 'time_iter': 0.06174, 'accuracy': 0.78669, 'f1': 0.7866, 'accuracy-SBM': 0.78658, 'auc': 0.96261}
2025-08-16 20:56:50,423 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:56:50,461 - INFO - test: {'epoch': 71, 'time_epoch': 4.13903, 'loss': 0.60969763, 'lr': 0, 'params': 515510, 'time_iter': 0.0657, 'accuracy': 0.78441, 'f1': 0.78436, 'accuracy-SBM': 0.78437, 'auc': 0.96327}
2025-08-16 20:56:50,466 - INFO - > Epoch 71: took 91.3s (avg 98.6s) | Best so far: epoch 71	train_loss: 0.5345 train_accuracy-SBM: 0.8055	val_loss: 0.6149 val_accuracy-SBM: 0.7866	test_loss: 0.6097 test_accuracy-SBM: 0.7844
2025-08-16 20:56:50,466 - INFO - === Epoch 72 ===
2025-08-16 20:58:13,122 - INFO - train: {'epoch': 72, 'time_epoch': 82.42441, 'eta': 2292.65197, 'eta_hours': 0.63685, 'loss': 0.53122042, 'lr': 0.00019946, 'params': 515510, 'time_iter': 0.13188, 'accuracy': 0.80666, 'f1': 0.80666, 'accuracy-SBM': 0.80666, 'auc': 0.97176}
2025-08-16 20:58:17,099 - INFO - val: {'epoch': 72, 'time_epoch': 3.92419, 'loss': 0.61445049, 'lr': 0, 'params': 515510, 'time_iter': 0.06229, 'accuracy': 0.78739, 'f1': 0.78727, 'accuracy-SBM': 0.78724, 'auc': 0.96253}
2025-08-16 20:58:23,286 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 20:58:23,341 - INFO - test: {'epoch': 72, 'time_epoch': 4.74799, 'loss': 0.60884416, 'lr': 0, 'params': 515510, 'time_iter': 0.07536, 'accuracy': 0.78435, 'f1': 0.78429, 'accuracy-SBM': 0.7843, 'auc': 0.96322}
2025-08-16 20:58:23,353 - INFO - > Epoch 72: took 92.9s (avg 98.6s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 20:58:23,353 - INFO - === Epoch 73 ===
2025-08-16 20:59:49,646 - INFO - train: {'epoch': 73, 'time_epoch': 86.01808, 'eta': 2208.1272, 'eta_hours': 0.61337, 'loss': 0.53024756, 'lr': 0.00018641, 'params': 515510, 'time_iter': 0.13763, 'accuracy': 0.80695, 'f1': 0.80695, 'accuracy-SBM': 0.80695, 'auc': 0.97187}
2025-08-16 20:59:54,045 - INFO - val: {'epoch': 73, 'time_epoch': 4.34867, 'loss': 0.61669737, 'lr': 0, 'params': 515510, 'time_iter': 0.06903, 'accuracy': 0.78425, 'f1': 0.78419, 'accuracy-SBM': 0.78423, 'auc': 0.96242}
2025-08-16 21:00:02,859 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:00:02,902 - INFO - test: {'epoch': 73, 'time_epoch': 4.65694, 'loss': 0.61524073, 'lr': 0, 'params': 515510, 'time_iter': 0.07392, 'accuracy': 0.78332, 'f1': 0.7833, 'accuracy-SBM': 0.7833, 'auc': 0.96258}
2025-08-16 21:00:02,904 - INFO - > Epoch 73: took 99.6s (avg 98.6s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:00:02,904 - INFO - === Epoch 74 ===
2025-08-16 21:01:28,784 - INFO - train: {'epoch': 74, 'time_epoch': 85.61221, 'eta': 2123.42731, 'eta_hours': 0.58984, 'loss': 0.52703288, 'lr': 0.00017371, 'params': 515510, 'time_iter': 0.13698, 'accuracy': 0.80859, 'f1': 0.80859, 'accuracy-SBM': 0.80859, 'auc': 0.97219}
2025-08-16 21:01:32,798 - INFO - val: {'epoch': 74, 'time_epoch': 3.97088, 'loss': 0.62149347, 'lr': 0, 'params': 515510, 'time_iter': 0.06303, 'accuracy': 0.78503, 'f1': 0.78491, 'accuracy-SBM': 0.78481, 'auc': 0.96204}
2025-08-16 21:01:38,079 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:01:38,119 - INFO - test: {'epoch': 74, 'time_epoch': 4.0482, 'loss': 0.61653805, 'lr': 0, 'params': 515510, 'time_iter': 0.06426, 'accuracy': 0.78322, 'f1': 0.78319, 'accuracy-SBM': 0.78322, 'auc': 0.96255}
2025-08-16 21:01:38,121 - INFO - > Epoch 74: took 95.2s (avg 98.5s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:01:38,121 - INFO - === Epoch 75 ===
2025-08-16 21:03:00,551 - INFO - train: {'epoch': 75, 'time_epoch': 82.19584, 'eta': 2037.62456, 'eta_hours': 0.56601, 'loss': 0.52668175, 'lr': 0.00016136, 'params': 515510, 'time_iter': 0.13151, 'accuracy': 0.80846, 'f1': 0.80846, 'accuracy-SBM': 0.80846, 'auc': 0.97225}
2025-08-16 21:03:04,521 - INFO - val: {'epoch': 75, 'time_epoch': 3.9267, 'loss': 0.61978781, 'lr': 0, 'params': 515510, 'time_iter': 0.06233, 'accuracy': 0.78487, 'f1': 0.78479, 'accuracy-SBM': 0.78477, 'auc': 0.96235}
2025-08-16 21:03:09,719 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:03:09,755 - INFO - test: {'epoch': 75, 'time_epoch': 3.92218, 'loss': 0.62099751, 'lr': 0, 'params': 515510, 'time_iter': 0.06226, 'accuracy': 0.78373, 'f1': 0.78368, 'accuracy-SBM': 0.7837, 'auc': 0.96221}
2025-08-16 21:03:09,757 - INFO - > Epoch 75: took 91.6s (avg 98.4s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:03:09,757 - INFO - === Epoch 76 ===
2025-08-16 21:04:32,386 - INFO - train: {'epoch': 76, 'time_epoch': 82.39539, 'eta': 1951.9751, 'eta_hours': 0.54222, 'loss': 0.52380534, 'lr': 0.00014938, 'params': 515510, 'time_iter': 0.13183, 'accuracy': 0.80968, 'f1': 0.80968, 'accuracy-SBM': 0.80968, 'auc': 0.97255}
2025-08-16 21:04:36,398 - INFO - val: {'epoch': 76, 'time_epoch': 3.96848, 'loss': 0.62076623, 'lr': 0, 'params': 515510, 'time_iter': 0.06299, 'accuracy': 0.78549, 'f1': 0.7854, 'accuracy-SBM': 0.78534, 'auc': 0.96224}
2025-08-16 21:04:41,943 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:04:41,983 - INFO - test: {'epoch': 76, 'time_epoch': 4.29058, 'loss': 0.61701709, 'lr': 0, 'params': 515510, 'time_iter': 0.0681, 'accuracy': 0.78425, 'f1': 0.78421, 'accuracy-SBM': 0.78424, 'auc': 0.96266}
2025-08-16 21:04:41,985 - INFO - > Epoch 76: took 92.2s (avg 98.4s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:04:41,985 - INFO - === Epoch 77 ===
2025-08-16 21:06:01,806 - INFO - train: {'epoch': 77, 'time_epoch': 79.58347, 'eta': 1865.61597, 'eta_hours': 0.51823, 'loss': 0.52172254, 'lr': 0.00013779, 'params': 515510, 'time_iter': 0.12733, 'accuracy': 0.81023, 'f1': 0.81023, 'accuracy-SBM': 0.81023, 'auc': 0.97277}
2025-08-16 21:06:05,835 - INFO - val: {'epoch': 77, 'time_epoch': 3.98544, 'loss': 0.62259368, 'lr': 0, 'params': 515510, 'time_iter': 0.06326, 'accuracy': 0.78419, 'f1': 0.78414, 'accuracy-SBM': 0.78416, 'auc': 0.96188}
2025-08-16 21:06:11,477 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:06:11,513 - INFO - test: {'epoch': 77, 'time_epoch': 4.30544, 'loss': 0.61368574, 'lr': 0, 'params': 515510, 'time_iter': 0.06834, 'accuracy': 0.78482, 'f1': 0.78482, 'accuracy-SBM': 0.78485, 'auc': 0.96292}
2025-08-16 21:06:11,515 - INFO - > Epoch 77: took 89.5s (avg 98.2s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:06:11,516 - INFO - === Epoch 78 ===
2025-08-16 21:07:31,875 - INFO - train: {'epoch': 78, 'time_epoch': 80.12429, 'eta': 1779.57214, 'eta_hours': 0.49433, 'loss': 0.52261727, 'lr': 0.00012659, 'params': 515510, 'time_iter': 0.1282, 'accuracy': 0.81001, 'f1': 0.81001, 'accuracy-SBM': 0.81001, 'auc': 0.97268}
2025-08-16 21:07:35,844 - INFO - val: {'epoch': 78, 'time_epoch': 3.92557, 'loss': 0.61840728, 'lr': 0, 'params': 515510, 'time_iter': 0.06231, 'accuracy': 0.78582, 'f1': 0.78569, 'accuracy-SBM': 0.78568, 'auc': 0.9624}
2025-08-16 21:07:41,816 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:07:41,852 - INFO - test: {'epoch': 78, 'time_epoch': 4.16294, 'loss': 0.61335394, 'lr': 0, 'params': 515510, 'time_iter': 0.06608, 'accuracy': 0.78584, 'f1': 0.78581, 'accuracy-SBM': 0.78581, 'auc': 0.96292}
2025-08-16 21:07:41,854 - INFO - > Epoch 78: took 90.3s (avg 98.1s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:07:41,854 - INFO - === Epoch 79 ===
2025-08-16 21:09:02,574 - INFO - train: {'epoch': 79, 'time_epoch': 80.47948, 'eta': 1693.7651, 'eta_hours': 0.47049, 'loss': 0.52126146, 'lr': 0.0001158, 'params': 515510, 'time_iter': 0.12877, 'accuracy': 0.81038, 'f1': 0.81038, 'accuracy-SBM': 0.81038, 'auc': 0.97282}
2025-08-16 21:09:06,674 - INFO - val: {'epoch': 79, 'time_epoch': 4.04958, 'loss': 0.61929804, 'lr': 0, 'params': 515510, 'time_iter': 0.06428, 'accuracy': 0.7865, 'f1': 0.78636, 'accuracy-SBM': 0.78634, 'auc': 0.96224}
2025-08-16 21:09:13,102 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:09:13,148 - INFO - test: {'epoch': 79, 'time_epoch': 4.26206, 'loss': 0.61169595, 'lr': 0, 'params': 515510, 'time_iter': 0.06765, 'accuracy': 0.78703, 'f1': 0.78697, 'accuracy-SBM': 0.78696, 'auc': 0.96311}
2025-08-16 21:09:13,150 - INFO - > Epoch 79: took 91.3s (avg 98.1s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:09:13,150 - INFO - === Epoch 80 ===
2025-08-16 21:10:33,512 - INFO - train: {'epoch': 80, 'time_epoch': 80.02959, 'eta': 1607.98407, 'eta_hours': 0.44666, 'loss': 0.51842903, 'lr': 0.00010543, 'params': 515510, 'time_iter': 0.12805, 'accuracy': 0.81134, 'f1': 0.81134, 'accuracy-SBM': 0.81134, 'auc': 0.97311}
2025-08-16 21:10:37,520 - INFO - val: {'epoch': 80, 'time_epoch': 3.96547, 'loss': 0.61874142, 'lr': 0, 'params': 515510, 'time_iter': 0.06294, 'accuracy': 0.78487, 'f1': 0.78475, 'accuracy-SBM': 0.78474, 'auc': 0.96238}
2025-08-16 21:10:43,702 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:10:43,738 - INFO - test: {'epoch': 80, 'time_epoch': 4.3134, 'loss': 0.61341125, 'lr': 0, 'params': 515510, 'time_iter': 0.06847, 'accuracy': 0.78674, 'f1': 0.78672, 'accuracy-SBM': 0.78668, 'auc': 0.96293}
2025-08-16 21:10:43,772 - INFO - > Epoch 80: took 90.6s (avg 98.0s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:10:43,772 - INFO - === Epoch 81 ===
2025-08-16 21:12:04,044 - INFO - train: {'epoch': 81, 'time_epoch': 80.01814, 'eta': 1522.34081, 'eta_hours': 0.42287, 'loss': 0.51700758, 'lr': 9.549e-05, 'params': 515510, 'time_iter': 0.12803, 'accuracy': 0.81127, 'f1': 0.81127, 'accuracy-SBM': 0.81127, 'auc': 0.97327}
2025-08-16 21:12:08,082 - INFO - val: {'epoch': 81, 'time_epoch': 3.99568, 'loss': 0.62811976, 'lr': 0, 'params': 515510, 'time_iter': 0.06342, 'accuracy': 0.78519, 'f1': 0.78513, 'accuracy-SBM': 0.7851, 'auc': 0.96164}
2025-08-16 21:12:13,948 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:12:13,984 - INFO - test: {'epoch': 81, 'time_epoch': 4.15777, 'loss': 0.62022148, 'lr': 0, 'params': 515510, 'time_iter': 0.066, 'accuracy': 0.78374, 'f1': 0.78374, 'accuracy-SBM': 0.78375, 'auc': 0.9625}
2025-08-16 21:12:13,990 - INFO - > Epoch 81: took 90.2s (avg 97.9s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:12:13,990 - INFO - === Epoch 82 ===
2025-08-16 21:13:32,012 - INFO - train: {'epoch': 82, 'time_epoch': 77.79366, 'eta': 1436.37747, 'eta_hours': 0.39899, 'loss': 0.51513791, 'lr': 8.6e-05, 'params': 515510, 'time_iter': 0.12447, 'accuracy': 0.81267, 'f1': 0.81267, 'accuracy-SBM': 0.81267, 'auc': 0.97344}
2025-08-16 21:13:35,902 - INFO - val: {'epoch': 82, 'time_epoch': 3.84744, 'loss': 0.62428828, 'lr': 0, 'params': 515510, 'time_iter': 0.06107, 'accuracy': 0.78592, 'f1': 0.78581, 'accuracy-SBM': 0.78579, 'auc': 0.96185}
2025-08-16 21:13:42,603 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:13:42,642 - INFO - test: {'epoch': 82, 'time_epoch': 4.09053, 'loss': 0.61596849, 'lr': 0, 'params': 515510, 'time_iter': 0.06493, 'accuracy': 0.78582, 'f1': 0.78578, 'accuracy-SBM': 0.78579, 'auc': 0.96273}
2025-08-16 21:13:42,645 - INFO - > Epoch 82: took 88.7s (avg 97.8s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:13:42,645 - INFO - === Epoch 83 ===
2025-08-16 21:14:59,419 - INFO - train: {'epoch': 83, 'time_epoch': 76.54962, 'eta': 1350.37169, 'eta_hours': 0.3751, 'loss': 0.51401444, 'lr': 7.695e-05, 'params': 515510, 'time_iter': 0.12248, 'accuracy': 0.81262, 'f1': 0.81262, 'accuracy-SBM': 0.81262, 'auc': 0.97358}
2025-08-16 21:15:03,314 - INFO - val: {'epoch': 83, 'time_epoch': 3.85329, 'loss': 0.62752853, 'lr': 0, 'params': 515510, 'time_iter': 0.06116, 'accuracy': 0.785, 'f1': 0.78493, 'accuracy-SBM': 0.78491, 'auc': 0.96162}
2025-08-16 21:15:08,475 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:15:08,511 - INFO - test: {'epoch': 83, 'time_epoch': 3.84766, 'loss': 0.61604723, 'lr': 0, 'params': 515510, 'time_iter': 0.06107, 'accuracy': 0.78625, 'f1': 0.7862, 'accuracy-SBM': 0.78622, 'auc': 0.96283}
2025-08-16 21:15:08,513 - INFO - > Epoch 83: took 85.9s (avg 97.6s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:15:08,513 - INFO - === Epoch 84 ===
2025-08-16 21:16:27,066 - INFO - train: {'epoch': 84, 'time_epoch': 78.22086, 'eta': 1264.88334, 'eta_hours': 0.35136, 'loss': 0.51474684, 'lr': 6.837e-05, 'params': 515510, 'time_iter': 0.12515, 'accuracy': 0.8123, 'f1': 0.8123, 'accuracy-SBM': 0.8123, 'auc': 0.9735}
2025-08-16 21:16:31,015 - INFO - val: {'epoch': 84, 'time_epoch': 3.90605, 'loss': 0.62356503, 'lr': 0, 'params': 515510, 'time_iter': 0.062, 'accuracy': 0.78576, 'f1': 0.78565, 'accuracy-SBM': 0.78565, 'auc': 0.96187}
2025-08-16 21:16:36,436 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:16:36,472 - INFO - test: {'epoch': 84, 'time_epoch': 4.17823, 'loss': 0.61361932, 'lr': 0, 'params': 515510, 'time_iter': 0.06632, 'accuracy': 0.78518, 'f1': 0.78516, 'accuracy-SBM': 0.78515, 'auc': 0.96292}
2025-08-16 21:16:36,474 - INFO - > Epoch 84: took 88.0s (avg 97.5s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:16:36,474 - INFO - === Epoch 85 ===
2025-08-16 21:17:55,399 - INFO - train: {'epoch': 85, 'time_epoch': 78.59856, 'eta': 1179.62548, 'eta_hours': 0.32767, 'loss': 0.51273639, 'lr': 6.026e-05, 'params': 515510, 'time_iter': 0.12576, 'accuracy': 0.81335, 'f1': 0.81335, 'accuracy-SBM': 0.81335, 'auc': 0.9737}
2025-08-16 21:17:59,356 - INFO - val: {'epoch': 85, 'time_epoch': 3.90538, 'loss': 0.62204733, 'lr': 0, 'params': 515510, 'time_iter': 0.06199, 'accuracy': 0.78605, 'f1': 0.78598, 'accuracy-SBM': 0.78597, 'auc': 0.96202}
2025-08-16 21:18:05,595 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:18:05,631 - INFO - test: {'epoch': 85, 'time_epoch': 4.20653, 'loss': 0.61093403, 'lr': 0, 'params': 515510, 'time_iter': 0.06677, 'accuracy': 0.78531, 'f1': 0.78529, 'accuracy-SBM': 0.7853, 'auc': 0.96325}
2025-08-16 21:18:05,635 - INFO - > Epoch 85: took 89.2s (avg 97.4s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:18:05,635 - INFO - === Epoch 86 ===
2025-08-16 21:19:24,982 - INFO - train: {'epoch': 86, 'time_epoch': 79.1125, 'eta': 1094.59751, 'eta_hours': 0.30405, 'loss': 0.5119317, 'lr': 5.264e-05, 'params': 515510, 'time_iter': 0.12658, 'accuracy': 0.81389, 'f1': 0.81389, 'accuracy-SBM': 0.81389, 'auc': 0.97378}
2025-08-16 21:19:28,985 - INFO - val: {'epoch': 86, 'time_epoch': 3.94691, 'loss': 0.62403213, 'lr': 0, 'params': 515510, 'time_iter': 0.06265, 'accuracy': 0.78665, 'f1': 0.78654, 'accuracy-SBM': 0.78653, 'auc': 0.96185}
2025-08-16 21:19:34,628 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:19:34,665 - INFO - test: {'epoch': 86, 'time_epoch': 4.22023, 'loss': 0.61286075, 'lr': 0, 'params': 515510, 'time_iter': 0.06699, 'accuracy': 0.78545, 'f1': 0.78543, 'accuracy-SBM': 0.78544, 'auc': 0.96309}
2025-08-16 21:19:34,667 - INFO - > Epoch 86: took 89.0s (avg 97.3s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:19:34,667 - INFO - === Epoch 87 ===
2025-08-16 21:20:54,414 - INFO - train: {'epoch': 87, 'time_epoch': 79.5142, 'eta': 1009.75875, 'eta_hours': 0.28049, 'loss': 0.51147686, 'lr': 4.55e-05, 'params': 515510, 'time_iter': 0.12722, 'accuracy': 0.81442, 'f1': 0.81442, 'accuracy-SBM': 0.81442, 'auc': 0.97382}
2025-08-16 21:20:58,472 - INFO - val: {'epoch': 87, 'time_epoch': 3.99776, 'loss': 0.62522434, 'lr': 0, 'params': 515510, 'time_iter': 0.06346, 'accuracy': 0.78674, 'f1': 0.78659, 'accuracy-SBM': 0.78657, 'auc': 0.96186}
2025-08-16 21:21:04,068 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:21:04,106 - INFO - test: {'epoch': 87, 'time_epoch': 4.28125, 'loss': 0.61545619, 'lr': 0, 'params': 515510, 'time_iter': 0.06796, 'accuracy': 0.78535, 'f1': 0.78531, 'accuracy-SBM': 0.7853, 'auc': 0.96292}
2025-08-16 21:21:04,115 - INFO - > Epoch 87: took 89.4s (avg 97.2s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:21:04,115 - INFO - === Epoch 88 ===
2025-08-16 21:22:23,650 - INFO - train: {'epoch': 88, 'time_epoch': 79.20323, 'eta': 925.00122, 'eta_hours': 0.25694, 'loss': 0.50966276, 'lr': 3.886e-05, 'params': 515510, 'time_iter': 0.12673, 'accuracy': 0.81484, 'f1': 0.81484, 'accuracy-SBM': 0.81483, 'auc': 0.97401}
2025-08-16 21:22:27,639 - INFO - val: {'epoch': 88, 'time_epoch': 3.94704, 'loss': 0.62220937, 'lr': 0, 'params': 515510, 'time_iter': 0.06265, 'accuracy': 0.78616, 'f1': 0.78606, 'accuracy-SBM': 0.78604, 'auc': 0.96211}
2025-08-16 21:22:32,801 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:22:32,837 - INFO - test: {'epoch': 88, 'time_epoch': 3.93384, 'loss': 0.61423298, 'lr': 0, 'params': 515510, 'time_iter': 0.06244, 'accuracy': 0.78572, 'f1': 0.78569, 'accuracy-SBM': 0.7857, 'auc': 0.96297}
2025-08-16 21:22:32,838 - INFO - > Epoch 88: took 88.7s (avg 97.1s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:22:32,839 - INFO - === Epoch 89 ===
2025-08-16 21:23:52,536 - INFO - train: {'epoch': 89, 'time_epoch': 79.37286, 'eta': 840.38596, 'eta_hours': 0.23344, 'loss': 0.50917383, 'lr': 3.272e-05, 'params': 515510, 'time_iter': 0.127, 'accuracy': 0.81442, 'f1': 0.81442, 'accuracy-SBM': 0.81442, 'auc': 0.97406}
2025-08-16 21:23:56,483 - INFO - val: {'epoch': 89, 'time_epoch': 3.90449, 'loss': 0.62132698, 'lr': 0, 'params': 515510, 'time_iter': 0.06198, 'accuracy': 0.78599, 'f1': 0.78589, 'accuracy-SBM': 0.78586, 'auc': 0.96218}
2025-08-16 21:24:01,968 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:24:02,005 - INFO - test: {'epoch': 89, 'time_epoch': 4.19513, 'loss': 0.61554808, 'lr': 0, 'params': 515510, 'time_iter': 0.06659, 'accuracy': 0.78506, 'f1': 0.78503, 'accuracy-SBM': 0.78504, 'auc': 0.96283}
2025-08-16 21:24:02,007 - INFO - > Epoch 89: took 89.2s (avg 97.0s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:24:02,007 - INFO - === Epoch 90 ===
2025-08-16 21:25:22,804 - INFO - train: {'epoch': 90, 'time_epoch': 80.56187, 'eta': 756.00351, 'eta_hours': 0.21, 'loss': 0.50785386, 'lr': 2.709e-05, 'params': 515510, 'time_iter': 0.1289, 'accuracy': 0.81491, 'f1': 0.81491, 'accuracy-SBM': 0.81491, 'auc': 0.9742}
2025-08-16 21:25:26,805 - INFO - val: {'epoch': 90, 'time_epoch': 3.9557, 'loss': 0.62842069, 'lr': 0, 'params': 515510, 'time_iter': 0.06279, 'accuracy': 0.78529, 'f1': 0.78516, 'accuracy-SBM': 0.78515, 'auc': 0.96159}
2025-08-16 21:25:32,393 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:25:32,430 - INFO - test: {'epoch': 90, 'time_epoch': 4.32225, 'loss': 0.61482407, 'lr': 0, 'params': 515510, 'time_iter': 0.06861, 'accuracy': 0.78629, 'f1': 0.78627, 'accuracy-SBM': 0.78627, 'auc': 0.96303}
2025-08-16 21:25:32,432 - INFO - > Epoch 90: took 90.4s (avg 97.0s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:25:32,432 - INFO - === Epoch 91 ===
2025-08-16 21:26:50,981 - INFO - train: {'epoch': 91, 'time_epoch': 78.31785, 'eta': 671.50899, 'eta_hours': 0.18653, 'loss': 0.50974292, 'lr': 2.198e-05, 'params': 515510, 'time_iter': 0.12531, 'accuracy': 0.81429, 'f1': 0.81429, 'accuracy-SBM': 0.81429, 'auc': 0.974}
2025-08-16 21:26:54,945 - INFO - val: {'epoch': 91, 'time_epoch': 3.92153, 'loss': 0.62380744, 'lr': 0, 'params': 515510, 'time_iter': 0.06225, 'accuracy': 0.78723, 'f1': 0.78715, 'accuracy-SBM': 0.78712, 'auc': 0.96204}
2025-08-16 21:27:00,323 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:27:00,360 - INFO - test: {'epoch': 91, 'time_epoch': 4.1611, 'loss': 0.61495957, 'lr': 0, 'params': 515510, 'time_iter': 0.06605, 'accuracy': 0.78598, 'f1': 0.78594, 'accuracy-SBM': 0.78597, 'auc': 0.963}
2025-08-16 21:27:00,362 - INFO - > Epoch 91: took 87.9s (avg 96.9s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:27:00,362 - INFO - === Epoch 92 ===
2025-08-16 21:28:19,120 - INFO - train: {'epoch': 92, 'time_epoch': 78.51559, 'eta': 587.16218, 'eta_hours': 0.1631, 'loss': 0.50743233, 'lr': 1.74e-05, 'params': 515510, 'time_iter': 0.12562, 'accuracy': 0.81536, 'f1': 0.81536, 'accuracy-SBM': 0.81535, 'auc': 0.97424}
2025-08-16 21:28:23,088 - INFO - val: {'epoch': 92, 'time_epoch': 3.92556, 'loss': 0.62450183, 'lr': 0, 'params': 515510, 'time_iter': 0.06231, 'accuracy': 0.78629, 'f1': 0.78618, 'accuracy-SBM': 0.78616, 'auc': 0.96194}
2025-08-16 21:28:28,539 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:28:28,575 - INFO - test: {'epoch': 92, 'time_epoch': 4.16747, 'loss': 0.61548029, 'lr': 0, 'params': 515510, 'time_iter': 0.06615, 'accuracy': 0.78619, 'f1': 0.78617, 'accuracy-SBM': 0.78618, 'auc': 0.96292}
2025-08-16 21:28:28,577 - INFO - > Epoch 92: took 88.2s (avg 96.8s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:28:28,577 - INFO - === Epoch 93 ===
2025-08-16 21:29:50,148 - INFO - train: {'epoch': 93, 'time_epoch': 81.33873, 'eta': 503.11964, 'eta_hours': 0.13976, 'loss': 0.50664669, 'lr': 1.334e-05, 'params': 515510, 'time_iter': 0.13014, 'accuracy': 0.81562, 'f1': 0.81562, 'accuracy-SBM': 0.81562, 'auc': 0.97431}
2025-08-16 21:29:54,157 - INFO - val: {'epoch': 93, 'time_epoch': 3.93454, 'loss': 0.62540768, 'lr': 0, 'params': 515510, 'time_iter': 0.06245, 'accuracy': 0.78622, 'f1': 0.78611, 'accuracy-SBM': 0.78609, 'auc': 0.96196}
2025-08-16 21:29:59,602 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:29:59,638 - INFO - test: {'epoch': 93, 'time_epoch': 4.20633, 'loss': 0.61805048, 'lr': 0, 'params': 515510, 'time_iter': 0.06677, 'accuracy': 0.78557, 'f1': 0.78556, 'accuracy-SBM': 0.78556, 'auc': 0.9627}
2025-08-16 21:29:59,640 - INFO - > Epoch 93: took 91.1s (avg 96.7s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:29:59,640 - INFO - === Epoch 94 ===
2025-08-16 21:31:18,785 - INFO - train: {'epoch': 94, 'time_epoch': 78.91024, 'eta': 419.00621, 'eta_hours': 0.11639, 'loss': 0.50611197, 'lr': 9.81e-06, 'params': 515510, 'time_iter': 0.12626, 'accuracy': 0.81569, 'f1': 0.81569, 'accuracy-SBM': 0.81569, 'auc': 0.97438}
2025-08-16 21:31:22,811 - INFO - val: {'epoch': 94, 'time_epoch': 3.96754, 'loss': 0.62241295, 'lr': 0, 'params': 515510, 'time_iter': 0.06298, 'accuracy': 0.78733, 'f1': 0.78724, 'accuracy-SBM': 0.78721, 'auc': 0.96225}
2025-08-16 21:31:28,038 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:31:28,082 - INFO - test: {'epoch': 94, 'time_epoch': 3.97696, 'loss': 0.61457516, 'lr': 0, 'params': 515510, 'time_iter': 0.06313, 'accuracy': 0.78606, 'f1': 0.786, 'accuracy-SBM': 0.78602, 'auc': 0.96303}
2025-08-16 21:31:28,085 - INFO - > Epoch 94: took 88.4s (avg 96.6s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:31:28,085 - INFO - === Epoch 95 ===
2025-08-16 21:32:48,108 - INFO - train: {'epoch': 95, 'time_epoch': 79.6898, 'eta': 335.03365, 'eta_hours': 0.09306, 'loss': 0.50627155, 'lr': 6.82e-06, 'params': 515510, 'time_iter': 0.1275, 'accuracy': 0.81601, 'f1': 0.816, 'accuracy-SBM': 0.816, 'auc': 0.97436}
2025-08-16 21:32:52,137 - INFO - val: {'epoch': 95, 'time_epoch': 3.97807, 'loss': 0.62693518, 'lr': 0, 'params': 515510, 'time_iter': 0.06314, 'accuracy': 0.78655, 'f1': 0.78645, 'accuracy-SBM': 0.78643, 'auc': 0.96176}
2025-08-16 21:32:57,359 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:32:57,396 - INFO - test: {'epoch': 95, 'time_epoch': 3.98402, 'loss': 0.61754836, 'lr': 0, 'params': 515510, 'time_iter': 0.06324, 'accuracy': 0.78589, 'f1': 0.78587, 'accuracy-SBM': 0.78589, 'auc': 0.96278}
2025-08-16 21:32:57,397 - INFO - > Epoch 95: took 89.3s (avg 96.6s) | Best so far: epoch 72	train_loss: 0.5312 train_accuracy-SBM: 0.8067	val_loss: 0.6145 val_accuracy-SBM: 0.7872	test_loss: 0.6088 test_accuracy-SBM: 0.7843
2025-08-16 21:32:57,398 - INFO - === Epoch 96 ===
2025-08-16 21:34:17,119 - INFO - train: {'epoch': 96, 'time_epoch': 79.48969, 'eta': 251.14322, 'eta_hours': 0.06976, 'loss': 0.50714493, 'lr': 4.37e-06, 'params': 515510, 'time_iter': 0.12718, 'accuracy': 0.81577, 'f1': 0.81577, 'accuracy-SBM': 0.81577, 'auc': 0.97426}
2025-08-16 21:34:21,118 - INFO - val: {'epoch': 96, 'time_epoch': 3.95506, 'loss': 0.62518208, 'lr': 0, 'params': 515510, 'time_iter': 0.06278, 'accuracy': 0.78745, 'f1': 0.78736, 'accuracy-SBM': 0.78733, 'auc': 0.9619}
2025-08-16 21:34:26,610 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:34:26,646 - INFO - test: {'epoch': 96, 'time_epoch': 4.2387, 'loss': 0.6168789, 'lr': 0, 'params': 515510, 'time_iter': 0.06728, 'accuracy': 0.78573, 'f1': 0.7857, 'accuracy-SBM': 0.78572, 'auc': 0.96279}
2025-08-16 21:34:26,648 - INFO - > Epoch 96: took 89.3s (avg 96.5s) | Best so far: epoch 96	train_loss: 0.5071 train_accuracy-SBM: 0.8158	val_loss: 0.6252 val_accuracy-SBM: 0.7873	test_loss: 0.6169 test_accuracy-SBM: 0.7857
2025-08-16 21:34:26,648 - INFO - === Epoch 97 ===
2025-08-16 21:35:46,630 - INFO - train: {'epoch': 97, 'time_epoch': 79.74686, 'eta': 167.34784, 'eta_hours': 0.04649, 'loss': 0.50736684, 'lr': 2.46e-06, 'params': 515510, 'time_iter': 0.12759, 'accuracy': 0.81535, 'f1': 0.81535, 'accuracy-SBM': 0.81535, 'auc': 0.97425}
2025-08-16 21:35:50,652 - INFO - val: {'epoch': 97, 'time_epoch': 3.97099, 'loss': 0.62431806, 'lr': 0, 'params': 515510, 'time_iter': 0.06303, 'accuracy': 0.78623, 'f1': 0.78612, 'accuracy-SBM': 0.7861, 'auc': 0.96196}
2025-08-16 21:35:56,132 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:35:56,169 - INFO - test: {'epoch': 97, 'time_epoch': 4.26543, 'loss': 0.61418639, 'lr': 0, 'params': 515510, 'time_iter': 0.06771, 'accuracy': 0.78635, 'f1': 0.78632, 'accuracy-SBM': 0.78634, 'auc': 0.96304}
2025-08-16 21:35:56,171 - INFO - > Epoch 97: took 89.5s (avg 96.4s) | Best so far: epoch 96	train_loss: 0.5071 train_accuracy-SBM: 0.8158	val_loss: 0.6252 val_accuracy-SBM: 0.7873	test_loss: 0.6169 test_accuracy-SBM: 0.7857
2025-08-16 21:35:56,171 - INFO - === Epoch 98 ===
2025-08-16 21:37:15,924 - INFO - train: {'epoch': 98, 'time_epoch': 79.5115, 'eta': 83.63188, 'eta_hours': 0.02323, 'loss': 0.50498234, 'lr': 1.09e-06, 'params': 515510, 'time_iter': 0.12722, 'accuracy': 0.81586, 'f1': 0.81586, 'accuracy-SBM': 0.81586, 'auc': 0.97449}
2025-08-16 21:37:19,916 - INFO - val: {'epoch': 98, 'time_epoch': 3.94897, 'loss': 0.62459371, 'lr': 0, 'params': 515510, 'time_iter': 0.06268, 'accuracy': 0.78683, 'f1': 0.78673, 'accuracy-SBM': 0.78668, 'auc': 0.96196}
2025-08-16 21:37:25,544 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:37:25,581 - INFO - test: {'epoch': 98, 'time_epoch': 4.38044, 'loss': 0.61374628, 'lr': 0, 'params': 515510, 'time_iter': 0.06953, 'accuracy': 0.78661, 'f1': 0.78657, 'accuracy-SBM': 0.78659, 'auc': 0.9631}
2025-08-16 21:37:25,583 - INFO - > Epoch 98: took 89.4s (avg 96.3s) | Best so far: epoch 96	train_loss: 0.5071 train_accuracy-SBM: 0.8158	val_loss: 0.6252 val_accuracy-SBM: 0.7873	test_loss: 0.6169 test_accuracy-SBM: 0.7857
2025-08-16 21:37:25,583 - INFO - === Epoch 99 ===
2025-08-16 21:38:45,696 - INFO - train: {'epoch': 99, 'time_epoch': 79.87504, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.50693397, 'lr': 2.7e-07, 'params': 515510, 'time_iter': 0.1278, 'accuracy': 0.81583, 'f1': 0.81583, 'accuracy-SBM': 0.81583, 'auc': 0.97429}
2025-08-16 21:38:49,876 - INFO - val: {'epoch': 99, 'time_epoch': 4.13578, 'loss': 0.62398769, 'lr': 0, 'params': 515510, 'time_iter': 0.06565, 'accuracy': 0.78678, 'f1': 0.78669, 'accuracy-SBM': 0.78666, 'auc': 0.96204}
2025-08-16 21:38:55,528 - INFO - Saved test results for 1000 graphs to results/Cluster/Cluster-SparseE-47/test_results
2025-08-16 21:38:55,565 - INFO - test: {'epoch': 99, 'time_epoch': 4.41389, 'loss': 0.61586534, 'lr': 0, 'params': 515510, 'time_iter': 0.07006, 'accuracy': 0.78616, 'f1': 0.78614, 'accuracy-SBM': 0.78615, 'auc': 0.96288}
2025-08-16 21:38:55,831 - INFO - > Epoch 99: took 90.0s (avg 96.3s) | Best so far: epoch 96	train_loss: 0.5071 train_accuracy-SBM: 0.8158	val_loss: 0.6252 val_accuracy-SBM: 0.7873	test_loss: 0.6169 test_accuracy-SBM: 0.7857
2025-08-16 21:38:55,832 - INFO - ================================================================================
2025-08-16 21:38:55,832 - INFO - NAS TRAINING COMPLETED SUCCESSFULLY
2025-08-16 21:38:55,832 - INFO - ================================================================================
2025-08-16 21:38:55,832 - INFO - Avg time per epoch: 96.27s
2025-08-16 21:38:55,832 - INFO - Total train loop time: 2.67h
2025-08-16 21:38:55,832 - INFO - Routing mode: nas
2025-08-16 21:38:55,832 - INFO - Final optimal weights: {'layer_0': 2, 'layer_1': 2, 'layer_2': 1, 'layer_3': 1, 'layer_4': 1, 'layer_5': 0, 'layer_6': 0, 'layer_7': 1, 'layer_8': 1, 'layer_9': 1, 'layer_10': 1, 'layer_11': 1, 'layer_12': 1, 'layer_13': 1, 'layer_14': 1, 'layer_15': 1}
2025-08-16 21:38:55,832 - INFO - Results include routing uncertainty (test only, NO variance)
'
