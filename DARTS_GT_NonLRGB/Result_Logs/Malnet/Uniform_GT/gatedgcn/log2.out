Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          376Gi        35Gi       281Gi       3.6Gi        59Gi       333Gi
Swap:         1.9Gi       6.0Mi       1.9Gi
Sat Aug 23 09:23:04 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-16GB           On  |   00000000:3B:00.0 Off |                    0 |
| N/A   44C    P0             27W /  250W |       0MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 45
Starting training for seed 45...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/MALNET/FINAL_SINGLE/PERFORMER_E/UNI_GT/GATEDGCN
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/MALNET/FINAL_SINGLE/PERFORMER_E/UNI_GT/GATEDGCN/confignas.yaml
Using device: cuda
2025-08-23 09:24:25,298 - INFO - GPU Mem: 17.1GB
2025-08-23 09:24:25,298 - INFO - Run directory: results/MALNET/MALNET-E-45
2025-08-23 09:24:25,298 - INFO - Seed: 45
2025-08-23 09:24:25,298 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-23 09:24:25,298 - INFO - Routing mode: none
2025-08-23 09:24:25,298 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-23 09:24:25,298 - INFO - Number of layers: 4
2025-08-23 09:24:25,298 - INFO - Uncertainty enabled: False
2025-08-23 09:24:25,298 - INFO - Training mode: custom
2025-08-23 09:24:25,298 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-23 09:24:25,298 - INFO - Additional features: Router weights logging + JSON export
2025-08-23 09:24:27,421 - INFO - Computing "LocalDegreeProfile" node features for MalNetTiny.
2025-08-23 09:24:32,047 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-23 09:24:32,051 - INFO -   Data(edge_index=[2, 14299688], y=[5000], x=[7051560, 5], num_nodes=7051560)
2025-08-23 09:24:32,069 - INFO -   undirected: False
2025-08-23 09:24:32,069 - INFO -   num graphs: 5000
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-23 09:24:32,070 - INFO -   avg num_nodes/graph: 1410
2025-08-23 09:24:32,070 - INFO -   num node features: 5
2025-08-23 09:24:32,070 - INFO -   num edge features: 0
2025-08-23 09:24:32,070 - INFO -   num classes: 5
2025-08-23 09:24:32,072 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny'
2025-08-23 09:24:32,317 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-23 09:24:32,317 - INFO - Inner model type: <class 'graphgps.network.uniform_gt_model_edge.UNIFORM_GTModelEdge'>
2025-08-23 09:24:32,317 - INFO - Inner model has get_darts_model: False
2025-08-23 09:24:32,319 - INFO - GraphGymModule(
  (model): UNIFORM_GTModelEdge(
    (encoder): FeatureEncoder(
      (edge_encoder): DummyEdgeEncoder(
        (encoder): Embedding(1, 64)
      )
    )
    (pre_mp): GeneralMultiLayer(
      (Layer_0): GeneralLayer(
        (layer): Linear(
          (model): Linear(5, 64, bias=False)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU()
        )
      )
    )
    (layers): Sequential(
      (0): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GatedGCNLayer()
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (1): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GatedGCNLayer()
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (2): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GatedGCNLayer()
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (3): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GatedGCNLayer()
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
    )
    (post_mp): GNNGraphHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(64, 5, bias=True)
          )
        )
      )
    )
  )
)
2025-08-23 09:24:32,321 - INFO - Number of parameters: 244,937
2025-08-23 09:24:32,321 - INFO - Starting optimized training: 2025-08-23 09:24:32.321073
2025-08-23 09:24:32,418 - INFO - Computing "LocalDegreeProfile" node features for MalNetTiny.
2025-08-23 09:24:36,549 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny':
2025-08-23 09:24:36,549 - INFO -   Data(edge_index=[2, 14299688], y=[5000], x=[7051560, 5], num_nodes=7051560)
2025-08-23 09:24:36,550 - INFO -   undirected: False
2025-08-23 09:24:36,550 - INFO -   num graphs: 5000
2025-08-23 09:24:36,550 - INFO -   avg num_nodes/graph: 1410
2025-08-23 09:24:36,551 - INFO -   num node features: 5
2025-08-23 09:24:36,551 - INFO -   num edge features: 0
2025-08-23 09:24:36,551 - INFO -   num classes: 5
2025-08-23 09:24:36,554 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny'
2025-08-23 09:24:36,558 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-23 09:24:36,558 - INFO - Start from epoch 0
2025-08-23 09:24:53,913 - INFO - train: {'epoch': 0, 'time_epoch': 16.82181, 'eta': 1665.35936, 'eta_hours': 0.4626, 'loss': 1.62081385, 'lr': 0.0, 'params': 244937, 'time_iter': 0.07681, 'accuracy': 0.2, 'f1': 0.06667, 'auc': 0.46877}
2025-08-23 09:24:53,916 - INFO - ...computing epoch stats took: 0.53s
2025-08-23 09:24:54,851 - INFO - val: {'epoch': 0, 'time_epoch': 0.92475, 'loss': 1.61834416, 'lr': 0, 'params': 244937, 'time_iter': 0.0289, 'accuracy': 0.2, 'f1': 0.06667, 'auc': 0.44425}
2025-08-23 09:24:54,853 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:24:56,639 - INFO - test: {'epoch': 0, 'time_epoch': 1.77461, 'loss': 1.61908786, 'lr': 0, 'params': 244937, 'time_iter': 0.02817, 'accuracy': 0.2, 'f1': 0.06667, 'auc': 0.42743}
2025-08-23 09:24:56,641 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:24:56,641 - INFO - > Epoch 0: took 20.1s (avg 20.1s) | Best so far: epoch 0	train_loss: 1.6208 train_accuracy: 0.2000	val_loss: 1.6183 val_accuracy: 0.2000	test_loss: 1.6191 test_accuracy: 0.2000
2025-08-23 09:25:10,464 - INFO - train: {'epoch': 1, 'time_epoch': 13.80351, 'eta': 1500.6409, 'eta_hours': 0.41684, 'loss': 1.53632499, 'lr': 5e-05, 'params': 244937, 'time_iter': 0.06303, 'accuracy': 0.39257, 'f1': 0.34967, 'auc': 0.75}
2025-08-23 09:25:10,467 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:25:11,309 - INFO - val: {'epoch': 1, 'time_epoch': 0.8326, 'loss': 1.48319392, 'lr': 0, 'params': 244937, 'time_iter': 0.02602, 'accuracy': 0.478, 'f1': 0.39734, 'auc': 0.83188}
2025-08-23 09:25:11,311 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:25:12,988 - INFO - test: {'epoch': 1, 'time_epoch': 1.66683, 'loss': 1.48842372, 'lr': 0, 'params': 244937, 'time_iter': 0.02646, 'accuracy': 0.486, 'f1': 0.41592, 'auc': 0.8084}
2025-08-23 09:25:12,990 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:25:12,990 - INFO - > Epoch 1: took 16.3s (avg 18.2s) | Best so far: epoch 1	train_loss: 1.5363 train_accuracy: 0.3926	val_loss: 1.4832 val_accuracy: 0.4780	test_loss: 1.4884 test_accuracy: 0.4860
2025-08-23 09:25:26,823 - INFO - train: {'epoch': 2, 'time_epoch': 13.81441, 'eta': 1436.88461, 'eta_hours': 0.39913, 'loss': 1.43038659, 'lr': 0.0001, 'params': 244937, 'time_iter': 0.06308, 'accuracy': 0.57543, 'f1': 0.53944, 'auc': 0.8265}
2025-08-23 09:25:26,827 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:25:27,671 - INFO - val: {'epoch': 2, 'time_epoch': 0.83228, 'loss': 1.40019442, 'lr': 0, 'params': 244937, 'time_iter': 0.02601, 'accuracy': 0.56, 'f1': 0.50319, 'auc': 0.86237}
2025-08-23 09:25:27,673 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:25:29,330 - INFO - test: {'epoch': 2, 'time_epoch': 1.64553, 'loss': 1.40831446, 'lr': 0, 'params': 244937, 'time_iter': 0.02612, 'accuracy': 0.558, 'f1': 0.52227, 'auc': 0.84595}
2025-08-23 09:25:29,333 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:25:29,333 - INFO - > Epoch 2: took 16.3s (avg 17.6s) | Best so far: epoch 2	train_loss: 1.4304 train_accuracy: 0.5754	val_loss: 1.4002 val_accuracy: 0.5600	test_loss: 1.4083 test_accuracy: 0.5580
2025-08-23 09:25:42,846 - INFO - train: {'epoch': 3, 'time_epoch': 13.4946, 'eta': 1390.42402, 'eta_hours': 0.38623, 'loss': 1.34841641, 'lr': 0.00015, 'params': 244937, 'time_iter': 0.06162, 'accuracy': 0.638, 'f1': 0.62677, 'auc': 0.85328}
2025-08-23 09:25:43,679 - INFO - val: {'epoch': 3, 'time_epoch': 0.81835, 'loss': 1.31328559, 'lr': 0, 'params': 244937, 'time_iter': 0.02557, 'accuracy': 0.62, 'f1': 0.59681, 'auc': 0.87333}
2025-08-23 09:25:45,332 - INFO - test: {'epoch': 3, 'time_epoch': 1.64076, 'loss': 1.32460787, 'lr': 0, 'params': 244937, 'time_iter': 0.02604, 'accuracy': 0.61, 'f1': 0.59499, 'auc': 0.8561}
2025-08-23 09:25:45,334 - INFO - > Epoch 3: took 16.0s (avg 17.2s) | Best so far: epoch 3	train_loss: 1.3484 train_accuracy: 0.6380	val_loss: 1.3133 val_accuracy: 0.6200	test_loss: 1.3246 test_accuracy: 0.6100
2025-08-23 09:25:59,281 - INFO - train: {'epoch': 4, 'time_epoch': 13.92653, 'eta': 1365.35641, 'eta_hours': 0.37927, 'loss': 1.24991362, 'lr': 0.0002, 'params': 244937, 'time_iter': 0.06359, 'accuracy': 0.70743, 'f1': 0.7089, 'auc': 0.88858}
2025-08-23 09:26:00,169 - INFO - val: {'epoch': 4, 'time_epoch': 0.87178, 'loss': 1.25688151, 'lr': 0, 'params': 244937, 'time_iter': 0.02724, 'accuracy': 0.558, 'f1': 0.50431, 'auc': 0.9224}
2025-08-23 09:26:01,907 - INFO - test: {'epoch': 4, 'time_epoch': 1.72016, 'loss': 1.27583298, 'lr': 0, 'params': 244937, 'time_iter': 0.0273, 'accuracy': 0.53, 'f1': 0.47336, 'auc': 0.89769}
2025-08-23 09:26:01,910 - INFO - > Epoch 4: took 16.6s (avg 17.1s) | Best so far: epoch 3	train_loss: 1.3484 train_accuracy: 0.6380	val_loss: 1.3133 val_accuracy: 0.6200	test_loss: 1.3246 test_accuracy: 0.6100
2025-08-23 09:26:15,403 - INFO - train: {'epoch': 5, 'time_epoch': 13.47482, 'eta': 1336.92575, 'eta_hours': 0.37137, 'loss': 1.15332038, 'lr': 0.00025, 'params': 244937, 'time_iter': 0.06153, 'accuracy': 0.73286, 'f1': 0.73536, 'auc': 0.90036}
2025-08-23 09:26:16,236 - INFO - val: {'epoch': 5, 'time_epoch': 0.82167, 'loss': 1.09358461, 'lr': 0, 'params': 244937, 'time_iter': 0.02568, 'accuracy': 0.784, 'f1': 0.78571, 'auc': 0.93077}
2025-08-23 09:26:17,902 - INFO - test: {'epoch': 5, 'time_epoch': 1.65331, 'loss': 1.10940582, 'lr': 0, 'params': 244937, 'time_iter': 0.02624, 'accuracy': 0.775, 'f1': 0.7766, 'auc': 0.91309}
2025-08-23 09:26:17,904 - INFO - > Epoch 5: took 16.0s (avg 16.9s) | Best so far: epoch 5	train_loss: 1.1533 train_accuracy: 0.7329	val_loss: 1.0936 val_accuracy: 0.7840	test_loss: 1.1094 test_accuracy: 0.7750
2025-08-23 09:26:31,574 - INFO - train: {'epoch': 6, 'time_epoch': 13.65277, 'eta': 1315.13233, 'eta_hours': 0.36531, 'loss': 1.05654862, 'lr': 0.0003, 'params': 244937, 'time_iter': 0.06234, 'accuracy': 0.76914, 'f1': 0.77036, 'auc': 0.91715}
2025-08-23 09:26:32,402 - INFO - val: {'epoch': 6, 'time_epoch': 0.81499, 'loss': 1.01837811, 'lr': 0, 'params': 244937, 'time_iter': 0.02547, 'accuracy': 0.76, 'f1': 0.75694, 'auc': 0.92215}
2025-08-23 09:26:34,053 - INFO - test: {'epoch': 6, 'time_epoch': 1.63833, 'loss': 1.0347184, 'lr': 0, 'params': 244937, 'time_iter': 0.02601, 'accuracy': 0.754, 'f1': 0.75397, 'auc': 0.90395}
2025-08-23 09:26:34,054 - INFO - > Epoch 6: took 16.2s (avg 16.8s) | Best so far: epoch 5	train_loss: 1.1533 train_accuracy: 0.7329	val_loss: 1.0936 val_accuracy: 0.7840	test_loss: 1.1094 test_accuracy: 0.7750
2025-08-23 09:26:47,597 - INFO - train: {'epoch': 7, 'time_epoch': 13.52344, 'eta': 1293.88681, 'eta_hours': 0.35941, 'loss': 0.96717799, 'lr': 0.00035, 'params': 244937, 'time_iter': 0.06175, 'accuracy': 0.78571, 'f1': 0.7881, 'auc': 0.92814}
2025-08-23 09:26:48,409 - INFO - val: {'epoch': 7, 'time_epoch': 0.80093, 'loss': 0.94148567, 'lr': 0, 'params': 244937, 'time_iter': 0.02503, 'accuracy': 0.784, 'f1': 0.78466, 'auc': 0.94433}
2025-08-23 09:26:50,034 - INFO - test: {'epoch': 7, 'time_epoch': 1.61432, 'loss': 0.95972477, 'lr': 0, 'params': 244937, 'time_iter': 0.02562, 'accuracy': 0.755, 'f1': 0.75619, 'auc': 0.93588}
2025-08-23 09:26:50,036 - INFO - > Epoch 7: took 16.0s (avg 16.7s) | Best so far: epoch 5	train_loss: 1.1533 train_accuracy: 0.7329	val_loss: 1.0936 val_accuracy: 0.7840	test_loss: 1.1094 test_accuracy: 0.7750
2025-08-23 09:27:03,630 - INFO - train: {'epoch': 8, 'time_epoch': 13.57651, 'eta': 1274.89388, 'eta_hours': 0.35414, 'loss': 0.87599239, 'lr': 0.0004, 'params': 244937, 'time_iter': 0.06199, 'accuracy': 0.80029, 'f1': 0.80181, 'auc': 0.94057}
2025-08-23 09:27:04,455 - INFO - val: {'epoch': 8, 'time_epoch': 0.81301, 'loss': 0.87449874, 'lr': 0, 'params': 244937, 'time_iter': 0.02541, 'accuracy': 0.766, 'f1': 0.77655, 'auc': 0.95193}
2025-08-23 09:27:06,101 - INFO - test: {'epoch': 8, 'time_epoch': 1.63431, 'loss': 0.90416405, 'lr': 0, 'params': 244937, 'time_iter': 0.02594, 'accuracy': 0.76, 'f1': 0.77161, 'auc': 0.94335}
2025-08-23 09:27:06,102 - INFO - > Epoch 8: took 16.1s (avg 16.6s) | Best so far: epoch 5	train_loss: 1.1533 train_accuracy: 0.7329	val_loss: 1.0936 val_accuracy: 0.7840	test_loss: 1.1094 test_accuracy: 0.7750
2025-08-23 09:27:19,714 - INFO - train: {'epoch': 9, 'time_epoch': 13.59448, 'eta': 1257.14597, 'eta_hours': 0.34921, 'loss': 0.78667318, 'lr': 0.00045, 'params': 244937, 'time_iter': 0.06208, 'accuracy': 0.81829, 'f1': 0.81945, 'auc': 0.94978}
2025-08-23 09:27:20,551 - INFO - val: {'epoch': 9, 'time_epoch': 0.82478, 'loss': 0.7331814, 'lr': 0, 'params': 244937, 'time_iter': 0.02577, 'accuracy': 0.82, 'f1': 0.81357, 'auc': 0.96211}
2025-08-23 09:27:22,200 - INFO - test: {'epoch': 9, 'time_epoch': 1.63761, 'loss': 0.75145767, 'lr': 0, 'params': 244937, 'time_iter': 0.02599, 'accuracy': 0.821, 'f1': 0.8165, 'auc': 0.96105}
2025-08-23 09:27:22,201 - INFO - > Epoch 9: took 16.1s (avg 16.6s) | Best so far: epoch 9	train_loss: 0.7867 train_accuracy: 0.8183	val_loss: 0.7332 val_accuracy: 0.8200	test_loss: 0.7515 test_accuracy: 0.8210
2025-08-23 09:27:35,805 - INFO - train: {'epoch': 10, 'time_epoch': 13.58612, 'eta': 1240.0856, 'eta_hours': 0.34447, 'loss': 0.71439854, 'lr': 0.0005, 'params': 244937, 'time_iter': 0.06204, 'accuracy': 0.83, 'f1': 0.83104, 'auc': 0.95398}
2025-08-23 09:27:36,629 - INFO - val: {'epoch': 10, 'time_epoch': 0.81219, 'loss': 0.65630425, 'lr': 0, 'params': 244937, 'time_iter': 0.02538, 'accuracy': 0.86, 'f1': 0.86274, 'auc': 0.96714}
2025-08-23 09:27:38,275 - INFO - test: {'epoch': 10, 'time_epoch': 1.6354, 'loss': 0.6727258, 'lr': 0, 'params': 244937, 'time_iter': 0.02596, 'accuracy': 0.844, 'f1': 0.84764, 'auc': 0.96984}
2025-08-23 09:27:38,277 - INFO - > Epoch 10: took 16.1s (avg 16.5s) | Best so far: epoch 10	train_loss: 0.7144 train_accuracy: 0.8300	val_loss: 0.6563 val_accuracy: 0.8600	test_loss: 0.6727 test_accuracy: 0.8440
2025-08-23 09:27:51,832 - INFO - train: {'epoch': 11, 'time_epoch': 13.53821, 'eta': 1223.25294, 'eta_hours': 0.33979, 'loss': 0.64334662, 'lr': 0.00049985, 'params': 244937, 'time_iter': 0.06182, 'accuracy': 0.83829, 'f1': 0.83867, 'auc': 0.95946}
2025-08-23 09:27:52,654 - INFO - val: {'epoch': 11, 'time_epoch': 0.81085, 'loss': 0.69467228, 'lr': 0, 'params': 244937, 'time_iter': 0.02534, 'accuracy': 0.786, 'f1': 0.7887, 'auc': 0.95942}
2025-08-23 09:27:54,290 - INFO - test: {'epoch': 11, 'time_epoch': 1.62483, 'loss': 0.71378719, 'lr': 0, 'params': 244937, 'time_iter': 0.02579, 'accuracy': 0.777, 'f1': 0.78037, 'auc': 0.95598}
2025-08-23 09:27:54,292 - INFO - > Epoch 11: took 16.0s (avg 16.5s) | Best so far: epoch 10	train_loss: 0.7144 train_accuracy: 0.8300	val_loss: 0.6563 val_accuracy: 0.8600	test_loss: 0.6727 test_accuracy: 0.8440
2025-08-23 09:28:07,841 - INFO - train: {'epoch': 12, 'time_epoch': 13.53199, 'eta': 1206.88547, 'eta_hours': 0.33525, 'loss': 0.5776406, 'lr': 0.00049939, 'params': 244937, 'time_iter': 0.06179, 'accuracy': 0.852, 'f1': 0.85248, 'auc': 0.96624}
2025-08-23 09:28:08,664 - INFO - val: {'epoch': 12, 'time_epoch': 0.81165, 'loss': 0.55629858, 'lr': 0, 'params': 244937, 'time_iter': 0.02536, 'accuracy': 0.848, 'f1': 0.85509, 'auc': 0.97636}
2025-08-23 09:28:10,301 - INFO - test: {'epoch': 12, 'time_epoch': 1.62698, 'loss': 0.57662023, 'lr': 0, 'params': 244937, 'time_iter': 0.02583, 'accuracy': 0.839, 'f1': 0.84664, 'auc': 0.9749}
2025-08-23 09:28:10,303 - INFO - > Epoch 12: took 16.0s (avg 16.4s) | Best so far: epoch 10	train_loss: 0.7144 train_accuracy: 0.8300	val_loss: 0.6563 val_accuracy: 0.8600	test_loss: 0.6727 test_accuracy: 0.8440
2025-08-23 09:28:23,900 - INFO - train: {'epoch': 13, 'time_epoch': 13.57958, 'eta': 1191.21539, 'eta_hours': 0.33089, 'loss': 0.52877337, 'lr': 0.00049863, 'params': 244937, 'time_iter': 0.06201, 'accuracy': 0.86086, 'f1': 0.86172, 'auc': 0.96879}
2025-08-23 09:28:24,730 - INFO - val: {'epoch': 13, 'time_epoch': 0.8175, 'loss': 0.48970877, 'lr': 0, 'params': 244937, 'time_iter': 0.02555, 'accuracy': 0.868, 'f1': 0.86605, 'auc': 0.97877}
2025-08-23 09:28:26,389 - INFO - test: {'epoch': 13, 'time_epoch': 1.64542, 'loss': 0.51610653, 'lr': 0, 'params': 244937, 'time_iter': 0.02612, 'accuracy': 0.85, 'f1': 0.84651, 'auc': 0.97648}
2025-08-23 09:28:26,391 - INFO - > Epoch 13: took 16.1s (avg 16.4s) | Best so far: epoch 13	train_loss: 0.5288 train_accuracy: 0.8609	val_loss: 0.4897 val_accuracy: 0.8680	test_loss: 0.5161 test_accuracy: 0.8500
2025-08-23 09:28:40,028 - INFO - train: {'epoch': 14, 'time_epoch': 13.61872, 'eta': 1176.04587, 'eta_hours': 0.32668, 'loss': 0.47364759, 'lr': 0.00049757, 'params': 244937, 'time_iter': 0.06219, 'accuracy': 0.87829, 'f1': 0.87881, 'auc': 0.97384}
2025-08-23 09:28:40,853 - INFO - val: {'epoch': 14, 'time_epoch': 0.81228, 'loss': 0.45875394, 'lr': 0, 'params': 244937, 'time_iter': 0.02538, 'accuracy': 0.868, 'f1': 0.87222, 'auc': 0.97799}
2025-08-23 09:28:42,506 - INFO - test: {'epoch': 14, 'time_epoch': 1.63982, 'loss': 0.48030171, 'lr': 0, 'params': 244937, 'time_iter': 0.02603, 'accuracy': 0.862, 'f1': 0.86574, 'auc': 0.97998}
2025-08-23 09:28:42,510 - INFO - > Epoch 14: took 16.1s (avg 16.4s) | Best so far: epoch 13	train_loss: 0.5288 train_accuracy: 0.8609	val_loss: 0.4897 val_accuracy: 0.8680	test_loss: 0.5161 test_accuracy: 0.8500
2025-08-23 09:28:56,070 - INFO - train: {'epoch': 15, 'time_epoch': 13.5426, 'eta': 1160.67058, 'eta_hours': 0.32241, 'loss': 0.44829604, 'lr': 0.0004962, 'params': 244937, 'time_iter': 0.06184, 'accuracy': 0.87914, 'f1': 0.87949, 'auc': 0.97446}
2025-08-23 09:28:56,892 - INFO - val: {'epoch': 15, 'time_epoch': 0.81084, 'loss': 0.55054881, 'lr': 0, 'params': 244937, 'time_iter': 0.02534, 'accuracy': 0.818, 'f1': 0.81272, 'auc': 0.97008}
2025-08-23 09:28:58,538 - INFO - test: {'epoch': 15, 'time_epoch': 1.63297, 'loss': 0.56384004, 'lr': 0, 'params': 244937, 'time_iter': 0.02592, 'accuracy': 0.808, 'f1': 0.80515, 'auc': 0.96509}
2025-08-23 09:28:58,540 - INFO - > Epoch 15: took 16.0s (avg 16.4s) | Best so far: epoch 13	train_loss: 0.5288 train_accuracy: 0.8609	val_loss: 0.4897 val_accuracy: 0.8680	test_loss: 0.5161 test_accuracy: 0.8500
2025-08-23 09:29:12,107 - INFO - train: {'epoch': 16, 'time_epoch': 13.55031, 'eta': 1145.54853, 'eta_hours': 0.31821, 'loss': 0.42318076, 'lr': 0.00049454, 'params': 244937, 'time_iter': 0.06187, 'accuracy': 0.87829, 'f1': 0.87892, 'auc': 0.9764}
2025-08-23 09:29:12,938 - INFO - val: {'epoch': 16, 'time_epoch': 0.81794, 'loss': 0.43372634, 'lr': 0, 'params': 244937, 'time_iter': 0.02556, 'accuracy': 0.864, 'f1': 0.86349, 'auc': 0.97939}
2025-08-23 09:29:14,599 - INFO - test: {'epoch': 16, 'time_epoch': 1.6485, 'loss': 0.41671832, 'lr': 0, 'params': 244937, 'time_iter': 0.02617, 'accuracy': 0.878, 'f1': 0.87847, 'auc': 0.98152}
2025-08-23 09:29:14,601 - INFO - > Epoch 16: took 16.1s (avg 16.4s) | Best so far: epoch 13	train_loss: 0.5288 train_accuracy: 0.8609	val_loss: 0.4897 val_accuracy: 0.8680	test_loss: 0.5161 test_accuracy: 0.8500
2025-08-23 09:29:28,169 - INFO - train: {'epoch': 17, 'time_epoch': 13.552, 'eta': 1130.60882, 'eta_hours': 0.31406, 'loss': 0.39331389, 'lr': 0.00049257, 'params': 244937, 'time_iter': 0.06188, 'accuracy': 0.88314, 'f1': 0.88342, 'auc': 0.97783}
2025-08-23 09:29:28,993 - INFO - val: {'epoch': 17, 'time_epoch': 0.81228, 'loss': 0.46579216, 'lr': 0, 'params': 244937, 'time_iter': 0.02538, 'accuracy': 0.824, 'f1': 0.8184, 'auc': 0.97978}
2025-08-23 09:29:30,649 - INFO - test: {'epoch': 17, 'time_epoch': 1.64412, 'loss': 0.44346266, 'lr': 0, 'params': 244937, 'time_iter': 0.0261, 'accuracy': 0.834, 'f1': 0.83299, 'auc': 0.98089}
2025-08-23 09:29:30,651 - INFO - > Epoch 17: took 16.1s (avg 16.3s) | Best so far: epoch 13	train_loss: 0.5288 train_accuracy: 0.8609	val_loss: 0.4897 val_accuracy: 0.8680	test_loss: 0.5161 test_accuracy: 0.8500
2025-08-23 09:29:44,225 - INFO - train: {'epoch': 18, 'time_epoch': 13.55635, 'eta': 1115.83371, 'eta_hours': 0.30995, 'loss': 0.37994479, 'lr': 0.00049032, 'params': 244937, 'time_iter': 0.0619, 'accuracy': 0.886, 'f1': 0.88621, 'auc': 0.97866}
2025-08-23 09:29:45,050 - INFO - val: {'epoch': 18, 'time_epoch': 0.81305, 'loss': 0.36842892, 'lr': 0, 'params': 244937, 'time_iter': 0.02541, 'accuracy': 0.906, 'f1': 0.9077, 'auc': 0.98271}
2025-08-23 09:29:46,693 - INFO - test: {'epoch': 18, 'time_epoch': 1.63165, 'loss': 0.37080492, 'lr': 0, 'params': 244937, 'time_iter': 0.0259, 'accuracy': 0.894, 'f1': 0.89654, 'auc': 0.98357}
2025-08-23 09:29:46,695 - INFO - > Epoch 18: took 16.0s (avg 16.3s) | Best so far: epoch 18	train_loss: 0.3799 train_accuracy: 0.8860	val_loss: 0.3684 val_accuracy: 0.9060	test_loss: 0.3708 test_accuracy: 0.8940
2025-08-23 09:30:00,238 - INFO - train: {'epoch': 19, 'time_epoch': 13.52732, 'eta': 1101.06436, 'eta_hours': 0.30585, 'loss': 0.3470427, 'lr': 0.00048776, 'params': 244937, 'time_iter': 0.06177, 'accuracy': 0.90114, 'f1': 0.9011, 'auc': 0.98082}
2025-08-23 09:30:01,048 - INFO - val: {'epoch': 19, 'time_epoch': 0.79941, 'loss': 0.42873433, 'lr': 0, 'params': 244937, 'time_iter': 0.02498, 'accuracy': 0.852, 'f1': 0.85614, 'auc': 0.97927}
2025-08-23 09:30:02,650 - INFO - test: {'epoch': 19, 'time_epoch': 1.59108, 'loss': 0.4202077, 'lr': 0, 'params': 244937, 'time_iter': 0.02526, 'accuracy': 0.866, 'f1': 0.86977, 'auc': 0.97855}
2025-08-23 09:30:02,652 - INFO - > Epoch 19: took 16.0s (avg 16.3s) | Best so far: epoch 18	train_loss: 0.3799 train_accuracy: 0.8860	val_loss: 0.3684 val_accuracy: 0.9060	test_loss: 0.3708 test_accuracy: 0.8940
2025-08-23 09:30:16,071 - INFO - train: {'epoch': 20, 'time_epoch': 13.40259, 'eta': 1085.9441, 'eta_hours': 0.30165, 'loss': 0.34999095, 'lr': 0.00048492, 'params': 244937, 'time_iter': 0.0612, 'accuracy': 0.89486, 'f1': 0.89515, 'auc': 0.98025}
2025-08-23 09:30:16,880 - INFO - val: {'epoch': 20, 'time_epoch': 0.79743, 'loss': 0.32271294, 'lr': 0, 'params': 244937, 'time_iter': 0.02492, 'accuracy': 0.91, 'f1': 0.91184, 'auc': 0.98479}
2025-08-23 09:30:18,500 - INFO - test: {'epoch': 20, 'time_epoch': 1.61046, 'loss': 0.33997077, 'lr': 0, 'params': 244937, 'time_iter': 0.02556, 'accuracy': 0.893, 'f1': 0.89426, 'auc': 0.98275}
2025-08-23 09:30:18,502 - INFO - > Epoch 20: took 15.8s (avg 16.3s) | Best so far: epoch 20	train_loss: 0.3500 train_accuracy: 0.8949	val_loss: 0.3227 val_accuracy: 0.9100	test_loss: 0.3400 test_accuracy: 0.8930
2025-08-23 09:30:31,974 - INFO - train: {'epoch': 21, 'time_epoch': 13.45535, 'eta': 1071.16702, 'eta_hours': 0.29755, 'loss': 0.34875764, 'lr': 0.0004818, 'params': 244937, 'time_iter': 0.06144, 'accuracy': 0.89686, 'f1': 0.89729, 'auc': 0.97969}
2025-08-23 09:30:32,796 - INFO - val: {'epoch': 21, 'time_epoch': 0.81029, 'loss': 0.34388495, 'lr': 0, 'params': 244937, 'time_iter': 0.02532, 'accuracy': 0.894, 'f1': 0.8955, 'auc': 0.98151}
2025-08-23 09:30:34,420 - INFO - test: {'epoch': 21, 'time_epoch': 1.61313, 'loss': 0.36480432, 'lr': 0, 'params': 244937, 'time_iter': 0.02561, 'accuracy': 0.882, 'f1': 0.88257, 'auc': 0.98186}
2025-08-23 09:30:34,422 - INFO - > Epoch 21: took 15.9s (avg 16.3s) | Best so far: epoch 20	train_loss: 0.3500 train_accuracy: 0.8949	val_loss: 0.3227 val_accuracy: 0.9100	test_loss: 0.3400 test_accuracy: 0.8930
2025-08-23 09:30:47,941 - INFO - train: {'epoch': 22, 'time_epoch': 13.50356, 'eta': 1056.66628, 'eta_hours': 0.29352, 'loss': 0.31555143, 'lr': 0.00047839, 'params': 244937, 'time_iter': 0.06166, 'accuracy': 0.90743, 'f1': 0.90814, 'auc': 0.9831}
2025-08-23 09:30:48,767 - INFO - val: {'epoch': 22, 'time_epoch': 0.81352, 'loss': 0.40233583, 'lr': 0, 'params': 244937, 'time_iter': 0.02542, 'accuracy': 0.87, 'f1': 0.86735, 'auc': 0.98207}
2025-08-23 09:30:50,431 - INFO - test: {'epoch': 22, 'time_epoch': 1.65268, 'loss': 0.39167134, 'lr': 0, 'params': 244937, 'time_iter': 0.02623, 'accuracy': 0.866, 'f1': 0.86234, 'auc': 0.98167}
2025-08-23 09:30:50,433 - INFO - > Epoch 22: took 16.0s (avg 16.3s) | Best so far: epoch 20	train_loss: 0.3500 train_accuracy: 0.8949	val_loss: 0.3227 val_accuracy: 0.9100	test_loss: 0.3400 test_accuracy: 0.8930
2025-08-23 09:31:04,024 - INFO - train: {'epoch': 23, 'time_epoch': 13.57439, 'eta': 1042.47296, 'eta_hours': 0.28958, 'loss': 0.31869719, 'lr': 0.0004747, 'params': 244937, 'time_iter': 0.06198, 'accuracy': 0.90171, 'f1': 0.90214, 'auc': 0.98207}
2025-08-23 09:31:04,840 - INFO - val: {'epoch': 23, 'time_epoch': 0.80486, 'loss': 0.3304395, 'lr': 0, 'params': 244937, 'time_iter': 0.02515, 'accuracy': 0.9, 'f1': 0.90113, 'auc': 0.98013}
2025-08-23 09:31:06,458 - INFO - test: {'epoch': 23, 'time_epoch': 1.60761, 'loss': 0.35660035, 'lr': 0, 'params': 244937, 'time_iter': 0.02552, 'accuracy': 0.877, 'f1': 0.87651, 'auc': 0.98183}
2025-08-23 09:31:06,461 - INFO - > Epoch 23: took 16.0s (avg 16.2s) | Best so far: epoch 20	train_loss: 0.3500 train_accuracy: 0.8949	val_loss: 0.3227 val_accuracy: 0.9100	test_loss: 0.3400 test_accuracy: 0.8930
2025-08-23 09:31:19,952 - INFO - train: {'epoch': 24, 'time_epoch': 13.47459, 'eta': 1028.02974, 'eta_hours': 0.28556, 'loss': 0.31519186, 'lr': 0.00047074, 'params': 244937, 'time_iter': 0.06153, 'accuracy': 0.90314, 'f1': 0.90383, 'auc': 0.98212}
2025-08-23 09:31:20,779 - INFO - val: {'epoch': 24, 'time_epoch': 0.81613, 'loss': 0.30674469, 'lr': 0, 'params': 244937, 'time_iter': 0.0255, 'accuracy': 0.91, 'f1': 0.91041, 'auc': 0.9839}
2025-08-23 09:31:22,441 - INFO - test: {'epoch': 24, 'time_epoch': 1.65008, 'loss': 0.31546191, 'lr': 0, 'params': 244937, 'time_iter': 0.02619, 'accuracy': 0.886, 'f1': 0.88568, 'auc': 0.98196}
2025-08-23 09:31:22,443 - INFO - > Epoch 24: took 16.0s (avg 16.2s) | Best so far: epoch 20	train_loss: 0.3500 train_accuracy: 0.8949	val_loss: 0.3227 val_accuracy: 0.9100	test_loss: 0.3400 test_accuracy: 0.8930
2025-08-23 09:31:36,036 - INFO - train: {'epoch': 25, 'time_epoch': 13.57716, 'eta': 1013.95295, 'eta_hours': 0.28165, 'loss': 0.30162563, 'lr': 0.00046651, 'params': 244937, 'time_iter': 0.062, 'accuracy': 0.90657, 'f1': 0.90712, 'auc': 0.98329}
2025-08-23 09:31:36,863 - INFO - val: {'epoch': 25, 'time_epoch': 0.81626, 'loss': 0.30348307, 'lr': 0, 'params': 244937, 'time_iter': 0.02551, 'accuracy': 0.898, 'f1': 0.90126, 'auc': 0.98548}
2025-08-23 09:31:38,500 - INFO - test: {'epoch': 25, 'time_epoch': 1.62638, 'loss': 0.30777196, 'lr': 0, 'params': 244937, 'time_iter': 0.02582, 'accuracy': 0.888, 'f1': 0.89009, 'auc': 0.98616}
2025-08-23 09:31:38,502 - INFO - > Epoch 25: took 16.1s (avg 16.2s) | Best so far: epoch 20	train_loss: 0.3500 train_accuracy: 0.8949	val_loss: 0.3227 val_accuracy: 0.9100	test_loss: 0.3400 test_accuracy: 0.8930
2025-08-23 09:31:52,048 - INFO - train: {'epoch': 26, 'time_epoch': 13.52921, 'eta': 999.78352, 'eta_hours': 0.27772, 'loss': 0.28636947, 'lr': 0.00046201, 'params': 244937, 'time_iter': 0.06178, 'accuracy': 0.90686, 'f1': 0.90705, 'auc': 0.98442}
2025-08-23 09:31:52,876 - INFO - val: {'epoch': 26, 'time_epoch': 0.81649, 'loss': 0.30771424, 'lr': 0, 'params': 244937, 'time_iter': 0.02552, 'accuracy': 0.902, 'f1': 0.90238, 'auc': 0.98524}
2025-08-23 09:31:54,537 - INFO - test: {'epoch': 26, 'time_epoch': 1.64919, 'loss': 0.33369217, 'lr': 0, 'params': 244937, 'time_iter': 0.02618, 'accuracy': 0.883, 'f1': 0.88267, 'auc': 0.98216}
2025-08-23 09:31:54,539 - INFO - > Epoch 26: took 16.0s (avg 16.2s) | Best so far: epoch 20	train_loss: 0.3500 train_accuracy: 0.8949	val_loss: 0.3227 val_accuracy: 0.9100	test_loss: 0.3400 test_accuracy: 0.8930
2025-08-23 09:32:08,112 - INFO - train: {'epoch': 27, 'time_epoch': 13.55679, 'eta': 985.73074, 'eta_hours': 0.27381, 'loss': 0.28959088, 'lr': 0.00045726, 'params': 244937, 'time_iter': 0.0619, 'accuracy': 0.906, 'f1': 0.90654, 'auc': 0.98409}
2025-08-23 09:32:08,939 - INFO - val: {'epoch': 27, 'time_epoch': 0.81533, 'loss': 0.28260413, 'lr': 0, 'params': 244937, 'time_iter': 0.02548, 'accuracy': 0.902, 'f1': 0.90318, 'auc': 0.98573}
2025-08-23 09:32:10,569 - INFO - test: {'epoch': 27, 'time_epoch': 1.61984, 'loss': 0.30830579, 'lr': 0, 'params': 244937, 'time_iter': 0.02571, 'accuracy': 0.885, 'f1': 0.88477, 'auc': 0.98437}
2025-08-23 09:32:10,571 - INFO - > Epoch 27: took 16.0s (avg 16.2s) | Best so far: epoch 20	train_loss: 0.3500 train_accuracy: 0.8949	val_loss: 0.3227 val_accuracy: 0.9100	test_loss: 0.3400 test_accuracy: 0.8930
2025-08-23 09:32:24,153 - INFO - train: {'epoch': 28, 'time_epoch': 13.56636, 'eta': 971.73561, 'eta_hours': 0.26993, 'loss': 0.28130453, 'lr': 0.00045225, 'params': 244937, 'time_iter': 0.06195, 'accuracy': 0.90771, 'f1': 0.90811, 'auc': 0.98482}
2025-08-23 09:32:24,982 - INFO - val: {'epoch': 28, 'time_epoch': 0.81694, 'loss': 0.30693572, 'lr': 0, 'params': 244937, 'time_iter': 0.02553, 'accuracy': 0.896, 'f1': 0.89487, 'auc': 0.98519}
2025-08-23 09:32:26,639 - INFO - test: {'epoch': 28, 'time_epoch': 1.6455, 'loss': 0.29200341, 'lr': 0, 'params': 244937, 'time_iter': 0.02612, 'accuracy': 0.903, 'f1': 0.90253, 'auc': 0.98588}
2025-08-23 09:32:26,640 - INFO - > Epoch 28: took 16.1s (avg 16.2s) | Best so far: epoch 20	train_loss: 0.3500 train_accuracy: 0.8949	val_loss: 0.3227 val_accuracy: 0.9100	test_loss: 0.3400 test_accuracy: 0.8930
2025-08-23 09:32:40,226 - INFO - train: {'epoch': 29, 'time_epoch': 13.5696, 'eta': 957.77662, 'eta_hours': 0.26605, 'loss': 0.27818272, 'lr': 0.000447, 'params': 244937, 'time_iter': 0.06196, 'accuracy': 0.90943, 'f1': 0.91007, 'auc': 0.98483}
2025-08-23 09:32:41,051 - INFO - val: {'epoch': 29, 'time_epoch': 0.81324, 'loss': 0.28316384, 'lr': 0, 'params': 244937, 'time_iter': 0.02541, 'accuracy': 0.904, 'f1': 0.90541, 'auc': 0.98618}
2025-08-23 09:32:42,695 - INFO - test: {'epoch': 29, 'time_epoch': 1.63315, 'loss': 0.27954286, 'lr': 0, 'params': 244937, 'time_iter': 0.02592, 'accuracy': 0.9, 'f1': 0.90062, 'auc': 0.98729}
2025-08-23 09:32:42,697 - INFO - > Epoch 29: took 16.1s (avg 16.2s) | Best so far: epoch 20	train_loss: 0.3500 train_accuracy: 0.8949	val_loss: 0.3227 val_accuracy: 0.9100	test_loss: 0.3400 test_accuracy: 0.8930
2025-08-23 09:32:56,266 - INFO - train: {'epoch': 30, 'time_epoch': 13.55386, 'eta': 943.80771, 'eta_hours': 0.26217, 'loss': 0.2702903, 'lr': 0.00044151, 'params': 244937, 'time_iter': 0.06189, 'accuracy': 0.91314, 'f1': 0.91328, 'auc': 0.98515}
2025-08-23 09:32:57,090 - INFO - val: {'epoch': 30, 'time_epoch': 0.81204, 'loss': 0.31009015, 'lr': 0, 'params': 244937, 'time_iter': 0.02538, 'accuracy': 0.894, 'f1': 0.89361, 'auc': 0.98427}
2025-08-23 09:32:58,740 - INFO - test: {'epoch': 30, 'time_epoch': 1.63804, 'loss': 0.33376925, 'lr': 0, 'params': 244937, 'time_iter': 0.026, 'accuracy': 0.881, 'f1': 0.87895, 'auc': 0.98254}
2025-08-23 09:32:58,742 - INFO - > Epoch 30: took 16.0s (avg 16.2s) | Best so far: epoch 20	train_loss: 0.3500 train_accuracy: 0.8949	val_loss: 0.3227 val_accuracy: 0.9100	test_loss: 0.3400 test_accuracy: 0.8930
2025-08-23 09:33:12,283 - INFO - train: {'epoch': 31, 'time_epoch': 13.52425, 'eta': 929.80182, 'eta_hours': 0.25828, 'loss': 0.26079915, 'lr': 0.00043579, 'params': 244937, 'time_iter': 0.06175, 'accuracy': 0.91314, 'f1': 0.91341, 'auc': 0.98537}
2025-08-23 09:33:13,099 - INFO - val: {'epoch': 31, 'time_epoch': 0.80428, 'loss': 0.28074521, 'lr': 0, 'params': 244937, 'time_iter': 0.02513, 'accuracy': 0.9, 'f1': 0.90137, 'auc': 0.98762}
2025-08-23 09:33:14,741 - INFO - test: {'epoch': 31, 'time_epoch': 1.63154, 'loss': 0.27093166, 'lr': 0, 'params': 244937, 'time_iter': 0.0259, 'accuracy': 0.905, 'f1': 0.90624, 'auc': 0.98741}
2025-08-23 09:33:14,742 - INFO - > Epoch 31: took 16.0s (avg 16.2s) | Best so far: epoch 20	train_loss: 0.3500 train_accuracy: 0.8949	val_loss: 0.3227 val_accuracy: 0.9100	test_loss: 0.3400 test_accuracy: 0.8930
2025-08-23 09:33:28,248 - INFO - train: {'epoch': 32, 'time_epoch': 13.48836, 'eta': 915.75226, 'eta_hours': 0.25438, 'loss': 0.2535209, 'lr': 0.00042983, 'params': 244937, 'time_iter': 0.06159, 'accuracy': 0.92114, 'f1': 0.92153, 'auc': 0.98656}
2025-08-23 09:33:29,071 - INFO - val: {'epoch': 32, 'time_epoch': 0.81167, 'loss': 0.28531099, 'lr': 0, 'params': 244937, 'time_iter': 0.02536, 'accuracy': 0.904, 'f1': 0.90376, 'auc': 0.9865}
2025-08-23 09:33:30,706 - INFO - test: {'epoch': 32, 'time_epoch': 1.62441, 'loss': 0.27652054, 'lr': 0, 'params': 244937, 'time_iter': 0.02578, 'accuracy': 0.898, 'f1': 0.89753, 'auc': 0.98598}
2025-08-23 09:33:30,708 - INFO - > Epoch 32: took 16.0s (avg 16.2s) | Best so far: epoch 20	train_loss: 0.3500 train_accuracy: 0.8949	val_loss: 0.3227 val_accuracy: 0.9100	test_loss: 0.3400 test_accuracy: 0.8930
2025-08-23 09:33:44,251 - INFO - train: {'epoch': 33, 'time_epoch': 13.52598, 'eta': 901.80874, 'eta_hours': 0.2505, 'loss': 0.26343004, 'lr': 0.00042366, 'params': 244937, 'time_iter': 0.06176, 'accuracy': 0.916, 'f1': 0.91631, 'auc': 0.98544}
2025-08-23 09:33:45,076 - INFO - val: {'epoch': 33, 'time_epoch': 0.81299, 'loss': 0.26567897, 'lr': 0, 'params': 244937, 'time_iter': 0.02541, 'accuracy': 0.922, 'f1': 0.92224, 'auc': 0.98693}
2025-08-23 09:33:46,724 - INFO - test: {'epoch': 33, 'time_epoch': 1.63659, 'loss': 0.27074555, 'lr': 0, 'params': 244937, 'time_iter': 0.02598, 'accuracy': 0.905, 'f1': 0.90486, 'auc': 0.98662}
2025-08-23 09:33:46,725 - INFO - > Epoch 33: took 16.0s (avg 16.2s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:34:00,295 - INFO - train: {'epoch': 34, 'time_epoch': 13.55254, 'eta': 887.93839, 'eta_hours': 0.24665, 'loss': 0.25186985, 'lr': 0.00041728, 'params': 244937, 'time_iter': 0.06188, 'accuracy': 0.91571, 'f1': 0.91611, 'auc': 0.98603}
2025-08-23 09:34:01,121 - INFO - val: {'epoch': 34, 'time_epoch': 0.81312, 'loss': 0.26225102, 'lr': 0, 'params': 244937, 'time_iter': 0.02541, 'accuracy': 0.916, 'f1': 0.91535, 'auc': 0.98795}
2025-08-23 09:34:02,765 - INFO - test: {'epoch': 34, 'time_epoch': 1.63331, 'loss': 0.25027903, 'lr': 0, 'params': 244937, 'time_iter': 0.02593, 'accuracy': 0.914, 'f1': 0.91385, 'auc': 0.98776}
2025-08-23 09:34:02,767 - INFO - > Epoch 34: took 16.0s (avg 16.2s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:34:16,206 - INFO - train: {'epoch': 35, 'time_epoch': 13.42269, 'eta': 873.85487, 'eta_hours': 0.24274, 'loss': 0.24119573, 'lr': 0.0004107, 'params': 244937, 'time_iter': 0.06129, 'accuracy': 0.92, 'f1': 0.92025, 'auc': 0.98693}
2025-08-23 09:34:17,042 - INFO - val: {'epoch': 35, 'time_epoch': 0.82498, 'loss': 0.27828282, 'lr': 0, 'params': 244937, 'time_iter': 0.02578, 'accuracy': 0.908, 'f1': 0.90671, 'auc': 0.98757}
2025-08-23 09:34:18,682 - INFO - test: {'epoch': 35, 'time_epoch': 1.62921, 'loss': 0.26266224, 'lr': 0, 'params': 244937, 'time_iter': 0.02586, 'accuracy': 0.91, 'f1': 0.90887, 'auc': 0.98733}
2025-08-23 09:34:18,684 - INFO - > Epoch 35: took 15.9s (avg 16.2s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:34:32,217 - INFO - train: {'epoch': 36, 'time_epoch': 13.51665, 'eta': 859.96705, 'eta_hours': 0.23888, 'loss': 0.24859019, 'lr': 0.00040392, 'params': 244937, 'time_iter': 0.06172, 'accuracy': 0.91714, 'f1': 0.91734, 'auc': 0.98637}
2025-08-23 09:34:33,035 - INFO - val: {'epoch': 36, 'time_epoch': 0.80737, 'loss': 0.27523916, 'lr': 0, 'params': 244937, 'time_iter': 0.02523, 'accuracy': 0.908, 'f1': 0.91074, 'auc': 0.98795}
2025-08-23 09:34:34,683 - INFO - test: {'epoch': 36, 'time_epoch': 1.63622, 'loss': 0.31144225, 'lr': 0, 'params': 244937, 'time_iter': 0.02597, 'accuracy': 0.889, 'f1': 0.89125, 'auc': 0.98647}
2025-08-23 09:34:34,685 - INFO - > Epoch 36: took 16.0s (avg 16.2s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:34:48,231 - INFO - train: {'epoch': 37, 'time_epoch': 13.5282, 'eta': 846.11761, 'eta_hours': 0.23503, 'loss': 0.24504678, 'lr': 0.00039695, 'params': 244937, 'time_iter': 0.06177, 'accuracy': 0.92343, 'f1': 0.92372, 'auc': 0.98664}
2025-08-23 09:34:49,055 - INFO - val: {'epoch': 37, 'time_epoch': 0.81254, 'loss': 0.25434373, 'lr': 0, 'params': 244937, 'time_iter': 0.02539, 'accuracy': 0.91, 'f1': 0.909, 'auc': 0.98951}
2025-08-23 09:34:50,700 - INFO - test: {'epoch': 37, 'time_epoch': 1.63349, 'loss': 0.28650012, 'lr': 0, 'params': 244937, 'time_iter': 0.02593, 'accuracy': 0.892, 'f1': 0.89117, 'auc': 0.98621}
2025-08-23 09:34:50,701 - INFO - > Epoch 37: took 16.0s (avg 16.2s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:35:04,157 - INFO - train: {'epoch': 38, 'time_epoch': 13.43877, 'eta': 832.14477, 'eta_hours': 0.23115, 'loss': 0.24769434, 'lr': 0.0003898, 'params': 244937, 'time_iter': 0.06136, 'accuracy': 0.91914, 'f1': 0.91939, 'auc': 0.98781}
2025-08-23 09:35:04,959 - INFO - val: {'epoch': 38, 'time_epoch': 0.79033, 'loss': 0.22394132, 'lr': 0, 'params': 244937, 'time_iter': 0.0247, 'accuracy': 0.922, 'f1': 0.92379, 'auc': 0.99038}
2025-08-23 09:35:06,572 - INFO - test: {'epoch': 38, 'time_epoch': 1.60099, 'loss': 0.25595074, 'lr': 0, 'params': 244937, 'time_iter': 0.02541, 'accuracy': 0.898, 'f1': 0.8994, 'auc': 0.98838}
2025-08-23 09:35:06,574 - INFO - > Epoch 38: took 15.9s (avg 16.2s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:35:19,796 - INFO - train: {'epoch': 39, 'time_epoch': 13.20601, 'eta': 817.84948, 'eta_hours': 0.22718, 'loss': 0.23660928, 'lr': 0.00038248, 'params': 244937, 'time_iter': 0.0603, 'accuracy': 0.91943, 'f1': 0.91975, 'auc': 0.98834}
2025-08-23 09:35:20,631 - INFO - val: {'epoch': 39, 'time_epoch': 0.82246, 'loss': 0.26843019, 'lr': 0, 'params': 244937, 'time_iter': 0.0257, 'accuracy': 0.908, 'f1': 0.911, 'auc': 0.989}
2025-08-23 09:35:22,284 - INFO - test: {'epoch': 39, 'time_epoch': 1.64115, 'loss': 0.32792986, 'lr': 0, 'params': 244937, 'time_iter': 0.02605, 'accuracy': 0.887, 'f1': 0.88948, 'auc': 0.98691}
2025-08-23 09:35:22,286 - INFO - > Epoch 39: took 15.7s (avg 16.1s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:35:35,846 - INFO - train: {'epoch': 40, 'time_epoch': 13.54331, 'eta': 804.09273, 'eta_hours': 0.22336, 'loss': 0.23722427, 'lr': 0.000375, 'params': 244937, 'time_iter': 0.06184, 'accuracy': 0.92286, 'f1': 0.92303, 'auc': 0.98686}
2025-08-23 09:35:36,671 - INFO - val: {'epoch': 40, 'time_epoch': 0.81312, 'loss': 0.23451991, 'lr': 0, 'params': 244937, 'time_iter': 0.02541, 'accuracy': 0.922, 'f1': 0.92241, 'auc': 0.9881}
2025-08-23 09:35:38,309 - INFO - test: {'epoch': 40, 'time_epoch': 1.62732, 'loss': 0.2309054, 'lr': 0, 'params': 244937, 'time_iter': 0.02583, 'accuracy': 0.908, 'f1': 0.90837, 'auc': 0.98967}
2025-08-23 09:35:38,311 - INFO - > Epoch 40: took 16.0s (avg 16.1s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:35:51,805 - INFO - train: {'epoch': 41, 'time_epoch': 13.47744, 'eta': 790.25518, 'eta_hours': 0.21952, 'loss': 0.22566786, 'lr': 0.00036737, 'params': 244937, 'time_iter': 0.06154, 'accuracy': 0.92114, 'f1': 0.92154, 'auc': 0.98823}
2025-08-23 09:35:52,631 - INFO - val: {'epoch': 41, 'time_epoch': 0.81444, 'loss': 0.24262041, 'lr': 0, 'params': 244937, 'time_iter': 0.02545, 'accuracy': 0.92, 'f1': 0.92122, 'auc': 0.98832}
2025-08-23 09:35:54,286 - INFO - test: {'epoch': 41, 'time_epoch': 1.64296, 'loss': 0.26298861, 'lr': 0, 'params': 244937, 'time_iter': 0.02608, 'accuracy': 0.899, 'f1': 0.90034, 'auc': 0.98841}
2025-08-23 09:35:54,288 - INFO - > Epoch 41: took 16.0s (avg 16.1s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:36:07,906 - INFO - train: {'epoch': 42, 'time_epoch': 13.59937, 'eta': 776.596, 'eta_hours': 0.21572, 'loss': 0.2161872, 'lr': 0.00035959, 'params': 244937, 'time_iter': 0.0621, 'accuracy': 0.92686, 'f1': 0.92722, 'auc': 0.9888}
2025-08-23 09:36:08,730 - INFO - val: {'epoch': 42, 'time_epoch': 0.81226, 'loss': 0.24005886, 'lr': 0, 'params': 244937, 'time_iter': 0.02538, 'accuracy': 0.916, 'f1': 0.91569, 'auc': 0.98831}
2025-08-23 09:36:10,370 - INFO - test: {'epoch': 42, 'time_epoch': 1.62902, 'loss': 0.23130734, 'lr': 0, 'params': 244937, 'time_iter': 0.02586, 'accuracy': 0.912, 'f1': 0.91214, 'auc': 0.98822}
2025-08-23 09:36:10,373 - INFO - > Epoch 42: took 16.1s (avg 16.1s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:36:23,880 - INFO - train: {'epoch': 43, 'time_epoch': 13.49053, 'eta': 762.80101, 'eta_hours': 0.21189, 'loss': 0.2238441, 'lr': 0.00035168, 'params': 244937, 'time_iter': 0.0616, 'accuracy': 0.92743, 'f1': 0.9277, 'auc': 0.98871}
2025-08-23 09:36:24,709 - INFO - val: {'epoch': 43, 'time_epoch': 0.81732, 'loss': 0.25820312, 'lr': 0, 'params': 244937, 'time_iter': 0.02554, 'accuracy': 0.918, 'f1': 0.91924, 'auc': 0.98885}
2025-08-23 09:36:26,353 - INFO - test: {'epoch': 43, 'time_epoch': 1.63228, 'loss': 0.26762161, 'lr': 0, 'params': 244937, 'time_iter': 0.02591, 'accuracy': 0.903, 'f1': 0.90445, 'auc': 0.98833}
2025-08-23 09:36:26,355 - INFO - > Epoch 43: took 16.0s (avg 16.1s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:36:39,916 - INFO - train: {'epoch': 44, 'time_epoch': 13.54474, 'eta': 749.0858, 'eta_hours': 0.20808, 'loss': 0.21914292, 'lr': 0.00034365, 'params': 244937, 'time_iter': 0.06185, 'accuracy': 0.928, 'f1': 0.92832, 'auc': 0.98893}
2025-08-23 09:36:40,762 - INFO - val: {'epoch': 44, 'time_epoch': 0.83243, 'loss': 0.24684466, 'lr': 0, 'params': 244937, 'time_iter': 0.02601, 'accuracy': 0.922, 'f1': 0.92302, 'auc': 0.98867}
2025-08-23 09:36:42,419 - INFO - test: {'epoch': 44, 'time_epoch': 1.6457, 'loss': 0.28218497, 'lr': 0, 'params': 244937, 'time_iter': 0.02612, 'accuracy': 0.905, 'f1': 0.90492, 'auc': 0.98713}
2025-08-23 09:36:42,421 - INFO - > Epoch 44: took 16.1s (avg 16.1s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:36:55,986 - INFO - train: {'epoch': 45, 'time_epoch': 13.54934, 'eta': 735.38342, 'eta_hours': 0.20427, 'loss': 0.22022264, 'lr': 0.00033551, 'params': 244937, 'time_iter': 0.06187, 'accuracy': 0.926, 'f1': 0.92642, 'auc': 0.98865}
2025-08-23 09:36:56,815 - INFO - val: {'epoch': 45, 'time_epoch': 0.81828, 'loss': 0.3034011, 'lr': 0, 'params': 244937, 'time_iter': 0.02557, 'accuracy': 0.914, 'f1': 0.91424, 'auc': 0.98656}
2025-08-23 09:36:58,458 - INFO - test: {'epoch': 45, 'time_epoch': 1.63167, 'loss': 0.29294132, 'lr': 0, 'params': 244937, 'time_iter': 0.0259, 'accuracy': 0.912, 'f1': 0.91176, 'auc': 0.9858}
2025-08-23 09:36:58,460 - INFO - > Epoch 45: took 16.0s (avg 16.1s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:37:12,010 - INFO - train: {'epoch': 46, 'time_epoch': 13.53515, 'eta': 721.67154, 'eta_hours': 0.20046, 'loss': 0.21121199, 'lr': 0.00032725, 'params': 244937, 'time_iter': 0.0618, 'accuracy': 0.92829, 'f1': 0.92849, 'auc': 0.9899}
2025-08-23 09:37:12,848 - INFO - val: {'epoch': 46, 'time_epoch': 0.82548, 'loss': 0.24616389, 'lr': 0, 'params': 244937, 'time_iter': 0.0258, 'accuracy': 0.912, 'f1': 0.91372, 'auc': 0.98842}
2025-08-23 09:37:14,490 - INFO - test: {'epoch': 46, 'time_epoch': 1.63036, 'loss': 0.22207664, 'lr': 0, 'params': 244937, 'time_iter': 0.02588, 'accuracy': 0.916, 'f1': 0.91774, 'auc': 0.98955}
2025-08-23 09:37:14,492 - INFO - > Epoch 46: took 16.0s (avg 16.1s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:37:28,017 - INFO - train: {'epoch': 47, 'time_epoch': 13.50965, 'eta': 707.9394, 'eta_hours': 0.19665, 'loss': 0.20081135, 'lr': 0.00031891, 'params': 244937, 'time_iter': 0.06169, 'accuracy': 0.932, 'f1': 0.93234, 'auc': 0.99079}
2025-08-23 09:37:28,838 - INFO - val: {'epoch': 47, 'time_epoch': 0.80878, 'loss': 0.24027555, 'lr': 0, 'params': 244937, 'time_iter': 0.02527, 'accuracy': 0.922, 'f1': 0.92144, 'auc': 0.9875}
2025-08-23 09:37:30,489 - INFO - test: {'epoch': 47, 'time_epoch': 1.63909, 'loss': 0.24140469, 'lr': 0, 'params': 244937, 'time_iter': 0.02602, 'accuracy': 0.914, 'f1': 0.91331, 'auc': 0.98976}
2025-08-23 09:37:30,491 - INFO - > Epoch 47: took 16.0s (avg 16.1s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:37:44,013 - INFO - train: {'epoch': 48, 'time_epoch': 13.50672, 'eta': 694.21329, 'eta_hours': 0.19284, 'loss': 0.1977459, 'lr': 0.00031048, 'params': 244937, 'time_iter': 0.06167, 'accuracy': 0.93286, 'f1': 0.93303, 'auc': 0.99076}
2025-08-23 09:37:44,850 - INFO - val: {'epoch': 48, 'time_epoch': 0.82622, 'loss': 0.28189278, 'lr': 0, 'params': 244937, 'time_iter': 0.02582, 'accuracy': 0.914, 'f1': 0.91341, 'auc': 0.98842}
2025-08-23 09:37:46,470 - INFO - test: {'epoch': 48, 'time_epoch': 1.60871, 'loss': 0.31841761, 'lr': 0, 'params': 244937, 'time_iter': 0.02554, 'accuracy': 0.894, 'f1': 0.89217, 'auc': 0.98467}
2025-08-23 09:37:46,471 - INFO - > Epoch 48: took 16.0s (avg 16.1s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:37:59,963 - INFO - train: {'epoch': 49, 'time_epoch': 13.47632, 'eta': 680.46556, 'eta_hours': 0.18902, 'loss': 0.20417242, 'lr': 0.00030198, 'params': 244937, 'time_iter': 0.06154, 'accuracy': 0.93086, 'f1': 0.93098, 'auc': 0.99077}
2025-08-23 09:38:00,784 - INFO - val: {'epoch': 49, 'time_epoch': 0.80998, 'loss': 0.23349112, 'lr': 0, 'params': 244937, 'time_iter': 0.02531, 'accuracy': 0.922, 'f1': 0.92273, 'auc': 0.98817}
2025-08-23 09:38:02,437 - INFO - test: {'epoch': 49, 'time_epoch': 1.64183, 'loss': 0.28892104, 'lr': 0, 'params': 244937, 'time_iter': 0.02606, 'accuracy': 0.904, 'f1': 0.90347, 'auc': 0.98898}
2025-08-23 09:38:02,439 - INFO - > Epoch 49: took 16.0s (avg 16.1s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:38:15,949 - INFO - train: {'epoch': 50, 'time_epoch': 13.49579, 'eta': 666.74717, 'eta_hours': 0.18521, 'loss': 0.1984068, 'lr': 0.00029341, 'params': 244937, 'time_iter': 0.06162, 'accuracy': 0.93343, 'f1': 0.93348, 'auc': 0.99109}
2025-08-23 09:38:16,768 - INFO - val: {'epoch': 50, 'time_epoch': 0.8071, 'loss': 0.24922626, 'lr': 0, 'params': 244937, 'time_iter': 0.02522, 'accuracy': 0.914, 'f1': 0.91444, 'auc': 0.98822}
2025-08-23 09:38:18,407 - INFO - test: {'epoch': 50, 'time_epoch': 1.62857, 'loss': 0.21116224, 'lr': 0, 'params': 244937, 'time_iter': 0.02585, 'accuracy': 0.926, 'f1': 0.92682, 'auc': 0.99059}
2025-08-23 09:38:18,409 - INFO - > Epoch 50: took 16.0s (avg 16.1s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:38:31,933 - INFO - train: {'epoch': 51, 'time_epoch': 13.50795, 'eta': 653.04858, 'eta_hours': 0.1814, 'loss': 0.19741031, 'lr': 0.00028479, 'params': 244937, 'time_iter': 0.06168, 'accuracy': 0.93286, 'f1': 0.93305, 'auc': 0.99091}
2025-08-23 09:38:32,758 - INFO - val: {'epoch': 51, 'time_epoch': 0.81409, 'loss': 0.24289955, 'lr': 0, 'params': 244937, 'time_iter': 0.02544, 'accuracy': 0.92, 'f1': 0.92012, 'auc': 0.98811}
2025-08-23 09:38:34,394 - INFO - test: {'epoch': 51, 'time_epoch': 1.6248, 'loss': 0.20774786, 'lr': 0, 'params': 244937, 'time_iter': 0.02579, 'accuracy': 0.929, 'f1': 0.92908, 'auc': 0.9912}
2025-08-23 09:38:34,396 - INFO - > Epoch 51: took 16.0s (avg 16.1s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:38:47,897 - INFO - train: {'epoch': 52, 'time_epoch': 13.48487, 'eta': 639.33672, 'eta_hours': 0.17759, 'loss': 0.19213016, 'lr': 0.00027613, 'params': 244937, 'time_iter': 0.06157, 'accuracy': 0.93229, 'f1': 0.93254, 'auc': 0.9919}
2025-08-23 09:38:48,708 - INFO - val: {'epoch': 52, 'time_epoch': 0.80019, 'loss': 0.24403569, 'lr': 0, 'params': 244937, 'time_iter': 0.02501, 'accuracy': 0.922, 'f1': 0.92233, 'auc': 0.98757}
2025-08-23 09:38:50,324 - INFO - test: {'epoch': 52, 'time_epoch': 1.60573, 'loss': 0.21765258, 'lr': 0, 'params': 244937, 'time_iter': 0.02549, 'accuracy': 0.928, 'f1': 0.92836, 'auc': 0.99016}
2025-08-23 09:38:50,326 - INFO - > Epoch 52: took 15.9s (avg 16.1s) | Best so far: epoch 33	train_loss: 0.2634 train_accuracy: 0.9160	val_loss: 0.2657 val_accuracy: 0.9220	test_loss: 0.2707 test_accuracy: 0.9050
2025-08-23 09:39:03,683 - INFO - train: {'epoch': 53, 'time_epoch': 13.3425, 'eta': 625.51198, 'eta_hours': 0.17375, 'loss': 0.1901551, 'lr': 0.00026744, 'params': 244937, 'time_iter': 0.06092, 'accuracy': 0.938, 'f1': 0.93807, 'auc': 0.99059}
2025-08-23 09:39:04,486 - INFO - val: {'epoch': 53, 'time_epoch': 0.79221, 'loss': 0.23164908, 'lr': 0, 'params': 244937, 'time_iter': 0.02476, 'accuracy': 0.924, 'f1': 0.92497, 'auc': 0.98835}
2025-08-23 09:39:06,101 - INFO - test: {'epoch': 53, 'time_epoch': 1.60441, 'loss': 0.22840256, 'lr': 0, 'params': 244937, 'time_iter': 0.02547, 'accuracy': 0.918, 'f1': 0.91929, 'auc': 0.99083}
2025-08-23 09:39:06,103 - INFO - > Epoch 53: took 15.8s (avg 16.1s) | Best so far: epoch 53	train_loss: 0.1902 train_accuracy: 0.9380	val_loss: 0.2316 val_accuracy: 0.9240	test_loss: 0.2284 test_accuracy: 0.9180
2025-08-23 09:39:19,620 - INFO - train: {'epoch': 54, 'time_epoch': 13.50201, 'eta': 611.83529, 'eta_hours': 0.16995, 'loss': 0.18383835, 'lr': 0.00025872, 'params': 244937, 'time_iter': 0.06165, 'accuracy': 0.94057, 'f1': 0.94074, 'auc': 0.9921}
2025-08-23 09:39:20,436 - INFO - val: {'epoch': 54, 'time_epoch': 0.80434, 'loss': 0.24331035, 'lr': 0, 'params': 244937, 'time_iter': 0.02514, 'accuracy': 0.92, 'f1': 0.91957, 'auc': 0.98847}
2025-08-23 09:39:22,071 - INFO - test: {'epoch': 54, 'time_epoch': 1.62365, 'loss': 0.21049221, 'lr': 0, 'params': 244937, 'time_iter': 0.02577, 'accuracy': 0.92, 'f1': 0.92014, 'auc': 0.99131}
2025-08-23 09:39:22,072 - INFO - > Epoch 54: took 16.0s (avg 16.1s) | Best so far: epoch 53	train_loss: 0.1902 train_accuracy: 0.9380	val_loss: 0.2316 val_accuracy: 0.9240	test_loss: 0.2284 test_accuracy: 0.9180
2025-08-23 09:39:35,557 - INFO - train: {'epoch': 55, 'time_epoch': 13.47, 'eta': 598.13968, 'eta_hours': 0.16615, 'loss': 0.18502905, 'lr': 0.00025, 'params': 244937, 'time_iter': 0.06151, 'accuracy': 0.938, 'f1': 0.93805, 'auc': 0.99155}
2025-08-23 09:39:36,377 - INFO - val: {'epoch': 55, 'time_epoch': 0.80896, 'loss': 0.23891579, 'lr': 0, 'params': 244937, 'time_iter': 0.02528, 'accuracy': 0.926, 'f1': 0.92716, 'auc': 0.98879}
2025-08-23 09:39:38,019 - INFO - test: {'epoch': 55, 'time_epoch': 1.63118, 'loss': 0.22254536, 'lr': 0, 'params': 244937, 'time_iter': 0.02589, 'accuracy': 0.923, 'f1': 0.92401, 'auc': 0.99083}
2025-08-23 09:39:38,021 - INFO - > Epoch 55: took 15.9s (avg 16.1s) | Best so far: epoch 55	train_loss: 0.1850 train_accuracy: 0.9380	val_loss: 0.2389 val_accuracy: 0.9260	test_loss: 0.2225 test_accuracy: 0.9230
2025-08-23 09:39:51,499 - INFO - train: {'epoch': 56, 'time_epoch': 13.46295, 'eta': 584.44667, 'eta_hours': 0.16235, 'loss': 0.18948068, 'lr': 0.00024128, 'params': 244937, 'time_iter': 0.06147, 'accuracy': 0.93771, 'f1': 0.93795, 'auc': 0.99142}
2025-08-23 09:39:52,325 - INFO - val: {'epoch': 56, 'time_epoch': 0.81495, 'loss': 0.21293757, 'lr': 0, 'params': 244937, 'time_iter': 0.02547, 'accuracy': 0.928, 'f1': 0.92907, 'auc': 0.99222}
2025-08-23 09:39:53,951 - INFO - test: {'epoch': 56, 'time_epoch': 1.61551, 'loss': 0.2315138, 'lr': 0, 'params': 244937, 'time_iter': 0.02564, 'accuracy': 0.918, 'f1': 0.91923, 'auc': 0.99093}
2025-08-23 09:39:53,953 - INFO - > Epoch 56: took 15.9s (avg 16.1s) | Best so far: epoch 56	train_loss: 0.1895 train_accuracy: 0.9377	val_loss: 0.2129 val_accuracy: 0.9280	test_loss: 0.2315 test_accuracy: 0.9180
2025-08-23 09:40:07,383 - INFO - train: {'epoch': 57, 'time_epoch': 13.41568, 'eta': 570.72736, 'eta_hours': 0.15854, 'loss': 0.18046915, 'lr': 0.00023256, 'params': 244937, 'time_iter': 0.06126, 'accuracy': 0.93857, 'f1': 0.93877, 'auc': 0.9922}
2025-08-23 09:40:08,188 - INFO - val: {'epoch': 57, 'time_epoch': 0.79396, 'loss': 0.23036888, 'lr': 0, 'params': 244937, 'time_iter': 0.02481, 'accuracy': 0.92, 'f1': 0.92118, 'auc': 0.98995}
2025-08-23 09:40:09,810 - INFO - test: {'epoch': 57, 'time_epoch': 1.61223, 'loss': 0.21217551, 'lr': 0, 'params': 244937, 'time_iter': 0.02559, 'accuracy': 0.933, 'f1': 0.93388, 'auc': 0.98974}
2025-08-23 09:40:09,812 - INFO - > Epoch 57: took 15.9s (avg 16.1s) | Best so far: epoch 56	train_loss: 0.1895 train_accuracy: 0.9377	val_loss: 0.2129 val_accuracy: 0.9280	test_loss: 0.2315 test_accuracy: 0.9180
2025-08-23 09:40:23,278 - INFO - train: {'epoch': 58, 'time_epoch': 13.44918, 'eta': 557.04163, 'eta_hours': 0.15473, 'loss': 0.1782533, 'lr': 0.00022387, 'params': 244937, 'time_iter': 0.06141, 'accuracy': 0.94057, 'f1': 0.94062, 'auc': 0.99176}
2025-08-23 09:40:24,113 - INFO - val: {'epoch': 58, 'time_epoch': 0.82373, 'loss': 0.23220146, 'lr': 0, 'params': 244937, 'time_iter': 0.02574, 'accuracy': 0.928, 'f1': 0.92706, 'auc': 0.98984}
2025-08-23 09:40:25,745 - INFO - test: {'epoch': 58, 'time_epoch': 1.62157, 'loss': 0.21360569, 'lr': 0, 'params': 244937, 'time_iter': 0.02574, 'accuracy': 0.925, 'f1': 0.92454, 'auc': 0.99115}
2025-08-23 09:40:25,747 - INFO - > Epoch 58: took 15.9s (avg 16.1s) | Best so far: epoch 56	train_loss: 0.1895 train_accuracy: 0.9377	val_loss: 0.2129 val_accuracy: 0.9280	test_loss: 0.2315 test_accuracy: 0.9180
2025-08-23 09:40:39,179 - INFO - train: {'epoch': 59, 'time_epoch': 13.41608, 'eta': 543.34172, 'eta_hours': 0.15093, 'loss': 0.16540994, 'lr': 0.00021521, 'params': 244937, 'time_iter': 0.06126, 'accuracy': 0.948, 'f1': 0.94793, 'auc': 0.99342}
2025-08-23 09:40:39,985 - INFO - val: {'epoch': 59, 'time_epoch': 0.79543, 'loss': 0.22547984, 'lr': 0, 'params': 244937, 'time_iter': 0.02486, 'accuracy': 0.922, 'f1': 0.92164, 'auc': 0.99068}
2025-08-23 09:40:41,594 - INFO - test: {'epoch': 59, 'time_epoch': 1.59939, 'loss': 0.20861877, 'lr': 0, 'params': 244937, 'time_iter': 0.02539, 'accuracy': 0.929, 'f1': 0.92912, 'auc': 0.9912}
2025-08-23 09:40:41,596 - INFO - > Epoch 59: took 15.8s (avg 16.1s) | Best so far: epoch 56	train_loss: 0.1895 train_accuracy: 0.9377	val_loss: 0.2129 val_accuracy: 0.9280	test_loss: 0.2315 test_accuracy: 0.9180
2025-08-23 09:40:55,003 - INFO - train: {'epoch': 60, 'time_epoch': 13.39142, 'eta': 529.63534, 'eta_hours': 0.14712, 'loss': 0.16737465, 'lr': 0.00020659, 'params': 244937, 'time_iter': 0.06115, 'accuracy': 0.94314, 'f1': 0.94313, 'auc': 0.99307}
2025-08-23 09:40:55,819 - INFO - val: {'epoch': 60, 'time_epoch': 0.80487, 'loss': 0.22727961, 'lr': 0, 'params': 244937, 'time_iter': 0.02515, 'accuracy': 0.93, 'f1': 0.93093, 'auc': 0.99118}
2025-08-23 09:40:57,461 - INFO - test: {'epoch': 60, 'time_epoch': 1.63039, 'loss': 0.22944647, 'lr': 0, 'params': 244937, 'time_iter': 0.02588, 'accuracy': 0.922, 'f1': 0.92278, 'auc': 0.99087}
2025-08-23 09:40:57,463 - INFO - > Epoch 60: took 15.9s (avg 16.1s) | Best so far: epoch 60	train_loss: 0.1674 train_accuracy: 0.9431	val_loss: 0.2273 val_accuracy: 0.9300	test_loss: 0.2294 test_accuracy: 0.9220
2025-08-23 09:41:10,893 - INFO - train: {'epoch': 61, 'time_epoch': 13.41461, 'eta': 515.95334, 'eta_hours': 0.14332, 'loss': 0.17295285, 'lr': 0.00019802, 'params': 244937, 'time_iter': 0.06125, 'accuracy': 0.94257, 'f1': 0.94264, 'auc': 0.99243}
2025-08-23 09:41:11,710 - INFO - val: {'epoch': 61, 'time_epoch': 0.80553, 'loss': 0.23307409, 'lr': 0, 'params': 244937, 'time_iter': 0.02517, 'accuracy': 0.926, 'f1': 0.92641, 'auc': 0.99005}
2025-08-23 09:41:13,336 - INFO - test: {'epoch': 61, 'time_epoch': 1.61525, 'loss': 0.21666999, 'lr': 0, 'params': 244937, 'time_iter': 0.02564, 'accuracy': 0.926, 'f1': 0.92657, 'auc': 0.99086}
2025-08-23 09:41:13,338 - INFO - > Epoch 61: took 15.9s (avg 16.1s) | Best so far: epoch 60	train_loss: 0.1674 train_accuracy: 0.9431	val_loss: 0.2273 val_accuracy: 0.9300	test_loss: 0.2294 test_accuracy: 0.9220
2025-08-23 09:41:26,795 - INFO - train: {'epoch': 62, 'time_epoch': 13.44051, 'eta': 502.29503, 'eta_hours': 0.13953, 'loss': 0.1625164, 'lr': 0.00018952, 'params': 244937, 'time_iter': 0.06137, 'accuracy': 0.94429, 'f1': 0.9444, 'auc': 0.9931}
2025-08-23 09:41:27,617 - INFO - val: {'epoch': 62, 'time_epoch': 0.81056, 'loss': 0.24095786, 'lr': 0, 'params': 244937, 'time_iter': 0.02533, 'accuracy': 0.926, 'f1': 0.92663, 'auc': 0.98987}
2025-08-23 09:41:29,264 - INFO - test: {'epoch': 62, 'time_epoch': 1.6352, 'loss': 0.23744101, 'lr': 0, 'params': 244937, 'time_iter': 0.02596, 'accuracy': 0.924, 'f1': 0.92488, 'auc': 0.9895}
2025-08-23 09:41:29,266 - INFO - > Epoch 62: took 15.9s (avg 16.1s) | Best so far: epoch 60	train_loss: 0.1674 train_accuracy: 0.9431	val_loss: 0.2273 val_accuracy: 0.9300	test_loss: 0.2294 test_accuracy: 0.9220
2025-08-23 09:41:42,725 - INFO - train: {'epoch': 63, 'time_epoch': 13.44207, 'eta': 488.64441, 'eta_hours': 0.13573, 'loss': 0.15697668, 'lr': 0.00018109, 'params': 244937, 'time_iter': 0.06138, 'accuracy': 0.94857, 'f1': 0.94865, 'auc': 0.99365}
2025-08-23 09:41:43,544 - INFO - val: {'epoch': 63, 'time_epoch': 0.80727, 'loss': 0.24760664, 'lr': 0, 'params': 244937, 'time_iter': 0.02523, 'accuracy': 0.928, 'f1': 0.92833, 'auc': 0.98863}
2025-08-23 09:41:45,169 - INFO - test: {'epoch': 63, 'time_epoch': 1.6142, 'loss': 0.22323934, 'lr': 0, 'params': 244937, 'time_iter': 0.02562, 'accuracy': 0.926, 'f1': 0.92644, 'auc': 0.98917}
2025-08-23 09:41:45,171 - INFO - > Epoch 63: took 15.9s (avg 16.1s) | Best so far: epoch 60	train_loss: 0.1674 train_accuracy: 0.9431	val_loss: 0.2273 val_accuracy: 0.9300	test_loss: 0.2294 test_accuracy: 0.9220
2025-08-23 09:41:58,600 - INFO - train: {'epoch': 64, 'time_epoch': 13.41302, 'eta': 474.98457, 'eta_hours': 0.13194, 'loss': 0.16363256, 'lr': 0.00017275, 'params': 244937, 'time_iter': 0.06125, 'accuracy': 0.94629, 'f1': 0.94626, 'auc': 0.99383}
2025-08-23 09:41:59,408 - INFO - val: {'epoch': 64, 'time_epoch': 0.79784, 'loss': 0.27378428, 'lr': 0, 'params': 244937, 'time_iter': 0.02493, 'accuracy': 0.92, 'f1': 0.91999, 'auc': 0.98748}
2025-08-23 09:42:01,011 - INFO - test: {'epoch': 64, 'time_epoch': 1.59289, 'loss': 0.23307011, 'lr': 0, 'params': 244937, 'time_iter': 0.02528, 'accuracy': 0.922, 'f1': 0.92222, 'auc': 0.99035}
2025-08-23 09:42:01,013 - INFO - > Epoch 64: took 15.8s (avg 16.1s) | Best so far: epoch 60	train_loss: 0.1674 train_accuracy: 0.9431	val_loss: 0.2273 val_accuracy: 0.9300	test_loss: 0.2294 test_accuracy: 0.9220
2025-08-23 09:42:14,378 - INFO - train: {'epoch': 65, 'time_epoch': 13.34985, 'eta': 461.29966, 'eta_hours': 0.12814, 'loss': 0.16580933, 'lr': 0.00016449, 'params': 244937, 'time_iter': 0.06096, 'accuracy': 0.94514, 'f1': 0.94521, 'auc': 0.99314}
2025-08-23 09:42:15,191 - INFO - val: {'epoch': 65, 'time_epoch': 0.80188, 'loss': 0.23443544, 'lr': 0, 'params': 244937, 'time_iter': 0.02506, 'accuracy': 0.932, 'f1': 0.93157, 'auc': 0.98923}
2025-08-23 09:42:16,814 - INFO - test: {'epoch': 65, 'time_epoch': 1.61239, 'loss': 0.21897889, 'lr': 0, 'params': 244937, 'time_iter': 0.02559, 'accuracy': 0.93, 'f1': 0.92974, 'auc': 0.99039}
2025-08-23 09:42:16,815 - INFO - > Epoch 65: took 15.8s (avg 16.1s) | Best so far: epoch 65	train_loss: 0.1658 train_accuracy: 0.9451	val_loss: 0.2344 val_accuracy: 0.9320	test_loss: 0.2190 test_accuracy: 0.9300
2025-08-23 09:42:30,194 - INFO - train: {'epoch': 66, 'time_epoch': 13.3628, 'eta': 447.63113, 'eta_hours': 0.12434, 'loss': 0.1636773, 'lr': 0.00015635, 'params': 244937, 'time_iter': 0.06102, 'accuracy': 0.946, 'f1': 0.94613, 'auc': 0.99357}
2025-08-23 09:42:30,989 - INFO - val: {'epoch': 66, 'time_epoch': 0.78421, 'loss': 0.22691759, 'lr': 0, 'params': 244937, 'time_iter': 0.02451, 'accuracy': 0.932, 'f1': 0.93212, 'auc': 0.98527}
2025-08-23 09:42:32,582 - INFO - test: {'epoch': 66, 'time_epoch': 1.58206, 'loss': 0.23000241, 'lr': 0, 'params': 244937, 'time_iter': 0.02511, 'accuracy': 0.925, 'f1': 0.9251, 'auc': 0.98872}
2025-08-23 09:42:32,584 - INFO - > Epoch 66: took 15.8s (avg 16.1s) | Best so far: epoch 65	train_loss: 0.1658 train_accuracy: 0.9451	val_loss: 0.2344 val_accuracy: 0.9320	test_loss: 0.2190 test_accuracy: 0.9300
2025-08-23 09:42:46,003 - INFO - train: {'epoch': 67, 'time_epoch': 13.40265, 'eta': 433.99035, 'eta_hours': 0.12055, 'loss': 0.15975725, 'lr': 0.00014832, 'params': 244937, 'time_iter': 0.0612, 'accuracy': 0.94886, 'f1': 0.94902, 'auc': 0.99341}
2025-08-23 09:42:46,822 - INFO - val: {'epoch': 67, 'time_epoch': 0.80729, 'loss': 0.22252536, 'lr': 0, 'params': 244937, 'time_iter': 0.02523, 'accuracy': 0.94, 'f1': 0.93987, 'auc': 0.98775}
2025-08-23 09:42:48,477 - INFO - test: {'epoch': 67, 'time_epoch': 1.64385, 'loss': 0.21852027, 'lr': 0, 'params': 244937, 'time_iter': 0.02609, 'accuracy': 0.932, 'f1': 0.93174, 'auc': 0.98869}
2025-08-23 09:42:48,479 - INFO - > Epoch 67: took 15.9s (avg 16.1s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:43:01,911 - INFO - train: {'epoch': 68, 'time_epoch': 13.4159, 'eta': 420.36242, 'eta_hours': 0.11677, 'loss': 0.15847616, 'lr': 0.00014041, 'params': 244937, 'time_iter': 0.06126, 'accuracy': 0.94857, 'f1': 0.94844, 'auc': 0.99383}
2025-08-23 09:43:02,722 - INFO - val: {'epoch': 68, 'time_epoch': 0.80025, 'loss': 0.22861041, 'lr': 0, 'params': 244937, 'time_iter': 0.02501, 'accuracy': 0.926, 'f1': 0.92638, 'auc': 0.98938}
2025-08-23 09:43:04,340 - INFO - test: {'epoch': 68, 'time_epoch': 1.60841, 'loss': 0.22459357, 'lr': 0, 'params': 244937, 'time_iter': 0.02553, 'accuracy': 0.924, 'f1': 0.9246, 'auc': 0.99022}
2025-08-23 09:43:04,342 - INFO - > Epoch 68: took 15.9s (avg 16.1s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:43:17,759 - INFO - train: {'epoch': 69, 'time_epoch': 13.40192, 'eta': 406.73456, 'eta_hours': 0.11298, 'loss': 0.15485132, 'lr': 0.00013263, 'params': 244937, 'time_iter': 0.0612, 'accuracy': 0.95086, 'f1': 0.95085, 'auc': 0.99393}
2025-08-23 09:43:18,573 - INFO - val: {'epoch': 69, 'time_epoch': 0.80232, 'loss': 0.25002869, 'lr': 0, 'params': 244937, 'time_iter': 0.02507, 'accuracy': 0.93, 'f1': 0.92921, 'auc': 0.98881}
2025-08-23 09:43:20,201 - INFO - test: {'epoch': 69, 'time_epoch': 1.61616, 'loss': 0.21101102, 'lr': 0, 'params': 244937, 'time_iter': 0.02565, 'accuracy': 0.935, 'f1': 0.93465, 'auc': 0.99014}
2025-08-23 09:43:20,203 - INFO - > Epoch 69: took 15.9s (avg 16.1s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:43:33,645 - INFO - train: {'epoch': 70, 'time_epoch': 13.42614, 'eta': 393.12296, 'eta_hours': 0.1092, 'loss': 0.1535791, 'lr': 0.000125, 'params': 244937, 'time_iter': 0.06131, 'accuracy': 0.94771, 'f1': 0.94777, 'auc': 0.99444}
2025-08-23 09:43:34,461 - INFO - val: {'epoch': 70, 'time_epoch': 0.80399, 'loss': 0.26289429, 'lr': 0, 'params': 244937, 'time_iter': 0.02512, 'accuracy': 0.928, 'f1': 0.92722, 'auc': 0.98752}
2025-08-23 09:43:36,086 - INFO - test: {'epoch': 70, 'time_epoch': 1.61366, 'loss': 0.24369313, 'lr': 0, 'params': 244937, 'time_iter': 0.02561, 'accuracy': 0.923, 'f1': 0.92231, 'auc': 0.98896}
2025-08-23 09:43:36,088 - INFO - > Epoch 70: took 15.9s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:43:49,510 - INFO - train: {'epoch': 71, 'time_epoch': 13.40584, 'eta': 379.50861, 'eta_hours': 0.10542, 'loss': 0.13814854, 'lr': 0.00011752, 'params': 244937, 'time_iter': 0.06121, 'accuracy': 0.95514, 'f1': 0.95511, 'auc': 0.99465}
2025-08-23 09:43:50,319 - INFO - val: {'epoch': 71, 'time_epoch': 0.79808, 'loss': 0.228144, 'lr': 0, 'params': 244937, 'time_iter': 0.02494, 'accuracy': 0.928, 'f1': 0.92874, 'auc': 0.99088}
2025-08-23 09:43:51,954 - INFO - test: {'epoch': 71, 'time_epoch': 1.62419, 'loss': 0.20547467, 'lr': 0, 'params': 244937, 'time_iter': 0.02578, 'accuracy': 0.934, 'f1': 0.93462, 'auc': 0.99098}
2025-08-23 09:43:51,956 - INFO - > Epoch 71: took 15.9s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:44:05,413 - INFO - train: {'epoch': 72, 'time_epoch': 13.44071, 'eta': 365.91288, 'eta_hours': 0.10164, 'loss': 0.14415879, 'lr': 0.0001102, 'params': 244937, 'time_iter': 0.06137, 'accuracy': 0.95371, 'f1': 0.95361, 'auc': 0.99448}
2025-08-23 09:44:06,225 - INFO - val: {'epoch': 72, 'time_epoch': 0.80105, 'loss': 0.23927262, 'lr': 0, 'params': 244937, 'time_iter': 0.02503, 'accuracy': 0.932, 'f1': 0.9319, 'auc': 0.98941}
2025-08-23 09:44:07,836 - INFO - test: {'epoch': 72, 'time_epoch': 1.60039, 'loss': 0.21213016, 'lr': 0, 'params': 244937, 'time_iter': 0.0254, 'accuracy': 0.933, 'f1': 0.93313, 'auc': 0.99056}
2025-08-23 09:44:07,837 - INFO - > Epoch 72: took 15.9s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:44:21,225 - INFO - train: {'epoch': 73, 'time_epoch': 13.36998, 'eta': 352.29648, 'eta_hours': 0.09786, 'loss': 0.14714985, 'lr': 0.00010305, 'params': 244937, 'time_iter': 0.06105, 'accuracy': 0.954, 'f1': 0.95404, 'auc': 0.99472}
2025-08-23 09:44:22,052 - INFO - val: {'epoch': 73, 'time_epoch': 0.81376, 'loss': 0.22673634, 'lr': 0, 'params': 244937, 'time_iter': 0.02543, 'accuracy': 0.938, 'f1': 0.93805, 'auc': 0.98948}
2025-08-23 09:44:23,662 - INFO - test: {'epoch': 73, 'time_epoch': 1.59889, 'loss': 0.21275569, 'lr': 0, 'params': 244937, 'time_iter': 0.02538, 'accuracy': 0.932, 'f1': 0.93227, 'auc': 0.99015}
2025-08-23 09:44:23,664 - INFO - > Epoch 73: took 15.8s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:44:37,050 - INFO - train: {'epoch': 74, 'time_epoch': 13.37057, 'eta': 338.68685, 'eta_hours': 0.09408, 'loss': 0.14367034, 'lr': 9.608e-05, 'params': 244937, 'time_iter': 0.06105, 'accuracy': 0.95257, 'f1': 0.95248, 'auc': 0.9948}
2025-08-23 09:44:37,861 - INFO - val: {'epoch': 74, 'time_epoch': 0.79893, 'loss': 0.23923003, 'lr': 0, 'params': 244937, 'time_iter': 0.02497, 'accuracy': 0.938, 'f1': 0.93758, 'auc': 0.98884}
2025-08-23 09:44:39,489 - INFO - test: {'epoch': 74, 'time_epoch': 1.61682, 'loss': 0.21474943, 'lr': 0, 'params': 244937, 'time_iter': 0.02566, 'accuracy': 0.929, 'f1': 0.92863, 'auc': 0.9899}
2025-08-23 09:44:39,491 - INFO - > Epoch 74: took 15.8s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:44:52,851 - INFO - train: {'epoch': 75, 'time_epoch': 13.3442, 'eta': 325.07518, 'eta_hours': 0.0903, 'loss': 0.15201999, 'lr': 8.93e-05, 'params': 244937, 'time_iter': 0.06093, 'accuracy': 0.95086, 'f1': 0.95077, 'auc': 0.99438}
2025-08-23 09:44:53,660 - INFO - val: {'epoch': 75, 'time_epoch': 0.79817, 'loss': 0.2278071, 'lr': 0, 'params': 244937, 'time_iter': 0.02494, 'accuracy': 0.936, 'f1': 0.9362, 'auc': 0.98936}
2025-08-23 09:44:55,281 - INFO - test: {'epoch': 75, 'time_epoch': 1.60952, 'loss': 0.21855653, 'lr': 0, 'params': 244937, 'time_iter': 0.02555, 'accuracy': 0.93, 'f1': 0.93034, 'auc': 0.98963}
2025-08-23 09:44:55,283 - INFO - > Epoch 75: took 15.8s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:45:08,652 - INFO - train: {'epoch': 76, 'time_epoch': 13.35367, 'eta': 311.47329, 'eta_hours': 0.08652, 'loss': 0.13562555, 'lr': 8.272e-05, 'params': 244937, 'time_iter': 0.06098, 'accuracy': 0.95657, 'f1': 0.95653, 'auc': 0.99471}
2025-08-23 09:45:09,461 - INFO - val: {'epoch': 76, 'time_epoch': 0.79848, 'loss': 0.23273411, 'lr': 0, 'params': 244937, 'time_iter': 0.02495, 'accuracy': 0.934, 'f1': 0.93412, 'auc': 0.98972}
2025-08-23 09:45:11,073 - INFO - test: {'epoch': 76, 'time_epoch': 1.60182, 'loss': 0.21328914, 'lr': 0, 'params': 244937, 'time_iter': 0.02543, 'accuracy': 0.932, 'f1': 0.93223, 'auc': 0.98964}
2025-08-23 09:45:11,075 - INFO - > Epoch 76: took 15.8s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:45:24,443 - INFO - train: {'epoch': 77, 'time_epoch': 13.35127, 'eta': 297.87709, 'eta_hours': 0.08274, 'loss': 0.1360055, 'lr': 7.634e-05, 'params': 244937, 'time_iter': 0.06096, 'accuracy': 0.95486, 'f1': 0.95486, 'auc': 0.995}
2025-08-23 09:45:25,256 - INFO - val: {'epoch': 77, 'time_epoch': 0.80174, 'loss': 0.23710808, 'lr': 0, 'params': 244937, 'time_iter': 0.02505, 'accuracy': 0.934, 'f1': 0.93399, 'auc': 0.98901}
2025-08-23 09:45:26,875 - INFO - test: {'epoch': 77, 'time_epoch': 1.60876, 'loss': 0.21810125, 'lr': 0, 'params': 244937, 'time_iter': 0.02554, 'accuracy': 0.932, 'f1': 0.93214, 'auc': 0.98927}
2025-08-23 09:45:26,877 - INFO - > Epoch 77: took 15.8s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:45:40,267 - INFO - train: {'epoch': 78, 'time_epoch': 13.37466, 'eta': 284.29331, 'eta_hours': 0.07897, 'loss': 0.13734931, 'lr': 7.017e-05, 'params': 244937, 'time_iter': 0.06107, 'accuracy': 0.95771, 'f1': 0.95775, 'auc': 0.99494}
2025-08-23 09:45:41,075 - INFO - val: {'epoch': 78, 'time_epoch': 0.79718, 'loss': 0.23201573, 'lr': 0, 'params': 244937, 'time_iter': 0.02491, 'accuracy': 0.936, 'f1': 0.9359, 'auc': 0.98932}
2025-08-23 09:45:42,678 - INFO - test: {'epoch': 78, 'time_epoch': 1.59216, 'loss': 0.21316701, 'lr': 0, 'params': 244937, 'time_iter': 0.02527, 'accuracy': 0.932, 'f1': 0.93204, 'auc': 0.99076}
2025-08-23 09:45:42,680 - INFO - > Epoch 78: took 15.8s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:45:56,036 - INFO - train: {'epoch': 79, 'time_epoch': 13.3407, 'eta': 270.70626, 'eta_hours': 0.0752, 'loss': 0.14087089, 'lr': 6.421e-05, 'params': 244937, 'time_iter': 0.06092, 'accuracy': 0.95657, 'f1': 0.95652, 'auc': 0.99486}
2025-08-23 09:45:56,852 - INFO - val: {'epoch': 79, 'time_epoch': 0.80508, 'loss': 0.23504947, 'lr': 0, 'params': 244937, 'time_iter': 0.02516, 'accuracy': 0.936, 'f1': 0.93609, 'auc': 0.98966}
2025-08-23 09:45:58,481 - INFO - test: {'epoch': 79, 'time_epoch': 1.6177, 'loss': 0.20857894, 'lr': 0, 'params': 244937, 'time_iter': 0.02568, 'accuracy': 0.936, 'f1': 0.9364, 'auc': 0.99025}
2025-08-23 09:45:58,483 - INFO - > Epoch 79: took 15.8s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:46:11,866 - INFO - train: {'epoch': 80, 'time_epoch': 13.3675, 'eta': 257.13158, 'eta_hours': 0.07143, 'loss': 0.13999623, 'lr': 5.849e-05, 'params': 244937, 'time_iter': 0.06104, 'accuracy': 0.954, 'f1': 0.95394, 'auc': 0.99497}
2025-08-23 09:46:12,674 - INFO - val: {'epoch': 80, 'time_epoch': 0.79774, 'loss': 0.22856945, 'lr': 0, 'params': 244937, 'time_iter': 0.02493, 'accuracy': 0.936, 'f1': 0.93581, 'auc': 0.98964}
2025-08-23 09:46:14,299 - INFO - test: {'epoch': 80, 'time_epoch': 1.61402, 'loss': 0.21234007, 'lr': 0, 'params': 244937, 'time_iter': 0.02562, 'accuracy': 0.931, 'f1': 0.93106, 'auc': 0.99015}
2025-08-23 09:46:14,301 - INFO - > Epoch 80: took 15.8s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:46:27,759 - INFO - train: {'epoch': 81, 'time_epoch': 13.44181, 'eta': 243.57827, 'eta_hours': 0.06766, 'loss': 0.13423702, 'lr': 5.3e-05, 'params': 244937, 'time_iter': 0.06138, 'accuracy': 0.95914, 'f1': 0.95909, 'auc': 0.99535}
2025-08-23 09:46:28,571 - INFO - val: {'epoch': 81, 'time_epoch': 0.80181, 'loss': 0.23225574, 'lr': 0, 'params': 244937, 'time_iter': 0.02506, 'accuracy': 0.934, 'f1': 0.93381, 'auc': 0.98906}
2025-08-23 09:46:30,200 - INFO - test: {'epoch': 81, 'time_epoch': 1.61808, 'loss': 0.20821871, 'lr': 0, 'params': 244937, 'time_iter': 0.02568, 'accuracy': 0.934, 'f1': 0.934, 'auc': 0.9901}
2025-08-23 09:46:30,202 - INFO - > Epoch 81: took 15.9s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:46:43,615 - INFO - train: {'epoch': 82, 'time_epoch': 13.39701, 'eta': 230.01847, 'eta_hours': 0.06389, 'loss': 0.13292118, 'lr': 4.775e-05, 'params': 244937, 'time_iter': 0.06117, 'accuracy': 0.95743, 'f1': 0.9574, 'auc': 0.99509}
2025-08-23 09:46:44,432 - INFO - val: {'epoch': 82, 'time_epoch': 0.8057, 'loss': 0.24052126, 'lr': 0, 'params': 244937, 'time_iter': 0.02518, 'accuracy': 0.932, 'f1': 0.93223, 'auc': 0.98958}
2025-08-23 09:46:46,064 - INFO - test: {'epoch': 82, 'time_epoch': 1.62131, 'loss': 0.20581032, 'lr': 0, 'params': 244937, 'time_iter': 0.02574, 'accuracy': 0.937, 'f1': 0.93737, 'auc': 0.99029}
2025-08-23 09:46:46,066 - INFO - > Epoch 82: took 15.9s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:46:59,504 - INFO - train: {'epoch': 83, 'time_epoch': 13.42267, 'eta': 216.46744, 'eta_hours': 0.06013, 'loss': 0.13255477, 'lr': 4.274e-05, 'params': 244937, 'time_iter': 0.06129, 'accuracy': 0.95771, 'f1': 0.95779, 'auc': 0.99535}
2025-08-23 09:47:00,321 - INFO - val: {'epoch': 83, 'time_epoch': 0.80584, 'loss': 0.23524075, 'lr': 0, 'params': 244937, 'time_iter': 0.02518, 'accuracy': 0.934, 'f1': 0.93403, 'auc': 0.98963}
2025-08-23 09:47:01,947 - INFO - test: {'epoch': 83, 'time_epoch': 1.61569, 'loss': 0.20626711, 'lr': 0, 'params': 244937, 'time_iter': 0.02565, 'accuracy': 0.931, 'f1': 0.93111, 'auc': 0.99046}
2025-08-23 09:47:01,949 - INFO - > Epoch 83: took 15.9s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:47:15,386 - INFO - train: {'epoch': 84, 'time_epoch': 13.42174, 'eta': 202.91925, 'eta_hours': 0.05637, 'loss': 0.13096382, 'lr': 3.799e-05, 'params': 244937, 'time_iter': 0.06129, 'accuracy': 0.954, 'f1': 0.95399, 'auc': 0.99522}
2025-08-23 09:47:16,200 - INFO - val: {'epoch': 84, 'time_epoch': 0.80331, 'loss': 0.23598058, 'lr': 0, 'params': 244937, 'time_iter': 0.0251, 'accuracy': 0.934, 'f1': 0.93417, 'auc': 0.98963}
2025-08-23 09:47:17,830 - INFO - test: {'epoch': 84, 'time_epoch': 1.61914, 'loss': 0.20876416, 'lr': 0, 'params': 244937, 'time_iter': 0.0257, 'accuracy': 0.937, 'f1': 0.93734, 'auc': 0.99022}
2025-08-23 09:47:17,832 - INFO - > Epoch 84: took 15.9s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:47:31,345 - INFO - train: {'epoch': 85, 'time_epoch': 13.49785, 'eta': 189.3864, 'eta_hours': 0.05261, 'loss': 0.12449731, 'lr': 3.349e-05, 'params': 244937, 'time_iter': 0.06163, 'accuracy': 0.95943, 'f1': 0.95942, 'auc': 0.9958}
2025-08-23 09:47:32,162 - INFO - val: {'epoch': 85, 'time_epoch': 0.80538, 'loss': 0.23218442, 'lr': 0, 'params': 244937, 'time_iter': 0.02517, 'accuracy': 0.936, 'f1': 0.93604, 'auc': 0.9897}
2025-08-23 09:47:33,794 - INFO - test: {'epoch': 85, 'time_epoch': 1.6196, 'loss': 0.20878023, 'lr': 0, 'params': 244937, 'time_iter': 0.02571, 'accuracy': 0.931, 'f1': 0.93117, 'auc': 0.99022}
2025-08-23 09:47:33,796 - INFO - > Epoch 85: took 16.0s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:47:47,262 - INFO - train: {'epoch': 86, 'time_epoch': 13.44738, 'eta': 175.84682, 'eta_hours': 0.04885, 'loss': 0.12810717, 'lr': 2.926e-05, 'params': 244937, 'time_iter': 0.0614, 'accuracy': 0.95771, 'f1': 0.95767, 'auc': 0.99539}
2025-08-23 09:47:48,079 - INFO - val: {'epoch': 86, 'time_epoch': 0.80547, 'loss': 0.23235612, 'lr': 0, 'params': 244937, 'time_iter': 0.02517, 'accuracy': 0.934, 'f1': 0.93417, 'auc': 0.98935}
2025-08-23 09:47:49,708 - INFO - test: {'epoch': 86, 'time_epoch': 1.6185, 'loss': 0.21171868, 'lr': 0, 'params': 244937, 'time_iter': 0.02569, 'accuracy': 0.934, 'f1': 0.93431, 'auc': 0.99008}
2025-08-23 09:47:49,710 - INFO - > Epoch 86: took 15.9s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:48:03,152 - INFO - train: {'epoch': 87, 'time_epoch': 13.42667, 'eta': 162.3065, 'eta_hours': 0.04509, 'loss': 0.11998967, 'lr': 2.53e-05, 'params': 244937, 'time_iter': 0.06131, 'accuracy': 0.96171, 'f1': 0.96175, 'auc': 0.9955}
2025-08-23 09:48:03,958 - INFO - val: {'epoch': 87, 'time_epoch': 0.79535, 'loss': 0.23886077, 'lr': 0, 'params': 244937, 'time_iter': 0.02485, 'accuracy': 0.938, 'f1': 0.93811, 'auc': 0.98949}
2025-08-23 09:48:05,570 - INFO - test: {'epoch': 87, 'time_epoch': 1.60236, 'loss': 0.20571294, 'lr': 0, 'params': 244937, 'time_iter': 0.02543, 'accuracy': 0.936, 'f1': 0.93629, 'auc': 0.99002}
2025-08-23 09:48:05,572 - INFO - > Epoch 87: took 15.9s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:48:18,990 - INFO - train: {'epoch': 88, 'time_epoch': 13.40296, 'eta': 148.76581, 'eta_hours': 0.04132, 'loss': 0.13282461, 'lr': 2.161e-05, 'params': 244937, 'time_iter': 0.0612, 'accuracy': 0.95686, 'f1': 0.95672, 'auc': 0.99505}
2025-08-23 09:48:19,802 - INFO - val: {'epoch': 88, 'time_epoch': 0.80039, 'loss': 0.24735471, 'lr': 0, 'params': 244937, 'time_iter': 0.02501, 'accuracy': 0.932, 'f1': 0.93203, 'auc': 0.98937}
2025-08-23 09:48:21,426 - INFO - test: {'epoch': 88, 'time_epoch': 1.61249, 'loss': 0.20853084, 'lr': 0, 'params': 244937, 'time_iter': 0.0256, 'accuracy': 0.933, 'f1': 0.9331, 'auc': 0.99029}
2025-08-23 09:48:21,428 - INFO - > Epoch 88: took 15.9s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:48:35,087 - INFO - train: {'epoch': 89, 'time_epoch': 13.64448, 'eta': 135.25501, 'eta_hours': 0.03757, 'loss': 0.12074784, 'lr': 1.82e-05, 'params': 244937, 'time_iter': 0.0623, 'accuracy': 0.962, 'f1': 0.96198, 'auc': 0.99588}
2025-08-23 09:48:35,902 - INFO - val: {'epoch': 89, 'time_epoch': 0.80392, 'loss': 0.24699038, 'lr': 0, 'params': 244937, 'time_iter': 0.02512, 'accuracy': 0.934, 'f1': 0.93404, 'auc': 0.98858}
2025-08-23 09:48:37,529 - INFO - test: {'epoch': 89, 'time_epoch': 1.61653, 'loss': 0.21175114, 'lr': 0, 'params': 244937, 'time_iter': 0.02566, 'accuracy': 0.934, 'f1': 0.93415, 'auc': 0.98978}
2025-08-23 09:48:37,531 - INFO - > Epoch 89: took 16.1s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:48:50,989 - INFO - train: {'epoch': 90, 'time_epoch': 13.44087, 'eta': 121.72114, 'eta_hours': 0.03381, 'loss': 0.13193162, 'lr': 1.508e-05, 'params': 244937, 'time_iter': 0.06137, 'accuracy': 0.95857, 'f1': 0.95856, 'auc': 0.99554}
2025-08-23 09:48:51,813 - INFO - val: {'epoch': 90, 'time_epoch': 0.81247, 'loss': 0.23528574, 'lr': 0, 'params': 244937, 'time_iter': 0.02539, 'accuracy': 0.936, 'f1': 0.93626, 'auc': 0.98916}
2025-08-23 09:48:53,453 - INFO - test: {'epoch': 90, 'time_epoch': 1.62911, 'loss': 0.2093338, 'lr': 0, 'params': 244937, 'time_iter': 0.02586, 'accuracy': 0.935, 'f1': 0.93523, 'auc': 0.98989}
2025-08-23 09:48:53,455 - INFO - > Epoch 90: took 15.9s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:49:06,780 - INFO - train: {'epoch': 91, 'time_epoch': 13.30976, 'eta': 108.17789, 'eta_hours': 0.03005, 'loss': 0.12735586, 'lr': 1.224e-05, 'params': 244937, 'time_iter': 0.06078, 'accuracy': 0.95857, 'f1': 0.95859, 'auc': 0.99555}
2025-08-23 09:49:07,596 - INFO - val: {'epoch': 91, 'time_epoch': 0.80438, 'loss': 0.2372469, 'lr': 0, 'params': 244937, 'time_iter': 0.02514, 'accuracy': 0.936, 'f1': 0.9362, 'auc': 0.98941}
2025-08-23 09:49:09,225 - INFO - test: {'epoch': 91, 'time_epoch': 1.61779, 'loss': 0.21033511, 'lr': 0, 'params': 244937, 'time_iter': 0.02568, 'accuracy': 0.935, 'f1': 0.93531, 'auc': 0.9898}
2025-08-23 09:49:09,226 - INFO - > Epoch 91: took 15.8s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:49:22,636 - INFO - train: {'epoch': 92, 'time_epoch': 13.39396, 'eta': 94.646, 'eta_hours': 0.02629, 'loss': 0.12937263, 'lr': 9.68e-06, 'params': 244937, 'time_iter': 0.06116, 'accuracy': 0.95743, 'f1': 0.95746, 'auc': 0.99546}
2025-08-23 09:49:23,445 - INFO - val: {'epoch': 92, 'time_epoch': 0.79849, 'loss': 0.23294479, 'lr': 0, 'params': 244937, 'time_iter': 0.02495, 'accuracy': 0.932, 'f1': 0.93221, 'auc': 0.9897}
2025-08-23 09:49:25,046 - INFO - test: {'epoch': 92, 'time_epoch': 1.59066, 'loss': 0.20904999, 'lr': 0, 'params': 244937, 'time_iter': 0.02525, 'accuracy': 0.934, 'f1': 0.93423, 'auc': 0.9901}
2025-08-23 09:49:25,047 - INFO - > Epoch 92: took 15.8s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:49:38,435 - INFO - train: {'epoch': 93, 'time_epoch': 13.37385, 'eta': 81.11576, 'eta_hours': 0.02253, 'loss': 0.11941611, 'lr': 7.43e-06, 'params': 244937, 'time_iter': 0.06107, 'accuracy': 0.95914, 'f1': 0.95911, 'auc': 0.99614}
2025-08-23 09:49:39,237 - INFO - val: {'epoch': 93, 'time_epoch': 0.79125, 'loss': 0.23356194, 'lr': 0, 'params': 244937, 'time_iter': 0.02473, 'accuracy': 0.934, 'f1': 0.93412, 'auc': 0.98954}
2025-08-23 09:49:40,854 - INFO - test: {'epoch': 93, 'time_epoch': 1.6065, 'loss': 0.20777095, 'lr': 0, 'params': 244937, 'time_iter': 0.0255, 'accuracy': 0.937, 'f1': 0.93728, 'auc': 0.99044}
2025-08-23 09:49:40,856 - INFO - > Epoch 93: took 15.8s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:49:54,259 - INFO - train: {'epoch': 94, 'time_epoch': 13.38806, 'eta': 67.58956, 'eta_hours': 0.01877, 'loss': 0.12558459, 'lr': 5.46e-06, 'params': 244937, 'time_iter': 0.06113, 'accuracy': 0.95971, 'f1': 0.95973, 'auc': 0.996}
2025-08-23 09:49:55,072 - INFO - val: {'epoch': 94, 'time_epoch': 0.80171, 'loss': 0.2315836, 'lr': 0, 'params': 244937, 'time_iter': 0.02505, 'accuracy': 0.936, 'f1': 0.9362, 'auc': 0.98954}
2025-08-23 09:49:56,700 - INFO - test: {'epoch': 94, 'time_epoch': 1.61726, 'loss': 0.20899223, 'lr': 0, 'params': 244937, 'time_iter': 0.02567, 'accuracy': 0.935, 'f1': 0.93528, 'auc': 0.99005}
2025-08-23 09:49:56,701 - INFO - > Epoch 94: took 15.8s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:50:10,113 - INFO - train: {'epoch': 95, 'time_epoch': 13.3968, 'eta': 54.0666, 'eta_hours': 0.01502, 'loss': 0.11676551, 'lr': 3.8e-06, 'params': 244937, 'time_iter': 0.06117, 'accuracy': 0.96343, 'f1': 0.96341, 'auc': 0.99561}
2025-08-23 09:50:10,925 - INFO - val: {'epoch': 95, 'time_epoch': 0.80077, 'loss': 0.23206918, 'lr': 0, 'params': 244937, 'time_iter': 0.02502, 'accuracy': 0.934, 'f1': 0.93417, 'auc': 0.98971}
2025-08-23 09:50:12,553 - INFO - test: {'epoch': 95, 'time_epoch': 1.6166, 'loss': 0.20738172, 'lr': 0, 'params': 244937, 'time_iter': 0.02566, 'accuracy': 0.934, 'f1': 0.9342, 'auc': 0.99012}
2025-08-23 09:50:12,555 - INFO - > Epoch 95: took 15.9s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:50:25,967 - INFO - train: {'epoch': 96, 'time_epoch': 13.39759, 'eta': 40.54627, 'eta_hours': 0.01126, 'loss': 0.12018006, 'lr': 2.43e-06, 'params': 244937, 'time_iter': 0.06118, 'accuracy': 0.96314, 'f1': 0.96317, 'auc': 0.99593}
2025-08-23 09:50:26,779 - INFO - val: {'epoch': 96, 'time_epoch': 0.80149, 'loss': 0.23475091, 'lr': 0, 'params': 244937, 'time_iter': 0.02505, 'accuracy': 0.936, 'f1': 0.9362, 'auc': 0.98964}
2025-08-23 09:50:28,409 - INFO - test: {'epoch': 96, 'time_epoch': 1.61841, 'loss': 0.20730931, 'lr': 0, 'params': 244937, 'time_iter': 0.02569, 'accuracy': 0.936, 'f1': 0.93629, 'auc': 0.99015}
2025-08-23 09:50:28,410 - INFO - > Epoch 96: took 15.9s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:50:41,811 - INFO - train: {'epoch': 97, 'time_epoch': 13.3857, 'eta': 27.0282, 'eta_hours': 0.00751, 'loss': 0.12240822, 'lr': 1.37e-06, 'params': 244937, 'time_iter': 0.06112, 'accuracy': 0.962, 'f1': 0.96199, 'auc': 0.99588}
2025-08-23 09:50:42,621 - INFO - val: {'epoch': 97, 'time_epoch': 0.79942, 'loss': 0.24121329, 'lr': 0, 'params': 244937, 'time_iter': 0.02498, 'accuracy': 0.936, 'f1': 0.93626, 'auc': 0.98898}
2025-08-23 09:50:44,245 - INFO - test: {'epoch': 97, 'time_epoch': 1.61373, 'loss': 0.2092316, 'lr': 0, 'params': 244937, 'time_iter': 0.02561, 'accuracy': 0.937, 'f1': 0.93741, 'auc': 0.98991}
2025-08-23 09:50:44,247 - INFO - > Epoch 97: took 15.8s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:50:57,617 - INFO - train: {'epoch': 98, 'time_epoch': 13.35525, 'eta': 13.51249, 'eta_hours': 0.00375, 'loss': 0.11405713, 'lr': 6.1e-07, 'params': 244937, 'time_iter': 0.06098, 'accuracy': 0.96257, 'f1': 0.9626, 'auc': 0.99609}
2025-08-23 09:50:58,432 - INFO - val: {'epoch': 98, 'time_epoch': 0.80326, 'loss': 0.23403555, 'lr': 0, 'params': 244937, 'time_iter': 0.0251, 'accuracy': 0.936, 'f1': 0.93615, 'auc': 0.98955}
2025-08-23 09:51:00,048 - INFO - test: {'epoch': 98, 'time_epoch': 1.60514, 'loss': 0.20800344, 'lr': 0, 'params': 244937, 'time_iter': 0.02548, 'accuracy': 0.937, 'f1': 0.93728, 'auc': 0.98991}
2025-08-23 09:51:00,050 - INFO - > Epoch 98: took 15.8s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:51:13,375 - INFO - train: {'epoch': 99, 'time_epoch': 13.31124, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.1248989, 'lr': 1.5e-07, 'params': 244937, 'time_iter': 0.06078, 'accuracy': 0.96, 'f1': 0.95993, 'auc': 0.99611}
2025-08-23 09:51:14,192 - INFO - val: {'epoch': 99, 'time_epoch': 0.80449, 'loss': 0.23452641, 'lr': 0, 'params': 244937, 'time_iter': 0.02514, 'accuracy': 0.936, 'f1': 0.9362, 'auc': 0.98949}
2025-08-23 09:51:15,820 - INFO - test: {'epoch': 99, 'time_epoch': 1.61773, 'loss': 0.20774708, 'lr': 0, 'params': 244937, 'time_iter': 0.02568, 'accuracy': 0.938, 'f1': 0.93829, 'auc': 0.98994}
2025-08-23 09:51:15,893 - INFO - > Epoch 99: took 15.8s (avg 16.0s) | Best so far: epoch 67	train_loss: 0.1598 train_accuracy: 0.9489	val_loss: 0.2225 val_accuracy: 0.9400	test_loss: 0.2185 test_accuracy: 0.9320
2025-08-23 09:51:15,893 - INFO - Avg time per epoch: 15.99s
2025-08-23 09:51:15,893 - INFO - Total train loop time: 0.44h
2025-08-23 09:51:15,895 - INFO - Task done, results saved in results/MALNET/MALNET-E-45
2025-08-23 09:51:15,895 - INFO - Total time: 1603.57s (0.45h)
2025-08-23 09:51:15,896 - INFO - Results aggregated across runs saved in results/MALNET/MALNET-E-45/agg
2025-08-23 09:51:15,896 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-23 09:51:15,896 - INFO - Results saved in: results/MALNET/MALNET-E-45
2025-08-23 09:51:15,896 - INFO - Test results JSON files saved in: results/MALNET/MALNET-E-45/test_results/
Completed seed 45. Results saved in results/MALNET/MALNET-E-45
----------------------------------------
Submitting next job for seed 47
Submitted batch job 5482724
