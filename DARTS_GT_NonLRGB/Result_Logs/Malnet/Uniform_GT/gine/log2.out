Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          376Gi        23Gi       300Gi       2.7Gi        52Gi       347Gi
Swap:         1.9Gi       0.0Ki       1.9Gi
Sat Aug 23 09:12:17 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-16GB           On  |   00000000:B1:00.0 Off |                    0 |
| N/A   48C    P0             28W /  250W |       0MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 45
Starting training for seed 45...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/MALNET/FINAL_SINGLE/PERFORMER_E/UNI_GT/GINE
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/MALNET/FINAL_SINGLE/PERFORMER_E/UNI_GT/GINE/confignas.yaml
Using device: cuda
2025-08-23 09:12:26,211 - INFO - GPU Mem: 17.1GB
2025-08-23 09:12:26,211 - INFO - Run directory: results/MALNET/MALNET-E-45
2025-08-23 09:12:26,211 - INFO - Seed: 45
2025-08-23 09:12:26,211 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-23 09:12:26,211 - INFO - Routing mode: none
2025-08-23 09:12:26,211 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-23 09:12:26,211 - INFO - Number of layers: 4
2025-08-23 09:12:26,211 - INFO - Uncertainty enabled: False
2025-08-23 09:12:26,211 - INFO - Training mode: custom
2025-08-23 09:12:26,211 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-23 09:12:26,211 - INFO - Additional features: Router weights logging + JSON export
2025-08-23 09:12:28,328 - INFO - Computing "LocalDegreeProfile" node features for MalNetTiny.
2025-08-23 09:12:32,976 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-23 09:12:32,977 - INFO -   Data(edge_index=[2, 14299688], y=[5000], x=[7051560, 5], num_nodes=7051560)
2025-08-23 09:12:32,978 - INFO -   undirected: False
2025-08-23 09:12:32,979 - INFO -   num graphs: 5000
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-23 09:12:32,979 - INFO -   avg num_nodes/graph: 1410
2025-08-23 09:12:32,979 - INFO -   num node features: 5
2025-08-23 09:12:32,979 - INFO -   num edge features: 0
2025-08-23 09:12:32,979 - INFO -   num classes: 5
2025-08-23 09:12:32,981 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny'
2025-08-23 09:12:33,155 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-23 09:12:33,155 - INFO - Inner model type: <class 'graphgps.network.uniform_gt_model_edge.UNIFORM_GTModelEdge'>
2025-08-23 09:12:33,155 - INFO - Inner model has get_darts_model: False
2025-08-23 09:12:33,157 - INFO - GraphGymModule(
  (model): UNIFORM_GTModelEdge(
    (encoder): FeatureEncoder(
      (edge_encoder): DummyEdgeEncoder(
        (encoder): Embedding(1, 64)
      )
    )
    (pre_mp): GeneralMultiLayer(
      (Layer_0): GeneralLayer(
        (layer): Linear(
          (model): Linear(5, 64, bias=False)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU()
        )
      )
    )
    (layers): Sequential(
      (0): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GINEConv(nn=Sequential(
          (0): Linear(64, 64, bias=True)
          (1): ReLU()
          (2): Linear(64, 64, bias=True)
        ))
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (1): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GINEConv(nn=Sequential(
          (0): Linear(64, 64, bias=True)
          (1): ReLU()
          (2): Linear(64, 64, bias=True)
        ))
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (2): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GINEConv(nn=Sequential(
          (0): Linear(64, 64, bias=True)
          (1): ReLU()
          (2): Linear(64, 64, bias=True)
        ))
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (3): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GINEConv(nn=Sequential(
          (0): Linear(64, 64, bias=True)
          (1): ReLU()
          (2): Linear(64, 64, bias=True)
        ))
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
    )
    (post_mp): GNNGraphHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(64, 5, bias=True)
          )
        )
      )
    )
  )
)
2025-08-23 09:12:33,158 - INFO - Number of parameters: 193,993
2025-08-23 09:12:33,158 - INFO - Starting optimized training: 2025-08-23 09:12:33.158886
2025-08-23 09:12:33,248 - INFO - Computing "LocalDegreeProfile" node features for MalNetTiny.
2025-08-23 09:12:37,538 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny':
2025-08-23 09:12:37,539 - INFO -   Data(edge_index=[2, 14299688], y=[5000], x=[7051560, 5], num_nodes=7051560)
2025-08-23 09:12:37,539 - INFO -   undirected: False
2025-08-23 09:12:37,540 - INFO -   num graphs: 5000
2025-08-23 09:12:37,540 - INFO -   avg num_nodes/graph: 1410
2025-08-23 09:12:37,540 - INFO -   num node features: 5
2025-08-23 09:12:37,540 - INFO -   num edge features: 0
2025-08-23 09:12:37,540 - INFO -   num classes: 5
2025-08-23 09:12:37,543 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny'
2025-08-23 09:12:37,547 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-23 09:12:37,547 - INFO - Start from epoch 0
2025-08-23 09:12:48,975 - INFO - train: {'epoch': 0, 'time_epoch': 11.31895, 'eta': 1120.57652, 'eta_hours': 0.31127, 'loss': 1.62646964, 'lr': 0.0, 'params': 193993, 'time_iter': 0.05168, 'accuracy': 0.2, 'f1': 0.06667, 'auc': 0.32546}
2025-08-23 09:12:48,978 - INFO - ...computing epoch stats took: 0.11s
2025-08-23 09:12:49,674 - INFO - val: {'epoch': 0, 'time_epoch': 0.68609, 'loss': 1.62833625, 'lr': 0, 'params': 193993, 'time_iter': 0.02144, 'accuracy': 0.2, 'f1': 0.06667, 'auc': 0.30393}
2025-08-23 09:12:49,675 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:12:51,056 - INFO - test: {'epoch': 0, 'time_epoch': 1.37074, 'loss': 1.62860605, 'lr': 0, 'params': 193993, 'time_iter': 0.02176, 'accuracy': 0.2, 'f1': 0.06667, 'auc': 0.31098}
2025-08-23 09:12:51,058 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:12:51,058 - INFO - > Epoch 0: took 13.5s (avg 13.5s) | Best so far: epoch 0	train_loss: 1.6265 train_accuracy: 0.2000	val_loss: 1.6283 val_accuracy: 0.2000	test_loss: 1.6286 test_accuracy: 0.2000
2025-08-23 09:13:01,621 - INFO - train: {'epoch': 1, 'time_epoch': 10.54772, 'eta': 1071.46689, 'eta_hours': 0.29763, 'loss': 1.54420872, 'lr': 5e-05, 'params': 193993, 'time_iter': 0.04816, 'accuracy': 0.37171, 'f1': 0.25692, 'auc': 0.7494}
2025-08-23 09:13:01,624 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:13:02,272 - INFO - val: {'epoch': 1, 'time_epoch': 0.63916, 'loss': 1.49885058, 'lr': 0, 'params': 193993, 'time_iter': 0.01997, 'accuracy': 0.48, 'f1': 0.39233, 'auc': 0.82623}
2025-08-23 09:13:02,273 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:13:03,595 - INFO - test: {'epoch': 1, 'time_epoch': 1.31208, 'loss': 1.50480321, 'lr': 0, 'params': 193993, 'time_iter': 0.02083, 'accuracy': 0.465, 'f1': 0.37802, 'auc': 0.79558}
2025-08-23 09:13:03,596 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:13:03,596 - INFO - > Epoch 1: took 12.5s (avg 13.0s) | Best so far: epoch 1	train_loss: 1.5442 train_accuracy: 0.3717	val_loss: 1.4989 val_accuracy: 0.4800	test_loss: 1.5048 test_accuracy: 0.4650
2025-08-23 09:13:14,354 - INFO - train: {'epoch': 2, 'time_epoch': 10.73986, 'eta': 1054.27776, 'eta_hours': 0.29285, 'loss': 1.44291018, 'lr': 0.0001, 'params': 193993, 'time_iter': 0.04904, 'accuracy': 0.516, 'f1': 0.43785, 'auc': 0.8061}
2025-08-23 09:13:14,356 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:13:15,029 - INFO - val: {'epoch': 2, 'time_epoch': 0.6612, 'loss': 1.40921379, 'lr': 0, 'params': 193993, 'time_iter': 0.02066, 'accuracy': 0.522, 'f1': 0.44795, 'auc': 0.8809}
2025-08-23 09:13:15,030 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:13:16,343 - INFO - test: {'epoch': 2, 'time_epoch': 1.30156, 'loss': 1.42124716, 'lr': 0, 'params': 193993, 'time_iter': 0.02066, 'accuracy': 0.509, 'f1': 0.43799, 'auc': 0.85046}
2025-08-23 09:13:16,345 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:13:16,345 - INFO - > Epoch 2: took 12.7s (avg 12.9s) | Best so far: epoch 2	train_loss: 1.4429 train_accuracy: 0.5160	val_loss: 1.4092 val_accuracy: 0.5220	test_loss: 1.4212 test_accuracy: 0.5090
2025-08-23 09:13:27,019 - INFO - train: {'epoch': 3, 'time_epoch': 10.65652, 'eta': 1038.31318, 'eta_hours': 0.28842, 'loss': 1.35539973, 'lr': 0.00015, 'params': 193993, 'time_iter': 0.04866, 'accuracy': 0.59343, 'f1': 0.56835, 'auc': 0.84792}
2025-08-23 09:13:27,691 - INFO - val: {'epoch': 3, 'time_epoch': 0.65922, 'loss': 1.30970249, 'lr': 0, 'params': 193993, 'time_iter': 0.0206, 'accuracy': 0.686, 'f1': 0.62183, 'auc': 0.89963}
2025-08-23 09:13:29,024 - INFO - test: {'epoch': 3, 'time_epoch': 1.32069, 'loss': 1.32597956, 'lr': 0, 'params': 193993, 'time_iter': 0.02096, 'accuracy': 0.662, 'f1': 0.60782, 'auc': 0.88359}
2025-08-23 09:13:29,026 - INFO - > Epoch 3: took 12.7s (avg 12.9s) | Best so far: epoch 3	train_loss: 1.3554 train_accuracy: 0.5934	val_loss: 1.3097 val_accuracy: 0.6860	test_loss: 1.3260 test_accuracy: 0.6620
2025-08-23 09:13:39,905 - INFO - train: {'epoch': 4, 'time_epoch': 10.86175, 'eta': 1028.37113, 'eta_hours': 0.28566, 'loss': 1.26057635, 'lr': 0.0002, 'params': 193993, 'time_iter': 0.0496, 'accuracy': 0.68371, 'f1': 0.66693, 'auc': 0.8782}
2025-08-23 09:13:40,590 - INFO - val: {'epoch': 4, 'time_epoch': 0.66953, 'loss': 1.21987694, 'lr': 0, 'params': 193993, 'time_iter': 0.02092, 'accuracy': 0.73, 'f1': 0.7345, 'auc': 0.91391}
2025-08-23 09:13:41,938 - INFO - test: {'epoch': 4, 'time_epoch': 1.33511, 'loss': 1.23809488, 'lr': 0, 'params': 193993, 'time_iter': 0.02119, 'accuracy': 0.709, 'f1': 0.71447, 'auc': 0.8896}
2025-08-23 09:13:41,940 - INFO - > Epoch 4: took 12.9s (avg 12.9s) | Best so far: epoch 4	train_loss: 1.2606 train_accuracy: 0.6837	val_loss: 1.2199 val_accuracy: 0.7300	test_loss: 1.2381 test_accuracy: 0.7090
2025-08-23 09:13:52,752 - INFO - train: {'epoch': 5, 'time_epoch': 10.79378, 'eta': 1017.05769, 'eta_hours': 0.28252, 'loss': 1.16470226, 'lr': 0.00025, 'params': 193993, 'time_iter': 0.04929, 'accuracy': 0.71971, 'f1': 0.71083, 'auc': 0.897}
2025-08-23 09:13:53,427 - INFO - val: {'epoch': 5, 'time_epoch': 0.66191, 'loss': 1.11713857, 'lr': 0, 'params': 193993, 'time_iter': 0.02068, 'accuracy': 0.712, 'f1': 0.68578, 'auc': 0.92832}
2025-08-23 09:13:54,769 - INFO - test: {'epoch': 5, 'time_epoch': 1.32883, 'loss': 1.13348532, 'lr': 0, 'params': 193993, 'time_iter': 0.02109, 'accuracy': 0.687, 'f1': 0.66288, 'auc': 0.91532}
2025-08-23 09:13:54,771 - INFO - > Epoch 5: took 12.8s (avg 12.9s) | Best so far: epoch 4	train_loss: 1.2606 train_accuracy: 0.6837	val_loss: 1.2199 val_accuracy: 0.7300	test_loss: 1.2381 test_accuracy: 0.7090
2025-08-23 09:14:05,608 - INFO - train: {'epoch': 6, 'time_epoch': 10.81986, 'eta': 1006.23919, 'eta_hours': 0.27951, 'loss': 1.07397257, 'lr': 0.0003, 'params': 193993, 'time_iter': 0.04941, 'accuracy': 0.72829, 'f1': 0.71956, 'auc': 0.90388}
2025-08-23 09:14:06,281 - INFO - val: {'epoch': 6, 'time_epoch': 0.66014, 'loss': 1.03430386, 'lr': 0, 'params': 193993, 'time_iter': 0.02063, 'accuracy': 0.746, 'f1': 0.74034, 'auc': 0.91856}
2025-08-23 09:14:07,615 - INFO - test: {'epoch': 6, 'time_epoch': 1.32151, 'loss': 1.05178377, 'lr': 0, 'params': 193993, 'time_iter': 0.02098, 'accuracy': 0.734, 'f1': 0.73103, 'auc': 0.91021}
2025-08-23 09:14:07,617 - INFO - > Epoch 6: took 12.8s (avg 12.9s) | Best so far: epoch 6	train_loss: 1.0740 train_accuracy: 0.7283	val_loss: 1.0343 val_accuracy: 0.7460	test_loss: 1.0518 test_accuracy: 0.7340
2025-08-23 09:14:18,464 - INFO - train: {'epoch': 7, 'time_epoch': 10.8295, 'eta': 995.53119, 'eta_hours': 0.27654, 'loss': 0.9985776, 'lr': 0.00035, 'params': 193993, 'time_iter': 0.04945, 'accuracy': 0.74, 'f1': 0.73661, 'auc': 0.90781}
2025-08-23 09:14:19,139 - INFO - val: {'epoch': 7, 'time_epoch': 0.66144, 'loss': 0.96175673, 'lr': 0, 'params': 193993, 'time_iter': 0.02067, 'accuracy': 0.738, 'f1': 0.71321, 'auc': 0.92481}
2025-08-23 09:14:20,471 - INFO - test: {'epoch': 7, 'time_epoch': 1.32014, 'loss': 0.98138003, 'lr': 0, 'params': 193993, 'time_iter': 0.02095, 'accuracy': 0.707, 'f1': 0.68133, 'auc': 0.91452}
2025-08-23 09:14:20,472 - INFO - > Epoch 7: took 12.9s (avg 12.9s) | Best so far: epoch 6	train_loss: 1.0740 train_accuracy: 0.7283	val_loss: 1.0343 val_accuracy: 0.7460	test_loss: 1.0518 test_accuracy: 0.7340
2025-08-23 09:14:31,310 - INFO - train: {'epoch': 8, 'time_epoch': 10.82, 'eta': 984.70015, 'eta_hours': 0.27353, 'loss': 0.91997917, 'lr': 0.0004, 'params': 193993, 'time_iter': 0.04941, 'accuracy': 0.742, 'f1': 0.73939, 'auc': 0.91823}
2025-08-23 09:14:31,983 - INFO - val: {'epoch': 8, 'time_epoch': 0.65983, 'loss': 0.86254244, 'lr': 0, 'params': 193993, 'time_iter': 0.02062, 'accuracy': 0.792, 'f1': 0.79368, 'auc': 0.93363}
2025-08-23 09:14:33,316 - INFO - test: {'epoch': 8, 'time_epoch': 1.32266, 'loss': 0.90145221, 'lr': 0, 'params': 193993, 'time_iter': 0.02099, 'accuracy': 0.774, 'f1': 0.77657, 'auc': 0.9082}
2025-08-23 09:14:33,318 - INFO - > Epoch 8: took 12.8s (avg 12.9s) | Best so far: epoch 8	train_loss: 0.9200 train_accuracy: 0.7420	val_loss: 0.8625 val_accuracy: 0.7920	test_loss: 0.9015 test_accuracy: 0.7740
2025-08-23 09:14:44,121 - INFO - train: {'epoch': 9, 'time_epoch': 10.78529, 'eta': 973.55898, 'eta_hours': 0.27043, 'loss': 0.84977746, 'lr': 0.00045, 'params': 193993, 'time_iter': 0.04925, 'accuracy': 0.76057, 'f1': 0.75937, 'auc': 0.92407}
2025-08-23 09:14:44,791 - INFO - val: {'epoch': 9, 'time_epoch': 0.6576, 'loss': 0.79148113, 'lr': 0, 'params': 193993, 'time_iter': 0.02055, 'accuracy': 0.796, 'f1': 0.79354, 'auc': 0.94436}
2025-08-23 09:14:46,113 - INFO - test: {'epoch': 9, 'time_epoch': 1.30995, 'loss': 0.81952177, 'lr': 0, 'params': 193993, 'time_iter': 0.02079, 'accuracy': 0.783, 'f1': 0.78084, 'auc': 0.93608}
2025-08-23 09:14:46,114 - INFO - > Epoch 9: took 12.8s (avg 12.9s) | Best so far: epoch 9	train_loss: 0.8498 train_accuracy: 0.7606	val_loss: 0.7915 val_accuracy: 0.7960	test_loss: 0.8195 test_accuracy: 0.7830
2025-08-23 09:14:56,938 - INFO - train: {'epoch': 10, 'time_epoch': 10.80644, 'eta': 962.65361, 'eta_hours': 0.2674, 'loss': 0.77233467, 'lr': 0.0005, 'params': 193993, 'time_iter': 0.04934, 'accuracy': 0.78286, 'f1': 0.7835, 'auc': 0.93318}
2025-08-23 09:14:57,605 - INFO - val: {'epoch': 10, 'time_epoch': 0.65303, 'loss': 0.80067816, 'lr': 0, 'params': 193993, 'time_iter': 0.02041, 'accuracy': 0.756, 'f1': 0.75165, 'auc': 0.93123}
2025-08-23 09:14:58,956 - INFO - test: {'epoch': 10, 'time_epoch': 1.33703, 'loss': 0.79971026, 'lr': 0, 'params': 193993, 'time_iter': 0.02122, 'accuracy': 0.741, 'f1': 0.73389, 'auc': 0.93581}
2025-08-23 09:14:58,959 - INFO - > Epoch 10: took 12.8s (avg 12.9s) | Best so far: epoch 9	train_loss: 0.8498 train_accuracy: 0.7606	val_loss: 0.7915 val_accuracy: 0.7960	test_loss: 0.8195 test_accuracy: 0.7830
2025-08-23 09:15:09,805 - INFO - train: {'epoch': 11, 'time_epoch': 10.8275, 'eta': 951.91914, 'eta_hours': 0.26442, 'loss': 0.73815226, 'lr': 0.00049985, 'params': 193993, 'time_iter': 0.04944, 'accuracy': 0.77143, 'f1': 0.77308, 'auc': 0.93406}
2025-08-23 09:15:10,480 - INFO - val: {'epoch': 11, 'time_epoch': 0.66383, 'loss': 0.7117074, 'lr': 0, 'params': 193993, 'time_iter': 0.02074, 'accuracy': 0.778, 'f1': 0.77473, 'auc': 0.94797}
2025-08-23 09:15:11,800 - INFO - test: {'epoch': 11, 'time_epoch': 1.30757, 'loss': 0.72728969, 'lr': 0, 'params': 193993, 'time_iter': 0.02076, 'accuracy': 0.766, 'f1': 0.76217, 'auc': 0.94803}
2025-08-23 09:15:11,801 - INFO - > Epoch 11: took 12.8s (avg 12.9s) | Best so far: epoch 9	train_loss: 0.8498 train_accuracy: 0.7606	val_loss: 0.7915 val_accuracy: 0.7960	test_loss: 0.8195 test_accuracy: 0.7830
2025-08-23 09:15:22,546 - INFO - train: {'epoch': 12, 'time_epoch': 10.72744, 'eta': 940.50078, 'eta_hours': 0.26125, 'loss': 0.67305471, 'lr': 0.00049939, 'params': 193993, 'time_iter': 0.04898, 'accuracy': 0.796, 'f1': 0.79691, 'auc': 0.94269}
2025-08-23 09:15:23,214 - INFO - val: {'epoch': 12, 'time_epoch': 0.65651, 'loss': 0.64428588, 'lr': 0, 'params': 193993, 'time_iter': 0.02052, 'accuracy': 0.822, 'f1': 0.82602, 'auc': 0.95075}
2025-08-23 09:15:24,540 - INFO - test: {'epoch': 12, 'time_epoch': 1.31391, 'loss': 0.67224384, 'lr': 0, 'params': 193993, 'time_iter': 0.02086, 'accuracy': 0.802, 'f1': 0.80764, 'auc': 0.94578}
2025-08-23 09:15:24,542 - INFO - > Epoch 12: took 12.7s (avg 12.8s) | Best so far: epoch 12	train_loss: 0.6731 train_accuracy: 0.7960	val_loss: 0.6443 val_accuracy: 0.8220	test_loss: 0.6722 test_accuracy: 0.8020
2025-08-23 09:15:35,303 - INFO - train: {'epoch': 13, 'time_epoch': 10.7452, 'eta': 929.29018, 'eta_hours': 0.25814, 'loss': 0.65240616, 'lr': 0.00049863, 'params': 193993, 'time_iter': 0.04906, 'accuracy': 0.79057, 'f1': 0.79153, 'auc': 0.9409}
2025-08-23 09:15:35,971 - INFO - val: {'epoch': 13, 'time_epoch': 0.65472, 'loss': 0.61150195, 'lr': 0, 'params': 193993, 'time_iter': 0.02046, 'accuracy': 0.8, 'f1': 0.79844, 'auc': 0.95864}
2025-08-23 09:15:37,299 - INFO - test: {'epoch': 13, 'time_epoch': 1.31693, 'loss': 0.65492397, 'lr': 0, 'params': 193993, 'time_iter': 0.0209, 'accuracy': 0.775, 'f1': 0.77436, 'auc': 0.94849}
2025-08-23 09:15:37,301 - INFO - > Epoch 13: took 12.8s (avg 12.8s) | Best so far: epoch 12	train_loss: 0.6731 train_accuracy: 0.7960	val_loss: 0.6443 val_accuracy: 0.8220	test_loss: 0.6722 test_accuracy: 0.8020
2025-08-23 09:15:48,073 - INFO - train: {'epoch': 14, 'time_epoch': 10.756, 'eta': 918.20284, 'eta_hours': 0.25506, 'loss': 0.60611867, 'lr': 0.00049757, 'params': 193993, 'time_iter': 0.04911, 'accuracy': 0.80629, 'f1': 0.80754, 'auc': 0.94868}
2025-08-23 09:15:48,741 - INFO - val: {'epoch': 14, 'time_epoch': 0.65615, 'loss': 0.56961643, 'lr': 0, 'params': 193993, 'time_iter': 0.0205, 'accuracy': 0.834, 'f1': 0.83878, 'auc': 0.96114}
2025-08-23 09:15:50,075 - INFO - test: {'epoch': 14, 'time_epoch': 1.32101, 'loss': 0.60917396, 'lr': 0, 'params': 193993, 'time_iter': 0.02097, 'accuracy': 0.815, 'f1': 0.81874, 'auc': 0.95368}
2025-08-23 09:15:50,076 - INFO - > Epoch 14: took 12.8s (avg 12.8s) | Best so far: epoch 14	train_loss: 0.6061 train_accuracy: 0.8063	val_loss: 0.5696 val_accuracy: 0.8340	test_loss: 0.6092 test_accuracy: 0.8150
2025-08-23 09:16:00,864 - INFO - train: {'epoch': 15, 'time_epoch': 10.77203, 'eta': 907.24106, 'eta_hours': 0.25201, 'loss': 0.57718735, 'lr': 0.0004962, 'params': 193993, 'time_iter': 0.04919, 'accuracy': 0.81371, 'f1': 0.81631, 'auc': 0.95126}
2025-08-23 09:16:01,537 - INFO - val: {'epoch': 15, 'time_epoch': 0.66125, 'loss': 0.61440503, 'lr': 0, 'params': 193993, 'time_iter': 0.02066, 'accuracy': 0.784, 'f1': 0.7894, 'auc': 0.95735}
2025-08-23 09:16:02,858 - INFO - test: {'epoch': 15, 'time_epoch': 1.30979, 'loss': 0.64593564, 'lr': 0, 'params': 193993, 'time_iter': 0.02079, 'accuracy': 0.76, 'f1': 0.76709, 'auc': 0.95371}
2025-08-23 09:16:02,860 - INFO - > Epoch 15: took 12.8s (avg 12.8s) | Best so far: epoch 14	train_loss: 0.6061 train_accuracy: 0.8063	val_loss: 0.5696 val_accuracy: 0.8340	test_loss: 0.6092 test_accuracy: 0.8150
2025-08-23 09:16:13,676 - INFO - train: {'epoch': 16, 'time_epoch': 10.79938, 'eta': 896.43515, 'eta_hours': 0.24901, 'loss': 0.54291707, 'lr': 0.00049454, 'params': 193993, 'time_iter': 0.04931, 'accuracy': 0.82314, 'f1': 0.82496, 'auc': 0.95702}
2025-08-23 09:16:14,347 - INFO - val: {'epoch': 16, 'time_epoch': 0.65795, 'loss': 0.55137833, 'lr': 0, 'params': 193993, 'time_iter': 0.02056, 'accuracy': 0.796, 'f1': 0.80122, 'auc': 0.96585}
2025-08-23 09:16:15,677 - INFO - test: {'epoch': 16, 'time_epoch': 1.31873, 'loss': 0.60036651, 'lr': 0, 'params': 193993, 'time_iter': 0.02093, 'accuracy': 0.78, 'f1': 0.786, 'auc': 0.95772}
2025-08-23 09:16:15,678 - INFO - > Epoch 16: took 12.8s (avg 12.8s) | Best so far: epoch 14	train_loss: 0.6061 train_accuracy: 0.8063	val_loss: 0.5696 val_accuracy: 0.8340	test_loss: 0.6092 test_accuracy: 0.8150
2025-08-23 09:16:26,530 - INFO - train: {'epoch': 17, 'time_epoch': 10.83422, 'eta': 885.78869, 'eta_hours': 0.24605, 'loss': 0.52050672, 'lr': 0.00049257, 'params': 193993, 'time_iter': 0.04947, 'accuracy': 0.82114, 'f1': 0.82327, 'auc': 0.95895}
2025-08-23 09:16:27,204 - INFO - val: {'epoch': 17, 'time_epoch': 0.66131, 'loss': 0.57967019, 'lr': 0, 'params': 193993, 'time_iter': 0.02067, 'accuracy': 0.78, 'f1': 0.78967, 'auc': 0.96298}
2025-08-23 09:16:28,545 - INFO - test: {'epoch': 17, 'time_epoch': 1.32808, 'loss': 0.64503792, 'lr': 0, 'params': 193993, 'time_iter': 0.02108, 'accuracy': 0.748, 'f1': 0.75956, 'auc': 0.95204}
2025-08-23 09:16:28,547 - INFO - > Epoch 17: took 12.9s (avg 12.8s) | Best so far: epoch 14	train_loss: 0.6061 train_accuracy: 0.8063	val_loss: 0.5696 val_accuracy: 0.8340	test_loss: 0.6092 test_accuracy: 0.8150
2025-08-23 09:16:39,407 - INFO - train: {'epoch': 18, 'time_epoch': 10.84232, 'eta': 875.15698, 'eta_hours': 0.2431, 'loss': 0.49645655, 'lr': 0.00049032, 'params': 193993, 'time_iter': 0.04951, 'accuracy': 0.82829, 'f1': 0.82998, 'auc': 0.96219}
2025-08-23 09:16:40,077 - INFO - val: {'epoch': 18, 'time_epoch': 0.65836, 'loss': 0.46372145, 'lr': 0, 'params': 193993, 'time_iter': 0.02057, 'accuracy': 0.834, 'f1': 0.83201, 'auc': 0.9677}
2025-08-23 09:16:41,407 - INFO - test: {'epoch': 18, 'time_epoch': 1.31836, 'loss': 0.50169479, 'lr': 0, 'params': 193993, 'time_iter': 0.02093, 'accuracy': 0.819, 'f1': 0.81804, 'auc': 0.95956}
2025-08-23 09:16:41,409 - INFO - > Epoch 18: took 12.9s (avg 12.8s) | Best so far: epoch 14	train_loss: 0.6061 train_accuracy: 0.8063	val_loss: 0.5696 val_accuracy: 0.8340	test_loss: 0.6092 test_accuracy: 0.8150
2025-08-23 09:16:52,063 - INFO - train: {'epoch': 19, 'time_epoch': 10.63909, 'eta': 863.69129, 'eta_hours': 0.23991, 'loss': 0.49306155, 'lr': 0.00048776, 'params': 193993, 'time_iter': 0.04858, 'accuracy': 0.828, 'f1': 0.82979, 'auc': 0.96084}
2025-08-23 09:16:52,703 - INFO - val: {'epoch': 19, 'time_epoch': 0.6295, 'loss': 0.56937327, 'lr': 0, 'params': 193993, 'time_iter': 0.01967, 'accuracy': 0.788, 'f1': 0.78269, 'auc': 0.95985}
2025-08-23 09:16:54,039 - INFO - test: {'epoch': 19, 'time_epoch': 1.32431, 'loss': 0.61162921, 'lr': 0, 'params': 193993, 'time_iter': 0.02102, 'accuracy': 0.764, 'f1': 0.76006, 'auc': 0.95127}
2025-08-23 09:16:54,067 - INFO - > Epoch 19: took 12.7s (avg 12.8s) | Best so far: epoch 14	train_loss: 0.6061 train_accuracy: 0.8063	val_loss: 0.5696 val_accuracy: 0.8340	test_loss: 0.6092 test_accuracy: 0.8150
2025-08-23 09:17:04,843 - INFO - train: {'epoch': 20, 'time_epoch': 10.7594, 'eta': 852.75692, 'eta_hours': 0.23688, 'loss': 0.48689982, 'lr': 0.00048492, 'params': 193993, 'time_iter': 0.04913, 'accuracy': 0.82857, 'f1': 0.8303, 'auc': 0.96158}
2025-08-23 09:17:05,507 - INFO - val: {'epoch': 20, 'time_epoch': 0.65191, 'loss': 0.45265637, 'lr': 0, 'params': 193993, 'time_iter': 0.02037, 'accuracy': 0.84, 'f1': 0.84437, 'auc': 0.97055}
2025-08-23 09:17:06,801 - INFO - test: {'epoch': 20, 'time_epoch': 1.28153, 'loss': 0.48661479, 'lr': 0, 'params': 193993, 'time_iter': 0.02034, 'accuracy': 0.824, 'f1': 0.82911, 'auc': 0.96344}
2025-08-23 09:17:06,804 - INFO - > Epoch 20: took 12.7s (avg 12.8s) | Best so far: epoch 20	train_loss: 0.4869 train_accuracy: 0.8286	val_loss: 0.4527 val_accuracy: 0.8400	test_loss: 0.4866 test_accuracy: 0.8240
2025-08-23 09:17:17,592 - INFO - train: {'epoch': 21, 'time_epoch': 10.77047, 'eta': 841.87771, 'eta_hours': 0.23385, 'loss': 0.4712192, 'lr': 0.0004818, 'params': 193993, 'time_iter': 0.04918, 'accuracy': 0.83286, 'f1': 0.83481, 'auc': 0.96353}
2025-08-23 09:17:18,267 - INFO - val: {'epoch': 21, 'time_epoch': 0.66241, 'loss': 0.51719662, 'lr': 0, 'params': 193993, 'time_iter': 0.0207, 'accuracy': 0.808, 'f1': 0.80169, 'auc': 0.96872}
2025-08-23 09:17:19,612 - INFO - test: {'epoch': 21, 'time_epoch': 1.33105, 'loss': 0.55834527, 'lr': 0, 'params': 193993, 'time_iter': 0.02113, 'accuracy': 0.791, 'f1': 0.78718, 'auc': 0.95874}
2025-08-23 09:17:19,615 - INFO - > Epoch 21: took 12.8s (avg 12.8s) | Best so far: epoch 20	train_loss: 0.4869 train_accuracy: 0.8286	val_loss: 0.4527 val_accuracy: 0.8400	test_loss: 0.4866 test_accuracy: 0.8240
2025-08-23 09:17:30,465 - INFO - train: {'epoch': 22, 'time_epoch': 10.83224, 'eta': 831.21477, 'eta_hours': 0.23089, 'loss': 0.4489965, 'lr': 0.00047839, 'params': 193993, 'time_iter': 0.04946, 'accuracy': 0.84, 'f1': 0.84133, 'auc': 0.96623}
2025-08-23 09:17:31,133 - INFO - val: {'epoch': 22, 'time_epoch': 0.65551, 'loss': 0.50153461, 'lr': 0, 'params': 193993, 'time_iter': 0.02048, 'accuracy': 0.808, 'f1': 0.80019, 'auc': 0.96474}
2025-08-23 09:17:32,461 - INFO - test: {'epoch': 22, 'time_epoch': 1.31468, 'loss': 0.54811249, 'lr': 0, 'params': 193993, 'time_iter': 0.02087, 'accuracy': 0.77, 'f1': 0.76245, 'auc': 0.95783}
2025-08-23 09:17:32,463 - INFO - > Epoch 22: took 12.8s (avg 12.8s) | Best so far: epoch 20	train_loss: 0.4869 train_accuracy: 0.8286	val_loss: 0.4527 val_accuracy: 0.8400	test_loss: 0.4866 test_accuracy: 0.8240
2025-08-23 09:17:43,401 - INFO - train: {'epoch': 23, 'time_epoch': 10.92027, 'eta': 820.81647, 'eta_hours': 0.228, 'loss': 0.44244435, 'lr': 0.0004747, 'params': 193993, 'time_iter': 0.04986, 'accuracy': 0.84029, 'f1': 0.84127, 'auc': 0.96708}
2025-08-23 09:17:44,053 - INFO - val: {'epoch': 23, 'time_epoch': 0.64022, 'loss': 0.40949102, 'lr': 0, 'params': 193993, 'time_iter': 0.02001, 'accuracy': 0.846, 'f1': 0.84951, 'auc': 0.97664}
2025-08-23 09:17:45,354 - INFO - test: {'epoch': 23, 'time_epoch': 1.28653, 'loss': 0.46877121, 'lr': 0, 'params': 193993, 'time_iter': 0.02042, 'accuracy': 0.829, 'f1': 0.83129, 'auc': 0.96851}
2025-08-23 09:17:45,356 - INFO - > Epoch 23: took 12.9s (avg 12.8s) | Best so far: epoch 23	train_loss: 0.4424 train_accuracy: 0.8403	val_loss: 0.4095 val_accuracy: 0.8460	test_loss: 0.4688 test_accuracy: 0.8290
2025-08-23 09:17:55,824 - INFO - train: {'epoch': 24, 'time_epoch': 10.45104, 'eta': 808.9687, 'eta_hours': 0.22471, 'loss': 0.43057866, 'lr': 0.00047074, 'params': 193993, 'time_iter': 0.04772, 'accuracy': 0.854, 'f1': 0.85586, 'auc': 0.96802}
2025-08-23 09:17:56,475 - INFO - val: {'epoch': 24, 'time_epoch': 0.63913, 'loss': 0.4668155, 'lr': 0, 'params': 193993, 'time_iter': 0.01997, 'accuracy': 0.802, 'f1': 0.79803, 'auc': 0.97185}
2025-08-23 09:17:57,767 - INFO - test: {'epoch': 24, 'time_epoch': 1.2814, 'loss': 0.49209757, 'lr': 0, 'params': 193993, 'time_iter': 0.02034, 'accuracy': 0.8, 'f1': 0.80363, 'auc': 0.96671}
2025-08-23 09:17:57,769 - INFO - > Epoch 24: took 12.4s (avg 12.8s) | Best so far: epoch 23	train_loss: 0.4424 train_accuracy: 0.8403	val_loss: 0.4095 val_accuracy: 0.8460	test_loss: 0.4688 test_accuracy: 0.8290
2025-08-23 09:18:08,195 - INFO - train: {'epoch': 25, 'time_epoch': 10.4118, 'eta': 797.11671, 'eta_hours': 0.22142, 'loss': 0.41976211, 'lr': 0.00046651, 'params': 193993, 'time_iter': 0.04754, 'accuracy': 0.84771, 'f1': 0.84955, 'auc': 0.96995}
2025-08-23 09:18:08,842 - INFO - val: {'epoch': 25, 'time_epoch': 0.63657, 'loss': 0.50883342, 'lr': 0, 'params': 193993, 'time_iter': 0.01989, 'accuracy': 0.808, 'f1': 0.80074, 'auc': 0.96997}
2025-08-23 09:18:10,141 - INFO - test: {'epoch': 25, 'time_epoch': 1.28882, 'loss': 0.54449556, 'lr': 0, 'params': 193993, 'time_iter': 0.02046, 'accuracy': 0.783, 'f1': 0.78385, 'auc': 0.96451}
2025-08-23 09:18:10,143 - INFO - > Epoch 25: took 12.4s (avg 12.8s) | Best so far: epoch 23	train_loss: 0.4424 train_accuracy: 0.8403	val_loss: 0.4095 val_accuracy: 0.8460	test_loss: 0.4688 test_accuracy: 0.8290
2025-08-23 09:18:20,548 - INFO - train: {'epoch': 26, 'time_epoch': 10.39052, 'eta': 785.31388, 'eta_hours': 0.21814, 'loss': 0.40094547, 'lr': 0.00046201, 'params': 193993, 'time_iter': 0.04745, 'accuracy': 0.85286, 'f1': 0.8543, 'auc': 0.97155}
2025-08-23 09:18:21,201 - INFO - val: {'epoch': 26, 'time_epoch': 0.64264, 'loss': 0.42044004, 'lr': 0, 'params': 193993, 'time_iter': 0.02008, 'accuracy': 0.84, 'f1': 0.84423, 'auc': 0.97491}
2025-08-23 09:18:22,487 - INFO - test: {'epoch': 26, 'time_epoch': 1.27532, 'loss': 0.44803227, 'lr': 0, 'params': 193993, 'time_iter': 0.02024, 'accuracy': 0.826, 'f1': 0.83049, 'auc': 0.96993}
2025-08-23 09:18:22,489 - INFO - > Epoch 26: took 12.3s (avg 12.8s) | Best so far: epoch 23	train_loss: 0.4424 train_accuracy: 0.8403	val_loss: 0.4095 val_accuracy: 0.8460	test_loss: 0.4688 test_accuracy: 0.8290
2025-08-23 09:18:32,912 - INFO - train: {'epoch': 27, 'time_epoch': 10.40932, 'eta': 773.66026, 'eta_hours': 0.21491, 'loss': 0.38902449, 'lr': 0.00045726, 'params': 193993, 'time_iter': 0.04753, 'accuracy': 0.86114, 'f1': 0.86221, 'auc': 0.97347}
2025-08-23 09:18:33,563 - INFO - val: {'epoch': 27, 'time_epoch': 0.63978, 'loss': 0.42089787, 'lr': 0, 'params': 193993, 'time_iter': 0.01999, 'accuracy': 0.85, 'f1': 0.85019, 'auc': 0.97674}
2025-08-23 09:18:34,853 - INFO - test: {'epoch': 27, 'time_epoch': 1.27978, 'loss': 0.46677113, 'lr': 0, 'params': 193993, 'time_iter': 0.02031, 'accuracy': 0.827, 'f1': 0.82819, 'auc': 0.96717}
2025-08-23 09:18:34,854 - INFO - > Epoch 27: took 12.4s (avg 12.8s) | Best so far: epoch 27	train_loss: 0.3890 train_accuracy: 0.8611	val_loss: 0.4209 val_accuracy: 0.8500	test_loss: 0.4668 test_accuracy: 0.8270
2025-08-23 09:18:45,293 - INFO - train: {'epoch': 28, 'time_epoch': 10.42375, 'eta': 762.12778, 'eta_hours': 0.2117, 'loss': 0.37281434, 'lr': 0.00045225, 'params': 193993, 'time_iter': 0.0476, 'accuracy': 0.87029, 'f1': 0.87063, 'auc': 0.97507}
2025-08-23 09:18:45,943 - INFO - val: {'epoch': 28, 'time_epoch': 0.63875, 'loss': 0.36365958, 'lr': 0, 'params': 193993, 'time_iter': 0.01996, 'accuracy': 0.876, 'f1': 0.87725, 'auc': 0.97668}
2025-08-23 09:18:47,236 - INFO - test: {'epoch': 28, 'time_epoch': 1.28242, 'loss': 0.41800101, 'lr': 0, 'params': 193993, 'time_iter': 0.02036, 'accuracy': 0.849, 'f1': 0.85055, 'auc': 0.97079}
2025-08-23 09:18:47,237 - INFO - > Epoch 28: took 12.4s (avg 12.7s) | Best so far: epoch 28	train_loss: 0.3728 train_accuracy: 0.8703	val_loss: 0.3637 val_accuracy: 0.8760	test_loss: 0.4180 test_accuracy: 0.8490
2025-08-23 09:18:57,664 - INFO - train: {'epoch': 29, 'time_epoch': 10.41307, 'eta': 750.6443, 'eta_hours': 0.20851, 'loss': 0.36979358, 'lr': 0.000447, 'params': 193993, 'time_iter': 0.04755, 'accuracy': 0.87314, 'f1': 0.87393, 'auc': 0.97603}
2025-08-23 09:18:58,313 - INFO - val: {'epoch': 29, 'time_epoch': 0.63905, 'loss': 0.34654658, 'lr': 0, 'params': 193993, 'time_iter': 0.01997, 'accuracy': 0.876, 'f1': 0.87829, 'auc': 0.98008}
2025-08-23 09:18:59,602 - INFO - test: {'epoch': 29, 'time_epoch': 1.27896, 'loss': 0.40873576, 'lr': 0, 'params': 193993, 'time_iter': 0.0203, 'accuracy': 0.85, 'f1': 0.85309, 'auc': 0.97293}
2025-08-23 09:18:59,603 - INFO - > Epoch 29: took 12.4s (avg 12.7s) | Best so far: epoch 28	train_loss: 0.3728 train_accuracy: 0.8703	val_loss: 0.3637 val_accuracy: 0.8760	test_loss: 0.4180 test_accuracy: 0.8490
2025-08-23 09:19:10,036 - INFO - train: {'epoch': 30, 'time_epoch': 10.41737, 'eta': 739.23945, 'eta_hours': 0.20534, 'loss': 0.36390851, 'lr': 0.00044151, 'params': 193993, 'time_iter': 0.04757, 'accuracy': 0.87229, 'f1': 0.87358, 'auc': 0.97607}
2025-08-23 09:19:10,686 - INFO - val: {'epoch': 30, 'time_epoch': 0.63915, 'loss': 0.34768422, 'lr': 0, 'params': 193993, 'time_iter': 0.01997, 'accuracy': 0.876, 'f1': 0.87861, 'auc': 0.98126}
2025-08-23 09:19:11,976 - INFO - test: {'epoch': 30, 'time_epoch': 1.28028, 'loss': 0.41822242, 'lr': 0, 'params': 193993, 'time_iter': 0.02032, 'accuracy': 0.835, 'f1': 0.83802, 'auc': 0.97436}
2025-08-23 09:19:11,978 - INFO - > Epoch 30: took 12.4s (avg 12.7s) | Best so far: epoch 28	train_loss: 0.3728 train_accuracy: 0.8703	val_loss: 0.3637 val_accuracy: 0.8760	test_loss: 0.4180 test_accuracy: 0.8490
2025-08-23 09:19:22,373 - INFO - train: {'epoch': 31, 'time_epoch': 10.38175, 'eta': 727.82063, 'eta_hours': 0.20217, 'loss': 0.3454934, 'lr': 0.00043579, 'params': 193993, 'time_iter': 0.04741, 'accuracy': 0.87743, 'f1': 0.87762, 'auc': 0.97857}
2025-08-23 09:19:23,024 - INFO - val: {'epoch': 31, 'time_epoch': 0.63973, 'loss': 0.32966282, 'lr': 0, 'params': 193993, 'time_iter': 0.01999, 'accuracy': 0.886, 'f1': 0.89018, 'auc': 0.98409}
2025-08-23 09:19:24,311 - INFO - test: {'epoch': 31, 'time_epoch': 1.27637, 'loss': 0.40398871, 'lr': 0, 'params': 193993, 'time_iter': 0.02026, 'accuracy': 0.86, 'f1': 0.86392, 'auc': 0.97566}
2025-08-23 09:19:24,312 - INFO - > Epoch 31: took 12.3s (avg 12.7s) | Best so far: epoch 31	train_loss: 0.3455 train_accuracy: 0.8774	val_loss: 0.3297 val_accuracy: 0.8860	test_loss: 0.4040 test_accuracy: 0.8600
2025-08-23 09:19:34,739 - INFO - train: {'epoch': 32, 'time_epoch': 10.41268, 'eta': 716.52745, 'eta_hours': 0.19904, 'loss': 0.32499685, 'lr': 0.00042983, 'params': 193993, 'time_iter': 0.04755, 'accuracy': 0.88543, 'f1': 0.88572, 'auc': 0.98026}
2025-08-23 09:19:35,388 - INFO - val: {'epoch': 32, 'time_epoch': 0.63808, 'loss': 0.3895663, 'lr': 0, 'params': 193993, 'time_iter': 0.01994, 'accuracy': 0.866, 'f1': 0.87047, 'auc': 0.98046}
2025-08-23 09:19:36,693 - INFO - test: {'epoch': 32, 'time_epoch': 1.29493, 'loss': 0.47156509, 'lr': 0, 'params': 193993, 'time_iter': 0.02055, 'accuracy': 0.827, 'f1': 0.8348, 'auc': 0.9712}
2025-08-23 09:19:36,694 - INFO - > Epoch 32: took 12.4s (avg 12.7s) | Best so far: epoch 31	train_loss: 0.3455 train_accuracy: 0.8774	val_loss: 0.3297 val_accuracy: 0.8860	test_loss: 0.4040 test_accuracy: 0.8600
2025-08-23 09:19:47,107 - INFO - train: {'epoch': 33, 'time_epoch': 10.3987, 'eta': 705.25893, 'eta_hours': 0.19591, 'loss': 0.33671272, 'lr': 0.00042366, 'params': 193993, 'time_iter': 0.04748, 'accuracy': 0.87971, 'f1': 0.88089, 'auc': 0.97863}
2025-08-23 09:19:47,753 - INFO - val: {'epoch': 33, 'time_epoch': 0.63504, 'loss': 0.32830803, 'lr': 0, 'params': 193993, 'time_iter': 0.01984, 'accuracy': 0.882, 'f1': 0.88398, 'auc': 0.98159}
2025-08-23 09:19:49,044 - INFO - test: {'epoch': 33, 'time_epoch': 1.28094, 'loss': 0.39502315, 'lr': 0, 'params': 193993, 'time_iter': 0.02033, 'accuracy': 0.85, 'f1': 0.85282, 'auc': 0.97606}
2025-08-23 09:19:49,046 - INFO - > Epoch 33: took 12.4s (avg 12.7s) | Best so far: epoch 31	train_loss: 0.3455 train_accuracy: 0.8774	val_loss: 0.3297 val_accuracy: 0.8860	test_loss: 0.4040 test_accuracy: 0.8600
2025-08-23 09:19:59,453 - INFO - train: {'epoch': 34, 'time_epoch': 10.39477, 'eta': 694.03281, 'eta_hours': 0.19279, 'loss': 0.33351534, 'lr': 0.00041728, 'params': 193993, 'time_iter': 0.04746, 'accuracy': 0.88314, 'f1': 0.88388, 'auc': 0.9793}
2025-08-23 09:20:00,100 - INFO - val: {'epoch': 34, 'time_epoch': 0.63658, 'loss': 0.37187989, 'lr': 0, 'params': 193993, 'time_iter': 0.01989, 'accuracy': 0.856, 'f1': 0.85744, 'auc': 0.98037}
2025-08-23 09:20:01,379 - INFO - test: {'epoch': 34, 'time_epoch': 1.26915, 'loss': 0.38604553, 'lr': 0, 'params': 193993, 'time_iter': 0.02015, 'accuracy': 0.848, 'f1': 0.85058, 'auc': 0.97601}
2025-08-23 09:20:01,381 - INFO - > Epoch 34: took 12.3s (avg 12.7s) | Best so far: epoch 31	train_loss: 0.3455 train_accuracy: 0.8774	val_loss: 0.3297 val_accuracy: 0.8860	test_loss: 0.4040 test_accuracy: 0.8600
2025-08-23 09:20:11,776 - INFO - train: {'epoch': 35, 'time_epoch': 10.38146, 'eta': 682.82922, 'eta_hours': 0.18967, 'loss': 0.31809367, 'lr': 0.0004107, 'params': 193993, 'time_iter': 0.0474, 'accuracy': 0.88657, 'f1': 0.8876, 'auc': 0.98062}
2025-08-23 09:20:12,421 - INFO - val: {'epoch': 35, 'time_epoch': 0.63441, 'loss': 0.2957391, 'lr': 0, 'params': 193993, 'time_iter': 0.01983, 'accuracy': 0.882, 'f1': 0.88645, 'auc': 0.98568}
2025-08-23 09:20:13,702 - INFO - test: {'epoch': 35, 'time_epoch': 1.27068, 'loss': 0.36869269, 'lr': 0, 'params': 193993, 'time_iter': 0.02017, 'accuracy': 0.851, 'f1': 0.85657, 'auc': 0.97893}
2025-08-23 09:20:13,703 - INFO - > Epoch 35: took 12.3s (avg 12.7s) | Best so far: epoch 31	train_loss: 0.3455 train_accuracy: 0.8774	val_loss: 0.3297 val_accuracy: 0.8860	test_loss: 0.4040 test_accuracy: 0.8600
2025-08-23 09:20:24,070 - INFO - train: {'epoch': 36, 'time_epoch': 10.35273, 'eta': 671.62115, 'eta_hours': 0.18656, 'loss': 0.31541518, 'lr': 0.00040392, 'params': 193993, 'time_iter': 0.04727, 'accuracy': 0.89114, 'f1': 0.892, 'auc': 0.98125}
2025-08-23 09:20:24,715 - INFO - val: {'epoch': 36, 'time_epoch': 0.63429, 'loss': 0.30518217, 'lr': 0, 'params': 193993, 'time_iter': 0.01982, 'accuracy': 0.894, 'f1': 0.89648, 'auc': 0.98522}
2025-08-23 09:20:26,002 - INFO - test: {'epoch': 36, 'time_epoch': 1.27629, 'loss': 0.37444756, 'lr': 0, 'params': 193993, 'time_iter': 0.02026, 'accuracy': 0.862, 'f1': 0.86562, 'auc': 0.97752}
2025-08-23 09:20:26,003 - INFO - > Epoch 36: took 12.3s (avg 12.7s) | Best so far: epoch 36	train_loss: 0.3154 train_accuracy: 0.8911	val_loss: 0.3052 val_accuracy: 0.8940	test_loss: 0.3744 test_accuracy: 0.8620
2025-08-23 09:20:36,391 - INFO - train: {'epoch': 37, 'time_epoch': 10.37414, 'eta': 660.49303, 'eta_hours': 0.18347, 'loss': 0.29697733, 'lr': 0.00039695, 'params': 193993, 'time_iter': 0.04737, 'accuracy': 0.89657, 'f1': 0.8971, 'auc': 0.98306}
2025-08-23 09:20:37,054 - INFO - val: {'epoch': 37, 'time_epoch': 0.65305, 'loss': 0.29764261, 'lr': 0, 'params': 193993, 'time_iter': 0.02041, 'accuracy': 0.9, 'f1': 0.90247, 'auc': 0.98468}
2025-08-23 09:20:38,362 - INFO - test: {'epoch': 37, 'time_epoch': 1.29773, 'loss': 0.39299129, 'lr': 0, 'params': 193993, 'time_iter': 0.0206, 'accuracy': 0.859, 'f1': 0.86165, 'auc': 0.9766}
2025-08-23 09:20:38,364 - INFO - > Epoch 37: took 12.4s (avg 12.7s) | Best so far: epoch 37	train_loss: 0.2970 train_accuracy: 0.8966	val_loss: 0.2976 val_accuracy: 0.9000	test_loss: 0.3930 test_accuracy: 0.8590
2025-08-23 09:20:48,768 - INFO - train: {'epoch': 38, 'time_epoch': 10.39124, 'eta': 649.43032, 'eta_hours': 0.1804, 'loss': 0.30854906, 'lr': 0.0003898, 'params': 193993, 'time_iter': 0.04745, 'accuracy': 0.89229, 'f1': 0.89253, 'auc': 0.98244}
2025-08-23 09:20:49,414 - INFO - val: {'epoch': 38, 'time_epoch': 0.63547, 'loss': 0.27395743, 'lr': 0, 'params': 193993, 'time_iter': 0.01986, 'accuracy': 0.914, 'f1': 0.91498, 'auc': 0.98679}
2025-08-23 09:20:50,696 - INFO - test: {'epoch': 38, 'time_epoch': 1.27206, 'loss': 0.33381425, 'lr': 0, 'params': 193993, 'time_iter': 0.02019, 'accuracy': 0.885, 'f1': 0.88746, 'auc': 0.98094}
2025-08-23 09:20:50,698 - INFO - > Epoch 38: took 12.3s (avg 12.6s) | Best so far: epoch 38	train_loss: 0.3085 train_accuracy: 0.8923	val_loss: 0.2740 val_accuracy: 0.9140	test_loss: 0.3338 test_accuracy: 0.8850
2025-08-23 09:21:01,112 - INFO - train: {'epoch': 39, 'time_epoch': 10.39965, 'eta': 638.4138, 'eta_hours': 0.17734, 'loss': 0.28554903, 'lr': 0.00038248, 'params': 193993, 'time_iter': 0.04749, 'accuracy': 0.90057, 'f1': 0.90131, 'auc': 0.98414}
2025-08-23 09:21:01,759 - INFO - val: {'epoch': 39, 'time_epoch': 0.63568, 'loss': 0.31676212, 'lr': 0, 'params': 193993, 'time_iter': 0.01987, 'accuracy': 0.88, 'f1': 0.88275, 'auc': 0.98412}
2025-08-23 09:21:03,044 - INFO - test: {'epoch': 39, 'time_epoch': 1.27502, 'loss': 0.36874695, 'lr': 0, 'params': 193993, 'time_iter': 0.02024, 'accuracy': 0.856, 'f1': 0.86086, 'auc': 0.97827}
2025-08-23 09:21:03,046 - INFO - > Epoch 39: took 12.3s (avg 12.6s) | Best so far: epoch 38	train_loss: 0.3085 train_accuracy: 0.8923	val_loss: 0.2740 val_accuracy: 0.9140	test_loss: 0.3338 test_accuracy: 0.8850
2025-08-23 09:21:13,443 - INFO - train: {'epoch': 40, 'time_epoch': 10.38454, 'eta': 627.40563, 'eta_hours': 0.17428, 'loss': 0.29444642, 'lr': 0.000375, 'params': 193993, 'time_iter': 0.04742, 'accuracy': 0.89114, 'f1': 0.89171, 'auc': 0.98283}
2025-08-23 09:21:14,089 - INFO - val: {'epoch': 40, 'time_epoch': 0.63506, 'loss': 0.26524305, 'lr': 0, 'params': 193993, 'time_iter': 0.01985, 'accuracy': 0.908, 'f1': 0.90988, 'auc': 0.98667}
2025-08-23 09:21:15,376 - INFO - test: {'epoch': 40, 'time_epoch': 1.27677, 'loss': 0.31431421, 'lr': 0, 'params': 193993, 'time_iter': 0.02027, 'accuracy': 0.89, 'f1': 0.89308, 'auc': 0.98332}
2025-08-23 09:21:15,377 - INFO - > Epoch 40: took 12.3s (avg 12.6s) | Best so far: epoch 38	train_loss: 0.3085 train_accuracy: 0.8923	val_loss: 0.2740 val_accuracy: 0.9140	test_loss: 0.3338 test_accuracy: 0.8850
2025-08-23 09:21:25,756 - INFO - train: {'epoch': 41, 'time_epoch': 10.36642, 'eta': 616.40213, 'eta_hours': 0.17122, 'loss': 0.28085753, 'lr': 0.00036737, 'params': 193993, 'time_iter': 0.04734, 'accuracy': 0.90257, 'f1': 0.90278, 'auc': 0.9851}
2025-08-23 09:21:26,415 - INFO - val: {'epoch': 41, 'time_epoch': 0.64772, 'loss': 0.25900469, 'lr': 0, 'params': 193993, 'time_iter': 0.02024, 'accuracy': 0.908, 'f1': 0.90898, 'auc': 0.98731}
2025-08-23 09:21:27,719 - INFO - test: {'epoch': 41, 'time_epoch': 1.29426, 'loss': 0.32132832, 'lr': 0, 'params': 193993, 'time_iter': 0.02054, 'accuracy': 0.882, 'f1': 0.88317, 'auc': 0.98277}
2025-08-23 09:21:27,721 - INFO - > Epoch 41: took 12.3s (avg 12.6s) | Best so far: epoch 38	train_loss: 0.3085 train_accuracy: 0.8923	val_loss: 0.2740 val_accuracy: 0.9140	test_loss: 0.3338 test_accuracy: 0.8850
2025-08-23 09:21:38,101 - INFO - train: {'epoch': 42, 'time_epoch': 10.36608, 'eta': 605.42781, 'eta_hours': 0.16817, 'loss': 0.27011746, 'lr': 0.00035959, 'params': 193993, 'time_iter': 0.04733, 'accuracy': 0.91143, 'f1': 0.91145, 'auc': 0.98529}
2025-08-23 09:21:38,747 - INFO - val: {'epoch': 42, 'time_epoch': 0.63508, 'loss': 0.26025901, 'lr': 0, 'params': 193993, 'time_iter': 0.01985, 'accuracy': 0.908, 'f1': 0.90804, 'auc': 0.98645}
2025-08-23 09:21:40,030 - INFO - test: {'epoch': 42, 'time_epoch': 1.27254, 'loss': 0.30796044, 'lr': 0, 'params': 193993, 'time_iter': 0.0202, 'accuracy': 0.886, 'f1': 0.88572, 'auc': 0.98266}
2025-08-23 09:21:40,031 - INFO - > Epoch 42: took 12.3s (avg 12.6s) | Best so far: epoch 38	train_loss: 0.3085 train_accuracy: 0.8923	val_loss: 0.2740 val_accuracy: 0.9140	test_loss: 0.3338 test_accuracy: 0.8850
2025-08-23 09:21:50,417 - INFO - train: {'epoch': 43, 'time_epoch': 10.37222, 'eta': 594.48895, 'eta_hours': 0.16514, 'loss': 0.26026958, 'lr': 0.00035168, 'params': 193993, 'time_iter': 0.04736, 'accuracy': 0.91457, 'f1': 0.91493, 'auc': 0.98643}
2025-08-23 09:21:51,082 - INFO - val: {'epoch': 43, 'time_epoch': 0.654, 'loss': 0.29006948, 'lr': 0, 'params': 193993, 'time_iter': 0.02044, 'accuracy': 0.91, 'f1': 0.91117, 'auc': 0.98776}
2025-08-23 09:21:52,366 - INFO - test: {'epoch': 43, 'time_epoch': 1.27328, 'loss': 0.32294513, 'lr': 0, 'params': 193993, 'time_iter': 0.02021, 'accuracy': 0.895, 'f1': 0.89678, 'auc': 0.9828}
2025-08-23 09:21:52,367 - INFO - > Epoch 43: took 12.3s (avg 12.6s) | Best so far: epoch 38	train_loss: 0.3085 train_accuracy: 0.8923	val_loss: 0.2740 val_accuracy: 0.9140	test_loss: 0.3338 test_accuracy: 0.8850
2025-08-23 09:22:02,762 - INFO - train: {'epoch': 44, 'time_epoch': 10.38186, 'eta': 583.58706, 'eta_hours': 0.16211, 'loss': 0.26253476, 'lr': 0.00034365, 'params': 193993, 'time_iter': 0.04741, 'accuracy': 0.90971, 'f1': 0.91033, 'auc': 0.98641}
2025-08-23 09:22:03,406 - INFO - val: {'epoch': 44, 'time_epoch': 0.63393, 'loss': 0.26959995, 'lr': 0, 'params': 193993, 'time_iter': 0.01981, 'accuracy': 0.906, 'f1': 0.90607, 'auc': 0.98687}
2025-08-23 09:22:04,688 - INFO - test: {'epoch': 44, 'time_epoch': 1.2722, 'loss': 0.30375779, 'lr': 0, 'params': 193993, 'time_iter': 0.02019, 'accuracy': 0.897, 'f1': 0.89702, 'auc': 0.98372}
2025-08-23 09:22:04,690 - INFO - > Epoch 44: took 12.3s (avg 12.6s) | Best so far: epoch 38	train_loss: 0.3085 train_accuracy: 0.8923	val_loss: 0.2740 val_accuracy: 0.9140	test_loss: 0.3338 test_accuracy: 0.8850
2025-08-23 09:22:15,125 - INFO - train: {'epoch': 45, 'time_epoch': 10.41832, 'eta': 572.75058, 'eta_hours': 0.1591, 'loss': 0.24827208, 'lr': 0.00033551, 'params': 193993, 'time_iter': 0.04757, 'accuracy': 0.91571, 'f1': 0.91596, 'auc': 0.98773}
2025-08-23 09:22:15,769 - INFO - val: {'epoch': 45, 'time_epoch': 0.633, 'loss': 0.23334179, 'lr': 0, 'params': 193993, 'time_iter': 0.01978, 'accuracy': 0.906, 'f1': 0.90678, 'auc': 0.9891}
2025-08-23 09:22:17,059 - INFO - test: {'epoch': 45, 'time_epoch': 1.27675, 'loss': 0.3089293, 'lr': 0, 'params': 193993, 'time_iter': 0.02027, 'accuracy': 0.883, 'f1': 0.88418, 'auc': 0.98279}
2025-08-23 09:22:17,061 - INFO - > Epoch 45: took 12.4s (avg 12.6s) | Best so far: epoch 38	train_loss: 0.3085 train_accuracy: 0.8923	val_loss: 0.2740 val_accuracy: 0.9140	test_loss: 0.3338 test_accuracy: 0.8850
2025-08-23 09:22:27,456 - INFO - train: {'epoch': 46, 'time_epoch': 10.38172, 'eta': 561.89062, 'eta_hours': 0.15608, 'loss': 0.23881852, 'lr': 0.00032725, 'params': 193993, 'time_iter': 0.04741, 'accuracy': 0.91543, 'f1': 0.91558, 'auc': 0.98857}
2025-08-23 09:22:28,103 - INFO - val: {'epoch': 46, 'time_epoch': 0.63503, 'loss': 0.23020414, 'lr': 0, 'params': 193993, 'time_iter': 0.01984, 'accuracy': 0.926, 'f1': 0.92506, 'auc': 0.99008}
2025-08-23 09:22:29,386 - INFO - test: {'epoch': 46, 'time_epoch': 1.27328, 'loss': 0.29422515, 'lr': 0, 'params': 193993, 'time_iter': 0.02021, 'accuracy': 0.894, 'f1': 0.89199, 'auc': 0.98375}
2025-08-23 09:22:29,388 - INFO - > Epoch 46: took 12.3s (avg 12.6s) | Best so far: epoch 46	train_loss: 0.2388 train_accuracy: 0.9154	val_loss: 0.2302 val_accuracy: 0.9260	test_loss: 0.2942 test_accuracy: 0.8940
2025-08-23 09:22:39,774 - INFO - train: {'epoch': 47, 'time_epoch': 10.37295, 'eta': 551.04108, 'eta_hours': 0.15307, 'loss': 0.22285831, 'lr': 0.00031891, 'params': 193993, 'time_iter': 0.04737, 'accuracy': 0.92171, 'f1': 0.92202, 'auc': 0.98921}
2025-08-23 09:22:40,419 - INFO - val: {'epoch': 47, 'time_epoch': 0.63421, 'loss': 0.25612249, 'lr': 0, 'params': 193993, 'time_iter': 0.01982, 'accuracy': 0.916, 'f1': 0.91519, 'auc': 0.98768}
2025-08-23 09:22:41,702 - INFO - test: {'epoch': 47, 'time_epoch': 1.2725, 'loss': 0.31389246, 'lr': 0, 'params': 193993, 'time_iter': 0.0202, 'accuracy': 0.889, 'f1': 0.88844, 'auc': 0.98301}
2025-08-23 09:22:41,703 - INFO - > Epoch 47: took 12.3s (avg 12.6s) | Best so far: epoch 46	train_loss: 0.2388 train_accuracy: 0.9154	val_loss: 0.2302 val_accuracy: 0.9260	test_loss: 0.2942 test_accuracy: 0.8940
2025-08-23 09:22:52,090 - INFO - train: {'epoch': 48, 'time_epoch': 10.37321, 'eta': 540.21127, 'eta_hours': 0.15006, 'loss': 0.24518331, 'lr': 0.00031048, 'params': 193993, 'time_iter': 0.04737, 'accuracy': 0.91571, 'f1': 0.91572, 'auc': 0.98808}
2025-08-23 09:22:52,731 - INFO - val: {'epoch': 48, 'time_epoch': 0.631, 'loss': 0.23338492, 'lr': 0, 'params': 193993, 'time_iter': 0.01972, 'accuracy': 0.924, 'f1': 0.92345, 'auc': 0.9885}
2025-08-23 09:22:54,006 - INFO - test: {'epoch': 48, 'time_epoch': 1.26469, 'loss': 0.29505509, 'lr': 0, 'params': 193993, 'time_iter': 0.02007, 'accuracy': 0.903, 'f1': 0.90304, 'auc': 0.98444}
2025-08-23 09:22:54,008 - INFO - > Epoch 48: took 12.3s (avg 12.6s) | Best so far: epoch 46	train_loss: 0.2388 train_accuracy: 0.9154	val_loss: 0.2302 val_accuracy: 0.9260	test_loss: 0.2942 test_accuracy: 0.8940
2025-08-23 09:23:04,383 - INFO - train: {'epoch': 49, 'time_epoch': 10.36213, 'eta': 529.38864, 'eta_hours': 0.14705, 'loss': 0.22794777, 'lr': 0.00030198, 'params': 193993, 'time_iter': 0.04732, 'accuracy': 0.92543, 'f1': 0.92548, 'auc': 0.98916}
2025-08-23 09:23:05,029 - INFO - val: {'epoch': 49, 'time_epoch': 0.63549, 'loss': 0.26359325, 'lr': 0, 'params': 193993, 'time_iter': 0.01986, 'accuracy': 0.926, 'f1': 0.92692, 'auc': 0.98677}
2025-08-23 09:23:06,321 - INFO - test: {'epoch': 49, 'time_epoch': 1.28238, 'loss': 0.29417421, 'lr': 0, 'params': 193993, 'time_iter': 0.02036, 'accuracy': 0.902, 'f1': 0.90363, 'auc': 0.98401}
2025-08-23 09:23:06,323 - INFO - > Epoch 49: took 12.3s (avg 12.6s) | Best so far: epoch 46	train_loss: 0.2388 train_accuracy: 0.9154	val_loss: 0.2302 val_accuracy: 0.9260	test_loss: 0.2942 test_accuracy: 0.8940
2025-08-23 09:23:16,712 - INFO - train: {'epoch': 50, 'time_epoch': 10.37624, 'eta': 518.59763, 'eta_hours': 0.14405, 'loss': 0.2254054, 'lr': 0.00029341, 'params': 193993, 'time_iter': 0.04738, 'accuracy': 0.92314, 'f1': 0.92336, 'auc': 0.98957}
2025-08-23 09:23:17,367 - INFO - val: {'epoch': 50, 'time_epoch': 0.64377, 'loss': 0.2452644, 'lr': 0, 'params': 193993, 'time_iter': 0.02012, 'accuracy': 0.912, 'f1': 0.91252, 'auc': 0.9879}
2025-08-23 09:23:18,667 - INFO - test: {'epoch': 50, 'time_epoch': 1.28892, 'loss': 0.29893085, 'lr': 0, 'params': 193993, 'time_iter': 0.02046, 'accuracy': 0.898, 'f1': 0.89888, 'auc': 0.98283}
2025-08-23 09:23:18,668 - INFO - > Epoch 50: took 12.3s (avg 12.6s) | Best so far: epoch 46	train_loss: 0.2388 train_accuracy: 0.9154	val_loss: 0.2302 val_accuracy: 0.9260	test_loss: 0.2942 test_accuracy: 0.8940
2025-08-23 09:23:29,255 - INFO - train: {'epoch': 51, 'time_epoch': 10.57307, 'eta': 508.00425, 'eta_hours': 0.14111, 'loss': 0.22142614, 'lr': 0.00028479, 'params': 193993, 'time_iter': 0.04828, 'accuracy': 0.92314, 'f1': 0.92293, 'auc': 0.99013}
2025-08-23 09:23:29,910 - INFO - val: {'epoch': 51, 'time_epoch': 0.64368, 'loss': 0.22870734, 'lr': 0, 'params': 193993, 'time_iter': 0.02012, 'accuracy': 0.928, 'f1': 0.92717, 'auc': 0.98858}
2025-08-23 09:23:31,199 - INFO - test: {'epoch': 51, 'time_epoch': 1.27908, 'loss': 0.27694023, 'lr': 0, 'params': 193993, 'time_iter': 0.0203, 'accuracy': 0.915, 'f1': 0.91435, 'auc': 0.98513}
2025-08-23 09:23:31,201 - INFO - > Epoch 51: took 12.5s (avg 12.6s) | Best so far: epoch 51	train_loss: 0.2214 train_accuracy: 0.9231	val_loss: 0.2287 val_accuracy: 0.9280	test_loss: 0.2769 test_accuracy: 0.9150
2025-08-23 09:23:41,789 - INFO - train: {'epoch': 52, 'time_epoch': 10.57154, 'eta': 497.41029, 'eta_hours': 0.13817, 'loss': 0.2143128, 'lr': 0.00027613, 'params': 193993, 'time_iter': 0.04827, 'accuracy': 0.92514, 'f1': 0.92568, 'auc': 0.99069}
2025-08-23 09:23:42,450 - INFO - val: {'epoch': 52, 'time_epoch': 0.65008, 'loss': 0.22754701, 'lr': 0, 'params': 193993, 'time_iter': 0.02031, 'accuracy': 0.922, 'f1': 0.92256, 'auc': 0.98841}
2025-08-23 09:23:43,764 - INFO - test: {'epoch': 52, 'time_epoch': 1.30261, 'loss': 0.28949969, 'lr': 0, 'params': 193993, 'time_iter': 0.02068, 'accuracy': 0.902, 'f1': 0.9027, 'auc': 0.98547}
2025-08-23 09:23:43,765 - INFO - > Epoch 52: took 12.6s (avg 12.6s) | Best so far: epoch 51	train_loss: 0.2214 train_accuracy: 0.9231	val_loss: 0.2287 val_accuracy: 0.9280	test_loss: 0.2769 test_accuracy: 0.9150
2025-08-23 09:23:54,282 - INFO - train: {'epoch': 53, 'time_epoch': 10.50239, 'eta': 486.75826, 'eta_hours': 0.13521, 'loss': 0.21072247, 'lr': 0.00026744, 'params': 193993, 'time_iter': 0.04796, 'accuracy': 0.92686, 'f1': 0.92687, 'auc': 0.99024}
2025-08-23 09:23:54,937 - INFO - val: {'epoch': 53, 'time_epoch': 0.64348, 'loss': 0.2456559, 'lr': 0, 'params': 193993, 'time_iter': 0.02011, 'accuracy': 0.92, 'f1': 0.92102, 'auc': 0.98871}
2025-08-23 09:23:56,238 - INFO - test: {'epoch': 53, 'time_epoch': 1.29107, 'loss': 0.31340471, 'lr': 0, 'params': 193993, 'time_iter': 0.02049, 'accuracy': 0.9, 'f1': 0.9015, 'auc': 0.98376}
2025-08-23 09:23:56,240 - INFO - > Epoch 53: took 12.5s (avg 12.6s) | Best so far: epoch 51	train_loss: 0.2214 train_accuracy: 0.9231	val_loss: 0.2287 val_accuracy: 0.9280	test_loss: 0.2769 test_accuracy: 0.9150
2025-08-23 09:24:06,765 - INFO - train: {'epoch': 54, 'time_epoch': 10.51001, 'eta': 476.11791, 'eta_hours': 0.13225, 'loss': 0.20706955, 'lr': 0.00025872, 'params': 193993, 'time_iter': 0.04799, 'accuracy': 0.93257, 'f1': 0.93295, 'auc': 0.99067}
2025-08-23 09:24:07,417 - INFO - val: {'epoch': 54, 'time_epoch': 0.64145, 'loss': 0.21530604, 'lr': 0, 'params': 193993, 'time_iter': 0.02005, 'accuracy': 0.928, 'f1': 0.92886, 'auc': 0.98948}
2025-08-23 09:24:08,716 - INFO - test: {'epoch': 54, 'time_epoch': 1.28873, 'loss': 0.27655653, 'lr': 0, 'params': 193993, 'time_iter': 0.02046, 'accuracy': 0.911, 'f1': 0.91138, 'auc': 0.9864}
2025-08-23 09:24:08,718 - INFO - > Epoch 54: took 12.5s (avg 12.6s) | Best so far: epoch 51	train_loss: 0.2214 train_accuracy: 0.9231	val_loss: 0.2287 val_accuracy: 0.9280	test_loss: 0.2769 test_accuracy: 0.9150
2025-08-23 09:24:19,354 - INFO - train: {'epoch': 55, 'time_epoch': 10.61834, 'eta': 465.56732, 'eta_hours': 0.12932, 'loss': 0.20303734, 'lr': 0.00025, 'params': 193993, 'time_iter': 0.04849, 'accuracy': 0.92686, 'f1': 0.92668, 'auc': 0.99052}
2025-08-23 09:24:19,999 - INFO - val: {'epoch': 55, 'time_epoch': 0.63382, 'loss': 0.23167544, 'lr': 0, 'params': 193993, 'time_iter': 0.01981, 'accuracy': 0.928, 'f1': 0.92892, 'auc': 0.98845}
2025-08-23 09:24:21,286 - INFO - test: {'epoch': 55, 'time_epoch': 1.27657, 'loss': 0.28141179, 'lr': 0, 'params': 193993, 'time_iter': 0.02026, 'accuracy': 0.91, 'f1': 0.91136, 'auc': 0.98596}
2025-08-23 09:24:21,287 - INFO - > Epoch 55: took 12.6s (avg 12.6s) | Best so far: epoch 51	train_loss: 0.2214 train_accuracy: 0.9231	val_loss: 0.2287 val_accuracy: 0.9280	test_loss: 0.2769 test_accuracy: 0.9150
2025-08-23 09:24:31,774 - INFO - train: {'epoch': 56, 'time_epoch': 10.47249, 'eta': 454.90433, 'eta_hours': 0.12636, 'loss': 0.19985488, 'lr': 0.00024128, 'params': 193993, 'time_iter': 0.04782, 'accuracy': 0.93, 'f1': 0.93004, 'auc': 0.99109}
2025-08-23 09:24:32,425 - INFO - val: {'epoch': 56, 'time_epoch': 0.63595, 'loss': 0.23431198, 'lr': 0, 'params': 193993, 'time_iter': 0.01987, 'accuracy': 0.922, 'f1': 0.92292, 'auc': 0.98782}
2025-08-23 09:24:33,709 - INFO - test: {'epoch': 56, 'time_epoch': 1.27429, 'loss': 0.33404122, 'lr': 0, 'params': 193993, 'time_iter': 0.02023, 'accuracy': 0.895, 'f1': 0.8971, 'auc': 0.98162}
2025-08-23 09:24:33,711 - INFO - > Epoch 56: took 12.4s (avg 12.6s) | Best so far: epoch 51	train_loss: 0.2214 train_accuracy: 0.9231	val_loss: 0.2287 val_accuracy: 0.9280	test_loss: 0.2769 test_accuracy: 0.9150
2025-08-23 09:24:44,070 - INFO - train: {'epoch': 57, 'time_epoch': 10.34499, 'eta': 444.15558, 'eta_hours': 0.12338, 'loss': 0.18605002, 'lr': 0.00023256, 'params': 193993, 'time_iter': 0.04724, 'accuracy': 0.93829, 'f1': 0.93834, 'auc': 0.99227}
2025-08-23 09:24:44,711 - INFO - val: {'epoch': 57, 'time_epoch': 0.62989, 'loss': 0.2289277, 'lr': 0, 'params': 193993, 'time_iter': 0.01968, 'accuracy': 0.934, 'f1': 0.93463, 'auc': 0.98992}
2025-08-23 09:24:45,986 - INFO - test: {'epoch': 57, 'time_epoch': 1.26544, 'loss': 0.26371134, 'lr': 0, 'params': 193993, 'time_iter': 0.02009, 'accuracy': 0.912, 'f1': 0.91362, 'auc': 0.98738}
2025-08-23 09:24:45,988 - INFO - > Epoch 57: took 12.3s (avg 12.6s) | Best so far: epoch 57	train_loss: 0.1861 train_accuracy: 0.9383	val_loss: 0.2289 val_accuracy: 0.9340	test_loss: 0.2637 test_accuracy: 0.9120
2025-08-23 09:24:56,350 - INFO - train: {'epoch': 58, 'time_epoch': 10.3487, 'eta': 433.4231, 'eta_hours': 0.1204, 'loss': 0.19386081, 'lr': 0.00022387, 'params': 193993, 'time_iter': 0.04725, 'accuracy': 0.93371, 'f1': 0.93379, 'auc': 0.99174}
2025-08-23 09:24:56,992 - INFO - val: {'epoch': 58, 'time_epoch': 0.63083, 'loss': 0.23507205, 'lr': 0, 'params': 193993, 'time_iter': 0.01971, 'accuracy': 0.926, 'f1': 0.92534, 'auc': 0.98847}
2025-08-23 09:24:58,268 - INFO - test: {'epoch': 58, 'time_epoch': 1.26575, 'loss': 0.28247346, 'lr': 0, 'params': 193993, 'time_iter': 0.02009, 'accuracy': 0.906, 'f1': 0.90571, 'auc': 0.98561}
2025-08-23 09:24:58,269 - INFO - > Epoch 58: took 12.3s (avg 12.6s) | Best so far: epoch 57	train_loss: 0.1861 train_accuracy: 0.9383	val_loss: 0.2289 val_accuracy: 0.9340	test_loss: 0.2637 test_accuracy: 0.9120
2025-08-23 09:25:08,632 - INFO - train: {'epoch': 59, 'time_epoch': 10.34921, 'eta': 422.70375, 'eta_hours': 0.11742, 'loss': 0.19270281, 'lr': 0.00021521, 'params': 193993, 'time_iter': 0.04726, 'accuracy': 0.93257, 'f1': 0.93245, 'auc': 0.99206}
2025-08-23 09:25:09,272 - INFO - val: {'epoch': 59, 'time_epoch': 0.62914, 'loss': 0.22059839, 'lr': 0, 'params': 193993, 'time_iter': 0.01966, 'accuracy': 0.932, 'f1': 0.93274, 'auc': 0.98994}
2025-08-23 09:25:10,542 - INFO - test: {'epoch': 59, 'time_epoch': 1.25987, 'loss': 0.27112216, 'lr': 0, 'params': 193993, 'time_iter': 0.02, 'accuracy': 0.912, 'f1': 0.91372, 'auc': 0.98655}
2025-08-23 09:25:10,543 - INFO - > Epoch 59: took 12.3s (avg 12.5s) | Best so far: epoch 57	train_loss: 0.1861 train_accuracy: 0.9383	val_loss: 0.2289 val_accuracy: 0.9340	test_loss: 0.2637 test_accuracy: 0.9120
2025-08-23 09:25:20,893 - INFO - train: {'epoch': 60, 'time_epoch': 10.33601, 'eta': 411.98809, 'eta_hours': 0.11444, 'loss': 0.18394679, 'lr': 0.00020659, 'params': 193993, 'time_iter': 0.0472, 'accuracy': 0.93857, 'f1': 0.93869, 'auc': 0.9922}
2025-08-23 09:25:21,531 - INFO - val: {'epoch': 60, 'time_epoch': 0.62758, 'loss': 0.22959945, 'lr': 0, 'params': 193993, 'time_iter': 0.01961, 'accuracy': 0.928, 'f1': 0.92714, 'auc': 0.98965}
2025-08-23 09:25:22,815 - INFO - test: {'epoch': 60, 'time_epoch': 1.27406, 'loss': 0.28039086, 'lr': 0, 'params': 193993, 'time_iter': 0.02022, 'accuracy': 0.905, 'f1': 0.90449, 'auc': 0.98585}
2025-08-23 09:25:22,817 - INFO - > Epoch 60: took 12.3s (avg 12.5s) | Best so far: epoch 57	train_loss: 0.1861 train_accuracy: 0.9383	val_loss: 0.2289 val_accuracy: 0.9340	test_loss: 0.2637 test_accuracy: 0.9120
2025-08-23 09:25:33,099 - INFO - train: {'epoch': 61, 'time_epoch': 10.26858, 'eta': 401.24335, 'eta_hours': 0.11146, 'loss': 0.18768791, 'lr': 0.00019802, 'params': 193993, 'time_iter': 0.04689, 'accuracy': 0.93829, 'f1': 0.93831, 'auc': 0.99261}
2025-08-23 09:25:33,744 - INFO - val: {'epoch': 61, 'time_epoch': 0.63523, 'loss': 0.21889639, 'lr': 0, 'params': 193993, 'time_iter': 0.01985, 'accuracy': 0.934, 'f1': 0.93485, 'auc': 0.9902}
2025-08-23 09:25:35,027 - INFO - test: {'epoch': 61, 'time_epoch': 1.27248, 'loss': 0.31241372, 'lr': 0, 'params': 193993, 'time_iter': 0.0202, 'accuracy': 0.898, 'f1': 0.90008, 'auc': 0.98454}
2025-08-23 09:25:35,028 - INFO - > Epoch 61: took 12.2s (avg 12.5s) | Best so far: epoch 57	train_loss: 0.1861 train_accuracy: 0.9383	val_loss: 0.2289 val_accuracy: 0.9340	test_loss: 0.2637 test_accuracy: 0.9120
2025-08-23 09:25:45,328 - INFO - train: {'epoch': 62, 'time_epoch': 10.28562, 'eta': 390.52374, 'eta_hours': 0.10848, 'loss': 0.18762812, 'lr': 0.00018952, 'params': 193993, 'time_iter': 0.04697, 'accuracy': 0.93686, 'f1': 0.93706, 'auc': 0.99237}
2025-08-23 09:25:45,961 - INFO - val: {'epoch': 62, 'time_epoch': 0.62353, 'loss': 0.2260412, 'lr': 0, 'params': 193993, 'time_iter': 0.01949, 'accuracy': 0.924, 'f1': 0.92526, 'auc': 0.98894}
2025-08-23 09:25:47,225 - INFO - test: {'epoch': 62, 'time_epoch': 1.25426, 'loss': 0.29820448, 'lr': 0, 'params': 193993, 'time_iter': 0.01991, 'accuracy': 0.898, 'f1': 0.90091, 'auc': 0.98604}
2025-08-23 09:25:47,226 - INFO - > Epoch 62: took 12.2s (avg 12.5s) | Best so far: epoch 57	train_loss: 0.1861 train_accuracy: 0.9383	val_loss: 0.2289 val_accuracy: 0.9340	test_loss: 0.2637 test_accuracy: 0.9120
2025-08-23 09:25:57,551 - INFO - train: {'epoch': 63, 'time_epoch': 10.31103, 'eta': 379.83198, 'eta_hours': 0.10551, 'loss': 0.17286255, 'lr': 0.00018109, 'params': 193993, 'time_iter': 0.04708, 'accuracy': 0.93886, 'f1': 0.93883, 'auc': 0.99301}
2025-08-23 09:25:58,190 - INFO - val: {'epoch': 63, 'time_epoch': 0.62794, 'loss': 0.22316644, 'lr': 0, 'params': 193993, 'time_iter': 0.01962, 'accuracy': 0.93, 'f1': 0.93103, 'auc': 0.99015}
2025-08-23 09:25:59,478 - INFO - test: {'epoch': 63, 'time_epoch': 1.27815, 'loss': 0.27239663, 'lr': 0, 'params': 193993, 'time_iter': 0.02029, 'accuracy': 0.91, 'f1': 0.91203, 'auc': 0.98657}
2025-08-23 09:25:59,479 - INFO - > Epoch 63: took 12.3s (avg 12.5s) | Best so far: epoch 57	train_loss: 0.1861 train_accuracy: 0.9383	val_loss: 0.2289 val_accuracy: 0.9340	test_loss: 0.2637 test_accuracy: 0.9120
2025-08-23 09:26:09,778 - INFO - train: {'epoch': 64, 'time_epoch': 10.28547, 'eta': 369.13817, 'eta_hours': 0.10254, 'loss': 0.17062548, 'lr': 0.00017275, 'params': 193993, 'time_iter': 0.04697, 'accuracy': 0.94486, 'f1': 0.94497, 'auc': 0.99262}
2025-08-23 09:26:10,414 - INFO - val: {'epoch': 64, 'time_epoch': 0.62564, 'loss': 0.22081393, 'lr': 0, 'params': 193993, 'time_iter': 0.01955, 'accuracy': 0.932, 'f1': 0.9322, 'auc': 0.98929}
2025-08-23 09:26:11,711 - INFO - test: {'epoch': 64, 'time_epoch': 1.28671, 'loss': 0.27464372, 'lr': 0, 'params': 193993, 'time_iter': 0.02042, 'accuracy': 0.915, 'f1': 0.91568, 'auc': 0.98577}
2025-08-23 09:26:11,713 - INFO - > Epoch 64: took 12.2s (avg 12.5s) | Best so far: epoch 57	train_loss: 0.1861 train_accuracy: 0.9383	val_loss: 0.2289 val_accuracy: 0.9340	test_loss: 0.2637 test_accuracy: 0.9120
2025-08-23 09:26:22,111 - INFO - train: {'epoch': 65, 'time_epoch': 10.38467, 'eta': 358.50784, 'eta_hours': 0.09959, 'loss': 0.16680033, 'lr': 0.00016449, 'params': 193993, 'time_iter': 0.04742, 'accuracy': 0.94343, 'f1': 0.94346, 'auc': 0.99343}
2025-08-23 09:26:22,751 - INFO - val: {'epoch': 65, 'time_epoch': 0.62922, 'loss': 0.21624978, 'lr': 0, 'params': 193993, 'time_iter': 0.01966, 'accuracy': 0.934, 'f1': 0.93487, 'auc': 0.9906}
2025-08-23 09:26:24,025 - INFO - test: {'epoch': 65, 'time_epoch': 1.26373, 'loss': 0.27830066, 'lr': 0, 'params': 193993, 'time_iter': 0.02006, 'accuracy': 0.912, 'f1': 0.91338, 'auc': 0.98594}
2025-08-23 09:26:24,026 - INFO - > Epoch 65: took 12.3s (avg 12.5s) | Best so far: epoch 57	train_loss: 0.1861 train_accuracy: 0.9383	val_loss: 0.2289 val_accuracy: 0.9340	test_loss: 0.2637 test_accuracy: 0.9120
2025-08-23 09:26:34,362 - INFO - train: {'epoch': 66, 'time_epoch': 10.32243, 'eta': 347.85419, 'eta_hours': 0.09663, 'loss': 0.16374813, 'lr': 0.00015635, 'params': 193993, 'time_iter': 0.04713, 'accuracy': 0.944, 'f1': 0.94383, 'auc': 0.99359}
2025-08-23 09:26:35,005 - INFO - val: {'epoch': 66, 'time_epoch': 0.63178, 'loss': 0.25331321, 'lr': 0, 'params': 193993, 'time_iter': 0.01974, 'accuracy': 0.918, 'f1': 0.91726, 'auc': 0.9896}
2025-08-23 09:26:36,278 - INFO - test: {'epoch': 66, 'time_epoch': 1.26348, 'loss': 0.25276334, 'lr': 0, 'params': 193993, 'time_iter': 0.02006, 'accuracy': 0.919, 'f1': 0.91904, 'auc': 0.98701}
2025-08-23 09:26:36,280 - INFO - > Epoch 66: took 12.3s (avg 12.5s) | Best so far: epoch 57	train_loss: 0.1861 train_accuracy: 0.9383	val_loss: 0.2289 val_accuracy: 0.9340	test_loss: 0.2637 test_accuracy: 0.9120
2025-08-23 09:26:46,625 - INFO - train: {'epoch': 67, 'time_epoch': 10.33151, 'eta': 337.21455, 'eta_hours': 0.09367, 'loss': 0.16073615, 'lr': 0.00014832, 'params': 193993, 'time_iter': 0.04718, 'accuracy': 0.94886, 'f1': 0.94901, 'auc': 0.99369}
2025-08-23 09:26:47,267 - INFO - val: {'epoch': 67, 'time_epoch': 0.63203, 'loss': 0.202161, 'lr': 0, 'params': 193993, 'time_iter': 0.01975, 'accuracy': 0.936, 'f1': 0.93703, 'auc': 0.98941}
2025-08-23 09:26:48,565 - INFO - test: {'epoch': 67, 'time_epoch': 1.2879, 'loss': 0.2872144, 'lr': 0, 'params': 193993, 'time_iter': 0.02044, 'accuracy': 0.91, 'f1': 0.91197, 'auc': 0.98571}
2025-08-23 09:26:48,567 - INFO - > Epoch 67: took 12.3s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:26:58,919 - INFO - train: {'epoch': 68, 'time_epoch': 10.33832, 'eta': 326.58691, 'eta_hours': 0.09072, 'loss': 0.167376, 'lr': 0.00014041, 'params': 193993, 'time_iter': 0.04721, 'accuracy': 0.94429, 'f1': 0.94435, 'auc': 0.99339}
2025-08-23 09:26:59,573 - INFO - val: {'epoch': 68, 'time_epoch': 0.64277, 'loss': 0.25074145, 'lr': 0, 'params': 193993, 'time_iter': 0.02009, 'accuracy': 0.922, 'f1': 0.9234, 'auc': 0.98798}
2025-08-23 09:27:00,854 - INFO - test: {'epoch': 68, 'time_epoch': 1.27091, 'loss': 0.28352779, 'lr': 0, 'params': 193993, 'time_iter': 0.02017, 'accuracy': 0.913, 'f1': 0.91484, 'auc': 0.98488}
2025-08-23 09:27:00,855 - INFO - > Epoch 68: took 12.3s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:27:11,172 - INFO - train: {'epoch': 69, 'time_epoch': 10.30359, 'eta': 315.95265, 'eta_hours': 0.08776, 'loss': 0.15549738, 'lr': 0.00013263, 'params': 193993, 'time_iter': 0.04705, 'accuracy': 0.94743, 'f1': 0.94746, 'auc': 0.99378}
2025-08-23 09:27:11,810 - INFO - val: {'epoch': 69, 'time_epoch': 0.62856, 'loss': 0.24451158, 'lr': 0, 'params': 193993, 'time_iter': 0.01964, 'accuracy': 0.928, 'f1': 0.92856, 'auc': 0.98848}
2025-08-23 09:27:13,103 - INFO - test: {'epoch': 69, 'time_epoch': 1.28304, 'loss': 0.28829525, 'lr': 0, 'params': 193993, 'time_iter': 0.02037, 'accuracy': 0.913, 'f1': 0.91447, 'auc': 0.9848}
2025-08-23 09:27:13,105 - INFO - > Epoch 69: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:27:23,420 - INFO - train: {'epoch': 70, 'time_epoch': 10.30192, 'eta': 305.32701, 'eta_hours': 0.08481, 'loss': 0.15684203, 'lr': 0.000125, 'params': 193993, 'time_iter': 0.04704, 'accuracy': 0.95057, 'f1': 0.9505, 'auc': 0.99389}
2025-08-23 09:27:24,058 - INFO - val: {'epoch': 70, 'time_epoch': 0.6277, 'loss': 0.24585162, 'lr': 0, 'params': 193993, 'time_iter': 0.01962, 'accuracy': 0.928, 'f1': 0.92799, 'auc': 0.98868}
2025-08-23 09:27:25,333 - INFO - test: {'epoch': 70, 'time_epoch': 1.26466, 'loss': 0.265795, 'lr': 0, 'params': 193993, 'time_iter': 0.02007, 'accuracy': 0.916, 'f1': 0.9167, 'auc': 0.98646}
2025-08-23 09:27:25,335 - INFO - > Epoch 70: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:27:35,638 - INFO - train: {'epoch': 71, 'time_epoch': 10.29002, 'eta': 294.70575, 'eta_hours': 0.08186, 'loss': 0.15051811, 'lr': 0.00011752, 'params': 193993, 'time_iter': 0.04699, 'accuracy': 0.94943, 'f1': 0.9494, 'auc': 0.99404}
2025-08-23 09:27:36,275 - INFO - val: {'epoch': 71, 'time_epoch': 0.62683, 'loss': 0.2428806, 'lr': 0, 'params': 193993, 'time_iter': 0.01959, 'accuracy': 0.926, 'f1': 0.92691, 'auc': 0.9893}
2025-08-23 09:27:37,547 - INFO - test: {'epoch': 71, 'time_epoch': 1.26196, 'loss': 0.28218441, 'lr': 0, 'params': 193993, 'time_iter': 0.02003, 'accuracy': 0.916, 'f1': 0.9172, 'auc': 0.98542}
2025-08-23 09:27:37,549 - INFO - > Epoch 71: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:27:47,839 - INFO - train: {'epoch': 72, 'time_epoch': 10.27728, 'eta': 284.08885, 'eta_hours': 0.07891, 'loss': 0.15100868, 'lr': 0.0001102, 'params': 193993, 'time_iter': 0.04693, 'accuracy': 0.94886, 'f1': 0.94897, 'auc': 0.99404}
2025-08-23 09:27:48,475 - INFO - val: {'epoch': 72, 'time_epoch': 0.62628, 'loss': 0.24783782, 'lr': 0, 'params': 193993, 'time_iter': 0.01957, 'accuracy': 0.928, 'f1': 0.92884, 'auc': 0.98887}
2025-08-23 09:27:49,748 - INFO - test: {'epoch': 72, 'time_epoch': 1.26285, 'loss': 0.27574968, 'lr': 0, 'params': 193993, 'time_iter': 0.02005, 'accuracy': 0.915, 'f1': 0.91649, 'auc': 0.9861}
2025-08-23 09:27:49,749 - INFO - > Epoch 72: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:28:00,045 - INFO - train: {'epoch': 73, 'time_epoch': 10.28033, 'eta': 273.48219, 'eta_hours': 0.07597, 'loss': 0.14672476, 'lr': 0.00010305, 'params': 193993, 'time_iter': 0.04694, 'accuracy': 0.954, 'f1': 0.95406, 'auc': 0.99435}
2025-08-23 09:28:00,686 - INFO - val: {'epoch': 73, 'time_epoch': 0.62974, 'loss': 0.26834509, 'lr': 0, 'params': 193993, 'time_iter': 0.01968, 'accuracy': 0.92, 'f1': 0.92048, 'auc': 0.98928}
2025-08-23 09:28:01,953 - INFO - test: {'epoch': 73, 'time_epoch': 1.25751, 'loss': 0.25908345, 'lr': 0, 'params': 193993, 'time_iter': 0.01996, 'accuracy': 0.915, 'f1': 0.91613, 'auc': 0.98829}
2025-08-23 09:28:01,955 - INFO - > Epoch 73: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:28:12,255 - INFO - train: {'epoch': 74, 'time_epoch': 10.2881, 'eta': 262.88683, 'eta_hours': 0.07302, 'loss': 0.14950647, 'lr': 9.608e-05, 'params': 193993, 'time_iter': 0.04698, 'accuracy': 0.95314, 'f1': 0.95314, 'auc': 0.99538}
2025-08-23 09:28:12,890 - INFO - val: {'epoch': 74, 'time_epoch': 0.62479, 'loss': 0.25337725, 'lr': 0, 'params': 193993, 'time_iter': 0.01952, 'accuracy': 0.922, 'f1': 0.9224, 'auc': 0.98843}
2025-08-23 09:28:14,178 - INFO - test: {'epoch': 74, 'time_epoch': 1.27807, 'loss': 0.25206711, 'lr': 0, 'params': 193993, 'time_iter': 0.02029, 'accuracy': 0.926, 'f1': 0.92672, 'auc': 0.98707}
2025-08-23 09:28:14,180 - INFO - > Epoch 74: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:28:24,476 - INFO - train: {'epoch': 75, 'time_epoch': 10.28335, 'eta': 252.29806, 'eta_hours': 0.07008, 'loss': 0.14081933, 'lr': 8.93e-05, 'params': 193993, 'time_iter': 0.04696, 'accuracy': 0.95514, 'f1': 0.95512, 'auc': 0.99525}
2025-08-23 09:28:25,115 - INFO - val: {'epoch': 75, 'time_epoch': 0.62738, 'loss': 0.24423204, 'lr': 0, 'params': 193993, 'time_iter': 0.01961, 'accuracy': 0.926, 'f1': 0.92711, 'auc': 0.98951}
2025-08-23 09:28:26,381 - INFO - test: {'epoch': 75, 'time_epoch': 1.2564, 'loss': 0.27801295, 'lr': 0, 'params': 193993, 'time_iter': 0.01994, 'accuracy': 0.916, 'f1': 0.91754, 'auc': 0.98671}
2025-08-23 09:28:26,382 - INFO - > Epoch 75: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:28:36,678 - INFO - train: {'epoch': 76, 'time_epoch': 10.28322, 'eta': 241.71718, 'eta_hours': 0.06714, 'loss': 0.14513682, 'lr': 8.272e-05, 'params': 193993, 'time_iter': 0.04696, 'accuracy': 0.95029, 'f1': 0.95047, 'auc': 0.99507}
2025-08-23 09:28:37,315 - INFO - val: {'epoch': 76, 'time_epoch': 0.62696, 'loss': 0.26724426, 'lr': 0, 'params': 193993, 'time_iter': 0.01959, 'accuracy': 0.912, 'f1': 0.91256, 'auc': 0.98863}
2025-08-23 09:28:38,584 - INFO - test: {'epoch': 76, 'time_epoch': 1.2591, 'loss': 0.26042638, 'lr': 0, 'params': 193993, 'time_iter': 0.01999, 'accuracy': 0.921, 'f1': 0.92244, 'auc': 0.98749}
2025-08-23 09:28:38,585 - INFO - > Epoch 76: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:28:48,884 - INFO - train: {'epoch': 77, 'time_epoch': 10.28674, 'eta': 231.14492, 'eta_hours': 0.06421, 'loss': 0.14351018, 'lr': 7.634e-05, 'params': 193993, 'time_iter': 0.04697, 'accuracy': 0.952, 'f1': 0.95199, 'auc': 0.99482}
2025-08-23 09:28:49,522 - INFO - val: {'epoch': 77, 'time_epoch': 0.62783, 'loss': 0.25588769, 'lr': 0, 'params': 193993, 'time_iter': 0.01962, 'accuracy': 0.922, 'f1': 0.92323, 'auc': 0.98993}
2025-08-23 09:28:50,791 - INFO - test: {'epoch': 77, 'time_epoch': 1.25855, 'loss': 0.25863057, 'lr': 0, 'params': 193993, 'time_iter': 0.01998, 'accuracy': 0.92, 'f1': 0.92149, 'auc': 0.98704}
2025-08-23 09:28:50,792 - INFO - > Epoch 77: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:29:01,105 - INFO - train: {'epoch': 78, 'time_epoch': 10.29945, 'eta': 220.58327, 'eta_hours': 0.06127, 'loss': 0.13979343, 'lr': 7.017e-05, 'params': 193993, 'time_iter': 0.04703, 'accuracy': 0.95514, 'f1': 0.95526, 'auc': 0.99507}
2025-08-23 09:29:01,740 - INFO - val: {'epoch': 78, 'time_epoch': 0.62454, 'loss': 0.2461524, 'lr': 0, 'params': 193993, 'time_iter': 0.01952, 'accuracy': 0.92, 'f1': 0.92111, 'auc': 0.98959}
2025-08-23 09:29:03,019 - INFO - test: {'epoch': 78, 'time_epoch': 1.26926, 'loss': 0.25578467, 'lr': 0, 'params': 193993, 'time_iter': 0.02015, 'accuracy': 0.926, 'f1': 0.92728, 'auc': 0.98694}
2025-08-23 09:29:03,022 - INFO - > Epoch 78: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:29:13,323 - INFO - train: {'epoch': 79, 'time_epoch': 10.28866, 'eta': 210.02548, 'eta_hours': 0.05834, 'loss': 0.13485799, 'lr': 6.421e-05, 'params': 193993, 'time_iter': 0.04698, 'accuracy': 0.95714, 'f1': 0.95721, 'auc': 0.99535}
2025-08-23 09:29:13,957 - INFO - val: {'epoch': 79, 'time_epoch': 0.62438, 'loss': 0.26581324, 'lr': 0, 'params': 193993, 'time_iter': 0.01951, 'accuracy': 0.91, 'f1': 0.91091, 'auc': 0.9887}
2025-08-23 09:29:15,241 - INFO - test: {'epoch': 79, 'time_epoch': 1.27414, 'loss': 0.25871126, 'lr': 0, 'params': 193993, 'time_iter': 0.02022, 'accuracy': 0.923, 'f1': 0.92424, 'auc': 0.98673}
2025-08-23 09:29:15,243 - INFO - > Epoch 79: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:29:25,531 - INFO - train: {'epoch': 80, 'time_epoch': 10.27542, 'eta': 199.47123, 'eta_hours': 0.05541, 'loss': 0.13234296, 'lr': 5.849e-05, 'params': 193993, 'time_iter': 0.04692, 'accuracy': 0.95371, 'f1': 0.95383, 'auc': 0.99575}
2025-08-23 09:29:26,167 - INFO - val: {'epoch': 80, 'time_epoch': 0.62536, 'loss': 0.25795074, 'lr': 0, 'params': 193993, 'time_iter': 0.01954, 'accuracy': 0.914, 'f1': 0.91507, 'auc': 0.98903}
2025-08-23 09:29:27,450 - INFO - test: {'epoch': 80, 'time_epoch': 1.27435, 'loss': 0.25752709, 'lr': 0, 'params': 193993, 'time_iter': 0.02023, 'accuracy': 0.922, 'f1': 0.92328, 'auc': 0.98642}
2025-08-23 09:29:27,452 - INFO - > Epoch 80: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:29:37,743 - INFO - train: {'epoch': 81, 'time_epoch': 10.27746, 'eta': 188.92422, 'eta_hours': 0.05248, 'loss': 0.13067118, 'lr': 5.3e-05, 'params': 193993, 'time_iter': 0.04693, 'accuracy': 0.96114, 'f1': 0.96114, 'auc': 0.99551}
2025-08-23 09:29:38,378 - INFO - val: {'epoch': 81, 'time_epoch': 0.62516, 'loss': 0.24557208, 'lr': 0, 'params': 193993, 'time_iter': 0.01954, 'accuracy': 0.924, 'f1': 0.92521, 'auc': 0.98894}
2025-08-23 09:29:39,646 - INFO - test: {'epoch': 81, 'time_epoch': 1.25786, 'loss': 0.28271946, 'lr': 0, 'params': 193993, 'time_iter': 0.01997, 'accuracy': 0.916, 'f1': 0.91752, 'auc': 0.98504}
2025-08-23 09:29:39,647 - INFO - > Epoch 81: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:29:49,967 - INFO - train: {'epoch': 82, 'time_epoch': 10.30614, 'eta': 178.38959, 'eta_hours': 0.04955, 'loss': 0.13892702, 'lr': 4.775e-05, 'params': 193993, 'time_iter': 0.04706, 'accuracy': 0.95486, 'f1': 0.95504, 'auc': 0.99511}
2025-08-23 09:29:50,605 - INFO - val: {'epoch': 82, 'time_epoch': 0.62726, 'loss': 0.2497602, 'lr': 0, 'params': 193993, 'time_iter': 0.0196, 'accuracy': 0.926, 'f1': 0.92656, 'auc': 0.99021}
2025-08-23 09:29:51,879 - INFO - test: {'epoch': 82, 'time_epoch': 1.26305, 'loss': 0.24751117, 'lr': 0, 'params': 193993, 'time_iter': 0.02005, 'accuracy': 0.927, 'f1': 0.92783, 'auc': 0.98738}
2025-08-23 09:29:51,880 - INFO - > Epoch 82: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:30:02,204 - INFO - train: {'epoch': 83, 'time_epoch': 10.31066, 'eta': 167.86126, 'eta_hours': 0.04663, 'loss': 0.13162248, 'lr': 4.274e-05, 'params': 193993, 'time_iter': 0.04708, 'accuracy': 0.96086, 'f1': 0.96088, 'auc': 0.99572}
2025-08-23 09:30:02,839 - INFO - val: {'epoch': 83, 'time_epoch': 0.62415, 'loss': 0.24014221, 'lr': 0, 'params': 193993, 'time_iter': 0.0195, 'accuracy': 0.93, 'f1': 0.93049, 'auc': 0.99035}
2025-08-23 09:30:04,118 - INFO - test: {'epoch': 83, 'time_epoch': 1.26861, 'loss': 0.24614618, 'lr': 0, 'params': 193993, 'time_iter': 0.02014, 'accuracy': 0.928, 'f1': 0.92894, 'auc': 0.98713}
2025-08-23 09:30:04,119 - INFO - > Epoch 83: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:30:14,402 - INFO - train: {'epoch': 84, 'time_epoch': 10.26973, 'eta': 157.33082, 'eta_hours': 0.0437, 'loss': 0.12229937, 'lr': 3.799e-05, 'params': 193993, 'time_iter': 0.04689, 'accuracy': 0.95914, 'f1': 0.95916, 'auc': 0.99638}
2025-08-23 09:30:15,037 - INFO - val: {'epoch': 84, 'time_epoch': 0.625, 'loss': 0.25735541, 'lr': 0, 'params': 193993, 'time_iter': 0.01953, 'accuracy': 0.918, 'f1': 0.91876, 'auc': 0.98938}
2025-08-23 09:30:16,312 - INFO - test: {'epoch': 84, 'time_epoch': 1.26567, 'loss': 0.25912443, 'lr': 0, 'params': 193993, 'time_iter': 0.02009, 'accuracy': 0.924, 'f1': 0.92524, 'auc': 0.98669}
2025-08-23 09:30:16,314 - INFO - > Epoch 84: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:30:26,591 - INFO - train: {'epoch': 85, 'time_epoch': 10.26455, 'eta': 146.80561, 'eta_hours': 0.04078, 'loss': 0.13091228, 'lr': 3.349e-05, 'params': 193993, 'time_iter': 0.04687, 'accuracy': 0.95686, 'f1': 0.95695, 'auc': 0.99613}
2025-08-23 09:30:27,226 - INFO - val: {'epoch': 85, 'time_epoch': 0.62425, 'loss': 0.25493234, 'lr': 0, 'params': 193993, 'time_iter': 0.01951, 'accuracy': 0.92, 'f1': 0.92054, 'auc': 0.98983}
2025-08-23 09:30:28,492 - INFO - test: {'epoch': 85, 'time_epoch': 1.25591, 'loss': 0.24957951, 'lr': 0, 'params': 193993, 'time_iter': 0.01994, 'accuracy': 0.925, 'f1': 0.92622, 'auc': 0.98706}
2025-08-23 09:30:28,493 - INFO - > Epoch 85: took 12.2s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:30:38,761 - INFO - train: {'epoch': 86, 'time_epoch': 10.25512, 'eta': 136.28498, 'eta_hours': 0.03786, 'loss': 0.12430704, 'lr': 2.926e-05, 'params': 193993, 'time_iter': 0.04683, 'accuracy': 0.96086, 'f1': 0.96089, 'auc': 0.99624}
2025-08-23 09:30:39,397 - INFO - val: {'epoch': 86, 'time_epoch': 0.62625, 'loss': 0.25580737, 'lr': 0, 'params': 193993, 'time_iter': 0.01957, 'accuracy': 0.92, 'f1': 0.92071, 'auc': 0.98938}
2025-08-23 09:30:40,674 - INFO - test: {'epoch': 86, 'time_epoch': 1.26659, 'loss': 0.25755582, 'lr': 0, 'params': 193993, 'time_iter': 0.0201, 'accuracy': 0.926, 'f1': 0.92722, 'auc': 0.98735}
2025-08-23 09:30:40,675 - INFO - > Epoch 86: took 12.2s (avg 12.4s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:30:50,932 - INFO - train: {'epoch': 87, 'time_epoch': 10.24435, 'eta': 125.76891, 'eta_hours': 0.03494, 'loss': 0.12102996, 'lr': 2.53e-05, 'params': 193993, 'time_iter': 0.04678, 'accuracy': 0.96286, 'f1': 0.9629, 'auc': 0.99605}
2025-08-23 09:30:51,565 - INFO - val: {'epoch': 87, 'time_epoch': 0.62371, 'loss': 0.25408391, 'lr': 0, 'params': 193993, 'time_iter': 0.01949, 'accuracy': 0.918, 'f1': 0.91837, 'auc': 0.9904}
2025-08-23 09:30:52,837 - INFO - test: {'epoch': 87, 'time_epoch': 1.26263, 'loss': 0.24740936, 'lr': 0, 'params': 193993, 'time_iter': 0.02004, 'accuracy': 0.924, 'f1': 0.92524, 'auc': 0.98769}
2025-08-23 09:30:52,839 - INFO - > Epoch 87: took 12.2s (avg 12.4s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:31:03,114 - INFO - train: {'epoch': 88, 'time_epoch': 10.26365, 'eta': 115.26134, 'eta_hours': 0.03202, 'loss': 0.12715342, 'lr': 2.161e-05, 'params': 193993, 'time_iter': 0.04687, 'accuracy': 0.96086, 'f1': 0.96079, 'auc': 0.9957}
2025-08-23 09:31:03,751 - INFO - val: {'epoch': 88, 'time_epoch': 0.62567, 'loss': 0.24857579, 'lr': 0, 'params': 193993, 'time_iter': 0.01955, 'accuracy': 0.922, 'f1': 0.92267, 'auc': 0.99002}
2025-08-23 09:31:05,028 - INFO - test: {'epoch': 88, 'time_epoch': 1.26742, 'loss': 0.25105039, 'lr': 0, 'params': 193993, 'time_iter': 0.02012, 'accuracy': 0.924, 'f1': 0.92515, 'auc': 0.98689}
2025-08-23 09:31:05,030 - INFO - > Epoch 88: took 12.2s (avg 12.4s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:31:15,305 - INFO - train: {'epoch': 89, 'time_epoch': 10.26286, 'eta': 104.7591, 'eta_hours': 0.0291, 'loss': 0.12768177, 'lr': 1.82e-05, 'params': 193993, 'time_iter': 0.04686, 'accuracy': 0.96029, 'f1': 0.96031, 'auc': 0.99556}
2025-08-23 09:31:15,940 - INFO - val: {'epoch': 89, 'time_epoch': 0.62501, 'loss': 0.2505018, 'lr': 0, 'params': 193993, 'time_iter': 0.01953, 'accuracy': 0.926, 'f1': 0.92666, 'auc': 0.98956}
2025-08-23 09:31:17,223 - INFO - test: {'epoch': 89, 'time_epoch': 1.27279, 'loss': 0.25252478, 'lr': 0, 'params': 193993, 'time_iter': 0.0202, 'accuracy': 0.925, 'f1': 0.92625, 'auc': 0.98678}
2025-08-23 09:31:17,228 - INFO - > Epoch 89: took 12.2s (avg 12.4s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:31:28,687 - INFO - train: {'epoch': 90, 'time_epoch': 11.38413, 'eta': 94.37301, 'eta_hours': 0.02621, 'loss': 0.12139472, 'lr': 1.508e-05, 'params': 193993, 'time_iter': 0.05198, 'accuracy': 0.96543, 'f1': 0.96541, 'auc': 0.99574}
2025-08-23 09:31:29,323 - INFO - val: {'epoch': 90, 'time_epoch': 0.62029, 'loss': 0.24827163, 'lr': 0, 'params': 193993, 'time_iter': 0.01938, 'accuracy': 0.926, 'f1': 0.92669, 'auc': 0.98899}
2025-08-23 09:31:30,588 - INFO - test: {'epoch': 90, 'time_epoch': 1.25419, 'loss': 0.2618421, 'lr': 0, 'params': 193993, 'time_iter': 0.01991, 'accuracy': 0.919, 'f1': 0.92033, 'auc': 0.98623}
2025-08-23 09:31:30,590 - INFO - > Epoch 90: took 13.4s (avg 12.5s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:31:40,745 - INFO - train: {'epoch': 91, 'time_epoch': 10.143, 'eta': 83.8573, 'eta_hours': 0.02329, 'loss': 0.1168087, 'lr': 1.224e-05, 'params': 193993, 'time_iter': 0.04632, 'accuracy': 0.964, 'f1': 0.96399, 'auc': 0.99644}
2025-08-23 09:31:41,373 - INFO - val: {'epoch': 91, 'time_epoch': 0.61872, 'loss': 0.26848303, 'lr': 0, 'params': 193993, 'time_iter': 0.01934, 'accuracy': 0.92, 'f1': 0.92075, 'auc': 0.98925}
2025-08-23 09:31:42,639 - INFO - test: {'epoch': 91, 'time_epoch': 1.25553, 'loss': 0.24909867, 'lr': 0, 'params': 193993, 'time_iter': 0.01993, 'accuracy': 0.925, 'f1': 0.92612, 'auc': 0.98703}
2025-08-23 09:31:42,640 - INFO - > Epoch 91: took 12.1s (avg 12.4s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:31:52,819 - INFO - train: {'epoch': 92, 'time_epoch': 10.16702, 'eta': 73.35142, 'eta_hours': 0.02038, 'loss': 0.11675037, 'lr': 9.68e-06, 'params': 193993, 'time_iter': 0.04642, 'accuracy': 0.96171, 'f1': 0.96172, 'auc': 0.99623}
2025-08-23 09:31:53,461 - INFO - val: {'epoch': 92, 'time_epoch': 0.63143, 'loss': 0.25426445, 'lr': 0, 'params': 193993, 'time_iter': 0.01973, 'accuracy': 0.926, 'f1': 0.92682, 'auc': 0.98881}
2025-08-23 09:31:54,731 - INFO - test: {'epoch': 92, 'time_epoch': 1.26093, 'loss': 0.26395358, 'lr': 0, 'params': 193993, 'time_iter': 0.02001, 'accuracy': 0.924, 'f1': 0.92529, 'auc': 0.98682}
2025-08-23 09:31:54,733 - INFO - > Epoch 92: took 12.1s (avg 12.4s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:32:04,912 - INFO - train: {'epoch': 93, 'time_epoch': 10.16667, 'eta': 62.85272, 'eta_hours': 0.01746, 'loss': 0.1308225, 'lr': 7.43e-06, 'params': 193993, 'time_iter': 0.04642, 'accuracy': 0.95943, 'f1': 0.95944, 'auc': 0.99589}
2025-08-23 09:32:05,542 - INFO - val: {'epoch': 93, 'time_epoch': 0.61921, 'loss': 0.25642431, 'lr': 0, 'params': 193993, 'time_iter': 0.01935, 'accuracy': 0.92, 'f1': 0.92077, 'auc': 0.98873}
2025-08-23 09:32:06,805 - INFO - test: {'epoch': 93, 'time_epoch': 1.25372, 'loss': 0.25551406, 'lr': 0, 'params': 193993, 'time_iter': 0.0199, 'accuracy': 0.927, 'f1': 0.92821, 'auc': 0.98669}
2025-08-23 09:32:06,807 - INFO - > Epoch 93: took 12.1s (avg 12.4s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:32:16,975 - INFO - train: {'epoch': 94, 'time_epoch': 10.15602, 'eta': 52.36046, 'eta_hours': 0.01454, 'loss': 0.12182957, 'lr': 5.46e-06, 'params': 193993, 'time_iter': 0.04637, 'accuracy': 0.96057, 'f1': 0.96063, 'auc': 0.99602}
2025-08-23 09:32:17,607 - INFO - val: {'epoch': 94, 'time_epoch': 0.62179, 'loss': 0.25058783, 'lr': 0, 'params': 193993, 'time_iter': 0.01943, 'accuracy': 0.924, 'f1': 0.92472, 'auc': 0.98937}
2025-08-23 09:32:18,862 - INFO - test: {'epoch': 94, 'time_epoch': 1.24397, 'loss': 0.25666663, 'lr': 0, 'params': 193993, 'time_iter': 0.01975, 'accuracy': 0.926, 'f1': 0.92726, 'auc': 0.98661}
2025-08-23 09:32:18,886 - INFO - > Epoch 94: took 12.1s (avg 12.4s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:32:29,099 - INFO - train: {'epoch': 95, 'time_epoch': 10.20138, 'eta': 41.87709, 'eta_hours': 0.01163, 'loss': 0.12264929, 'lr': 3.8e-06, 'params': 193993, 'time_iter': 0.04658, 'accuracy': 0.96171, 'f1': 0.96177, 'auc': 0.99591}
2025-08-23 09:32:29,730 - INFO - val: {'epoch': 95, 'time_epoch': 0.62089, 'loss': 0.25375703, 'lr': 0, 'params': 193993, 'time_iter': 0.0194, 'accuracy': 0.922, 'f1': 0.92292, 'auc': 0.98898}
2025-08-23 09:32:31,005 - INFO - test: {'epoch': 95, 'time_epoch': 1.2652, 'loss': 0.26118639, 'lr': 0, 'params': 193993, 'time_iter': 0.02008, 'accuracy': 0.924, 'f1': 0.92531, 'auc': 0.98677}
2025-08-23 09:32:31,007 - INFO - > Epoch 95: took 12.1s (avg 12.4s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:32:41,213 - INFO - train: {'epoch': 96, 'time_epoch': 10.19492, 'eta': 31.39933, 'eta_hours': 0.00872, 'loss': 0.11689149, 'lr': 2.43e-06, 'params': 193993, 'time_iter': 0.04655, 'accuracy': 0.96657, 'f1': 0.96662, 'auc': 0.99595}
2025-08-23 09:32:41,844 - INFO - val: {'epoch': 96, 'time_epoch': 0.62043, 'loss': 0.25924453, 'lr': 0, 'params': 193993, 'time_iter': 0.01939, 'accuracy': 0.922, 'f1': 0.92283, 'auc': 0.98879}
2025-08-23 09:32:43,112 - INFO - test: {'epoch': 96, 'time_epoch': 1.25845, 'loss': 0.25920174, 'lr': 0, 'params': 193993, 'time_iter': 0.01998, 'accuracy': 0.928, 'f1': 0.92919, 'auc': 0.98647}
2025-08-23 09:32:43,114 - INFO - > Epoch 96: took 12.1s (avg 12.4s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:32:53,319 - INFO - train: {'epoch': 97, 'time_epoch': 10.19234, 'eta': 20.92729, 'eta_hours': 0.00581, 'loss': 0.12561219, 'lr': 1.37e-06, 'params': 193993, 'time_iter': 0.04654, 'accuracy': 0.95971, 'f1': 0.9598, 'auc': 0.99601}
2025-08-23 09:32:53,950 - INFO - val: {'epoch': 97, 'time_epoch': 0.62109, 'loss': 0.25481361, 'lr': 0, 'params': 193993, 'time_iter': 0.01941, 'accuracy': 0.924, 'f1': 0.92483, 'auc': 0.98938}
2025-08-23 09:32:55,219 - INFO - test: {'epoch': 97, 'time_epoch': 1.25971, 'loss': 0.25809278, 'lr': 0, 'params': 193993, 'time_iter': 0.02, 'accuracy': 0.924, 'f1': 0.92526, 'auc': 0.98656}
2025-08-23 09:32:55,220 - INFO - > Epoch 97: took 12.1s (avg 12.4s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:33:05,430 - INFO - train: {'epoch': 98, 'time_epoch': 10.19832, 'eta': 10.46097, 'eta_hours': 0.00291, 'loss': 0.12339891, 'lr': 6.1e-07, 'params': 193993, 'time_iter': 0.04657, 'accuracy': 0.962, 'f1': 0.962, 'auc': 0.99624}
2025-08-23 09:33:06,071 - INFO - val: {'epoch': 98, 'time_epoch': 0.63037, 'loss': 0.25571998, 'lr': 0, 'params': 193993, 'time_iter': 0.0197, 'accuracy': 0.926, 'f1': 0.92682, 'auc': 0.98948}
2025-08-23 09:33:07,343 - INFO - test: {'epoch': 98, 'time_epoch': 1.263, 'loss': 0.25538444, 'lr': 0, 'params': 193993, 'time_iter': 0.02005, 'accuracy': 0.927, 'f1': 0.92821, 'auc': 0.98673}
2025-08-23 09:33:07,346 - INFO - > Epoch 98: took 12.1s (avg 12.4s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:33:17,570 - INFO - train: {'epoch': 99, 'time_epoch': 10.21225, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.12461351, 'lr': 1.5e-07, 'params': 193993, 'time_iter': 0.04663, 'accuracy': 0.95886, 'f1': 0.95894, 'auc': 0.99615}
2025-08-23 09:33:18,203 - INFO - val: {'epoch': 99, 'time_epoch': 0.62283, 'loss': 0.26585404, 'lr': 0, 'params': 193993, 'time_iter': 0.01946, 'accuracy': 0.924, 'f1': 0.92483, 'auc': 0.98949}
2025-08-23 09:33:19,481 - INFO - test: {'epoch': 99, 'time_epoch': 1.26858, 'loss': 0.25581324, 'lr': 0, 'params': 193993, 'time_iter': 0.02014, 'accuracy': 0.926, 'f1': 0.92724, 'auc': 0.9868}
2025-08-23 09:33:19,538 - INFO - > Epoch 99: took 12.1s (avg 12.4s) | Best so far: epoch 67	train_loss: 0.1607 train_accuracy: 0.9489	val_loss: 0.2022 val_accuracy: 0.9360	test_loss: 0.2872 test_accuracy: 0.9100
2025-08-23 09:33:19,538 - INFO - Avg time per epoch: 12.42s
2025-08-23 09:33:19,538 - INFO - Total train loop time: 0.34h
2025-08-23 09:33:19,539 - INFO - Task done, results saved in results/MALNET/MALNET-E-45
2025-08-23 09:33:19,540 - INFO - Total time: 1246.38s (0.35h)
2025-08-23 09:33:19,541 - INFO - Results aggregated across runs saved in results/MALNET/MALNET-E-45/agg
2025-08-23 09:33:19,541 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-23 09:33:19,541 - INFO - Results saved in: results/MALNET/MALNET-E-45
2025-08-23 09:33:19,541 - INFO - Test results JSON files saved in: results/MALNET/MALNET-E-45/test_results/
Completed seed 45. Results saved in results/MALNET/MALNET-E-45
----------------------------------------
Submitting next job for seed 47
Submitted batch job 5482713
