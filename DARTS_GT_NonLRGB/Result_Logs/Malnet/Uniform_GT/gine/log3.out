Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          376Gi        23Gi       300Gi       2.7Gi        52Gi       347Gi
Swap:         1.9Gi       0.0Ki       1.9Gi
Sat Aug 23 09:34:18 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-16GB           On  |   00000000:B1:00.0 Off |                    0 |
| N/A   44C    P0             27W /  250W |       0MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 47
Starting training for seed 47...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/MALNET/FINAL_SINGLE/PERFORMER_E/UNI_GT/GINE
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/MALNET/FINAL_SINGLE/PERFORMER_E/UNI_GT/GINE/confignas.yaml
Using device: cuda
2025-08-23 09:34:26,333 - INFO - GPU Mem: 17.1GB
2025-08-23 09:34:26,333 - INFO - Run directory: results/MALNET/MALNET-E-47
2025-08-23 09:34:26,333 - INFO - Seed: 47
2025-08-23 09:34:26,333 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-23 09:34:26,334 - INFO - Routing mode: none
2025-08-23 09:34:26,334 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-23 09:34:26,334 - INFO - Number of layers: 4
2025-08-23 09:34:26,334 - INFO - Uncertainty enabled: False
2025-08-23 09:34:26,334 - INFO - Training mode: custom
2025-08-23 09:34:26,334 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-23 09:34:26,334 - INFO - Additional features: Router weights logging + JSON export
2025-08-23 09:34:28,364 - INFO - Computing "LocalDegreeProfile" node features for MalNetTiny.
2025-08-23 09:34:32,636 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-23 09:34:32,637 - INFO -   Data(edge_index=[2, 14299688], y=[5000], x=[7051560, 5], num_nodes=7051560)
2025-08-23 09:34:32,638 - INFO -   undirected: False
2025-08-23 09:34:32,638 - INFO -   num graphs: 5000
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-23 09:34:32,639 - INFO -   avg num_nodes/graph: 1410
2025-08-23 09:34:32,639 - INFO -   num node features: 5
2025-08-23 09:34:32,639 - INFO -   num edge features: 0
2025-08-23 09:34:32,639 - INFO -   num classes: 5
2025-08-23 09:34:32,641 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny'
2025-08-23 09:34:32,790 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-23 09:34:32,790 - INFO - Inner model type: <class 'graphgps.network.uniform_gt_model_edge.UNIFORM_GTModelEdge'>
2025-08-23 09:34:32,790 - INFO - Inner model has get_darts_model: False
2025-08-23 09:34:32,791 - INFO - GraphGymModule(
  (model): UNIFORM_GTModelEdge(
    (encoder): FeatureEncoder(
      (edge_encoder): DummyEdgeEncoder(
        (encoder): Embedding(1, 64)
      )
    )
    (pre_mp): GeneralMultiLayer(
      (Layer_0): GeneralLayer(
        (layer): Linear(
          (model): Linear(5, 64, bias=False)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU()
        )
      )
    )
    (layers): Sequential(
      (0): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GINEConv(nn=Sequential(
          (0): Linear(64, 64, bias=True)
          (1): ReLU()
          (2): Linear(64, 64, bias=True)
        ))
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (1): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GINEConv(nn=Sequential(
          (0): Linear(64, 64, bias=True)
          (1): ReLU()
          (2): Linear(64, 64, bias=True)
        ))
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (2): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GINEConv(nn=Sequential(
          (0): Linear(64, 64, bias=True)
          (1): ReLU()
          (2): Linear(64, 64, bias=True)
        ))
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (3): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GINEConv(nn=Sequential(
          (0): Linear(64, 64, bias=True)
          (1): ReLU()
          (2): Linear(64, 64, bias=True)
        ))
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
    )
    (post_mp): GNNGraphHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(64, 5, bias=True)
          )
        )
      )
    )
  )
)
2025-08-23 09:34:32,793 - INFO - Number of parameters: 193,993
2025-08-23 09:34:32,793 - INFO - Starting optimized training: 2025-08-23 09:34:32.793642
2025-08-23 09:34:32,883 - INFO - Computing "LocalDegreeProfile" node features for MalNetTiny.
2025-08-23 09:34:36,962 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny':
2025-08-23 09:34:36,962 - INFO -   Data(edge_index=[2, 14299688], y=[5000], x=[7051560, 5], num_nodes=7051560)
2025-08-23 09:34:36,963 - INFO -   undirected: False
2025-08-23 09:34:36,963 - INFO -   num graphs: 5000
2025-08-23 09:34:36,963 - INFO -   avg num_nodes/graph: 1410
2025-08-23 09:34:36,963 - INFO -   num node features: 5
2025-08-23 09:34:36,963 - INFO -   num edge features: 0
2025-08-23 09:34:36,964 - INFO -   num classes: 5
2025-08-23 09:34:36,967 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny'
2025-08-23 09:34:36,970 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-23 09:34:36,970 - INFO - Start from epoch 0
2025-08-23 09:34:48,169 - INFO - train: {'epoch': 0, 'time_epoch': 11.11227, 'eta': 1100.11474, 'eta_hours': 0.30559, 'loss': 1.61720524, 'lr': 0.0, 'params': 193993, 'time_iter': 0.05074, 'accuracy': 0.2, 'f1': 0.06667, 'auc': 0.53351}
2025-08-23 09:34:48,172 - INFO - ...computing epoch stats took: 0.08s
2025-08-23 09:34:48,856 - INFO - val: {'epoch': 0, 'time_epoch': 0.67452, 'loss': 1.61381979, 'lr': 0, 'params': 193993, 'time_iter': 0.02108, 'accuracy': 0.2, 'f1': 0.06667, 'auc': 0.57794}
2025-08-23 09:34:48,858 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:34:50,246 - INFO - test: {'epoch': 0, 'time_epoch': 1.3781, 'loss': 1.61402543, 'lr': 0, 'params': 193993, 'time_iter': 0.02187, 'accuracy': 0.2, 'f1': 0.06667, 'auc': 0.5644}
2025-08-23 09:34:50,248 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:34:50,249 - INFO - > Epoch 0: took 13.3s (avg 13.3s) | Best so far: epoch 0	train_loss: 1.6172 train_accuracy: 0.2000	val_loss: 1.6138 val_accuracy: 0.2000	test_loss: 1.6140 test_accuracy: 0.2000
2025-08-23 09:35:00,829 - INFO - train: {'epoch': 1, 'time_epoch': 10.56522, 'eta': 1062.19722, 'eta_hours': 0.29505, 'loss': 1.54844405, 'lr': 5e-05, 'params': 193993, 'time_iter': 0.04824, 'accuracy': 0.34029, 'f1': 0.28418, 'auc': 0.7495}
2025-08-23 09:35:00,832 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:35:01,487 - INFO - val: {'epoch': 1, 'time_epoch': 0.64598, 'loss': 1.48548768, 'lr': 0, 'params': 193993, 'time_iter': 0.02019, 'accuracy': 0.5, 'f1': 0.46306, 'auc': 0.83417}
2025-08-23 09:35:01,488 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:35:02,786 - INFO - test: {'epoch': 1, 'time_epoch': 1.2884, 'loss': 1.49119679, 'lr': 0, 'params': 193993, 'time_iter': 0.02045, 'accuracy': 0.492, 'f1': 0.45355, 'auc': 0.7996}
2025-08-23 09:35:02,788 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:35:02,788 - INFO - > Epoch 1: took 12.5s (avg 12.9s) | Best so far: epoch 1	train_loss: 1.5484 train_accuracy: 0.3403	val_loss: 1.4855 val_accuracy: 0.5000	test_loss: 1.4912 test_accuracy: 0.4920
2025-08-23 09:35:13,341 - INFO - train: {'epoch': 2, 'time_epoch': 10.53726, 'eta': 1041.61025, 'eta_hours': 0.28934, 'loss': 1.43424911, 'lr': 0.0001, 'params': 193993, 'time_iter': 0.04812, 'accuracy': 0.50086, 'f1': 0.45668, 'auc': 0.81732}
2025-08-23 09:35:13,344 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:35:14,000 - INFO - val: {'epoch': 2, 'time_epoch': 0.64693, 'loss': 1.39815314, 'lr': 0, 'params': 193993, 'time_iter': 0.02022, 'accuracy': 0.534, 'f1': 0.50152, 'auc': 0.85314}
2025-08-23 09:35:14,001 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:35:15,316 - INFO - test: {'epoch': 2, 'time_epoch': 1.30482, 'loss': 1.40890901, 'lr': 0, 'params': 193993, 'time_iter': 0.02071, 'accuracy': 0.496, 'f1': 0.47119, 'auc': 0.82121}
2025-08-23 09:35:15,318 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:35:15,318 - INFO - > Epoch 2: took 12.5s (avg 12.8s) | Best so far: epoch 2	train_loss: 1.4342 train_accuracy: 0.5009	val_loss: 1.3982 val_accuracy: 0.5340	test_loss: 1.4089 test_accuracy: 0.4960
2025-08-23 09:35:25,895 - INFO - train: {'epoch': 3, 'time_epoch': 10.56365, 'eta': 1026.68167, 'eta_hours': 0.28519, 'loss': 1.35474079, 'lr': 0.00015, 'params': 193993, 'time_iter': 0.04824, 'accuracy': 0.58, 'f1': 0.57646, 'auc': 0.85602}
2025-08-23 09:35:26,553 - INFO - val: {'epoch': 3, 'time_epoch': 0.64539, 'loss': 1.30697934, 'lr': 0, 'params': 193993, 'time_iter': 0.02017, 'accuracy': 0.59, 'f1': 0.55205, 'auc': 0.89272}
2025-08-23 09:35:27,847 - INFO - test: {'epoch': 3, 'time_epoch': 1.28369, 'loss': 1.32261114, 'lr': 0, 'params': 193993, 'time_iter': 0.02038, 'accuracy': 0.57, 'f1': 0.54598, 'auc': 0.86656}
2025-08-23 09:35:27,850 - INFO - > Epoch 3: took 12.5s (avg 12.7s) | Best so far: epoch 3	train_loss: 1.3547 train_accuracy: 0.5800	val_loss: 1.3070 val_accuracy: 0.5900	test_loss: 1.3226 test_accuracy: 0.5700
2025-08-23 09:35:38,482 - INFO - train: {'epoch': 4, 'time_epoch': 10.6162, 'eta': 1014.4975, 'eta_hours': 0.2818, 'loss': 1.25758381, 'lr': 0.0002, 'params': 193993, 'time_iter': 0.04848, 'accuracy': 0.67829, 'f1': 0.67543, 'auc': 0.88628}
2025-08-23 09:35:39,146 - INFO - val: {'epoch': 4, 'time_epoch': 0.65268, 'loss': 1.20021071, 'lr': 0, 'params': 193993, 'time_iter': 0.0204, 'accuracy': 0.76, 'f1': 0.75962, 'auc': 0.90525}
2025-08-23 09:35:40,454 - INFO - test: {'epoch': 4, 'time_epoch': 1.29593, 'loss': 1.21976545, 'lr': 0, 'params': 193993, 'time_iter': 0.02057, 'accuracy': 0.729, 'f1': 0.73067, 'auc': 0.88878}
2025-08-23 09:35:40,456 - INFO - > Epoch 4: took 12.6s (avg 12.7s) | Best so far: epoch 4	train_loss: 1.2576 train_accuracy: 0.6783	val_loss: 1.2002 val_accuracy: 0.7600	test_loss: 1.2198 test_accuracy: 0.7290
2025-08-23 09:35:51,088 - INFO - train: {'epoch': 5, 'time_epoch': 10.61526, 'eta': 1002.82116, 'eta_hours': 0.27856, 'loss': 1.15616292, 'lr': 0.00025, 'params': 193993, 'time_iter': 0.04847, 'accuracy': 0.724, 'f1': 0.72292, 'auc': 0.90975}
2025-08-23 09:35:51,746 - INFO - val: {'epoch': 5, 'time_epoch': 0.64649, 'loss': 1.10775721, 'lr': 0, 'params': 193993, 'time_iter': 0.0202, 'accuracy': 0.75, 'f1': 0.75429, 'auc': 0.92997}
2025-08-23 09:35:53,064 - INFO - test: {'epoch': 5, 'time_epoch': 1.30666, 'loss': 1.12557505, 'lr': 0, 'params': 193993, 'time_iter': 0.02074, 'accuracy': 0.743, 'f1': 0.74832, 'auc': 0.92105}
2025-08-23 09:35:53,066 - INFO - > Epoch 5: took 12.6s (avg 12.7s) | Best so far: epoch 4	train_loss: 1.2576 train_accuracy: 0.6783	val_loss: 1.2002 val_accuracy: 0.7600	test_loss: 1.2198 test_accuracy: 0.7290
2025-08-23 09:36:03,644 - INFO - train: {'epoch': 6, 'time_epoch': 10.56179, 'eta': 990.7376, 'eta_hours': 0.2752, 'loss': 1.07513707, 'lr': 0.0003, 'params': 193993, 'time_iter': 0.04823, 'accuracy': 0.744, 'f1': 0.74408, 'auc': 0.91348}
2025-08-23 09:36:04,314 - INFO - val: {'epoch': 6, 'time_epoch': 0.6569, 'loss': 1.01864712, 'lr': 0, 'params': 193993, 'time_iter': 0.02053, 'accuracy': 0.78, 'f1': 0.78253, 'auc': 0.93967}
2025-08-23 09:36:05,619 - INFO - test: {'epoch': 6, 'time_epoch': 1.29302, 'loss': 1.04332244, 'lr': 0, 'params': 193993, 'time_iter': 0.02052, 'accuracy': 0.752, 'f1': 0.75764, 'auc': 0.93074}
2025-08-23 09:36:05,621 - INFO - > Epoch 6: took 12.6s (avg 12.7s) | Best so far: epoch 6	train_loss: 1.0751 train_accuracy: 0.7440	val_loss: 1.0186 val_accuracy: 0.7800	test_loss: 1.0433 test_accuracy: 0.7520
2025-08-23 09:36:16,276 - INFO - train: {'epoch': 7, 'time_epoch': 10.63867, 'eta': 979.91861, 'eta_hours': 0.2722, 'loss': 0.98230541, 'lr': 0.00035, 'params': 193993, 'time_iter': 0.04858, 'accuracy': 0.76114, 'f1': 0.76206, 'auc': 0.92478}
2025-08-23 09:36:16,940 - INFO - val: {'epoch': 7, 'time_epoch': 0.65082, 'loss': 0.95408452, 'lr': 0, 'params': 193993, 'time_iter': 0.02034, 'accuracy': 0.76, 'f1': 0.76746, 'auc': 0.93939}
2025-08-23 09:36:18,259 - INFO - test: {'epoch': 7, 'time_epoch': 1.30524, 'loss': 0.9681477, 'lr': 0, 'params': 193993, 'time_iter': 0.02072, 'accuracy': 0.751, 'f1': 0.75966, 'auc': 0.93472}
2025-08-23 09:36:18,261 - INFO - > Epoch 7: took 12.6s (avg 12.7s) | Best so far: epoch 6	train_loss: 1.0751 train_accuracy: 0.7440	val_loss: 1.0186 val_accuracy: 0.7800	test_loss: 1.0433 test_accuracy: 0.7520
2025-08-23 09:36:28,921 - INFO - train: {'epoch': 8, 'time_epoch': 10.64337, 'eta': 969.18724, 'eta_hours': 0.26922, 'loss': 0.9084064, 'lr': 0.0004, 'params': 193993, 'time_iter': 0.0486, 'accuracy': 0.76514, 'f1': 0.76725, 'auc': 0.92889}
2025-08-23 09:36:29,583 - INFO - val: {'epoch': 8, 'time_epoch': 0.64924, 'loss': 0.90834547, 'lr': 0, 'params': 193993, 'time_iter': 0.02029, 'accuracy': 0.74, 'f1': 0.7366, 'auc': 0.92266}
2025-08-23 09:36:30,894 - INFO - test: {'epoch': 8, 'time_epoch': 1.29963, 'loss': 0.92078505, 'lr': 0, 'params': 193993, 'time_iter': 0.02063, 'accuracy': 0.711, 'f1': 0.70925, 'auc': 0.92171}
2025-08-23 09:36:30,896 - INFO - > Epoch 8: took 12.6s (avg 12.7s) | Best so far: epoch 6	train_loss: 1.0751 train_accuracy: 0.7440	val_loss: 1.0186 val_accuracy: 0.7800	test_loss: 1.0433 test_accuracy: 0.7520
2025-08-23 09:36:41,496 - INFO - train: {'epoch': 9, 'time_epoch': 10.58383, 'eta': 957.93762, 'eta_hours': 0.26609, 'loss': 0.83445954, 'lr': 0.00045, 'params': 193993, 'time_iter': 0.04833, 'accuracy': 0.77057, 'f1': 0.77219, 'auc': 0.93087}
2025-08-23 09:36:42,155 - INFO - val: {'epoch': 9, 'time_epoch': 0.64708, 'loss': 0.81597376, 'lr': 0, 'params': 193993, 'time_iter': 0.02022, 'accuracy': 0.784, 'f1': 0.79255, 'auc': 0.94664}
2025-08-23 09:36:43,458 - INFO - test: {'epoch': 9, 'time_epoch': 1.29129, 'loss': 0.8457898, 'lr': 0, 'params': 193993, 'time_iter': 0.0205, 'accuracy': 0.764, 'f1': 0.77184, 'auc': 0.93532}
2025-08-23 09:36:43,460 - INFO - > Epoch 9: took 12.6s (avg 12.6s) | Best so far: epoch 9	train_loss: 0.8345 train_accuracy: 0.7706	val_loss: 0.8160 val_accuracy: 0.7840	test_loss: 0.8458 test_accuracy: 0.7640
2025-08-23 09:36:54,121 - INFO - train: {'epoch': 10, 'time_epoch': 10.64465, 'eta': 947.30111, 'eta_hours': 0.26314, 'loss': 0.7646801, 'lr': 0.0005, 'params': 193993, 'time_iter': 0.04861, 'accuracy': 0.78571, 'f1': 0.7886, 'auc': 0.93909}
2025-08-23 09:36:54,796 - INFO - val: {'epoch': 10, 'time_epoch': 0.66217, 'loss': 0.71502087, 'lr': 0, 'params': 193993, 'time_iter': 0.02069, 'accuracy': 0.808, 'f1': 0.807, 'auc': 0.9546}
2025-08-23 09:36:56,128 - INFO - test: {'epoch': 10, 'time_epoch': 1.31894, 'loss': 0.75657648, 'lr': 0, 'params': 193993, 'time_iter': 0.02094, 'accuracy': 0.788, 'f1': 0.78806, 'auc': 0.94516}
2025-08-23 09:36:56,130 - INFO - > Epoch 10: took 12.7s (avg 12.7s) | Best so far: epoch 10	train_loss: 0.7647 train_accuracy: 0.7857	val_loss: 0.7150 val_accuracy: 0.8080	test_loss: 0.7566 test_accuracy: 0.7880
2025-08-23 09:37:06,771 - INFO - train: {'epoch': 11, 'time_epoch': 10.62382, 'eta': 936.51054, 'eta_hours': 0.26014, 'loss': 0.70624344, 'lr': 0.00049985, 'params': 193993, 'time_iter': 0.04851, 'accuracy': 0.78771, 'f1': 0.78999, 'auc': 0.94112}
2025-08-23 09:37:07,443 - INFO - val: {'epoch': 11, 'time_epoch': 0.6592, 'loss': 0.6721949, 'lr': 0, 'params': 193993, 'time_iter': 0.0206, 'accuracy': 0.818, 'f1': 0.82145, 'auc': 0.95418}
2025-08-23 09:37:08,773 - INFO - test: {'epoch': 11, 'time_epoch': 1.31835, 'loss': 0.71503041, 'lr': 0, 'params': 193993, 'time_iter': 0.02093, 'accuracy': 0.801, 'f1': 0.80548, 'auc': 0.9431}
2025-08-23 09:37:08,775 - INFO - > Epoch 11: took 12.6s (avg 12.7s) | Best so far: epoch 11	train_loss: 0.7062 train_accuracy: 0.7877	val_loss: 0.6722 val_accuracy: 0.8180	test_loss: 0.7150 test_accuracy: 0.8010
2025-08-23 09:37:19,446 - INFO - train: {'epoch': 12, 'time_epoch': 10.65451, 'eta': 925.95099, 'eta_hours': 0.25721, 'loss': 0.66173394, 'lr': 0.00049939, 'params': 193993, 'time_iter': 0.04865, 'accuracy': 0.79771, 'f1': 0.79983, 'auc': 0.94573}
2025-08-23 09:37:20,115 - INFO - val: {'epoch': 12, 'time_epoch': 0.65777, 'loss': 0.70241899, 'lr': 0, 'params': 193993, 'time_iter': 0.02056, 'accuracy': 0.76, 'f1': 0.76401, 'auc': 0.95183}
2025-08-23 09:37:21,433 - INFO - test: {'epoch': 12, 'time_epoch': 1.30772, 'loss': 0.72324014, 'lr': 0, 'params': 193993, 'time_iter': 0.02076, 'accuracy': 0.741, 'f1': 0.74566, 'auc': 0.94671}
2025-08-23 09:37:21,435 - INFO - > Epoch 12: took 12.7s (avg 12.7s) | Best so far: epoch 11	train_loss: 0.7062 train_accuracy: 0.7877	val_loss: 0.6722 val_accuracy: 0.8180	test_loss: 0.7150 test_accuracy: 0.8010
2025-08-23 09:37:32,053 - INFO - train: {'epoch': 13, 'time_epoch': 10.60116, 'eta': 915.05017, 'eta_hours': 0.25418, 'loss': 0.62175798, 'lr': 0.00049863, 'params': 193993, 'time_iter': 0.04841, 'accuracy': 0.80457, 'f1': 0.80658, 'auc': 0.94885}
2025-08-23 09:37:32,715 - INFO - val: {'epoch': 13, 'time_epoch': 0.65048, 'loss': 0.58305751, 'lr': 0, 'params': 193993, 'time_iter': 0.02033, 'accuracy': 0.828, 'f1': 0.83314, 'auc': 0.96261}
2025-08-23 09:37:34,033 - INFO - test: {'epoch': 13, 'time_epoch': 1.30656, 'loss': 0.61474301, 'lr': 0, 'params': 193993, 'time_iter': 0.02074, 'accuracy': 0.806, 'f1': 0.81146, 'auc': 0.95437}
2025-08-23 09:37:34,036 - INFO - > Epoch 13: took 12.6s (avg 12.6s) | Best so far: epoch 13	train_loss: 0.6218 train_accuracy: 0.8046	val_loss: 0.5831 val_accuracy: 0.8280	test_loss: 0.6147 test_accuracy: 0.8060
2025-08-23 09:37:44,619 - INFO - train: {'epoch': 14, 'time_epoch': 10.56785, 'eta': 904.00051, 'eta_hours': 0.25111, 'loss': 0.58558748, 'lr': 0.00049757, 'params': 193993, 'time_iter': 0.04826, 'accuracy': 0.81714, 'f1': 0.81905, 'auc': 0.95205}
2025-08-23 09:37:45,284 - INFO - val: {'epoch': 14, 'time_epoch': 0.65389, 'loss': 0.57811846, 'lr': 0, 'params': 193993, 'time_iter': 0.02043, 'accuracy': 0.82, 'f1': 0.8207, 'auc': 0.95927}
2025-08-23 09:37:46,599 - INFO - test: {'epoch': 14, 'time_epoch': 1.30392, 'loss': 0.60423605, 'lr': 0, 'params': 193993, 'time_iter': 0.0207, 'accuracy': 0.812, 'f1': 0.81333, 'auc': 0.95669}
2025-08-23 09:37:46,601 - INFO - > Epoch 14: took 12.6s (avg 12.6s) | Best so far: epoch 13	train_loss: 0.6218 train_accuracy: 0.8046	val_loss: 0.5831 val_accuracy: 0.8280	test_loss: 0.6147 test_accuracy: 0.8060
2025-08-23 09:37:57,258 - INFO - train: {'epoch': 15, 'time_epoch': 10.64095, 'eta': 893.39485, 'eta_hours': 0.24817, 'loss': 0.55335416, 'lr': 0.0004962, 'params': 193993, 'time_iter': 0.04859, 'accuracy': 0.82514, 'f1': 0.82608, 'auc': 0.95668}
2025-08-23 09:37:57,923 - INFO - val: {'epoch': 15, 'time_epoch': 0.65246, 'loss': 0.51818091, 'lr': 0, 'params': 193993, 'time_iter': 0.02039, 'accuracy': 0.844, 'f1': 0.8496, 'auc': 0.97023}
2025-08-23 09:37:59,243 - INFO - test: {'epoch': 15, 'time_epoch': 1.30788, 'loss': 0.58640122, 'lr': 0, 'params': 193993, 'time_iter': 0.02076, 'accuracy': 0.811, 'f1': 0.81621, 'auc': 0.95632}
2025-08-23 09:37:59,245 - INFO - > Epoch 15: took 12.6s (avg 12.6s) | Best so far: epoch 15	train_loss: 0.5534 train_accuracy: 0.8251	val_loss: 0.5182 val_accuracy: 0.8440	test_loss: 0.5864 test_accuracy: 0.8110
2025-08-23 09:38:09,896 - INFO - train: {'epoch': 16, 'time_epoch': 10.6355, 'eta': 882.75847, 'eta_hours': 0.24521, 'loss': 0.52565472, 'lr': 0.00049454, 'params': 193993, 'time_iter': 0.04856, 'accuracy': 0.83114, 'f1': 0.83283, 'auc': 0.95972}
2025-08-23 09:38:10,558 - INFO - val: {'epoch': 16, 'time_epoch': 0.64965, 'loss': 0.57427554, 'lr': 0, 'params': 193993, 'time_iter': 0.0203, 'accuracy': 0.828, 'f1': 0.83468, 'auc': 0.96348}
2025-08-23 09:38:11,875 - INFO - test: {'epoch': 16, 'time_epoch': 1.30504, 'loss': 0.60097554, 'lr': 0, 'params': 193993, 'time_iter': 0.02071, 'accuracy': 0.803, 'f1': 0.80981, 'auc': 0.95634}
2025-08-23 09:38:11,877 - INFO - > Epoch 16: took 12.6s (avg 12.6s) | Best so far: epoch 15	train_loss: 0.5534 train_accuracy: 0.8251	val_loss: 0.5182 val_accuracy: 0.8440	test_loss: 0.5864 test_accuracy: 0.8110
2025-08-23 09:38:22,538 - INFO - train: {'epoch': 17, 'time_epoch': 10.64577, 'eta': 872.16898, 'eta_hours': 0.24227, 'loss': 0.48673382, 'lr': 0.00049257, 'params': 193993, 'time_iter': 0.04861, 'accuracy': 0.84629, 'f1': 0.84749, 'auc': 0.96667}
2025-08-23 09:38:23,203 - INFO - val: {'epoch': 17, 'time_epoch': 0.65196, 'loss': 0.47685143, 'lr': 0, 'params': 193993, 'time_iter': 0.02037, 'accuracy': 0.856, 'f1': 0.86309, 'auc': 0.97806}
2025-08-23 09:38:24,521 - INFO - test: {'epoch': 17, 'time_epoch': 1.30658, 'loss': 0.53130224, 'lr': 0, 'params': 193993, 'time_iter': 0.02074, 'accuracy': 0.83, 'f1': 0.83733, 'auc': 0.96785}
2025-08-23 09:38:24,523 - INFO - > Epoch 17: took 12.6s (avg 12.6s) | Best so far: epoch 17	train_loss: 0.4867 train_accuracy: 0.8463	val_loss: 0.4769 val_accuracy: 0.8560	test_loss: 0.5313 test_accuracy: 0.8300
2025-08-23 09:38:35,173 - INFO - train: {'epoch': 18, 'time_epoch': 10.63402, 'eta': 861.52345, 'eta_hours': 0.23931, 'loss': 0.46495729, 'lr': 0.00049032, 'params': 193993, 'time_iter': 0.04856, 'accuracy': 0.85543, 'f1': 0.85623, 'auc': 0.96751}
2025-08-23 09:38:35,836 - INFO - val: {'epoch': 18, 'time_epoch': 0.65104, 'loss': 0.56851335, 'lr': 0, 'params': 193993, 'time_iter': 0.02035, 'accuracy': 0.794, 'f1': 0.79656, 'auc': 0.96502}
2025-08-23 09:38:37,148 - INFO - test: {'epoch': 18, 'time_epoch': 1.29992, 'loss': 0.58503831, 'lr': 0, 'params': 193993, 'time_iter': 0.02063, 'accuracy': 0.784, 'f1': 0.7897, 'auc': 0.95996}
2025-08-23 09:38:37,149 - INFO - > Epoch 18: took 12.6s (avg 12.6s) | Best so far: epoch 17	train_loss: 0.4867 train_accuracy: 0.8463	val_loss: 0.4769 val_accuracy: 0.8560	test_loss: 0.5313 test_accuracy: 0.8300
2025-08-23 09:38:47,778 - INFO - train: {'epoch': 19, 'time_epoch': 10.61279, 'eta': 850.79413, 'eta_hours': 0.23633, 'loss': 0.43822494, 'lr': 0.00048776, 'params': 193993, 'time_iter': 0.04846, 'accuracy': 0.86343, 'f1': 0.86453, 'auc': 0.97198}
2025-08-23 09:38:48,438 - INFO - val: {'epoch': 19, 'time_epoch': 0.64976, 'loss': 0.46269918, 'lr': 0, 'params': 193993, 'time_iter': 0.0203, 'accuracy': 0.834, 'f1': 0.84221, 'auc': 0.97914}
2025-08-23 09:38:49,745 - INFO - test: {'epoch': 19, 'time_epoch': 1.29553, 'loss': 0.49510828, 'lr': 0, 'params': 193993, 'time_iter': 0.02056, 'accuracy': 0.821, 'f1': 0.82798, 'auc': 0.97612}
2025-08-23 09:38:49,747 - INFO - > Epoch 19: took 12.6s (avg 12.6s) | Best so far: epoch 17	train_loss: 0.4867 train_accuracy: 0.8463	val_loss: 0.4769 val_accuracy: 0.8560	test_loss: 0.5313 test_accuracy: 0.8300
2025-08-23 09:39:00,468 - INFO - train: {'epoch': 20, 'time_epoch': 10.70399, 'eta': 840.41902, 'eta_hours': 0.23345, 'loss': 0.41742083, 'lr': 0.00048492, 'params': 193993, 'time_iter': 0.04888, 'accuracy': 0.86457, 'f1': 0.8654, 'auc': 0.97421}
2025-08-23 09:39:01,147 - INFO - val: {'epoch': 20, 'time_epoch': 0.66579, 'loss': 0.37422468, 'lr': 0, 'params': 193993, 'time_iter': 0.02081, 'accuracy': 0.88, 'f1': 0.88426, 'auc': 0.9826}
2025-08-23 09:39:02,502 - INFO - test: {'epoch': 20, 'time_epoch': 1.34028, 'loss': 0.43116443, 'lr': 0, 'params': 193993, 'time_iter': 0.02127, 'accuracy': 0.851, 'f1': 0.85496, 'auc': 0.9762}
2025-08-23 09:39:02,504 - INFO - > Epoch 20: took 12.8s (avg 12.6s) | Best so far: epoch 20	train_loss: 0.4174 train_accuracy: 0.8646	val_loss: 0.3742 val_accuracy: 0.8800	test_loss: 0.4312 test_accuracy: 0.8510
2025-08-23 09:39:13,340 - INFO - train: {'epoch': 21, 'time_epoch': 10.81817, 'eta': 830.41883, 'eta_hours': 0.23067, 'loss': 0.38639952, 'lr': 0.0004818, 'params': 193993, 'time_iter': 0.0494, 'accuracy': 0.87886, 'f1': 0.87952, 'auc': 0.97691}
2025-08-23 09:39:14,026 - INFO - val: {'epoch': 21, 'time_epoch': 0.67362, 'loss': 0.32857517, 'lr': 0, 'params': 193993, 'time_iter': 0.02105, 'accuracy': 0.9, 'f1': 0.90301, 'auc': 0.98432}
2025-08-23 09:39:15,376 - INFO - test: {'epoch': 21, 'time_epoch': 1.33603, 'loss': 0.36967112, 'lr': 0, 'params': 193993, 'time_iter': 0.02121, 'accuracy': 0.885, 'f1': 0.88763, 'auc': 0.98071}
2025-08-23 09:39:15,378 - INFO - > Epoch 21: took 12.9s (avg 12.7s) | Best so far: epoch 21	train_loss: 0.3864 train_accuracy: 0.8789	val_loss: 0.3286 val_accuracy: 0.9000	test_loss: 0.3697 test_accuracy: 0.8850
2025-08-23 09:39:26,163 - INFO - train: {'epoch': 22, 'time_epoch': 10.76722, 'eta': 820.17692, 'eta_hours': 0.22783, 'loss': 0.36843944, 'lr': 0.00047839, 'params': 193993, 'time_iter': 0.04917, 'accuracy': 0.88771, 'f1': 0.88803, 'auc': 0.97767}
2025-08-23 09:39:26,825 - INFO - val: {'epoch': 22, 'time_epoch': 0.65033, 'loss': 0.40186657, 'lr': 0, 'params': 193993, 'time_iter': 0.02032, 'accuracy': 0.858, 'f1': 0.86531, 'auc': 0.98254}
2025-08-23 09:39:28,142 - INFO - test: {'epoch': 22, 'time_epoch': 1.30575, 'loss': 0.44821341, 'lr': 0, 'params': 193993, 'time_iter': 0.02073, 'accuracy': 0.84, 'f1': 0.84825, 'auc': 0.97973}
2025-08-23 09:39:28,144 - INFO - > Epoch 22: took 12.8s (avg 12.7s) | Best so far: epoch 21	train_loss: 0.3864 train_accuracy: 0.8789	val_loss: 0.3286 val_accuracy: 0.9000	test_loss: 0.3697 test_accuracy: 0.8850
2025-08-23 09:39:38,794 - INFO - train: {'epoch': 23, 'time_epoch': 10.6348, 'eta': 809.47192, 'eta_hours': 0.22485, 'loss': 0.34456464, 'lr': 0.0004747, 'params': 193993, 'time_iter': 0.04856, 'accuracy': 0.894, 'f1': 0.89484, 'auc': 0.97979}
2025-08-23 09:39:39,457 - INFO - val: {'epoch': 23, 'time_epoch': 0.65065, 'loss': 0.43514135, 'lr': 0, 'params': 193993, 'time_iter': 0.02033, 'accuracy': 0.874, 'f1': 0.87532, 'auc': 0.97726}
2025-08-23 09:39:40,765 - INFO - test: {'epoch': 23, 'time_epoch': 1.29649, 'loss': 0.48774139, 'lr': 0, 'params': 193993, 'time_iter': 0.02058, 'accuracy': 0.854, 'f1': 0.85393, 'auc': 0.9702}
2025-08-23 09:39:40,767 - INFO - > Epoch 23: took 12.6s (avg 12.7s) | Best so far: epoch 21	train_loss: 0.3864 train_accuracy: 0.8789	val_loss: 0.3286 val_accuracy: 0.9000	test_loss: 0.3697 test_accuracy: 0.8850
2025-08-23 09:39:51,387 - INFO - train: {'epoch': 24, 'time_epoch': 10.60425, 'eta': 798.68087, 'eta_hours': 0.22186, 'loss': 0.33414206, 'lr': 0.00047074, 'params': 193993, 'time_iter': 0.04842, 'accuracy': 0.894, 'f1': 0.89462, 'auc': 0.98134}
2025-08-23 09:39:52,052 - INFO - val: {'epoch': 24, 'time_epoch': 0.65371, 'loss': 0.32465265, 'lr': 0, 'params': 193993, 'time_iter': 0.02043, 'accuracy': 0.898, 'f1': 0.9007, 'auc': 0.98387}
2025-08-23 09:39:53,374 - INFO - test: {'epoch': 24, 'time_epoch': 1.3099, 'loss': 0.35588776, 'lr': 0, 'params': 193993, 'time_iter': 0.02079, 'accuracy': 0.874, 'f1': 0.87657, 'auc': 0.98056}
2025-08-23 09:39:53,376 - INFO - > Epoch 24: took 12.6s (avg 12.7s) | Best so far: epoch 21	train_loss: 0.3864 train_accuracy: 0.8789	val_loss: 0.3286 val_accuracy: 0.9000	test_loss: 0.3697 test_accuracy: 0.8850
2025-08-23 09:40:04,066 - INFO - train: {'epoch': 25, 'time_epoch': 10.67364, 'eta': 788.10171, 'eta_hours': 0.21892, 'loss': 0.3294057, 'lr': 0.00046651, 'params': 193993, 'time_iter': 0.04874, 'accuracy': 0.89457, 'f1': 0.89525, 'auc': 0.98103}
2025-08-23 09:40:04,731 - INFO - val: {'epoch': 25, 'time_epoch': 0.65304, 'loss': 0.36504782, 'lr': 0, 'params': 193993, 'time_iter': 0.02041, 'accuracy': 0.864, 'f1': 0.86783, 'auc': 0.98256}
2025-08-23 09:40:06,062 - INFO - test: {'epoch': 25, 'time_epoch': 1.31717, 'loss': 0.40292514, 'lr': 0, 'params': 193993, 'time_iter': 0.02091, 'accuracy': 0.859, 'f1': 0.86432, 'auc': 0.97794}
2025-08-23 09:40:06,063 - INFO - > Epoch 25: took 12.7s (avg 12.7s) | Best so far: epoch 21	train_loss: 0.3864 train_accuracy: 0.8789	val_loss: 0.3286 val_accuracy: 0.9000	test_loss: 0.3697 test_accuracy: 0.8850
2025-08-23 09:40:16,754 - INFO - train: {'epoch': 26, 'time_epoch': 10.67339, 'eta': 777.51486, 'eta_hours': 0.21598, 'loss': 0.31889341, 'lr': 0.00046201, 'params': 193993, 'time_iter': 0.04874, 'accuracy': 0.89543, 'f1': 0.89569, 'auc': 0.98258}
2025-08-23 09:40:17,415 - INFO - val: {'epoch': 26, 'time_epoch': 0.64997, 'loss': 0.33704829, 'lr': 0, 'params': 193993, 'time_iter': 0.02031, 'accuracy': 0.894, 'f1': 0.89578, 'auc': 0.9834}
2025-08-23 09:40:18,726 - INFO - test: {'epoch': 26, 'time_epoch': 1.29855, 'loss': 0.35324737, 'lr': 0, 'params': 193993, 'time_iter': 0.02061, 'accuracy': 0.88, 'f1': 0.88251, 'auc': 0.98169}
2025-08-23 09:40:18,728 - INFO - > Epoch 26: took 12.7s (avg 12.7s) | Best so far: epoch 21	train_loss: 0.3864 train_accuracy: 0.8789	val_loss: 0.3286 val_accuracy: 0.9000	test_loss: 0.3697 test_accuracy: 0.8850
2025-08-23 09:40:29,365 - INFO - train: {'epoch': 27, 'time_epoch': 10.6211, 'eta': 766.78737, 'eta_hours': 0.213, 'loss': 0.31694436, 'lr': 0.00045726, 'params': 193993, 'time_iter': 0.0485, 'accuracy': 0.90143, 'f1': 0.90171, 'auc': 0.98185}
2025-08-23 09:40:30,023 - INFO - val: {'epoch': 27, 'time_epoch': 0.64552, 'loss': 0.43701171, 'lr': 0, 'params': 193993, 'time_iter': 0.02017, 'accuracy': 0.856, 'f1': 0.85368, 'auc': 0.98017}
2025-08-23 09:40:31,320 - INFO - test: {'epoch': 27, 'time_epoch': 1.2854, 'loss': 0.49999674, 'lr': 0, 'params': 193993, 'time_iter': 0.0204, 'accuracy': 0.822, 'f1': 0.82179, 'auc': 0.97384}
2025-08-23 09:40:31,322 - INFO - > Epoch 27: took 12.6s (avg 12.7s) | Best so far: epoch 21	train_loss: 0.3864 train_accuracy: 0.8789	val_loss: 0.3286 val_accuracy: 0.9000	test_loss: 0.3697 test_accuracy: 0.8850
2025-08-23 09:40:41,972 - INFO - train: {'epoch': 28, 'time_epoch': 10.63343, 'eta': 756.09741, 'eta_hours': 0.21003, 'loss': 0.30306292, 'lr': 0.00045225, 'params': 193993, 'time_iter': 0.04855, 'accuracy': 0.90114, 'f1': 0.90131, 'auc': 0.98366}
2025-08-23 09:40:42,640 - INFO - val: {'epoch': 28, 'time_epoch': 0.65583, 'loss': 0.27205836, 'lr': 0, 'params': 193993, 'time_iter': 0.02049, 'accuracy': 0.916, 'f1': 0.91719, 'auc': 0.98685}
2025-08-23 09:40:43,980 - INFO - test: {'epoch': 28, 'time_epoch': 1.32824, 'loss': 0.30554589, 'lr': 0, 'params': 193993, 'time_iter': 0.02108, 'accuracy': 0.895, 'f1': 0.89514, 'auc': 0.98416}
2025-08-23 09:40:43,982 - INFO - > Epoch 28: took 12.7s (avg 12.7s) | Best so far: epoch 28	train_loss: 0.3031 train_accuracy: 0.9011	val_loss: 0.2721 val_accuracy: 0.9160	test_loss: 0.3055 test_accuracy: 0.8950
2025-08-23 09:40:54,583 - INFO - train: {'epoch': 29, 'time_epoch': 10.58548, 'eta': 745.29932, 'eta_hours': 0.20703, 'loss': 0.27782529, 'lr': 0.000447, 'params': 193993, 'time_iter': 0.04834, 'accuracy': 0.91, 'f1': 0.91009, 'auc': 0.98572}
2025-08-23 09:40:55,240 - INFO - val: {'epoch': 29, 'time_epoch': 0.64507, 'loss': 0.31414732, 'lr': 0, 'params': 193993, 'time_iter': 0.02016, 'accuracy': 0.906, 'f1': 0.90754, 'auc': 0.98526}
2025-08-23 09:40:56,545 - INFO - test: {'epoch': 29, 'time_epoch': 1.29435, 'loss': 0.34648357, 'lr': 0, 'params': 193993, 'time_iter': 0.02055, 'accuracy': 0.885, 'f1': 0.8875, 'auc': 0.98092}
2025-08-23 09:40:56,546 - INFO - > Epoch 29: took 12.6s (avg 12.7s) | Best so far: epoch 28	train_loss: 0.3031 train_accuracy: 0.9011	val_loss: 0.2721 val_accuracy: 0.9160	test_loss: 0.3055 test_accuracy: 0.8950
2025-08-23 09:41:07,163 - INFO - train: {'epoch': 30, 'time_epoch': 10.60141, 'eta': 734.55041, 'eta_hours': 0.20404, 'loss': 0.27893573, 'lr': 0.00044151, 'params': 193993, 'time_iter': 0.04841, 'accuracy': 0.91029, 'f1': 0.91025, 'auc': 0.98424}
2025-08-23 09:41:07,823 - INFO - val: {'epoch': 30, 'time_epoch': 0.64762, 'loss': 0.27830351, 'lr': 0, 'params': 193993, 'time_iter': 0.02024, 'accuracy': 0.916, 'f1': 0.91614, 'auc': 0.98439}
2025-08-23 09:41:09,122 - INFO - test: {'epoch': 30, 'time_epoch': 1.28851, 'loss': 0.27885143, 'lr': 0, 'params': 193993, 'time_iter': 0.02045, 'accuracy': 0.908, 'f1': 0.90809, 'auc': 0.98612}
2025-08-23 09:41:09,123 - INFO - > Epoch 30: took 12.6s (avg 12.6s) | Best so far: epoch 28	train_loss: 0.3031 train_accuracy: 0.9011	val_loss: 0.2721 val_accuracy: 0.9160	test_loss: 0.3055 test_accuracy: 0.8950
2025-08-23 09:41:19,751 - INFO - train: {'epoch': 31, 'time_epoch': 10.61135, 'eta': 723.83185, 'eta_hours': 0.20106, 'loss': 0.27426507, 'lr': 0.00043579, 'params': 193993, 'time_iter': 0.04845, 'accuracy': 0.90686, 'f1': 0.90718, 'auc': 0.98565}
2025-08-23 09:41:20,411 - INFO - val: {'epoch': 31, 'time_epoch': 0.64884, 'loss': 0.2874049, 'lr': 0, 'params': 193993, 'time_iter': 0.02028, 'accuracy': 0.906, 'f1': 0.90822, 'auc': 0.98426}
2025-08-23 09:41:21,715 - INFO - test: {'epoch': 31, 'time_epoch': 1.29336, 'loss': 0.31324312, 'lr': 0, 'params': 193993, 'time_iter': 0.02053, 'accuracy': 0.899, 'f1': 0.90182, 'auc': 0.98407}
2025-08-23 09:41:21,717 - INFO - > Epoch 31: took 12.6s (avg 12.6s) | Best so far: epoch 28	train_loss: 0.3031 train_accuracy: 0.9011	val_loss: 0.2721 val_accuracy: 0.9160	test_loss: 0.3055 test_accuracy: 0.8950
2025-08-23 09:41:32,395 - INFO - train: {'epoch': 32, 'time_epoch': 10.66174, 'eta': 713.2221, 'eta_hours': 0.19812, 'loss': 0.26163809, 'lr': 0.00042983, 'params': 193993, 'time_iter': 0.04868, 'accuracy': 0.91371, 'f1': 0.91376, 'auc': 0.9857}
2025-08-23 09:41:33,063 - INFO - val: {'epoch': 32, 'time_epoch': 0.65509, 'loss': 0.28577174, 'lr': 0, 'params': 193993, 'time_iter': 0.02047, 'accuracy': 0.906, 'f1': 0.90897, 'auc': 0.98784}
2025-08-23 09:41:34,380 - INFO - test: {'epoch': 32, 'time_epoch': 1.30409, 'loss': 0.3505218, 'lr': 0, 'params': 193993, 'time_iter': 0.0207, 'accuracy': 0.878, 'f1': 0.88224, 'auc': 0.98207}
2025-08-23 09:41:34,382 - INFO - > Epoch 32: took 12.7s (avg 12.6s) | Best so far: epoch 28	train_loss: 0.3031 train_accuracy: 0.9011	val_loss: 0.2721 val_accuracy: 0.9160	test_loss: 0.3055 test_accuracy: 0.8950
2025-08-23 09:41:45,054 - INFO - train: {'epoch': 33, 'time_epoch': 10.65508, 'eta': 702.59635, 'eta_hours': 0.19517, 'loss': 0.2655466, 'lr': 0.00042366, 'params': 193993, 'time_iter': 0.04865, 'accuracy': 0.91114, 'f1': 0.91173, 'auc': 0.98622}
2025-08-23 09:41:45,715 - INFO - val: {'epoch': 33, 'time_epoch': 0.64868, 'loss': 0.26468479, 'lr': 0, 'params': 193993, 'time_iter': 0.02027, 'accuracy': 0.916, 'f1': 0.91706, 'auc': 0.98759}
2025-08-23 09:41:47,026 - INFO - test: {'epoch': 33, 'time_epoch': 1.29944, 'loss': 0.27964816, 'lr': 0, 'params': 193993, 'time_iter': 0.02063, 'accuracy': 0.901, 'f1': 0.9028, 'auc': 0.98471}
2025-08-23 09:41:47,028 - INFO - > Epoch 33: took 12.6s (avg 12.6s) | Best so far: epoch 28	train_loss: 0.3031 train_accuracy: 0.9011	val_loss: 0.2721 val_accuracy: 0.9160	test_loss: 0.3055 test_accuracy: 0.8950
2025-08-23 09:41:57,720 - INFO - train: {'epoch': 34, 'time_epoch': 10.67486, 'eta': 692.00566, 'eta_hours': 0.19222, 'loss': 0.25925164, 'lr': 0.00041728, 'params': 193993, 'time_iter': 0.04874, 'accuracy': 0.91457, 'f1': 0.91492, 'auc': 0.98614}
2025-08-23 09:41:58,387 - INFO - val: {'epoch': 34, 'time_epoch': 0.65361, 'loss': 0.36544308, 'lr': 0, 'params': 193993, 'time_iter': 0.02043, 'accuracy': 0.876, 'f1': 0.87989, 'auc': 0.98514}
2025-08-23 09:41:59,709 - INFO - test: {'epoch': 34, 'time_epoch': 1.31057, 'loss': 0.38869518, 'lr': 0, 'params': 193993, 'time_iter': 0.0208, 'accuracy': 0.852, 'f1': 0.85849, 'auc': 0.98406}
2025-08-23 09:41:59,711 - INFO - > Epoch 34: took 12.7s (avg 12.6s) | Best so far: epoch 28	train_loss: 0.3031 train_accuracy: 0.9011	val_loss: 0.2721 val_accuracy: 0.9160	test_loss: 0.3055 test_accuracy: 0.8950
2025-08-23 09:42:10,397 - INFO - train: {'epoch': 35, 'time_epoch': 10.66943, 'eta': 681.40064, 'eta_hours': 0.18928, 'loss': 0.25567317, 'lr': 0.0004107, 'params': 193993, 'time_iter': 0.04872, 'accuracy': 0.91343, 'f1': 0.91364, 'auc': 0.98735}
2025-08-23 09:42:11,060 - INFO - val: {'epoch': 35, 'time_epoch': 0.65111, 'loss': 0.28913263, 'lr': 0, 'params': 193993, 'time_iter': 0.02035, 'accuracy': 0.904, 'f1': 0.90349, 'auc': 0.98513}
2025-08-23 09:42:12,374 - INFO - test: {'epoch': 35, 'time_epoch': 1.30165, 'loss': 0.2821264, 'lr': 0, 'params': 193993, 'time_iter': 0.02066, 'accuracy': 0.904, 'f1': 0.90417, 'auc': 0.98498}
2025-08-23 09:42:12,375 - INFO - > Epoch 35: took 12.7s (avg 12.6s) | Best so far: epoch 28	train_loss: 0.3031 train_accuracy: 0.9011	val_loss: 0.2721 val_accuracy: 0.9160	test_loss: 0.3055 test_accuracy: 0.8950
2025-08-23 09:42:23,067 - INFO - train: {'epoch': 36, 'time_epoch': 10.67595, 'eta': 670.80324, 'eta_hours': 0.18633, 'loss': 0.24732548, 'lr': 0.00040392, 'params': 193993, 'time_iter': 0.04875, 'accuracy': 0.92114, 'f1': 0.9213, 'auc': 0.98705}
2025-08-23 09:42:23,730 - INFO - val: {'epoch': 36, 'time_epoch': 0.65099, 'loss': 0.25102821, 'lr': 0, 'params': 193993, 'time_iter': 0.02034, 'accuracy': 0.918, 'f1': 0.91944, 'auc': 0.98812}
2025-08-23 09:42:25,048 - INFO - test: {'epoch': 36, 'time_epoch': 1.30681, 'loss': 0.26686707, 'lr': 0, 'params': 193993, 'time_iter': 0.02074, 'accuracy': 0.906, 'f1': 0.90848, 'auc': 0.9861}
2025-08-23 09:42:25,050 - INFO - > Epoch 36: took 12.7s (avg 12.7s) | Best so far: epoch 36	train_loss: 0.2473 train_accuracy: 0.9211	val_loss: 0.2510 val_accuracy: 0.9180	test_loss: 0.2669 test_accuracy: 0.9060
2025-08-23 09:42:35,703 - INFO - train: {'epoch': 37, 'time_epoch': 10.63667, 'eta': 660.13763, 'eta_hours': 0.18337, 'loss': 0.24371208, 'lr': 0.00039695, 'params': 193993, 'time_iter': 0.04857, 'accuracy': 0.92257, 'f1': 0.92288, 'auc': 0.98739}
2025-08-23 09:42:36,367 - INFO - val: {'epoch': 37, 'time_epoch': 0.65122, 'loss': 0.25844649, 'lr': 0, 'params': 193993, 'time_iter': 0.02035, 'accuracy': 0.916, 'f1': 0.91772, 'auc': 0.98691}
2025-08-23 09:42:37,675 - INFO - test: {'epoch': 37, 'time_epoch': 1.29834, 'loss': 0.30269427, 'lr': 0, 'params': 193993, 'time_iter': 0.02061, 'accuracy': 0.906, 'f1': 0.90807, 'auc': 0.98404}
2025-08-23 09:42:37,677 - INFO - > Epoch 37: took 12.6s (avg 12.6s) | Best so far: epoch 36	train_loss: 0.2473 train_accuracy: 0.9211	val_loss: 0.2510 val_accuracy: 0.9180	test_loss: 0.2669 test_accuracy: 0.9060
2025-08-23 09:42:48,293 - INFO - train: {'epoch': 38, 'time_epoch': 10.59991, 'eta': 649.41599, 'eta_hours': 0.18039, 'loss': 0.23780607, 'lr': 0.0003898, 'params': 193993, 'time_iter': 0.0484, 'accuracy': 0.92629, 'f1': 0.92653, 'auc': 0.98819}
2025-08-23 09:42:48,956 - INFO - val: {'epoch': 38, 'time_epoch': 0.65067, 'loss': 0.31916677, 'lr': 0, 'params': 193993, 'time_iter': 0.02033, 'accuracy': 0.898, 'f1': 0.89978, 'auc': 0.98549}
2025-08-23 09:42:50,267 - INFO - test: {'epoch': 38, 'time_epoch': 1.29923, 'loss': 0.33166122, 'lr': 0, 'params': 193993, 'time_iter': 0.02062, 'accuracy': 0.887, 'f1': 0.88982, 'auc': 0.98523}
2025-08-23 09:42:50,269 - INFO - > Epoch 38: took 12.6s (avg 12.6s) | Best so far: epoch 36	train_loss: 0.2473 train_accuracy: 0.9211	val_loss: 0.2510 val_accuracy: 0.9180	test_loss: 0.2669 test_accuracy: 0.9060
2025-08-23 09:43:00,944 - INFO - train: {'epoch': 39, 'time_epoch': 10.65934, 'eta': 638.78959, 'eta_hours': 0.17744, 'loss': 0.24000093, 'lr': 0.00038248, 'params': 193993, 'time_iter': 0.04867, 'accuracy': 0.92143, 'f1': 0.92168, 'auc': 0.98835}
2025-08-23 09:43:01,616 - INFO - val: {'epoch': 39, 'time_epoch': 0.65895, 'loss': 0.24798625, 'lr': 0, 'params': 193993, 'time_iter': 0.02059, 'accuracy': 0.92, 'f1': 0.92069, 'auc': 0.98763}
2025-08-23 09:43:02,942 - INFO - test: {'epoch': 39, 'time_epoch': 1.31236, 'loss': 0.25200072, 'lr': 0, 'params': 193993, 'time_iter': 0.02083, 'accuracy': 0.915, 'f1': 0.91609, 'auc': 0.98608}
2025-08-23 09:43:02,944 - INFO - > Epoch 39: took 12.7s (avg 12.6s) | Best so far: epoch 39	train_loss: 0.2400 train_accuracy: 0.9214	val_loss: 0.2480 val_accuracy: 0.9200	test_loss: 0.2520 test_accuracy: 0.9150
2025-08-23 09:43:13,634 - INFO - train: {'epoch': 40, 'time_epoch': 10.6733, 'eta': 628.18167, 'eta_hours': 0.17449, 'loss': 0.22575066, 'lr': 0.000375, 'params': 193993, 'time_iter': 0.04874, 'accuracy': 0.92686, 'f1': 0.92713, 'auc': 0.98901}
2025-08-23 09:43:14,297 - INFO - val: {'epoch': 40, 'time_epoch': 0.65042, 'loss': 0.26714439, 'lr': 0, 'params': 193993, 'time_iter': 0.02033, 'accuracy': 0.912, 'f1': 0.91327, 'auc': 0.98631}
2025-08-23 09:43:15,605 - INFO - test: {'epoch': 40, 'time_epoch': 1.29521, 'loss': 0.27399889, 'lr': 0, 'params': 193993, 'time_iter': 0.02056, 'accuracy': 0.909, 'f1': 0.9103, 'auc': 0.98535}
2025-08-23 09:43:15,608 - INFO - > Epoch 40: took 12.7s (avg 12.6s) | Best so far: epoch 39	train_loss: 0.2400 train_accuracy: 0.9214	val_loss: 0.2480 val_accuracy: 0.9200	test_loss: 0.2520 test_accuracy: 0.9150
2025-08-23 09:43:26,249 - INFO - train: {'epoch': 41, 'time_epoch': 10.62266, 'eta': 617.5007, 'eta_hours': 0.17153, 'loss': 0.22485816, 'lr': 0.00036737, 'params': 193993, 'time_iter': 0.04851, 'accuracy': 0.92914, 'f1': 0.9292, 'auc': 0.98896}
2025-08-23 09:43:26,898 - INFO - val: {'epoch': 41, 'time_epoch': 0.63704, 'loss': 0.26531761, 'lr': 0, 'params': 193993, 'time_iter': 0.01991, 'accuracy': 0.918, 'f1': 0.91827, 'auc': 0.98695}
2025-08-23 09:43:28,193 - INFO - test: {'epoch': 41, 'time_epoch': 1.2834, 'loss': 0.2619866, 'lr': 0, 'params': 193993, 'time_iter': 0.02037, 'accuracy': 0.913, 'f1': 0.91364, 'auc': 0.98654}
2025-08-23 09:43:28,195 - INFO - > Epoch 41: took 12.6s (avg 12.6s) | Best so far: epoch 39	train_loss: 0.2400 train_accuracy: 0.9214	val_loss: 0.2480 val_accuracy: 0.9200	test_loss: 0.2520 test_accuracy: 0.9150
2025-08-23 09:43:38,598 - INFO - train: {'epoch': 42, 'time_epoch': 10.38813, 'eta': 606.51157, 'eta_hours': 0.16848, 'loss': 0.22867639, 'lr': 0.00035959, 'params': 193993, 'time_iter': 0.04743, 'accuracy': 0.92743, 'f1': 0.9279, 'auc': 0.98882}
2025-08-23 09:43:39,245 - INFO - val: {'epoch': 42, 'time_epoch': 0.63684, 'loss': 0.3121016, 'lr': 0, 'params': 193993, 'time_iter': 0.0199, 'accuracy': 0.884, 'f1': 0.88516, 'auc': 0.98331}
2025-08-23 09:43:40,531 - INFO - test: {'epoch': 42, 'time_epoch': 1.27509, 'loss': 0.31410471, 'lr': 0, 'params': 193993, 'time_iter': 0.02024, 'accuracy': 0.882, 'f1': 0.88521, 'auc': 0.98346}
2025-08-23 09:43:40,533 - INFO - > Epoch 42: took 12.3s (avg 12.6s) | Best so far: epoch 39	train_loss: 0.2400 train_accuracy: 0.9214	val_loss: 0.2480 val_accuracy: 0.9200	test_loss: 0.2520 test_accuracy: 0.9150
2025-08-23 09:43:50,942 - INFO - train: {'epoch': 43, 'time_epoch': 10.39497, 'eta': 595.55846, 'eta_hours': 0.16543, 'loss': 0.22809385, 'lr': 0.00035168, 'params': 193993, 'time_iter': 0.04747, 'accuracy': 0.92629, 'f1': 0.92658, 'auc': 0.98865}
2025-08-23 09:43:51,603 - INFO - val: {'epoch': 43, 'time_epoch': 0.64917, 'loss': 0.235362, 'lr': 0, 'params': 193993, 'time_iter': 0.02029, 'accuracy': 0.93, 'f1': 0.93073, 'auc': 0.98833}
2025-08-23 09:43:52,899 - INFO - test: {'epoch': 43, 'time_epoch': 1.28533, 'loss': 0.2708806, 'lr': 0, 'params': 193993, 'time_iter': 0.0204, 'accuracy': 0.911, 'f1': 0.91211, 'auc': 0.98666}
2025-08-23 09:43:52,901 - INFO - > Epoch 43: took 12.4s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:44:03,312 - INFO - train: {'epoch': 44, 'time_epoch': 10.39755, 'eta': 584.63331, 'eta_hours': 0.1624, 'loss': 0.21590915, 'lr': 0.00034365, 'params': 193993, 'time_iter': 0.04748, 'accuracy': 0.93086, 'f1': 0.93108, 'auc': 0.98992}
2025-08-23 09:44:03,961 - INFO - val: {'epoch': 44, 'time_epoch': 0.63866, 'loss': 0.26010287, 'lr': 0, 'params': 193993, 'time_iter': 0.01996, 'accuracy': 0.918, 'f1': 0.91868, 'auc': 0.98731}
2025-08-23 09:44:05,272 - INFO - test: {'epoch': 44, 'time_epoch': 1.30059, 'loss': 0.26333787, 'lr': 0, 'params': 193993, 'time_iter': 0.02064, 'accuracy': 0.915, 'f1': 0.91628, 'auc': 0.98527}
2025-08-23 09:44:05,274 - INFO - > Epoch 44: took 12.4s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:44:15,665 - INFO - train: {'epoch': 45, 'time_epoch': 10.3768, 'eta': 573.70674, 'eta_hours': 0.15936, 'loss': 0.20934267, 'lr': 0.00033551, 'params': 193993, 'time_iter': 0.04738, 'accuracy': 0.93286, 'f1': 0.93281, 'auc': 0.9902}
2025-08-23 09:44:16,309 - INFO - val: {'epoch': 45, 'time_epoch': 0.63252, 'loss': 0.24148175, 'lr': 0, 'params': 193993, 'time_iter': 0.01977, 'accuracy': 0.922, 'f1': 0.92327, 'auc': 0.9887}
2025-08-23 09:44:17,598 - INFO - test: {'epoch': 45, 'time_epoch': 1.27886, 'loss': 0.2826481, 'lr': 0, 'params': 193993, 'time_iter': 0.0203, 'accuracy': 0.908, 'f1': 0.90971, 'auc': 0.98561}
2025-08-23 09:44:17,600 - INFO - > Epoch 45: took 12.3s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:44:27,964 - INFO - train: {'epoch': 46, 'time_epoch': 10.34971, 'eta': 562.77301, 'eta_hours': 0.15633, 'loss': 0.21464027, 'lr': 0.00032725, 'params': 193993, 'time_iter': 0.04726, 'accuracy': 0.93229, 'f1': 0.93231, 'auc': 0.9894}
2025-08-23 09:44:28,609 - INFO - val: {'epoch': 46, 'time_epoch': 0.63443, 'loss': 0.24864665, 'lr': 0, 'params': 193993, 'time_iter': 0.01983, 'accuracy': 0.922, 'f1': 0.92346, 'auc': 0.98748}
2025-08-23 09:44:29,902 - INFO - test: {'epoch': 46, 'time_epoch': 1.28239, 'loss': 0.26900383, 'lr': 0, 'params': 193993, 'time_iter': 0.02036, 'accuracy': 0.907, 'f1': 0.90851, 'auc': 0.98683}
2025-08-23 09:44:29,904 - INFO - > Epoch 46: took 12.3s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:44:40,261 - INFO - train: {'epoch': 47, 'time_epoch': 10.34313, 'eta': 551.85648, 'eta_hours': 0.15329, 'loss': 0.21049655, 'lr': 0.00031891, 'params': 193993, 'time_iter': 0.04723, 'accuracy': 0.932, 'f1': 0.93218, 'auc': 0.99041}
2025-08-23 09:44:40,906 - INFO - val: {'epoch': 47, 'time_epoch': 0.63484, 'loss': 0.25206165, 'lr': 0, 'params': 193993, 'time_iter': 0.01984, 'accuracy': 0.926, 'f1': 0.92649, 'auc': 0.98578}
2025-08-23 09:44:42,197 - INFO - test: {'epoch': 47, 'time_epoch': 1.28027, 'loss': 0.2491171, 'lr': 0, 'params': 193993, 'time_iter': 0.02032, 'accuracy': 0.925, 'f1': 0.92631, 'auc': 0.98749}
2025-08-23 09:44:42,198 - INFO - > Epoch 47: took 12.3s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:44:52,558 - INFO - train: {'epoch': 48, 'time_epoch': 10.34605, 'eta': 540.96641, 'eta_hours': 0.15027, 'loss': 0.19518456, 'lr': 0.00031048, 'params': 193993, 'time_iter': 0.04724, 'accuracy': 0.93771, 'f1': 0.93781, 'auc': 0.99086}
2025-08-23 09:44:53,201 - INFO - val: {'epoch': 48, 'time_epoch': 0.63212, 'loss': 0.24619399, 'lr': 0, 'params': 193993, 'time_iter': 0.01975, 'accuracy': 0.922, 'f1': 0.92245, 'auc': 0.98615}
2025-08-23 09:44:54,496 - INFO - test: {'epoch': 48, 'time_epoch': 1.28496, 'loss': 0.26839626, 'lr': 0, 'params': 193993, 'time_iter': 0.0204, 'accuracy': 0.916, 'f1': 0.9176, 'auc': 0.98612}
2025-08-23 09:44:54,498 - INFO - > Epoch 48: took 12.3s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:45:04,898 - INFO - train: {'epoch': 49, 'time_epoch': 10.38613, 'eta': 530.13816, 'eta_hours': 0.14726, 'loss': 0.20221829, 'lr': 0.00030198, 'params': 193993, 'time_iter': 0.04743, 'accuracy': 0.93457, 'f1': 0.93472, 'auc': 0.99177}
2025-08-23 09:45:05,545 - INFO - val: {'epoch': 49, 'time_epoch': 0.63712, 'loss': 0.27745239, 'lr': 0, 'params': 193993, 'time_iter': 0.01991, 'accuracy': 0.912, 'f1': 0.91291, 'auc': 0.98666}
2025-08-23 09:45:06,830 - INFO - test: {'epoch': 49, 'time_epoch': 1.27404, 'loss': 0.27855264, 'lr': 0, 'params': 193993, 'time_iter': 0.02022, 'accuracy': 0.911, 'f1': 0.91268, 'auc': 0.98528}
2025-08-23 09:45:06,831 - INFO - > Epoch 49: took 12.3s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:45:17,244 - INFO - train: {'epoch': 50, 'time_epoch': 10.39852, 'eta': 519.33916, 'eta_hours': 0.14426, 'loss': 0.18712549, 'lr': 0.00029341, 'params': 193993, 'time_iter': 0.04748, 'accuracy': 0.93943, 'f1': 0.93952, 'auc': 0.99141}
2025-08-23 09:45:17,887 - INFO - val: {'epoch': 50, 'time_epoch': 0.63154, 'loss': 0.39103734, 'lr': 0, 'params': 193993, 'time_iter': 0.01974, 'accuracy': 0.862, 'f1': 0.86005, 'auc': 0.97967}
2025-08-23 09:45:19,170 - INFO - test: {'epoch': 50, 'time_epoch': 1.27327, 'loss': 0.39232572, 'lr': 0, 'params': 193993, 'time_iter': 0.02021, 'accuracy': 0.86, 'f1': 0.86087, 'auc': 0.98091}
2025-08-23 09:45:19,172 - INFO - > Epoch 50: took 12.3s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:45:29,551 - INFO - train: {'epoch': 51, 'time_epoch': 10.36498, 'eta': 508.52461, 'eta_hours': 0.14126, 'loss': 0.20977068, 'lr': 0.00028479, 'params': 193993, 'time_iter': 0.04733, 'accuracy': 0.92943, 'f1': 0.92974, 'auc': 0.99063}
2025-08-23 09:45:30,199 - INFO - val: {'epoch': 51, 'time_epoch': 0.63822, 'loss': 0.25233269, 'lr': 0, 'params': 193993, 'time_iter': 0.01994, 'accuracy': 0.926, 'f1': 0.92661, 'auc': 0.98514}
2025-08-23 09:45:31,489 - INFO - test: {'epoch': 51, 'time_epoch': 1.27858, 'loss': 0.24684967, 'lr': 0, 'params': 193993, 'time_iter': 0.02029, 'accuracy': 0.921, 'f1': 0.92206, 'auc': 0.98774}
2025-08-23 09:45:31,491 - INFO - > Epoch 51: took 12.3s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:45:41,872 - INFO - train: {'epoch': 52, 'time_epoch': 10.36718, 'eta': 497.72897, 'eta_hours': 0.13826, 'loss': 0.19442324, 'lr': 0.00027613, 'params': 193993, 'time_iter': 0.04734, 'accuracy': 0.93829, 'f1': 0.93833, 'auc': 0.99146}
2025-08-23 09:45:42,526 - INFO - val: {'epoch': 52, 'time_epoch': 0.64259, 'loss': 0.25087005, 'lr': 0, 'params': 193993, 'time_iter': 0.02008, 'accuracy': 0.92, 'f1': 0.92042, 'auc': 0.9864}
2025-08-23 09:45:43,816 - INFO - test: {'epoch': 52, 'time_epoch': 1.28004, 'loss': 0.26536042, 'lr': 0, 'params': 193993, 'time_iter': 0.02032, 'accuracy': 0.913, 'f1': 0.91395, 'auc': 0.98665}
2025-08-23 09:45:43,817 - INFO - > Epoch 52: took 12.3s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:45:54,200 - INFO - train: {'epoch': 53, 'time_epoch': 10.36872, 'eta': 486.95051, 'eta_hours': 0.13526, 'loss': 0.18448625, 'lr': 0.00026744, 'params': 193993, 'time_iter': 0.04735, 'accuracy': 0.93771, 'f1': 0.93792, 'auc': 0.99249}
2025-08-23 09:45:54,854 - INFO - val: {'epoch': 53, 'time_epoch': 0.64257, 'loss': 0.25016769, 'lr': 0, 'params': 193993, 'time_iter': 0.02008, 'accuracy': 0.916, 'f1': 0.91643, 'auc': 0.98903}
2025-08-23 09:45:56,133 - INFO - test: {'epoch': 53, 'time_epoch': 1.26885, 'loss': 0.26411342, 'lr': 0, 'params': 193993, 'time_iter': 0.02014, 'accuracy': 0.917, 'f1': 0.91782, 'auc': 0.98635}
2025-08-23 09:45:56,135 - INFO - > Epoch 53: took 12.3s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:46:06,543 - INFO - train: {'epoch': 54, 'time_epoch': 10.39309, 'eta': 476.20689, 'eta_hours': 0.13228, 'loss': 0.19134962, 'lr': 0.00025872, 'params': 193993, 'time_iter': 0.04746, 'accuracy': 0.93857, 'f1': 0.93872, 'auc': 0.9919}
2025-08-23 09:46:07,197 - INFO - val: {'epoch': 54, 'time_epoch': 0.64388, 'loss': 0.27835163, 'lr': 0, 'params': 193993, 'time_iter': 0.02012, 'accuracy': 0.914, 'f1': 0.91358, 'auc': 0.98652}
2025-08-23 09:46:08,514 - INFO - test: {'epoch': 54, 'time_epoch': 1.30629, 'loss': 0.28277029, 'lr': 0, 'params': 193993, 'time_iter': 0.02073, 'accuracy': 0.908, 'f1': 0.90823, 'auc': 0.98494}
2025-08-23 09:46:08,515 - INFO - > Epoch 54: took 12.4s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:46:18,969 - INFO - train: {'epoch': 55, 'time_epoch': 10.43839, 'eta': 465.51139, 'eta_hours': 0.12931, 'loss': 0.17908621, 'lr': 0.00025, 'params': 193993, 'time_iter': 0.04766, 'accuracy': 0.93857, 'f1': 0.93876, 'auc': 0.99246}
2025-08-23 09:46:19,639 - INFO - val: {'epoch': 55, 'time_epoch': 0.65837, 'loss': 0.28442634, 'lr': 0, 'params': 193993, 'time_iter': 0.02057, 'accuracy': 0.914, 'f1': 0.91502, 'auc': 0.98321}
2025-08-23 09:46:20,943 - INFO - test: {'epoch': 55, 'time_epoch': 1.29279, 'loss': 0.29618549, 'lr': 0, 'params': 193993, 'time_iter': 0.02052, 'accuracy': 0.908, 'f1': 0.91029, 'auc': 0.98461}
2025-08-23 09:46:20,944 - INFO - > Epoch 55: took 12.4s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:46:31,411 - INFO - train: {'epoch': 56, 'time_epoch': 10.45251, 'eta': 454.83556, 'eta_hours': 0.12634, 'loss': 0.17739085, 'lr': 0.00024128, 'params': 193993, 'time_iter': 0.04773, 'accuracy': 0.94171, 'f1': 0.94181, 'auc': 0.9928}
2025-08-23 09:46:32,061 - INFO - val: {'epoch': 56, 'time_epoch': 0.63971, 'loss': 0.28166998, 'lr': 0, 'params': 193993, 'time_iter': 0.01999, 'accuracy': 0.91, 'f1': 0.91046, 'auc': 0.98519}
2025-08-23 09:46:33,357 - INFO - test: {'epoch': 56, 'time_epoch': 1.28526, 'loss': 0.30444406, 'lr': 0, 'params': 193993, 'time_iter': 0.0204, 'accuracy': 0.899, 'f1': 0.89978, 'auc': 0.98511}
2025-08-23 09:46:33,359 - INFO - > Epoch 56: took 12.4s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:46:43,789 - INFO - train: {'epoch': 57, 'time_epoch': 10.41655, 'eta': 444.14138, 'eta_hours': 0.12337, 'loss': 0.17732999, 'lr': 0.00023256, 'params': 193993, 'time_iter': 0.04756, 'accuracy': 0.94429, 'f1': 0.94445, 'auc': 0.99252}
2025-08-23 09:46:44,439 - INFO - val: {'epoch': 57, 'time_epoch': 0.63909, 'loss': 0.24762115, 'lr': 0, 'params': 193993, 'time_iter': 0.01997, 'accuracy': 0.922, 'f1': 0.92168, 'auc': 0.98718}
2025-08-23 09:46:45,737 - INFO - test: {'epoch': 57, 'time_epoch': 1.28664, 'loss': 0.24454381, 'lr': 0, 'params': 193993, 'time_iter': 0.02042, 'accuracy': 0.924, 'f1': 0.92428, 'auc': 0.98766}
2025-08-23 09:46:45,738 - INFO - > Epoch 57: took 12.4s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:46:56,181 - INFO - train: {'epoch': 58, 'time_epoch': 10.4286, 'eta': 433.46499, 'eta_hours': 0.12041, 'loss': 0.18543623, 'lr': 0.00022387, 'params': 193993, 'time_iter': 0.04762, 'accuracy': 0.93429, 'f1': 0.93441, 'auc': 0.993}
2025-08-23 09:46:56,828 - INFO - val: {'epoch': 58, 'time_epoch': 0.6358, 'loss': 0.3205227, 'lr': 0, 'params': 193993, 'time_iter': 0.01987, 'accuracy': 0.892, 'f1': 0.89211, 'auc': 0.98435}
2025-08-23 09:46:58,118 - INFO - test: {'epoch': 58, 'time_epoch': 1.27947, 'loss': 0.29431151, 'lr': 0, 'params': 193993, 'time_iter': 0.02031, 'accuracy': 0.903, 'f1': 0.90441, 'auc': 0.98459}
2025-08-23 09:46:58,120 - INFO - > Epoch 58: took 12.4s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:47:08,400 - INFO - train: {'epoch': 59, 'time_epoch': 10.2665, 'eta': 422.6888, 'eta_hours': 0.11741, 'loss': 0.17828264, 'lr': 0.00021521, 'params': 193993, 'time_iter': 0.04688, 'accuracy': 0.94086, 'f1': 0.94102, 'auc': 0.9929}
2025-08-23 09:47:09,038 - INFO - val: {'epoch': 59, 'time_epoch': 0.62738, 'loss': 0.27715585, 'lr': 0, 'params': 193993, 'time_iter': 0.01961, 'accuracy': 0.908, 'f1': 0.91027, 'auc': 0.98765}
2025-08-23 09:47:10,320 - INFO - test: {'epoch': 59, 'time_epoch': 1.27151, 'loss': 0.33215268, 'lr': 0, 'params': 193993, 'time_iter': 0.02018, 'accuracy': 0.888, 'f1': 0.89116, 'auc': 0.98147}
2025-08-23 09:47:10,321 - INFO - > Epoch 59: took 12.2s (avg 12.6s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:47:20,552 - INFO - train: {'epoch': 60, 'time_epoch': 10.21791, 'eta': 411.89825, 'eta_hours': 0.11442, 'loss': 0.17271589, 'lr': 0.00020659, 'params': 193993, 'time_iter': 0.04666, 'accuracy': 0.942, 'f1': 0.94236, 'auc': 0.99264}
2025-08-23 09:47:21,190 - INFO - val: {'epoch': 60, 'time_epoch': 0.62778, 'loss': 0.26890453, 'lr': 0, 'params': 193993, 'time_iter': 0.01962, 'accuracy': 0.92, 'f1': 0.92026, 'auc': 0.98798}
2025-08-23 09:47:22,472 - INFO - test: {'epoch': 60, 'time_epoch': 1.27156, 'loss': 0.27424938, 'lr': 0, 'params': 193993, 'time_iter': 0.02018, 'accuracy': 0.912, 'f1': 0.91294, 'auc': 0.98605}
2025-08-23 09:47:22,473 - INFO - > Epoch 60: took 12.2s (avg 12.5s) | Best so far: epoch 43	train_loss: 0.2281 train_accuracy: 0.9263	val_loss: 0.2354 val_accuracy: 0.9300	test_loss: 0.2709 test_accuracy: 0.9110
2025-08-23 09:47:32,712 - INFO - train: {'epoch': 61, 'time_epoch': 10.22531, 'eta': 401.13071, 'eta_hours': 0.11143, 'loss': 0.16538303, 'lr': 0.00019802, 'params': 193993, 'time_iter': 0.04669, 'accuracy': 0.94171, 'f1': 0.94179, 'auc': 0.99333}
2025-08-23 09:47:33,348 - INFO - val: {'epoch': 61, 'time_epoch': 0.62547, 'loss': 0.21203257, 'lr': 0, 'params': 193993, 'time_iter': 0.01955, 'accuracy': 0.934, 'f1': 0.93399, 'auc': 0.98959}
2025-08-23 09:47:34,627 - INFO - test: {'epoch': 61, 'time_epoch': 1.26894, 'loss': 0.25070658, 'lr': 0, 'params': 193993, 'time_iter': 0.02014, 'accuracy': 0.923, 'f1': 0.92385, 'auc': 0.98778}
2025-08-23 09:47:34,629 - INFO - > Epoch 61: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:47:44,841 - INFO - train: {'epoch': 62, 'time_epoch': 10.19963, 'eta': 390.3653, 'eta_hours': 0.10843, 'loss': 0.15245987, 'lr': 0.00018952, 'params': 193993, 'time_iter': 0.04657, 'accuracy': 0.95286, 'f1': 0.9529, 'auc': 0.99437}
2025-08-23 09:47:45,479 - INFO - val: {'epoch': 62, 'time_epoch': 0.6268, 'loss': 0.28665602, 'lr': 0, 'params': 193993, 'time_iter': 0.01959, 'accuracy': 0.912, 'f1': 0.9129, 'auc': 0.98708}
2025-08-23 09:47:46,755 - INFO - test: {'epoch': 62, 'time_epoch': 1.26655, 'loss': 0.28525694, 'lr': 0, 'params': 193993, 'time_iter': 0.0201, 'accuracy': 0.907, 'f1': 0.90935, 'auc': 0.9857}
2025-08-23 09:47:46,757 - INFO - > Epoch 62: took 12.1s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:47:57,075 - INFO - train: {'epoch': 63, 'time_epoch': 10.30582, 'eta': 379.67731, 'eta_hours': 0.10547, 'loss': 0.14818231, 'lr': 0.00018109, 'params': 193993, 'time_iter': 0.04706, 'accuracy': 0.95286, 'f1': 0.95289, 'auc': 0.99462}
2025-08-23 09:47:57,716 - INFO - val: {'epoch': 63, 'time_epoch': 0.63006, 'loss': 0.22550406, 'lr': 0, 'params': 193993, 'time_iter': 0.01969, 'accuracy': 0.924, 'f1': 0.92391, 'auc': 0.98938}
2025-08-23 09:47:58,992 - INFO - test: {'epoch': 63, 'time_epoch': 1.26568, 'loss': 0.24162909, 'lr': 0, 'params': 193993, 'time_iter': 0.02009, 'accuracy': 0.925, 'f1': 0.92579, 'auc': 0.9877}
2025-08-23 09:47:58,994 - INFO - > Epoch 63: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:48:09,331 - INFO - train: {'epoch': 64, 'time_epoch': 10.32436, 'eta': 369.01105, 'eta_hours': 0.1025, 'loss': 0.15802278, 'lr': 0.00017275, 'params': 193993, 'time_iter': 0.04714, 'accuracy': 0.94771, 'f1': 0.9479, 'auc': 0.99356}
2025-08-23 09:48:09,972 - INFO - val: {'epoch': 64, 'time_epoch': 0.62986, 'loss': 0.25242747, 'lr': 0, 'params': 193993, 'time_iter': 0.01968, 'accuracy': 0.922, 'f1': 0.92278, 'auc': 0.98755}
2025-08-23 09:48:11,259 - INFO - test: {'epoch': 64, 'time_epoch': 1.27755, 'loss': 0.26852664, 'lr': 0, 'params': 193993, 'time_iter': 0.02028, 'accuracy': 0.918, 'f1': 0.91967, 'auc': 0.98666}
2025-08-23 09:48:11,261 - INFO - > Epoch 64: took 12.3s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:48:21,586 - INFO - train: {'epoch': 65, 'time_epoch': 10.31192, 'eta': 358.34875, 'eta_hours': 0.09954, 'loss': 0.15915167, 'lr': 0.00016449, 'params': 193993, 'time_iter': 0.04709, 'accuracy': 0.948, 'f1': 0.94814, 'auc': 0.99406}
2025-08-23 09:48:22,226 - INFO - val: {'epoch': 65, 'time_epoch': 0.62869, 'loss': 0.22234591, 'lr': 0, 'params': 193993, 'time_iter': 0.01965, 'accuracy': 0.928, 'f1': 0.92857, 'auc': 0.98733}
2025-08-23 09:48:23,513 - INFO - test: {'epoch': 65, 'time_epoch': 1.27745, 'loss': 0.25471187, 'lr': 0, 'params': 193993, 'time_iter': 0.02028, 'accuracy': 0.919, 'f1': 0.92056, 'auc': 0.987}
2025-08-23 09:48:23,515 - INFO - > Epoch 65: took 12.3s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:48:33,822 - INFO - train: {'epoch': 66, 'time_epoch': 10.29471, 'eta': 347.68842, 'eta_hours': 0.09658, 'loss': 0.1534839, 'lr': 0.00015635, 'params': 193993, 'time_iter': 0.04701, 'accuracy': 0.95057, 'f1': 0.95056, 'auc': 0.99419}
2025-08-23 09:48:34,460 - INFO - val: {'epoch': 66, 'time_epoch': 0.62833, 'loss': 0.22605236, 'lr': 0, 'params': 193993, 'time_iter': 0.01964, 'accuracy': 0.934, 'f1': 0.93444, 'auc': 0.98738}
2025-08-23 09:48:35,748 - INFO - test: {'epoch': 66, 'time_epoch': 1.27767, 'loss': 0.26159283, 'lr': 0, 'params': 193993, 'time_iter': 0.02028, 'accuracy': 0.914, 'f1': 0.9153, 'auc': 0.98679}
2025-08-23 09:48:35,750 - INFO - > Epoch 66: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:48:46,066 - INFO - train: {'epoch': 67, 'time_epoch': 10.30244, 'eta': 337.0425, 'eta_hours': 0.09362, 'loss': 0.14717231, 'lr': 0.00014832, 'params': 193993, 'time_iter': 0.04704, 'accuracy': 0.95343, 'f1': 0.95359, 'auc': 0.99471}
2025-08-23 09:48:46,709 - INFO - val: {'epoch': 67, 'time_epoch': 0.63246, 'loss': 0.25943985, 'lr': 0, 'params': 193993, 'time_iter': 0.01976, 'accuracy': 0.914, 'f1': 0.9145, 'auc': 0.98852}
2025-08-23 09:48:47,996 - INFO - test: {'epoch': 67, 'time_epoch': 1.27598, 'loss': 0.27066648, 'lr': 0, 'params': 193993, 'time_iter': 0.02025, 'accuracy': 0.923, 'f1': 0.92442, 'auc': 0.98552}
2025-08-23 09:48:47,999 - INFO - > Epoch 67: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:48:58,385 - INFO - train: {'epoch': 68, 'time_epoch': 10.37175, 'eta': 326.43766, 'eta_hours': 0.09068, 'loss': 0.14338476, 'lr': 0.00014041, 'params': 193993, 'time_iter': 0.04736, 'accuracy': 0.95429, 'f1': 0.9544, 'auc': 0.99481}
2025-08-23 09:48:59,033 - INFO - val: {'epoch': 68, 'time_epoch': 0.63684, 'loss': 0.27098827, 'lr': 0, 'params': 193993, 'time_iter': 0.0199, 'accuracy': 0.922, 'f1': 0.92304, 'auc': 0.98603}
2025-08-23 09:49:00,326 - INFO - test: {'epoch': 68, 'time_epoch': 1.28103, 'loss': 0.26919783, 'lr': 0, 'params': 193993, 'time_iter': 0.02033, 'accuracy': 0.921, 'f1': 0.92282, 'auc': 0.98554}
2025-08-23 09:49:00,328 - INFO - > Epoch 68: took 12.3s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:49:10,686 - INFO - train: {'epoch': 69, 'time_epoch': 10.34352, 'eta': 315.82739, 'eta_hours': 0.08773, 'loss': 0.14259783, 'lr': 0.00013263, 'params': 193993, 'time_iter': 0.04723, 'accuracy': 0.95543, 'f1': 0.95553, 'auc': 0.99484}
2025-08-23 09:49:11,328 - INFO - val: {'epoch': 69, 'time_epoch': 0.63169, 'loss': 0.2418246, 'lr': 0, 'params': 193993, 'time_iter': 0.01974, 'accuracy': 0.932, 'f1': 0.93227, 'auc': 0.9873}
2025-08-23 09:49:12,620 - INFO - test: {'epoch': 69, 'time_epoch': 1.28117, 'loss': 0.23780806, 'lr': 0, 'params': 193993, 'time_iter': 0.02034, 'accuracy': 0.924, 'f1': 0.92505, 'auc': 0.98747}
2025-08-23 09:49:12,621 - INFO - > Epoch 69: took 12.3s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:49:22,982 - INFO - train: {'epoch': 70, 'time_epoch': 10.34665, 'eta': 305.22591, 'eta_hours': 0.08478, 'loss': 0.13162812, 'lr': 0.000125, 'params': 193993, 'time_iter': 0.04724, 'accuracy': 0.95857, 'f1': 0.95869, 'auc': 0.99536}
2025-08-23 09:49:23,624 - INFO - val: {'epoch': 70, 'time_epoch': 0.63148, 'loss': 0.22947723, 'lr': 0, 'params': 193993, 'time_iter': 0.01973, 'accuracy': 0.934, 'f1': 0.93394, 'auc': 0.9886}
2025-08-23 09:49:24,906 - INFO - test: {'epoch': 70, 'time_epoch': 1.27144, 'loss': 0.23044787, 'lr': 0, 'params': 193993, 'time_iter': 0.02018, 'accuracy': 0.927, 'f1': 0.92753, 'auc': 0.98882}
2025-08-23 09:49:24,908 - INFO - > Epoch 70: took 12.3s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:49:35,261 - INFO - train: {'epoch': 71, 'time_epoch': 10.33881, 'eta': 294.62846, 'eta_hours': 0.08184, 'loss': 0.13319095, 'lr': 0.00011752, 'params': 193993, 'time_iter': 0.04721, 'accuracy': 0.95914, 'f1': 0.95915, 'auc': 0.99531}
2025-08-23 09:49:35,904 - INFO - val: {'epoch': 71, 'time_epoch': 0.63174, 'loss': 0.28104769, 'lr': 0, 'params': 193993, 'time_iter': 0.01974, 'accuracy': 0.92, 'f1': 0.92069, 'auc': 0.98659}
2025-08-23 09:49:37,181 - INFO - test: {'epoch': 71, 'time_epoch': 1.26749, 'loss': 0.26370728, 'lr': 0, 'params': 193993, 'time_iter': 0.02012, 'accuracy': 0.925, 'f1': 0.92631, 'auc': 0.98587}
2025-08-23 09:49:37,183 - INFO - > Epoch 71: took 12.3s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:49:47,497 - INFO - train: {'epoch': 72, 'time_epoch': 10.30028, 'eta': 284.02384, 'eta_hours': 0.0789, 'loss': 0.13391913, 'lr': 0.0001102, 'params': 193993, 'time_iter': 0.04703, 'accuracy': 0.95743, 'f1': 0.95749, 'auc': 0.99535}
2025-08-23 09:49:48,138 - INFO - val: {'epoch': 72, 'time_epoch': 0.63042, 'loss': 0.23941097, 'lr': 0, 'params': 193993, 'time_iter': 0.0197, 'accuracy': 0.922, 'f1': 0.92243, 'auc': 0.98887}
2025-08-23 09:49:49,422 - INFO - test: {'epoch': 72, 'time_epoch': 1.27232, 'loss': 0.23933198, 'lr': 0, 'params': 193993, 'time_iter': 0.0202, 'accuracy': 0.927, 'f1': 0.92816, 'auc': 0.98711}
2025-08-23 09:49:49,424 - INFO - > Epoch 72: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:49:59,740 - INFO - train: {'epoch': 73, 'time_epoch': 10.30177, 'eta': 273.42797, 'eta_hours': 0.07595, 'loss': 0.13420822, 'lr': 0.00010305, 'params': 193993, 'time_iter': 0.04704, 'accuracy': 0.95629, 'f1': 0.95634, 'auc': 0.99527}
2025-08-23 09:50:00,382 - INFO - val: {'epoch': 73, 'time_epoch': 0.63139, 'loss': 0.27174104, 'lr': 0, 'params': 193993, 'time_iter': 0.01973, 'accuracy': 0.922, 'f1': 0.92281, 'auc': 0.98723}
2025-08-23 09:50:01,667 - INFO - test: {'epoch': 73, 'time_epoch': 1.27298, 'loss': 0.2666984, 'lr': 0, 'params': 193993, 'time_iter': 0.02021, 'accuracy': 0.925, 'f1': 0.92621, 'auc': 0.98611}
2025-08-23 09:50:01,669 - INFO - > Epoch 73: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:50:12,031 - INFO - train: {'epoch': 74, 'time_epoch': 10.34656, 'eta': 262.85488, 'eta_hours': 0.07302, 'loss': 0.13675996, 'lr': 9.608e-05, 'params': 193993, 'time_iter': 0.04724, 'accuracy': 0.956, 'f1': 0.95596, 'auc': 0.99501}
2025-08-23 09:50:12,680 - INFO - val: {'epoch': 74, 'time_epoch': 0.63923, 'loss': 0.24592132, 'lr': 0, 'params': 193993, 'time_iter': 0.01998, 'accuracy': 0.934, 'f1': 0.93455, 'auc': 0.98765}
2025-08-23 09:50:13,966 - INFO - test: {'epoch': 74, 'time_epoch': 1.27603, 'loss': 0.23020995, 'lr': 0, 'params': 193993, 'time_iter': 0.02025, 'accuracy': 0.935, 'f1': 0.93584, 'auc': 0.98835}
2025-08-23 09:50:13,968 - INFO - > Epoch 74: took 12.3s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:50:24,284 - INFO - train: {'epoch': 75, 'time_epoch': 10.30135, 'eta': 252.27347, 'eta_hours': 0.07008, 'loss': 0.13593421, 'lr': 8.93e-05, 'params': 193993, 'time_iter': 0.04704, 'accuracy': 0.95629, 'f1': 0.9563, 'auc': 0.99523}
2025-08-23 09:50:24,927 - INFO - val: {'epoch': 75, 'time_epoch': 0.63249, 'loss': 0.27559068, 'lr': 0, 'params': 193993, 'time_iter': 0.01977, 'accuracy': 0.916, 'f1': 0.91582, 'auc': 0.98599}
2025-08-23 09:50:26,217 - INFO - test: {'epoch': 75, 'time_epoch': 1.27961, 'loss': 0.23905493, 'lr': 0, 'params': 193993, 'time_iter': 0.02031, 'accuracy': 0.926, 'f1': 0.92661, 'auc': 0.98758}
2025-08-23 09:50:26,218 - INFO - > Epoch 75: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:50:36,529 - INFO - train: {'epoch': 76, 'time_epoch': 10.29688, 'eta': 241.698, 'eta_hours': 0.06714, 'loss': 0.12981723, 'lr': 8.272e-05, 'params': 193993, 'time_iter': 0.04702, 'accuracy': 0.95686, 'f1': 0.95686, 'auc': 0.99542}
2025-08-23 09:50:37,175 - INFO - val: {'epoch': 76, 'time_epoch': 0.63511, 'loss': 0.25153338, 'lr': 0, 'params': 193993, 'time_iter': 0.01985, 'accuracy': 0.926, 'f1': 0.92594, 'auc': 0.98789}
2025-08-23 09:50:38,451 - INFO - test: {'epoch': 76, 'time_epoch': 1.26662, 'loss': 0.24033175, 'lr': 0, 'params': 193993, 'time_iter': 0.02011, 'accuracy': 0.926, 'f1': 0.92644, 'auc': 0.988}
2025-08-23 09:50:38,453 - INFO - > Epoch 76: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:50:48,774 - INFO - train: {'epoch': 77, 'time_epoch': 10.30717, 'eta': 231.13258, 'eta_hours': 0.0642, 'loss': 0.12928604, 'lr': 7.634e-05, 'params': 193993, 'time_iter': 0.04706, 'accuracy': 0.95943, 'f1': 0.95942, 'auc': 0.99575}
2025-08-23 09:50:49,410 - INFO - val: {'epoch': 77, 'time_epoch': 0.62592, 'loss': 0.27911722, 'lr': 0, 'params': 193993, 'time_iter': 0.01956, 'accuracy': 0.914, 'f1': 0.9148, 'auc': 0.98691}
2025-08-23 09:50:50,686 - INFO - test: {'epoch': 77, 'time_epoch': 1.26604, 'loss': 0.25896425, 'lr': 0, 'params': 193993, 'time_iter': 0.0201, 'accuracy': 0.913, 'f1': 0.91449, 'auc': 0.98653}
2025-08-23 09:50:50,688 - INFO - > Epoch 77: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:51:00,981 - INFO - train: {'epoch': 78, 'time_epoch': 10.27807, 'eta': 220.56596, 'eta_hours': 0.06127, 'loss': 0.12775811, 'lr': 7.017e-05, 'params': 193993, 'time_iter': 0.04693, 'accuracy': 0.96057, 'f1': 0.96069, 'auc': 0.99592}
2025-08-23 09:51:01,623 - INFO - val: {'epoch': 78, 'time_epoch': 0.63175, 'loss': 0.29128643, 'lr': 0, 'params': 193993, 'time_iter': 0.01974, 'accuracy': 0.916, 'f1': 0.91644, 'auc': 0.98678}
2025-08-23 09:51:02,895 - INFO - test: {'epoch': 78, 'time_epoch': 1.26152, 'loss': 0.26258301, 'lr': 0, 'params': 193993, 'time_iter': 0.02002, 'accuracy': 0.923, 'f1': 0.92395, 'auc': 0.98652}
2025-08-23 09:51:02,897 - INFO - > Epoch 78: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:51:13,185 - INFO - train: {'epoch': 79, 'time_epoch': 10.27519, 'eta': 210.00583, 'eta_hours': 0.05833, 'loss': 0.13096261, 'lr': 6.421e-05, 'params': 193993, 'time_iter': 0.04692, 'accuracy': 0.95886, 'f1': 0.95884, 'auc': 0.99556}
2025-08-23 09:51:13,822 - INFO - val: {'epoch': 79, 'time_epoch': 0.62631, 'loss': 0.2836225, 'lr': 0, 'params': 193993, 'time_iter': 0.01957, 'accuracy': 0.916, 'f1': 0.91669, 'auc': 0.98725}
2025-08-23 09:51:15,097 - INFO - test: {'epoch': 79, 'time_epoch': 1.26442, 'loss': 0.2705326, 'lr': 0, 'params': 193993, 'time_iter': 0.02007, 'accuracy': 0.921, 'f1': 0.92243, 'auc': 0.98552}
2025-08-23 09:51:15,098 - INFO - > Epoch 79: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:51:25,696 - INFO - train: {'epoch': 80, 'time_epoch': 10.5822, 'eta': 199.52475, 'eta_hours': 0.05542, 'loss': 0.12304409, 'lr': 5.849e-05, 'params': 193993, 'time_iter': 0.04832, 'accuracy': 0.96229, 'f1': 0.96238, 'auc': 0.99576}
2025-08-23 09:51:26,348 - INFO - val: {'epoch': 80, 'time_epoch': 0.64107, 'loss': 0.27135088, 'lr': 0, 'params': 193993, 'time_iter': 0.02003, 'accuracy': 0.924, 'f1': 0.92463, 'auc': 0.98654}
2025-08-23 09:51:27,650 - INFO - test: {'epoch': 80, 'time_epoch': 1.29051, 'loss': 0.25578774, 'lr': 0, 'params': 193993, 'time_iter': 0.02048, 'accuracy': 0.925, 'f1': 0.92635, 'auc': 0.98647}
2025-08-23 09:51:27,652 - INFO - > Epoch 80: took 12.6s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:51:38,007 - INFO - train: {'epoch': 81, 'time_epoch': 10.34037, 'eta': 188.98812, 'eta_hours': 0.0525, 'loss': 0.12512321, 'lr': 5.3e-05, 'params': 193993, 'time_iter': 0.04722, 'accuracy': 0.95657, 'f1': 0.95659, 'auc': 0.99593}
2025-08-23 09:51:38,651 - INFO - val: {'epoch': 81, 'time_epoch': 0.63325, 'loss': 0.27343355, 'lr': 0, 'params': 193993, 'time_iter': 0.01979, 'accuracy': 0.922, 'f1': 0.92231, 'auc': 0.98764}
2025-08-23 09:51:39,929 - INFO - test: {'epoch': 81, 'time_epoch': 1.26668, 'loss': 0.25968348, 'lr': 0, 'params': 193993, 'time_iter': 0.02011, 'accuracy': 0.925, 'f1': 0.92586, 'auc': 0.98662}
2025-08-23 09:51:39,931 - INFO - > Epoch 81: took 12.3s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:51:50,276 - INFO - train: {'epoch': 82, 'time_epoch': 10.33005, 'eta': 178.45411, 'eta_hours': 0.04957, 'loss': 0.11276953, 'lr': 4.775e-05, 'params': 193993, 'time_iter': 0.04717, 'accuracy': 0.96543, 'f1': 0.96545, 'auc': 0.99646}
2025-08-23 09:51:50,916 - INFO - val: {'epoch': 82, 'time_epoch': 0.63016, 'loss': 0.25067006, 'lr': 0, 'params': 193993, 'time_iter': 0.01969, 'accuracy': 0.922, 'f1': 0.92216, 'auc': 0.98811}
2025-08-23 09:51:52,193 - INFO - test: {'epoch': 82, 'time_epoch': 1.26519, 'loss': 0.24438703, 'lr': 0, 'params': 193993, 'time_iter': 0.02008, 'accuracy': 0.927, 'f1': 0.92805, 'auc': 0.988}
2025-08-23 09:51:52,194 - INFO - > Epoch 82: took 12.3s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:52:02,531 - INFO - train: {'epoch': 83, 'time_epoch': 10.32185, 'eta': 167.92339, 'eta_hours': 0.04665, 'loss': 0.12243893, 'lr': 4.274e-05, 'params': 193993, 'time_iter': 0.04713, 'accuracy': 0.96171, 'f1': 0.96167, 'auc': 0.99606}
2025-08-23 09:52:03,172 - INFO - val: {'epoch': 83, 'time_epoch': 0.63049, 'loss': 0.25881736, 'lr': 0, 'params': 193993, 'time_iter': 0.0197, 'accuracy': 0.92, 'f1': 0.92042, 'auc': 0.98831}
2025-08-23 09:52:04,445 - INFO - test: {'epoch': 83, 'time_epoch': 1.26246, 'loss': 0.2502348, 'lr': 0, 'params': 193993, 'time_iter': 0.02004, 'accuracy': 0.926, 'f1': 0.92688, 'auc': 0.98757}
2025-08-23 09:52:04,447 - INFO - > Epoch 83: took 12.3s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:52:14,733 - INFO - train: {'epoch': 84, 'time_epoch': 10.27264, 'eta': 157.3889, 'eta_hours': 0.04372, 'loss': 0.11836194, 'lr': 3.799e-05, 'params': 193993, 'time_iter': 0.04691, 'accuracy': 0.96171, 'f1': 0.9617, 'auc': 0.99596}
2025-08-23 09:52:15,374 - INFO - val: {'epoch': 84, 'time_epoch': 0.63142, 'loss': 0.27793112, 'lr': 0, 'params': 193993, 'time_iter': 0.01973, 'accuracy': 0.92, 'f1': 0.9204, 'auc': 0.98749}
2025-08-23 09:52:16,642 - INFO - test: {'epoch': 84, 'time_epoch': 1.25693, 'loss': 0.266349, 'lr': 0, 'params': 193993, 'time_iter': 0.01995, 'accuracy': 0.92, 'f1': 0.92124, 'auc': 0.98613}
2025-08-23 09:52:16,644 - INFO - > Epoch 84: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:52:26,903 - INFO - train: {'epoch': 85, 'time_epoch': 10.2471, 'eta': 146.85634, 'eta_hours': 0.04079, 'loss': 0.12197328, 'lr': 3.349e-05, 'params': 193993, 'time_iter': 0.04679, 'accuracy': 0.96257, 'f1': 0.96256, 'auc': 0.99623}
2025-08-23 09:52:27,543 - INFO - val: {'epoch': 85, 'time_epoch': 0.63028, 'loss': 0.26536178, 'lr': 0, 'params': 193993, 'time_iter': 0.0197, 'accuracy': 0.92, 'f1': 0.92041, 'auc': 0.98744}
2025-08-23 09:52:28,812 - INFO - test: {'epoch': 85, 'time_epoch': 1.25851, 'loss': 0.26289978, 'lr': 0, 'params': 193993, 'time_iter': 0.01998, 'accuracy': 0.917, 'f1': 0.9182, 'auc': 0.98623}
2025-08-23 09:52:28,814 - INFO - > Epoch 85: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:52:39,087 - INFO - train: {'epoch': 86, 'time_epoch': 10.26011, 'eta': 136.33229, 'eta_hours': 0.03787, 'loss': 0.12192002, 'lr': 2.926e-05, 'params': 193993, 'time_iter': 0.04685, 'accuracy': 0.95971, 'f1': 0.95969, 'auc': 0.99613}
2025-08-23 09:52:39,727 - INFO - val: {'epoch': 86, 'time_epoch': 0.62996, 'loss': 0.25478841, 'lr': 0, 'params': 193993, 'time_iter': 0.01969, 'accuracy': 0.92, 'f1': 0.92044, 'auc': 0.98812}
2025-08-23 09:52:40,994 - INFO - test: {'epoch': 86, 'time_epoch': 1.25655, 'loss': 0.24799082, 'lr': 0, 'params': 193993, 'time_iter': 0.01995, 'accuracy': 0.93, 'f1': 0.93085, 'auc': 0.98722}
2025-08-23 09:52:40,996 - INFO - > Epoch 86: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:52:51,254 - INFO - train: {'epoch': 87, 'time_epoch': 10.24626, 'eta': 125.81235, 'eta_hours': 0.03495, 'loss': 0.11865796, 'lr': 2.53e-05, 'params': 193993, 'time_iter': 0.04679, 'accuracy': 0.96229, 'f1': 0.9623, 'auc': 0.99649}
2025-08-23 09:52:51,895 - INFO - val: {'epoch': 87, 'time_epoch': 0.62392, 'loss': 0.23775614, 'lr': 0, 'params': 193993, 'time_iter': 0.0195, 'accuracy': 0.93, 'f1': 0.92988, 'auc': 0.98797}
2025-08-23 09:52:53,163 - INFO - test: {'epoch': 87, 'time_epoch': 1.25884, 'loss': 0.2450785, 'lr': 0, 'params': 193993, 'time_iter': 0.01998, 'accuracy': 0.928, 'f1': 0.92843, 'auc': 0.98732}
2025-08-23 09:52:53,165 - INFO - > Epoch 87: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:53:03,420 - INFO - train: {'epoch': 88, 'time_epoch': 10.24194, 'eta': 115.29803, 'eta_hours': 0.03203, 'loss': 0.11516419, 'lr': 2.161e-05, 'params': 193993, 'time_iter': 0.04677, 'accuracy': 0.96057, 'f1': 0.96055, 'auc': 0.99658}
2025-08-23 09:53:04,058 - INFO - val: {'epoch': 88, 'time_epoch': 0.62804, 'loss': 0.26091001, 'lr': 0, 'params': 193993, 'time_iter': 0.01963, 'accuracy': 0.92, 'f1': 0.92031, 'auc': 0.9876}
2025-08-23 09:53:05,320 - INFO - test: {'epoch': 88, 'time_epoch': 1.25157, 'loss': 0.2477116, 'lr': 0, 'params': 193993, 'time_iter': 0.01987, 'accuracy': 0.93, 'f1': 0.93079, 'auc': 0.98724}
2025-08-23 09:53:05,322 - INFO - > Epoch 88: took 12.2s (avg 12.5s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:53:15,549 - INFO - train: {'epoch': 89, 'time_epoch': 10.2147, 'eta': 104.78673, 'eta_hours': 0.02911, 'loss': 0.10866828, 'lr': 1.82e-05, 'params': 193993, 'time_iter': 0.04664, 'accuracy': 0.96457, 'f1': 0.96454, 'auc': 0.99657}
2025-08-23 09:53:16,183 - INFO - val: {'epoch': 89, 'time_epoch': 0.62376, 'loss': 0.25537541, 'lr': 0, 'params': 193993, 'time_iter': 0.01949, 'accuracy': 0.92, 'f1': 0.92031, 'auc': 0.98835}
2025-08-23 09:53:17,452 - INFO - test: {'epoch': 89, 'time_epoch': 1.25967, 'loss': 0.24547495, 'lr': 0, 'params': 193993, 'time_iter': 0.01999, 'accuracy': 0.934, 'f1': 0.93466, 'auc': 0.98716}
2025-08-23 09:53:17,454 - INFO - > Epoch 89: took 12.1s (avg 12.4s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:53:27,690 - INFO - train: {'epoch': 90, 'time_epoch': 10.2242, 'eta': 94.28289, 'eta_hours': 0.02619, 'loss': 0.11620026, 'lr': 1.508e-05, 'params': 193993, 'time_iter': 0.04669, 'accuracy': 0.96286, 'f1': 0.96284, 'auc': 0.99646}
2025-08-23 09:53:28,324 - INFO - val: {'epoch': 90, 'time_epoch': 0.62324, 'loss': 0.25484465, 'lr': 0, 'params': 193993, 'time_iter': 0.01948, 'accuracy': 0.92, 'f1': 0.92044, 'auc': 0.98752}
2025-08-23 09:53:29,589 - INFO - test: {'epoch': 90, 'time_epoch': 1.25503, 'loss': 0.24481154, 'lr': 0, 'params': 193993, 'time_iter': 0.01992, 'accuracy': 0.926, 'f1': 0.92724, 'auc': 0.98746}
2025-08-23 09:53:29,591 - INFO - > Epoch 90: took 12.1s (avg 12.4s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:53:39,810 - INFO - train: {'epoch': 91, 'time_epoch': 10.20656, 'eta': 83.78359, 'eta_hours': 0.02327, 'loss': 0.10736617, 'lr': 1.224e-05, 'params': 193993, 'time_iter': 0.04661, 'accuracy': 0.96486, 'f1': 0.96489, 'auc': 0.99691}
2025-08-23 09:53:40,440 - INFO - val: {'epoch': 91, 'time_epoch': 0.62071, 'loss': 0.26229365, 'lr': 0, 'params': 193993, 'time_iter': 0.0194, 'accuracy': 0.922, 'f1': 0.92235, 'auc': 0.98772}
2025-08-23 09:53:41,709 - INFO - test: {'epoch': 91, 'time_epoch': 1.2587, 'loss': 0.24597231, 'lr': 0, 'params': 193993, 'time_iter': 0.01998, 'accuracy': 0.928, 'f1': 0.92891, 'auc': 0.98734}
2025-08-23 09:53:41,710 - INFO - > Epoch 91: took 12.1s (avg 12.4s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:53:51,884 - INFO - train: {'epoch': 92, 'time_epoch': 10.16218, 'eta': 73.28725, 'eta_hours': 0.02036, 'loss': 0.10761044, 'lr': 9.68e-06, 'params': 193993, 'time_iter': 0.0464, 'accuracy': 0.96371, 'f1': 0.96367, 'auc': 0.99711}
2025-08-23 09:53:52,515 - INFO - val: {'epoch': 92, 'time_epoch': 0.62073, 'loss': 0.26035125, 'lr': 0, 'params': 193993, 'time_iter': 0.0194, 'accuracy': 0.92, 'f1': 0.92062, 'auc': 0.98713}
2025-08-23 09:53:53,773 - INFO - test: {'epoch': 92, 'time_epoch': 1.24912, 'loss': 0.25139274, 'lr': 0, 'params': 193993, 'time_iter': 0.01983, 'accuracy': 0.924, 'f1': 0.92517, 'auc': 0.98704}
2025-08-23 09:53:53,775 - INFO - > Epoch 92: took 12.1s (avg 12.4s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:54:04,004 - INFO - train: {'epoch': 93, 'time_epoch': 10.21637, 'eta': 62.80148, 'eta_hours': 0.01744, 'loss': 0.11337965, 'lr': 7.43e-06, 'params': 193993, 'time_iter': 0.04665, 'accuracy': 0.96371, 'f1': 0.96369, 'auc': 0.99649}
2025-08-23 09:54:04,635 - INFO - val: {'epoch': 93, 'time_epoch': 0.62101, 'loss': 0.24540872, 'lr': 0, 'params': 193993, 'time_iter': 0.01941, 'accuracy': 0.922, 'f1': 0.92241, 'auc': 0.98797}
2025-08-23 09:54:05,902 - INFO - test: {'epoch': 93, 'time_epoch': 1.25693, 'loss': 0.24185135, 'lr': 0, 'params': 193993, 'time_iter': 0.01995, 'accuracy': 0.929, 'f1': 0.92975, 'auc': 0.98722}
2025-08-23 09:54:05,904 - INFO - > Epoch 93: took 12.1s (avg 12.4s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:54:16,141 - INFO - train: {'epoch': 94, 'time_epoch': 10.22549, 'eta': 52.32186, 'eta_hours': 0.01453, 'loss': 0.10895937, 'lr': 5.46e-06, 'params': 193993, 'time_iter': 0.04669, 'accuracy': 0.96514, 'f1': 0.96516, 'auc': 0.99674}
2025-08-23 09:54:16,772 - INFO - val: {'epoch': 94, 'time_epoch': 0.62078, 'loss': 0.24882561, 'lr': 0, 'params': 193993, 'time_iter': 0.0194, 'accuracy': 0.916, 'f1': 0.91628, 'auc': 0.98758}
2025-08-23 09:54:18,052 - INFO - test: {'epoch': 94, 'time_epoch': 1.27, 'loss': 0.24410681, 'lr': 0, 'params': 193993, 'time_iter': 0.02016, 'accuracy': 0.93, 'f1': 0.93091, 'auc': 0.98674}
2025-08-23 09:54:18,054 - INFO - > Epoch 94: took 12.1s (avg 12.4s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:54:28,254 - INFO - train: {'epoch': 95, 'time_epoch': 10.18821, 'eta': 41.84598, 'eta_hours': 0.01162, 'loss': 0.11190094, 'lr': 3.8e-06, 'params': 193993, 'time_iter': 0.04652, 'accuracy': 0.96457, 'f1': 0.96457, 'auc': 0.99647}
2025-08-23 09:54:28,886 - INFO - val: {'epoch': 95, 'time_epoch': 0.62136, 'loss': 0.26351492, 'lr': 0, 'params': 193993, 'time_iter': 0.01942, 'accuracy': 0.922, 'f1': 0.92273, 'auc': 0.98702}
2025-08-23 09:54:30,152 - INFO - test: {'epoch': 95, 'time_epoch': 1.25704, 'loss': 0.24623679, 'lr': 0, 'params': 193993, 'time_iter': 0.01995, 'accuracy': 0.928, 'f1': 0.92896, 'auc': 0.98721}
2025-08-23 09:54:30,154 - INFO - > Epoch 95: took 12.1s (avg 12.4s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:54:40,396 - INFO - train: {'epoch': 96, 'time_epoch': 10.22914, 'eta': 31.3773, 'eta_hours': 0.00872, 'loss': 0.11232929, 'lr': 2.43e-06, 'params': 193993, 'time_iter': 0.04671, 'accuracy': 0.96314, 'f1': 0.96309, 'auc': 0.99685}
2025-08-23 09:54:41,025 - INFO - val: {'epoch': 96, 'time_epoch': 0.6198, 'loss': 0.26414758, 'lr': 0, 'params': 193993, 'time_iter': 0.01937, 'accuracy': 0.916, 'f1': 0.91622, 'auc': 0.98753}
2025-08-23 09:54:42,296 - INFO - test: {'epoch': 96, 'time_epoch': 1.26062, 'loss': 0.24759488, 'lr': 0, 'params': 193993, 'time_iter': 0.02001, 'accuracy': 0.932, 'f1': 0.93277, 'auc': 0.98673}
2025-08-23 09:54:42,298 - INFO - > Epoch 96: took 12.1s (avg 12.4s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:54:52,566 - INFO - train: {'epoch': 97, 'time_epoch': 10.25471, 'eta': 20.91403, 'eta_hours': 0.00581, 'loss': 0.1083966, 'lr': 1.37e-06, 'params': 193993, 'time_iter': 0.04683, 'accuracy': 0.96629, 'f1': 0.96619, 'auc': 0.99689}
2025-08-23 09:54:53,199 - INFO - val: {'epoch': 97, 'time_epoch': 0.62298, 'loss': 0.2669103, 'lr': 0, 'params': 193993, 'time_iter': 0.01947, 'accuracy': 0.918, 'f1': 0.91846, 'auc': 0.98747}
2025-08-23 09:54:54,459 - INFO - test: {'epoch': 97, 'time_epoch': 1.25056, 'loss': 0.24974648, 'lr': 0, 'params': 193993, 'time_iter': 0.01985, 'accuracy': 0.93, 'f1': 0.93091, 'auc': 0.98641}
2025-08-23 09:54:54,461 - INFO - > Epoch 97: took 12.2s (avg 12.4s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:55:04,772 - INFO - train: {'epoch': 98, 'time_epoch': 10.29709, 'eta': 10.4554, 'eta_hours': 0.0029, 'loss': 0.11340756, 'lr': 6.1e-07, 'params': 193993, 'time_iter': 0.04702, 'accuracy': 0.96257, 'f1': 0.96251, 'auc': 0.9965}
2025-08-23 09:55:05,407 - INFO - val: {'epoch': 98, 'time_epoch': 0.624, 'loss': 0.26152658, 'lr': 0, 'params': 193993, 'time_iter': 0.0195, 'accuracy': 0.92, 'f1': 0.92044, 'auc': 0.98774}
2025-08-23 09:55:06,670 - INFO - test: {'epoch': 98, 'time_epoch': 1.25226, 'loss': 0.24593857, 'lr': 0, 'params': 193993, 'time_iter': 0.01988, 'accuracy': 0.931, 'f1': 0.93182, 'auc': 0.98707}
2025-08-23 09:55:06,672 - INFO - > Epoch 98: took 12.2s (avg 12.4s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:55:16,923 - INFO - train: {'epoch': 99, 'time_epoch': 10.23723, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.10534335, 'lr': 1.5e-07, 'params': 193993, 'time_iter': 0.04675, 'accuracy': 0.966, 'f1': 0.96598, 'auc': 0.99694}
2025-08-23 09:55:17,553 - INFO - val: {'epoch': 99, 'time_epoch': 0.61982, 'loss': 0.26387254, 'lr': 0, 'params': 193993, 'time_iter': 0.01937, 'accuracy': 0.92, 'f1': 0.92059, 'auc': 0.98724}
2025-08-23 09:55:18,812 - INFO - test: {'epoch': 99, 'time_epoch': 1.24871, 'loss': 0.24693222, 'lr': 0, 'params': 193993, 'time_iter': 0.01982, 'accuracy': 0.927, 'f1': 0.92806, 'auc': 0.98684}
2025-08-23 09:55:18,909 - INFO - > Epoch 99: took 12.1s (avg 12.4s) | Best so far: epoch 61	train_loss: 0.1654 train_accuracy: 0.9417	val_loss: 0.2120 val_accuracy: 0.9340	test_loss: 0.2507 test_accuracy: 0.9230
2025-08-23 09:55:18,909 - INFO - Avg time per epoch: 12.42s
2025-08-23 09:55:18,909 - INFO - Total train loop time: 0.34h
2025-08-23 09:55:18,910 - INFO - Task done, results saved in results/MALNET/MALNET-E-47
2025-08-23 09:55:18,910 - INFO - Total time: 1246.12s (0.35h)
2025-08-23 09:55:18,911 - INFO - Results aggregated across runs saved in results/MALNET/MALNET-E-47/agg
2025-08-23 09:55:18,911 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-23 09:55:18,911 - INFO - Results saved in: results/MALNET/MALNET-E-47
2025-08-23 09:55:18,911 - INFO - Test results JSON files saved in: results/MALNET/MALNET-E-47/test_results/
Completed seed 47. Results saved in results/MALNET/MALNET-E-47
----------------------------------------
All experiments completed!
