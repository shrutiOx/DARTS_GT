Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          376Gi        35Gi       280Gi       3.6Gi        59Gi       333Gi
Swap:         1.9Gi       6.0Mi       1.9Gi
Sat Aug 23 09:52:04 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-16GB           On  |   00000000:3B:00.0 Off |                    0 |
| N/A   41C    P0             27W /  250W |       0MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 47
Starting training for seed 47...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/MALNET/FINAL_SINGLE/PERFORMER_E/UNI_GT/GATV2
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/MALNET/FINAL_SINGLE/PERFORMER_E/UNI_GT/GATV2/confignas.yaml
Using device: cuda
2025-08-23 09:52:17,579 - INFO - GPU Mem: 17.1GB
2025-08-23 09:52:17,579 - INFO - Run directory: results/MALNET/MALNET-E-47
2025-08-23 09:52:17,579 - INFO - Seed: 47
2025-08-23 09:52:17,579 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-23 09:52:17,579 - INFO - Routing mode: none
2025-08-23 09:52:17,579 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-23 09:52:17,579 - INFO - Number of layers: 4
2025-08-23 09:52:17,579 - INFO - Uncertainty enabled: False
2025-08-23 09:52:17,579 - INFO - Training mode: custom
2025-08-23 09:52:17,579 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-23 09:52:17,579 - INFO - Additional features: Router weights logging + JSON export
2025-08-23 09:52:19,585 - INFO - Computing "LocalDegreeProfile" node features for MalNetTiny.
2025-08-23 09:52:24,359 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-23 09:52:24,361 - INFO -   Data(edge_index=[2, 14299688], y=[5000], x=[7051560, 5], num_nodes=7051560)
2025-08-23 09:52:24,378 - INFO -   undirected: False
2025-08-23 09:52:24,378 - INFO -   num graphs: 5000
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-23 09:52:24,379 - INFO -   avg num_nodes/graph: 1410
2025-08-23 09:52:24,379 - INFO -   num node features: 5
2025-08-23 09:52:24,379 - INFO -   num edge features: 0
2025-08-23 09:52:24,379 - INFO -   num classes: 5
2025-08-23 09:52:24,381 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny'
2025-08-23 09:52:24,575 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-23 09:52:24,576 - INFO - Inner model type: <class 'graphgps.network.uniform_gt_model_edge.UNIFORM_GTModelEdge'>
2025-08-23 09:52:24,576 - INFO - Inner model has get_darts_model: False
2025-08-23 09:52:24,577 - INFO - GraphGymModule(
  (model): UNIFORM_GTModelEdge(
    (encoder): FeatureEncoder(
      (edge_encoder): DummyEdgeEncoder(
        (encoder): Embedding(1, 64)
      )
    )
    (pre_mp): GeneralMultiLayer(
      (Layer_0): GeneralLayer(
        (layer): Linear(
          (model): Linear(5, 64, bias=False)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU()
        )
      )
    )
    (layers): Sequential(
      (0): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GATv2Conv(64, 16, heads=4)
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (1): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GATv2Conv(64, 16, heads=4)
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (2): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GATv2Conv(64, 16, heads=4)
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (3): UNIFORMGTLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
        (kv_model): GATv2Conv(64, 16, heads=4)
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
    )
    (post_mp): GNNGraphHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(64, 5, bias=True)
          )
        )
      )
    )
  )
)
2025-08-23 09:52:24,579 - INFO - Number of parameters: 210,889
2025-08-23 09:52:24,579 - INFO - Starting optimized training: 2025-08-23 09:52:24.579440
2025-08-23 09:52:24,671 - INFO - Computing "LocalDegreeProfile" node features for MalNetTiny.
2025-08-23 09:52:29,072 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny':
2025-08-23 09:52:29,073 - INFO -   Data(edge_index=[2, 14299688], y=[5000], x=[7051560, 5], num_nodes=7051560)
2025-08-23 09:52:29,073 - INFO -   undirected: False
2025-08-23 09:52:29,074 - INFO -   num graphs: 5000
2025-08-23 09:52:29,074 - INFO -   avg num_nodes/graph: 1410
2025-08-23 09:52:29,074 - INFO -   num node features: 5
2025-08-23 09:52:29,074 - INFO -   num edge features: 0
2025-08-23 09:52:29,074 - INFO -   num classes: 5
2025-08-23 09:52:29,077 - INFO - [*] Loaded dataset 'LocalDegreeProfile' from 'PyG-MalNetTiny'
2025-08-23 09:52:29,081 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-23 09:52:29,081 - INFO - Start from epoch 0
2025-08-23 09:52:46,706 - INFO - train: {'epoch': 0, 'time_epoch': 17.0432, 'eta': 1687.27694, 'eta_hours': 0.46869, 'loss': 1.61804258, 'lr': 0.0, 'params': 210889, 'time_iter': 0.07782, 'accuracy': 0.2, 'f1': 0.06667, 'auc': 0.44269}
2025-08-23 09:52:46,709 - INFO - ...computing epoch stats took: 0.58s
2025-08-23 09:52:47,691 - INFO - val: {'epoch': 0, 'time_epoch': 0.97251, 'loss': 1.61701814, 'lr': 0, 'params': 210889, 'time_iter': 0.03039, 'accuracy': 0.2, 'f1': 0.06667, 'auc': 0.43266}
2025-08-23 09:52:47,693 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:52:49,603 - INFO - test: {'epoch': 0, 'time_epoch': 1.89876, 'loss': 1.61611209, 'lr': 0, 'params': 210889, 'time_iter': 0.03014, 'accuracy': 0.2, 'f1': 0.06667, 'auc': 0.4509}
2025-08-23 09:52:49,605 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:52:49,606 - INFO - > Epoch 0: took 20.5s (avg 20.5s) | Best so far: epoch 0	train_loss: 1.6180 train_accuracy: 0.2000	val_loss: 1.6170 val_accuracy: 0.2000	test_loss: 1.6161 test_accuracy: 0.2000
2025-08-23 09:53:03,968 - INFO - train: {'epoch': 1, 'time_epoch': 14.34419, 'eta': 1537.98213, 'eta_hours': 0.42722, 'loss': 1.56680386, 'lr': 5e-05, 'params': 210889, 'time_iter': 0.0655, 'accuracy': 0.32086, 'f1': 0.23254, 'auc': 0.72191}
2025-08-23 09:53:03,970 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:53:04,875 - INFO - val: {'epoch': 1, 'time_epoch': 0.89486, 'loss': 1.52259897, 'lr': 0, 'params': 210889, 'time_iter': 0.02796, 'accuracy': 0.414, 'f1': 0.27881, 'auc': 0.829}
2025-08-23 09:53:04,876 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:53:06,741 - INFO - test: {'epoch': 1, 'time_epoch': 1.85488, 'loss': 1.52477371, 'lr': 0, 'params': 210889, 'time_iter': 0.02944, 'accuracy': 0.415, 'f1': 0.28699, 'auc': 0.80509}
2025-08-23 09:53:06,743 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:53:06,743 - INFO - > Epoch 1: took 17.1s (avg 18.8s) | Best so far: epoch 1	train_loss: 1.5668 train_accuracy: 0.3209	val_loss: 1.5226 val_accuracy: 0.4140	test_loss: 1.5248 test_accuracy: 0.4150
2025-08-23 09:53:21,066 - INFO - train: {'epoch': 2, 'time_epoch': 14.30626, 'eta': 1477.42804, 'eta_hours': 0.4104, 'loss': 1.46270781, 'lr': 0.0001, 'params': 210889, 'time_iter': 0.06533, 'accuracy': 0.57829, 'f1': 0.54405, 'auc': 0.82652}
2025-08-23 09:53:21,069 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:53:21,975 - INFO - val: {'epoch': 2, 'time_epoch': 0.89566, 'loss': 1.42010502, 'lr': 0, 'params': 210889, 'time_iter': 0.02799, 'accuracy': 0.584, 'f1': 0.55786, 'auc': 0.85141}
2025-08-23 09:53:21,976 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:53:23,834 - INFO - test: {'epoch': 2, 'time_epoch': 1.84764, 'loss': 1.42750859, 'lr': 0, 'params': 210889, 'time_iter': 0.02933, 'accuracy': 0.588, 'f1': 0.56836, 'auc': 0.82615}
2025-08-23 09:53:23,836 - INFO - ...computing epoch stats took: 0.01s
2025-08-23 09:53:23,836 - INFO - > Epoch 2: took 17.1s (avg 18.3s) | Best so far: epoch 2	train_loss: 1.4627 train_accuracy: 0.5783	val_loss: 1.4201 val_accuracy: 0.5840	test_loss: 1.4275 test_accuracy: 0.5880
2025-08-23 09:53:38,157 - INFO - train: {'epoch': 3, 'time_epoch': 14.30433, 'eta': 1439.95142, 'eta_hours': 0.39999, 'loss': 1.36598783, 'lr': 0.00015, 'params': 210889, 'time_iter': 0.06532, 'accuracy': 0.67057, 'f1': 0.6553, 'auc': 0.86426}
2025-08-23 09:53:39,063 - INFO - val: {'epoch': 3, 'time_epoch': 0.89413, 'loss': 1.33307668, 'lr': 0, 'params': 210889, 'time_iter': 0.02794, 'accuracy': 0.644, 'f1': 0.61354, 'auc': 0.87715}
2025-08-23 09:53:40,858 - INFO - test: {'epoch': 3, 'time_epoch': 1.78418, 'loss': 1.34561094, 'lr': 0, 'params': 210889, 'time_iter': 0.02832, 'accuracy': 0.632, 'f1': 0.61179, 'auc': 0.8488}
2025-08-23 09:53:40,860 - INFO - > Epoch 3: took 17.0s (avg 17.9s) | Best so far: epoch 3	train_loss: 1.3660 train_accuracy: 0.6706	val_loss: 1.3331 val_accuracy: 0.6440	test_loss: 1.3456 test_accuracy: 0.6320
2025-08-23 09:53:55,059 - INFO - train: {'epoch': 4, 'time_epoch': 14.18215, 'eta': 1409.42237, 'eta_hours': 0.39151, 'loss': 1.26941242, 'lr': 0.0002, 'params': 210889, 'time_iter': 0.06476, 'accuracy': 0.69543, 'f1': 0.68482, 'auc': 0.8843}
2025-08-23 09:53:55,970 - INFO - val: {'epoch': 4, 'time_epoch': 0.89886, 'loss': 1.21860178, 'lr': 0, 'params': 210889, 'time_iter': 0.02809, 'accuracy': 0.732, 'f1': 0.73958, 'auc': 0.92453}
2025-08-23 09:53:57,776 - INFO - test: {'epoch': 4, 'time_epoch': 1.79507, 'loss': 1.23246179, 'lr': 0, 'params': 210889, 'time_iter': 0.02849, 'accuracy': 0.719, 'f1': 0.72696, 'auc': 0.91464}
2025-08-23 09:53:57,778 - INFO - > Epoch 4: took 16.9s (avg 17.7s) | Best so far: epoch 4	train_loss: 1.2694 train_accuracy: 0.6954	val_loss: 1.2186 val_accuracy: 0.7320	test_loss: 1.2325 test_accuracy: 0.7190
2025-08-23 09:54:12,080 - INFO - train: {'epoch': 5, 'time_epoch': 14.28587, 'eta': 1385.96722, 'eta_hours': 0.38499, 'loss': 1.17931461, 'lr': 0.00025, 'params': 210889, 'time_iter': 0.06523, 'accuracy': 0.69486, 'f1': 0.6844, 'auc': 0.8946}
2025-08-23 09:54:12,984 - INFO - val: {'epoch': 5, 'time_epoch': 0.89265, 'loss': 1.12128001, 'lr': 0, 'params': 210889, 'time_iter': 0.0279, 'accuracy': 0.762, 'f1': 0.76893, 'auc': 0.93037}
2025-08-23 09:54:14,801 - INFO - test: {'epoch': 5, 'time_epoch': 1.80461, 'loss': 1.14710002, 'lr': 0, 'params': 210889, 'time_iter': 0.02864, 'accuracy': 0.718, 'f1': 0.7271, 'auc': 0.90996}
2025-08-23 09:54:14,803 - INFO - > Epoch 5: took 17.0s (avg 17.6s) | Best so far: epoch 5	train_loss: 1.1793 train_accuracy: 0.6949	val_loss: 1.1213 val_accuracy: 0.7620	test_loss: 1.1471 test_accuracy: 0.7180
2025-08-23 09:54:29,100 - INFO - train: {'epoch': 6, 'time_epoch': 14.28182, 'eta': 1365.07807, 'eta_hours': 0.37919, 'loss': 1.08229048, 'lr': 0.0003, 'params': 210889, 'time_iter': 0.06521, 'accuracy': 0.71714, 'f1': 0.70523, 'auc': 0.90519}
2025-08-23 09:54:30,010 - INFO - val: {'epoch': 6, 'time_epoch': 0.89761, 'loss': 1.03069324, 'lr': 0, 'params': 210889, 'time_iter': 0.02805, 'accuracy': 0.766, 'f1': 0.77148, 'auc': 0.93331}
2025-08-23 09:54:31,900 - INFO - test: {'epoch': 6, 'time_epoch': 1.87827, 'loss': 1.0626136, 'lr': 0, 'params': 210889, 'time_iter': 0.02981, 'accuracy': 0.729, 'f1': 0.73769, 'auc': 0.91543}
2025-08-23 09:54:31,902 - INFO - > Epoch 6: took 17.1s (avg 17.5s) | Best so far: epoch 6	train_loss: 1.0823 train_accuracy: 0.7171	val_loss: 1.0307 val_accuracy: 0.7660	test_loss: 1.0626 test_accuracy: 0.7290
2025-08-23 09:54:46,333 - INFO - train: {'epoch': 7, 'time_epoch': 14.41347, 'eta': 1347.35473, 'eta_hours': 0.37427, 'loss': 0.99705411, 'lr': 0.00035, 'params': 210889, 'time_iter': 0.06581, 'accuracy': 0.71486, 'f1': 0.70197, 'auc': 0.90964}
2025-08-23 09:54:47,271 - INFO - val: {'epoch': 7, 'time_epoch': 0.92458, 'loss': 0.98670025, 'lr': 0, 'params': 210889, 'time_iter': 0.02889, 'accuracy': 0.702, 'f1': 0.68392, 'auc': 0.91889}
2025-08-23 09:54:49,128 - INFO - test: {'epoch': 7, 'time_epoch': 1.84517, 'loss': 0.99554978, 'lr': 0, 'params': 210889, 'time_iter': 0.02929, 'accuracy': 0.716, 'f1': 0.7032, 'auc': 0.91649}
2025-08-23 09:54:49,130 - INFO - > Epoch 7: took 17.2s (avg 17.5s) | Best so far: epoch 6	train_loss: 1.0823 train_accuracy: 0.7171	val_loss: 1.0307 val_accuracy: 0.7660	test_loss: 1.0626 test_accuracy: 0.7290
2025-08-23 09:55:03,730 - INFO - train: {'epoch': 8, 'time_epoch': 14.58227, 'eta': 1332.07373, 'eta_hours': 0.37002, 'loss': 0.92040129, 'lr': 0.0004, 'params': 210889, 'time_iter': 0.06659, 'accuracy': 0.72571, 'f1': 0.71797, 'auc': 0.91782}
2025-08-23 09:55:04,642 - INFO - val: {'epoch': 8, 'time_epoch': 0.8984, 'loss': 0.898003, 'lr': 0, 'params': 210889, 'time_iter': 0.02808, 'accuracy': 0.782, 'f1': 0.78165, 'auc': 0.92861}
2025-08-23 09:55:06,460 - INFO - test: {'epoch': 8, 'time_epoch': 1.80295, 'loss': 0.91828598, 'lr': 0, 'params': 210889, 'time_iter': 0.02862, 'accuracy': 0.753, 'f1': 0.75928, 'auc': 0.92212}
2025-08-23 09:55:06,462 - INFO - > Epoch 8: took 17.3s (avg 17.5s) | Best so far: epoch 8	train_loss: 0.9204 train_accuracy: 0.7257	val_loss: 0.8980 val_accuracy: 0.7820	test_loss: 0.9183 test_accuracy: 0.7530
2025-08-23 09:55:20,917 - INFO - train: {'epoch': 9, 'time_epoch': 14.43702, 'eta': 1315.62516, 'eta_hours': 0.36545, 'loss': 0.84099465, 'lr': 0.00045, 'params': 210889, 'time_iter': 0.06592, 'accuracy': 0.74686, 'f1': 0.73965, 'auc': 0.9261}
2025-08-23 09:55:21,825 - INFO - val: {'epoch': 9, 'time_epoch': 0.8961, 'loss': 0.84480962, 'lr': 0, 'params': 210889, 'time_iter': 0.028, 'accuracy': 0.744, 'f1': 0.73111, 'auc': 0.93245}
2025-08-23 09:55:23,634 - INFO - test: {'epoch': 9, 'time_epoch': 1.7947, 'loss': 0.85953954, 'lr': 0, 'params': 210889, 'time_iter': 0.02849, 'accuracy': 0.753, 'f1': 0.74392, 'auc': 0.9253}
2025-08-23 09:55:23,636 - INFO - > Epoch 9: took 17.2s (avg 17.5s) | Best so far: epoch 8	train_loss: 0.9204 train_accuracy: 0.7257	val_loss: 0.8980 val_accuracy: 0.7820	test_loss: 0.9183 test_accuracy: 0.7530
2025-08-23 09:55:38,006 - INFO - train: {'epoch': 10, 'time_epoch': 14.35183, 'eta': 1298.85305, 'eta_hours': 0.36079, 'loss': 0.77966585, 'lr': 0.0005, 'params': 210889, 'time_iter': 0.06553, 'accuracy': 0.74971, 'f1': 0.74668, 'auc': 0.9293}
2025-08-23 09:55:38,916 - INFO - val: {'epoch': 10, 'time_epoch': 0.89857, 'loss': 0.75433671, 'lr': 0, 'params': 210889, 'time_iter': 0.02808, 'accuracy': 0.782, 'f1': 0.79311, 'auc': 0.94745}
2025-08-23 09:55:40,708 - INFO - test: {'epoch': 10, 'time_epoch': 1.78028, 'loss': 0.79381643, 'lr': 0, 'params': 210889, 'time_iter': 0.02826, 'accuracy': 0.74, 'f1': 0.75278, 'auc': 0.93601}
2025-08-23 09:55:40,710 - INFO - > Epoch 10: took 17.1s (avg 17.4s) | Best so far: epoch 8	train_loss: 0.9204 train_accuracy: 0.7257	val_loss: 0.8980 val_accuracy: 0.7820	test_loss: 0.9183 test_accuracy: 0.7530
2025-08-23 09:55:55,150 - INFO - train: {'epoch': 11, 'time_epoch': 14.42222, 'eta': 1283.00057, 'eta_hours': 0.35639, 'loss': 0.7271791, 'lr': 0.00049985, 'params': 210889, 'time_iter': 0.06585, 'accuracy': 0.76171, 'f1': 0.7557, 'auc': 0.93449}
2025-08-23 09:55:56,074 - INFO - val: {'epoch': 11, 'time_epoch': 0.91065, 'loss': 0.78109969, 'lr': 0, 'params': 210889, 'time_iter': 0.02846, 'accuracy': 0.712, 'f1': 0.69514, 'auc': 0.9302}
2025-08-23 09:55:57,893 - INFO - test: {'epoch': 11, 'time_epoch': 1.8046, 'loss': 0.80392308, 'lr': 0, 'params': 210889, 'time_iter': 0.02864, 'accuracy': 0.707, 'f1': 0.69395, 'auc': 0.92503}
2025-08-23 09:55:57,895 - INFO - > Epoch 11: took 17.2s (avg 17.4s) | Best so far: epoch 8	train_loss: 0.9204 train_accuracy: 0.7257	val_loss: 0.8980 val_accuracy: 0.7820	test_loss: 0.9183 test_accuracy: 0.7530
2025-08-23 09:56:12,357 - INFO - train: {'epoch': 12, 'time_epoch': 14.44504, 'eta': 1267.52084, 'eta_hours': 0.35209, 'loss': 0.70039932, 'lr': 0.00049939, 'params': 210889, 'time_iter': 0.06596, 'accuracy': 0.758, 'f1': 0.75735, 'auc': 0.93471}
2025-08-23 09:56:13,283 - INFO - val: {'epoch': 12, 'time_epoch': 0.91161, 'loss': 0.66485041, 'lr': 0, 'params': 210889, 'time_iter': 0.02849, 'accuracy': 0.796, 'f1': 0.80307, 'auc': 0.95451}
2025-08-23 09:56:15,113 - INFO - test: {'epoch': 12, 'time_epoch': 1.81523, 'loss': 0.69335775, 'lr': 0, 'params': 210889, 'time_iter': 0.02881, 'accuracy': 0.776, 'f1': 0.78564, 'auc': 0.94469}
2025-08-23 09:56:15,115 - INFO - > Epoch 12: took 17.2s (avg 17.4s) | Best so far: epoch 12	train_loss: 0.7004 train_accuracy: 0.7580	val_loss: 0.6649 val_accuracy: 0.7960	test_loss: 0.6934 test_accuracy: 0.7760
2025-08-23 09:56:29,595 - INFO - train: {'epoch': 13, 'time_epoch': 14.46256, 'eta': 1252.29655, 'eta_hours': 0.34786, 'loss': 0.66822306, 'lr': 0.00049863, 'params': 210889, 'time_iter': 0.06604, 'accuracy': 0.76286, 'f1': 0.7619, 'auc': 0.93829}
2025-08-23 09:56:30,507 - INFO - val: {'epoch': 13, 'time_epoch': 0.89849, 'loss': 0.67104974, 'lr': 0, 'params': 210889, 'time_iter': 0.02808, 'accuracy': 0.786, 'f1': 0.78541, 'auc': 0.94538}
2025-08-23 09:56:32,333 - INFO - test: {'epoch': 13, 'time_epoch': 1.81154, 'loss': 0.68402505, 'lr': 0, 'params': 210889, 'time_iter': 0.02875, 'accuracy': 0.78, 'f1': 0.78177, 'auc': 0.94044}
2025-08-23 09:56:32,335 - INFO - > Epoch 13: took 17.2s (avg 17.4s) | Best so far: epoch 12	train_loss: 0.7004 train_accuracy: 0.7580	val_loss: 0.6649 val_accuracy: 0.7960	test_loss: 0.6934 test_accuracy: 0.7760
2025-08-23 09:56:46,895 - INFO - train: {'epoch': 14, 'time_epoch': 14.5414, 'eta': 1237.62055, 'eta_hours': 0.34378, 'loss': 0.64446939, 'lr': 0.00049757, 'params': 210889, 'time_iter': 0.0664, 'accuracy': 0.77743, 'f1': 0.7785, 'auc': 0.94016}
2025-08-23 09:56:47,808 - INFO - val: {'epoch': 14, 'time_epoch': 0.89846, 'loss': 0.69994972, 'lr': 0, 'params': 210889, 'time_iter': 0.02808, 'accuracy': 0.696, 'f1': 0.68345, 'auc': 0.93536}
2025-08-23 09:56:49,630 - INFO - test: {'epoch': 14, 'time_epoch': 1.80872, 'loss': 0.70865714, 'lr': 0, 'params': 210889, 'time_iter': 0.02871, 'accuracy': 0.713, 'f1': 0.7001, 'auc': 0.92999}
2025-08-23 09:56:49,633 - INFO - > Epoch 14: took 17.3s (avg 17.4s) | Best so far: epoch 12	train_loss: 0.7004 train_accuracy: 0.7580	val_loss: 0.6649 val_accuracy: 0.7960	test_loss: 0.6934 test_accuracy: 0.7760
2025-08-23 09:57:04,060 - INFO - train: {'epoch': 15, 'time_epoch': 14.40946, 'eta': 1222.2687, 'eta_hours': 0.33952, 'loss': 0.623977, 'lr': 0.0004962, 'params': 210889, 'time_iter': 0.0658, 'accuracy': 0.77714, 'f1': 0.77979, 'auc': 0.94029}
2025-08-23 09:57:04,991 - INFO - val: {'epoch': 15, 'time_epoch': 0.91522, 'loss': 0.69180468, 'lr': 0, 'params': 210889, 'time_iter': 0.0286, 'accuracy': 0.72, 'f1': 0.70706, 'auc': 0.9385}
2025-08-23 09:57:06,808 - INFO - test: {'epoch': 15, 'time_epoch': 1.80311, 'loss': 0.69426353, 'lr': 0, 'params': 210889, 'time_iter': 0.02862, 'accuracy': 0.729, 'f1': 0.71461, 'auc': 0.93402}
2025-08-23 09:57:06,810 - INFO - > Epoch 15: took 17.2s (avg 17.4s) | Best so far: epoch 12	train_loss: 0.7004 train_accuracy: 0.7580	val_loss: 0.6649 val_accuracy: 0.7960	test_loss: 0.6934 test_accuracy: 0.7760
2025-08-23 09:57:21,536 - INFO - train: {'epoch': 16, 'time_epoch': 14.70844, 'eta': 1208.48744, 'eta_hours': 0.33569, 'loss': 0.59887789, 'lr': 0.00049454, 'params': 210889, 'time_iter': 0.06716, 'accuracy': 0.78171, 'f1': 0.78373, 'auc': 0.94367}
2025-08-23 09:57:22,441 - INFO - val: {'epoch': 16, 'time_epoch': 0.89278, 'loss': 0.74309297, 'lr': 0, 'params': 210889, 'time_iter': 0.0279, 'accuracy': 0.68, 'f1': 0.66639, 'auc': 0.93685}
2025-08-23 09:57:24,242 - INFO - test: {'epoch': 16, 'time_epoch': 1.7902, 'loss': 0.72358479, 'lr': 0, 'params': 210889, 'time_iter': 0.02842, 'accuracy': 0.695, 'f1': 0.68278, 'auc': 0.93347}
2025-08-23 09:57:24,244 - INFO - > Epoch 16: took 17.4s (avg 17.4s) | Best so far: epoch 12	train_loss: 0.7004 train_accuracy: 0.7580	val_loss: 0.6649 val_accuracy: 0.7960	test_loss: 0.6934 test_accuracy: 0.7760
2025-08-23 09:57:38,658 - INFO - train: {'epoch': 17, 'time_epoch': 14.3906, 'eta': 1193.15524, 'eta_hours': 0.33143, 'loss': 0.58109498, 'lr': 0.00049257, 'params': 210889, 'time_iter': 0.06571, 'accuracy': 0.78657, 'f1': 0.78927, 'auc': 0.94509}
2025-08-23 09:57:39,560 - INFO - val: {'epoch': 17, 'time_epoch': 0.8884, 'loss': 0.57561887, 'lr': 0, 'params': 210889, 'time_iter': 0.02776, 'accuracy': 0.79, 'f1': 0.78869, 'auc': 0.95118}
2025-08-23 09:57:41,351 - INFO - test: {'epoch': 17, 'time_epoch': 1.78046, 'loss': 0.60827116, 'lr': 0, 'params': 210889, 'time_iter': 0.02826, 'accuracy': 0.778, 'f1': 0.78013, 'auc': 0.94445}
2025-08-23 09:57:41,353 - INFO - > Epoch 17: took 17.1s (avg 17.3s) | Best so far: epoch 12	train_loss: 0.7004 train_accuracy: 0.7580	val_loss: 0.6649 val_accuracy: 0.7960	test_loss: 0.6934 test_accuracy: 0.7760
2025-08-23 09:57:55,743 - INFO - train: {'epoch': 18, 'time_epoch': 14.37387, 'eta': 1177.8508, 'eta_hours': 0.32718, 'loss': 0.56639654, 'lr': 0.00049032, 'params': 210889, 'time_iter': 0.06563, 'accuracy': 0.78771, 'f1': 0.79177, 'auc': 0.94732}
2025-08-23 09:57:56,638 - INFO - val: {'epoch': 18, 'time_epoch': 0.88317, 'loss': 0.5194791, 'lr': 0, 'params': 210889, 'time_iter': 0.0276, 'accuracy': 0.818, 'f1': 0.81876, 'auc': 0.95976}
2025-08-23 09:57:58,402 - INFO - test: {'epoch': 18, 'time_epoch': 1.75363, 'loss': 0.54952394, 'lr': 0, 'params': 210889, 'time_iter': 0.02784, 'accuracy': 0.801, 'f1': 0.80362, 'auc': 0.95554}
2025-08-23 09:57:58,405 - INFO - > Epoch 18: took 17.1s (avg 17.3s) | Best so far: epoch 18	train_loss: 0.5664 train_accuracy: 0.7877	val_loss: 0.5195 val_accuracy: 0.8180	test_loss: 0.5495 test_accuracy: 0.8010
2025-08-23 09:58:12,795 - INFO - train: {'epoch': 19, 'time_epoch': 14.37402, 'eta': 1162.64004, 'eta_hours': 0.32296, 'loss': 0.5428641, 'lr': 0.00048776, 'params': 210889, 'time_iter': 0.06563, 'accuracy': 0.79629, 'f1': 0.7981, 'auc': 0.94982}
2025-08-23 09:58:13,699 - INFO - val: {'epoch': 19, 'time_epoch': 0.89189, 'loss': 0.52896611, 'lr': 0, 'params': 210889, 'time_iter': 0.02787, 'accuracy': 0.794, 'f1': 0.7934, 'auc': 0.95959}
2025-08-23 09:58:15,500 - INFO - test: {'epoch': 19, 'time_epoch': 1.78983, 'loss': 0.54512417, 'lr': 0, 'params': 210889, 'time_iter': 0.02841, 'accuracy': 0.795, 'f1': 0.79717, 'auc': 0.9548}
2025-08-23 09:58:15,501 - INFO - > Epoch 19: took 17.1s (avg 17.3s) | Best so far: epoch 18	train_loss: 0.5664 train_accuracy: 0.7877	val_loss: 0.5195 val_accuracy: 0.8180	test_loss: 0.5495 test_accuracy: 0.8010
2025-08-23 09:58:29,916 - INFO - train: {'epoch': 20, 'time_epoch': 14.39755, 'eta': 1147.59748, 'eta_hours': 0.31878, 'loss': 0.51252974, 'lr': 0.00048492, 'params': 210889, 'time_iter': 0.06574, 'accuracy': 0.82057, 'f1': 0.82214, 'auc': 0.95812}
2025-08-23 09:58:30,823 - INFO - val: {'epoch': 20, 'time_epoch': 0.89462, 'loss': 0.51961743, 'lr': 0, 'params': 210889, 'time_iter': 0.02796, 'accuracy': 0.81, 'f1': 0.80511, 'auc': 0.9598}
2025-08-23 09:58:32,632 - INFO - test: {'epoch': 20, 'time_epoch': 1.79804, 'loss': 0.53954005, 'lr': 0, 'params': 210889, 'time_iter': 0.02854, 'accuracy': 0.798, 'f1': 0.7977, 'auc': 0.95502}
2025-08-23 09:58:32,634 - INFO - > Epoch 20: took 17.1s (avg 17.3s) | Best so far: epoch 18	train_loss: 0.5664 train_accuracy: 0.7877	val_loss: 0.5195 val_accuracy: 0.8180	test_loss: 0.5495 test_accuracy: 0.8010
2025-08-23 09:58:47,045 - INFO - train: {'epoch': 21, 'time_epoch': 14.3944, 'eta': 1132.6024, 'eta_hours': 0.31461, 'loss': 0.51993096, 'lr': 0.0004818, 'params': 210889, 'time_iter': 0.06573, 'accuracy': 0.812, 'f1': 0.81411, 'auc': 0.95528}
2025-08-23 09:58:47,957 - INFO - val: {'epoch': 21, 'time_epoch': 0.90064, 'loss': 0.49691058, 'lr': 0, 'params': 210889, 'time_iter': 0.02814, 'accuracy': 0.818, 'f1': 0.8196, 'auc': 0.96766}
2025-08-23 09:58:49,768 - INFO - test: {'epoch': 21, 'time_epoch': 1.79972, 'loss': 0.50781915, 'lr': 0, 'params': 210889, 'time_iter': 0.02857, 'accuracy': 0.818, 'f1': 0.82194, 'auc': 0.96251}
2025-08-23 09:58:49,770 - INFO - > Epoch 21: took 17.1s (avg 17.3s) | Best so far: epoch 18	train_loss: 0.5664 train_accuracy: 0.7877	val_loss: 0.5195 val_accuracy: 0.8180	test_loss: 0.5495 test_accuracy: 0.8010
2025-08-23 09:59:04,120 - INFO - train: {'epoch': 22, 'time_epoch': 14.33407, 'eta': 1117.45759, 'eta_hours': 0.3104, 'loss': 0.49849476, 'lr': 0.00047839, 'params': 210889, 'time_iter': 0.06545, 'accuracy': 0.82343, 'f1': 0.82592, 'auc': 0.95885}
2025-08-23 09:59:05,013 - INFO - val: {'epoch': 22, 'time_epoch': 0.88105, 'loss': 0.50117904, 'lr': 0, 'params': 210889, 'time_iter': 0.02753, 'accuracy': 0.842, 'f1': 0.84845, 'auc': 0.96953}
2025-08-23 09:59:06,784 - INFO - test: {'epoch': 22, 'time_epoch': 1.75993, 'loss': 0.54269677, 'lr': 0, 'params': 210889, 'time_iter': 0.02794, 'accuracy': 0.819, 'f1': 0.82636, 'auc': 0.9627}
2025-08-23 09:59:06,786 - INFO - > Epoch 22: took 17.0s (avg 17.3s) | Best so far: epoch 22	train_loss: 0.4985 train_accuracy: 0.8234	val_loss: 0.5012 val_accuracy: 0.8420	test_loss: 0.5427 test_accuracy: 0.8190
2025-08-23 09:59:21,095 - INFO - train: {'epoch': 23, 'time_epoch': 14.29345, 'eta': 1102.25168, 'eta_hours': 0.30618, 'loss': 0.49261693, 'lr': 0.0004747, 'params': 210889, 'time_iter': 0.06527, 'accuracy': 0.81886, 'f1': 0.82052, 'auc': 0.96006}
2025-08-23 09:59:21,991 - INFO - val: {'epoch': 23, 'time_epoch': 0.88483, 'loss': 0.44440346, 'lr': 0, 'params': 210889, 'time_iter': 0.02765, 'accuracy': 0.854, 'f1': 0.85929, 'auc': 0.97402}
2025-08-23 09:59:23,784 - INFO - test: {'epoch': 23, 'time_epoch': 1.78185, 'loss': 0.48794181, 'lr': 0, 'params': 210889, 'time_iter': 0.02828, 'accuracy': 0.837, 'f1': 0.84256, 'auc': 0.96794}
2025-08-23 09:59:23,786 - INFO - > Epoch 23: took 17.0s (avg 17.3s) | Best so far: epoch 23	train_loss: 0.4926 train_accuracy: 0.8189	val_loss: 0.4444 val_accuracy: 0.8540	test_loss: 0.4879 test_accuracy: 0.8370
2025-08-23 09:59:38,191 - INFO - train: {'epoch': 24, 'time_epoch': 14.38721, 'eta': 1087.40007, 'eta_hours': 0.30206, 'loss': 0.47115777, 'lr': 0.00047074, 'params': 210889, 'time_iter': 0.0657, 'accuracy': 0.83286, 'f1': 0.83421, 'auc': 0.96332}
2025-08-23 09:59:39,103 - INFO - val: {'epoch': 24, 'time_epoch': 0.8996, 'loss': 0.45177385, 'lr': 0, 'params': 210889, 'time_iter': 0.02811, 'accuracy': 0.838, 'f1': 0.83929, 'auc': 0.9724}
2025-08-23 09:59:40,897 - INFO - test: {'epoch': 24, 'time_epoch': 1.7832, 'loss': 0.47477595, 'lr': 0, 'params': 210889, 'time_iter': 0.0283, 'accuracy': 0.823, 'f1': 0.82644, 'auc': 0.96747}
2025-08-23 09:59:40,898 - INFO - > Epoch 24: took 17.1s (avg 17.3s) | Best so far: epoch 23	train_loss: 0.4926 train_accuracy: 0.8189	val_loss: 0.4444 val_accuracy: 0.8540	test_loss: 0.4879 test_accuracy: 0.8370
2025-08-23 09:59:55,291 - INFO - train: {'epoch': 25, 'time_epoch': 14.37529, 'eta': 1072.55025, 'eta_hours': 0.29793, 'loss': 0.43907586, 'lr': 0.00046651, 'params': 210889, 'time_iter': 0.06564, 'accuracy': 0.84371, 'f1': 0.84515, 'auc': 0.96823}
2025-08-23 09:59:56,191 - INFO - val: {'epoch': 25, 'time_epoch': 0.88872, 'loss': 0.47223346, 'lr': 0, 'params': 210889, 'time_iter': 0.02777, 'accuracy': 0.816, 'f1': 0.81674, 'auc': 0.97107}
2025-08-23 09:59:57,987 - INFO - test: {'epoch': 25, 'time_epoch': 1.78493, 'loss': 0.47486257, 'lr': 0, 'params': 210889, 'time_iter': 0.02833, 'accuracy': 0.835, 'f1': 0.8368, 'auc': 0.96894}
2025-08-23 09:59:57,988 - INFO - > Epoch 25: took 17.1s (avg 17.3s) | Best so far: epoch 23	train_loss: 0.4926 train_accuracy: 0.8189	val_loss: 0.4444 val_accuracy: 0.8540	test_loss: 0.4879 test_accuracy: 0.8370
2025-08-23 10:00:12,312 - INFO - train: {'epoch': 26, 'time_epoch': 14.30709, 'eta': 1057.55119, 'eta_hours': 0.29376, 'loss': 0.43086017, 'lr': 0.00046201, 'params': 210889, 'time_iter': 0.06533, 'accuracy': 0.84771, 'f1': 0.84913, 'auc': 0.96968}
2025-08-23 10:00:13,208 - INFO - val: {'epoch': 26, 'time_epoch': 0.8851, 'loss': 0.38127792, 'lr': 0, 'params': 210889, 'time_iter': 0.02766, 'accuracy': 0.874, 'f1': 0.87624, 'auc': 0.97986}
2025-08-23 10:00:15,002 - INFO - test: {'epoch': 26, 'time_epoch': 1.78264, 'loss': 0.42505709, 'lr': 0, 'params': 210889, 'time_iter': 0.0283, 'accuracy': 0.839, 'f1': 0.84189, 'auc': 0.97572}
2025-08-23 10:00:15,004 - INFO - > Epoch 26: took 17.0s (avg 17.3s) | Best so far: epoch 26	train_loss: 0.4309 train_accuracy: 0.8477	val_loss: 0.3813 val_accuracy: 0.8740	test_loss: 0.4251 test_accuracy: 0.8390
2025-08-23 10:00:29,367 - INFO - train: {'epoch': 27, 'time_epoch': 14.3461, 'eta': 1042.70187, 'eta_hours': 0.28964, 'loss': 0.41366064, 'lr': 0.00045726, 'params': 210889, 'time_iter': 0.06551, 'accuracy': 0.862, 'f1': 0.86359, 'auc': 0.97152}
2025-08-23 10:00:30,274 - INFO - val: {'epoch': 27, 'time_epoch': 0.89567, 'loss': 0.35976816, 'lr': 0, 'params': 210889, 'time_iter': 0.02799, 'accuracy': 0.886, 'f1': 0.88963, 'auc': 0.98296}
2025-08-23 10:00:32,077 - INFO - test: {'epoch': 27, 'time_epoch': 1.79208, 'loss': 0.39899182, 'lr': 0, 'params': 210889, 'time_iter': 0.02845, 'accuracy': 0.86, 'f1': 0.86561, 'auc': 0.97783}
2025-08-23 10:00:32,079 - INFO - > Epoch 27: took 17.1s (avg 17.2s) | Best so far: epoch 27	train_loss: 0.4137 train_accuracy: 0.8620	val_loss: 0.3598 val_accuracy: 0.8860	test_loss: 0.3990 test_accuracy: 0.8600
2025-08-23 10:00:46,534 - INFO - train: {'epoch': 28, 'time_epoch': 14.43793, 'eta': 1028.11208, 'eta_hours': 0.28559, 'loss': 0.39576574, 'lr': 0.00045225, 'params': 210889, 'time_iter': 0.06593, 'accuracy': 0.86743, 'f1': 0.86901, 'auc': 0.97329}
2025-08-23 10:00:47,441 - INFO - val: {'epoch': 28, 'time_epoch': 0.89462, 'loss': 0.32404793, 'lr': 0, 'params': 210889, 'time_iter': 0.02796, 'accuracy': 0.904, 'f1': 0.904, 'auc': 0.98419}
2025-08-23 10:00:49,255 - INFO - test: {'epoch': 28, 'time_epoch': 1.80156, 'loss': 0.37598679, 'lr': 0, 'params': 210889, 'time_iter': 0.0286, 'accuracy': 0.871, 'f1': 0.87227, 'auc': 0.97843}
2025-08-23 10:00:49,257 - INFO - > Epoch 28: took 17.2s (avg 17.2s) | Best so far: epoch 28	train_loss: 0.3958 train_accuracy: 0.8674	val_loss: 0.3240 val_accuracy: 0.9040	test_loss: 0.3760 test_accuracy: 0.8710
2025-08-23 10:01:03,676 - INFO - train: {'epoch': 29, 'time_epoch': 14.40191, 'eta': 1013.44836, 'eta_hours': 0.28151, 'loss': 0.37226642, 'lr': 0.000447, 'params': 210889, 'time_iter': 0.06576, 'accuracy': 0.87743, 'f1': 0.87832, 'auc': 0.9762}
2025-08-23 10:01:04,578 - INFO - val: {'epoch': 29, 'time_epoch': 0.8902, 'loss': 0.38870536, 'lr': 0, 'params': 210889, 'time_iter': 0.02782, 'accuracy': 0.872, 'f1': 0.87428, 'auc': 0.98161}
2025-08-23 10:01:06,388 - INFO - test: {'epoch': 29, 'time_epoch': 1.79679, 'loss': 0.40102553, 'lr': 0, 'params': 210889, 'time_iter': 0.02852, 'accuracy': 0.857, 'f1': 0.86006, 'auc': 0.97807}
2025-08-23 10:01:06,389 - INFO - > Epoch 29: took 17.1s (avg 17.2s) | Best so far: epoch 28	train_loss: 0.3958 train_accuracy: 0.8674	val_loss: 0.3240 val_accuracy: 0.9040	test_loss: 0.3760 test_accuracy: 0.8710
2025-08-23 10:01:20,734 - INFO - train: {'epoch': 30, 'time_epoch': 14.32821, 'eta': 998.6375, 'eta_hours': 0.2774, 'loss': 0.35198143, 'lr': 0.00044151, 'params': 210889, 'time_iter': 0.06543, 'accuracy': 0.882, 'f1': 0.88274, 'auc': 0.97862}
2025-08-23 10:01:21,640 - INFO - val: {'epoch': 30, 'time_epoch': 0.89403, 'loss': 0.32690282, 'lr': 0, 'params': 210889, 'time_iter': 0.02794, 'accuracy': 0.886, 'f1': 0.88716, 'auc': 0.98588}
2025-08-23 10:01:23,451 - INFO - test: {'epoch': 30, 'time_epoch': 1.79703, 'loss': 0.35233176, 'lr': 0, 'params': 210889, 'time_iter': 0.02852, 'accuracy': 0.877, 'f1': 0.87766, 'auc': 0.97991}
2025-08-23 10:01:23,453 - INFO - > Epoch 30: took 17.1s (avg 17.2s) | Best so far: epoch 28	train_loss: 0.3958 train_accuracy: 0.8674	val_loss: 0.3240 val_accuracy: 0.9040	test_loss: 0.3760 test_accuracy: 0.8710
2025-08-23 10:01:37,846 - INFO - train: {'epoch': 31, 'time_epoch': 14.37635, 'eta': 983.9591, 'eta_hours': 0.27332, 'loss': 0.34346548, 'lr': 0.00043579, 'params': 210889, 'time_iter': 0.06565, 'accuracy': 0.88686, 'f1': 0.88739, 'auc': 0.97962}
2025-08-23 10:01:38,753 - INFO - val: {'epoch': 31, 'time_epoch': 0.89358, 'loss': 0.31849835, 'lr': 0, 'params': 210889, 'time_iter': 0.02792, 'accuracy': 0.91, 'f1': 0.91068, 'auc': 0.98562}
2025-08-23 10:01:40,553 - INFO - test: {'epoch': 31, 'time_epoch': 1.7892, 'loss': 0.33548386, 'lr': 0, 'params': 210889, 'time_iter': 0.0284, 'accuracy': 0.89, 'f1': 0.89093, 'auc': 0.9812}
2025-08-23 10:01:40,555 - INFO - > Epoch 31: took 17.1s (avg 17.2s) | Best so far: epoch 31	train_loss: 0.3435 train_accuracy: 0.8869	val_loss: 0.3185 val_accuracy: 0.9100	test_loss: 0.3355 test_accuracy: 0.8900
2025-08-23 10:01:54,972 - INFO - train: {'epoch': 32, 'time_epoch': 14.40063, 'eta': 969.3483, 'eta_hours': 0.26926, 'loss': 0.32555557, 'lr': 0.00042983, 'params': 210889, 'time_iter': 0.06576, 'accuracy': 0.89371, 'f1': 0.89467, 'auc': 0.98059}
2025-08-23 10:01:55,873 - INFO - val: {'epoch': 32, 'time_epoch': 0.88871, 'loss': 0.28751358, 'lr': 0, 'params': 210889, 'time_iter': 0.02777, 'accuracy': 0.914, 'f1': 0.91615, 'auc': 0.98794}
2025-08-23 10:01:57,683 - INFO - test: {'epoch': 32, 'time_epoch': 1.79865, 'loss': 0.32610358, 'lr': 0, 'params': 210889, 'time_iter': 0.02855, 'accuracy': 0.886, 'f1': 0.88909, 'auc': 0.98297}
2025-08-23 10:01:57,685 - INFO - > Epoch 32: took 17.1s (avg 17.2s) | Best so far: epoch 32	train_loss: 0.3256 train_accuracy: 0.8937	val_loss: 0.2875 val_accuracy: 0.9140	test_loss: 0.3261 test_accuracy: 0.8860
2025-08-23 10:02:12,012 - INFO - train: {'epoch': 33, 'time_epoch': 14.30983, 'eta': 954.57361, 'eta_hours': 0.26516, 'loss': 0.32019283, 'lr': 0.00042366, 'params': 210889, 'time_iter': 0.06534, 'accuracy': 0.89486, 'f1': 0.89563, 'auc': 0.98107}
2025-08-23 10:02:12,906 - INFO - val: {'epoch': 33, 'time_epoch': 0.88338, 'loss': 0.30579338, 'lr': 0, 'params': 210889, 'time_iter': 0.02761, 'accuracy': 0.912, 'f1': 0.91365, 'auc': 0.98648}
2025-08-23 10:02:14,697 - INFO - test: {'epoch': 33, 'time_epoch': 1.77967, 'loss': 0.33494961, 'lr': 0, 'params': 210889, 'time_iter': 0.02825, 'accuracy': 0.882, 'f1': 0.88484, 'auc': 0.9824}
2025-08-23 10:02:14,699 - INFO - > Epoch 33: took 17.0s (avg 17.2s) | Best so far: epoch 32	train_loss: 0.3256 train_accuracy: 0.8937	val_loss: 0.2875 val_accuracy: 0.9140	test_loss: 0.3261 test_accuracy: 0.8860
2025-08-23 10:02:29,064 - INFO - train: {'epoch': 34, 'time_epoch': 14.34919, 'eta': 939.89857, 'eta_hours': 0.26108, 'loss': 0.30737559, 'lr': 0.00041728, 'params': 210889, 'time_iter': 0.06552, 'accuracy': 0.89571, 'f1': 0.89659, 'auc': 0.98206}
2025-08-23 10:02:29,977 - INFO - val: {'epoch': 34, 'time_epoch': 0.89492, 'loss': 0.30386691, 'lr': 0, 'params': 210889, 'time_iter': 0.02797, 'accuracy': 0.904, 'f1': 0.90723, 'auc': 0.98592}
2025-08-23 10:02:31,763 - INFO - test: {'epoch': 34, 'time_epoch': 1.77302, 'loss': 0.36848051, 'lr': 0, 'params': 210889, 'time_iter': 0.02814, 'accuracy': 0.879, 'f1': 0.88252, 'auc': 0.97892}
2025-08-23 10:02:31,765 - INFO - > Epoch 34: took 17.1s (avg 17.2s) | Best so far: epoch 32	train_loss: 0.3256 train_accuracy: 0.8937	val_loss: 0.2875 val_accuracy: 0.9140	test_loss: 0.3261 test_accuracy: 0.8860
2025-08-23 10:02:46,159 - INFO - train: {'epoch': 35, 'time_epoch': 14.37695, 'eta': 925.29099, 'eta_hours': 0.25703, 'loss': 0.31147485, 'lr': 0.0004107, 'params': 210889, 'time_iter': 0.06565, 'accuracy': 0.896, 'f1': 0.89649, 'auc': 0.98158}
2025-08-23 10:02:47,070 - INFO - val: {'epoch': 35, 'time_epoch': 0.89809, 'loss': 0.28049162, 'lr': 0, 'params': 210889, 'time_iter': 0.02807, 'accuracy': 0.92, 'f1': 0.92121, 'auc': 0.98604}
2025-08-23 10:02:48,894 - INFO - test: {'epoch': 35, 'time_epoch': 1.81152, 'loss': 0.31315536, 'lr': 0, 'params': 210889, 'time_iter': 0.02875, 'accuracy': 0.887, 'f1': 0.88831, 'auc': 0.98265}
2025-08-23 10:02:48,896 - INFO - > Epoch 35: took 17.1s (avg 17.2s) | Best so far: epoch 35	train_loss: 0.3115 train_accuracy: 0.8960	val_loss: 0.2805 val_accuracy: 0.9200	test_loss: 0.3132 test_accuracy: 0.8870
2025-08-23 10:03:03,312 - INFO - train: {'epoch': 36, 'time_epoch': 14.39902, 'eta': 910.73346, 'eta_hours': 0.25298, 'loss': 0.30665843, 'lr': 0.00040392, 'params': 210889, 'time_iter': 0.06575, 'accuracy': 0.89857, 'f1': 0.89941, 'auc': 0.98216}
2025-08-23 10:03:04,224 - INFO - val: {'epoch': 36, 'time_epoch': 0.89988, 'loss': 0.2703369, 'lr': 0, 'params': 210889, 'time_iter': 0.02812, 'accuracy': 0.91, 'f1': 0.9113, 'auc': 0.98852}
2025-08-23 10:03:06,017 - INFO - test: {'epoch': 36, 'time_epoch': 1.7607, 'loss': 0.29539632, 'lr': 0, 'params': 210889, 'time_iter': 0.02795, 'accuracy': 0.89, 'f1': 0.89073, 'auc': 0.98527}
2025-08-23 10:03:06,020 - INFO - > Epoch 36: took 17.1s (avg 17.2s) | Best so far: epoch 35	train_loss: 0.3115 train_accuracy: 0.8960	val_loss: 0.2805 val_accuracy: 0.9200	test_loss: 0.3132 test_accuracy: 0.8870
2025-08-23 10:03:19,932 - INFO - train: {'epoch': 37, 'time_epoch': 13.89851, 'eta': 895.36764, 'eta_hours': 0.24871, 'loss': 0.2995657, 'lr': 0.00039695, 'params': 210889, 'time_iter': 0.06346, 'accuracy': 0.896, 'f1': 0.8971, 'auc': 0.98235}
2025-08-23 10:03:20,811 - INFO - val: {'epoch': 37, 'time_epoch': 0.86677, 'loss': 0.26990697, 'lr': 0, 'params': 210889, 'time_iter': 0.02709, 'accuracy': 0.914, 'f1': 0.91634, 'auc': 0.98853}
2025-08-23 10:03:22,570 - INFO - test: {'epoch': 37, 'time_epoch': 1.74607, 'loss': 0.31034028, 'lr': 0, 'params': 210889, 'time_iter': 0.02772, 'accuracy': 0.89, 'f1': 0.89286, 'auc': 0.98502}
2025-08-23 10:03:22,572 - INFO - > Epoch 37: took 16.6s (avg 17.2s) | Best so far: epoch 35	train_loss: 0.3115 train_accuracy: 0.8960	val_loss: 0.2805 val_accuracy: 0.9200	test_loss: 0.3132 test_accuracy: 0.8870
2025-08-23 10:03:36,429 - INFO - train: {'epoch': 38, 'time_epoch': 13.84435, 'eta': 879.99236, 'eta_hours': 0.24444, 'loss': 0.2935525, 'lr': 0.0003898, 'params': 210889, 'time_iter': 0.06322, 'accuracy': 0.90057, 'f1': 0.90188, 'auc': 0.98314}
2025-08-23 10:03:37,304 - INFO - val: {'epoch': 38, 'time_epoch': 0.8622, 'loss': 0.25838275, 'lr': 0, 'params': 210889, 'time_iter': 0.02694, 'accuracy': 0.926, 'f1': 0.92742, 'auc': 0.98911}
2025-08-23 10:03:39,055 - INFO - test: {'epoch': 38, 'time_epoch': 1.73995, 'loss': 0.2932658, 'lr': 0, 'params': 210889, 'time_iter': 0.02762, 'accuracy': 0.894, 'f1': 0.89686, 'auc': 0.98555}
2025-08-23 10:03:39,061 - INFO - > Epoch 38: took 16.5s (avg 17.2s) | Best so far: epoch 38	train_loss: 0.2936 train_accuracy: 0.9006	val_loss: 0.2584 val_accuracy: 0.9260	test_loss: 0.2933 test_accuracy: 0.8940
2025-08-23 10:03:52,911 - INFO - train: {'epoch': 39, 'time_epoch': 13.83623, 'eta': 864.68144, 'eta_hours': 0.24019, 'loss': 0.28459139, 'lr': 0.00038248, 'params': 210889, 'time_iter': 0.06318, 'accuracy': 0.908, 'f1': 0.90875, 'auc': 0.98393}
2025-08-23 10:03:53,792 - INFO - val: {'epoch': 39, 'time_epoch': 0.86936, 'loss': 0.30918688, 'lr': 0, 'params': 210889, 'time_iter': 0.02717, 'accuracy': 0.898, 'f1': 0.8995, 'auc': 0.98762}
2025-08-23 10:03:55,558 - INFO - test: {'epoch': 39, 'time_epoch': 1.75538, 'loss': 0.3078017, 'lr': 0, 'params': 210889, 'time_iter': 0.02786, 'accuracy': 0.891, 'f1': 0.89321, 'auc': 0.98444}
2025-08-23 10:03:55,559 - INFO - > Epoch 39: took 16.5s (avg 17.2s) | Best so far: epoch 38	train_loss: 0.2936 train_accuracy: 0.9006	val_loss: 0.2584 val_accuracy: 0.9260	test_loss: 0.2933 test_accuracy: 0.8940
2025-08-23 10:04:09,418 - INFO - train: {'epoch': 40, 'time_epoch': 13.84529, 'eta': 849.4555, 'eta_hours': 0.23596, 'loss': 0.27425086, 'lr': 0.000375, 'params': 210889, 'time_iter': 0.06322, 'accuracy': 0.90886, 'f1': 0.90916, 'auc': 0.98484}
2025-08-23 10:04:10,305 - INFO - val: {'epoch': 40, 'time_epoch': 0.86617, 'loss': 0.32300591, 'lr': 0, 'params': 210889, 'time_iter': 0.02707, 'accuracy': 0.876, 'f1': 0.87773, 'auc': 0.98715}
2025-08-23 10:04:12,062 - INFO - test: {'epoch': 40, 'time_epoch': 1.73967, 'loss': 0.32050469, 'lr': 0, 'params': 210889, 'time_iter': 0.02761, 'accuracy': 0.887, 'f1': 0.88853, 'auc': 0.98417}
2025-08-23 10:04:12,070 - INFO - > Epoch 40: took 16.5s (avg 17.1s) | Best so far: epoch 38	train_loss: 0.2936 train_accuracy: 0.9006	val_loss: 0.2584 val_accuracy: 0.9260	test_loss: 0.2933 test_accuracy: 0.8940
2025-08-23 10:04:25,936 - INFO - train: {'epoch': 41, 'time_epoch': 13.85329, 'eta': 834.30635, 'eta_hours': 0.23175, 'loss': 0.27270502, 'lr': 0.00036737, 'params': 210889, 'time_iter': 0.06326, 'accuracy': 0.912, 'f1': 0.91274, 'auc': 0.98492}
2025-08-23 10:04:26,827 - INFO - val: {'epoch': 41, 'time_epoch': 0.88032, 'loss': 0.24472224, 'lr': 0, 'params': 210889, 'time_iter': 0.02751, 'accuracy': 0.93, 'f1': 0.93008, 'auc': 0.98932}
2025-08-23 10:04:28,603 - INFO - test: {'epoch': 41, 'time_epoch': 1.74419, 'loss': 0.29517656, 'lr': 0, 'params': 210889, 'time_iter': 0.02769, 'accuracy': 0.899, 'f1': 0.8996, 'auc': 0.98442}
2025-08-23 10:04:28,605 - INFO - > Epoch 41: took 16.5s (avg 17.1s) | Best so far: epoch 41	train_loss: 0.2727 train_accuracy: 0.9120	val_loss: 0.2447 val_accuracy: 0.9300	test_loss: 0.2952 test_accuracy: 0.8990
2025-08-23 10:04:42,482 - INFO - train: {'epoch': 42, 'time_epoch': 13.86305, 'eta': 819.23041, 'eta_hours': 0.22756, 'loss': 0.26748333, 'lr': 0.00035959, 'params': 210889, 'time_iter': 0.0633, 'accuracy': 0.90829, 'f1': 0.90897, 'auc': 0.98503}
2025-08-23 10:04:43,366 - INFO - val: {'epoch': 42, 'time_epoch': 0.86064, 'loss': 0.4299461, 'lr': 0, 'params': 210889, 'time_iter': 0.0269, 'accuracy': 0.824, 'f1': 0.82892, 'auc': 0.98338}
2025-08-23 10:04:45,140 - INFO - test: {'epoch': 42, 'time_epoch': 1.73266, 'loss': 0.41209545, 'lr': 0, 'params': 210889, 'time_iter': 0.0275, 'accuracy': 0.837, 'f1': 0.83987, 'auc': 0.97893}
2025-08-23 10:04:45,179 - INFO - > Epoch 42: took 16.6s (avg 17.1s) | Best so far: epoch 41	train_loss: 0.2727 train_accuracy: 0.9120	val_loss: 0.2447 val_accuracy: 0.9300	test_loss: 0.2952 test_accuracy: 0.8990
2025-08-23 10:04:59,009 - INFO - train: {'epoch': 43, 'time_epoch': 13.81735, 'eta': 804.15144, 'eta_hours': 0.22338, 'loss': 0.26663968, 'lr': 0.00035168, 'params': 210889, 'time_iter': 0.06309, 'accuracy': 0.91114, 'f1': 0.91193, 'auc': 0.98526}
2025-08-23 10:04:59,881 - INFO - val: {'epoch': 43, 'time_epoch': 0.8606, 'loss': 0.27763492, 'lr': 0, 'params': 210889, 'time_iter': 0.02689, 'accuracy': 0.904, 'f1': 0.90421, 'auc': 0.98734}
2025-08-23 10:05:01,629 - INFO - test: {'epoch': 43, 'time_epoch': 1.73695, 'loss': 0.33624301, 'lr': 0, 'params': 210889, 'time_iter': 0.02757, 'accuracy': 0.876, 'f1': 0.87604, 'auc': 0.98252}
2025-08-23 10:05:01,631 - INFO - > Epoch 43: took 16.5s (avg 17.1s) | Best so far: epoch 41	train_loss: 0.2727 train_accuracy: 0.9120	val_loss: 0.2447 val_accuracy: 0.9300	test_loss: 0.2952 test_accuracy: 0.8990
2025-08-23 10:05:15,453 - INFO - train: {'epoch': 44, 'time_epoch': 13.8094, 'eta': 789.11883, 'eta_hours': 0.2192, 'loss': 0.26714193, 'lr': 0.00034365, 'params': 210889, 'time_iter': 0.06306, 'accuracy': 0.90829, 'f1': 0.90863, 'auc': 0.98499}
2025-08-23 10:05:16,389 - INFO - val: {'epoch': 44, 'time_epoch': 0.8624, 'loss': 0.26868216, 'lr': 0, 'params': 210889, 'time_iter': 0.02695, 'accuracy': 0.906, 'f1': 0.90643, 'auc': 0.98771}
2025-08-23 10:05:18,155 - INFO - test: {'epoch': 44, 'time_epoch': 1.73074, 'loss': 0.29232126, 'lr': 0, 'params': 210889, 'time_iter': 0.02747, 'accuracy': 0.893, 'f1': 0.89375, 'auc': 0.98426}
2025-08-23 10:05:18,194 - INFO - > Epoch 44: took 16.6s (avg 17.1s) | Best so far: epoch 41	train_loss: 0.2727 train_accuracy: 0.9120	val_loss: 0.2447 val_accuracy: 0.9300	test_loss: 0.2952 test_accuracy: 0.8990
2025-08-23 10:05:32,054 - INFO - train: {'epoch': 45, 'time_epoch': 13.83162, 'eta': 774.16547, 'eta_hours': 0.21505, 'loss': 0.25078654, 'lr': 0.00033551, 'params': 210889, 'time_iter': 0.06316, 'accuracy': 0.91629, 'f1': 0.91738, 'auc': 0.98645}
2025-08-23 10:05:32,966 - INFO - val: {'epoch': 45, 'time_epoch': 0.86059, 'loss': 0.28477726, 'lr': 0, 'params': 210889, 'time_iter': 0.02689, 'accuracy': 0.904, 'f1': 0.90413, 'auc': 0.98991}
2025-08-23 10:05:34,746 - INFO - test: {'epoch': 45, 'time_epoch': 1.73031, 'loss': 0.31590511, 'lr': 0, 'params': 210889, 'time_iter': 0.02747, 'accuracy': 0.889, 'f1': 0.88881, 'auc': 0.98434}
2025-08-23 10:05:34,778 - INFO - > Epoch 45: took 16.6s (avg 17.1s) | Best so far: epoch 41	train_loss: 0.2727 train_accuracy: 0.9120	val_loss: 0.2447 val_accuracy: 0.9300	test_loss: 0.2952 test_accuracy: 0.8990
2025-08-23 10:05:48,634 - INFO - train: {'epoch': 46, 'time_epoch': 13.84299, 'eta': 759.27268, 'eta_hours': 0.21091, 'loss': 0.26342452, 'lr': 0.00032725, 'params': 210889, 'time_iter': 0.06321, 'accuracy': 0.91029, 'f1': 0.91119, 'auc': 0.98639}
2025-08-23 10:05:49,513 - INFO - val: {'epoch': 46, 'time_epoch': 0.86788, 'loss': 0.24237241, 'lr': 0, 'params': 210889, 'time_iter': 0.02712, 'accuracy': 0.924, 'f1': 0.92515, 'auc': 0.9905}
2025-08-23 10:05:51,303 - INFO - test: {'epoch': 46, 'time_epoch': 1.74397, 'loss': 0.27162882, 'lr': 0, 'params': 210889, 'time_iter': 0.02768, 'accuracy': 0.893, 'f1': 0.89456, 'auc': 0.98626}
2025-08-23 10:05:51,315 - INFO - > Epoch 46: took 16.5s (avg 17.1s) | Best so far: epoch 41	train_loss: 0.2727 train_accuracy: 0.9120	val_loss: 0.2447 val_accuracy: 0.9300	test_loss: 0.2952 test_accuracy: 0.8990
2025-08-23 10:06:05,185 - INFO - train: {'epoch': 47, 'time_epoch': 13.85787, 'eta': 744.43975, 'eta_hours': 0.20679, 'loss': 0.24409344, 'lr': 0.00031891, 'params': 210889, 'time_iter': 0.06328, 'accuracy': 0.91314, 'f1': 0.91377, 'auc': 0.98752}
2025-08-23 10:06:06,063 - INFO - val: {'epoch': 47, 'time_epoch': 0.86374, 'loss': 0.24981588, 'lr': 0, 'params': 210889, 'time_iter': 0.02699, 'accuracy': 0.916, 'f1': 0.91543, 'auc': 0.99073}
2025-08-23 10:06:07,833 - INFO - test: {'epoch': 47, 'time_epoch': 1.75922, 'loss': 0.28064306, 'lr': 0, 'params': 210889, 'time_iter': 0.02792, 'accuracy': 0.904, 'f1': 0.90359, 'auc': 0.98571}
2025-08-23 10:06:07,834 - INFO - > Epoch 47: took 16.5s (avg 17.1s) | Best so far: epoch 41	train_loss: 0.2727 train_accuracy: 0.9120	val_loss: 0.2447 val_accuracy: 0.9300	test_loss: 0.2952 test_accuracy: 0.8990
2025-08-23 10:06:21,664 - INFO - train: {'epoch': 48, 'time_epoch': 13.81556, 'eta': 729.60257, 'eta_hours': 0.20267, 'loss': 0.23998722, 'lr': 0.00031048, 'params': 210889, 'time_iter': 0.06308, 'accuracy': 0.92114, 'f1': 0.92174, 'auc': 0.98731}
2025-08-23 10:06:22,536 - INFO - val: {'epoch': 48, 'time_epoch': 0.86153, 'loss': 0.23975659, 'lr': 0, 'params': 210889, 'time_iter': 0.02692, 'accuracy': 0.918, 'f1': 0.91937, 'auc': 0.98998}
2025-08-23 10:06:24,289 - INFO - test: {'epoch': 48, 'time_epoch': 1.74322, 'loss': 0.26950678, 'lr': 0, 'params': 210889, 'time_iter': 0.02767, 'accuracy': 0.898, 'f1': 0.89975, 'auc': 0.98602}
2025-08-23 10:06:24,291 - INFO - > Epoch 48: took 16.5s (avg 17.0s) | Best so far: epoch 41	train_loss: 0.2727 train_accuracy: 0.9120	val_loss: 0.2447 val_accuracy: 0.9300	test_loss: 0.2952 test_accuracy: 0.8990
2025-08-23 10:06:38,167 - INFO - train: {'epoch': 49, 'time_epoch': 13.86015, 'eta': 714.85086, 'eta_hours': 0.19857, 'loss': 0.24723196, 'lr': 0.00030198, 'params': 210889, 'time_iter': 0.06329, 'accuracy': 0.91629, 'f1': 0.91691, 'auc': 0.98681}
2025-08-23 10:06:39,039 - INFO - val: {'epoch': 49, 'time_epoch': 0.86225, 'loss': 0.31301318, 'lr': 0, 'params': 210889, 'time_iter': 0.02695, 'accuracy': 0.88, 'f1': 0.88161, 'auc': 0.98884}
2025-08-23 10:06:40,804 - INFO - test: {'epoch': 49, 'time_epoch': 1.75417, 'loss': 0.31034253, 'lr': 0, 'params': 210889, 'time_iter': 0.02784, 'accuracy': 0.889, 'f1': 0.89077, 'auc': 0.98487}
2025-08-23 10:06:40,806 - INFO - > Epoch 49: took 16.5s (avg 17.0s) | Best so far: epoch 41	train_loss: 0.2727 train_accuracy: 0.9120	val_loss: 0.2447 val_accuracy: 0.9300	test_loss: 0.2952 test_accuracy: 0.8990
2025-08-23 10:06:54,674 - INFO - train: {'epoch': 50, 'time_epoch': 13.8525, 'eta': 700.12676, 'eta_hours': 0.19448, 'loss': 0.22900177, 'lr': 0.00029341, 'params': 210889, 'time_iter': 0.06325, 'accuracy': 0.926, 'f1': 0.92623, 'auc': 0.98821}
2025-08-23 10:06:55,547 - INFO - val: {'epoch': 50, 'time_epoch': 0.86297, 'loss': 0.2292215, 'lr': 0, 'params': 210889, 'time_iter': 0.02697, 'accuracy': 0.932, 'f1': 0.93259, 'auc': 0.99093}
2025-08-23 10:06:57,317 - INFO - test: {'epoch': 50, 'time_epoch': 1.75856, 'loss': 0.29805211, 'lr': 0, 'params': 210889, 'time_iter': 0.02791, 'accuracy': 0.899, 'f1': 0.89936, 'auc': 0.98514}
2025-08-23 10:06:57,319 - INFO - > Epoch 50: took 16.5s (avg 17.0s) | Best so far: epoch 50	train_loss: 0.2290 train_accuracy: 0.9260	val_loss: 0.2292 val_accuracy: 0.9320	test_loss: 0.2981 test_accuracy: 0.8990
2025-08-23 10:07:11,249 - INFO - train: {'epoch': 51, 'time_epoch': 13.91478, 'eta': 685.49367, 'eta_hours': 0.19041, 'loss': 0.24168304, 'lr': 0.00028479, 'params': 210889, 'time_iter': 0.06354, 'accuracy': 0.91829, 'f1': 0.9187, 'auc': 0.98764}
2025-08-23 10:07:12,126 - INFO - val: {'epoch': 51, 'time_epoch': 0.86646, 'loss': 0.22470727, 'lr': 0, 'params': 210889, 'time_iter': 0.02708, 'accuracy': 0.922, 'f1': 0.92281, 'auc': 0.99102}
2025-08-23 10:07:13,887 - INFO - test: {'epoch': 51, 'time_epoch': 1.75099, 'loss': 0.26050103, 'lr': 0, 'params': 210889, 'time_iter': 0.02779, 'accuracy': 0.914, 'f1': 0.91478, 'auc': 0.98707}
2025-08-23 10:07:13,889 - INFO - > Epoch 51: took 16.6s (avg 17.0s) | Best so far: epoch 50	train_loss: 0.2290 train_accuracy: 0.9260	val_loss: 0.2292 val_accuracy: 0.9320	test_loss: 0.2981 test_accuracy: 0.8990
2025-08-23 10:07:28,100 - INFO - train: {'epoch': 52, 'time_epoch': 14.1949, 'eta': 671.13609, 'eta_hours': 0.18643, 'loss': 0.22608206, 'lr': 0.00027613, 'params': 210889, 'time_iter': 0.06482, 'accuracy': 0.92514, 'f1': 0.92557, 'auc': 0.98854}
2025-08-23 10:07:28,998 - INFO - val: {'epoch': 52, 'time_epoch': 0.88667, 'loss': 0.27515433, 'lr': 0, 'params': 210889, 'time_iter': 0.02771, 'accuracy': 0.908, 'f1': 0.90682, 'auc': 0.99101}
2025-08-23 10:07:30,773 - INFO - test: {'epoch': 52, 'time_epoch': 1.765, 'loss': 0.31242008, 'lr': 0, 'params': 210889, 'time_iter': 0.02802, 'accuracy': 0.899, 'f1': 0.8979, 'auc': 0.98592}
2025-08-23 10:07:30,775 - INFO - > Epoch 52: took 16.9s (avg 17.0s) | Best so far: epoch 50	train_loss: 0.2290 train_accuracy: 0.9260	val_loss: 0.2292 val_accuracy: 0.9320	test_loss: 0.2981 test_accuracy: 0.8990
2025-08-23 10:07:45,010 - INFO - train: {'epoch': 53, 'time_epoch': 14.21915, 'eta': 656.8052, 'eta_hours': 0.18245, 'loss': 0.23603299, 'lr': 0.00026744, 'params': 210889, 'time_iter': 0.06493, 'accuracy': 0.91886, 'f1': 0.91926, 'auc': 0.98799}
2025-08-23 10:07:45,908 - INFO - val: {'epoch': 53, 'time_epoch': 0.88603, 'loss': 0.2922346, 'lr': 0, 'params': 210889, 'time_iter': 0.02769, 'accuracy': 0.912, 'f1': 0.91287, 'auc': 0.98972}
2025-08-23 10:07:47,701 - INFO - test: {'epoch': 53, 'time_epoch': 1.7824, 'loss': 0.3198468, 'lr': 0, 'params': 210889, 'time_iter': 0.02829, 'accuracy': 0.89, 'f1': 0.8911, 'auc': 0.98494}
2025-08-23 10:07:47,703 - INFO - > Epoch 53: took 16.9s (avg 17.0s) | Best so far: epoch 50	train_loss: 0.2290 train_accuracy: 0.9260	val_loss: 0.2292 val_accuracy: 0.9320	test_loss: 0.2981 test_accuracy: 0.8990
2025-08-23 10:08:01,966 - INFO - train: {'epoch': 54, 'time_epoch': 14.24598, 'eta': 642.50032, 'eta_hours': 0.17847, 'loss': 0.22207578, 'lr': 0.00025872, 'params': 210889, 'time_iter': 0.06505, 'accuracy': 0.92457, 'f1': 0.92523, 'auc': 0.98848}
2025-08-23 10:08:02,861 - INFO - val: {'epoch': 54, 'time_epoch': 0.88446, 'loss': 0.22869688, 'lr': 0, 'params': 210889, 'time_iter': 0.02764, 'accuracy': 0.928, 'f1': 0.92877, 'auc': 0.99058}
2025-08-23 10:08:04,637 - INFO - test: {'epoch': 54, 'time_epoch': 1.76529, 'loss': 0.26840991, 'lr': 0, 'params': 210889, 'time_iter': 0.02802, 'accuracy': 0.907, 'f1': 0.90803, 'auc': 0.98661}
2025-08-23 10:08:04,639 - INFO - > Epoch 54: took 16.9s (avg 17.0s) | Best so far: epoch 50	train_loss: 0.2290 train_accuracy: 0.9260	val_loss: 0.2292 val_accuracy: 0.9320	test_loss: 0.2981 test_accuracy: 0.8990
2025-08-23 10:08:18,926 - INFO - train: {'epoch': 55, 'time_epoch': 14.27049, 'eta': 628.2168, 'eta_hours': 0.1745, 'loss': 0.2290752, 'lr': 0.00025, 'params': 210889, 'time_iter': 0.06516, 'accuracy': 0.92686, 'f1': 0.92717, 'auc': 0.98793}
2025-08-23 10:08:19,816 - INFO - val: {'epoch': 55, 'time_epoch': 0.8787, 'loss': 0.24897472, 'lr': 0, 'params': 210889, 'time_iter': 0.02746, 'accuracy': 0.914, 'f1': 0.91518, 'auc': 0.99088}
2025-08-23 10:08:21,596 - INFO - test: {'epoch': 55, 'time_epoch': 1.76994, 'loss': 0.26169431, 'lr': 0, 'params': 210889, 'time_iter': 0.02809, 'accuracy': 0.908, 'f1': 0.90973, 'auc': 0.98767}
2025-08-23 10:08:21,598 - INFO - > Epoch 55: took 17.0s (avg 17.0s) | Best so far: epoch 50	train_loss: 0.2290 train_accuracy: 0.9260	val_loss: 0.2292 val_accuracy: 0.9320	test_loss: 0.2981 test_accuracy: 0.8990
2025-08-23 10:08:35,794 - INFO - train: {'epoch': 56, 'time_epoch': 14.18153, 'eta': 613.86663, 'eta_hours': 0.17052, 'loss': 0.2196141, 'lr': 0.00024128, 'params': 210889, 'time_iter': 0.06476, 'accuracy': 0.92743, 'f1': 0.92777, 'auc': 0.98898}
2025-08-23 10:08:36,668 - INFO - val: {'epoch': 56, 'time_epoch': 0.86223, 'loss': 0.25459581, 'lr': 0, 'params': 210889, 'time_iter': 0.02694, 'accuracy': 0.92, 'f1': 0.92148, 'auc': 0.99126}
2025-08-23 10:08:38,411 - INFO - test: {'epoch': 56, 'time_epoch': 1.73272, 'loss': 0.29460116, 'lr': 0, 'params': 210889, 'time_iter': 0.0275, 'accuracy': 0.894, 'f1': 0.89591, 'auc': 0.9874}
2025-08-23 10:08:38,413 - INFO - > Epoch 56: took 16.8s (avg 17.0s) | Best so far: epoch 50	train_loss: 0.2290 train_accuracy: 0.9260	val_loss: 0.2292 val_accuracy: 0.9320	test_loss: 0.2981 test_accuracy: 0.8990
2025-08-23 10:08:52,633 - INFO - train: {'epoch': 57, 'time_epoch': 14.2051, 'eta': 599.53935, 'eta_hours': 0.16654, 'loss': 0.21979631, 'lr': 0.00023256, 'params': 210889, 'time_iter': 0.06486, 'accuracy': 0.924, 'f1': 0.92434, 'auc': 0.98896}
2025-08-23 10:08:53,522 - INFO - val: {'epoch': 57, 'time_epoch': 0.87783, 'loss': 0.25151885, 'lr': 0, 'params': 210889, 'time_iter': 0.02743, 'accuracy': 0.908, 'f1': 0.90931, 'auc': 0.99021}
2025-08-23 10:08:55,299 - INFO - test: {'epoch': 57, 'time_epoch': 1.76764, 'loss': 0.24667178, 'lr': 0, 'params': 210889, 'time_iter': 0.02806, 'accuracy': 0.911, 'f1': 0.9123, 'auc': 0.98808}
2025-08-23 10:08:55,301 - INFO - > Epoch 57: took 16.9s (avg 17.0s) | Best so far: epoch 50	train_loss: 0.2290 train_accuracy: 0.9260	val_loss: 0.2292 val_accuracy: 0.9320	test_loss: 0.2981 test_accuracy: 0.8990
2025-08-23 10:09:09,380 - INFO - train: {'epoch': 58, 'time_epoch': 14.06501, 'eta': 585.11885, 'eta_hours': 0.16253, 'loss': 0.21392285, 'lr': 0.00022387, 'params': 210889, 'time_iter': 0.06422, 'accuracy': 0.92486, 'f1': 0.92514, 'auc': 0.98993}
2025-08-23 10:09:10,250 - INFO - val: {'epoch': 58, 'time_epoch': 0.85891, 'loss': 0.23287012, 'lr': 0, 'params': 210889, 'time_iter': 0.02684, 'accuracy': 0.922, 'f1': 0.92332, 'auc': 0.99088}
2025-08-23 10:09:12,018 - INFO - test: {'epoch': 58, 'time_epoch': 1.75761, 'loss': 0.26825237, 'lr': 0, 'params': 210889, 'time_iter': 0.0279, 'accuracy': 0.915, 'f1': 0.91616, 'auc': 0.98694}
2025-08-23 10:09:12,020 - INFO - > Epoch 58: took 16.7s (avg 17.0s) | Best so far: epoch 50	train_loss: 0.2290 train_accuracy: 0.9260	val_loss: 0.2292 val_accuracy: 0.9320	test_loss: 0.2981 test_accuracy: 0.8990
2025-08-23 10:09:26,213 - INFO - train: {'epoch': 59, 'time_epoch': 14.17821, 'eta': 570.78568, 'eta_hours': 0.15855, 'loss': 0.2107841, 'lr': 0.00021521, 'params': 210889, 'time_iter': 0.06474, 'accuracy': 0.92971, 'f1': 0.92987, 'auc': 0.98966}
2025-08-23 10:09:27,090 - INFO - val: {'epoch': 59, 'time_epoch': 0.86639, 'loss': 0.22394517, 'lr': 0, 'params': 210889, 'time_iter': 0.02707, 'accuracy': 0.93, 'f1': 0.93031, 'auc': 0.99032}
2025-08-23 10:09:28,856 - INFO - test: {'epoch': 59, 'time_epoch': 1.75462, 'loss': 0.28533035, 'lr': 0, 'params': 210889, 'time_iter': 0.02785, 'accuracy': 0.907, 'f1': 0.90731, 'auc': 0.98514}
2025-08-23 10:09:28,858 - INFO - > Epoch 59: took 16.8s (avg 17.0s) | Best so far: epoch 50	train_loss: 0.2290 train_accuracy: 0.9260	val_loss: 0.2292 val_accuracy: 0.9320	test_loss: 0.2981 test_accuracy: 0.8990
2025-08-23 10:09:42,800 - INFO - train: {'epoch': 60, 'time_epoch': 13.92898, 'eta': 556.29823, 'eta_hours': 0.15453, 'loss': 0.21169846, 'lr': 0.00020659, 'params': 210889, 'time_iter': 0.0636, 'accuracy': 0.92829, 'f1': 0.92839, 'auc': 0.99008}
2025-08-23 10:09:43,683 - INFO - val: {'epoch': 60, 'time_epoch': 0.87116, 'loss': 0.24732418, 'lr': 0, 'params': 210889, 'time_iter': 0.02722, 'accuracy': 0.92, 'f1': 0.92024, 'auc': 0.99034}
2025-08-23 10:09:45,485 - INFO - test: {'epoch': 60, 'time_epoch': 1.79194, 'loss': 0.28963834, 'lr': 0, 'params': 210889, 'time_iter': 0.02844, 'accuracy': 0.906, 'f1': 0.90616, 'auc': 0.98474}
2025-08-23 10:09:45,487 - INFO - > Epoch 60: took 16.6s (avg 17.0s) | Best so far: epoch 50	train_loss: 0.2290 train_accuracy: 0.9260	val_loss: 0.2292 val_accuracy: 0.9320	test_loss: 0.2981 test_accuracy: 0.8990
2025-08-23 10:09:59,477 - INFO - train: {'epoch': 61, 'time_epoch': 13.97607, 'eta': 541.85767, 'eta_hours': 0.15052, 'loss': 0.20151424, 'lr': 0.00019802, 'params': 210889, 'time_iter': 0.06382, 'accuracy': 0.93171, 'f1': 0.93199, 'auc': 0.99071}
2025-08-23 10:10:00,365 - INFO - val: {'epoch': 61, 'time_epoch': 0.87741, 'loss': 0.22167162, 'lr': 0, 'params': 210889, 'time_iter': 0.02742, 'accuracy': 0.926, 'f1': 0.92674, 'auc': 0.99234}
2025-08-23 10:10:02,121 - INFO - test: {'epoch': 61, 'time_epoch': 1.74575, 'loss': 0.25010839, 'lr': 0, 'params': 210889, 'time_iter': 0.02771, 'accuracy': 0.917, 'f1': 0.91811, 'auc': 0.98779}
2025-08-23 10:10:02,123 - INFO - > Epoch 61: took 16.6s (avg 17.0s) | Best so far: epoch 50	train_loss: 0.2290 train_accuracy: 0.9260	val_loss: 0.2292 val_accuracy: 0.9320	test_loss: 0.2981 test_accuracy: 0.8990
2025-08-23 10:10:16,286 - INFO - train: {'epoch': 62, 'time_epoch': 14.14775, 'eta': 527.53268, 'eta_hours': 0.14654, 'loss': 0.20164741, 'lr': 0.00018952, 'params': 210889, 'time_iter': 0.0646, 'accuracy': 0.93086, 'f1': 0.93115, 'auc': 0.9902}
2025-08-23 10:10:17,162 - INFO - val: {'epoch': 62, 'time_epoch': 0.8643, 'loss': 0.22876379, 'lr': 0, 'params': 210889, 'time_iter': 0.02701, 'accuracy': 0.92, 'f1': 0.92127, 'auc': 0.99133}
2025-08-23 10:10:18,904 - INFO - test: {'epoch': 62, 'time_epoch': 1.73262, 'loss': 0.24963972, 'lr': 0, 'params': 210889, 'time_iter': 0.0275, 'accuracy': 0.915, 'f1': 0.916, 'auc': 0.98789}
2025-08-23 10:10:18,906 - INFO - > Epoch 62: took 16.8s (avg 17.0s) | Best so far: epoch 50	train_loss: 0.2290 train_accuracy: 0.9260	val_loss: 0.2292 val_accuracy: 0.9320	test_loss: 0.2981 test_accuracy: 0.8990
2025-08-23 10:10:33,090 - INFO - train: {'epoch': 63, 'time_epoch': 14.16898, 'eta': 513.22517, 'eta_hours': 0.14256, 'loss': 0.20251295, 'lr': 0.00018109, 'params': 210889, 'time_iter': 0.0647, 'accuracy': 0.936, 'f1': 0.93588, 'auc': 0.99025}
2025-08-23 10:10:33,973 - INFO - val: {'epoch': 63, 'time_epoch': 0.87267, 'loss': 0.23349505, 'lr': 0, 'params': 210889, 'time_iter': 0.02727, 'accuracy': 0.928, 'f1': 0.92922, 'auc': 0.99107}
2025-08-23 10:10:35,752 - INFO - test: {'epoch': 63, 'time_epoch': 1.76893, 'loss': 0.2638876, 'lr': 0, 'params': 210889, 'time_iter': 0.02808, 'accuracy': 0.906, 'f1': 0.90796, 'auc': 0.98759}
2025-08-23 10:10:35,754 - INFO - > Epoch 63: took 16.8s (avg 17.0s) | Best so far: epoch 50	train_loss: 0.2290 train_accuracy: 0.9260	val_loss: 0.2292 val_accuracy: 0.9320	test_loss: 0.2981 test_accuracy: 0.8990
2025-08-23 10:10:49,933 - INFO - train: {'epoch': 64, 'time_epoch': 14.16442, 'eta': 498.91946, 'eta_hours': 0.13859, 'loss': 0.20105053, 'lr': 0.00017275, 'params': 210889, 'time_iter': 0.06468, 'accuracy': 0.93371, 'f1': 0.93379, 'auc': 0.99055}
2025-08-23 10:10:50,820 - INFO - val: {'epoch': 64, 'time_epoch': 0.87616, 'loss': 0.2153948, 'lr': 0, 'params': 210889, 'time_iter': 0.02738, 'accuracy': 0.938, 'f1': 0.93798, 'auc': 0.98996}
2025-08-23 10:10:52,593 - INFO - test: {'epoch': 64, 'time_epoch': 1.76191, 'loss': 0.26208399, 'lr': 0, 'params': 210889, 'time_iter': 0.02797, 'accuracy': 0.914, 'f1': 0.91364, 'auc': 0.98499}
2025-08-23 10:10:52,594 - INFO - > Epoch 64: took 16.8s (avg 17.0s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:11:06,792 - INFO - train: {'epoch': 65, 'time_epoch': 14.1825, 'eta': 484.62735, 'eta_hours': 0.13462, 'loss': 0.19675966, 'lr': 0.00016449, 'params': 210889, 'time_iter': 0.06476, 'accuracy': 0.932, 'f1': 0.93217, 'auc': 0.99066}
2025-08-23 10:11:07,683 - INFO - val: {'epoch': 65, 'time_epoch': 0.88061, 'loss': 0.22567745, 'lr': 0, 'params': 210889, 'time_iter': 0.02752, 'accuracy': 0.924, 'f1': 0.92534, 'auc': 0.9914}
2025-08-23 10:11:09,467 - INFO - test: {'epoch': 65, 'time_epoch': 1.7735, 'loss': 0.25961936, 'lr': 0, 'params': 210889, 'time_iter': 0.02815, 'accuracy': 0.905, 'f1': 0.90688, 'auc': 0.98806}
2025-08-23 10:11:09,469 - INFO - > Epoch 65: took 16.9s (avg 17.0s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:11:23,702 - INFO - train: {'epoch': 66, 'time_epoch': 14.21844, 'eta': 470.35622, 'eta_hours': 0.13065, 'loss': 0.1834217, 'lr': 0.00015635, 'params': 210889, 'time_iter': 0.06492, 'accuracy': 0.93686, 'f1': 0.9369, 'auc': 0.99207}
2025-08-23 10:11:24,589 - INFO - val: {'epoch': 66, 'time_epoch': 0.87587, 'loss': 0.24366547, 'lr': 0, 'params': 210889, 'time_iter': 0.02737, 'accuracy': 0.922, 'f1': 0.92245, 'auc': 0.99102}
2025-08-23 10:11:26,367 - INFO - test: {'epoch': 66, 'time_epoch': 1.7673, 'loss': 0.282077, 'lr': 0, 'params': 210889, 'time_iter': 0.02805, 'accuracy': 0.906, 'f1': 0.90733, 'auc': 0.98681}
2025-08-23 10:11:26,369 - INFO - > Epoch 66: took 16.9s (avg 17.0s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:11:40,617 - INFO - train: {'epoch': 67, 'time_epoch': 14.233, 'eta': 456.09349, 'eta_hours': 0.12669, 'loss': 0.19513442, 'lr': 0.00014832, 'params': 210889, 'time_iter': 0.06499, 'accuracy': 0.93343, 'f1': 0.93343, 'auc': 0.99164}
2025-08-23 10:11:41,510 - INFO - val: {'epoch': 67, 'time_epoch': 0.88121, 'loss': 0.23771071, 'lr': 0, 'params': 210889, 'time_iter': 0.02754, 'accuracy': 0.93, 'f1': 0.93126, 'auc': 0.99113}
2025-08-23 10:11:43,284 - INFO - test: {'epoch': 67, 'time_epoch': 1.76227, 'loss': 0.28855544, 'lr': 0, 'params': 210889, 'time_iter': 0.02797, 'accuracy': 0.906, 'f1': 0.90804, 'auc': 0.98843}
2025-08-23 10:11:43,286 - INFO - > Epoch 67: took 16.9s (avg 17.0s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:11:57,451 - INFO - train: {'epoch': 68, 'time_epoch': 14.14989, 'eta': 441.79428, 'eta_hours': 0.12272, 'loss': 0.18043731, 'lr': 0.00014041, 'params': 210889, 'time_iter': 0.06461, 'accuracy': 0.93943, 'f1': 0.93956, 'auc': 0.99218}
2025-08-23 10:11:58,340 - INFO - val: {'epoch': 68, 'time_epoch': 0.87794, 'loss': 0.21347472, 'lr': 0, 'params': 210889, 'time_iter': 0.02744, 'accuracy': 0.926, 'f1': 0.92668, 'auc': 0.99145}
2025-08-23 10:12:00,093 - INFO - test: {'epoch': 68, 'time_epoch': 1.74237, 'loss': 0.2549293, 'lr': 0, 'params': 210889, 'time_iter': 0.02766, 'accuracy': 0.912, 'f1': 0.91262, 'auc': 0.9879}
2025-08-23 10:12:00,095 - INFO - > Epoch 68: took 16.8s (avg 17.0s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:12:14,300 - INFO - train: {'epoch': 69, 'time_epoch': 14.18987, 'eta': 427.51646, 'eta_hours': 0.11875, 'loss': 0.18924731, 'lr': 0.00013263, 'params': 210889, 'time_iter': 0.06479, 'accuracy': 0.938, 'f1': 0.93804, 'auc': 0.9913}
2025-08-23 10:12:15,187 - INFO - val: {'epoch': 69, 'time_epoch': 0.87695, 'loss': 0.25079341, 'lr': 0, 'params': 210889, 'time_iter': 0.0274, 'accuracy': 0.922, 'f1': 0.92357, 'auc': 0.9908}
2025-08-23 10:12:16,939 - INFO - test: {'epoch': 69, 'time_epoch': 1.74149, 'loss': 0.26620577, 'lr': 0, 'params': 210889, 'time_iter': 0.02764, 'accuracy': 0.917, 'f1': 0.91878, 'auc': 0.98838}
2025-08-23 10:12:16,941 - INFO - > Epoch 69: took 16.8s (avg 17.0s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:12:31,089 - INFO - train: {'epoch': 70, 'time_epoch': 14.13338, 'eta': 413.21806, 'eta_hours': 0.11478, 'loss': 0.18088666, 'lr': 0.000125, 'params': 210889, 'time_iter': 0.06454, 'accuracy': 0.94314, 'f1': 0.94323, 'auc': 0.99163}
2025-08-23 10:12:31,959 - INFO - val: {'epoch': 70, 'time_epoch': 0.8594, 'loss': 0.23327067, 'lr': 0, 'params': 210889, 'time_iter': 0.02686, 'accuracy': 0.926, 'f1': 0.92758, 'auc': 0.99106}
2025-08-23 10:12:33,723 - INFO - test: {'epoch': 70, 'time_epoch': 1.75373, 'loss': 0.26189657, 'lr': 0, 'params': 210889, 'time_iter': 0.02784, 'accuracy': 0.908, 'f1': 0.90984, 'auc': 0.98916}
2025-08-23 10:12:33,725 - INFO - > Epoch 70: took 16.8s (avg 17.0s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:12:47,840 - INFO - train: {'epoch': 71, 'time_epoch': 14.10069, 'eta': 398.91152, 'eta_hours': 0.11081, 'loss': 0.1834919, 'lr': 0.00011752, 'params': 210889, 'time_iter': 0.06439, 'accuracy': 0.942, 'f1': 0.94204, 'auc': 0.99217}
2025-08-23 10:12:48,730 - INFO - val: {'epoch': 71, 'time_epoch': 0.87873, 'loss': 0.20875845, 'lr': 0, 'params': 210889, 'time_iter': 0.02746, 'accuracy': 0.93, 'f1': 0.9303, 'auc': 0.99156}
2025-08-23 10:12:50,505 - INFO - test: {'epoch': 71, 'time_epoch': 1.76501, 'loss': 0.24492162, 'lr': 0, 'params': 210889, 'time_iter': 0.02802, 'accuracy': 0.92, 'f1': 0.92009, 'auc': 0.98892}
2025-08-23 10:12:50,507 - INFO - > Epoch 71: took 16.8s (avg 17.0s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:13:04,591 - INFO - train: {'epoch': 72, 'time_epoch': 14.06944, 'eta': 384.59907, 'eta_hours': 0.10683, 'loss': 0.17635808, 'lr': 0.0001102, 'params': 210889, 'time_iter': 0.06424, 'accuracy': 0.94257, 'f1': 0.94257, 'auc': 0.99249}
2025-08-23 10:13:05,463 - INFO - val: {'epoch': 72, 'time_epoch': 0.86088, 'loss': 0.24018684, 'lr': 0, 'params': 210889, 'time_iter': 0.0269, 'accuracy': 0.928, 'f1': 0.92903, 'auc': 0.99022}
2025-08-23 10:13:07,206 - INFO - test: {'epoch': 72, 'time_epoch': 1.73205, 'loss': 0.27407587, 'lr': 0, 'params': 210889, 'time_iter': 0.02749, 'accuracy': 0.911, 'f1': 0.91277, 'auc': 0.98722}
2025-08-23 10:13:07,208 - INFO - > Epoch 72: took 16.7s (avg 17.0s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:13:21,356 - INFO - train: {'epoch': 73, 'time_epoch': 14.13462, 'eta': 370.31608, 'eta_hours': 0.10287, 'loss': 0.1841772, 'lr': 0.00010305, 'params': 210889, 'time_iter': 0.06454, 'accuracy': 0.93743, 'f1': 0.93752, 'auc': 0.9921}
2025-08-23 10:13:22,225 - INFO - val: {'epoch': 73, 'time_epoch': 0.85839, 'loss': 0.24249031, 'lr': 0, 'params': 210889, 'time_iter': 0.02682, 'accuracy': 0.924, 'f1': 0.92525, 'auc': 0.99052}
2025-08-23 10:13:23,974 - INFO - test: {'epoch': 73, 'time_epoch': 1.73992, 'loss': 0.29794207, 'lr': 0, 'params': 210889, 'time_iter': 0.02762, 'accuracy': 0.905, 'f1': 0.90604, 'auc': 0.98639}
2025-08-23 10:13:23,976 - INFO - > Epoch 73: took 16.8s (avg 17.0s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:13:37,970 - INFO - train: {'epoch': 74, 'time_epoch': 13.97947, 'eta': 355.98534, 'eta_hours': 0.09888, 'loss': 0.18072796, 'lr': 9.608e-05, 'params': 210889, 'time_iter': 0.06383, 'accuracy': 0.94143, 'f1': 0.94137, 'auc': 0.99186}
2025-08-23 10:13:38,853 - INFO - val: {'epoch': 74, 'time_epoch': 0.87344, 'loss': 0.2126668, 'lr': 0, 'params': 210889, 'time_iter': 0.02729, 'accuracy': 0.932, 'f1': 0.93266, 'auc': 0.99172}
2025-08-23 10:13:40,592 - INFO - test: {'epoch': 74, 'time_epoch': 1.72871, 'loss': 0.24623416, 'lr': 0, 'params': 210889, 'time_iter': 0.02744, 'accuracy': 0.916, 'f1': 0.91668, 'auc': 0.98817}
2025-08-23 10:13:40,594 - INFO - > Epoch 74: took 16.6s (avg 17.0s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:13:54,734 - INFO - train: {'epoch': 75, 'time_epoch': 14.12573, 'eta': 341.71002, 'eta_hours': 0.09492, 'loss': 0.16666263, 'lr': 8.93e-05, 'params': 210889, 'time_iter': 0.0645, 'accuracy': 0.94343, 'f1': 0.94345, 'auc': 0.99278}
2025-08-23 10:13:55,624 - INFO - val: {'epoch': 75, 'time_epoch': 0.87922, 'loss': 0.23419647, 'lr': 0, 'params': 210889, 'time_iter': 0.02748, 'accuracy': 0.93, 'f1': 0.93086, 'auc': 0.99135}
2025-08-23 10:13:57,395 - INFO - test: {'epoch': 75, 'time_epoch': 1.76024, 'loss': 0.26857909, 'lr': 0, 'params': 210889, 'time_iter': 0.02794, 'accuracy': 0.911, 'f1': 0.91186, 'auc': 0.98823}
2025-08-23 10:13:57,396 - INFO - > Epoch 75: took 16.8s (avg 17.0s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:14:11,587 - INFO - train: {'epoch': 76, 'time_epoch': 14.17583, 'eta': 327.45356, 'eta_hours': 0.09096, 'loss': 0.17103159, 'lr': 8.272e-05, 'params': 210889, 'time_iter': 0.06473, 'accuracy': 0.942, 'f1': 0.94213, 'auc': 0.99301}
2025-08-23 10:14:12,482 - INFO - val: {'epoch': 76, 'time_epoch': 0.88231, 'loss': 0.22453548, 'lr': 0, 'params': 210889, 'time_iter': 0.02757, 'accuracy': 0.926, 'f1': 0.92687, 'auc': 0.99104}
2025-08-23 10:14:14,265 - INFO - test: {'epoch': 76, 'time_epoch': 1.77117, 'loss': 0.26704787, 'lr': 0, 'params': 210889, 'time_iter': 0.02811, 'accuracy': 0.904, 'f1': 0.90506, 'auc': 0.988}
2025-08-23 10:14:14,267 - INFO - > Epoch 76: took 16.9s (avg 17.0s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:14:28,495 - INFO - train: {'epoch': 77, 'time_epoch': 14.21178, 'eta': 313.2093, 'eta_hours': 0.087, 'loss': 0.17316884, 'lr': 7.634e-05, 'params': 210889, 'time_iter': 0.06489, 'accuracy': 0.94114, 'f1': 0.94121, 'auc': 0.9926}
2025-08-23 10:14:29,376 - INFO - val: {'epoch': 77, 'time_epoch': 0.8693, 'loss': 0.22721863, 'lr': 0, 'params': 210889, 'time_iter': 0.02717, 'accuracy': 0.924, 'f1': 0.92471, 'auc': 0.99078}
2025-08-23 10:14:31,126 - INFO - test: {'epoch': 77, 'time_epoch': 1.7386, 'loss': 0.25175967, 'lr': 0, 'params': 210889, 'time_iter': 0.0276, 'accuracy': 0.912, 'f1': 0.91295, 'auc': 0.98857}
2025-08-23 10:14:31,128 - INFO - > Epoch 77: took 16.9s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:14:45,134 - INFO - train: {'epoch': 78, 'time_epoch': 13.99131, 'eta': 298.90727, 'eta_hours': 0.08303, 'loss': 0.16231569, 'lr': 7.017e-05, 'params': 210889, 'time_iter': 0.06389, 'accuracy': 0.948, 'f1': 0.94807, 'auc': 0.99295}
2025-08-23 10:14:46,021 - INFO - val: {'epoch': 78, 'time_epoch': 0.87632, 'loss': 0.24918405, 'lr': 0, 'params': 210889, 'time_iter': 0.02739, 'accuracy': 0.922, 'f1': 0.92203, 'auc': 0.99084}
2025-08-23 10:14:47,782 - INFO - test: {'epoch': 78, 'time_epoch': 1.74911, 'loss': 0.26253514, 'lr': 0, 'params': 210889, 'time_iter': 0.02776, 'accuracy': 0.916, 'f1': 0.9163, 'auc': 0.98817}
2025-08-23 10:14:47,784 - INFO - > Epoch 78: took 16.7s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:15:01,794 - INFO - train: {'epoch': 79, 'time_epoch': 13.99668, 'eta': 284.61434, 'eta_hours': 0.07906, 'loss': 0.1666098, 'lr': 6.421e-05, 'params': 210889, 'time_iter': 0.06391, 'accuracy': 0.94457, 'f1': 0.94446, 'auc': 0.99301}
2025-08-23 10:15:02,672 - INFO - val: {'epoch': 79, 'time_epoch': 0.86357, 'loss': 0.24281948, 'lr': 0, 'params': 210889, 'time_iter': 0.02699, 'accuracy': 0.924, 'f1': 0.92522, 'auc': 0.99099}
2025-08-23 10:15:04,455 - INFO - test: {'epoch': 79, 'time_epoch': 1.77232, 'loss': 0.25915491, 'lr': 0, 'params': 210889, 'time_iter': 0.02813, 'accuracy': 0.918, 'f1': 0.91925, 'auc': 0.98837}
2025-08-23 10:15:04,458 - INFO - > Epoch 79: took 16.7s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:15:18,312 - INFO - train: {'epoch': 80, 'time_epoch': 13.83982, 'eta': 270.29193, 'eta_hours': 0.07508, 'loss': 0.16572785, 'lr': 5.849e-05, 'params': 210889, 'time_iter': 0.0632, 'accuracy': 0.94714, 'f1': 0.94709, 'auc': 0.99261}
2025-08-23 10:15:19,183 - INFO - val: {'epoch': 80, 'time_epoch': 0.86025, 'loss': 0.23808636, 'lr': 0, 'params': 210889, 'time_iter': 0.02688, 'accuracy': 0.926, 'f1': 0.92705, 'auc': 0.9908}
2025-08-23 10:15:20,927 - INFO - test: {'epoch': 80, 'time_epoch': 1.73325, 'loss': 0.2523664, 'lr': 0, 'params': 210889, 'time_iter': 0.02751, 'accuracy': 0.924, 'f1': 0.92499, 'auc': 0.9885}
2025-08-23 10:15:20,929 - INFO - > Epoch 80: took 16.5s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:15:34,788 - INFO - train: {'epoch': 81, 'time_epoch': 13.84557, 'eta': 255.98255, 'eta_hours': 0.07111, 'loss': 0.16431448, 'lr': 5.3e-05, 'params': 210889, 'time_iter': 0.06322, 'accuracy': 0.94486, 'f1': 0.94495, 'auc': 0.99334}
2025-08-23 10:15:35,658 - INFO - val: {'epoch': 81, 'time_epoch': 0.85898, 'loss': 0.22216375, 'lr': 0, 'params': 210889, 'time_iter': 0.02684, 'accuracy': 0.926, 'f1': 0.92692, 'auc': 0.99076}
2025-08-23 10:15:37,416 - INFO - test: {'epoch': 81, 'time_epoch': 1.74896, 'loss': 0.2643213, 'lr': 0, 'params': 210889, 'time_iter': 0.02776, 'accuracy': 0.913, 'f1': 0.9147, 'auc': 0.98873}
2025-08-23 10:15:37,418 - INFO - > Epoch 81: took 16.5s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:15:51,333 - INFO - train: {'epoch': 82, 'time_epoch': 13.90096, 'eta': 241.6957, 'eta_hours': 0.06714, 'loss': 0.16830319, 'lr': 4.775e-05, 'params': 210889, 'time_iter': 0.06347, 'accuracy': 0.94314, 'f1': 0.94306, 'auc': 0.99329}
2025-08-23 10:15:52,195 - INFO - val: {'epoch': 82, 'time_epoch': 0.85242, 'loss': 0.23357311, 'lr': 0, 'params': 210889, 'time_iter': 0.02664, 'accuracy': 0.928, 'f1': 0.929, 'auc': 0.99082}
2025-08-23 10:15:53,935 - INFO - test: {'epoch': 82, 'time_epoch': 1.72934, 'loss': 0.25748729, 'lr': 0, 'params': 210889, 'time_iter': 0.02745, 'accuracy': 0.917, 'f1': 0.91817, 'auc': 0.98854}
2025-08-23 10:15:53,937 - INFO - > Epoch 82: took 16.5s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:16:07,853 - INFO - train: {'epoch': 83, 'time_epoch': 13.90054, 'eta': 227.41795, 'eta_hours': 0.06317, 'loss': 0.17473422, 'lr': 4.274e-05, 'params': 210889, 'time_iter': 0.06347, 'accuracy': 0.94257, 'f1': 0.9426, 'auc': 0.99256}
2025-08-23 10:16:08,732 - INFO - val: {'epoch': 83, 'time_epoch': 0.8688, 'loss': 0.23021879, 'lr': 0, 'params': 210889, 'time_iter': 0.02715, 'accuracy': 0.926, 'f1': 0.92712, 'auc': 0.992}
2025-08-23 10:16:10,504 - INFO - test: {'epoch': 83, 'time_epoch': 1.76201, 'loss': 0.26110189, 'lr': 0, 'params': 210889, 'time_iter': 0.02797, 'accuracy': 0.919, 'f1': 0.92047, 'auc': 0.98825}
2025-08-23 10:16:10,506 - INFO - > Epoch 83: took 16.6s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:16:24,561 - INFO - train: {'epoch': 84, 'time_epoch': 14.03998, 'eta': 213.17368, 'eta_hours': 0.05921, 'loss': 0.15761205, 'lr': 3.799e-05, 'params': 210889, 'time_iter': 0.06411, 'accuracy': 0.94914, 'f1': 0.94921, 'auc': 0.99365}
2025-08-23 10:16:25,450 - INFO - val: {'epoch': 84, 'time_epoch': 0.87759, 'loss': 0.22307167, 'lr': 0, 'params': 210889, 'time_iter': 0.02742, 'accuracy': 0.93, 'f1': 0.93084, 'auc': 0.99186}
2025-08-23 10:16:27,212 - INFO - test: {'epoch': 84, 'time_epoch': 1.75225, 'loss': 0.25566882, 'lr': 0, 'params': 210889, 'time_iter': 0.02781, 'accuracy': 0.92, 'f1': 0.9214, 'auc': 0.98862}
2025-08-23 10:16:27,214 - INFO - > Epoch 84: took 16.7s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:16:41,274 - INFO - train: {'epoch': 85, 'time_epoch': 14.04521, 'eta': 198.93502, 'eta_hours': 0.05526, 'loss': 0.17041857, 'lr': 3.349e-05, 'params': 210889, 'time_iter': 0.06413, 'accuracy': 0.94114, 'f1': 0.94138, 'auc': 0.99239}
2025-08-23 10:16:42,146 - INFO - val: {'epoch': 85, 'time_epoch': 0.86196, 'loss': 0.22804661, 'lr': 0, 'params': 210889, 'time_iter': 0.02694, 'accuracy': 0.932, 'f1': 0.93302, 'auc': 0.99177}
2025-08-23 10:16:43,920 - INFO - test: {'epoch': 85, 'time_epoch': 1.76371, 'loss': 0.26332103, 'lr': 0, 'params': 210889, 'time_iter': 0.028, 'accuracy': 0.916, 'f1': 0.91759, 'auc': 0.98876}
2025-08-23 10:16:43,922 - INFO - > Epoch 85: took 16.7s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:16:57,854 - INFO - train: {'epoch': 86, 'time_epoch': 13.9192, 'eta': 184.68198, 'eta_hours': 0.0513, 'loss': 0.16338824, 'lr': 2.926e-05, 'params': 210889, 'time_iter': 0.06356, 'accuracy': 0.94657, 'f1': 0.94666, 'auc': 0.99327}
2025-08-23 10:16:58,718 - INFO - val: {'epoch': 86, 'time_epoch': 0.85246, 'loss': 0.22015509, 'lr': 0, 'params': 210889, 'time_iter': 0.02664, 'accuracy': 0.928, 'f1': 0.9288, 'auc': 0.99205}
2025-08-23 10:17:00,475 - INFO - test: {'epoch': 86, 'time_epoch': 1.74633, 'loss': 0.24875299, 'lr': 0, 'params': 210889, 'time_iter': 0.02772, 'accuracy': 0.925, 'f1': 0.92576, 'auc': 0.98839}
2025-08-23 10:17:00,476 - INFO - > Epoch 86: took 16.6s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:17:14,321 - INFO - train: {'epoch': 87, 'time_epoch': 13.83113, 'eta': 170.42451, 'eta_hours': 0.04734, 'loss': 0.16059216, 'lr': 2.53e-05, 'params': 210889, 'time_iter': 0.06316, 'accuracy': 0.94714, 'f1': 0.94726, 'auc': 0.99362}
2025-08-23 10:17:15,189 - INFO - val: {'epoch': 87, 'time_epoch': 0.858, 'loss': 0.22845429, 'lr': 0, 'params': 210889, 'time_iter': 0.02681, 'accuracy': 0.93, 'f1': 0.93119, 'auc': 0.99186}
2025-08-23 10:17:16,944 - INFO - test: {'epoch': 87, 'time_epoch': 1.74639, 'loss': 0.26189729, 'lr': 0, 'params': 210889, 'time_iter': 0.02772, 'accuracy': 0.921, 'f1': 0.92253, 'auc': 0.98861}
2025-08-23 10:17:16,946 - INFO - > Epoch 87: took 16.5s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:17:31,084 - INFO - train: {'epoch': 88, 'time_epoch': 14.12363, 'eta': 156.21278, 'eta_hours': 0.04339, 'loss': 0.15831862, 'lr': 2.161e-05, 'params': 210889, 'time_iter': 0.06449, 'accuracy': 0.94686, 'f1': 0.94689, 'auc': 0.99395}
2025-08-23 10:17:31,963 - INFO - val: {'epoch': 88, 'time_epoch': 0.86713, 'loss': 0.22014433, 'lr': 0, 'params': 210889, 'time_iter': 0.0271, 'accuracy': 0.926, 'f1': 0.92696, 'auc': 0.99151}
2025-08-23 10:17:33,705 - INFO - test: {'epoch': 88, 'time_epoch': 1.73115, 'loss': 0.25069674, 'lr': 0, 'params': 210889, 'time_iter': 0.02748, 'accuracy': 0.919, 'f1': 0.92003, 'auc': 0.98886}
2025-08-23 10:17:33,707 - INFO - > Epoch 88: took 16.8s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:17:47,791 - INFO - train: {'epoch': 89, 'time_epoch': 14.06884, 'eta': 141.99691, 'eta_hours': 0.03944, 'loss': 0.1529226, 'lr': 1.82e-05, 'params': 210889, 'time_iter': 0.06424, 'accuracy': 0.95086, 'f1': 0.95091, 'auc': 0.99401}
2025-08-23 10:17:48,684 - INFO - val: {'epoch': 89, 'time_epoch': 0.87914, 'loss': 0.22568662, 'lr': 0, 'params': 210889, 'time_iter': 0.02747, 'accuracy': 0.928, 'f1': 0.92917, 'auc': 0.99175}
2025-08-23 10:17:50,451 - INFO - test: {'epoch': 89, 'time_epoch': 1.7571, 'loss': 0.25542496, 'lr': 0, 'params': 210889, 'time_iter': 0.02789, 'accuracy': 0.92, 'f1': 0.92145, 'auc': 0.98827}
2025-08-23 10:17:50,453 - INFO - > Epoch 89: took 16.7s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:18:04,597 - INFO - train: {'epoch': 90, 'time_epoch': 14.12931, 'eta': 127.79026, 'eta_hours': 0.0355, 'loss': 0.15326657, 'lr': 1.508e-05, 'params': 210889, 'time_iter': 0.06452, 'accuracy': 0.95086, 'f1': 0.95087, 'auc': 0.99385}
2025-08-23 10:18:05,487 - INFO - val: {'epoch': 90, 'time_epoch': 0.87903, 'loss': 0.22708299, 'lr': 0, 'params': 210889, 'time_iter': 0.02747, 'accuracy': 0.926, 'f1': 0.92712, 'auc': 0.99195}
2025-08-23 10:18:07,270 - INFO - test: {'epoch': 90, 'time_epoch': 1.77185, 'loss': 0.25711218, 'lr': 0, 'params': 210889, 'time_iter': 0.02812, 'accuracy': 0.923, 'f1': 0.92439, 'auc': 0.9884}
2025-08-23 10:18:07,272 - INFO - > Epoch 90: took 16.8s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:18:21,394 - INFO - train: {'epoch': 91, 'time_epoch': 14.10677, 'eta': 113.58333, 'eta_hours': 0.03155, 'loss': 0.16544612, 'lr': 1.224e-05, 'params': 210889, 'time_iter': 0.06441, 'accuracy': 0.94771, 'f1': 0.94781, 'auc': 0.9932}
2025-08-23 10:18:22,296 - INFO - val: {'epoch': 91, 'time_epoch': 0.88893, 'loss': 0.22263668, 'lr': 0, 'params': 210889, 'time_iter': 0.02778, 'accuracy': 0.926, 'f1': 0.92696, 'auc': 0.99168}
2025-08-23 10:18:24,057 - INFO - test: {'epoch': 91, 'time_epoch': 1.75003, 'loss': 0.25275687, 'lr': 0, 'params': 210889, 'time_iter': 0.02778, 'accuracy': 0.919, 'f1': 0.92011, 'auc': 0.98828}
2025-08-23 10:18:24,058 - INFO - > Epoch 91: took 16.8s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:18:38,120 - INFO - train: {'epoch': 92, 'time_epoch': 14.04741, 'eta': 99.37409, 'eta_hours': 0.0276, 'loss': 0.15403654, 'lr': 9.68e-06, 'params': 210889, 'time_iter': 0.06414, 'accuracy': 0.94657, 'f1': 0.94655, 'auc': 0.99419}
2025-08-23 10:18:38,999 - INFO - val: {'epoch': 92, 'time_epoch': 0.86727, 'loss': 0.22362449, 'lr': 0, 'params': 210889, 'time_iter': 0.0271, 'accuracy': 0.928, 'f1': 0.92917, 'auc': 0.99156}
2025-08-23 10:18:40,746 - INFO - test: {'epoch': 92, 'time_epoch': 1.73536, 'loss': 0.25311033, 'lr': 0, 'params': 210889, 'time_iter': 0.02755, 'accuracy': 0.923, 'f1': 0.92424, 'auc': 0.98867}
2025-08-23 10:18:40,748 - INFO - > Epoch 92: took 16.7s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:18:54,654 - INFO - train: {'epoch': 93, 'time_epoch': 13.89225, 'eta': 85.15838, 'eta_hours': 0.02366, 'loss': 0.15131615, 'lr': 7.43e-06, 'params': 210889, 'time_iter': 0.06343, 'accuracy': 0.94943, 'f1': 0.94942, 'auc': 0.99412}
2025-08-23 10:18:55,521 - INFO - val: {'epoch': 93, 'time_epoch': 0.85727, 'loss': 0.22474499, 'lr': 0, 'params': 210889, 'time_iter': 0.02679, 'accuracy': 0.926, 'f1': 0.92696, 'auc': 0.99168}
2025-08-23 10:18:57,271 - INFO - test: {'epoch': 93, 'time_epoch': 1.73909, 'loss': 0.25529027, 'lr': 0, 'params': 210889, 'time_iter': 0.0276, 'accuracy': 0.917, 'f1': 0.91826, 'auc': 0.98854}
2025-08-23 10:18:57,272 - INFO - > Epoch 93: took 16.5s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:19:11,266 - INFO - train: {'epoch': 94, 'time_epoch': 13.9784, 'eta': 70.95402, 'eta_hours': 0.01971, 'loss': 0.15337509, 'lr': 5.46e-06, 'params': 210889, 'time_iter': 0.06383, 'accuracy': 0.94886, 'f1': 0.94876, 'auc': 0.99427}
2025-08-23 10:19:12,157 - INFO - val: {'epoch': 94, 'time_epoch': 0.87949, 'loss': 0.22251499, 'lr': 0, 'params': 210889, 'time_iter': 0.02748, 'accuracy': 0.924, 'f1': 0.92505, 'auc': 0.99187}
2025-08-23 10:19:13,918 - INFO - test: {'epoch': 94, 'time_epoch': 1.74957, 'loss': 0.24964476, 'lr': 0, 'params': 210889, 'time_iter': 0.02777, 'accuracy': 0.922, 'f1': 0.92301, 'auc': 0.98854}
2025-08-23 10:19:13,920 - INFO - > Epoch 94: took 16.6s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:19:28,047 - INFO - train: {'epoch': 95, 'time_epoch': 14.1127, 'eta': 56.75996, 'eta_hours': 0.01577, 'loss': 0.15025021, 'lr': 3.8e-06, 'params': 210889, 'time_iter': 0.06444, 'accuracy': 0.94543, 'f1': 0.94545, 'auc': 0.99465}
2025-08-23 10:19:28,925 - INFO - val: {'epoch': 95, 'time_epoch': 0.86719, 'loss': 0.22493442, 'lr': 0, 'params': 210889, 'time_iter': 0.0271, 'accuracy': 0.928, 'f1': 0.92893, 'auc': 0.99171}
2025-08-23 10:19:30,672 - INFO - test: {'epoch': 95, 'time_epoch': 1.7356, 'loss': 0.25302942, 'lr': 0, 'params': 210889, 'time_iter': 0.02755, 'accuracy': 0.922, 'f1': 0.923, 'auc': 0.98861}
2025-08-23 10:19:30,674 - INFO - > Epoch 95: took 16.8s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:19:44,863 - INFO - train: {'epoch': 96, 'time_epoch': 14.17486, 'eta': 42.5695, 'eta_hours': 0.01182, 'loss': 0.15434711, 'lr': 2.43e-06, 'params': 210889, 'time_iter': 0.06473, 'accuracy': 0.94971, 'f1': 0.94955, 'auc': 0.99379}
2025-08-23 10:19:45,738 - INFO - val: {'epoch': 96, 'time_epoch': 0.86321, 'loss': 0.22785331, 'lr': 0, 'params': 210889, 'time_iter': 0.02698, 'accuracy': 0.928, 'f1': 0.92893, 'auc': 0.99182}
2025-08-23 10:19:47,481 - INFO - test: {'epoch': 96, 'time_epoch': 1.7313, 'loss': 0.25904814, 'lr': 0, 'params': 210889, 'time_iter': 0.02748, 'accuracy': 0.917, 'f1': 0.91826, 'auc': 0.9886}
2025-08-23 10:19:47,482 - INFO - > Epoch 96: took 16.8s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:20:01,427 - INFO - train: {'epoch': 97, 'time_epoch': 13.9309, 'eta': 28.37438, 'eta_hours': 0.00788, 'loss': 0.14733877, 'lr': 1.37e-06, 'params': 210889, 'time_iter': 0.06361, 'accuracy': 0.95286, 'f1': 0.95285, 'auc': 0.99425}
2025-08-23 10:20:02,296 - INFO - val: {'epoch': 97, 'time_epoch': 0.85853, 'loss': 0.22362116, 'lr': 0, 'params': 210889, 'time_iter': 0.02683, 'accuracy': 0.928, 'f1': 0.92893, 'auc': 0.9919}
2025-08-23 10:20:04,058 - INFO - test: {'epoch': 97, 'time_epoch': 1.75119, 'loss': 0.25276616, 'lr': 0, 'params': 210889, 'time_iter': 0.0278, 'accuracy': 0.922, 'f1': 0.92293, 'auc': 0.98848}
2025-08-23 10:20:04,060 - INFO - > Epoch 97: took 16.6s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:20:18,157 - INFO - train: {'epoch': 98, 'time_epoch': 14.08207, 'eta': 14.18613, 'eta_hours': 0.00394, 'loss': 0.15614999, 'lr': 6.1e-07, 'params': 210889, 'time_iter': 0.0643, 'accuracy': 0.94686, 'f1': 0.94697, 'auc': 0.99392}
2025-08-23 10:20:19,026 - INFO - val: {'epoch': 98, 'time_epoch': 0.85906, 'loss': 0.224563, 'lr': 0, 'params': 210889, 'time_iter': 0.02685, 'accuracy': 0.928, 'f1': 0.92893, 'auc': 0.99179}
2025-08-23 10:20:20,785 - INFO - test: {'epoch': 98, 'time_epoch': 1.74829, 'loss': 0.25220655, 'lr': 0, 'params': 210889, 'time_iter': 0.02775, 'accuracy': 0.918, 'f1': 0.91962, 'auc': 0.98882}
2025-08-23 10:20:20,787 - INFO - > Epoch 98: took 16.7s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:20:34,736 - INFO - train: {'epoch': 99, 'time_epoch': 13.9336, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.16131641, 'lr': 1.5e-07, 'params': 210889, 'time_iter': 0.06362, 'accuracy': 0.94886, 'f1': 0.94888, 'auc': 0.9932}
2025-08-23 10:20:35,606 - INFO - val: {'epoch': 99, 'time_epoch': 0.85912, 'loss': 0.22354742, 'lr': 0, 'params': 210889, 'time_iter': 0.02685, 'accuracy': 0.926, 'f1': 0.92696, 'auc': 0.99174}
2025-08-23 10:20:37,360 - INFO - test: {'epoch': 99, 'time_epoch': 1.74427, 'loss': 0.24873679, 'lr': 0, 'params': 210889, 'time_iter': 0.02769, 'accuracy': 0.924, 'f1': 0.92514, 'auc': 0.98879}
2025-08-23 10:20:37,436 - INFO - > Epoch 99: took 16.6s (avg 16.9s) | Best so far: epoch 64	train_loss: 0.2011 train_accuracy: 0.9337	val_loss: 0.2154 val_accuracy: 0.9380	test_loss: 0.2621 test_accuracy: 0.9140
2025-08-23 10:20:37,436 - INFO - Avg time per epoch: 16.88s
2025-08-23 10:20:37,436 - INFO - Total train loop time: 0.47h
2025-08-23 10:20:37,438 - INFO - Task done, results saved in results/MALNET/MALNET-E-47
2025-08-23 10:20:37,438 - INFO - Total time: 1692.86s (0.47h)
2025-08-23 10:20:37,459 - INFO - Results aggregated across runs saved in results/MALNET/MALNET-E-47/agg
2025-08-23 10:20:37,459 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-23 10:20:37,459 - INFO - Results saved in: results/MALNET/MALNET-E-47
2025-08-23 10:20:37,459 - INFO - Test results JSON files saved in: results/MALNET/MALNET-E-47/test_results/
Completed seed 47. Results saved in results/MALNET/MALNET-E-47
----------------------------------------
All experiments completed!
