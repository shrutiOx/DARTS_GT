Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          376Gi        18Gi       205Gi       4.0Gi       152Gi       350Gi
Swap:         1.9Gi       316Mi       1.6Gi
Sat Aug 16 03:54:45 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:1C:00.0 Off |                    0 |
| N/A   40C    P0             47W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 66
Starting training for seed 66...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLPCBA/TRANS
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLPCBA/TRANS/confignas.yaml
Using device: cuda
2025-08-16 03:54:57,772 - INFO - GPU Mem: 34.1GB
2025-08-16 03:54:57,772 - INFO - Run directory: results/molpcba/molpcba-Vanilla-66
2025-08-16 03:54:57,772 - INFO - Seed: 66
2025-08-16 03:54:57,772 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-16 03:54:57,772 - INFO - Routing mode: none
2025-08-16 03:54:57,772 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 03:54:57,772 - INFO - Number of layers: 8
2025-08-16 03:54:57,772 - INFO - Uncertainty enabled: False
2025-08-16 03:54:57,772 - INFO - Training mode: custom
2025-08-16 03:54:57,772 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-16 03:54:57,772 - INFO - Additional features: Router weights logging + JSON export
Downloading http://snap.stanford.edu/ogb/data/graphproppred/csv_mol_download/pcba.zip
  0%|          | 0/39 [00:00<?, ?it/s]Downloaded 0.00 GB:   0%|          | 0/39 [00:01<?, ?it/s]Downloaded 0.00 GB:   3%|▎         | 1/39 [00:01<01:10,  1.86s/it]Downloaded 0.00 GB:   3%|▎         | 1/39 [00:02<01:10,  1.86s/it]Downloaded 0.00 GB:   5%|▌         | 2/39 [00:02<00:43,  1.19s/it]Downloaded 0.00 GB:   5%|▌         | 2/39 [00:03<00:43,  1.19s/it]Downloaded 0.00 GB:   8%|▊         | 3/39 [00:03<00:32,  1.10it/s]Downloaded 0.00 GB:   8%|▊         | 3/39 [00:03<00:32,  1.10it/s]Downloaded 0.00 GB:  10%|█         | 4/39 [00:03<00:23,  1.51it/s]Downloaded 0.00 GB:  10%|█         | 4/39 [00:03<00:23,  1.51it/s]Downloaded 0.00 GB:  13%|█▎        | 5/39 [00:03<00:19,  1.73it/s]Downloaded 0.01 GB:  13%|█▎        | 5/39 [00:04<00:19,  1.73it/s]Downloaded 0.01 GB:  15%|█▌        | 6/39 [00:04<00:15,  2.09it/s]Downloaded 0.01 GB:  15%|█▌        | 6/39 [00:04<00:15,  2.09it/s]Downloaded 0.01 GB:  18%|█▊        | 7/39 [00:04<00:11,  2.70it/s]Downloaded 0.01 GB:  18%|█▊        | 7/39 [00:04<00:11,  2.70it/s]Downloaded 0.01 GB:  21%|██        | 8/39 [00:04<00:10,  2.92it/s]Downloaded 0.01 GB:  21%|██        | 8/39 [00:04<00:10,  2.92it/s]Downloaded 0.01 GB:  23%|██▎       | 9/39 [00:04<00:08,  3.56it/s]Downloaded 0.01 GB:  23%|██▎       | 9/39 [00:04<00:08,  3.56it/s]Downloaded 0.01 GB:  26%|██▌       | 10/39 [00:04<00:06,  4.18it/s]Downloaded 0.01 GB:  26%|██▌       | 10/39 [00:05<00:06,  4.18it/s]Downloaded 0.01 GB:  28%|██▊       | 11/39 [00:05<00:05,  4.75it/s]Downloaded 0.01 GB:  28%|██▊       | 11/39 [00:05<00:05,  4.75it/s]Downloaded 0.01 GB:  31%|███       | 12/39 [00:05<00:05,  5.26it/s]Downloaded 0.01 GB:  31%|███       | 12/39 [00:05<00:05,  5.26it/s]Downloaded 0.01 GB:  33%|███▎      | 13/39 [00:05<00:04,  5.70it/s]Downloaded 0.01 GB:  33%|███▎      | 13/39 [00:05<00:04,  5.70it/s]Downloaded 0.01 GB:  36%|███▌      | 14/39 [00:05<00:04,  6.05it/s]Downloaded 0.01 GB:  36%|███▌      | 14/39 [00:05<00:04,  6.05it/s]Downloaded 0.01 GB:  38%|███▊      | 15/39 [00:05<00:03,  6.33it/s]Downloaded 0.02 GB:  38%|███▊      | 15/39 [00:05<00:03,  6.33it/s]Downloaded 0.02 GB:  41%|████      | 16/39 [00:05<00:03,  6.56it/s]Downloaded 0.02 GB:  41%|████      | 16/39 [00:05<00:03,  6.56it/s]Downloaded 0.02 GB:  41%|████      | 16/39 [00:05<00:03,  6.56it/s]Downloaded 0.02 GB:  46%|████▌     | 18/39 [00:05<00:02,  8.57it/s]Downloaded 0.02 GB:  46%|████▌     | 18/39 [00:06<00:02,  8.57it/s]Downloaded 0.02 GB:  49%|████▊     | 19/39 [00:06<00:02,  8.20it/s]Downloaded 0.02 GB:  49%|████▊     | 19/39 [00:06<00:02,  8.20it/s]Downloaded 0.02 GB:  49%|████▊     | 19/39 [00:06<00:02,  8.20it/s]Downloaded 0.02 GB:  54%|█████▍    | 21/39 [00:06<00:01,  9.81it/s]Downloaded 0.02 GB:  54%|█████▍    | 21/39 [00:06<00:01,  9.81it/s]Downloaded 0.02 GB:  54%|█████▍    | 21/39 [00:06<00:01,  9.81it/s]Downloaded 0.02 GB:  59%|█████▉    | 23/39 [00:06<00:01, 10.96it/s]Downloaded 0.02 GB:  59%|█████▉    | 23/39 [00:06<00:01, 10.96it/s]Downloaded 0.02 GB:  59%|█████▉    | 23/39 [00:06<00:01, 10.96it/s]Downloaded 0.02 GB:  64%|██████▍   | 25/39 [00:06<00:01, 11.81it/s]Downloaded 0.03 GB:  64%|██████▍   | 25/39 [00:06<00:01, 11.81it/s]Downloaded 0.03 GB:  64%|██████▍   | 25/39 [00:06<00:01, 11.81it/s]Downloaded 0.03 GB:  69%|██████▉   | 27/39 [00:06<00:00, 12.46it/s]Downloaded 0.03 GB:  69%|██████▉   | 27/39 [00:06<00:00, 12.46it/s]Downloaded 0.03 GB:  69%|██████▉   | 27/39 [00:06<00:00, 12.46it/s]Downloaded 0.03 GB:  74%|███████▍  | 29/39 [00:06<00:00, 12.93it/s]Downloaded 0.03 GB:  74%|███████▍  | 29/39 [00:06<00:00, 12.93it/s]Downloaded 0.03 GB:  74%|███████▍  | 29/39 [00:06<00:00, 12.93it/s]Downloaded 0.03 GB:  79%|███████▉  | 31/39 [00:06<00:00, 13.31it/s]Downloaded 0.03 GB:  79%|███████▉  | 31/39 [00:06<00:00, 13.31it/s]Downloaded 0.03 GB:  79%|███████▉  | 31/39 [00:07<00:00, 13.31it/s]Downloaded 0.03 GB:  85%|████████▍ | 33/39 [00:07<00:00, 13.62it/s]Downloaded 0.03 GB:  85%|████████▍ | 33/39 [00:07<00:00, 13.62it/s]Downloaded 0.03 GB:  85%|████████▍ | 33/39 [00:07<00:00, 13.62it/s]Downloaded 0.04 GB:  85%|████████▍ | 33/39 [00:07<00:00, 13.62it/s]Downloaded 0.04 GB:  92%|█████████▏| 36/39 [00:07<00:00, 15.68it/s]Downloaded 0.04 GB:  92%|█████████▏| 36/39 [00:07<00:00, 15.68it/s]Downloaded 0.04 GB:  92%|█████████▏| 36/39 [00:07<00:00, 15.68it/s]Downloaded 0.04 GB:  92%|█████████▏| 36/39 [00:07<00:00, 15.68it/s]Downloaded 0.04 GB: 100%|██████████| 39/39 [00:07<00:00,  5.43it/s]
Extracting ./datasets/pcba.zip
Processing...
Loading necessary files...
This might take a while.
Processing graphs...
  0%|          | 0/437929 [00:00<?, ?it/s]  2%|▏         | 9575/437929 [00:00<00:04, 95737.08it/s]  5%|▍         | 20741/437929 [00:00<00:03, 105099.36it/s]  7%|▋         | 31868/437929 [00:00<00:03, 107913.27it/s] 10%|▉         | 43264/437929 [00:00<00:03, 110297.88it/s] 12%|█▏        | 54734/437929 [00:00<00:03, 111881.24it/s] 15%|█▌        | 65923/437929 [00:00<00:03, 110952.97it/s] 18%|█▊        | 77020/437929 [00:00<00:03, 108001.23it/s] 20%|██        | 87836/437929 [00:00<00:03, 106076.91it/s] 22%|██▏       | 98458/437929 [00:00<00:03, 104725.35it/s] 25%|██▍       | 108940/437929 [00:01<00:03, 103919.81it/s] 27%|██▋       | 119338/437929 [00:01<00:03, 103204.58it/s] 30%|██▉       | 129662/437929 [00:01<00:03, 101776.29it/s] 32%|███▏      | 139844/437929 [00:01<00:02, 100702.05it/s] 34%|███▍      | 149917/437929 [00:01<00:02, 99198.58it/s]  37%|███▋      | 159872/437929 [00:01<00:02, 99299.67it/s] 39%|███▉      | 169805/437929 [00:01<00:02, 98343.43it/s] 41%|████      | 179666/437929 [00:01<00:02, 98417.66it/s] 43%|████▎     | 189510/437929 [00:01<00:02, 98182.63it/s] 46%|████▌     | 199330/437929 [00:01<00:02, 97611.19it/s] 48%|████▊     | 209225/437929 [00:02<00:02, 98005.37it/s] 50%|█████     | 219027/437929 [00:02<00:02, 97451.56it/s] 52%|█████▏    | 228774/437929 [00:02<00:02, 97273.60it/s] 54%|█████▍    | 238621/437929 [00:02<00:02, 97627.95it/s] 57%|█████▋    | 248385/437929 [00:02<00:01, 97059.85it/s] 59%|█████▉    | 258310/437929 [00:02<00:01, 97709.08it/s] 61%|██████    | 268129/437929 [00:02<00:01, 97849.57it/s] 63%|██████▎   | 278012/437929 [00:02<00:01, 98140.30it/s] 66%|██████▌   | 288050/437929 [00:02<00:01, 98807.30it/s] 68%|██████▊   | 297932/437929 [00:02<00:01, 98342.76it/s] 70%|███████   | 307913/437929 [00:03<00:01, 98778.49it/s] 73%|███████▎  | 317792/437929 [00:03<00:01, 98320.28it/s] 75%|███████▍  | 327625/437929 [00:03<00:01, 98094.99it/s] 77%|███████▋  | 337454/437929 [00:03<00:01, 98150.12it/s] 79%|███████▉  | 347270/437929 [00:03<00:00, 93817.73it/s] 82%|████████▏ | 357311/437929 [00:03<00:00, 95726.62it/s] 84%|████████▍ | 367100/437929 [00:03<00:00, 96357.08it/s] 86%|████████▌ | 376920/437929 [00:03<00:00, 96896.29it/s] 88%|████████▊ | 386951/437929 [00:03<00:00, 97903.17it/s] 91%|█████████ | 396756/437929 [00:03<00:00, 97362.16it/s] 93%|█████████▎| 406911/437929 [00:04<00:00, 98603.33it/s] 95%|█████████▌| 416780/437929 [00:04<00:00, 98597.52it/s] 97%|█████████▋| 426690/437929 [00:04<00:00, 98744.63it/s]100%|█████████▉| 436964/437929 [00:04<00:00, 99934.23it/s]100%|██████████| 437929/437929 [00:04<00:00, 99922.16it/s]
Converting graphs into PyG objects...
  0%|          | 0/437929 [00:00<?, ?it/s]  0%|          | 1328/437929 [00:00<01:20, 5400.67it/s]  1%|▏         | 5803/437929 [00:00<00:21, 19859.20it/s]  2%|▏         | 9877/437929 [00:00<00:15, 27044.00it/s]  3%|▎         | 13288/437929 [00:00<00:23, 17758.18it/s]  4%|▍         | 17599/437929 [00:00<00:17, 23375.51it/s]  5%|▍         | 21859/437929 [00:00<00:14, 27997.63it/s]  6%|▌         | 25988/437929 [00:01<00:13, 31316.78it/s]  7%|▋         | 29705/437929 [00:01<00:18, 22561.79it/s]  8%|▊         | 33966/437929 [00:01<00:15, 26720.70it/s]  9%|▉         | 38347/437929 [00:01<00:13, 30625.97it/s] 10%|▉         | 42746/437929 [00:01<00:11, 33915.21it/s] 11%|█         | 46649/437929 [00:01<00:16, 23359.38it/s] 12%|█▏        | 50966/437929 [00:02<00:14, 27274.26it/s] 13%|█▎        | 55298/437929 [00:02<00:12, 30806.42it/s] 14%|█▎        | 59672/437929 [00:02<00:11, 33899.59it/s] 15%|█▍        | 64054/437929 [00:02<00:10, 36426.01it/s] 16%|█▌        | 68120/437929 [00:02<00:15, 23524.64it/s] 17%|█▋        | 72477/437929 [00:02<00:13, 27387.04it/s] 18%|█▊        | 76871/437929 [00:02<00:11, 30959.55it/s] 19%|█▊        | 81237/437929 [00:02<00:10, 33952.52it/s] 20%|█▉        | 85583/437929 [00:03<00:09, 36230.79it/s] 21%|██        | 89986/437929 [00:03<00:09, 38288.35it/s] 22%|██▏       | 94158/437929 [00:03<00:15, 22807.94it/s] 22%|██▏       | 98452/437929 [00:03<00:12, 26537.58it/s] 23%|██▎       | 102784/437929 [00:03<00:11, 29985.42it/s] 24%|██▍       | 107171/437929 [00:03<00:09, 33175.17it/s] 25%|██▌       | 111435/437929 [00:03<00:09, 35512.73it/s] 26%|██▋       | 115761/437929 [00:04<00:08, 37532.74it/s] 27%|██▋       | 120132/437929 [00:04<00:08, 39208.49it/s] 28%|██▊       | 124490/437929 [00:04<00:07, 40428.20it/s] 29%|██▉       | 128742/437929 [00:04<00:13, 22176.83it/s] 30%|███       | 133141/437929 [00:04<00:11, 26094.19it/s] 31%|███▏      | 137529/437929 [00:04<00:10, 29737.17it/s] 32%|███▏      | 141760/437929 [00:04<00:09, 32570.64it/s] 33%|███▎      | 146113/437929 [00:04<00:08, 35247.44it/s] 34%|███▍      | 150341/437929 [00:05<00:07, 37065.25it/s] 35%|███▌      | 154738/437929 [00:05<00:07, 38896.89it/s] 36%|███▋      | 159150/437929 [00:05<00:06, 40348.49it/s] 37%|███▋      | 163501/437929 [00:05<00:06, 41246.32it/s] 38%|███▊      | 167793/437929 [00:05<00:13, 20711.54it/s] 39%|███▉      | 172110/437929 [00:05<00:10, 24528.01it/s] 40%|████      | 176288/437929 [00:06<00:09, 27897.85it/s] 41%|████▏     | 180720/437929 [00:06<00:08, 31480.90it/s] 42%|████▏     | 185098/437929 [00:06<00:07, 34403.17it/s] 43%|████▎     | 189446/437929 [00:06<00:06, 36701.21it/s] 44%|████▍     | 193794/437929 [00:06<00:06, 38501.21it/s] 45%|████▌     | 198089/437929 [00:06<00:06, 39724.88it/s] 46%|████▌     | 202498/437929 [00:06<00:05, 40955.13it/s] 47%|████▋     | 206884/437929 [00:06<00:05, 41788.53it/s] 48%|████▊     | 211318/437929 [00:06<00:05, 42530.21it/s] 49%|████▉     | 215673/437929 [00:06<00:05, 42633.18it/s] 50%|█████     | 220016/437929 [00:07<00:05, 42866.40it/s] 51%|█████     | 224353/437929 [00:07<00:11, 19170.53it/s] 52%|█████▏    | 228681/437929 [00:07<00:09, 22994.95it/s] 53%|█████▎    | 232913/437929 [00:07<00:07, 26563.26it/s] 54%|█████▍    | 237247/437929 [00:07<00:06, 30065.01it/s] 55%|█████▌    | 241659/437929 [00:07<00:05, 33292.52it/s] 56%|█████▌    | 245892/437929 [00:08<00:05, 35524.78it/s] 57%|█████▋    | 250351/437929 [00:08<00:04, 37888.01it/s] 58%|█████▊    | 254710/437929 [00:08<00:04, 39434.82it/s] 59%|█████▉    | 259046/437929 [00:08<00:04, 40530.39it/s] 60%|██████    | 263470/437929 [00:08<00:04, 41587.85it/s] 61%|██████    | 267800/437929 [00:08<00:04, 41907.73it/s] 62%|██████▏   | 272228/437929 [00:08<00:03, 42598.99it/s] 63%|██████▎   | 276621/437929 [00:08<00:03, 42989.59it/s] 64%|██████▍   | 280981/437929 [00:08<00:03, 43055.80it/s] 65%|██████▌   | 285378/437929 [00:08<00:03, 43324.17it/s] 66%|██████▌   | 289741/437929 [00:09<00:09, 16096.68it/s] 67%|██████▋   | 294042/437929 [00:09<00:07, 19760.47it/s] 68%|██████▊   | 298461/437929 [00:09<00:05, 23737.40it/s] 69%|██████▉   | 302741/437929 [00:09<00:04, 27333.90it/s] 70%|███████   | 306983/437929 [00:10<00:04, 30536.91it/s] 71%|███████   | 311227/437929 [00:10<00:03, 33305.65it/s] 72%|███████▏  | 315595/437929 [00:10<00:03, 35893.03it/s] 73%|███████▎  | 320012/437929 [00:10<00:03, 38067.19it/s] 74%|███████▍  | 324348/437929 [00:10<00:02, 39508.96it/s] 75%|███████▌  | 328626/437929 [00:10<00:02, 40327.87it/s] 76%|███████▌  | 333045/437929 [00:10<00:02, 41430.26it/s] 77%|███████▋  | 337413/437929 [00:10<00:02, 42081.17it/s] 78%|███████▊  | 341809/437929 [00:10<00:02, 42629.87it/s] 79%|███████▉  | 346158/437929 [00:10<00:02, 42617.25it/s] 80%|████████  | 350480/437929 [00:11<00:02, 42666.32it/s] 81%|████████  | 354789/437929 [00:11<00:01, 41938.96it/s] 82%|████████▏ | 359119/437929 [00:11<00:01, 42336.15it/s] 83%|████████▎ | 363541/437929 [00:11<00:01, 42823.12it/s] 84%|████████▍ | 367885/437929 [00:11<00:01, 43004.03it/s] 85%|████████▍ | 372198/437929 [00:12<00:04, 14396.04it/s] 86%|████████▌ | 376595/437929 [00:12<00:03, 18068.29it/s] 87%|████████▋ | 380909/437929 [00:12<00:02, 21849.62it/s] 88%|████████▊ | 385250/437929 [00:12<00:02, 25671.09it/s] 89%|████████▉ | 389573/437929 [00:12<00:01, 29197.88it/s] 90%|████████▉ | 393944/437929 [00:12<00:01, 32446.55it/s] 91%|█████████ | 398113/437929 [00:12<00:01, 34684.56it/s] 92%|█████████▏| 402423/437929 [00:12<00:00, 36846.47it/s] 93%|█████████▎| 406749/437929 [00:13<00:00, 38567.41it/s] 94%|█████████▍| 411092/437929 [00:13<00:00, 39913.42it/s] 95%|█████████▍| 415397/437929 [00:13<00:00, 40802.94it/s] 96%|█████████▌| 419827/437929 [00:13<00:00, 41809.99it/s] 97%|█████████▋| 424192/437929 [00:13<00:00, 42345.30it/s] 98%|█████████▊| 428529/437929 [00:13<00:00, 42557.65it/s] 99%|█████████▉| 432857/437929 [00:13<00:00, 42502.76it/s]100%|█████████▉| 437158/437929 [00:13<00:00, 42540.30it/s]100%|██████████| 437929/437929 [00:13<00:00, 31850.21it/s]
Saving...
Done!
2025-08-16 03:57:10,412 - INFO - [*] Loaded dataset 'ogbg-molpcba' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 03:57:10,414 - INFO -   Data(edge_index=[2, 24618372], edge_attr=[24618372, 3], x=[11373137, 9], y=[437929, 128], num_nodes=11373137)
2025-08-16 03:57:10,416 - INFO -   undirected: True
2025-08-16 03:57:10,416 - INFO -   num graphs: 437929
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 03:57:10,418 - INFO -   avg num_nodes/graph: 25
2025-08-16 03:57:10,418 - INFO -   num node features: 9
2025-08-16 03:57:10,418 - INFO -   num edge features: 3
2025-08-16 03:57:10,418 - INFO -   num tasks: 128
2025-08-16 03:57:10,419 - INFO -   num classes: 2
2025-08-16 03:57:10,420 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 03:57:10,420 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 03:57:10,424 - INFO -   ...estimated to be undirected: True
  0%|          | 0/437929 [00:00<?, ?it/s]  0%|          | 0/437929 [00:17<?, ?it/s]  3%|▎         | 13765/437929 [00:17<09:05, 777.92it/s]  5%|▍         | 21847/437929 [00:27<08:45, 791.43it/s]  7%|▋         | 30305/437929 [00:37<08:21, 812.61it/s]  9%|▉         | 38906/437929 [00:47<08:00, 829.57it/s] 11%|█         | 47391/437929 [00:57<07:47, 835.97it/s] 13%|█▎        | 55811/437929 [01:07<07:40, 830.26it/s] 15%|█▍        | 63646/437929 [01:17<07:38, 815.48it/s] 17%|█▋        | 72286/437929 [01:27<07:20, 830.56it/s] 18%|█▊        | 80248/437929 [01:37<07:16, 819.98it/s] 20%|██        | 88584/437929 [01:47<07:03, 824.10it/s] 22%|██▏       | 96500/437929 [01:57<06:59, 814.22it/s] 24%|██▎       | 103842/437929 [02:07<07:02, 790.01it/s] 26%|██▌       | 111750/437929 [02:17<06:52, 790.24it/s] 27%|██▋       | 119404/437929 [02:27<06:46, 782.74it/s] 29%|██▉       | 127319/437929 [02:37<06:35, 785.35it/s] 31%|███       | 134921/437929 [02:47<06:29, 777.78it/s] 32%|███▏      | 142231/437929 [02:57<06:27, 763.73it/s] 34%|███▍      | 150233/437929 [03:07<06:11, 774.65it/s] 36%|███▌      | 158626/437929 [03:17<05:51, 794.06it/s] 38%|███▊      | 166198/437929 [03:27<05:47, 782.97it/s] 40%|███▉      | 173052/437929 [03:37<05:51, 753.67it/s] 41%|████      | 180642/437929 [03:47<05:40, 755.26it/s] 43%|████▎     | 188189/437929 [03:57<05:30, 755.09it/s] 45%|████▍     | 195769/437929 [04:07<05:20, 755.95it/s] 46%|████▋     | 203595/437929 [04:17<05:06, 763.94it/s] 48%|████▊     | 211205/437929 [04:27<04:57, 763.03it/s] 50%|████▉     | 217700/437929 [04:37<05:02, 728.96it/s] 51%|█████▏    | 225298/437929 [04:47<04:48, 738.20it/s] 53%|█████▎    | 232932/437929 [04:57<04:34, 745.75it/s] 55%|█████▍    | 240498/437929 [05:07<04:23, 748.99it/s] 57%|█████▋    | 248062/437929 [05:17<04:12, 751.19it/s] 58%|█████▊    | 255602/437929 [05:27<04:02, 752.01it/s] 60%|██████    | 263067/437929 [05:37<03:53, 750.33it/s] 62%|██████▏   | 270594/437929 [05:47<03:42, 751.02it/s] 63%|██████▎   | 276996/437929 [05:57<03:44, 717.77it/s] 65%|██████▍   | 284572/437929 [06:07<03:30, 729.70it/s] 67%|██████▋   | 292211/437929 [06:17<03:16, 739.96it/s] 68%|██████▊   | 299656/437929 [06:28<03:06, 741.30it/s] 70%|███████   | 307087/437929 [06:38<02:56, 741.82it/s] 72%|███████▏  | 314625/437929 [06:48<02:45, 745.41it/s] 74%|███████▎  | 322208/437929 [06:58<02:34, 749.27it/s] 75%|███████▌  | 329698/437929 [07:08<02:24, 749.16it/s] 77%|███████▋  | 337544/437929 [07:18<02:12, 759.78it/s] 79%|███████▉  | 345125/437929 [07:28<02:02, 759.25it/s] 80%|████████  | 350911/437929 [07:38<02:03, 705.04it/s] 82%|████████▏ | 358390/437929 [07:48<01:50, 717.87it/s] 84%|████████▎ | 365791/437929 [07:58<01:39, 724.52it/s] 85%|████████▌ | 373506/437929 [08:08<01:27, 738.61it/s] 87%|████████▋ | 381060/437929 [08:18<01:16, 743.64it/s] 89%|████████▊ | 388494/437929 [08:28<01:06, 743.57it/s] 90%|█████████ | 395704/437929 [08:38<00:57, 736.80it/s] 92%|█████████▏| 403200/437929 [08:48<00:46, 740.61it/s] 94%|█████████▍| 410768/437929 [08:58<00:36, 745.44it/s] 95%|█████████▌| 418136/437929 [09:08<00:26, 742.82it/s] 97%|█████████▋| 425398/437929 [09:18<00:16, 737.81it/s] 99%|█████████▊| 432445/437929 [09:28<00:07, 727.84it/s]100%|█████████▉| 437755/437929 [09:39<00:00, 642.06it/s]100%|██████████| 437929/437929 [09:39<00:00, 755.45it/s]
2025-08-16 04:07:02,401 - INFO - Done! Took 00:09:51.98
2025-08-16 04:07:04,236 - INFO - [*] Loaded dataset 'ogbg-molpcba' from 'OGB'
2025-08-16 04:07:04,423 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-16 04:07:04,424 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-08-16 04:07:04,424 - INFO - Inner model has get_darts_model: False
2025-08-16 04:07:04,426 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 364)
            (1): Embedding(5, 364)
            (2-3): 2 x Embedding(12, 364)
            (4): Embedding(10, 364)
            (5-6): 2 x Embedding(6, 364)
            (7-8): 2 x Embedding(2, 364)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=20, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 384)
          (1): Embedding(6, 384)
          (2): Embedding(2, 384)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
    )
    (post_mp): GNNGraphHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): Linear(
            (model): Linear(384, 128, bias=True)
          )
        )
      )
    )
  )
)
2025-08-16 04:07:04,427 - INFO - Number of parameters: 9,588,956
2025-08-16 04:07:04,427 - INFO - Starting optimized training: 2025-08-16 04:07:04.427834
2025-08-16 04:08:03,633 - INFO - [*] Loaded dataset 'ogbg-molpcba' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 04:08:03,634 - INFO -   Data(edge_index=[2, 24618372], edge_attr=[24618372, 3], x=[11373137, 9], y=[437929, 128], num_nodes=11373137)
2025-08-16 04:08:03,635 - INFO -   undirected: True
2025-08-16 04:08:03,635 - INFO -   num graphs: 437929
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 04:08:03,636 - INFO -   avg num_nodes/graph: 25
2025-08-16 04:08:03,637 - INFO -   num node features: 9
2025-08-16 04:08:03,637 - INFO -   num edge features: 3
2025-08-16 04:08:03,637 - INFO -   num tasks: 128
2025-08-16 04:08:03,638 - INFO -   num classes: 2
2025-08-16 04:08:03,638 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 04:08:03,638 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 04:08:03,642 - INFO -   ...estimated to be undirected: True
  0%|          | 0/437929 [00:00<?, ?it/s]  0%|          | 0/437929 [00:16<?, ?it/s]  3%|▎         | 12512/437929 [00:16<09:10, 772.83it/s]  5%|▍         | 19958/437929 [00:26<09:10, 759.57it/s]  6%|▋         | 27569/437929 [00:36<08:59, 760.16it/s]  8%|▊         | 35279/437929 [00:46<08:46, 764.08it/s] 10%|▉         | 42689/437929 [00:56<08:42, 756.17it/s] 12%|█▏        | 50572/437929 [01:06<08:25, 766.71it/s] 13%|█▎        | 58497/437929 [01:16<08:09, 774.94it/s] 15%|█▌        | 66732/437929 [01:26<07:49, 790.14it/s] 17%|█▋        | 74171/437929 [01:36<07:48, 775.82it/s] 19%|█▊        | 82089/437929 [01:46<07:35, 780.70it/s] 21%|██        | 89871/437929 [01:56<07:26, 779.93it/s] 22%|██▏       | 97060/437929 [02:06<07:27, 761.42it/s] 24%|██▍       | 104908/437929 [02:16<07:13, 768.47it/s] 26%|██▌       | 112762/437929 [02:26<07:00, 773.56it/s] 27%|██▋       | 120308/437929 [02:36<06:53, 767.84it/s] 29%|██▉       | 128528/437929 [02:46<06:34, 784.11it/s] 31%|███       | 136746/437929 [02:56<06:18, 795.41it/s] 33%|███▎      | 144417/437929 [03:06<06:13, 786.88it/s] 35%|███▍      | 152214/437929 [03:16<06:04, 784.70it/s] 36%|███▋      | 159392/437929 [03:26<06:04, 764.62it/s] 38%|███▊      | 167223/437929 [03:36<05:51, 770.15it/s] 40%|███▉      | 175077/437929 [03:46<05:39, 774.70it/s] 42%|████▏     | 182890/437929 [03:56<05:28, 776.65it/s] 44%|████▎     | 191053/437929 [04:06<05:13, 788.54it/s] 45%|████▌     | 198778/437929 [04:16<05:05, 783.73it/s] 47%|████▋     | 205962/437929 [04:26<05:03, 764.12it/s] 49%|████▉     | 213776/437929 [04:36<04:51, 769.30it/s] 51%|█████     | 221526/437929 [04:46<04:40, 771.00it/s] 52%|█████▏    | 229281/437929 [04:56<04:30, 772.32it/s] 54%|█████▍    | 237117/437929 [05:06<04:18, 775.70it/s] 56%|█████▌    | 244612/437929 [05:16<04:11, 767.83it/s] 58%|█████▊    | 252522/437929 [05:26<03:59, 774.69it/s] 59%|█████▉    | 259444/437929 [05:36<03:57, 749.94it/s] 61%|██████    | 267199/437929 [05:46<03:45, 757.60it/s] 63%|██████▎   | 274935/437929 [05:56<03:33, 762.39it/s] 65%|██████▍   | 282663/437929 [06:06<03:22, 765.51it/s] 66%|██████▋   | 290325/437929 [06:16<03:12, 765.70it/s] 68%|██████▊   | 298062/437929 [06:26<03:02, 768.09it/s] 70%|██████▉   | 305735/437929 [06:36<02:52, 767.83it/s] 72%|███████▏  | 313462/437929 [06:46<02:41, 769.28it/s] 73%|███████▎  | 321234/437929 [06:56<02:31, 771.64it/s] 75%|███████▍  | 327116/437929 [07:06<02:34, 716.60it/s] 76%|███████▋  | 334843/437929 [07:16<02:20, 733.41it/s] 78%|███████▊  | 342696/437929 [07:26<02:07, 748.95it/s] 80%|███████▉  | 349834/437929 [07:36<01:59, 738.40it/s] 82%|████████▏ | 357499/437929 [07:46<01:47, 746.81it/s] 83%|████████▎ | 365645/437929 [07:56<01:34, 767.13it/s] 85%|████████▌ | 373509/437929 [08:06<01:23, 772.89it/s] 87%|████████▋ | 381231/437929 [08:16<01:13, 772.66it/s] 89%|████████▉ | 389543/437929 [08:26<01:01, 790.22it/s] 91%|█████████ | 397059/437929 [08:36<00:52, 778.61it/s] 92%|█████████▏| 404707/437929 [08:46<00:42, 774.44it/s] 94%|█████████▍| 410724/437929 [08:56<00:37, 722.62it/s] 96%|█████████▌| 418339/437929 [09:06<00:26, 734.26it/s] 97%|█████████▋| 425981/437929 [09:16<00:16, 743.23it/s] 99%|█████████▉| 433771/437929 [09:26<00:05, 753.96it/s]100%|██████████| 437929/437929 [09:31<00:00, 766.13it/s]
2025-08-16 04:17:47,098 - INFO - Done! Took 00:09:43.46
2025-08-16 04:17:48,902 - INFO - [*] Loaded dataset 'ogbg-molpcba' from 'OGB'
2025-08-16 04:17:49,075 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-16 04:17:49,075 - INFO - Start from epoch 0
2025-08-16 04:21:27,665 - INFO - train: {'epoch': 0, 'time_epoch': 207.43405, 'eta': 20535.97072, 'eta_hours': 5.70444, 'loss': 0.70138463, 'lr': 0.0, 'params': 9588956, 'time_iter': 0.30282, 'accuracy': 0.50393, 'auc': 0.50117, 'ap': 0.02249}
2025-08-16 04:21:27,682 - INFO - ...computing epoch stats took: 11.16s
2025-08-16 04:21:47,609 - INFO - val: {'epoch': 0, 'time_epoch': 18.21876, 'loss': 0.69893581, 'lr': 0, 'params': 9588956, 'time_iter': 0.21185, 'accuracy': 0.52806, 'auc': 0.49505, 'ap': 0.02889}
2025-08-16 04:21:47,613 - INFO - ...computing epoch stats took: 1.71s
2025-08-16 04:22:03,373 - INFO - test: {'epoch': 0, 'time_epoch': 14.30145, 'loss': 0.69943443, 'lr': 0, 'params': 9588956, 'time_iter': 0.1663, 'accuracy': 0.5271, 'auc': 0.48965, 'ap': 0.02779}
2025-08-16 04:22:03,376 - INFO - ...computing epoch stats took: 1.46s
2025-08-16 04:22:03,376 - INFO - > Epoch 0: took 254.3s (avg 254.3s) | Best so far: epoch 0	train_loss: 0.7014 train_ap: 0.0225	val_loss: 0.6989 val_ap: 0.0289	test_loss: 0.6994 test_ap: 0.0278
2025-08-16 04:24:59,498 - INFO - train: {'epoch': 1, 'time_epoch': 166.12741, 'eta': 18304.51134, 'eta_hours': 5.08459, 'loss': 0.44920475, 'lr': 0.0001, 'params': 9588956, 'time_iter': 0.24252, 'accuracy': 0.88585, 'auc': 0.54, 'ap': 0.03038}
2025-08-16 04:24:59,513 - INFO - ...computing epoch stats took: 9.99s
2025-08-16 04:25:09,883 - INFO - val: {'epoch': 1, 'time_epoch': 8.95851, 'loss': 0.48452116, 'lr': 0, 'params': 9588956, 'time_iter': 0.10417, 'accuracy': 0.75561, 'auc': 0.56064, 'ap': 0.03688}
2025-08-16 04:25:09,885 - INFO - ...computing epoch stats took: 1.41s
2025-08-16 04:25:20,922 - INFO - test: {'epoch': 1, 'time_epoch': 9.61441, 'loss': 0.48053707, 'lr': 0, 'params': 9588956, 'time_iter': 0.1118, 'accuracy': 0.76313, 'auc': 0.55058, 'ap': 0.03714}
2025-08-16 04:25:20,924 - INFO - ...computing epoch stats took: 1.42s
2025-08-16 04:25:20,924 - INFO - > Epoch 1: took 197.5s (avg 225.9s) | Best so far: epoch 1	train_loss: 0.4492 train_ap: 0.0304	val_loss: 0.4845 val_ap: 0.0369	test_loss: 0.4805 test_ap: 0.0371
2025-08-16 04:28:16,951 - INFO - train: {'epoch': 2, 'time_epoch': 166.08365, 'eta': 17448.52493, 'eta_hours': 4.84681, 'loss': 0.12604821, 'lr': 0.0002, 'params': 9588956, 'time_iter': 0.24246, 'accuracy': 0.97362, 'auc': 0.5435, 'ap': 0.03051}
2025-08-16 04:28:16,959 - INFO - ...computing epoch stats took: 9.94s
2025-08-16 04:28:27,330 - INFO - val: {'epoch': 2, 'time_epoch': 8.94076, 'loss': 0.08018805, 'lr': 0, 'params': 9588956, 'time_iter': 0.10396, 'accuracy': 0.963, 'auc': 0.6058, 'ap': 0.04366}
2025-08-16 04:28:27,332 - INFO - ...computing epoch stats took: 1.43s
2025-08-16 04:28:38,374 - INFO - test: {'epoch': 2, 'time_epoch': 9.62991, 'loss': 0.08297506, 'lr': 0, 'params': 9588956, 'time_iter': 0.11198, 'accuracy': 0.96122, 'auc': 0.60649, 'ap': 0.0443}
2025-08-16 04:28:38,376 - INFO - ...computing epoch stats took: 1.41s
2025-08-16 04:28:38,376 - INFO - > Epoch 2: took 197.5s (avg 216.4s) | Best so far: epoch 2	train_loss: 0.1260 train_ap: 0.0305	val_loss: 0.0802 val_ap: 0.0437	test_loss: 0.0830 test_ap: 0.0443
2025-08-16 04:31:30,066 - INFO - train: {'epoch': 3, 'time_epoch': 161.5393, 'eta': 16828.42574, 'eta_hours': 4.67456, 'loss': 0.05458097, 'lr': 0.0003, 'params': 9588956, 'time_iter': 0.23582, 'accuracy': 0.9797, 'auc': 0.60807, 'ap': 0.03695}
2025-08-16 04:31:40,413 - INFO - val: {'epoch': 3, 'time_epoch': 8.92597, 'loss': 0.06757935, 'lr': 0, 'params': 9588956, 'time_iter': 0.10379, 'accuracy': 0.96999, 'auc': 0.64915, 'ap': 0.04756}
2025-08-16 04:31:51,369 - INFO - test: {'epoch': 3, 'time_epoch': 9.58347, 'loss': 0.06985223, 'lr': 0, 'params': 9588956, 'time_iter': 0.11144, 'accuracy': 0.9687, 'auc': 0.65494, 'ap': 0.04814}
2025-08-16 04:31:51,371 - INFO - > Epoch 3: took 193.0s (avg 210.6s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 04:34:47,077 - INFO - train: {'epoch': 4, 'time_epoch': 165.56656, 'eta': 16468.26826, 'eta_hours': 4.57452, 'loss': 0.05451343, 'lr': 0.0004, 'params': 9588956, 'time_iter': 0.2417, 'accuracy': 0.97937, 'auc': 0.59324, 'ap': 0.03112}
2025-08-16 04:34:57,421 - INFO - val: {'epoch': 4, 'time_epoch': 8.92512, 'loss': 0.06597126, 'lr': 0, 'params': 9588956, 'time_iter': 0.10378, 'accuracy': 0.97603, 'auc': 0.55832, 'ap': 0.03629}
2025-08-16 04:35:08,343 - INFO - test: {'epoch': 4, 'time_epoch': 9.57697, 'loss': 0.06833116, 'lr': 0, 'params': 9588956, 'time_iter': 0.11136, 'accuracy': 0.97482, 'auc': 0.55769, 'ap': 0.03655}
2025-08-16 04:35:08,345 - INFO - > Epoch 4: took 197.0s (avg 207.9s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 04:37:59,586 - INFO - train: {'epoch': 5, 'time_epoch': 161.12124, 'eta': 16103.33109, 'eta_hours': 4.47315, 'loss': 0.05532027, 'lr': 0.0005, 'params': 9588956, 'time_iter': 0.23521, 'accuracy': 0.97934, 'auc': 0.53254, 'ap': 0.02419}
2025-08-16 04:38:09,883 - INFO - val: {'epoch': 5, 'time_epoch': 8.90003, 'loss': 0.06752974, 'lr': 0, 'params': 9588956, 'time_iter': 0.10349, 'accuracy': 0.97603, 'auc': 0.53227, 'ap': 0.02636}
2025-08-16 04:38:20,795 - INFO - test: {'epoch': 5, 'time_epoch': 9.55653, 'loss': 0.06971597, 'lr': 0, 'params': 9588956, 'time_iter': 0.11112, 'accuracy': 0.97482, 'auc': 0.534, 'ap': 0.02808}
2025-08-16 04:38:20,798 - INFO - > Epoch 5: took 192.5s (avg 205.3s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 04:41:16,006 - INFO - train: {'epoch': 6, 'time_epoch': 165.05885, 'eta': 15848.94112, 'eta_hours': 4.40248, 'loss': 0.05521816, 'lr': 0.00049986, 'params': 9588956, 'time_iter': 0.24096, 'accuracy': 0.97942, 'auc': 0.5456, 'ap': 0.02524}
2025-08-16 04:41:26,272 - INFO - val: {'epoch': 6, 'time_epoch': 8.8924, 'loss': 0.06636903, 'lr': 0, 'params': 9588956, 'time_iter': 0.1034, 'accuracy': 0.97603, 'auc': 0.531, 'ap': 0.02864}
2025-08-16 04:41:37,153 - INFO - test: {'epoch': 6, 'time_epoch': 9.51863, 'loss': 0.06868269, 'lr': 0, 'params': 9588956, 'time_iter': 0.11068, 'accuracy': 0.97482, 'auc': 0.5338, 'ap': 0.02974}
2025-08-16 04:41:37,156 - INFO - > Epoch 6: took 196.4s (avg 204.0s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 04:44:30,948 - INFO - train: {'epoch': 7, 'time_epoch': 163.59157, 'eta': 15600.01014, 'eta_hours': 4.33334, 'loss': 0.0551778, 'lr': 0.00049945, 'params': 9588956, 'time_iter': 0.23882, 'accuracy': 0.97945, 'auc': 0.53863, 'ap': 0.02506}
2025-08-16 04:44:41,202 - INFO - val: {'epoch': 7, 'time_epoch': 8.84485, 'loss': 0.065734, 'lr': 0, 'params': 9588956, 'time_iter': 0.10285, 'accuracy': 0.97603, 'auc': 0.49134, 'ap': 0.02334}
2025-08-16 04:44:52,012 - INFO - test: {'epoch': 7, 'time_epoch': 9.45812, 'loss': 0.06809479, 'lr': 0, 'params': 9588956, 'time_iter': 0.10998, 'accuracy': 0.97482, 'auc': 0.5043, 'ap': 0.0263}
2025-08-16 04:44:52,014 - INFO - > Epoch 7: took 194.9s (avg 202.9s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 04:47:42,506 - INFO - train: {'epoch': 8, 'time_epoch': 160.42675, 'eta': 15338.04362, 'eta_hours': 4.26057, 'loss': 0.05525703, 'lr': 0.00049877, 'params': 9588956, 'time_iter': 0.2342, 'accuracy': 0.97949, 'auc': 0.53155, 'ap': 0.02524}
2025-08-16 04:47:52,607 - INFO - val: {'epoch': 8, 'time_epoch': 8.81497, 'loss': 0.0661112, 'lr': 0, 'params': 9588956, 'time_iter': 0.1025, 'accuracy': 0.97603, 'auc': 0.48925, 'ap': 0.02578}
2025-08-16 04:48:03,319 - INFO - test: {'epoch': 8, 'time_epoch': 9.45103, 'loss': 0.06851092, 'lr': 0, 'params': 9588956, 'time_iter': 0.1099, 'accuracy': 0.97482, 'auc': 0.49044, 'ap': 0.02646}
2025-08-16 04:48:03,322 - INFO - > Epoch 8: took 191.3s (avg 201.6s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 04:50:56,490 - INFO - train: {'epoch': 9, 'time_epoch': 163.19138, 'eta': 15121.26671, 'eta_hours': 4.20035, 'loss': 0.05534018, 'lr': 0.00049782, 'params': 9588956, 'time_iter': 0.23824, 'accuracy': 0.97947, 'auc': 0.52331, 'ap': 0.02425}
2025-08-16 04:51:06,671 - INFO - val: {'epoch': 9, 'time_epoch': 8.8298, 'loss': 0.0659239, 'lr': 0, 'params': 9588956, 'time_iter': 0.10267, 'accuracy': 0.97603, 'auc': 0.54241, 'ap': 0.02819}
2025-08-16 04:51:17,422 - INFO - test: {'epoch': 9, 'time_epoch': 9.44187, 'loss': 0.06829292, 'lr': 0, 'params': 9588956, 'time_iter': 0.10979, 'accuracy': 0.97482, 'auc': 0.52962, 'ap': 0.02787}
2025-08-16 04:51:17,424 - INFO - > Epoch 9: took 194.1s (avg 200.8s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 04:54:08,482 - INFO - train: {'epoch': 10, 'time_epoch': 161.0268, 'eta': 14896.7192, 'eta_hours': 4.13798, 'loss': 0.05538288, 'lr': 0.00049659, 'params': 9588956, 'time_iter': 0.23508, 'accuracy': 0.97941, 'auc': 0.5167, 'ap': 0.02325}
2025-08-16 04:54:18,506 - INFO - val: {'epoch': 10, 'time_epoch': 8.76357, 'loss': 0.06569038, 'lr': 0, 'params': 9588956, 'time_iter': 0.1019, 'accuracy': 0.97603, 'auc': 0.49788, 'ap': 0.0246}
2025-08-16 04:54:29,101 - INFO - test: {'epoch': 10, 'time_epoch': 9.40372, 'loss': 0.06806676, 'lr': 0, 'params': 9588956, 'time_iter': 0.10935, 'accuracy': 0.97482, 'auc': 0.50508, 'ap': 0.02622}
2025-08-16 04:54:29,103 - INFO - > Epoch 10: took 191.7s (avg 200.0s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 04:57:21,497 - INFO - train: {'epoch': 11, 'time_epoch': 162.43756, 'eta': 14693.10405, 'eta_hours': 4.08142, 'loss': 0.05542285, 'lr': 0.00049509, 'params': 9588956, 'time_iter': 0.23714, 'accuracy': 0.97936, 'auc': 0.51493, 'ap': 0.02273}
2025-08-16 04:57:31,493 - INFO - val: {'epoch': 11, 'time_epoch': 8.77928, 'loss': 0.06668259, 'lr': 0, 'params': 9588956, 'time_iter': 0.10208, 'accuracy': 0.97603, 'auc': 0.47088, 'ap': 0.02205}
2025-08-16 04:57:42,228 - INFO - test: {'epoch': 11, 'time_epoch': 9.42876, 'loss': 0.06914039, 'lr': 0, 'params': 9588956, 'time_iter': 0.10964, 'accuracy': 0.97482, 'auc': 0.46986, 'ap': 0.02314}
2025-08-16 04:57:42,230 - INFO - > Epoch 11: took 193.1s (avg 199.4s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:00:36,570 - INFO - train: {'epoch': 12, 'time_epoch': 164.11603, 'eta': 14507.05681, 'eta_hours': 4.02974, 'loss': 0.05538218, 'lr': 0.00049333, 'params': 9588956, 'time_iter': 0.23959, 'accuracy': 0.9794, 'auc': 0.51972, 'ap': 0.02312}
2025-08-16 05:00:46,784 - INFO - val: {'epoch': 12, 'time_epoch': 8.98371, 'loss': 0.06592787, 'lr': 0, 'params': 9588956, 'time_iter': 0.10446, 'accuracy': 0.97603, 'auc': 0.52226, 'ap': 0.02763}
2025-08-16 05:00:57,806 - INFO - test: {'epoch': 12, 'time_epoch': 9.7129, 'loss': 0.06830965, 'lr': 0, 'params': 9588956, 'time_iter': 0.11294, 'accuracy': 0.97482, 'auc': 0.52462, 'ap': 0.02819}
2025-08-16 05:00:57,808 - INFO - > Epoch 12: took 195.6s (avg 199.1s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:03:50,103 - INFO - train: {'epoch': 13, 'time_epoch': 161.98169, 'eta': 14311.03163, 'eta_hours': 3.97529, 'loss': 0.05542398, 'lr': 0.0004913, 'params': 9588956, 'time_iter': 0.23647, 'accuracy': 0.97936, 'auc': 0.5163, 'ap': 0.02291}
2025-08-16 05:04:00,224 - INFO - val: {'epoch': 13, 'time_epoch': 8.90604, 'loss': 0.0658938, 'lr': 0, 'params': 9588956, 'time_iter': 0.10356, 'accuracy': 0.97603, 'auc': 0.48551, 'ap': 0.02466}
2025-08-16 05:04:11,163 - INFO - test: {'epoch': 13, 'time_epoch': 9.6953, 'loss': 0.06826744, 'lr': 0, 'params': 9588956, 'time_iter': 0.11274, 'accuracy': 0.97482, 'auc': 0.48335, 'ap': 0.02593}
2025-08-16 05:04:11,166 - INFO - > Epoch 13: took 193.4s (avg 198.7s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:07:05,353 - INFO - train: {'epoch': 14, 'time_epoch': 163.21769, 'eta': 14126.54957, 'eta_hours': 3.92404, 'loss': 0.05542044, 'lr': 0.00048901, 'params': 9588956, 'time_iter': 0.23827, 'accuracy': 0.97939, 'auc': 0.5136, 'ap': 0.02293}
2025-08-16 05:07:15,606 - INFO - val: {'epoch': 14, 'time_epoch': 9.06313, 'loss': 0.06637182, 'lr': 0, 'params': 9588956, 'time_iter': 0.10539, 'accuracy': 0.97603, 'auc': 0.51517, 'ap': 0.02467}
2025-08-16 05:07:26,893 - INFO - test: {'epoch': 14, 'time_epoch': 10.01851, 'loss': 0.06876863, 'lr': 0, 'params': 9588956, 'time_iter': 0.11649, 'accuracy': 0.97482, 'auc': 0.50894, 'ap': 0.0256}
2025-08-16 05:07:26,897 - INFO - > Epoch 14: took 195.7s (avg 198.5s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:10:18,413 - INFO - train: {'epoch': 15, 'time_epoch': 161.04337, 'eta': 13933.31039, 'eta_hours': 3.87036, 'loss': 0.05542093, 'lr': 0.00048645, 'params': 9588956, 'time_iter': 0.2351, 'accuracy': 0.97936, 'auc': 0.51093, 'ap': 0.02302}
2025-08-16 05:10:28,547 - INFO - val: {'epoch': 15, 'time_epoch': 8.83383, 'loss': 0.066031, 'lr': 0, 'params': 9588956, 'time_iter': 0.10272, 'accuracy': 0.97603, 'auc': 0.47476, 'ap': 0.02347}
2025-08-16 05:10:43,385 - INFO - test: {'epoch': 15, 'time_epoch': 13.35783, 'loss': 0.06845028, 'lr': 0, 'params': 9588956, 'time_iter': 0.15532, 'accuracy': 0.97482, 'auc': 0.48325, 'ap': 0.02502}
2025-08-16 05:10:43,398 - INFO - > Epoch 15: took 196.5s (avg 198.4s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:13:34,413 - INFO - train: {'epoch': 16, 'time_epoch': 161.12835, 'eta': 13744.27387, 'eta_hours': 3.81785, 'loss': 0.05539689, 'lr': 0.00048364, 'params': 9588956, 'time_iter': 0.23522, 'accuracy': 0.97937, 'auc': 0.51287, 'ap': 0.02326}
2025-08-16 05:13:44,376 - INFO - val: {'epoch': 16, 'time_epoch': 8.79818, 'loss': 0.06594344, 'lr': 0, 'params': 9588956, 'time_iter': 0.1023, 'accuracy': 0.97603, 'auc': 0.50224, 'ap': 0.02415}
2025-08-16 05:13:54,942 - INFO - test: {'epoch': 16, 'time_epoch': 9.43042, 'loss': 0.06835383, 'lr': 0, 'params': 9588956, 'time_iter': 0.10966, 'accuracy': 0.97482, 'auc': 0.51352, 'ap': 0.02588}
2025-08-16 05:13:54,944 - INFO - > Epoch 16: took 191.5s (avg 198.0s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:16:47,278 - INFO - train: {'epoch': 17, 'time_epoch': 162.71411, 'eta': 13565.56226, 'eta_hours': 3.76821, 'loss': 0.05533047, 'lr': 0.00048057, 'params': 9588956, 'time_iter': 0.23754, 'accuracy': 0.97937, 'auc': 0.52243, 'ap': 0.02368}
2025-08-16 05:16:57,198 - INFO - val: {'epoch': 17, 'time_epoch': 8.75888, 'loss': 0.06601695, 'lr': 0, 'params': 9588956, 'time_iter': 0.10185, 'accuracy': 0.97603, 'auc': 0.50297, 'ap': 0.02524}
2025-08-16 05:17:07,677 - INFO - test: {'epoch': 17, 'time_epoch': 9.34875, 'loss': 0.06843312, 'lr': 0, 'params': 9588956, 'time_iter': 0.10871, 'accuracy': 0.97482, 'auc': 0.50251, 'ap': 0.02643}
2025-08-16 05:17:07,679 - INFO - > Epoch 17: took 192.7s (avg 197.7s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:20:00,835 - INFO - train: {'epoch': 18, 'time_epoch': 161.81256, 'eta': 13384.69116, 'eta_hours': 3.71797, 'loss': 0.05528799, 'lr': 0.00047725, 'params': 9588956, 'time_iter': 0.23622, 'accuracy': 0.97943, 'auc': 0.52503, 'ap': 0.02394}
2025-08-16 05:20:12,509 - INFO - val: {'epoch': 18, 'time_epoch': 10.01753, 'loss': 0.06622733, 'lr': 0, 'params': 9588956, 'time_iter': 0.11648, 'accuracy': 0.97603, 'auc': 0.50682, 'ap': 0.02597}
2025-08-16 05:20:23,356 - INFO - test: {'epoch': 18, 'time_epoch': 9.40122, 'loss': 0.06866608, 'lr': 0, 'params': 9588956, 'time_iter': 0.10932, 'accuracy': 0.97482, 'auc': 0.50297, 'ap': 0.02733}
2025-08-16 05:20:23,358 - INFO - > Epoch 18: took 195.7s (avg 197.6s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:23:20,386 - INFO - train: {'epoch': 19, 'time_epoch': 167.07625, 'eta': 13226.78067, 'eta_hours': 3.67411, 'loss': 0.05528348, 'lr': 0.00047368, 'params': 9588956, 'time_iter': 0.24391, 'accuracy': 0.97944, 'auc': 0.52557, 'ap': 0.02407}
2025-08-16 05:23:30,422 - INFO - val: {'epoch': 19, 'time_epoch': 8.82889, 'loss': 0.06583855, 'lr': 0, 'params': 9588956, 'time_iter': 0.10266, 'accuracy': 0.97603, 'auc': 0.49238, 'ap': 0.02537}
2025-08-16 05:23:41,221 - INFO - test: {'epoch': 19, 'time_epoch': 9.49321, 'loss': 0.0682102, 'lr': 0, 'params': 9588956, 'time_iter': 0.11039, 'accuracy': 0.97482, 'auc': 0.4838, 'ap': 0.02631}
2025-08-16 05:23:41,224 - INFO - > Epoch 19: took 197.9s (avg 197.6s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:26:30,946 - INFO - train: {'epoch': 20, 'time_epoch': 160.0972, 'eta': 13041.74272, 'eta_hours': 3.62271, 'loss': 0.05538271, 'lr': 0.00046987, 'params': 9588956, 'time_iter': 0.23372, 'accuracy': 0.97942, 'auc': 0.51735, 'ap': 0.0238}
2025-08-16 05:26:40,923 - INFO - val: {'epoch': 20, 'time_epoch': 8.75176, 'loss': 0.06575089, 'lr': 0, 'params': 9588956, 'time_iter': 0.10176, 'accuracy': 0.97603, 'auc': 0.49625, 'ap': 0.02532}
2025-08-16 05:26:54,544 - INFO - test: {'epoch': 20, 'time_epoch': 12.42642, 'loss': 0.06814531, 'lr': 0, 'params': 9588956, 'time_iter': 0.14449, 'accuracy': 0.97482, 'auc': 0.48969, 'ap': 0.02654}
2025-08-16 05:26:54,546 - INFO - > Epoch 20: took 193.3s (avg 197.4s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:29:43,495 - INFO - train: {'epoch': 21, 'time_epoch': 159.30835, 'eta': 12856.17529, 'eta_hours': 3.57116, 'loss': 0.05535746, 'lr': 0.00046581, 'params': 9588956, 'time_iter': 0.23257, 'accuracy': 0.97945, 'auc': 0.52406, 'ap': 0.02384}
2025-08-16 05:29:53,570 - INFO - val: {'epoch': 21, 'time_epoch': 8.82865, 'loss': 0.06563974, 'lr': 0, 'params': 9588956, 'time_iter': 0.10266, 'accuracy': 0.97603, 'auc': 0.50962, 'ap': 0.02648}
2025-08-16 05:30:04,277 - INFO - test: {'epoch': 21, 'time_epoch': 9.45795, 'loss': 0.06798511, 'lr': 0, 'params': 9588956, 'time_iter': 0.10998, 'accuracy': 0.97482, 'auc': 0.51039, 'ap': 0.02773}
2025-08-16 05:30:04,279 - INFO - > Epoch 21: took 189.7s (avg 197.1s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:32:56,740 - INFO - train: {'epoch': 22, 'time_epoch': 162.83121, 'eta': 12684.68518, 'eta_hours': 3.52352, 'loss': 0.05524893, 'lr': 0.00046152, 'params': 9588956, 'time_iter': 0.23771, 'accuracy': 0.97942, 'auc': 0.53457, 'ap': 0.02435}
2025-08-16 05:33:06,614 - INFO - val: {'epoch': 22, 'time_epoch': 8.76649, 'loss': 0.06687513, 'lr': 0, 'params': 9588956, 'time_iter': 0.10194, 'accuracy': 0.97414, 'auc': 0.49326, 'ap': 0.02495}
2025-08-16 05:33:17,092 - INFO - test: {'epoch': 22, 'time_epoch': 9.40546, 'loss': 0.06928019, 'lr': 0, 'params': 9588956, 'time_iter': 0.10937, 'accuracy': 0.97272, 'auc': 0.49614, 'ap': 0.02632}
2025-08-16 05:33:17,094 - INFO - > Epoch 22: took 192.8s (avg 196.9s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:36:06,372 - INFO - train: {'epoch': 23, 'time_epoch': 159.54861, 'eta': 12503.52173, 'eta_hours': 3.4732, 'loss': 0.05523579, 'lr': 0.000457, 'params': 9588956, 'time_iter': 0.23292, 'accuracy': 0.97949, 'auc': 0.53633, 'ap': 0.02495}
2025-08-16 05:36:16,298 - INFO - val: {'epoch': 23, 'time_epoch': 8.76752, 'loss': 0.06815957, 'lr': 0, 'params': 9588956, 'time_iter': 0.10195, 'accuracy': 0.97414, 'auc': 0.47941, 'ap': 0.02447}
2025-08-16 05:36:26,841 - INFO - test: {'epoch': 23, 'time_epoch': 9.45339, 'loss': 0.07060941, 'lr': 0, 'params': 9588956, 'time_iter': 0.10992, 'accuracy': 0.97272, 'auc': 0.4898, 'ap': 0.02556}
2025-08-16 05:36:26,844 - INFO - > Epoch 23: took 189.7s (avg 196.6s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:39:19,551 - INFO - train: {'epoch': 24, 'time_epoch': 163.01138, 'eta': 12334.47579, 'eta_hours': 3.42624, 'loss': 0.05519371, 'lr': 0.00045225, 'params': 9588956, 'time_iter': 0.23797, 'accuracy': 0.97952, 'auc': 0.54033, 'ap': 0.02532}
2025-08-16 05:39:29,421 - INFO - val: {'epoch': 24, 'time_epoch': 8.75754, 'loss': 0.06697184, 'lr': 0, 'params': 9588956, 'time_iter': 0.10183, 'accuracy': 0.97414, 'auc': 0.50177, 'ap': 0.02505}
2025-08-16 05:39:39,924 - INFO - test: {'epoch': 24, 'time_epoch': 9.41244, 'loss': 0.06933072, 'lr': 0, 'params': 9588956, 'time_iter': 0.10945, 'accuracy': 0.97272, 'auc': 0.49243, 'ap': 0.02619}
2025-08-16 05:39:39,926 - INFO - > Epoch 24: took 193.1s (avg 196.4s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:42:29,041 - INFO - train: {'epoch': 25, 'time_epoch': 159.45838, 'eta': 12155.78166, 'eta_hours': 3.37661, 'loss': 0.05529994, 'lr': 0.00044729, 'params': 9588956, 'time_iter': 0.23279, 'accuracy': 0.97948, 'auc': 0.53343, 'ap': 0.02499}
2025-08-16 05:42:39,062 - INFO - val: {'epoch': 25, 'time_epoch': 8.80195, 'loss': 0.06639513, 'lr': 0, 'params': 9588956, 'time_iter': 0.10235, 'accuracy': 0.97414, 'auc': 0.50644, 'ap': 0.02535}
2025-08-16 05:42:52,683 - INFO - test: {'epoch': 25, 'time_epoch': 12.43313, 'loss': 0.06880746, 'lr': 0, 'params': 9588956, 'time_iter': 0.14457, 'accuracy': 0.97272, 'auc': 0.50151, 'ap': 0.02674}
2025-08-16 05:42:52,685 - INFO - > Epoch 25: took 192.8s (avg 196.3s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:45:40,984 - INFO - train: {'epoch': 26, 'time_epoch': 158.66414, 'eta': 11976.36501, 'eta_hours': 3.32677, 'loss': 0.05521796, 'lr': 0.0004421, 'params': 9588956, 'time_iter': 0.23163, 'accuracy': 0.97934, 'auc': 0.53289, 'ap': 0.02458}
2025-08-16 05:45:50,972 - INFO - val: {'epoch': 26, 'time_epoch': 8.75133, 'loss': 0.06572267, 'lr': 0, 'params': 9588956, 'time_iter': 0.10176, 'accuracy': 0.97603, 'auc': 0.51025, 'ap': 0.02617}
2025-08-16 05:46:01,575 - INFO - test: {'epoch': 26, 'time_epoch': 9.39441, 'loss': 0.06808473, 'lr': 0, 'params': 9588956, 'time_iter': 0.10924, 'accuracy': 0.97482, 'auc': 0.50055, 'ap': 0.02598}
2025-08-16 05:46:01,577 - INFO - > Epoch 26: took 188.9s (avg 196.0s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:48:52,710 - INFO - train: {'epoch': 27, 'time_epoch': 161.54393, 'eta': 11805.83584, 'eta_hours': 3.2794, 'loss': 0.05515062, 'lr': 0.00043671, 'params': 9588956, 'time_iter': 0.23583, 'accuracy': 0.9795, 'auc': 0.53718, 'ap': 0.02571}
2025-08-16 05:49:02,694 - INFO - val: {'epoch': 27, 'time_epoch': 8.74745, 'loss': 0.06634885, 'lr': 0, 'params': 9588956, 'time_iter': 0.10171, 'accuracy': 0.97603, 'auc': 0.50449, 'ap': 0.02637}
2025-08-16 05:49:13,208 - INFO - test: {'epoch': 27, 'time_epoch': 9.31758, 'loss': 0.06872735, 'lr': 0, 'params': 9588956, 'time_iter': 0.10834, 'accuracy': 0.97482, 'auc': 0.5075, 'ap': 0.02712}
2025-08-16 05:49:13,210 - INFO - > Epoch 27: took 191.6s (avg 195.9s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:52:02,505 - INFO - train: {'epoch': 28, 'time_epoch': 159.42067, 'eta': 11630.72803, 'eta_hours': 3.23076, 'loss': 0.05518359, 'lr': 0.00043111, 'params': 9588956, 'time_iter': 0.23273, 'accuracy': 0.9795, 'auc': 0.5374, 'ap': 0.02521}
2025-08-16 05:52:12,449 - INFO - val: {'epoch': 28, 'time_epoch': 8.78176, 'loss': 0.06650707, 'lr': 0, 'params': 9588956, 'time_iter': 0.10211, 'accuracy': 0.97414, 'auc': 0.48802, 'ap': 0.02571}
2025-08-16 05:52:22,993 - INFO - test: {'epoch': 28, 'time_epoch': 9.40822, 'loss': 0.06887692, 'lr': 0, 'params': 9588956, 'time_iter': 0.1094, 'accuracy': 0.97272, 'auc': 0.50842, 'ap': 0.02553}
2025-08-16 05:52:22,995 - INFO - > Epoch 28: took 189.8s (avg 195.7s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:55:15,311 - INFO - train: {'epoch': 29, 'time_epoch': 162.73303, 'eta': 11464.39486, 'eta_hours': 3.18455, 'loss': 0.05517614, 'lr': 0.00042531, 'params': 9588956, 'time_iter': 0.23757, 'accuracy': 0.97945, 'auc': 0.53469, 'ap': 0.02537}
2025-08-16 05:55:25,318 - INFO - val: {'epoch': 29, 'time_epoch': 8.80182, 'loss': 0.06628991, 'lr': 0, 'params': 9588956, 'time_iter': 0.10235, 'accuracy': 0.97603, 'auc': 0.49916, 'ap': 0.02481}
2025-08-16 05:55:35,934 - INFO - test: {'epoch': 29, 'time_epoch': 9.45026, 'loss': 0.06870503, 'lr': 0, 'params': 9588956, 'time_iter': 0.10989, 'accuracy': 0.97482, 'auc': 0.49115, 'ap': 0.02651}
2025-08-16 05:55:35,937 - INFO - > Epoch 29: took 192.9s (avg 195.6s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 05:58:25,333 - INFO - train: {'epoch': 30, 'time_epoch': 159.79006, 'eta': 11291.74347, 'eta_hours': 3.1366, 'loss': 0.05513253, 'lr': 0.00041932, 'params': 9588956, 'time_iter': 0.23327, 'accuracy': 0.97951, 'auc': 0.53856, 'ap': 0.02552}
2025-08-16 05:58:38,340 - INFO - val: {'epoch': 30, 'time_epoch': 11.75838, 'loss': 0.06643273, 'lr': 0, 'params': 9588956, 'time_iter': 0.13673, 'accuracy': 0.97414, 'auc': 0.53373, 'ap': 0.02559}
2025-08-16 05:58:48,969 - INFO - test: {'epoch': 30, 'time_epoch': 9.40762, 'loss': 0.06885623, 'lr': 0, 'params': 9588956, 'time_iter': 0.10939, 'accuracy': 0.97272, 'auc': 0.51835, 'ap': 0.02628}
2025-08-16 05:58:48,971 - INFO - > Epoch 30: took 193.0s (avg 195.5s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:01:38,940 - INFO - train: {'epoch': 31, 'time_epoch': 160.25125, 'eta': 11120.87596, 'eta_hours': 3.08913, 'loss': 0.05512821, 'lr': 0.00041315, 'params': 9588956, 'time_iter': 0.23394, 'accuracy': 0.9795, 'auc': 0.53828, 'ap': 0.02553}
2025-08-16 06:01:48,933 - INFO - val: {'epoch': 31, 'time_epoch': 8.75037, 'loss': 0.06741728, 'lr': 0, 'params': 9588956, 'time_iter': 0.10175, 'accuracy': 0.97414, 'auc': 0.51683, 'ap': 0.02589}
2025-08-16 06:01:59,543 - INFO - test: {'epoch': 31, 'time_epoch': 9.39736, 'loss': 0.06981626, 'lr': 0, 'params': 9588956, 'time_iter': 0.10927, 'accuracy': 0.97272, 'auc': 0.52516, 'ap': 0.02758}
2025-08-16 06:01:59,545 - INFO - > Epoch 31: took 190.6s (avg 195.3s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:04:51,565 - INFO - train: {'epoch': 32, 'time_epoch': 162.43611, 'eta': 10955.08779, 'eta_hours': 3.04308, 'loss': 0.05517305, 'lr': 0.00040679, 'params': 9588956, 'time_iter': 0.23713, 'accuracy': 0.97947, 'auc': 0.53522, 'ap': 0.02506}
2025-08-16 06:05:01,507 - INFO - val: {'epoch': 32, 'time_epoch': 8.74355, 'loss': 0.06611779, 'lr': 0, 'params': 9588956, 'time_iter': 0.10167, 'accuracy': 0.97603, 'auc': 0.50324, 'ap': 0.02655}
2025-08-16 06:05:12,957 - INFO - test: {'epoch': 32, 'time_epoch': 9.39636, 'loss': 0.06850053, 'lr': 0, 'params': 9588956, 'time_iter': 0.10926, 'accuracy': 0.97482, 'auc': 0.51112, 'ap': 0.02643}
2025-08-16 06:05:12,960 - INFO - > Epoch 32: took 193.4s (avg 195.3s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:08:03,088 - INFO - train: {'epoch': 33, 'time_epoch': 160.21184, 'eta': 10785.17909, 'eta_hours': 2.99588, 'loss': 0.05506609, 'lr': 0.00040027, 'params': 9588956, 'time_iter': 0.23389, 'accuracy': 0.97956, 'auc': 0.5431, 'ap': 0.02608}
2025-08-16 06:08:13,247 - INFO - val: {'epoch': 33, 'time_epoch': 8.87628, 'loss': 0.06658372, 'lr': 0, 'params': 9588956, 'time_iter': 0.10321, 'accuracy': 0.97414, 'auc': 0.50434, 'ap': 0.02494}
2025-08-16 06:08:23,965 - INFO - test: {'epoch': 33, 'time_epoch': 9.4656, 'loss': 0.06901728, 'lr': 0, 'params': 9588956, 'time_iter': 0.11007, 'accuracy': 0.97272, 'auc': 0.49804, 'ap': 0.02566}
2025-08-16 06:08:23,967 - INFO - > Epoch 33: took 191.0s (avg 195.1s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:11:17,495 - INFO - train: {'epoch': 34, 'time_epoch': 163.59611, 'eta': 10622.10956, 'eta_hours': 2.95059, 'loss': 0.05502637, 'lr': 0.00039358, 'params': 9588956, 'time_iter': 0.23883, 'accuracy': 0.97957, 'auc': 0.54732, 'ap': 0.0262}
2025-08-16 06:11:27,592 - INFO - val: {'epoch': 34, 'time_epoch': 8.80575, 'loss': 0.06681582, 'lr': 0, 'params': 9588956, 'time_iter': 0.10239, 'accuracy': 0.97414, 'auc': 0.50361, 'ap': 0.02532}
2025-08-16 06:11:38,309 - INFO - test: {'epoch': 34, 'time_epoch': 9.44979, 'loss': 0.06919361, 'lr': 0, 'params': 9588956, 'time_iter': 0.10988, 'accuracy': 0.97272, 'auc': 0.50344, 'ap': 0.02688}
2025-08-16 06:11:38,311 - INFO - > Epoch 34: took 194.3s (avg 195.1s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:14:28,201 - INFO - train: {'epoch': 35, 'time_epoch': 159.92787, 'eta': 10452.48947, 'eta_hours': 2.90347, 'loss': 0.05508404, 'lr': 0.00038674, 'params': 9588956, 'time_iter': 0.23347, 'accuracy': 0.97954, 'auc': 0.54365, 'ap': 0.02576}
2025-08-16 06:14:41,358 - INFO - val: {'epoch': 35, 'time_epoch': 11.84541, 'loss': 0.06589718, 'lr': 0, 'params': 9588956, 'time_iter': 0.13774, 'accuracy': 0.97603, 'auc': 0.52195, 'ap': 0.02633}
2025-08-16 06:14:52,101 - INFO - test: {'epoch': 35, 'time_epoch': 9.45983, 'loss': 0.06830163, 'lr': 0, 'params': 9588956, 'time_iter': 0.11, 'accuracy': 0.97482, 'auc': 0.51718, 'ap': 0.02742}
2025-08-16 06:14:52,103 - INFO - > Epoch 35: took 193.8s (avg 195.1s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:17:42,301 - INFO - train: {'epoch': 36, 'time_epoch': 160.52079, 'eta': 10284.40285, 'eta_hours': 2.85678, 'loss': 0.05507737, 'lr': 0.00037974, 'params': 9588956, 'time_iter': 0.23434, 'accuracy': 0.97954, 'auc': 0.54192, 'ap': 0.02579}
2025-08-16 06:17:52,308 - INFO - val: {'epoch': 36, 'time_epoch': 8.74993, 'loss': 0.06607468, 'lr': 0, 'params': 9588956, 'time_iter': 0.10174, 'accuracy': 0.97603, 'auc': 0.49192, 'ap': 0.02364}
2025-08-16 06:18:02,962 - INFO - test: {'epoch': 36, 'time_epoch': 9.41603, 'loss': 0.06849041, 'lr': 0, 'params': 9588956, 'time_iter': 0.10949, 'accuracy': 0.97482, 'auc': 0.49437, 'ap': 0.02483}
2025-08-16 06:18:02,964 - INFO - > Epoch 36: took 190.9s (avg 195.0s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:20:56,128 - INFO - train: {'epoch': 37, 'time_epoch': 163.41519, 'eta': 10121.43687, 'eta_hours': 2.81151, 'loss': 0.05507966, 'lr': 0.00037261, 'params': 9588956, 'time_iter': 0.23856, 'accuracy': 0.97953, 'auc': 0.54313, 'ap': 0.02575}
2025-08-16 06:21:06,181 - INFO - val: {'epoch': 37, 'time_epoch': 8.80653, 'loss': 0.06596119, 'lr': 0, 'params': 9588956, 'time_iter': 0.1024, 'accuracy': 0.97603, 'auc': 0.49458, 'ap': 0.02425}
2025-08-16 06:21:16,889 - INFO - test: {'epoch': 37, 'time_epoch': 9.4735, 'loss': 0.06831758, 'lr': 0, 'params': 9588956, 'time_iter': 0.11016, 'accuracy': 0.97482, 'auc': 0.50116, 'ap': 0.02551}
2025-08-16 06:21:16,896 - INFO - > Epoch 37: took 193.9s (avg 194.9s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:24:06,671 - INFO - train: {'epoch': 38, 'time_epoch': 160.11018, 'eta': 9953.27848, 'eta_hours': 2.7648, 'loss': 0.05507302, 'lr': 0.00036534, 'params': 9588956, 'time_iter': 0.23374, 'accuracy': 0.97952, 'auc': 0.54466, 'ap': 0.02612}
2025-08-16 06:24:16,678 - INFO - val: {'epoch': 38, 'time_epoch': 8.73592, 'loss': 0.06665933, 'lr': 0, 'params': 9588956, 'time_iter': 0.10158, 'accuracy': 0.97414, 'auc': 0.50554, 'ap': 0.02532}
2025-08-16 06:24:27,311 - INFO - test: {'epoch': 38, 'time_epoch': 9.40557, 'loss': 0.06905105, 'lr': 0, 'params': 9588956, 'time_iter': 0.10937, 'accuracy': 0.97272, 'auc': 0.50107, 'ap': 0.02712}
2025-08-16 06:24:27,313 - INFO - > Epoch 38: took 190.4s (avg 194.8s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:27:18,616 - INFO - train: {'epoch': 39, 'time_epoch': 161.76899, 'eta': 9788.01072, 'eta_hours': 2.71889, 'loss': 0.05506063, 'lr': 0.00035794, 'params': 9588956, 'time_iter': 0.23616, 'accuracy': 0.9795, 'auc': 0.5469, 'ap': 0.02601}
2025-08-16 06:27:28,570 - INFO - val: {'epoch': 39, 'time_epoch': 8.73188, 'loss': 0.06596436, 'lr': 0, 'params': 9588956, 'time_iter': 0.10153, 'accuracy': 0.97603, 'auc': 0.49818, 'ap': 0.02435}
2025-08-16 06:27:39,156 - INFO - test: {'epoch': 39, 'time_epoch': 9.38597, 'loss': 0.0683198, 'lr': 0, 'params': 9588956, 'time_iter': 0.10914, 'accuracy': 0.97482, 'auc': 0.50553, 'ap': 0.02518}
2025-08-16 06:27:39,158 - INFO - > Epoch 39: took 191.8s (avg 194.8s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:30:30,887 - INFO - train: {'epoch': 40, 'time_epoch': 162.08387, 'eta': 9623.36675, 'eta_hours': 2.67316, 'loss': 0.05504862, 'lr': 0.00035042, 'params': 9588956, 'time_iter': 0.23662, 'accuracy': 0.97955, 'auc': 0.54549, 'ap': 0.02594}
2025-08-16 06:30:40,824 - INFO - val: {'epoch': 40, 'time_epoch': 8.734, 'loss': 0.06624426, 'lr': 0, 'params': 9588956, 'time_iter': 0.10156, 'accuracy': 0.97414, 'auc': 0.4978, 'ap': 0.02493}
2025-08-16 06:30:51,395 - INFO - test: {'epoch': 40, 'time_epoch': 9.39892, 'loss': 0.06862631, 'lr': 0, 'params': 9588956, 'time_iter': 0.10929, 'accuracy': 0.97272, 'auc': 0.49212, 'ap': 0.02666}
2025-08-16 06:30:51,397 - INFO - > Epoch 40: took 192.2s (avg 194.7s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:33:40,518 - INFO - train: {'epoch': 41, 'time_epoch': 159.47087, 'eta': 9455.23626, 'eta_hours': 2.62645, 'loss': 0.05508874, 'lr': 0.0003428, 'params': 9588956, 'time_iter': 0.2328, 'accuracy': 0.97946, 'auc': 0.54453, 'ap': 0.02587}
2025-08-16 06:33:50,571 - INFO - val: {'epoch': 41, 'time_epoch': 8.76713, 'loss': 0.06598404, 'lr': 0, 'params': 9588956, 'time_iter': 0.10194, 'accuracy': 0.97603, 'auc': 0.50855, 'ap': 0.0253}
2025-08-16 06:34:01,259 - INFO - test: {'epoch': 41, 'time_epoch': 9.40348, 'loss': 0.06832062, 'lr': 0, 'params': 9588956, 'time_iter': 0.10934, 'accuracy': 0.97482, 'auc': 0.50857, 'ap': 0.02659}
2025-08-16 06:34:01,261 - INFO - > Epoch 41: took 189.9s (avg 194.6s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:36:54,031 - INFO - train: {'epoch': 42, 'time_epoch': 163.07878, 'eta': 9292.29112, 'eta_hours': 2.58119, 'loss': 0.05510798, 'lr': 0.00033507, 'params': 9588956, 'time_iter': 0.23807, 'accuracy': 0.97946, 'auc': 0.54537, 'ap': 0.02561}
2025-08-16 06:37:04,196 - INFO - val: {'epoch': 42, 'time_epoch': 8.90588, 'loss': 0.06640365, 'lr': 0, 'params': 9588956, 'time_iter': 0.10356, 'accuracy': 0.97603, 'auc': 0.49698, 'ap': 0.02579}
2025-08-16 06:37:14,872 - INFO - test: {'epoch': 42, 'time_epoch': 9.45618, 'loss': 0.0688221, 'lr': 0, 'params': 9588956, 'time_iter': 0.10996, 'accuracy': 0.97482, 'auc': 0.49231, 'ap': 0.02589}
2025-08-16 06:37:14,874 - INFO - > Epoch 42: took 193.6s (avg 194.6s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:40:04,934 - INFO - train: {'epoch': 43, 'time_epoch': 160.34865, 'eta': 9125.86519, 'eta_hours': 2.53496, 'loss': 0.05510951, 'lr': 0.00032725, 'params': 9588956, 'time_iter': 0.23409, 'accuracy': 0.97949, 'auc': 0.54295, 'ap': 0.0256}
2025-08-16 06:40:14,954 - INFO - val: {'epoch': 43, 'time_epoch': 8.7575, 'loss': 0.0661835, 'lr': 0, 'params': 9588956, 'time_iter': 0.10183, 'accuracy': 0.97414, 'auc': 0.50302, 'ap': 0.02607}
2025-08-16 06:40:25,590 - INFO - test: {'epoch': 43, 'time_epoch': 9.39982, 'loss': 0.06852299, 'lr': 0, 'params': 9588956, 'time_iter': 0.1093, 'accuracy': 0.97272, 'auc': 0.4935, 'ap': 0.02725}
2025-08-16 06:40:25,592 - INFO - > Epoch 43: took 190.7s (avg 194.5s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:43:17,577 - INFO - train: {'epoch': 44, 'time_epoch': 162.27605, 'eta': 8962.06508, 'eta_hours': 2.48946, 'loss': 0.05505474, 'lr': 0.00031935, 'params': 9588956, 'time_iter': 0.2369, 'accuracy': 0.9795, 'auc': 0.54496, 'ap': 0.02591}
2025-08-16 06:43:27,608 - INFO - val: {'epoch': 44, 'time_epoch': 8.76472, 'loss': 0.06651411, 'lr': 0, 'params': 9588956, 'time_iter': 0.10192, 'accuracy': 0.97414, 'auc': 0.48859, 'ap': 0.0245}
2025-08-16 06:43:38,269 - INFO - test: {'epoch': 44, 'time_epoch': 9.42336, 'loss': 0.06884298, 'lr': 0, 'params': 9588956, 'time_iter': 0.10957, 'accuracy': 0.97272, 'auc': 0.48151, 'ap': 0.02583}
2025-08-16 06:43:38,271 - INFO - > Epoch 44: took 192.7s (avg 194.4s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:46:31,117 - INFO - train: {'epoch': 45, 'time_epoch': 163.12923, 'eta': 8799.33279, 'eta_hours': 2.44426, 'loss': 0.0550249, 'lr': 0.00031137, 'params': 9588956, 'time_iter': 0.23814, 'accuracy': 0.97949, 'auc': 0.54854, 'ap': 0.02616}
2025-08-16 06:46:41,141 - INFO - val: {'epoch': 45, 'time_epoch': 8.76712, 'loss': 0.06643288, 'lr': 0, 'params': 9588956, 'time_iter': 0.10194, 'accuracy': 0.97414, 'auc': 0.487, 'ap': 0.02476}
2025-08-16 06:46:51,779 - INFO - test: {'epoch': 45, 'time_epoch': 9.41419, 'loss': 0.06881068, 'lr': 0, 'params': 9588956, 'time_iter': 0.10947, 'accuracy': 0.97272, 'auc': 0.47545, 'ap': 0.02608}
2025-08-16 06:46:51,782 - INFO - > Epoch 45: took 193.5s (avg 194.4s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:49:41,805 - INFO - train: {'epoch': 46, 'time_epoch': 160.409, 'eta': 8633.51612, 'eta_hours': 2.3982, 'loss': 0.05502371, 'lr': 0.00030332, 'params': 9588956, 'time_iter': 0.23417, 'accuracy': 0.97951, 'auc': 0.54723, 'ap': 0.02616}
2025-08-16 06:49:51,665 - INFO - val: {'epoch': 46, 'time_epoch': 8.70097, 'loss': 0.0680456, 'lr': 0, 'params': 9588956, 'time_iter': 0.10117, 'accuracy': 0.97414, 'auc': 0.49357, 'ap': 0.02555}
2025-08-16 06:50:02,137 - INFO - test: {'epoch': 46, 'time_epoch': 9.34618, 'loss': 0.07044922, 'lr': 0, 'params': 9588956, 'time_iter': 0.10868, 'accuracy': 0.97272, 'auc': 0.48989, 'ap': 0.02559}
2025-08-16 06:50:02,139 - INFO - > Epoch 46: took 190.4s (avg 194.3s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:52:53,784 - INFO - train: {'epoch': 47, 'time_epoch': 162.13746, 'eta': 8469.79726, 'eta_hours': 2.35272, 'loss': 0.05499711, 'lr': 0.00029522, 'params': 9588956, 'time_iter': 0.2367, 'accuracy': 0.9795, 'auc': 0.54866, 'ap': 0.0262}
2025-08-16 06:53:03,724 - INFO - val: {'epoch': 47, 'time_epoch': 8.73502, 'loss': 0.06658275, 'lr': 0, 'params': 9588956, 'time_iter': 0.10157, 'accuracy': 0.97414, 'auc': 0.48269, 'ap': 0.02481}
2025-08-16 06:53:14,242 - INFO - test: {'epoch': 47, 'time_epoch': 9.36071, 'loss': 0.06896279, 'lr': 0, 'params': 9588956, 'time_iter': 0.10885, 'accuracy': 0.97272, 'auc': 0.49281, 'ap': 0.02658}
2025-08-16 06:53:14,244 - INFO - > Epoch 47: took 192.1s (avg 194.3s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:56:03,369 - INFO - train: {'epoch': 48, 'time_epoch': 159.51711, 'eta': 8303.41564, 'eta_hours': 2.3065, 'loss': 0.05494455, 'lr': 0.00028707, 'params': 9588956, 'time_iter': 0.23287, 'accuracy': 0.97951, 'auc': 0.55346, 'ap': 0.02664}
2025-08-16 06:56:13,329 - INFO - val: {'epoch': 48, 'time_epoch': 8.73153, 'loss': 0.06789185, 'lr': 0, 'params': 9588956, 'time_iter': 0.10153, 'accuracy': 0.97414, 'auc': 0.47979, 'ap': 0.02493}
2025-08-16 06:56:23,942 - INFO - test: {'epoch': 48, 'time_epoch': 9.39593, 'loss': 0.07028578, 'lr': 0, 'params': 9588956, 'time_iter': 0.10925, 'accuracy': 0.97272, 'auc': 0.49319, 'ap': 0.02647}
2025-08-16 06:56:23,944 - INFO - > Epoch 48: took 189.7s (avg 194.2s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 06:59:17,124 - INFO - train: {'epoch': 49, 'time_epoch': 163.51873, 'eta': 8141.31023, 'eta_hours': 2.26148, 'loss': 0.05497851, 'lr': 0.00027887, 'params': 9588956, 'time_iter': 0.23871, 'accuracy': 0.9795, 'auc': 0.55162, 'ap': 0.02636}
2025-08-16 06:59:27,117 - INFO - val: {'epoch': 49, 'time_epoch': 8.74612, 'loss': 0.0671135, 'lr': 0, 'params': 9588956, 'time_iter': 0.1017, 'accuracy': 0.97414, 'auc': 0.48853, 'ap': 0.02473}
2025-08-16 06:59:37,749 - INFO - test: {'epoch': 49, 'time_epoch': 9.41393, 'loss': 0.06954287, 'lr': 0, 'params': 9588956, 'time_iter': 0.10946, 'accuracy': 0.97272, 'auc': 0.4958, 'ap': 0.02625}
2025-08-16 06:59:37,751 - INFO - > Epoch 49: took 193.8s (avg 194.2s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:02:30,406 - INFO - train: {'epoch': 50, 'time_epoch': 162.94984, 'eta': 7978.60281, 'eta_hours': 2.21628, 'loss': 0.05493189, 'lr': 0.00027064, 'params': 9588956, 'time_iter': 0.23788, 'accuracy': 0.97952, 'auc': 0.55507, 'ap': 0.02648}
2025-08-16 07:02:40,402 - INFO - val: {'epoch': 50, 'time_epoch': 8.77596, 'loss': 0.06675909, 'lr': 0, 'params': 9588956, 'time_iter': 0.10205, 'accuracy': 0.97414, 'auc': 0.50837, 'ap': 0.02559}
2025-08-16 07:02:51,013 - INFO - test: {'epoch': 50, 'time_epoch': 9.42836, 'loss': 0.06912062, 'lr': 0, 'params': 9588956, 'time_iter': 0.10963, 'accuracy': 0.97272, 'auc': 0.51057, 'ap': 0.02643}
2025-08-16 07:02:51,015 - INFO - > Epoch 50: took 193.3s (avg 194.2s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:05:40,911 - INFO - train: {'epoch': 51, 'time_epoch': 160.14241, 'eta': 7813.2946, 'eta_hours': 2.17036, 'loss': 0.05489969, 'lr': 0.0002624, 'params': 9588956, 'time_iter': 0.23378, 'accuracy': 0.97952, 'auc': 0.55726, 'ap': 0.02707}
2025-08-16 07:05:50,832 - INFO - val: {'epoch': 51, 'time_epoch': 8.73594, 'loss': 0.06648943, 'lr': 0, 'params': 9588956, 'time_iter': 0.10158, 'accuracy': 0.97414, 'auc': 0.51036, 'ap': 0.02644}
2025-08-16 07:06:01,406 - INFO - test: {'epoch': 51, 'time_epoch': 9.41498, 'loss': 0.06889481, 'lr': 0, 'params': 9588956, 'time_iter': 0.10948, 'accuracy': 0.97272, 'auc': 0.51358, 'ap': 0.02713}
2025-08-16 07:06:01,408 - INFO - > Epoch 51: took 190.4s (avg 194.1s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:08:58,775 - INFO - train: {'epoch': 52, 'time_epoch': 166.05616, 'eta': 7653.42559, 'eta_hours': 2.12595, 'loss': 0.05491135, 'lr': 0.00025413, 'params': 9588956, 'time_iter': 0.24242, 'accuracy': 0.9795, 'auc': 0.55452, 'ap': 0.0268}
2025-08-16 07:09:09,414 - INFO - val: {'epoch': 52, 'time_epoch': 9.20474, 'loss': 0.06737711, 'lr': 0, 'params': 9588956, 'time_iter': 0.10703, 'accuracy': 0.97414, 'auc': 0.49866, 'ap': 0.0257}
2025-08-16 07:09:20,568 - INFO - test: {'epoch': 52, 'time_epoch': 9.89218, 'loss': 0.06975218, 'lr': 0, 'params': 9588956, 'time_iter': 0.11503, 'accuracy': 0.97272, 'auc': 0.4983, 'ap': 0.02722}
2025-08-16 07:09:20,571 - INFO - > Epoch 52: took 199.2s (avg 194.2s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:12:11,307 - INFO - train: {'epoch': 53, 'time_epoch': 161.02222, 'eta': 7489.03925, 'eta_hours': 2.08029, 'loss': 0.05492238, 'lr': 0.00024587, 'params': 9588956, 'time_iter': 0.23507, 'accuracy': 0.97954, 'auc': 0.55491, 'ap': 0.02704}
2025-08-16 07:12:21,277 - INFO - val: {'epoch': 53, 'time_epoch': 8.78581, 'loss': 0.06746453, 'lr': 0, 'params': 9588956, 'time_iter': 0.10216, 'accuracy': 0.97414, 'auc': 0.49031, 'ap': 0.025}
2025-08-16 07:12:31,859 - INFO - test: {'epoch': 53, 'time_epoch': 9.42842, 'loss': 0.06986664, 'lr': 0, 'params': 9588956, 'time_iter': 0.10963, 'accuracy': 0.97272, 'auc': 0.49195, 'ap': 0.027}
2025-08-16 07:12:31,861 - INFO - > Epoch 53: took 191.3s (avg 194.1s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:15:25,583 - INFO - train: {'epoch': 54, 'time_epoch': 164.01644, 'eta': 7327.22506, 'eta_hours': 2.03534, 'loss': 0.05490359, 'lr': 0.0002376, 'params': 9588956, 'time_iter': 0.23944, 'accuracy': 0.97957, 'auc': 0.55692, 'ap': 0.02691}
2025-08-16 07:15:35,622 - INFO - val: {'epoch': 54, 'time_epoch': 8.81474, 'loss': 0.06703789, 'lr': 0, 'params': 9588956, 'time_iter': 0.1025, 'accuracy': 0.97414, 'auc': 0.48098, 'ap': 0.02491}
2025-08-16 07:15:46,273 - INFO - test: {'epoch': 54, 'time_epoch': 9.44792, 'loss': 0.06942681, 'lr': 0, 'params': 9588956, 'time_iter': 0.10986, 'accuracy': 0.97272, 'auc': 0.47827, 'ap': 0.02588}
2025-08-16 07:15:46,275 - INFO - > Epoch 54: took 194.4s (avg 194.1s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:18:38,624 - INFO - train: {'epoch': 55, 'time_epoch': 162.3777, 'eta': 7164.04464, 'eta_hours': 1.99001, 'loss': 0.05488396, 'lr': 0.00022936, 'params': 9588956, 'time_iter': 0.23705, 'accuracy': 0.97956, 'auc': 0.55844, 'ap': 0.02744}
2025-08-16 07:18:48,749 - INFO - val: {'epoch': 55, 'time_epoch': 8.8232, 'loss': 0.06666149, 'lr': 0, 'params': 9588956, 'time_iter': 0.1026, 'accuracy': 0.97414, 'auc': 0.49149, 'ap': 0.02576}
2025-08-16 07:18:59,495 - INFO - test: {'epoch': 55, 'time_epoch': 9.47383, 'loss': 0.06901045, 'lr': 0, 'params': 9588956, 'time_iter': 0.11016, 'accuracy': 0.97272, 'auc': 0.48417, 'ap': 0.02741}
2025-08-16 07:18:59,498 - INFO - > Epoch 55: took 193.2s (avg 194.1s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:21:51,321 - INFO - train: {'epoch': 56, 'time_epoch': 160.42925, 'eta': 6999.4225, 'eta_hours': 1.94428, 'loss': 0.0548712, 'lr': 0.00022113, 'params': 9588956, 'time_iter': 0.2342, 'accuracy': 0.97956, 'auc': 0.55897, 'ap': 0.02702}
2025-08-16 07:22:01,386 - INFO - val: {'epoch': 56, 'time_epoch': 8.81261, 'loss': 0.06668977, 'lr': 0, 'params': 9588956, 'time_iter': 0.10247, 'accuracy': 0.97414, 'auc': 0.48213, 'ap': 0.0251}
2025-08-16 07:22:12,092 - INFO - test: {'epoch': 56, 'time_epoch': 9.47641, 'loss': 0.06903268, 'lr': 0, 'params': 9588956, 'time_iter': 0.11019, 'accuracy': 0.97272, 'auc': 0.47137, 'ap': 0.02572}
2025-08-16 07:22:12,094 - INFO - > Epoch 56: took 192.6s (avg 194.1s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:25:04,705 - INFO - train: {'epoch': 57, 'time_epoch': 162.41358, 'eta': 6836.38187, 'eta_hours': 1.89899, 'loss': 0.05487228, 'lr': 0.00021293, 'params': 9588956, 'time_iter': 0.2371, 'accuracy': 0.97952, 'auc': 0.55862, 'ap': 0.02721}
2025-08-16 07:25:14,810 - INFO - val: {'epoch': 57, 'time_epoch': 8.82866, 'loss': 0.06642363, 'lr': 0, 'params': 9588956, 'time_iter': 0.10266, 'accuracy': 0.97603, 'auc': 0.48212, 'ap': 0.02526}
2025-08-16 07:25:25,528 - INFO - test: {'epoch': 57, 'time_epoch': 9.46886, 'loss': 0.06870966, 'lr': 0, 'params': 9588956, 'time_iter': 0.1101, 'accuracy': 0.97482, 'auc': 0.47581, 'ap': 0.02679}
2025-08-16 07:25:25,530 - INFO - > Epoch 57: took 193.4s (avg 194.1s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:28:14,560 - INFO - train: {'epoch': 58, 'time_epoch': 159.0664, 'eta': 6671.03649, 'eta_hours': 1.85307, 'loss': 0.05486544, 'lr': 0.00020478, 'params': 9588956, 'time_iter': 0.23221, 'accuracy': 0.97953, 'auc': 0.55948, 'ap': 0.02718}
2025-08-16 07:28:24,679 - INFO - val: {'epoch': 58, 'time_epoch': 8.80607, 'loss': 0.06673521, 'lr': 0, 'params': 9588956, 'time_iter': 0.1024, 'accuracy': 0.97414, 'auc': 0.49691, 'ap': 0.02498}
2025-08-16 07:28:38,389 - INFO - test: {'epoch': 58, 'time_epoch': 12.46824, 'loss': 0.06898851, 'lr': 0, 'params': 9588956, 'time_iter': 0.14498, 'accuracy': 0.97272, 'auc': 0.49417, 'ap': 0.02664}
2025-08-16 07:28:38,391 - INFO - > Epoch 58: took 192.9s (avg 194.1s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:31:28,765 - INFO - train: {'epoch': 59, 'time_epoch': 160.4272, 'eta': 6506.80761, 'eta_hours': 1.80745, 'loss': 0.05487935, 'lr': 0.00019668, 'params': 9588956, 'time_iter': 0.2342, 'accuracy': 0.9796, 'auc': 0.5592, 'ap': 0.02747}
2025-08-16 07:31:38,825 - INFO - val: {'epoch': 59, 'time_epoch': 8.81227, 'loss': 0.06675599, 'lr': 0, 'params': 9588956, 'time_iter': 0.10247, 'accuracy': 0.97414, 'auc': 0.50337, 'ap': 0.02531}
2025-08-16 07:31:49,512 - INFO - test: {'epoch': 59, 'time_epoch': 9.46642, 'loss': 0.06907883, 'lr': 0, 'params': 9588956, 'time_iter': 0.11007, 'accuracy': 0.97272, 'auc': 0.51136, 'ap': 0.02814}
2025-08-16 07:31:49,514 - INFO - > Epoch 59: took 191.1s (avg 194.0s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:34:41,154 - INFO - train: {'epoch': 60, 'time_epoch': 161.65205, 'eta': 6343.48648, 'eta_hours': 1.76208, 'loss': 0.05486228, 'lr': 0.00018863, 'params': 9588956, 'time_iter': 0.23599, 'accuracy': 0.97954, 'auc': 0.5632, 'ap': 0.02744}
2025-08-16 07:34:51,213 - INFO - val: {'epoch': 60, 'time_epoch': 8.8175, 'loss': 0.06675194, 'lr': 0, 'params': 9588956, 'time_iter': 0.10253, 'accuracy': 0.97414, 'auc': 0.50551, 'ap': 0.0248}
2025-08-16 07:35:01,903 - INFO - test: {'epoch': 60, 'time_epoch': 9.46288, 'loss': 0.06904953, 'lr': 0, 'params': 9588956, 'time_iter': 0.11003, 'accuracy': 0.97272, 'auc': 0.51338, 'ap': 0.02606}
2025-08-16 07:35:01,906 - INFO - > Epoch 60: took 192.4s (avg 194.0s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:37:52,353 - INFO - train: {'epoch': 61, 'time_epoch': 160.48714, 'eta': 6179.50521, 'eta_hours': 1.71653, 'loss': 0.05484907, 'lr': 0.00018065, 'params': 9588956, 'time_iter': 0.23429, 'accuracy': 0.97961, 'auc': 0.5603, 'ap': 0.02775}
2025-08-16 07:38:02,327 - INFO - val: {'epoch': 61, 'time_epoch': 8.77246, 'loss': 0.06628252, 'lr': 0, 'params': 9588956, 'time_iter': 0.10201, 'accuracy': 0.97603, 'auc': 0.50247, 'ap': 0.02473}
2025-08-16 07:38:12,937 - INFO - test: {'epoch': 61, 'time_epoch': 9.43715, 'loss': 0.06860116, 'lr': 0, 'params': 9588956, 'time_iter': 0.10973, 'accuracy': 0.97482, 'auc': 0.51076, 'ap': 0.02619}
2025-08-16 07:38:12,939 - INFO - > Epoch 61: took 191.0s (avg 193.9s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:41:05,386 - INFO - train: {'epoch': 62, 'time_epoch': 162.46126, 'eta': 6016.79427, 'eta_hours': 1.67133, 'loss': 0.05483644, 'lr': 0.00017275, 'params': 9588956, 'time_iter': 0.23717, 'accuracy': 0.97953, 'auc': 0.56079, 'ap': 0.02749}
2025-08-16 07:41:15,425 - INFO - val: {'epoch': 62, 'time_epoch': 8.81287, 'loss': 0.06618749, 'lr': 0, 'params': 9588956, 'time_iter': 0.10248, 'accuracy': 0.97603, 'auc': 0.49694, 'ap': 0.02418}
2025-08-16 07:41:26,090 - INFO - test: {'epoch': 62, 'time_epoch': 9.46489, 'loss': 0.06853564, 'lr': 0, 'params': 9588956, 'time_iter': 0.11006, 'accuracy': 0.97482, 'auc': 0.50559, 'ap': 0.02559}
2025-08-16 07:41:26,092 - INFO - > Epoch 62: took 193.2s (avg 193.9s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:44:16,601 - INFO - train: {'epoch': 63, 'time_epoch': 160.56176, 'eta': 5853.02266, 'eta_hours': 1.62584, 'loss': 0.05485197, 'lr': 0.00016493, 'params': 9588956, 'time_iter': 0.2344, 'accuracy': 0.9796, 'auc': 0.5597, 'ap': 0.02769}
2025-08-16 07:44:26,599 - INFO - val: {'epoch': 63, 'time_epoch': 8.75967, 'loss': 0.06621297, 'lr': 0, 'params': 9588956, 'time_iter': 0.10186, 'accuracy': 0.97603, 'auc': 0.48766, 'ap': 0.02429}
2025-08-16 07:44:40,221 - INFO - test: {'epoch': 63, 'time_epoch': 12.40759, 'loss': 0.06857283, 'lr': 0, 'params': 9588956, 'time_iter': 0.14427, 'accuracy': 0.97482, 'auc': 0.48963, 'ap': 0.02565}
2025-08-16 07:44:40,235 - INFO - > Epoch 63: took 194.1s (avg 193.9s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:47:30,636 - INFO - train: {'epoch': 64, 'time_epoch': 160.4101, 'eta': 5689.26816, 'eta_hours': 1.58035, 'loss': 0.05485188, 'lr': 0.0001572, 'params': 9588956, 'time_iter': 0.23418, 'accuracy': 0.97957, 'auc': 0.55998, 'ap': 0.02787}
2025-08-16 07:47:40,724 - INFO - val: {'epoch': 64, 'time_epoch': 8.81983, 'loss': 0.06614668, 'lr': 0, 'params': 9588956, 'time_iter': 0.10256, 'accuracy': 0.97603, 'auc': 0.47611, 'ap': 0.02428}
2025-08-16 07:47:51,436 - INFO - test: {'epoch': 64, 'time_epoch': 9.46856, 'loss': 0.06852907, 'lr': 0, 'params': 9588956, 'time_iter': 0.1101, 'accuracy': 0.97482, 'auc': 0.48222, 'ap': 0.02614}
2025-08-16 07:47:51,439 - INFO - > Epoch 64: took 191.2s (avg 193.9s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:50:44,603 - INFO - train: {'epoch': 65, 'time_epoch': 163.21267, 'eta': 5527.05875, 'eta_hours': 1.53529, 'loss': 0.05482827, 'lr': 0.00014958, 'params': 9588956, 'time_iter': 0.23827, 'accuracy': 0.97957, 'auc': 0.5596, 'ap': 0.02735}
2025-08-16 07:50:54,741 - INFO - val: {'epoch': 65, 'time_epoch': 8.82017, 'loss': 0.06593186, 'lr': 0, 'params': 9588956, 'time_iter': 0.10256, 'accuracy': 0.97603, 'auc': 0.47544, 'ap': 0.02418}
2025-08-16 07:51:05,509 - INFO - test: {'epoch': 65, 'time_epoch': 9.47404, 'loss': 0.06831428, 'lr': 0, 'params': 9588956, 'time_iter': 0.11016, 'accuracy': 0.97482, 'auc': 0.492, 'ap': 0.026}
2025-08-16 07:51:05,511 - INFO - > Epoch 65: took 194.1s (avg 193.9s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:53:55,950 - INFO - train: {'epoch': 66, 'time_epoch': 160.46202, 'eta': 5363.46459, 'eta_hours': 1.48985, 'loss': 0.05482781, 'lr': 0.00014206, 'params': 9588956, 'time_iter': 0.23425, 'accuracy': 0.97959, 'auc': 0.55966, 'ap': 0.02807}
2025-08-16 07:54:06,066 - INFO - val: {'epoch': 66, 'time_epoch': 8.81626, 'loss': 0.0660983, 'lr': 0, 'params': 9588956, 'time_iter': 0.10251, 'accuracy': 0.97603, 'auc': 0.4785, 'ap': 0.02427}
2025-08-16 07:54:16,813 - INFO - test: {'epoch': 66, 'time_epoch': 9.47244, 'loss': 0.06848199, 'lr': 0, 'params': 9588956, 'time_iter': 0.11014, 'accuracy': 0.97482, 'auc': 0.49364, 'ap': 0.02633}
2025-08-16 07:54:16,815 - INFO - > Epoch 66: took 191.3s (avg 193.8s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 07:57:08,879 - INFO - train: {'epoch': 67, 'time_epoch': 162.30858, 'eta': 5200.83153, 'eta_hours': 1.44468, 'loss': 0.0548168, 'lr': 0.00013466, 'params': 9588956, 'time_iter': 0.23695, 'accuracy': 0.97962, 'auc': 0.56252, 'ap': 0.02795}
2025-08-16 07:57:18,940 - INFO - val: {'epoch': 67, 'time_epoch': 8.78022, 'loss': 0.06602869, 'lr': 0, 'params': 9588956, 'time_iter': 0.1021, 'accuracy': 0.97603, 'auc': 0.48375, 'ap': 0.02425}
2025-08-16 07:57:29,625 - INFO - test: {'epoch': 67, 'time_epoch': 9.45043, 'loss': 0.0683489, 'lr': 0, 'params': 9588956, 'time_iter': 0.10989, 'accuracy': 0.97482, 'auc': 0.49787, 'ap': 0.02639}
2025-08-16 07:57:29,632 - INFO - > Epoch 67: took 192.8s (avg 193.8s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:00:19,879 - INFO - train: {'epoch': 68, 'time_epoch': 160.49865, 'eta': 5037.39471, 'eta_hours': 1.39928, 'loss': 0.05482271, 'lr': 0.00012739, 'params': 9588956, 'time_iter': 0.2343, 'accuracy': 0.97956, 'auc': 0.56167, 'ap': 0.02783}
2025-08-16 08:00:32,925 - INFO - val: {'epoch': 68, 'time_epoch': 11.77791, 'loss': 0.06690658, 'lr': 0, 'params': 9588956, 'time_iter': 0.13695, 'accuracy': 0.97414, 'auc': 0.50037, 'ap': 0.02468}
2025-08-16 08:00:43,599 - INFO - test: {'epoch': 68, 'time_epoch': 9.43761, 'loss': 0.06930638, 'lr': 0, 'params': 9588956, 'time_iter': 0.10974, 'accuracy': 0.97272, 'auc': 0.51245, 'ap': 0.02619}
2025-08-16 08:00:43,601 - INFO - > Epoch 68: took 194.0s (avg 193.8s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:03:33,480 - INFO - train: {'epoch': 69, 'time_epoch': 160.12837, 'eta': 4873.88315, 'eta_hours': 1.35386, 'loss': 0.0548037, 'lr': 0.00012026, 'params': 9588956, 'time_iter': 0.23376, 'accuracy': 0.97957, 'auc': 0.56176, 'ap': 0.02781}
2025-08-16 08:03:43,560 - INFO - val: {'epoch': 69, 'time_epoch': 8.7945, 'loss': 0.06647314, 'lr': 0, 'params': 9588956, 'time_iter': 0.10226, 'accuracy': 0.97414, 'auc': 0.50576, 'ap': 0.02419}
2025-08-16 08:03:54,256 - INFO - test: {'epoch': 69, 'time_epoch': 9.44352, 'loss': 0.06885293, 'lr': 0, 'params': 9588956, 'time_iter': 0.10981, 'accuracy': 0.97272, 'auc': 0.51564, 'ap': 0.02545}
2025-08-16 08:03:54,258 - INFO - > Epoch 69: took 190.7s (avg 193.8s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:06:51,567 - INFO - train: {'epoch': 70, 'time_epoch': 166.29594, 'eta': 4712.98604, 'eta_hours': 1.30916, 'loss': 0.05480449, 'lr': 0.00011326, 'params': 9588956, 'time_iter': 0.24277, 'accuracy': 0.97951, 'auc': 0.56113, 'ap': 0.02743}
2025-08-16 08:07:01,757 - INFO - val: {'epoch': 70, 'time_epoch': 8.86518, 'loss': 0.06682427, 'lr': 0, 'params': 9588956, 'time_iter': 0.10308, 'accuracy': 0.97414, 'auc': 0.51077, 'ap': 0.02434}
2025-08-16 08:07:12,556 - INFO - test: {'epoch': 70, 'time_epoch': 9.50141, 'loss': 0.06923187, 'lr': 0, 'params': 9588956, 'time_iter': 0.11048, 'accuracy': 0.97272, 'auc': 0.52019, 'ap': 0.02569}
2025-08-16 08:07:12,558 - INFO - > Epoch 70: took 198.3s (avg 193.9s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:10:02,276 - INFO - train: {'epoch': 71, 'time_epoch': 159.23867, 'eta': 4549.19447, 'eta_hours': 1.26367, 'loss': 0.05480492, 'lr': 0.00010642, 'params': 9588956, 'time_iter': 0.23247, 'accuracy': 0.97956, 'auc': 0.56056, 'ap': 0.0279}
2025-08-16 08:10:12,451 - INFO - val: {'epoch': 71, 'time_epoch': 8.8485, 'loss': 0.06682372, 'lr': 0, 'params': 9588956, 'time_iter': 0.10289, 'accuracy': 0.97414, 'auc': 0.52311, 'ap': 0.02455}
2025-08-16 08:10:23,203 - INFO - test: {'epoch': 71, 'time_epoch': 9.45927, 'loss': 0.06920169, 'lr': 0, 'params': 9588956, 'time_iter': 0.10999, 'accuracy': 0.97272, 'auc': 0.52485, 'ap': 0.02612}
2025-08-16 08:10:23,206 - INFO - > Epoch 71: took 190.6s (avg 193.8s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:13:15,699 - INFO - train: {'epoch': 72, 'time_epoch': 162.55319, 'eta': 4386.75355, 'eta_hours': 1.21854, 'loss': 0.05480411, 'lr': 9.973e-05, 'params': 9588956, 'time_iter': 0.2373, 'accuracy': 0.97955, 'auc': 0.55905, 'ap': 0.02779}
2025-08-16 08:13:25,823 - INFO - val: {'epoch': 72, 'time_epoch': 8.80805, 'loss': 0.06685759, 'lr': 0, 'params': 9588956, 'time_iter': 0.10242, 'accuracy': 0.97414, 'auc': 0.51042, 'ap': 0.02444}
2025-08-16 08:13:36,585 - INFO - test: {'epoch': 72, 'time_epoch': 9.47846, 'loss': 0.06923365, 'lr': 0, 'params': 9588956, 'time_iter': 0.11021, 'accuracy': 0.97272, 'auc': 0.5189, 'ap': 0.02595}
2025-08-16 08:13:36,587 - INFO - > Epoch 72: took 193.4s (avg 193.8s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:16:26,659 - INFO - train: {'epoch': 73, 'time_epoch': 160.07342, 'eta': 4223.43833, 'eta_hours': 1.17318, 'loss': 0.0547979, 'lr': 9.321e-05, 'params': 9588956, 'time_iter': 0.23368, 'accuracy': 0.97958, 'auc': 0.563, 'ap': 0.02762}
2025-08-16 08:16:39,745 - INFO - val: {'epoch': 73, 'time_epoch': 11.81262, 'loss': 0.06657005, 'lr': 0, 'params': 9588956, 'time_iter': 0.13736, 'accuracy': 0.97414, 'auc': 0.52717, 'ap': 0.02484}
2025-08-16 08:16:50,446 - INFO - test: {'epoch': 73, 'time_epoch': 9.46249, 'loss': 0.06895506, 'lr': 0, 'params': 9588956, 'time_iter': 0.11003, 'accuracy': 0.97272, 'auc': 0.52251, 'ap': 0.02617}
2025-08-16 08:16:50,448 - INFO - > Epoch 73: took 193.9s (avg 193.8s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:19:40,099 - INFO - train: {'epoch': 74, 'time_epoch': 159.98777, 'eta': 4060.18101, 'eta_hours': 1.12783, 'loss': 0.05478167, 'lr': 8.685e-05, 'params': 9588956, 'time_iter': 0.23356, 'accuracy': 0.97955, 'auc': 0.56663, 'ap': 0.02774}
2025-08-16 08:19:50,182 - INFO - val: {'epoch': 74, 'time_epoch': 8.73678, 'loss': 0.06663031, 'lr': 0, 'params': 9588956, 'time_iter': 0.10159, 'accuracy': 0.97414, 'auc': 0.51927, 'ap': 0.02458}
2025-08-16 08:20:00,787 - INFO - test: {'epoch': 74, 'time_epoch': 9.34778, 'loss': 0.06900227, 'lr': 0, 'params': 9588956, 'time_iter': 0.1087, 'accuracy': 0.97272, 'auc': 0.5125, 'ap': 0.02539}
2025-08-16 08:20:00,789 - INFO - > Epoch 74: took 190.3s (avg 193.8s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:22:52,968 - INFO - train: {'epoch': 75, 'time_epoch': 162.29768, 'eta': 3897.73917, 'eta_hours': 1.08271, 'loss': 0.05479537, 'lr': 8.068e-05, 'params': 9588956, 'time_iter': 0.23693, 'accuracy': 0.97953, 'auc': 0.56511, 'ap': 0.02768}
2025-08-16 08:23:03,047 - INFO - val: {'epoch': 75, 'time_epoch': 8.80137, 'loss': 0.06733923, 'lr': 0, 'params': 9588956, 'time_iter': 0.10234, 'accuracy': 0.97414, 'auc': 0.5135, 'ap': 0.02503}
2025-08-16 08:23:13,757 - INFO - test: {'epoch': 75, 'time_epoch': 9.45429, 'loss': 0.06973893, 'lr': 0, 'params': 9588956, 'time_iter': 0.10993, 'accuracy': 0.97272, 'auc': 0.51098, 'ap': 0.02593}
2025-08-16 08:23:13,759 - INFO - > Epoch 75: took 193.0s (avg 193.7s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:26:03,447 - INFO - train: {'epoch': 76, 'time_epoch': 159.81409, 'eta': 3734.55922, 'eta_hours': 1.03738, 'loss': 0.05479791, 'lr': 7.469e-05, 'params': 9588956, 'time_iter': 0.23331, 'accuracy': 0.97956, 'auc': 0.56487, 'ap': 0.02791}
2025-08-16 08:26:13,506 - INFO - val: {'epoch': 76, 'time_epoch': 8.78374, 'loss': 0.06759548, 'lr': 0, 'params': 9588956, 'time_iter': 0.10214, 'accuracy': 0.97414, 'auc': 0.51722, 'ap': 0.02595}
2025-08-16 08:26:24,199 - INFO - test: {'epoch': 76, 'time_epoch': 9.443, 'loss': 0.06999486, 'lr': 0, 'params': 9588956, 'time_iter': 0.1098, 'accuracy': 0.97272, 'auc': 0.51751, 'ap': 0.02704}
2025-08-16 08:26:24,201 - INFO - > Epoch 76: took 190.4s (avg 193.7s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:29:17,381 - INFO - train: {'epoch': 77, 'time_epoch': 163.17221, 'eta': 3572.41274, 'eta_hours': 0.99234, 'loss': 0.05477452, 'lr': 6.889e-05, 'params': 9588956, 'time_iter': 0.23821, 'accuracy': 0.97958, 'auc': 0.56168, 'ap': 0.02807}
2025-08-16 08:29:27,512 - INFO - val: {'epoch': 77, 'time_epoch': 8.82322, 'loss': 0.06691489, 'lr': 0, 'params': 9588956, 'time_iter': 0.1026, 'accuracy': 0.97414, 'auc': 0.51627, 'ap': 0.02561}
2025-08-16 08:29:38,292 - INFO - test: {'epoch': 77, 'time_epoch': 9.49032, 'loss': 0.06928547, 'lr': 0, 'params': 9588956, 'time_iter': 0.11035, 'accuracy': 0.97272, 'auc': 0.51536, 'ap': 0.02677}
2025-08-16 08:29:38,295 - INFO - > Epoch 77: took 194.1s (avg 193.7s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:32:31,267 - INFO - train: {'epoch': 78, 'time_epoch': 162.99011, 'eta': 3410.19189, 'eta_hours': 0.94728, 'loss': 0.05477049, 'lr': 6.329e-05, 'params': 9588956, 'time_iter': 0.23794, 'accuracy': 0.97958, 'auc': 0.566, 'ap': 0.0282}
2025-08-16 08:32:41,429 - INFO - val: {'epoch': 78, 'time_epoch': 8.82479, 'loss': 0.06678597, 'lr': 0, 'params': 9588956, 'time_iter': 0.10261, 'accuracy': 0.97414, 'auc': 0.5288, 'ap': 0.02559}
2025-08-16 08:32:52,196 - INFO - test: {'epoch': 78, 'time_epoch': 9.48335, 'loss': 0.06915946, 'lr': 0, 'params': 9588956, 'time_iter': 0.11027, 'accuracy': 0.97272, 'auc': 0.52332, 'ap': 0.02669}
2025-08-16 08:32:52,198 - INFO - > Epoch 78: took 193.9s (avg 193.7s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:35:42,762 - INFO - train: {'epoch': 79, 'time_epoch': 160.55587, 'eta': 3247.34325, 'eta_hours': 0.90204, 'loss': 0.05476981, 'lr': 5.79e-05, 'params': 9588956, 'time_iter': 0.23439, 'accuracy': 0.97958, 'auc': 0.56429, 'ap': 0.02818}
2025-08-16 08:35:52,898 - INFO - val: {'epoch': 79, 'time_epoch': 8.81513, 'loss': 0.06682639, 'lr': 0, 'params': 9588956, 'time_iter': 0.1025, 'accuracy': 0.97414, 'auc': 0.52592, 'ap': 0.02505}
2025-08-16 08:36:03,694 - INFO - test: {'epoch': 79, 'time_epoch': 9.48615, 'loss': 0.06921096, 'lr': 0, 'params': 9588956, 'time_iter': 0.1103, 'accuracy': 0.97272, 'auc': 0.52141, 'ap': 0.02619}
2025-08-16 08:36:03,696 - INFO - > Epoch 79: took 191.5s (avg 193.7s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:38:57,255 - INFO - train: {'epoch': 80, 'time_epoch': 163.78494, 'eta': 3085.30865, 'eta_hours': 0.85703, 'loss': 0.05476898, 'lr': 5.271e-05, 'params': 9588956, 'time_iter': 0.2391, 'accuracy': 0.97952, 'auc': 0.56428, 'ap': 0.02829}
2025-08-16 08:39:07,327 - INFO - val: {'epoch': 80, 'time_epoch': 8.80123, 'loss': 0.06696222, 'lr': 0, 'params': 9588956, 'time_iter': 0.10234, 'accuracy': 0.97414, 'auc': 0.52593, 'ap': 0.02556}
2025-08-16 08:39:18,026 - INFO - test: {'epoch': 80, 'time_epoch': 9.45049, 'loss': 0.06934963, 'lr': 0, 'params': 9588956, 'time_iter': 0.10989, 'accuracy': 0.97272, 'auc': 0.52421, 'ap': 0.02694}
2025-08-16 08:39:18,028 - INFO - > Epoch 80: took 194.3s (avg 193.7s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:42:07,678 - INFO - train: {'epoch': 81, 'time_epoch': 159.83585, 'eta': 2922.36449, 'eta_hours': 0.81177, 'loss': 0.05475921, 'lr': 4.775e-05, 'params': 9588956, 'time_iter': 0.23334, 'accuracy': 0.97954, 'auc': 0.56652, 'ap': 0.02831}
2025-08-16 08:42:17,784 - INFO - val: {'epoch': 81, 'time_epoch': 8.77851, 'loss': 0.06688646, 'lr': 0, 'params': 9588956, 'time_iter': 0.10208, 'accuracy': 0.97414, 'auc': 0.51978, 'ap': 0.02509}
2025-08-16 08:42:28,550 - INFO - test: {'epoch': 81, 'time_epoch': 9.47047, 'loss': 0.06927232, 'lr': 0, 'params': 9588956, 'time_iter': 0.11012, 'accuracy': 0.97272, 'auc': 0.51519, 'ap': 0.02572}
2025-08-16 08:42:28,553 - INFO - > Epoch 81: took 190.5s (avg 193.7s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:45:22,053 - INFO - train: {'epoch': 82, 'time_epoch': 163.46903, 'eta': 2760.23937, 'eta_hours': 0.76673, 'loss': 0.05476867, 'lr': 4.3e-05, 'params': 9588956, 'time_iter': 0.23864, 'accuracy': 0.97958, 'auc': 0.5664, 'ap': 0.02815}
2025-08-16 08:45:32,235 - INFO - val: {'epoch': 82, 'time_epoch': 8.85002, 'loss': 0.0665204, 'lr': 0, 'params': 9588956, 'time_iter': 0.10291, 'accuracy': 0.97414, 'auc': 0.51978, 'ap': 0.02528}
2025-08-16 08:45:43,033 - INFO - test: {'epoch': 82, 'time_epoch': 9.49797, 'loss': 0.06888142, 'lr': 0, 'params': 9588956, 'time_iter': 0.11044, 'accuracy': 0.97272, 'auc': 0.51754, 'ap': 0.0264}
2025-08-16 08:45:43,035 - INFO - > Epoch 82: took 194.5s (avg 193.7s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:48:35,802 - INFO - train: {'epoch': 83, 'time_epoch': 162.77563, 'eta': 2597.95018, 'eta_hours': 0.72165, 'loss': 0.05475882, 'lr': 3.848e-05, 'params': 9588956, 'time_iter': 0.23763, 'accuracy': 0.97955, 'auc': 0.56605, 'ap': 0.02824}
2025-08-16 08:48:45,947 - INFO - val: {'epoch': 83, 'time_epoch': 8.82296, 'loss': 0.06662706, 'lr': 0, 'params': 9588956, 'time_iter': 0.10259, 'accuracy': 0.97414, 'auc': 0.5178, 'ap': 0.02528}
2025-08-16 08:48:56,724 - INFO - test: {'epoch': 83, 'time_epoch': 9.48561, 'loss': 0.06899933, 'lr': 0, 'params': 9588956, 'time_iter': 0.1103, 'accuracy': 0.97272, 'auc': 0.51448, 'ap': 0.02636}
2025-08-16 08:48:56,726 - INFO - > Epoch 83: took 193.7s (avg 193.7s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:51:46,146 - INFO - train: {'epoch': 84, 'time_epoch': 159.38247, 'eta': 2435.05075, 'eta_hours': 0.6764, 'loss': 0.05475324, 'lr': 3.419e-05, 'params': 9588956, 'time_iter': 0.23268, 'accuracy': 0.97956, 'auc': 0.56506, 'ap': 0.02806}
2025-08-16 08:51:56,283 - INFO - val: {'epoch': 84, 'time_epoch': 8.82162, 'loss': 0.06680225, 'lr': 0, 'params': 9588956, 'time_iter': 0.10258, 'accuracy': 0.97414, 'auc': 0.51822, 'ap': 0.02531}
2025-08-16 08:52:07,036 - INFO - test: {'epoch': 84, 'time_epoch': 9.46752, 'loss': 0.06917201, 'lr': 0, 'params': 9588956, 'time_iter': 0.11009, 'accuracy': 0.97272, 'auc': 0.51312, 'ap': 0.02651}
2025-08-16 08:52:07,038 - INFO - > Epoch 84: took 190.3s (avg 193.6s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:54:59,959 - INFO - train: {'epoch': 85, 'time_epoch': 163.01906, 'eta': 2272.82511, 'eta_hours': 0.63134, 'loss': 0.05474301, 'lr': 3.013e-05, 'params': 9588956, 'time_iter': 0.23798, 'accuracy': 0.97962, 'auc': 0.56913, 'ap': 0.02827}
2025-08-16 08:55:10,057 - INFO - val: {'epoch': 85, 'time_epoch': 8.80383, 'loss': 0.06660948, 'lr': 0, 'params': 9588956, 'time_iter': 0.10237, 'accuracy': 0.97414, 'auc': 0.52018, 'ap': 0.02516}
2025-08-16 08:55:20,763 - INFO - test: {'epoch': 85, 'time_epoch': 9.44673, 'loss': 0.06899248, 'lr': 0, 'params': 9588956, 'time_iter': 0.10985, 'accuracy': 0.97272, 'auc': 0.51614, 'ap': 0.02622}
2025-08-16 08:55:20,765 - INFO - > Epoch 85: took 193.7s (avg 193.6s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 08:58:09,403 - INFO - train: {'epoch': 86, 'time_epoch': 158.73573, 'eta': 2109.9412, 'eta_hours': 0.58609, 'loss': 0.05473674, 'lr': 2.632e-05, 'params': 9588956, 'time_iter': 0.23173, 'accuracy': 0.97957, 'auc': 0.56852, 'ap': 0.02832}
2025-08-16 08:58:19,486 - INFO - val: {'epoch': 86, 'time_epoch': 8.78031, 'loss': 0.06657398, 'lr': 0, 'params': 9588956, 'time_iter': 0.1021, 'accuracy': 0.97414, 'auc': 0.51922, 'ap': 0.0251}
2025-08-16 08:58:30,204 - INFO - test: {'epoch': 86, 'time_epoch': 9.43848, 'loss': 0.06894635, 'lr': 0, 'params': 9588956, 'time_iter': 0.10975, 'accuracy': 0.97272, 'auc': 0.51725, 'ap': 0.02626}
2025-08-16 08:58:30,206 - INFO - > Epoch 86: took 189.4s (avg 193.6s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 09:01:23,414 - INFO - train: {'epoch': 87, 'time_epoch': 163.19884, 'eta': 1947.76017, 'eta_hours': 0.54104, 'loss': 0.05475741, 'lr': 2.275e-05, 'params': 9588956, 'time_iter': 0.23825, 'accuracy': 0.97962, 'auc': 0.56592, 'ap': 0.02819}
2025-08-16 09:01:33,559 - INFO - val: {'epoch': 87, 'time_epoch': 8.82747, 'loss': 0.06681305, 'lr': 0, 'params': 9588956, 'time_iter': 0.10265, 'accuracy': 0.97414, 'auc': 0.51589, 'ap': 0.02516}
2025-08-16 09:01:44,237 - INFO - test: {'epoch': 87, 'time_epoch': 9.44367, 'loss': 0.06919233, 'lr': 0, 'params': 9588956, 'time_iter': 0.10981, 'accuracy': 0.97272, 'auc': 0.51401, 'ap': 0.02602}
2025-08-16 09:01:44,240 - INFO - > Epoch 87: took 194.0s (avg 193.6s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 09:04:37,269 - INFO - train: {'epoch': 88, 'time_epoch': 163.27016, 'eta': 1785.56508, 'eta_hours': 0.49599, 'loss': 0.05474866, 'lr': 1.943e-05, 'params': 9588956, 'time_iter': 0.23835, 'accuracy': 0.97957, 'auc': 0.56831, 'ap': 0.02881}
2025-08-16 09:04:47,327 - INFO - val: {'epoch': 88, 'time_epoch': 8.78324, 'loss': 0.06646214, 'lr': 0, 'params': 9588956, 'time_iter': 0.10213, 'accuracy': 0.97414, 'auc': 0.51293, 'ap': 0.02483}
2025-08-16 09:04:58,020 - INFO - test: {'epoch': 88, 'time_epoch': 9.44209, 'loss': 0.06884077, 'lr': 0, 'params': 9588956, 'time_iter': 0.10979, 'accuracy': 0.97272, 'auc': 0.51086, 'ap': 0.02587}
2025-08-16 09:04:58,022 - INFO - > Epoch 88: took 193.8s (avg 193.6s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 09:07:48,382 - INFO - train: {'epoch': 89, 'time_epoch': 160.49519, 'eta': 1623.03777, 'eta_hours': 0.45084, 'loss': 0.05474287, 'lr': 1.636e-05, 'params': 9588956, 'time_iter': 0.2343, 'accuracy': 0.97962, 'auc': 0.5667, 'ap': 0.02871}
2025-08-16 09:07:58,478 - INFO - val: {'epoch': 89, 'time_epoch': 8.80243, 'loss': 0.06648981, 'lr': 0, 'params': 9588956, 'time_iter': 0.10235, 'accuracy': 0.97414, 'auc': 0.51122, 'ap': 0.02473}
2025-08-16 09:08:09,141 - INFO - test: {'epoch': 89, 'time_epoch': 9.44272, 'loss': 0.06886356, 'lr': 0, 'params': 9588956, 'time_iter': 0.1098, 'accuracy': 0.97272, 'auc': 0.50689, 'ap': 0.02576}
2025-08-16 09:08:09,144 - INFO - > Epoch 89: took 191.1s (avg 193.6s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 09:11:01,873 - INFO - train: {'epoch': 90, 'time_epoch': 162.75096, 'eta': 1460.77822, 'eta_hours': 0.40577, 'loss': 0.05474034, 'lr': 1.355e-05, 'params': 9588956, 'time_iter': 0.23759, 'accuracy': 0.97958, 'auc': 0.56886, 'ap': 0.02842}
2025-08-16 09:11:12,009 - INFO - val: {'epoch': 90, 'time_epoch': 8.81862, 'loss': 0.06655543, 'lr': 0, 'params': 9588956, 'time_iter': 0.10254, 'accuracy': 0.97414, 'auc': 0.51022, 'ap': 0.02461}
2025-08-16 09:11:22,768 - INFO - test: {'epoch': 90, 'time_epoch': 9.47411, 'loss': 0.06893346, 'lr': 0, 'params': 9588956, 'time_iter': 0.11016, 'accuracy': 0.97272, 'auc': 0.50673, 'ap': 0.02566}
2025-08-16 09:11:22,771 - INFO - > Epoch 90: took 193.6s (avg 193.6s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 09:14:12,926 - INFO - train: {'epoch': 91, 'time_epoch': 160.17513, 'eta': 1298.284, 'eta_hours': 0.36063, 'loss': 0.05474869, 'lr': 1.099e-05, 'params': 9588956, 'time_iter': 0.23383, 'accuracy': 0.97961, 'auc': 0.56789, 'ap': 0.02872}
2025-08-16 09:14:23,053 - INFO - val: {'epoch': 91, 'time_epoch': 8.81215, 'loss': 0.06652808, 'lr': 0, 'params': 9588956, 'time_iter': 0.10247, 'accuracy': 0.97414, 'auc': 0.51245, 'ap': 0.02464}
2025-08-16 09:14:33,799 - INFO - test: {'epoch': 91, 'time_epoch': 9.46346, 'loss': 0.06890688, 'lr': 0, 'params': 9588956, 'time_iter': 0.11004, 'accuracy': 0.97272, 'auc': 0.51021, 'ap': 0.02588}
2025-08-16 09:14:33,801 - INFO - > Epoch 91: took 191.0s (avg 193.5s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 09:17:26,033 - INFO - train: {'epoch': 92, 'time_epoch': 162.22295, 'eta': 1135.99379, 'eta_hours': 0.31555, 'loss': 0.05472564, 'lr': 8.7e-06, 'params': 9588956, 'time_iter': 0.23682, 'accuracy': 0.97957, 'auc': 0.5722, 'ap': 0.0286}
2025-08-16 09:17:36,173 - INFO - val: {'epoch': 92, 'time_epoch': 8.81689, 'loss': 0.06645821, 'lr': 0, 'params': 9588956, 'time_iter': 0.10252, 'accuracy': 0.97414, 'auc': 0.51235, 'ap': 0.02458}
2025-08-16 09:17:46,946 - INFO - test: {'epoch': 92, 'time_epoch': 9.48225, 'loss': 0.06883795, 'lr': 0, 'params': 9588956, 'time_iter': 0.11026, 'accuracy': 0.97272, 'auc': 0.50936, 'ap': 0.02583}
2025-08-16 09:17:46,948 - INFO - > Epoch 92: took 193.1s (avg 193.5s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 09:20:40,011 - INFO - train: {'epoch': 93, 'time_epoch': 163.06014, 'eta': 973.75845, 'eta_hours': 0.27049, 'loss': 0.05474244, 'lr': 6.67e-06, 'params': 9588956, 'time_iter': 0.23804, 'accuracy': 0.97957, 'auc': 0.56903, 'ap': 0.02869}
2025-08-16 09:20:50,154 - INFO - val: {'epoch': 93, 'time_epoch': 8.82259, 'loss': 0.0666571, 'lr': 0, 'params': 9588956, 'time_iter': 0.10259, 'accuracy': 0.97414, 'auc': 0.51061, 'ap': 0.0246}
2025-08-16 09:21:00,945 - INFO - test: {'epoch': 93, 'time_epoch': 9.48477, 'loss': 0.0690412, 'lr': 0, 'params': 9588956, 'time_iter': 0.11029, 'accuracy': 0.97272, 'auc': 0.50972, 'ap': 0.02587}
2025-08-16 09:21:00,947 - INFO - > Epoch 93: took 194.0s (avg 193.5s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 09:23:51,945 - INFO - train: {'epoch': 94, 'time_epoch': 161.00873, 'eta': 811.39778, 'eta_hours': 0.22539, 'loss': 0.05473106, 'lr': 4.91e-06, 'params': 9588956, 'time_iter': 0.23505, 'accuracy': 0.97958, 'auc': 0.56697, 'ap': 0.02836}
2025-08-16 09:24:02,087 - INFO - val: {'epoch': 94, 'time_epoch': 8.81964, 'loss': 0.06669952, 'lr': 0, 'params': 9588956, 'time_iter': 0.10255, 'accuracy': 0.97414, 'auc': 0.51024, 'ap': 0.02463}
2025-08-16 09:24:12,820 - INFO - test: {'epoch': 94, 'time_epoch': 9.45244, 'loss': 0.06908905, 'lr': 0, 'params': 9588956, 'time_iter': 0.10991, 'accuracy': 0.97272, 'auc': 0.50773, 'ap': 0.02588}
2025-08-16 09:24:12,822 - INFO - > Epoch 94: took 191.9s (avg 193.5s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 09:27:06,057 - INFO - train: {'epoch': 95, 'time_epoch': 163.40598, 'eta': 649.16516, 'eta_hours': 0.18032, 'loss': 0.05473725, 'lr': 3.41e-06, 'params': 9588956, 'time_iter': 0.23855, 'accuracy': 0.97961, 'auc': 0.56884, 'ap': 0.0285}
2025-08-16 09:27:16,132 - INFO - val: {'epoch': 95, 'time_epoch': 8.79724, 'loss': 0.06667958, 'lr': 0, 'params': 9588956, 'time_iter': 0.10229, 'accuracy': 0.97414, 'auc': 0.50994, 'ap': 0.02462}
2025-08-16 09:27:26,824 - INFO - test: {'epoch': 95, 'time_epoch': 9.44795, 'loss': 0.06907015, 'lr': 0, 'params': 9588956, 'time_iter': 0.10986, 'accuracy': 0.97272, 'auc': 0.50755, 'ap': 0.02585}
2025-08-16 09:27:26,826 - INFO - > Epoch 95: took 194.0s (avg 193.5s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 09:30:17,422 - INFO - train: {'epoch': 96, 'time_epoch': 160.76986, 'eta': 486.82681, 'eta_hours': 0.13523, 'loss': 0.05474535, 'lr': 2.18e-06, 'params': 9588956, 'time_iter': 0.2347, 'accuracy': 0.97956, 'auc': 0.56861, 'ap': 0.02825}
2025-08-16 09:30:27,485 - INFO - val: {'epoch': 96, 'time_epoch': 8.78727, 'loss': 0.06670656, 'lr': 0, 'params': 9588956, 'time_iter': 0.10218, 'accuracy': 0.97414, 'auc': 0.5106, 'ap': 0.02464}
2025-08-16 09:30:41,204 - INFO - test: {'epoch': 96, 'time_epoch': 12.46899, 'loss': 0.06909605, 'lr': 0, 'params': 9588956, 'time_iter': 0.14499, 'accuracy': 0.97272, 'auc': 0.50754, 'ap': 0.02585}
2025-08-16 09:30:41,206 - INFO - > Epoch 96: took 194.4s (avg 193.5s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 09:33:31,376 - INFO - train: {'epoch': 97, 'time_epoch': 160.17823, 'eta': 324.50841, 'eta_hours': 0.09014, 'loss': 0.05474695, 'lr': 1.23e-06, 'params': 9588956, 'time_iter': 0.23384, 'accuracy': 0.97955, 'auc': 0.56783, 'ap': 0.02833}
2025-08-16 09:33:41,547 - INFO - val: {'epoch': 97, 'time_epoch': 8.82918, 'loss': 0.0666923, 'lr': 0, 'params': 9588956, 'time_iter': 0.10266, 'accuracy': 0.97414, 'auc': 0.51113, 'ap': 0.02462}
2025-08-16 09:33:52,309 - INFO - test: {'epoch': 97, 'time_epoch': 9.47171, 'loss': 0.06908201, 'lr': 0, 'params': 9588956, 'time_iter': 0.11014, 'accuracy': 0.97272, 'auc': 0.50944, 'ap': 0.02585}
2025-08-16 09:33:52,311 - INFO - > Epoch 97: took 191.1s (avg 193.5s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 09:36:45,468 - INFO - train: {'epoch': 98, 'time_epoch': 163.08007, 'eta': 162.26254, 'eta_hours': 0.04507, 'loss': 0.05474699, 'lr': 5.5e-07, 'params': 9588956, 'time_iter': 0.23807, 'accuracy': 0.97952, 'auc': 0.56828, 'ap': 0.02819}
2025-08-16 09:36:55,711 - INFO - val: {'epoch': 98, 'time_epoch': 8.91454, 'loss': 0.06665802, 'lr': 0, 'params': 9588956, 'time_iter': 0.10366, 'accuracy': 0.97414, 'auc': 0.51008, 'ap': 0.02462}
2025-08-16 09:37:06,511 - INFO - test: {'epoch': 98, 'time_epoch': 9.51249, 'loss': 0.06904603, 'lr': 0, 'params': 9588956, 'time_iter': 0.11061, 'accuracy': 0.97272, 'auc': 0.50738, 'ap': 0.02586}
2025-08-16 09:37:06,513 - INFO - > Epoch 98: took 194.2s (avg 193.5s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 09:39:57,087 - INFO - train: {'epoch': 99, 'time_epoch': 160.55593, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.05473728, 'lr': 1.4e-07, 'params': 9588956, 'time_iter': 0.23439, 'accuracy': 0.97959, 'auc': 0.56761, 'ap': 0.02854}
2025-08-16 09:40:07,202 - INFO - val: {'epoch': 99, 'time_epoch': 8.79598, 'loss': 0.06667185, 'lr': 0, 'params': 9588956, 'time_iter': 0.10228, 'accuracy': 0.97414, 'auc': 0.51067, 'ap': 0.0246}
2025-08-16 09:40:17,958 - INFO - test: {'epoch': 99, 'time_epoch': 9.4658, 'loss': 0.06906058, 'lr': 0, 'params': 9588956, 'time_iter': 0.11007, 'accuracy': 0.97272, 'auc': 0.50762, 'ap': 0.02584}
2025-08-16 09:40:19,255 - INFO - > Epoch 99: took 191.4s (avg 193.5s) | Best so far: epoch 3	train_loss: 0.0546 train_ap: 0.0369	val_loss: 0.0676 val_ap: 0.0476	test_loss: 0.0699 test_ap: 0.0481
2025-08-16 09:40:19,255 - INFO - Avg time per epoch: 193.49s
2025-08-16 09:40:19,255 - INFO - Total train loop time: 5.37h
2025-08-16 09:40:19,266 - INFO - Task done, results saved in results/molpcba/molpcba-Vanilla-66
2025-08-16 09:40:19,267 - INFO - Total time: 19994.84s (5.55h)
2025-08-16 09:40:19,293 - INFO - Results aggregated across runs saved in results/molpcba/molpcba-Vanilla-66/agg
2025-08-16 09:40:19,293 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-16 09:40:19,293 - INFO - Results saved in: results/molpcba/molpcba-Vanilla-66
2025-08-16 09:40:19,293 - INFO - Test results JSON files saved in: results/molpcba/molpcba-Vanilla-66/test_results/
Completed seed 66. Results saved in results/molpcba/molpcba-Vanilla-66
----------------------------------------
All experiments completed!
/var/spool/slurmd/job5441427/slurm_script: line 72: syntax error near unexpected token `"/data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLPCBA"'
/var/spool/slurmd/job5441427/slurm_script: line 72: `os.chdir("/data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLPCBA")'
