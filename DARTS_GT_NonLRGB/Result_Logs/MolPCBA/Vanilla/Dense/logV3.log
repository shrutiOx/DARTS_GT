Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLPCBA
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLPCBA/confignas.yaml
Using device: cuda
2025-06-20 14:45:40,326 - INFO - GPU Mem: 34.1GB
2025-06-20 14:45:40,326 - INFO - Run directory: results/molpcba/molpcba-Vanilla-45
2025-06-20 14:45:40,326 - INFO - Seed: 45
2025-06-20 14:45:40,326 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-06-20 14:45:40,326 - INFO - Routing mode: none
2025-06-20 14:45:40,326 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-06-20 14:45:40,326 - INFO - Number of layers: 8
2025-06-20 14:45:40,326 - INFO - Uncertainty enabled: False
2025-06-20 14:45:40,326 - INFO - Training mode: custom
2025-06-20 14:45:40,326 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-06-20 14:45:40,327 - INFO - Additional features: Router weights logging + JSON export
2025-06-20 14:47:33,228 - INFO - [*] Loaded dataset 'ogbg-molpcba' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-20 14:47:33,234 - INFO -   Data(edge_index=[2, 24618372], edge_attr=[24618372, 3], x=[11373137, 9], y=[437929, 128], num_nodes=11373137)
2025-06-20 14:47:33,277 - INFO -   undirected: True
2025-06-20 14:47:33,277 - INFO -   num graphs: 437929
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-20 14:47:33,279 - INFO -   avg num_nodes/graph: 25
2025-06-20 14:47:33,279 - INFO -   num node features: 9
2025-06-20 14:47:33,279 - INFO -   num edge features: 3
2025-06-20 14:47:33,279 - INFO -   num tasks: 128
2025-06-20 14:47:33,281 - INFO -   num classes: 2
2025-06-20 14:47:33,281 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-06-20 14:47:33,281 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-06-20 14:47:33,286 - INFO -   ...estimated to be undirected: True
  0%|          | 0/437929 [00:00<?, ?it/s]  0%|          | 0/437929 [00:14<?, ?it/s]  3%|▎         | 11102/437929 [00:14<09:14, 770.14it/s]  4%|▍         | 18737/437929 [00:24<09:06, 766.79it/s]  6%|▌         | 26424/437929 [00:34<08:56, 767.57it/s]  8%|▊         | 34096/437929 [00:44<08:46, 767.42it/s] 10%|▉         | 41746/437929 [00:54<08:36, 766.56it/s] 11%|█▏        | 49373/437929 [01:04<08:27, 765.26it/s] 13%|█▎        | 56972/437929 [01:14<08:18, 763.52it/s] 15%|█▍        | 64617/437929 [01:24<08:08, 763.80it/s] 16%|█▋        | 72197/437929 [01:34<07:59, 761.98it/s] 18%|█▊        | 79782/437929 [01:44<07:50, 760.90it/s] 20%|█▉        | 87418/437929 [01:54<07:40, 761.70it/s] 22%|██▏       | 94522/437929 [02:04<07:40, 746.13it/s] 23%|██▎       | 102070/437929 [02:14<07:28, 748.74it/s] 25%|██▌       | 109667/437929 [02:24<07:16, 752.04it/s] 27%|██▋       | 116615/437929 [02:34<07:17, 734.79it/s] 28%|██▊       | 124142/437929 [02:44<07:03, 740.15it/s] 30%|███       | 131752/437929 [02:54<06:50, 746.41it/s] 32%|███▏      | 139244/437929 [03:04<06:39, 747.22it/s] 34%|███▎      | 146722/437929 [03:14<06:29, 747.38it/s] 35%|███▌      | 153626/437929 [03:24<06:29, 730.27it/s] 37%|███▋      | 161177/437929 [03:34<06:15, 737.72it/s] 39%|███▊      | 168620/437929 [03:44<06:04, 739.68it/s] 40%|████      | 176165/437929 [03:54<05:51, 744.10it/s] 42%|████▏     | 183572/437929 [04:04<05:42, 743.07it/s] 44%|████▎     | 191009/437929 [04:14<05:32, 743.23it/s] 45%|████▌     | 197548/437929 [04:24<05:35, 716.41it/s] 47%|████▋     | 205120/437929 [04:34<05:19, 728.62it/s] 49%|████▊     | 212523/437929 [04:44<05:07, 732.12it/s] 50%|█████     | 219783/437929 [04:54<04:58, 730.28it/s] 52%|█████▏    | 227122/437929 [05:04<04:48, 731.36it/s] 54%|█████▎    | 234534/437929 [05:14<04:36, 734.30it/s] 55%|█████▌    | 241877/437929 [05:24<04:26, 734.30it/s] 57%|█████▋    | 248261/437929 [05:34<04:28, 705.52it/s] 58%|█████▊    | 255589/437929 [05:44<04:15, 713.69it/s] 60%|██████    | 262998/437929 [05:54<04:02, 721.84it/s] 62%|██████▏   | 270277/437929 [06:04<03:51, 723.66it/s] 63%|██████▎   | 277422/437929 [06:14<03:42, 720.88it/s] 65%|██████▍   | 284632/437929 [06:24<03:32, 720.89it/s] 67%|██████▋   | 291971/437929 [06:34<03:21, 724.79it/s] 68%|██████▊   | 299164/437929 [06:44<03:11, 723.14it/s] 70%|██████▉   | 306314/437929 [06:54<03:02, 720.68it/s] 71%|███████▏  | 312359/437929 [07:04<03:03, 685.82it/s] 73%|███████▎  | 319344/437929 [07:14<02:51, 689.61it/s] 74%|███████▍  | 326240/437929 [07:24<02:41, 689.58it/s] 76%|███████▌  | 333015/437929 [07:34<02:32, 685.96it/s] 78%|███████▊  | 339888/437929 [07:44<02:22, 686.34it/s] 79%|███████▉  | 346785/437929 [07:54<02:12, 687.32it/s] 81%|████████  | 353638/437929 [08:04<02:02, 686.68it/s] 82%|████████▏ | 360576/437929 [08:14<01:52, 688.79it/s] 84%|████████▍ | 367552/437929 [08:24<01:41, 691.41it/s] 86%|████████▌ | 374552/437929 [08:34<01:31, 693.97it/s] 87%|████████▋ | 381532/437929 [08:44<01:21, 695.15it/s] 89%|████████▊ | 388647/437929 [08:54<01:10, 700.05it/s] 90%|████████▉ | 394070/437929 [09:04<01:07, 652.71it/s] 92%|█████████▏| 401319/437929 [09:14<00:54, 674.35it/s] 93%|█████████▎| 408469/437929 [09:24<00:42, 686.52it/s] 95%|█████████▍| 415516/437929 [09:34<00:32, 691.96it/s] 97%|█████████▋| 422624/437929 [09:44<00:21, 697.60it/s] 98%|█████████▊| 429248/437929 [09:54<00:12, 687.03it/s]100%|█████████▉| 436018/437929 [10:04<00:02, 684.01it/s]100%|██████████| 437929/437929 [10:07<00:00, 721.13it/s]
2025-06-20 14:57:54,183 - INFO - Done! Took 00:10:20.90
2025-06-20 14:57:56,094 - INFO - [*] Loaded dataset 'ogbg-molpcba' from 'OGB'
2025-06-20 14:57:56,341 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-06-20 14:57:56,341 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-06-20 14:57:56,341 - INFO - Inner model has get_darts_model: False
2025-06-20 14:57:56,345 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 364)
            (1): Embedding(5, 364)
            (2-3): 2 x Embedding(12, 364)
            (4): Embedding(10, 364)
            (5-6): 2 x Embedding(6, 364)
            (7-8): 2 x Embedding(2, 364)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=20, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 384)
          (1): Embedding(6, 384)
          (2): Embedding(2, 384)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=384, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (norm1_attn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.2, inplace=False)
        (ff_linear1): Linear(in_features=384, out_features=768, bias=True)
        (ff_linear2): Linear(in_features=768, out_features=384, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.2, inplace=False)
        (ff_dropout2): Dropout(p=0.2, inplace=False)
      )
    )
    (post_mp): GNNGraphHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): Linear(
            (model): Linear(384, 128, bias=True)
          )
        )
      )
    )
  )
)
2025-06-20 14:57:56,347 - INFO - Number of parameters: 9,588,956
2025-06-20 14:57:56,347 - INFO - Starting optimized training: 2025-06-20 14:57:56.347591
2025-06-20 14:59:24,516 - INFO - [*] Loaded dataset 'ogbg-molpcba' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-20 14:59:24,517 - INFO -   Data(edge_index=[2, 24618372], edge_attr=[24618372, 3], x=[11373137, 9], y=[437929, 128], num_nodes=11373137)
2025-06-20 14:59:24,519 - INFO -   undirected: True
2025-06-20 14:59:24,519 - INFO -   num graphs: 437929
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-20 14:59:24,521 - INFO -   avg num_nodes/graph: 25
2025-06-20 14:59:24,521 - INFO -   num node features: 9
2025-06-20 14:59:24,521 - INFO -   num edge features: 3
2025-06-20 14:59:24,521 - INFO -   num tasks: 128
2025-06-20 14:59:24,523 - INFO -   num classes: 2
2025-06-20 14:59:24,523 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-06-20 14:59:24,523 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-06-20 14:59:24,529 - INFO -   ...estimated to be undirected: True
  0%|          | 0/437929 [00:00<?, ?it/s]  0%|          | 0/437929 [00:13<?, ?it/s]  2%|▏         | 9870/437929 [00:13<09:32, 747.70it/s]  4%|▍         | 17287/437929 [00:23<09:24, 744.56it/s]  6%|▌         | 24625/437929 [00:33<09:18, 739.86it/s]  7%|▋         | 31983/437929 [00:43<09:09, 738.29it/s]  9%|▉         | 39361/437929 [00:53<08:59, 738.10it/s] 11%|█         | 46679/437929 [01:03<08:51, 735.98it/s] 12%|█▏        | 53993/437929 [01:13<08:42, 734.48it/s] 14%|█▍        | 61330/437929 [01:23<08:32, 734.21it/s] 16%|█▌        | 68635/437929 [01:33<08:23, 733.05it/s] 17%|█▋        | 75913/437929 [01:43<08:14, 731.40it/s] 19%|█▉        | 83257/437929 [01:53<08:04, 732.29it/s] 21%|██        | 90534/437929 [02:03<07:55, 730.88it/s] 22%|██▏       | 97789/437929 [02:13<07:46, 729.23it/s] 24%|██▍       | 104606/437929 [02:23<07:46, 714.88it/s] 26%|██▌       | 111834/437929 [02:33<07:34, 717.26it/s] 27%|██▋       | 119039/437929 [02:43<07:23, 718.22it/s] 29%|██▉       | 126360/437929 [02:53<07:11, 722.38it/s] 30%|███       | 132952/437929 [03:03<07:13, 703.38it/s] 32%|███▏      | 140461/437929 [03:13<06:54, 717.62it/s] 34%|███▍      | 148024/437929 [03:23<06:37, 729.23it/s] 36%|███▌      | 155537/437929 [03:33<06:23, 735.85it/s] 37%|███▋      | 162946/437929 [03:43<06:12, 737.36it/s] 39%|███▉      | 169735/437929 [03:53<06:12, 719.80it/s] 40%|████      | 177243/437929 [04:03<05:57, 729.08it/s] 42%|████▏     | 184689/437929 [04:13<05:45, 733.73it/s] 44%|████▍     | 192251/437929 [04:23<05:31, 740.44it/s] 46%|████▌     | 199739/437929 [04:33<05:20, 742.95it/s] 47%|████▋     | 207169/437929 [04:43<05:10, 742.94it/s] 49%|████▉     | 214732/437929 [04:53<04:58, 746.92it/s] 50%|█████     | 221012/437929 [05:03<05:04, 711.22it/s] 52%|█████▏    | 228140/437929 [05:13<04:54, 711.67it/s] 54%|█████▍    | 235490/437929 [05:23<04:41, 718.66it/s] 55%|█████▌    | 242975/437929 [05:33<04:27, 727.59it/s] 57%|█████▋    | 249965/437929 [05:43<04:21, 719.01it/s] 59%|█████▊    | 256816/437929 [05:53<04:15, 708.83it/s] 60%|██████    | 263714/437929 [06:03<04:07, 703.12it/s] 62%|██████▏   | 270712/437929 [06:13<03:58, 702.10it/s] 63%|██████▎   | 276720/437929 [06:23<04:00, 671.68it/s] 65%|██████▍   | 284056/437929 [06:33<03:42, 690.24it/s] 67%|██████▋   | 291323/437929 [06:43<03:29, 701.16it/s] 68%|██████▊   | 298565/437929 [06:53<03:16, 708.06it/s] 70%|██████▉   | 305937/437929 [07:03<03:04, 716.80it/s] 72%|███████▏  | 313281/437929 [07:13<02:52, 722.05it/s] 73%|███████▎  | 320711/437929 [07:23<02:40, 728.33it/s] 75%|███████▍  | 327833/437929 [07:33<02:32, 723.47it/s] 76%|███████▋  | 334927/437929 [07:43<02:23, 719.22it/s] 78%|███████▊  | 342139/437929 [07:53<02:13, 719.80it/s] 79%|███████▉  | 348024/437929 [08:03<02:13, 674.49it/s] 81%|████████  | 355167/437929 [08:13<02:00, 686.34it/s] 83%|████████▎ | 362422/437929 [08:23<01:48, 698.02it/s] 84%|████████▍ | 369571/437929 [08:33<01:37, 703.05it/s] 86%|████████▌ | 376790/437929 [08:43<01:26, 708.68it/s] 88%|████████▊ | 384191/437929 [08:53<01:14, 718.08it/s] 89%|████████▉ | 391529/437929 [09:03<01:04, 722.79it/s] 91%|█████████ | 398827/437929 [09:13<00:53, 724.88it/s] 93%|█████████▎| 406218/437929 [09:23<00:43, 729.13it/s] 94%|█████████▍| 413563/437929 [09:33<00:33, 730.74it/s] 96%|█████████▌| 420926/437929 [09:43<00:23, 732.38it/s] 98%|█████████▊| 428249/437929 [09:53<00:13, 732.34it/s] 99%|█████████▉| 435383/437929 [10:03<00:03, 726.64it/s]100%|██████████| 437929/437929 [10:07<00:00, 721.29it/s]
2025-06-20 15:09:44,477 - INFO - Done! Took 00:10:19.95
2025-06-20 15:09:47,611 - INFO - [*] Loaded dataset 'ogbg-molpcba' from 'OGB'
2025-06-20 15:09:47,637 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-06-20 15:09:47,637 - INFO - Start from epoch 0
2025-06-20 15:14:25,615 - INFO - train: {'epoch': 0, 'time_epoch': 267.71359, 'eta': 26503.64585, 'eta_hours': 7.36212, 'loss': 0.7008229, 'lr': 0.0, 'params': 9588956, 'time_iter': 0.39082, 'accuracy': 0.501, 'auc': 0.49692, 'ap': 0.02182}
2025-06-20 15:14:25,629 - INFO - ...computing epoch stats took: 10.26s
2025-06-20 15:14:48,883 - INFO - val: {'epoch': 0, 'time_epoch': 21.75477, 'loss': 0.69861972, 'lr': 0, 'params': 9588956, 'time_iter': 0.25296, 'accuracy': 0.51283, 'auc': 0.4873, 'ap': 0.02641}
2025-06-20 15:14:48,894 - INFO - ...computing epoch stats took: 1.51s
2025-06-20 15:15:13,464 - INFO - test: {'epoch': 0, 'time_epoch': 23.18901, 'loss': 0.69940048, 'lr': 0, 'params': 9588956, 'time_iter': 0.26964, 'accuracy': 0.51314, 'auc': 0.48999, 'ap': 0.02817}
2025-06-20 15:15:13,478 - INFO - ...computing epoch stats took: 1.39s
2025-06-20 15:15:13,478 - INFO - > Epoch 0: took 325.8s (avg 325.8s) | Best so far: epoch 0	train_loss: 0.7008 train_ap: 0.0218	val_loss: 0.6986 val_ap: 0.0264	test_loss: 0.6994 test_ap: 0.0282
2025-06-20 15:18:44,212 - INFO - train: {'epoch': 1, 'time_epoch': 201.19537, 'eta': 22976.5395, 'eta_hours': 6.38237, 'loss': 0.44440367, 'lr': 0.0001, 'params': 9588956, 'time_iter': 0.29372, 'accuracy': 0.88207, 'auc': 0.53684, 'ap': 0.02963}
2025-06-20 15:18:44,220 - INFO - ...computing epoch stats took: 9.53s
2025-06-20 15:18:57,163 - INFO - val: {'epoch': 1, 'time_epoch': 11.49515, 'loss': 0.58577361, 'lr': 0, 'params': 9588956, 'time_iter': 0.13366, 'accuracy': 0.72629, 'auc': 0.55639, 'ap': 0.03513}
2025-06-20 15:18:57,165 - INFO - ...computing epoch stats took: 1.45s
2025-06-20 15:19:10,891 - INFO - test: {'epoch': 1, 'time_epoch': 12.38277, 'loss': 0.60878807, 'lr': 0, 'params': 9588956, 'time_iter': 0.14399, 'accuracy': 0.73146, 'auc': 0.54687, 'ap': 0.03473}
2025-06-20 15:19:10,893 - INFO - ...computing epoch stats took: 1.34s
2025-06-20 15:19:10,894 - INFO - > Epoch 1: took 237.4s (avg 281.6s) | Best so far: epoch 1	train_loss: 0.4444 train_ap: 0.0296	val_loss: 0.5858 val_ap: 0.0351	test_loss: 0.6088 test_ap: 0.0347
2025-06-20 15:22:45,522 - INFO - train: {'epoch': 2, 'time_epoch': 205.14767, 'eta': 21794.49801, 'eta_hours': 6.05403, 'loss': 0.09989389, 'lr': 0.0002, 'params': 9588956, 'time_iter': 0.29949, 'accuracy': 0.97637, 'auc': 0.56957, 'ap': 0.03273}
2025-06-20 15:22:45,530 - INFO - ...computing epoch stats took: 9.47s
2025-06-20 15:22:58,388 - INFO - val: {'epoch': 2, 'time_epoch': 11.44803, 'loss': 0.15016694, 'lr': 0, 'params': 9588956, 'time_iter': 0.13312, 'accuracy': 0.9161, 'auc': 0.61851, 'ap': 0.0501}
2025-06-20 15:22:58,391 - INFO - ...computing epoch stats took: 1.41s
2025-06-20 15:23:12,164 - INFO - test: {'epoch': 2, 'time_epoch': 12.37763, 'loss': 0.15273892, 'lr': 0, 'params': 9588956, 'time_iter': 0.14393, 'accuracy': 0.91647, 'auc': 0.6122, 'ap': 0.05316}
2025-06-20 15:23:12,166 - INFO - ...computing epoch stats took: 1.40s
2025-06-20 15:23:12,167 - INFO - > Epoch 2: took 241.3s (avg 268.2s) | Best so far: epoch 2	train_loss: 0.0999 train_ap: 0.0327	val_loss: 0.1502 val_ap: 0.0501	test_loss: 0.1527 test_ap: 0.0532
2025-06-20 15:26:43,016 - INFO - train: {'epoch': 3, 'time_epoch': 201.07391, 'eta': 21003.13307, 'eta_hours': 5.8342, 'loss': 0.05325356, 'lr': 0.0003, 'params': 9588956, 'time_iter': 0.29354, 'accuracy': 0.97972, 'auc': 0.65322, 'ap': 0.04315}
2025-06-20 15:26:55,772 - INFO - val: {'epoch': 3, 'time_epoch': 11.36767, 'loss': 0.07053707, 'lr': 0, 'params': 9588956, 'time_iter': 0.13218, 'accuracy': 0.96806, 'auc': 0.6847, 'ap': 0.05047}
2025-06-20 15:27:09,471 - INFO - test: {'epoch': 3, 'time_epoch': 12.35252, 'loss': 0.07282029, 'lr': 0, 'params': 9588956, 'time_iter': 0.14363, 'accuracy': 0.96684, 'auc': 0.67989, 'ap': 0.05102}
2025-06-20 15:27:09,474 - INFO - > Epoch 3: took 237.3s (avg 260.5s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 15:30:43,467 - INFO - train: {'epoch': 4, 'time_epoch': 203.92226, 'eta': 20502.0033, 'eta_hours': 5.695, 'loss': 0.05341491, 'lr': 0.0004, 'params': 9588956, 'time_iter': 0.2977, 'accuracy': 0.97959, 'auc': 0.64981, 'ap': 0.03811}
2025-06-20 15:30:56,397 - INFO - val: {'epoch': 4, 'time_epoch': 11.45722, 'loss': 0.06425278, 'lr': 0, 'params': 9588956, 'time_iter': 0.13322, 'accuracy': 0.97603, 'auc': 0.6617, 'ap': 0.04453}
2025-06-20 15:31:10,208 - INFO - test: {'epoch': 4, 'time_epoch': 12.38317, 'loss': 0.06660504, 'lr': 0, 'params': 9588956, 'time_iter': 0.14399, 'accuracy': 0.97481, 'auc': 0.65911, 'ap': 0.04502}
2025-06-20 15:31:10,210 - INFO - > Epoch 4: took 240.7s (avg 256.5s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 15:34:45,621 - INFO - train: {'epoch': 5, 'time_epoch': 205.67335, 'eta': 20127.37643, 'eta_hours': 5.59094, 'loss': 0.05530377, 'lr': 0.0005, 'params': 9588956, 'time_iter': 0.30025, 'accuracy': 0.97937, 'auc': 0.542, 'ap': 0.02464}
2025-06-20 15:34:58,313 - INFO - val: {'epoch': 5, 'time_epoch': 11.39313, 'loss': 0.06599144, 'lr': 0, 'params': 9588956, 'time_iter': 0.13248, 'accuracy': 0.97603, 'auc': 0.48374, 'ap': 0.02523}
2025-06-20 15:35:11,878 - INFO - test: {'epoch': 5, 'time_epoch': 12.30359, 'loss': 0.06838785, 'lr': 0, 'params': 9588956, 'time_iter': 0.14307, 'accuracy': 0.97482, 'auc': 0.4891, 'ap': 0.02768}
2025-06-20 15:35:11,881 - INFO - > Epoch 5: took 241.7s (avg 254.0s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 15:38:44,955 - INFO - train: {'epoch': 6, 'time_epoch': 203.0867, 'eta': 19766.65649, 'eta_hours': 5.49074, 'loss': 0.05535847, 'lr': 0.00049986, 'params': 9588956, 'time_iter': 0.29648, 'accuracy': 0.97937, 'auc': 0.51677, 'ap': 0.02374}
2025-06-20 15:38:57,795 - INFO - val: {'epoch': 6, 'time_epoch': 11.42827, 'loss': 0.0663428, 'lr': 0, 'params': 9588956, 'time_iter': 0.13289, 'accuracy': 0.97603, 'auc': 0.51231, 'ap': 0.0258}
2025-06-20 15:39:11,557 - INFO - test: {'epoch': 6, 'time_epoch': 12.44786, 'loss': 0.06877567, 'lr': 0, 'params': 9588956, 'time_iter': 0.14474, 'accuracy': 0.97482, 'auc': 0.51012, 'ap': 0.02788}
2025-06-20 15:39:11,560 - INFO - > Epoch 6: took 239.7s (avg 252.0s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 15:42:48,522 - INFO - train: {'epoch': 7, 'time_epoch': 206.73583, 'eta': 19487.30989, 'eta_hours': 5.41314, 'loss': 0.05537246, 'lr': 0.00049945, 'params': 9588956, 'time_iter': 0.3018, 'accuracy': 0.97936, 'auc': 0.51863, 'ap': 0.02317}
2025-06-20 15:43:01,355 - INFO - val: {'epoch': 7, 'time_epoch': 11.5027, 'loss': 0.06611386, 'lr': 0, 'params': 9588956, 'time_iter': 0.13375, 'accuracy': 0.97603, 'auc': 0.50571, 'ap': 0.02352}
2025-06-20 15:43:14,960 - INFO - test: {'epoch': 7, 'time_epoch': 12.27789, 'loss': 0.06857534, 'lr': 0, 'params': 9588956, 'time_iter': 0.14277, 'accuracy': 0.97482, 'auc': 0.51077, 'ap': 0.02537}
2025-06-20 15:43:14,963 - INFO - > Epoch 7: took 243.4s (avg 250.9s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 15:46:47,326 - INFO - train: {'epoch': 8, 'time_epoch': 202.57921, 'eta': 19182.07094, 'eta_hours': 5.32835, 'loss': 0.05535941, 'lr': 0.00049877, 'params': 9588956, 'time_iter': 0.29574, 'accuracy': 0.97943, 'auc': 0.51454, 'ap': 0.02299}
2025-06-20 15:46:59,925 - INFO - val: {'epoch': 8, 'time_epoch': 11.37229, 'loss': 0.06616062, 'lr': 0, 'params': 9588956, 'time_iter': 0.13224, 'accuracy': 0.97603, 'auc': 0.48815, 'ap': 0.02499}
2025-06-20 15:47:13,430 - INFO - test: {'epoch': 8, 'time_epoch': 12.25077, 'loss': 0.06859504, 'lr': 0, 'params': 9588956, 'time_iter': 0.14245, 'accuracy': 0.97482, 'auc': 0.48211, 'ap': 0.02711}
2025-06-20 15:47:13,433 - INFO - > Epoch 8: took 238.5s (avg 249.5s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 15:50:50,098 - INFO - train: {'epoch': 9, 'time_epoch': 206.74975, 'eta': 18934.89884, 'eta_hours': 5.25969, 'loss': 0.05541788, 'lr': 0.00049782, 'params': 9588956, 'time_iter': 0.30182, 'accuracy': 0.97936, 'auc': 0.51025, 'ap': 0.0225}
2025-06-20 15:51:02,860 - INFO - val: {'epoch': 9, 'time_epoch': 11.48013, 'loss': 0.06615415, 'lr': 0, 'params': 9588956, 'time_iter': 0.13349, 'accuracy': 0.97603, 'auc': 0.48342, 'ap': 0.02412}
2025-06-20 15:51:16,356 - INFO - test: {'epoch': 9, 'time_epoch': 12.26926, 'loss': 0.06857992, 'lr': 0, 'params': 9588956, 'time_iter': 0.14267, 'accuracy': 0.97482, 'auc': 0.48316, 'ap': 0.02537}
2025-06-20 15:51:16,359 - INFO - > Epoch 9: took 242.9s (avg 248.9s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 15:54:52,455 - INFO - train: {'epoch': 10, 'time_epoch': 206.18102, 'eta': 18690.4747, 'eta_hours': 5.1918, 'loss': 0.05538637, 'lr': 0.00049659, 'params': 9588956, 'time_iter': 0.30099, 'accuracy': 0.97943, 'auc': 0.51366, 'ap': 0.02306}
2025-06-20 15:55:05,114 - INFO - val: {'epoch': 10, 'time_epoch': 11.3572, 'loss': 0.06606313, 'lr': 0, 'params': 9588956, 'time_iter': 0.13206, 'accuracy': 0.97603, 'auc': 0.48148, 'ap': 0.02233}
2025-06-20 15:55:18,648 - INFO - test: {'epoch': 10, 'time_epoch': 12.25464, 'loss': 0.0684481, 'lr': 0, 'params': 9588956, 'time_iter': 0.1425, 'accuracy': 0.97482, 'auc': 0.48918, 'ap': 0.02515}
2025-06-20 15:55:18,651 - INFO - > Epoch 10: took 242.3s (avg 248.3s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 15:58:51,435 - INFO - train: {'epoch': 11, 'time_epoch': 202.77131, 'eta': 18427.41989, 'eta_hours': 5.11873, 'loss': 0.05532915, 'lr': 0.00049509, 'params': 9588956, 'time_iter': 0.29602, 'accuracy': 0.97936, 'auc': 0.52711, 'ap': 0.02413}
2025-06-20 15:59:04,204 - INFO - val: {'epoch': 11, 'time_epoch': 11.42553, 'loss': 0.06591145, 'lr': 0, 'params': 9588956, 'time_iter': 0.13286, 'accuracy': 0.97603, 'auc': 0.49215, 'ap': 0.02639}
2025-06-20 15:59:17,830 - INFO - test: {'epoch': 11, 'time_epoch': 12.31434, 'loss': 0.06829551, 'lr': 0, 'params': 9588956, 'time_iter': 0.14319, 'accuracy': 0.97482, 'auc': 0.48564, 'ap': 0.02644}
2025-06-20 15:59:17,833 - INFO - > Epoch 11: took 239.2s (avg 247.5s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 16:02:55,341 - INFO - train: {'epoch': 12, 'time_epoch': 207.47637, 'eta': 18205.12716, 'eta_hours': 5.05698, 'loss': 0.05530061, 'lr': 0.00049333, 'params': 9588956, 'time_iter': 0.30289, 'accuracy': 0.97942, 'auc': 0.52281, 'ap': 0.02472}
2025-06-20 16:03:08,247 - INFO - val: {'epoch': 12, 'time_epoch': 11.43917, 'loss': 0.06591314, 'lr': 0, 'params': 9588956, 'time_iter': 0.13301, 'accuracy': 0.97603, 'auc': 0.48601, 'ap': 0.02646}
2025-06-20 16:03:21,995 - INFO - test: {'epoch': 12, 'time_epoch': 12.37183, 'loss': 0.06829482, 'lr': 0, 'params': 9588956, 'time_iter': 0.14386, 'accuracy': 0.97482, 'auc': 0.49001, 'ap': 0.02738}
2025-06-20 16:03:21,997 - INFO - > Epoch 12: took 244.2s (avg 247.3s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 16:06:54,704 - INFO - train: {'epoch': 13, 'time_epoch': 202.74689, 'eta': 17955.89849, 'eta_hours': 4.98775, 'loss': 0.0553339, 'lr': 0.0004913, 'params': 9588956, 'time_iter': 0.29598, 'accuracy': 0.97938, 'auc': 0.51964, 'ap': 0.02428}
2025-06-20 16:07:07,411 - INFO - val: {'epoch': 13, 'time_epoch': 11.45911, 'loss': 0.06698757, 'lr': 0, 'params': 9588956, 'time_iter': 0.13325, 'accuracy': 0.97414, 'auc': 0.49145, 'ap': 0.02399}
2025-06-20 16:07:25,105 - INFO - test: {'epoch': 13, 'time_epoch': 16.48299, 'loss': 0.06941992, 'lr': 0, 'params': 9588956, 'time_iter': 0.19166, 'accuracy': 0.97272, 'auc': 0.49615, 'ap': 0.02535}
2025-06-20 16:07:25,108 - INFO - > Epoch 13: took 243.1s (avg 247.0s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 16:10:58,069 - INFO - train: {'epoch': 14, 'time_epoch': 203.21665, 'eta': 17715.5294, 'eta_hours': 4.92098, 'loss': 0.05525316, 'lr': 0.00048901, 'params': 9588956, 'time_iter': 0.29667, 'accuracy': 0.97936, 'auc': 0.52299, 'ap': 0.0248}
2025-06-20 16:11:10,615 - INFO - val: {'epoch': 14, 'time_epoch': 11.40006, 'loss': 0.06831586, 'lr': 0, 'params': 9588956, 'time_iter': 0.13256, 'accuracy': 0.97414, 'auc': 0.48316, 'ap': 0.02371}
2025-06-20 16:11:24,099 - INFO - test: {'epoch': 14, 'time_epoch': 12.29079, 'loss': 0.07079025, 'lr': 0, 'params': 9588956, 'time_iter': 0.14292, 'accuracy': 0.97272, 'auc': 0.48268, 'ap': 0.02518}
2025-06-20 16:11:24,102 - INFO - > Epoch 14: took 239.0s (avg 246.4s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 16:15:00,778 - INFO - train: {'epoch': 15, 'time_epoch': 206.73438, 'eta': 17498.27245, 'eta_hours': 4.86063, 'loss': 0.05523501, 'lr': 0.00048645, 'params': 9588956, 'time_iter': 0.3018, 'accuracy': 0.97939, 'auc': 0.52941, 'ap': 0.02459}
2025-06-20 16:15:13,527 - INFO - val: {'epoch': 15, 'time_epoch': 11.49726, 'loss': 0.0668468, 'lr': 0, 'params': 9588956, 'time_iter': 0.13369, 'accuracy': 0.97414, 'auc': 0.53321, 'ap': 0.0261}
2025-06-20 16:15:27,088 - INFO - test: {'epoch': 15, 'time_epoch': 12.38651, 'loss': 0.06930468, 'lr': 0, 'params': 9588956, 'time_iter': 0.14403, 'accuracy': 0.97272, 'auc': 0.52693, 'ap': 0.02744}
2025-06-20 16:15:27,090 - INFO - > Epoch 15: took 243.0s (avg 246.2s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 16:18:58,702 - INFO - train: {'epoch': 16, 'time_epoch': 201.77462, 'eta': 17258.03815, 'eta_hours': 4.7939, 'loss': 0.05520099, 'lr': 0.00048364, 'params': 9588956, 'time_iter': 0.29456, 'accuracy': 0.9795, 'auc': 0.53286, 'ap': 0.02505}
2025-06-20 16:19:11,254 - INFO - val: {'epoch': 16, 'time_epoch': 11.33464, 'loss': 0.06662492, 'lr': 0, 'params': 9588956, 'time_iter': 0.1318, 'accuracy': 0.97603, 'auc': 0.50796, 'ap': 0.02444}
2025-06-20 16:19:24,618 - INFO - test: {'epoch': 16, 'time_epoch': 12.19073, 'loss': 0.06912489, 'lr': 0, 'params': 9588956, 'time_iter': 0.14175, 'accuracy': 0.97482, 'auc': 0.51371, 'ap': 0.02551}
2025-06-20 16:19:24,621 - INFO - > Epoch 16: took 237.5s (avg 245.7s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 16:23:00,242 - INFO - train: {'epoch': 17, 'time_epoch': 205.70653, 'eta': 17039.98919, 'eta_hours': 4.73333, 'loss': 0.05523435, 'lr': 0.00048057, 'params': 9588956, 'time_iter': 0.3003, 'accuracy': 0.97938, 'auc': 0.53033, 'ap': 0.0245}
2025-06-20 16:23:12,902 - INFO - val: {'epoch': 17, 'time_epoch': 11.39102, 'loss': 0.06633558, 'lr': 0, 'params': 9588956, 'time_iter': 0.13245, 'accuracy': 0.97603, 'auc': 0.49389, 'ap': 0.02656}
2025-06-20 16:23:26,360 - INFO - test: {'epoch': 17, 'time_epoch': 12.25559, 'loss': 0.06879205, 'lr': 0, 'params': 9588956, 'time_iter': 0.14251, 'accuracy': 0.97482, 'auc': 0.48735, 'ap': 0.02724}
2025-06-20 16:23:26,363 - INFO - > Epoch 17: took 241.7s (avg 245.5s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 16:26:56,917 - INFO - train: {'epoch': 18, 'time_epoch': 200.79213, 'eta': 16802.28855, 'eta_hours': 4.6673, 'loss': 0.0551945, 'lr': 0.00047725, 'params': 9588956, 'time_iter': 0.29313, 'accuracy': 0.97946, 'auc': 0.53236, 'ap': 0.02507}
2025-06-20 16:27:12,681 - INFO - val: {'epoch': 18, 'time_epoch': 14.51347, 'loss': 0.06601084, 'lr': 0, 'params': 9588956, 'time_iter': 0.16876, 'accuracy': 0.97603, 'auc': 0.49683, 'ap': 0.02656}
2025-06-20 16:27:26,235 - INFO - test: {'epoch': 18, 'time_epoch': 12.27281, 'loss': 0.06844923, 'lr': 0, 'params': 9588956, 'time_iter': 0.14271, 'accuracy': 0.97482, 'auc': 0.49963, 'ap': 0.02694}
2025-06-20 16:27:26,238 - INFO - > Epoch 18: took 239.9s (avg 245.2s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 16:30:55,583 - INFO - train: {'epoch': 19, 'time_epoch': 199.49776, 'eta': 16563.10128, 'eta_hours': 4.60086, 'loss': 0.05513445, 'lr': 0.00047368, 'params': 9588956, 'time_iter': 0.29124, 'accuracy': 0.97948, 'auc': 0.53937, 'ap': 0.0254}
2025-06-20 16:31:08,152 - INFO - val: {'epoch': 19, 'time_epoch': 11.2845, 'loss': 0.06583507, 'lr': 0, 'params': 9588956, 'time_iter': 0.13122, 'accuracy': 0.97603, 'auc': 0.50898, 'ap': 0.02344}
2025-06-20 16:31:21,570 - INFO - test: {'epoch': 19, 'time_epoch': 12.12996, 'loss': 0.06820993, 'lr': 0, 'params': 9588956, 'time_iter': 0.14105, 'accuracy': 0.97482, 'auc': 0.51455, 'ap': 0.02577}
2025-06-20 16:31:21,573 - INFO - > Epoch 19: took 235.3s (avg 244.7s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 16:34:55,258 - INFO - train: {'epoch': 20, 'time_epoch': 203.87463, 'eta': 16344.15934, 'eta_hours': 4.54004, 'loss': 0.05510805, 'lr': 0.00046987, 'params': 9588956, 'time_iter': 0.29763, 'accuracy': 0.97949, 'auc': 0.54097, 'ap': 0.02571}
2025-06-20 16:35:07,604 - INFO - val: {'epoch': 20, 'time_epoch': 11.17935, 'loss': 0.06793539, 'lr': 0, 'params': 9588956, 'time_iter': 0.12999, 'accuracy': 0.97414, 'auc': 0.49936, 'ap': 0.02308}
2025-06-20 16:35:20,769 - INFO - test: {'epoch': 20, 'time_epoch': 12.02544, 'loss': 0.07034514, 'lr': 0, 'params': 9588956, 'time_iter': 0.13983, 'accuracy': 0.97272, 'auc': 0.50305, 'ap': 0.02434}
2025-06-20 16:35:20,772 - INFO - > Epoch 20: took 239.2s (avg 244.4s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 16:38:48,133 - INFO - train: {'epoch': 21, 'time_epoch': 198.21669, 'eta': 16106.52717, 'eta_hours': 4.47404, 'loss': 0.05511107, 'lr': 0.00046581, 'params': 9588956, 'time_iter': 0.28937, 'accuracy': 0.97951, 'auc': 0.53971, 'ap': 0.02576}
2025-06-20 16:39:00,359 - INFO - val: {'epoch': 21, 'time_epoch': 11.13205, 'loss': 0.07018563, 'lr': 0, 'params': 9588956, 'time_iter': 0.12944, 'accuracy': 0.96874, 'auc': 0.49081, 'ap': 0.02386}
2025-06-20 16:39:13,462 - INFO - test: {'epoch': 21, 'time_epoch': 12.04235, 'loss': 0.07275817, 'lr': 0, 'params': 9588956, 'time_iter': 0.14003, 'accuracy': 0.96768, 'auc': 0.4927, 'ap': 0.02482}
2025-06-20 16:39:13,464 - INFO - > Epoch 21: took 232.7s (avg 243.9s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 16:42:44,892 - INFO - train: {'epoch': 22, 'time_epoch': 202.17697, 'eta': 15885.58078, 'eta_hours': 4.41266, 'loss': 0.05507688, 'lr': 0.00046152, 'params': 9588956, 'time_iter': 0.29515, 'accuracy': 0.97942, 'auc': 0.54742, 'ap': 0.02617}
2025-06-20 16:42:57,131 - INFO - val: {'epoch': 22, 'time_epoch': 11.12874, 'loss': 0.07537448, 'lr': 0, 'params': 9588956, 'time_iter': 0.1294, 'accuracy': 0.95487, 'auc': 0.49616, 'ap': 0.02516}
2025-06-20 16:43:10,250 - INFO - test: {'epoch': 22, 'time_epoch': 12.03739, 'loss': 0.07793697, 'lr': 0, 'params': 9588956, 'time_iter': 0.13997, 'accuracy': 0.95429, 'auc': 0.48864, 'ap': 0.02646}
2025-06-20 16:43:10,252 - INFO - > Epoch 22: took 236.8s (avg 243.6s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 16:46:38,932 - INFO - train: {'epoch': 23, 'time_epoch': 199.51022, 'eta': 15657.75379, 'eta_hours': 4.34938, 'loss': 0.05505578, 'lr': 0.000457, 'params': 9588956, 'time_iter': 0.29126, 'accuracy': 0.97952, 'auc': 0.54523, 'ap': 0.02615}
2025-06-20 16:46:54,141 - INFO - val: {'epoch': 23, 'time_epoch': 14.12183, 'loss': 0.07621697, 'lr': 0, 'params': 9588956, 'time_iter': 0.16421, 'accuracy': 0.95487, 'auc': 0.50709, 'ap': 0.02476}
2025-06-20 16:47:07,286 - INFO - test: {'epoch': 23, 'time_epoch': 12.04668, 'loss': 0.07892706, 'lr': 0, 'params': 9588956, 'time_iter': 0.14008, 'accuracy': 0.95429, 'auc': 0.50257, 'ap': 0.0259}
2025-06-20 16:47:07,289 - INFO - > Epoch 23: took 237.0s (avg 243.3s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 16:50:35,968 - INFO - train: {'epoch': 24, 'time_epoch': 199.41797, 'eta': 15431.9154, 'eta_hours': 4.28664, 'loss': 0.05494633, 'lr': 0.00045225, 'params': 9588956, 'time_iter': 0.29112, 'accuracy': 0.97953, 'auc': 0.55634, 'ap': 0.02673}
2025-06-20 16:50:48,282 - INFO - val: {'epoch': 24, 'time_epoch': 11.13661, 'loss': 0.07532051, 'lr': 0, 'params': 9588956, 'time_iter': 0.1295, 'accuracy': 0.96442, 'auc': 0.53356, 'ap': 0.02772}
2025-06-20 16:51:01,517 - INFO - test: {'epoch': 24, 'time_epoch': 12.05831, 'loss': 0.07790949, 'lr': 0, 'params': 9588956, 'time_iter': 0.14021, 'accuracy': 0.96344, 'auc': 0.52625, 'ap': 0.02939}
2025-06-20 16:51:01,519 - INFO - > Epoch 24: took 234.2s (avg 243.0s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 16:54:32,250 - INFO - train: {'epoch': 25, 'time_epoch': 201.29393, 'eta': 15213.44861, 'eta_hours': 4.22596, 'loss': 0.05495305, 'lr': 0.00044729, 'params': 9588956, 'time_iter': 0.29386, 'accuracy': 0.97953, 'auc': 0.55311, 'ap': 0.02722}
2025-06-20 16:54:44,603 - INFO - val: {'epoch': 25, 'time_epoch': 11.20401, 'loss': 0.07786411, 'lr': 0, 'params': 9588956, 'time_iter': 0.13028, 'accuracy': 0.95487, 'auc': 0.52445, 'ap': 0.02699}
2025-06-20 16:54:57,753 - INFO - test: {'epoch': 25, 'time_epoch': 12.05103, 'loss': 0.08059325, 'lr': 0, 'params': 9588956, 'time_iter': 0.14013, 'accuracy': 0.95429, 'auc': 0.52127, 'ap': 0.02824}
2025-06-20 16:54:57,756 - INFO - > Epoch 25: took 236.2s (avg 242.7s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 16:58:25,588 - INFO - train: {'epoch': 26, 'time_epoch': 198.86567, 'eta': 14989.6886, 'eta_hours': 4.1638, 'loss': 0.05498772, 'lr': 0.0004421, 'params': 9588956, 'time_iter': 0.29031, 'accuracy': 0.9795, 'auc': 0.55169, 'ap': 0.02663}
2025-06-20 16:58:37,828 - INFO - val: {'epoch': 26, 'time_epoch': 11.09215, 'loss': 0.07495525, 'lr': 0, 'params': 9588956, 'time_iter': 0.12898, 'accuracy': 0.96003, 'auc': 0.48145, 'ap': 0.02357}
2025-06-20 16:58:50,967 - INFO - test: {'epoch': 26, 'time_epoch': 12.01677, 'loss': 0.07758887, 'lr': 0, 'params': 9588956, 'time_iter': 0.13973, 'accuracy': 0.95938, 'auc': 0.48375, 'ap': 0.02471}
2025-06-20 16:58:50,970 - INFO - > Epoch 26: took 233.2s (avg 242.3s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 17:02:21,739 - INFO - train: {'epoch': 27, 'time_epoch': 201.69133, 'eta': 14774.97273, 'eta_hours': 4.10416, 'loss': 0.05495655, 'lr': 0.00043671, 'params': 9588956, 'time_iter': 0.29444, 'accuracy': 0.97956, 'auc': 0.55359, 'ap': 0.02688}
2025-06-20 17:02:34,247 - INFO - val: {'epoch': 27, 'time_epoch': 11.2625, 'loss': 0.0717562, 'lr': 0, 'params': 9588956, 'time_iter': 0.13096, 'accuracy': 0.96982, 'auc': 0.50778, 'ap': 0.02617}
2025-06-20 17:02:47,559 - INFO - test: {'epoch': 27, 'time_epoch': 12.1332, 'loss': 0.07430277, 'lr': 0, 'params': 9588956, 'time_iter': 0.14108, 'accuracy': 0.96848, 'auc': 0.50976, 'ap': 0.02743}
2025-06-20 17:02:47,561 - INFO - > Epoch 27: took 236.6s (avg 242.1s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 17:06:15,330 - INFO - train: {'epoch': 28, 'time_epoch': 198.77283, 'eta': 14554.00981, 'eta_hours': 4.04278, 'loss': 0.05491812, 'lr': 0.00043111, 'params': 9588956, 'time_iter': 0.29018, 'accuracy': 0.97961, 'auc': 0.55754, 'ap': 0.02763}
2025-06-20 17:06:27,580 - INFO - val: {'epoch': 28, 'time_epoch': 11.09237, 'loss': 0.07563441, 'lr': 0, 'params': 9588956, 'time_iter': 0.12898, 'accuracy': 0.96003, 'auc': 0.46771, 'ap': 0.02236}
2025-06-20 17:06:40,702 - INFO - test: {'epoch': 28, 'time_epoch': 11.99676, 'loss': 0.07820289, 'lr': 0, 'params': 9588956, 'time_iter': 0.1395, 'accuracy': 0.95938, 'auc': 0.47073, 'ap': 0.02375}
2025-06-20 17:06:40,705 - INFO - > Epoch 28: took 233.1s (avg 241.8s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 17:10:05,146 - INFO - train: {'epoch': 29, 'time_epoch': 195.78759, 'eta': 14327.56068, 'eta_hours': 3.97988, 'loss': 0.05491133, 'lr': 0.00042531, 'params': 9588956, 'time_iter': 0.28582, 'accuracy': 0.97956, 'auc': 0.55505, 'ap': 0.02707}
2025-06-20 17:10:17,267 - INFO - val: {'epoch': 29, 'time_epoch': 10.9835, 'loss': 0.07562569, 'lr': 0, 'params': 9588956, 'time_iter': 0.12772, 'accuracy': 0.96442, 'auc': 0.46339, 'ap': 0.0236}
2025-06-20 17:10:30,242 - INFO - test: {'epoch': 29, 'time_epoch': 11.85382, 'loss': 0.07822643, 'lr': 0, 'params': 9588956, 'time_iter': 0.13784, 'accuracy': 0.96344, 'auc': 0.48316, 'ap': 0.02475}
2025-06-20 17:10:30,244 - INFO - > Epoch 29: took 229.5s (avg 241.4s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 17:13:57,989 - INFO - train: {'epoch': 30, 'time_epoch': 198.90249, 'eta': 14110.02288, 'eta_hours': 3.91945, 'loss': 0.05488964, 'lr': 0.00041932, 'params': 9588956, 'time_iter': 0.29037, 'accuracy': 0.97954, 'auc': 0.55607, 'ap': 0.02723}
2025-06-20 17:14:10,203 - INFO - val: {'epoch': 30, 'time_epoch': 11.07899, 'loss': 0.07736509, 'lr': 0, 'params': 9588956, 'time_iter': 0.12883, 'accuracy': 0.95487, 'auc': 0.48354, 'ap': 0.02407}
2025-06-20 17:14:23,285 - INFO - test: {'epoch': 30, 'time_epoch': 11.97119, 'loss': 0.07995154, 'lr': 0, 'params': 9588956, 'time_iter': 0.1392, 'accuracy': 0.95429, 'auc': 0.49127, 'ap': 0.02537}
2025-06-20 17:14:23,288 - INFO - > Epoch 30: took 233.0s (avg 241.1s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 17:17:50,203 - INFO - train: {'epoch': 31, 'time_epoch': 198.07446, 'eta': 13891.89021, 'eta_hours': 3.85886, 'loss': 0.05489627, 'lr': 0.00041315, 'params': 9588956, 'time_iter': 0.28916, 'accuracy': 0.97956, 'auc': 0.55622, 'ap': 0.02734}
2025-06-20 17:18:02,429 - INFO - val: {'epoch': 31, 'time_epoch': 11.07295, 'loss': 0.07099384, 'lr': 0, 'params': 9588956, 'time_iter': 0.12876, 'accuracy': 0.97414, 'auc': 0.48143, 'ap': 0.02346}
2025-06-20 17:18:15,518 - INFO - test: {'epoch': 31, 'time_epoch': 11.97481, 'loss': 0.0734746, 'lr': 0, 'params': 9588956, 'time_iter': 0.13924, 'accuracy': 0.97272, 'auc': 0.49308, 'ap': 0.02441}
2025-06-20 17:18:15,520 - INFO - > Epoch 31: took 232.2s (avg 240.9s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 17:21:44,021 - INFO - train: {'epoch': 32, 'time_epoch': 199.52736, 'eta': 13677.92303, 'eta_hours': 3.79942, 'loss': 0.05490964, 'lr': 0.00040679, 'params': 9588956, 'time_iter': 0.29128, 'accuracy': 0.97946, 'auc': 0.55636, 'ap': 0.02681}
2025-06-20 17:21:56,126 - INFO - val: {'epoch': 32, 'time_epoch': 11.02752, 'loss': 0.07527888, 'lr': 0, 'params': 9588956, 'time_iter': 0.12823, 'accuracy': 0.96003, 'auc': 0.4786, 'ap': 0.02402}
2025-06-20 17:22:09,131 - INFO - test: {'epoch': 32, 'time_epoch': 11.94511, 'loss': 0.0778441, 'lr': 0, 'params': 9588956, 'time_iter': 0.1389, 'accuracy': 0.95938, 'auc': 0.48631, 'ap': 0.02453}
2025-06-20 17:22:09,133 - INFO - > Epoch 32: took 233.6s (avg 240.7s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 17:25:37,680 - INFO - train: {'epoch': 33, 'time_epoch': 199.72234, 'eta': 13465.18373, 'eta_hours': 3.74033, 'loss': 0.0548962, 'lr': 0.00040027, 'params': 9588956, 'time_iter': 0.29157, 'accuracy': 0.97944, 'auc': 0.56235, 'ap': 0.02726}
2025-06-20 17:25:49,835 - INFO - val: {'epoch': 33, 'time_epoch': 11.03039, 'loss': 0.07344796, 'lr': 0, 'params': 9588956, 'time_iter': 0.12826, 'accuracy': 0.96003, 'auc': 0.48801, 'ap': 0.02375}
2025-06-20 17:26:02,894 - INFO - test: {'epoch': 33, 'time_epoch': 11.9468, 'loss': 0.0759703, 'lr': 0, 'params': 9588956, 'time_iter': 0.13892, 'accuracy': 0.95938, 'auc': 0.49722, 'ap': 0.02506}
2025-06-20 17:26:02,896 - INFO - > Epoch 33: took 233.8s (avg 240.4s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 17:29:28,823 - INFO - train: {'epoch': 34, 'time_epoch': 196.62332, 'eta': 13247.43293, 'eta_hours': 3.67984, 'loss': 0.05486023, 'lr': 0.00039358, 'params': 9588956, 'time_iter': 0.28704, 'accuracy': 0.97948, 'auc': 0.56306, 'ap': 0.0269}
2025-06-20 17:29:41,269 - INFO - val: {'epoch': 34, 'time_epoch': 11.17931, 'loss': 0.07785419, 'lr': 0, 'params': 9588956, 'time_iter': 0.12999, 'accuracy': 0.95487, 'auc': 0.54526, 'ap': 0.02735}
2025-06-20 17:29:54,573 - INFO - test: {'epoch': 34, 'time_epoch': 12.07073, 'loss': 0.08045875, 'lr': 0, 'params': 9588956, 'time_iter': 0.14036, 'accuracy': 0.95429, 'auc': 0.54049, 'ap': 0.02956}
2025-06-20 17:29:54,576 - INFO - > Epoch 34: took 231.7s (avg 240.2s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 17:33:24,260 - INFO - train: {'epoch': 35, 'time_epoch': 200.30052, 'eta': 13037.39313, 'eta_hours': 3.6215, 'loss': 0.05489098, 'lr': 0.00038674, 'params': 9588956, 'time_iter': 0.29241, 'accuracy': 0.97948, 'auc': 0.5549, 'ap': 0.02709}
2025-06-20 17:33:36,734 - INFO - val: {'epoch': 35, 'time_epoch': 11.18781, 'loss': 0.07489503, 'lr': 0, 'params': 9588956, 'time_iter': 0.13009, 'accuracy': 0.95487, 'auc': 0.51372, 'ap': 0.02541}
2025-06-20 17:33:50,101 - INFO - test: {'epoch': 35, 'time_epoch': 12.12876, 'loss': 0.07742165, 'lr': 0, 'params': 9588956, 'time_iter': 0.14103, 'accuracy': 0.95429, 'auc': 0.51799, 'ap': 0.02779}
2025-06-20 17:33:50,105 - INFO - > Epoch 35: took 235.5s (avg 240.1s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 17:37:16,916 - INFO - train: {'epoch': 36, 'time_epoch': 197.5174, 'eta': 12823.14095, 'eta_hours': 3.56198, 'loss': 0.05488247, 'lr': 0.00037974, 'params': 9588956, 'time_iter': 0.28835, 'accuracy': 0.97948, 'auc': 0.55812, 'ap': 0.02682}
2025-06-20 17:37:29,353 - INFO - val: {'epoch': 36, 'time_epoch': 11.18669, 'loss': 0.07132422, 'lr': 0, 'params': 9588956, 'time_iter': 0.13008, 'accuracy': 0.96863, 'auc': 0.46074, 'ap': 0.02312}
2025-06-20 17:37:45,373 - INFO - test: {'epoch': 36, 'time_epoch': 14.81511, 'loss': 0.07380777, 'lr': 0, 'params': 9588956, 'time_iter': 0.17227, 'accuracy': 0.96754, 'auc': 0.47142, 'ap': 0.02457}
2025-06-20 17:37:45,376 - INFO - > Epoch 36: took 235.3s (avg 239.9s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 17:41:12,649 - INFO - train: {'epoch': 37, 'time_epoch': 198.01003, 'eta': 12610.57332, 'eta_hours': 3.50294, 'loss': 0.0548263, 'lr': 0.00037261, 'params': 9588956, 'time_iter': 0.28907, 'accuracy': 0.97949, 'auc': 0.56427, 'ap': 0.02717}
2025-06-20 17:41:24,954 - INFO - val: {'epoch': 37, 'time_epoch': 11.15435, 'loss': 0.07091843, 'lr': 0, 'params': 9588956, 'time_iter': 0.1297, 'accuracy': 0.97414, 'auc': 0.48126, 'ap': 0.02367}
2025-06-20 17:41:38,102 - INFO - test: {'epoch': 37, 'time_epoch': 12.02149, 'loss': 0.07333527, 'lr': 0, 'params': 9588956, 'time_iter': 0.13978, 'accuracy': 0.97272, 'auc': 0.48966, 'ap': 0.02484}
2025-06-20 17:41:38,104 - INFO - > Epoch 37: took 232.7s (avg 239.7s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 17:45:07,428 - INFO - train: {'epoch': 38, 'time_epoch': 200.0386, 'eta': 12401.92512, 'eta_hours': 3.44498, 'loss': 0.05480242, 'lr': 0.00036534, 'params': 9588956, 'time_iter': 0.29203, 'accuracy': 0.97946, 'auc': 0.57223, 'ap': 0.02766}
2025-06-20 17:45:19,717 - INFO - val: {'epoch': 38, 'time_epoch': 11.15189, 'loss': 0.07505923, 'lr': 0, 'params': 9588956, 'time_iter': 0.12967, 'accuracy': 0.95487, 'auc': 0.48855, 'ap': 0.02487}
2025-06-20 17:45:32,899 - INFO - test: {'epoch': 38, 'time_epoch': 12.05397, 'loss': 0.07750021, 'lr': 0, 'params': 9588956, 'time_iter': 0.14016, 'accuracy': 0.95429, 'auc': 0.48426, 'ap': 0.02643}
2025-06-20 17:45:32,902 - INFO - > Epoch 38: took 234.8s (avg 239.6s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 17:48:59,840 - INFO - train: {'epoch': 39, 'time_epoch': 197.64429, 'eta': 12190.11594, 'eta_hours': 3.38614, 'loss': 0.05483686, 'lr': 0.00035794, 'params': 9588956, 'time_iter': 0.28853, 'accuracy': 0.97953, 'auc': 0.56781, 'ap': 0.02734}
2025-06-20 17:49:12,088 - INFO - val: {'epoch': 39, 'time_epoch': 11.13869, 'loss': 0.07535334, 'lr': 0, 'params': 9588956, 'time_iter': 0.12952, 'accuracy': 0.95487, 'auc': 0.50099, 'ap': 0.0249}
2025-06-20 17:49:25,236 - INFO - test: {'epoch': 39, 'time_epoch': 12.069, 'loss': 0.07784523, 'lr': 0, 'params': 9588956, 'time_iter': 0.14034, 'accuracy': 0.95429, 'auc': 0.49721, 'ap': 0.02599}
2025-06-20 17:49:25,239 - INFO - > Epoch 39: took 232.3s (avg 239.4s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 17:52:54,629 - INFO - train: {'epoch': 40, 'time_epoch': 200.12178, 'eta': 11982.5629, 'eta_hours': 3.32849, 'loss': 0.05487677, 'lr': 0.00035042, 'params': 9588956, 'time_iter': 0.29215, 'accuracy': 0.97956, 'auc': 0.56165, 'ap': 0.0272}
2025-06-20 17:53:06,870 - INFO - val: {'epoch': 40, 'time_epoch': 11.13071, 'loss': 0.0780201, 'lr': 0, 'params': 9588956, 'time_iter': 0.12943, 'accuracy': 0.95487, 'auc': 0.50939, 'ap': 0.02682}
2025-06-20 17:53:20,038 - INFO - test: {'epoch': 40, 'time_epoch': 12.04441, 'loss': 0.0806354, 'lr': 0, 'params': 9588956, 'time_iter': 0.14005, 'accuracy': 0.95429, 'auc': 0.50267, 'ap': 0.02807}
2025-06-20 17:53:20,040 - INFO - > Epoch 40: took 234.8s (avg 239.3s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 17:56:47,943 - INFO - train: {'epoch': 41, 'time_epoch': 197.91383, 'eta': 11772.31465, 'eta_hours': 3.27009, 'loss': 0.05491096, 'lr': 0.0003428, 'params': 9588956, 'time_iter': 0.28893, 'accuracy': 0.97954, 'auc': 0.56057, 'ap': 0.02718}
2025-06-20 17:57:02,985 - INFO - val: {'epoch': 41, 'time_epoch': 13.91067, 'loss': 0.0769621, 'lr': 0, 'params': 9588956, 'time_iter': 0.16175, 'accuracy': 0.95487, 'auc': 0.4901, 'ap': 0.02348}
2025-06-20 17:57:16,136 - INFO - test: {'epoch': 41, 'time_epoch': 12.04063, 'loss': 0.07955044, 'lr': 0, 'params': 9588956, 'time_iter': 0.14001, 'accuracy': 0.95429, 'auc': 0.48054, 'ap': 0.02463}
2025-06-20 17:57:16,139 - INFO - > Epoch 41: took 236.1s (avg 239.2s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:00:44,069 - INFO - train: {'epoch': 42, 'time_epoch': 198.93408, 'eta': 11563.99251, 'eta_hours': 3.21222, 'loss': 0.05490525, 'lr': 0.00033507, 'params': 9588956, 'time_iter': 0.29041, 'accuracy': 0.97954, 'auc': 0.55484, 'ap': 0.02731}
2025-06-20 18:00:56,348 - INFO - val: {'epoch': 42, 'time_epoch': 11.17057, 'loss': 0.08067071, 'lr': 0, 'params': 9588956, 'time_iter': 0.12989, 'accuracy': 0.95487, 'auc': 0.51873, 'ap': 0.02428}
2025-06-20 18:01:09,440 - INFO - test: {'epoch': 42, 'time_epoch': 12.00505, 'loss': 0.08344385, 'lr': 0, 'params': 9588956, 'time_iter': 0.13959, 'accuracy': 0.95429, 'auc': 0.51451, 'ap': 0.02532}
2025-06-20 18:01:09,442 - INFO - > Epoch 42: took 233.3s (avg 239.1s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:04:37,964 - INFO - train: {'epoch': 43, 'time_epoch': 199.32894, 'eta': 11356.59966, 'eta_hours': 3.15461, 'loss': 0.05491311, 'lr': 0.00032725, 'params': 9588956, 'time_iter': 0.29099, 'accuracy': 0.97955, 'auc': 0.55565, 'ap': 0.02714}
2025-06-20 18:04:50,263 - INFO - val: {'epoch': 43, 'time_epoch': 11.14073, 'loss': 0.07774829, 'lr': 0, 'params': 9588956, 'time_iter': 0.12954, 'accuracy': 0.95487, 'auc': 0.48161, 'ap': 0.02366}
2025-06-20 18:05:03,446 - INFO - test: {'epoch': 43, 'time_epoch': 12.06049, 'loss': 0.08044918, 'lr': 0, 'params': 9588956, 'time_iter': 0.14024, 'accuracy': 0.95429, 'auc': 0.47777, 'ap': 0.02512}
2025-06-20 18:05:03,448 - INFO - > Epoch 43: took 234.0s (avg 239.0s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:08:30,424 - INFO - train: {'epoch': 44, 'time_epoch': 197.78246, 'eta': 11147.67506, 'eta_hours': 3.09658, 'loss': 0.05489782, 'lr': 0.00031935, 'params': 9588956, 'time_iter': 0.28873, 'accuracy': 0.97954, 'auc': 0.55352, 'ap': 0.02714}
2025-06-20 18:08:42,763 - INFO - val: {'epoch': 44, 'time_epoch': 11.14569, 'loss': 0.08084476, 'lr': 0, 'params': 9588956, 'time_iter': 0.1296, 'accuracy': 0.95487, 'auc': 0.49486, 'ap': 0.02608}
2025-06-20 18:08:55,989 - INFO - test: {'epoch': 44, 'time_epoch': 12.07306, 'loss': 0.08352323, 'lr': 0, 'params': 9588956, 'time_iter': 0.14038, 'accuracy': 0.95429, 'auc': 0.50815, 'ap': 0.02762}
2025-06-20 18:08:55,992 - INFO - > Epoch 44: took 232.5s (avg 238.9s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:12:25,832 - INFO - train: {'epoch': 45, 'time_epoch': 200.62859, 'eta': 10942.57601, 'eta_hours': 3.0396, 'loss': 0.05487341, 'lr': 0.00031137, 'params': 9588956, 'time_iter': 0.29289, 'accuracy': 0.97954, 'auc': 0.55737, 'ap': 0.02774}
2025-06-20 18:12:38,122 - INFO - val: {'epoch': 45, 'time_epoch': 11.1266, 'loss': 0.08153291, 'lr': 0, 'params': 9588956, 'time_iter': 0.12938, 'accuracy': 0.95487, 'auc': 0.48605, 'ap': 0.02334}
2025-06-20 18:12:51,303 - INFO - test: {'epoch': 45, 'time_epoch': 12.03955, 'loss': 0.08423235, 'lr': 0, 'params': 9588956, 'time_iter': 0.13999, 'accuracy': 0.95429, 'auc': 0.48788, 'ap': 0.02509}
2025-06-20 18:12:51,305 - INFO - > Epoch 45: took 235.3s (avg 238.8s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:16:19,047 - INFO - train: {'epoch': 46, 'time_epoch': 198.55019, 'eta': 10735.32347, 'eta_hours': 2.98203, 'loss': 0.05486681, 'lr': 0.00030332, 'params': 9588956, 'time_iter': 0.28985, 'accuracy': 0.9795, 'auc': 0.55884, 'ap': 0.0277}
2025-06-20 18:16:31,353 - INFO - val: {'epoch': 46, 'time_epoch': 11.12155, 'loss': 0.08043933, 'lr': 0, 'params': 9588956, 'time_iter': 0.12932, 'accuracy': 0.95487, 'auc': 0.48647, 'ap': 0.02385}
2025-06-20 18:16:44,510 - INFO - test: {'epoch': 46, 'time_epoch': 12.01357, 'loss': 0.08310091, 'lr': 0, 'params': 9588956, 'time_iter': 0.13969, 'accuracy': 0.95429, 'auc': 0.49269, 'ap': 0.02553}
2025-06-20 18:16:44,513 - INFO - > Epoch 46: took 233.2s (avg 238.7s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:20:10,458 - INFO - train: {'epoch': 47, 'time_epoch': 196.72893, 'eta': 10526.46048, 'eta_hours': 2.92402, 'loss': 0.05485124, 'lr': 0.00029522, 'params': 9588956, 'time_iter': 0.2872, 'accuracy': 0.97956, 'auc': 0.56245, 'ap': 0.02766}
2025-06-20 18:20:22,786 - INFO - val: {'epoch': 47, 'time_epoch': 11.12604, 'loss': 0.07684592, 'lr': 0, 'params': 9588956, 'time_iter': 0.12937, 'accuracy': 0.95487, 'auc': 0.48938, 'ap': 0.02412}
2025-06-20 18:20:35,967 - INFO - test: {'epoch': 47, 'time_epoch': 12.01503, 'loss': 0.07942732, 'lr': 0, 'params': 9588956, 'time_iter': 0.13971, 'accuracy': 0.95429, 'auc': 0.48898, 'ap': 0.02566}
2025-06-20 18:20:35,970 - INFO - > Epoch 47: took 231.5s (avg 238.5s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:24:04,775 - INFO - train: {'epoch': 48, 'time_epoch': 199.4937, 'eta': 10320.97039, 'eta_hours': 2.86694, 'loss': 0.05483238, 'lr': 0.00028707, 'params': 9588956, 'time_iter': 0.29123, 'accuracy': 0.97959, 'auc': 0.55993, 'ap': 0.02793}
2025-06-20 18:24:17,087 - INFO - val: {'epoch': 48, 'time_epoch': 11.13381, 'loss': 0.075474, 'lr': 0, 'params': 9588956, 'time_iter': 0.12946, 'accuracy': 0.96003, 'auc': 0.48529, 'ap': 0.0229}
2025-06-20 18:24:30,285 - INFO - test: {'epoch': 48, 'time_epoch': 12.03006, 'loss': 0.07805554, 'lr': 0, 'params': 9588956, 'time_iter': 0.13988, 'accuracy': 0.95938, 'auc': 0.47545, 'ap': 0.02438}
2025-06-20 18:24:30,287 - INFO - > Epoch 48: took 234.3s (avg 238.4s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:27:57,641 - INFO - train: {'epoch': 49, 'time_epoch': 198.16048, 'eta': 10114.38693, 'eta_hours': 2.80955, 'loss': 0.0548429, 'lr': 0.00027887, 'params': 9588956, 'time_iter': 0.28929, 'accuracy': 0.97955, 'auc': 0.55971, 'ap': 0.02767}
2025-06-20 18:28:09,896 - INFO - val: {'epoch': 49, 'time_epoch': 11.08011, 'loss': 0.07640244, 'lr': 0, 'params': 9588956, 'time_iter': 0.12884, 'accuracy': 0.95487, 'auc': 0.49571, 'ap': 0.02437}
2025-06-20 18:28:23,076 - INFO - test: {'epoch': 49, 'time_epoch': 11.99462, 'loss': 0.07899234, 'lr': 0, 'params': 9588956, 'time_iter': 0.13947, 'accuracy': 0.95429, 'auc': 0.48481, 'ap': 0.02544}
2025-06-20 18:28:23,078 - INFO - > Epoch 49: took 232.8s (avg 238.3s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:31:51,468 - INFO - train: {'epoch': 50, 'time_epoch': 198.88601, 'eta': 9908.83087, 'eta_hours': 2.75245, 'loss': 0.05481899, 'lr': 0.00027064, 'params': 9588956, 'time_iter': 0.29034, 'accuracy': 0.97954, 'auc': 0.56179, 'ap': 0.02759}
2025-06-20 18:32:03,812 - INFO - val: {'epoch': 50, 'time_epoch': 11.17703, 'loss': 0.07745867, 'lr': 0, 'params': 9588956, 'time_iter': 0.12997, 'accuracy': 0.95926, 'auc': 0.48288, 'ap': 0.02358}
2025-06-20 18:32:17,039 - INFO - test: {'epoch': 50, 'time_epoch': 12.07752, 'loss': 0.08008889, 'lr': 0, 'params': 9588956, 'time_iter': 0.14044, 'accuracy': 0.95834, 'auc': 0.48348, 'ap': 0.0252}
2025-06-20 18:32:17,041 - INFO - > Epoch 50: took 234.0s (avg 238.2s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:35:48,342 - INFO - train: {'epoch': 51, 'time_epoch': 201.79723, 'eta': 9706.21862, 'eta_hours': 2.69617, 'loss': 0.05480888, 'lr': 0.0002624, 'params': 9588956, 'time_iter': 0.29459, 'accuracy': 0.97957, 'auc': 0.56346, 'ap': 0.02799}
2025-06-20 18:36:00,741 - INFO - val: {'epoch': 51, 'time_epoch': 11.19739, 'loss': 0.07475661, 'lr': 0, 'params': 9588956, 'time_iter': 0.1302, 'accuracy': 0.96442, 'auc': 0.48579, 'ap': 0.02391}
2025-06-20 18:36:14,004 - INFO - test: {'epoch': 51, 'time_epoch': 12.09512, 'loss': 0.07733167, 'lr': 0, 'params': 9588956, 'time_iter': 0.14064, 'accuracy': 0.96344, 'auc': 0.48466, 'ap': 0.02527}
2025-06-20 18:36:14,007 - INFO - > Epoch 51: took 237.0s (avg 238.2s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:39:42,418 - INFO - train: {'epoch': 52, 'time_epoch': 198.92272, 'eta': 9501.08803, 'eta_hours': 2.63919, 'loss': 0.05482046, 'lr': 0.00025413, 'params': 9588956, 'time_iter': 0.2904, 'accuracy': 0.97957, 'auc': 0.56323, 'ap': 0.02773}
2025-06-20 18:39:54,603 - INFO - val: {'epoch': 52, 'time_epoch': 11.09766, 'loss': 0.07707673, 'lr': 0, 'params': 9588956, 'time_iter': 0.12904, 'accuracy': 0.95926, 'auc': 0.5022, 'ap': 0.02414}
2025-06-20 18:40:07,657 - INFO - test: {'epoch': 52, 'time_epoch': 11.98921, 'loss': 0.07965905, 'lr': 0, 'params': 9588956, 'time_iter': 0.13941, 'accuracy': 0.95834, 'auc': 0.49952, 'ap': 0.02511}
2025-06-20 18:40:07,660 - INFO - > Epoch 52: took 233.7s (avg 238.1s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:43:38,519 - INFO - train: {'epoch': 53, 'time_epoch': 201.26866, 'eta': 9298.18577, 'eta_hours': 2.58283, 'loss': 0.05481042, 'lr': 0.00024587, 'params': 9588956, 'time_iter': 0.29382, 'accuracy': 0.97956, 'auc': 0.56056, 'ap': 0.02802}
2025-06-20 18:43:50,887 - INFO - val: {'epoch': 53, 'time_epoch': 11.19182, 'loss': 0.07386529, 'lr': 0, 'params': 9588956, 'time_iter': 0.13014, 'accuracy': 0.96442, 'auc': 0.51943, 'ap': 0.02643}
2025-06-20 18:44:04,142 - INFO - test: {'epoch': 53, 'time_epoch': 12.09541, 'loss': 0.07638988, 'lr': 0, 'params': 9588956, 'time_iter': 0.14064, 'accuracy': 0.96344, 'auc': 0.51685, 'ap': 0.02712}
2025-06-20 18:44:04,145 - INFO - > Epoch 53: took 236.5s (avg 238.1s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:47:32,586 - INFO - train: {'epoch': 54, 'time_epoch': 198.86102, 'eta': 9093.37301, 'eta_hours': 2.52594, 'loss': 0.05480553, 'lr': 0.0002376, 'params': 9588956, 'time_iter': 0.29031, 'accuracy': 0.97961, 'auc': 0.5625, 'ap': 0.02777}
2025-06-20 18:47:44,866 - INFO - val: {'epoch': 54, 'time_epoch': 11.13794, 'loss': 0.07384222, 'lr': 0, 'params': 9588956, 'time_iter': 0.12951, 'accuracy': 0.96442, 'auc': 0.51902, 'ap': 0.02677}
2025-06-20 18:47:58,091 - INFO - test: {'epoch': 54, 'time_epoch': 12.09775, 'loss': 0.07636169, 'lr': 0, 'params': 9588956, 'time_iter': 0.14067, 'accuracy': 0.96344, 'auc': 0.5192, 'ap': 0.02688}
2025-06-20 18:47:58,093 - INFO - > Epoch 54: took 233.9s (avg 238.0s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:51:28,295 - INFO - train: {'epoch': 55, 'time_epoch': 200.62223, 'eta': 8890.15663, 'eta_hours': 2.46949, 'loss': 0.05480188, 'lr': 0.00022936, 'params': 9588956, 'time_iter': 0.29288, 'accuracy': 0.97955, 'auc': 0.56414, 'ap': 0.0278}
2025-06-20 18:51:40,756 - INFO - val: {'epoch': 55, 'time_epoch': 11.21835, 'loss': 0.07330185, 'lr': 0, 'params': 9588956, 'time_iter': 0.13045, 'accuracy': 0.96982, 'auc': 0.49442, 'ap': 0.02681}
2025-06-20 18:51:54,094 - INFO - test: {'epoch': 55, 'time_epoch': 12.11937, 'loss': 0.07582723, 'lr': 0, 'params': 9588956, 'time_iter': 0.14092, 'accuracy': 0.96848, 'auc': 0.49126, 'ap': 0.0264}
2025-06-20 18:51:54,096 - INFO - > Epoch 55: took 236.0s (avg 238.0s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:55:24,823 - INFO - train: {'epoch': 56, 'time_epoch': 201.16402, 'eta': 8687.43999, 'eta_hours': 2.41318, 'loss': 0.0547841, 'lr': 0.00022113, 'params': 9588956, 'time_iter': 0.29367, 'accuracy': 0.97958, 'auc': 0.56248, 'ap': 0.0279}
2025-06-20 18:55:37,276 - INFO - val: {'epoch': 56, 'time_epoch': 11.20952, 'loss': 0.07049906, 'lr': 0, 'params': 9588956, 'time_iter': 0.13034, 'accuracy': 0.97414, 'auc': 0.49802, 'ap': 0.02641}
2025-06-20 18:55:50,559 - INFO - test: {'epoch': 56, 'time_epoch': 12.06708, 'loss': 0.07293248, 'lr': 0, 'params': 9588956, 'time_iter': 0.14031, 'accuracy': 0.97272, 'auc': 0.49674, 'ap': 0.02726}
2025-06-20 18:55:50,562 - INFO - > Epoch 56: took 236.5s (avg 237.9s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 18:59:18,421 - INFO - train: {'epoch': 57, 'time_epoch': 198.27851, 'eta': 8482.68737, 'eta_hours': 2.3563, 'loss': 0.05477083, 'lr': 0.00021293, 'params': 9588956, 'time_iter': 0.28946, 'accuracy': 0.97956, 'auc': 0.56546, 'ap': 0.02796}
2025-06-20 18:59:30,802 - INFO - val: {'epoch': 57, 'time_epoch': 11.13056, 'loss': 0.07114799, 'lr': 0, 'params': 9588956, 'time_iter': 0.12943, 'accuracy': 0.96982, 'auc': 0.48505, 'ap': 0.02536}
2025-06-20 18:59:44,124 - INFO - test: {'epoch': 57, 'time_epoch': 12.08501, 'loss': 0.07361653, 'lr': 0, 'params': 9588956, 'time_iter': 0.14052, 'accuracy': 0.96848, 'auc': 0.49908, 'ap': 0.0268}
2025-06-20 18:59:44,126 - INFO - > Epoch 57: took 233.6s (avg 237.9s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 19:03:13,505 - INFO - train: {'epoch': 58, 'time_epoch': 199.8467, 'eta': 8279.24398, 'eta_hours': 2.29979, 'loss': 0.05478879, 'lr': 0.00020478, 'params': 9588956, 'time_iter': 0.29175, 'accuracy': 0.97959, 'auc': 0.56437, 'ap': 0.02776}
2025-06-20 19:03:25,938 - INFO - val: {'epoch': 58, 'time_epoch': 11.17593, 'loss': 0.07158417, 'lr': 0, 'params': 9588956, 'time_iter': 0.12995, 'accuracy': 0.97414, 'auc': 0.49599, 'ap': 0.02682}
2025-06-20 19:03:39,278 - INFO - test: {'epoch': 58, 'time_epoch': 12.12045, 'loss': 0.07406389, 'lr': 0, 'params': 9588956, 'time_iter': 0.14094, 'accuracy': 0.97272, 'auc': 0.50844, 'ap': 0.02858}
2025-06-20 19:03:39,281 - INFO - > Epoch 58: took 235.2s (avg 237.8s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 19:07:07,180 - INFO - train: {'epoch': 59, 'time_epoch': 198.32963, 'eta': 8074.9091, 'eta_hours': 2.24303, 'loss': 0.05480919, 'lr': 0.00019668, 'params': 9588956, 'time_iter': 0.28953, 'accuracy': 0.97958, 'auc': 0.56369, 'ap': 0.0278}
2025-06-20 19:07:19,521 - INFO - val: {'epoch': 59, 'time_epoch': 11.13505, 'loss': 0.07256034, 'lr': 0, 'params': 9588956, 'time_iter': 0.12948, 'accuracy': 0.96442, 'auc': 0.52043, 'ap': 0.02856}
2025-06-20 19:07:35,698 - INFO - test: {'epoch': 59, 'time_epoch': 14.95798, 'loss': 0.0750377, 'lr': 0, 'params': 9588956, 'time_iter': 0.17393, 'accuracy': 0.96344, 'auc': 0.51788, 'ap': 0.02881}
2025-06-20 19:07:35,700 - INFO - > Epoch 59: took 236.4s (avg 237.8s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 19:11:03,879 - INFO - train: {'epoch': 60, 'time_epoch': 198.49723, 'eta': 7870.87827, 'eta_hours': 2.18636, 'loss': 0.05479569, 'lr': 0.00018863, 'params': 9588956, 'time_iter': 0.28978, 'accuracy': 0.97956, 'auc': 0.56309, 'ap': 0.02803}
2025-06-20 19:11:16,278 - INFO - val: {'epoch': 60, 'time_epoch': 11.16209, 'loss': 0.07306769, 'lr': 0, 'params': 9588956, 'time_iter': 0.12979, 'accuracy': 0.96442, 'auc': 0.53168, 'ap': 0.02652}
2025-06-20 19:11:29,551 - INFO - test: {'epoch': 60, 'time_epoch': 12.05935, 'loss': 0.07560172, 'lr': 0, 'params': 9588956, 'time_iter': 0.14022, 'accuracy': 0.96344, 'auc': 0.51883, 'ap': 0.02656}
2025-06-20 19:11:29,554 - INFO - > Epoch 60: took 233.9s (avg 237.7s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 19:14:59,566 - INFO - train: {'epoch': 61, 'time_epoch': 200.449, 'eta': 7668.22219, 'eta_hours': 2.13006, 'loss': 0.05479855, 'lr': 0.00018065, 'params': 9588956, 'time_iter': 0.29263, 'accuracy': 0.97953, 'auc': 0.56324, 'ap': 0.02814}
2025-06-20 19:15:11,913 - INFO - val: {'epoch': 61, 'time_epoch': 11.14933, 'loss': 0.07337709, 'lr': 0, 'params': 9588956, 'time_iter': 0.12964, 'accuracy': 0.96982, 'auc': 0.5178, 'ap': 0.02535}
2025-06-20 19:15:25,117 - INFO - test: {'epoch': 61, 'time_epoch': 12.02348, 'loss': 0.07589392, 'lr': 0, 'params': 9588956, 'time_iter': 0.13981, 'accuracy': 0.96848, 'auc': 0.51886, 'ap': 0.02593}
2025-06-20 19:15:25,120 - INFO - > Epoch 61: took 235.6s (avg 237.7s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 19:18:50,083 - INFO - train: {'epoch': 62, 'time_epoch': 195.64068, 'eta': 7462.81224, 'eta_hours': 2.073, 'loss': 0.05481282, 'lr': 0.00017275, 'params': 9588956, 'time_iter': 0.28561, 'accuracy': 0.97951, 'auc': 0.56276, 'ap': 0.02753}
2025-06-20 19:19:02,370 - INFO - val: {'epoch': 62, 'time_epoch': 11.1193, 'loss': 0.07387363, 'lr': 0, 'params': 9588956, 'time_iter': 0.12929, 'accuracy': 0.96982, 'auc': 0.52576, 'ap': 0.02534}
2025-06-20 19:19:15,530 - INFO - test: {'epoch': 62, 'time_epoch': 11.99303, 'loss': 0.07642662, 'lr': 0, 'params': 9588956, 'time_iter': 0.13945, 'accuracy': 0.96848, 'auc': 0.51886, 'ap': 0.02599}
2025-06-20 19:19:15,533 - INFO - > Epoch 62: took 230.4s (avg 237.6s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 19:22:45,519 - INFO - train: {'epoch': 63, 'time_epoch': 200.61396, 'eta': 7260.50504, 'eta_hours': 2.01681, 'loss': 0.05479989, 'lr': 0.00016493, 'params': 9588956, 'time_iter': 0.29287, 'accuracy': 0.97954, 'auc': 0.56385, 'ap': 0.02807}
2025-06-20 19:22:57,841 - INFO - val: {'epoch': 63, 'time_epoch': 11.11369, 'loss': 0.07335669, 'lr': 0, 'params': 9588956, 'time_iter': 0.12923, 'accuracy': 0.96442, 'auc': 0.53106, 'ap': 0.02687}
2025-06-20 19:23:11,074 - INFO - test: {'epoch': 63, 'time_epoch': 12.01242, 'loss': 0.07591162, 'lr': 0, 'params': 9588956, 'time_iter': 0.13968, 'accuracy': 0.96344, 'auc': 0.52146, 'ap': 0.02686}
2025-06-20 19:23:11,076 - INFO - > Epoch 63: took 235.5s (avg 237.6s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 19:26:37,657 - INFO - train: {'epoch': 64, 'time_epoch': 197.17517, 'eta': 7056.3983, 'eta_hours': 1.96011, 'loss': 0.05479984, 'lr': 0.0001572, 'params': 9588956, 'time_iter': 0.28785, 'accuracy': 0.97952, 'auc': 0.5642, 'ap': 0.02805}
2025-06-20 19:26:52,815 - INFO - val: {'epoch': 64, 'time_epoch': 13.94883, 'loss': 0.07395281, 'lr': 0, 'params': 9588956, 'time_iter': 0.1622, 'accuracy': 0.96442, 'auc': 0.53159, 'ap': 0.02832}
2025-06-20 19:27:05,984 - INFO - test: {'epoch': 64, 'time_epoch': 11.98103, 'loss': 0.07650895, 'lr': 0, 'params': 9588956, 'time_iter': 0.13931, 'accuracy': 0.96344, 'auc': 0.52196, 'ap': 0.02754}
2025-06-20 19:27:05,986 - INFO - > Epoch 64: took 234.9s (avg 237.5s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 19:30:32,231 - INFO - train: {'epoch': 65, 'time_epoch': 196.7891, 'eta': 6852.30271, 'eta_hours': 1.90342, 'loss': 0.05480743, 'lr': 0.00014958, 'params': 9588956, 'time_iter': 0.28728, 'accuracy': 0.97948, 'auc': 0.56393, 'ap': 0.0276}
2025-06-20 19:30:44,582 - INFO - val: {'epoch': 65, 'time_epoch': 11.12993, 'loss': 0.07356824, 'lr': 0, 'params': 9588956, 'time_iter': 0.12942, 'accuracy': 0.96982, 'auc': 0.5262, 'ap': 0.0266}
2025-06-20 19:30:57,814 - INFO - test: {'epoch': 65, 'time_epoch': 12.02427, 'loss': 0.07610128, 'lr': 0, 'params': 9588956, 'time_iter': 0.13982, 'accuracy': 0.96848, 'auc': 0.524, 'ap': 0.02674}
2025-06-20 19:30:57,816 - INFO - > Epoch 65: took 231.8s (avg 237.4s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 19:34:28,054 - INFO - train: {'epoch': 66, 'time_epoch': 200.70992, 'eta': 6650.35638, 'eta_hours': 1.84732, 'loss': 0.05478259, 'lr': 0.00014206, 'params': 9588956, 'time_iter': 0.29301, 'accuracy': 0.97957, 'auc': 0.56474, 'ap': 0.02836}
2025-06-20 19:34:40,421 - INFO - val: {'epoch': 66, 'time_epoch': 11.13839, 'loss': 0.07494604, 'lr': 0, 'params': 9588956, 'time_iter': 0.12952, 'accuracy': 0.96442, 'auc': 0.5292, 'ap': 0.02684}
2025-06-20 19:34:53,682 - INFO - test: {'epoch': 66, 'time_epoch': 12.01224, 'loss': 0.07753542, 'lr': 0, 'params': 9588956, 'time_iter': 0.13968, 'accuracy': 0.96344, 'auc': 0.52322, 'ap': 0.02671}
2025-06-20 19:34:53,684 - INFO - > Epoch 66: took 235.9s (avg 237.4s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 19:38:19,689 - INFO - train: {'epoch': 67, 'time_epoch': 196.6059, 'eta': 6446.51511, 'eta_hours': 1.7907, 'loss': 0.0547819, 'lr': 0.00013466, 'params': 9588956, 'time_iter': 0.28702, 'accuracy': 0.97952, 'auc': 0.56577, 'ap': 0.02786}
2025-06-20 19:38:32,035 - INFO - val: {'epoch': 67, 'time_epoch': 11.11729, 'loss': 0.07351031, 'lr': 0, 'params': 9588956, 'time_iter': 0.12927, 'accuracy': 0.96442, 'auc': 0.53609, 'ap': 0.02675}
2025-06-20 19:38:45,234 - INFO - test: {'epoch': 67, 'time_epoch': 12.01546, 'loss': 0.07607944, 'lr': 0, 'params': 9588956, 'time_iter': 0.13971, 'accuracy': 0.96344, 'auc': 0.52255, 'ap': 0.02678}
2025-06-20 19:38:45,236 - INFO - > Epoch 67: took 231.6s (avg 237.3s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 19:42:14,809 - INFO - train: {'epoch': 68, 'time_epoch': 200.18804, 'eta': 6244.49292, 'eta_hours': 1.73458, 'loss': 0.05478751, 'lr': 0.00012739, 'params': 9588956, 'time_iter': 0.29225, 'accuracy': 0.97955, 'auc': 0.56496, 'ap': 0.02801}
2025-06-20 19:42:27,086 - INFO - val: {'epoch': 68, 'time_epoch': 11.08757, 'loss': 0.07372068, 'lr': 0, 'params': 9588956, 'time_iter': 0.12893, 'accuracy': 0.96442, 'auc': 0.5332, 'ap': 0.02677}
2025-06-20 19:42:40,183 - INFO - test: {'epoch': 68, 'time_epoch': 11.93042, 'loss': 0.07626124, 'lr': 0, 'params': 9588956, 'time_iter': 0.13873, 'accuracy': 0.96344, 'auc': 0.52228, 'ap': 0.0266}
2025-06-20 19:42:40,186 - INFO - > Epoch 68: took 234.9s (avg 237.3s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 19:46:09,026 - INFO - train: {'epoch': 69, 'time_epoch': 199.4388, 'eta': 6042.20204, 'eta_hours': 1.67839, 'loss': 0.0547723, 'lr': 0.00012026, 'params': 9588956, 'time_iter': 0.29115, 'accuracy': 0.97962, 'auc': 0.56703, 'ap': 0.02808}
2025-06-20 19:46:21,366 - INFO - val: {'epoch': 69, 'time_epoch': 11.11359, 'loss': 0.07354445, 'lr': 0, 'params': 9588956, 'time_iter': 0.12923, 'accuracy': 0.96442, 'auc': 0.53228, 'ap': 0.02832}
2025-06-20 19:46:34,579 - INFO - test: {'epoch': 69, 'time_epoch': 12.00347, 'loss': 0.07609591, 'lr': 0, 'params': 9588956, 'time_iter': 0.13958, 'accuracy': 0.96344, 'auc': 0.52053, 'ap': 0.02687}
2025-06-20 19:46:34,581 - INFO - > Epoch 69: took 234.4s (avg 237.2s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 19:49:59,106 - INFO - train: {'epoch': 70, 'time_epoch': 195.03836, 'eta': 5838.19414, 'eta_hours': 1.62172, 'loss': 0.0547863, 'lr': 0.00011326, 'params': 9588956, 'time_iter': 0.28473, 'accuracy': 0.97952, 'auc': 0.56655, 'ap': 0.02765}
2025-06-20 19:50:11,471 - INFO - val: {'epoch': 70, 'time_epoch': 11.12857, 'loss': 0.07462549, 'lr': 0, 'params': 9588956, 'time_iter': 0.1294, 'accuracy': 0.96442, 'auc': 0.53074, 'ap': 0.02717}
2025-06-20 19:50:24,667 - INFO - test: {'epoch': 70, 'time_epoch': 11.97571, 'loss': 0.07718339, 'lr': 0, 'params': 9588956, 'time_iter': 0.13925, 'accuracy': 0.96344, 'auc': 0.51988, 'ap': 0.02661}
2025-06-20 19:50:24,669 - INFO - > Epoch 70: took 230.1s (avg 237.1s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 19:53:54,488 - INFO - train: {'epoch': 71, 'time_epoch': 200.41649, 'eta': 5636.52689, 'eta_hours': 1.5657, 'loss': 0.0547895, 'lr': 0.00010642, 'params': 9588956, 'time_iter': 0.29258, 'accuracy': 0.97957, 'auc': 0.56573, 'ap': 0.02765}
2025-06-20 19:54:06,844 - INFO - val: {'epoch': 71, 'time_epoch': 11.11578, 'loss': 0.06902866, 'lr': 0, 'params': 9588956, 'time_iter': 0.12925, 'accuracy': 0.97414, 'auc': 0.53219, 'ap': 0.02684}
2025-06-20 19:54:20,108 - INFO - test: {'epoch': 71, 'time_epoch': 12.04459, 'loss': 0.07147192, 'lr': 0, 'params': 9588956, 'time_iter': 0.14005, 'accuracy': 0.97272, 'auc': 0.5209, 'ap': 0.02643}
2025-06-20 19:54:20,111 - INFO - > Epoch 71: took 235.4s (avg 237.1s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 19:57:46,866 - INFO - train: {'epoch': 72, 'time_epoch': 197.20177, 'eta': 5433.7049, 'eta_hours': 1.50936, 'loss': 0.05478136, 'lr': 9.973e-05, 'params': 9588956, 'time_iter': 0.28789, 'accuracy': 0.97952, 'auc': 0.56607, 'ap': 0.02813}
2025-06-20 19:57:59,285 - INFO - val: {'epoch': 72, 'time_epoch': 11.15775, 'loss': 0.06961019, 'lr': 0, 'params': 9588956, 'time_iter': 0.12974, 'accuracy': 0.97414, 'auc': 0.53376, 'ap': 0.02704}
2025-06-20 19:58:12,593 - INFO - test: {'epoch': 72, 'time_epoch': 12.05414, 'loss': 0.07205628, 'lr': 0, 'params': 9588956, 'time_iter': 0.14016, 'accuracy': 0.97272, 'auc': 0.52138, 'ap': 0.02665}
2025-06-20 19:58:12,595 - INFO - > Epoch 72: took 232.5s (avg 237.1s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 20:01:42,459 - INFO - train: {'epoch': 73, 'time_epoch': 200.37662, 'eta': 5232.15029, 'eta_hours': 1.45338, 'loss': 0.05477845, 'lr': 9.321e-05, 'params': 9588956, 'time_iter': 0.29252, 'accuracy': 0.97951, 'auc': 0.56654, 'ap': 0.02764}
2025-06-20 20:01:54,813 - INFO - val: {'epoch': 73, 'time_epoch': 11.11301, 'loss': 0.07056845, 'lr': 0, 'params': 9588956, 'time_iter': 0.12922, 'accuracy': 0.97414, 'auc': 0.52847, 'ap': 0.02733}
2025-06-20 20:02:08,100 - INFO - test: {'epoch': 73, 'time_epoch': 12.03565, 'loss': 0.07301739, 'lr': 0, 'params': 9588956, 'time_iter': 0.13995, 'accuracy': 0.97272, 'auc': 0.5232, 'ap': 0.02689}
2025-06-20 20:02:08,103 - INFO - > Epoch 73: took 235.5s (avg 237.0s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 20:05:37,404 - INFO - train: {'epoch': 74, 'time_epoch': 199.89795, 'eta': 5030.46754, 'eta_hours': 1.39735, 'loss': 0.05474896, 'lr': 8.685e-05, 'params': 9588956, 'time_iter': 0.29182, 'accuracy': 0.97955, 'auc': 0.5676, 'ap': 0.02792}
2025-06-20 20:05:49,783 - INFO - val: {'epoch': 74, 'time_epoch': 11.13602, 'loss': 0.07147185, 'lr': 0, 'params': 9588956, 'time_iter': 0.12949, 'accuracy': 0.96982, 'auc': 0.53445, 'ap': 0.02863}
2025-06-20 20:06:03,047 - INFO - test: {'epoch': 74, 'time_epoch': 12.03598, 'loss': 0.07397682, 'lr': 0, 'params': 9588956, 'time_iter': 0.13995, 'accuracy': 0.96848, 'auc': 0.52147, 'ap': 0.02726}
2025-06-20 20:06:03,049 - INFO - > Epoch 74: took 234.9s (avg 237.0s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 20:09:29,800 - INFO - train: {'epoch': 75, 'time_epoch': 197.13814, 'eta': 4827.96024, 'eta_hours': 1.3411, 'loss': 0.05475351, 'lr': 8.068e-05, 'params': 9588956, 'time_iter': 0.28779, 'accuracy': 0.97953, 'auc': 0.56934, 'ap': 0.02835}
2025-06-20 20:09:42,181 - INFO - val: {'epoch': 75, 'time_epoch': 11.12968, 'loss': 0.0737904, 'lr': 0, 'params': 9588956, 'time_iter': 0.12941, 'accuracy': 0.96442, 'auc': 0.53548, 'ap': 0.0286}
2025-06-20 20:09:55,448 - INFO - test: {'epoch': 75, 'time_epoch': 12.059, 'loss': 0.0763269, 'lr': 0, 'params': 9588956, 'time_iter': 0.14022, 'accuracy': 0.96344, 'auc': 0.52346, 'ap': 0.0272}
2025-06-20 20:09:55,451 - INFO - > Epoch 75: took 232.4s (avg 236.9s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 20:13:24,739 - INFO - train: {'epoch': 76, 'time_epoch': 199.80876, 'eta': 4626.39012, 'eta_hours': 1.28511, 'loss': 0.05474905, 'lr': 7.469e-05, 'params': 9588956, 'time_iter': 0.29169, 'accuracy': 0.97951, 'auc': 0.56648, 'ap': 0.02863}
2025-06-20 20:13:37,234 - INFO - val: {'epoch': 76, 'time_epoch': 11.23051, 'loss': 0.07632119, 'lr': 0, 'params': 9588956, 'time_iter': 0.13059, 'accuracy': 0.95926, 'auc': 0.53345, 'ap': 0.02857}
2025-06-20 20:13:50,847 - INFO - test: {'epoch': 76, 'time_epoch': 12.14069, 'loss': 0.07888837, 'lr': 0, 'params': 9588956, 'time_iter': 0.14117, 'accuracy': 0.95834, 'auc': 0.52181, 'ap': 0.02715}
2025-06-20 20:13:50,850 - INFO - > Epoch 76: took 235.4s (avg 236.9s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 20:17:18,745 - INFO - train: {'epoch': 77, 'time_epoch': 198.20178, 'eta': 4424.41191, 'eta_hours': 1.229, 'loss': 0.05473756, 'lr': 6.889e-05, 'params': 9588956, 'time_iter': 0.28935, 'accuracy': 0.97955, 'auc': 0.56976, 'ap': 0.02856}
2025-06-20 20:17:31,227 - INFO - val: {'epoch': 77, 'time_epoch': 11.20666, 'loss': 0.0744274, 'lr': 0, 'params': 9588956, 'time_iter': 0.13031, 'accuracy': 0.96982, 'auc': 0.53537, 'ap': 0.02869}
2025-06-20 20:17:47,527 - INFO - test: {'epoch': 77, 'time_epoch': 15.02567, 'loss': 0.07694446, 'lr': 0, 'params': 9588956, 'time_iter': 0.17472, 'accuracy': 0.96848, 'auc': 0.52254, 'ap': 0.0272}
2025-06-20 20:17:47,530 - INFO - > Epoch 77: took 236.7s (avg 236.9s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 20:21:17,099 - INFO - train: {'epoch': 78, 'time_epoch': 200.00697, 'eta': 4223.00916, 'eta_hours': 1.17306, 'loss': 0.05474491, 'lr': 6.329e-05, 'params': 9588956, 'time_iter': 0.29198, 'accuracy': 0.97954, 'auc': 0.56806, 'ap': 0.02817}
2025-06-20 20:21:29,536 - INFO - val: {'epoch': 78, 'time_epoch': 11.16381, 'loss': 0.07490717, 'lr': 0, 'params': 9588956, 'time_iter': 0.12981, 'accuracy': 0.96442, 'auc': 0.53373, 'ap': 0.02832}
2025-06-20 20:21:42,812 - INFO - test: {'epoch': 78, 'time_epoch': 12.04264, 'loss': 0.07745953, 'lr': 0, 'params': 9588956, 'time_iter': 0.14003, 'accuracy': 0.96344, 'auc': 0.51855, 'ap': 0.02717}
2025-06-20 20:21:42,814 - INFO - > Epoch 78: took 235.3s (avg 236.9s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 20:25:12,064 - INFO - train: {'epoch': 79, 'time_epoch': 199.77772, 'eta': 4021.584, 'eta_hours': 1.11711, 'loss': 0.05474302, 'lr': 5.79e-05, 'params': 9588956, 'time_iter': 0.29165, 'accuracy': 0.97955, 'auc': 0.56888, 'ap': 0.02831}
2025-06-20 20:25:24,462 - INFO - val: {'epoch': 79, 'time_epoch': 11.13722, 'loss': 0.07432444, 'lr': 0, 'params': 9588956, 'time_iter': 0.1295, 'accuracy': 0.96442, 'auc': 0.53524, 'ap': 0.02842}
2025-06-20 20:25:37,772 - INFO - test: {'epoch': 79, 'time_epoch': 12.07831, 'loss': 0.07687233, 'lr': 0, 'params': 9588956, 'time_iter': 0.14045, 'accuracy': 0.96344, 'auc': 0.52089, 'ap': 0.02716}
2025-06-20 20:25:37,775 - INFO - > Epoch 79: took 235.0s (avg 236.9s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 20:29:04,784 - INFO - train: {'epoch': 80, 'time_epoch': 197.48874, 'eta': 3819.66259, 'eta_hours': 1.06102, 'loss': 0.05474465, 'lr': 5.271e-05, 'params': 9588956, 'time_iter': 0.2883, 'accuracy': 0.97954, 'auc': 0.56828, 'ap': 0.0286}
2025-06-20 20:29:17,140 - INFO - val: {'epoch': 80, 'time_epoch': 11.12812, 'loss': 0.0733828, 'lr': 0, 'params': 9588956, 'time_iter': 0.1294, 'accuracy': 0.96982, 'auc': 0.53403, 'ap': 0.02848}
2025-06-20 20:29:30,321 - INFO - test: {'epoch': 80, 'time_epoch': 11.97342, 'loss': 0.0758995, 'lr': 0, 'params': 9588956, 'time_iter': 0.13923, 'accuracy': 0.96848, 'auc': 0.52039, 'ap': 0.02725}
2025-06-20 20:29:30,324 - INFO - > Epoch 80: took 232.5s (avg 236.8s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 20:33:00,064 - INFO - train: {'epoch': 81, 'time_epoch': 200.24941, 'eta': 3618.4553, 'eta_hours': 1.00513, 'loss': 0.05472742, 'lr': 4.775e-05, 'params': 9588956, 'time_iter': 0.29233, 'accuracy': 0.97953, 'auc': 0.57248, 'ap': 0.02819}
2025-06-20 20:33:12,393 - INFO - val: {'epoch': 81, 'time_epoch': 11.08918, 'loss': 0.07290597, 'lr': 0, 'params': 9588956, 'time_iter': 0.12894, 'accuracy': 0.96982, 'auc': 0.53508, 'ap': 0.02853}
2025-06-20 20:33:25,607 - INFO - test: {'epoch': 81, 'time_epoch': 11.96912, 'loss': 0.07542443, 'lr': 0, 'params': 9588956, 'time_iter': 0.13918, 'accuracy': 0.96848, 'auc': 0.52106, 'ap': 0.02722}
2025-06-20 20:33:25,609 - INFO - > Epoch 81: took 235.3s (avg 236.8s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 20:36:54,383 - INFO - train: {'epoch': 82, 'time_epoch': 199.25391, 'eta': 3417.06719, 'eta_hours': 0.94919, 'loss': 0.05473014, 'lr': 4.3e-05, 'params': 9588956, 'time_iter': 0.29088, 'accuracy': 0.97955, 'auc': 0.5689, 'ap': 0.02859}
2025-06-20 20:37:09,727 - INFO - val: {'epoch': 82, 'time_epoch': 14.07282, 'loss': 0.07479908, 'lr': 0, 'params': 9588956, 'time_iter': 0.16364, 'accuracy': 0.96442, 'auc': 0.53344, 'ap': 0.02734}
2025-06-20 20:37:23,020 - INFO - test: {'epoch': 82, 'time_epoch': 12.06702, 'loss': 0.07734038, 'lr': 0, 'params': 9588956, 'time_iter': 0.14031, 'accuracy': 0.96344, 'auc': 0.52105, 'ap': 0.02705}
2025-06-20 20:37:23,022 - INFO - > Epoch 82: took 237.4s (avg 236.8s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 20:40:49,336 - INFO - train: {'epoch': 83, 'time_epoch': 196.92447, 'eta': 3215.2862, 'eta_hours': 0.89314, 'loss': 0.05472672, 'lr': 3.848e-05, 'params': 9588956, 'time_iter': 0.28748, 'accuracy': 0.97954, 'auc': 0.56972, 'ap': 0.02872}
2025-06-20 20:41:01,667 - INFO - val: {'epoch': 83, 'time_epoch': 11.08369, 'loss': 0.07498021, 'lr': 0, 'params': 9588956, 'time_iter': 0.12888, 'accuracy': 0.96442, 'auc': 0.53473, 'ap': 0.02832}
2025-06-20 20:41:14,847 - INFO - test: {'epoch': 83, 'time_epoch': 11.95972, 'loss': 0.07752215, 'lr': 0, 'params': 9588956, 'time_iter': 0.13907, 'accuracy': 0.96344, 'auc': 0.52071, 'ap': 0.02707}
2025-06-20 20:41:14,850 - INFO - > Epoch 83: took 231.8s (avg 236.8s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 20:44:44,803 - INFO - train: {'epoch': 84, 'time_epoch': 200.5989, 'eta': 3014.2679, 'eta_hours': 0.8373, 'loss': 0.05471931, 'lr': 3.419e-05, 'params': 9588956, 'time_iter': 0.29285, 'accuracy': 0.97956, 'auc': 0.56935, 'ap': 0.02863}
2025-06-20 20:44:57,130 - INFO - val: {'epoch': 84, 'time_epoch': 11.08577, 'loss': 0.07428031, 'lr': 0, 'params': 9588956, 'time_iter': 0.1289, 'accuracy': 0.96442, 'auc': 0.53453, 'ap': 0.02737}
2025-06-20 20:45:10,378 - INFO - test: {'epoch': 84, 'time_epoch': 12.00403, 'loss': 0.07682793, 'lr': 0, 'params': 9588956, 'time_iter': 0.13958, 'accuracy': 0.96344, 'auc': 0.52122, 'ap': 0.02708}
2025-06-20 20:45:10,380 - INFO - > Epoch 84: took 235.5s (avg 236.7s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 20:48:35,644 - INFO - train: {'epoch': 85, 'time_epoch': 195.96267, 'eta': 2812.50462, 'eta_hours': 0.78125, 'loss': 0.05471344, 'lr': 3.013e-05, 'params': 9588956, 'time_iter': 0.28608, 'accuracy': 0.97958, 'auc': 0.56975, 'ap': 0.02827}
2025-06-20 20:48:47,923 - INFO - val: {'epoch': 85, 'time_epoch': 11.05658, 'loss': 0.07512417, 'lr': 0, 'params': 9588956, 'time_iter': 0.12856, 'accuracy': 0.96442, 'auc': 0.53375, 'ap': 0.02664}
2025-06-20 20:49:01,044 - INFO - test: {'epoch': 85, 'time_epoch': 11.90925, 'loss': 0.07767171, 'lr': 0, 'params': 9588956, 'time_iter': 0.13848, 'accuracy': 0.96344, 'auc': 0.51926, 'ap': 0.02676}
2025-06-20 20:49:01,046 - INFO - > Epoch 85: took 230.7s (avg 236.7s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 20:52:29,269 - INFO - train: {'epoch': 86, 'time_epoch': 198.95559, 'eta': 2611.32191, 'eta_hours': 0.72537, 'loss': 0.05473331, 'lr': 2.632e-05, 'params': 9588956, 'time_iter': 0.29045, 'accuracy': 0.97951, 'auc': 0.56932, 'ap': 0.0282}
2025-06-20 20:52:42,248 - INFO - val: {'epoch': 86, 'time_epoch': 11.11745, 'loss': 0.07547946, 'lr': 0, 'params': 9588956, 'time_iter': 0.12927, 'accuracy': 0.96442, 'auc': 0.53371, 'ap': 0.02668}
2025-06-20 20:52:55,523 - INFO - test: {'epoch': 86, 'time_epoch': 12.04206, 'loss': 0.07803872, 'lr': 0, 'params': 9588956, 'time_iter': 0.14002, 'accuracy': 0.96344, 'auc': 0.52013, 'ap': 0.02687}
2025-06-20 20:52:55,525 - INFO - > Epoch 86: took 234.5s (avg 236.6s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 20:56:20,959 - INFO - train: {'epoch': 87, 'time_epoch': 196.14198, 'eta': 2409.80614, 'eta_hours': 0.66939, 'loss': 0.05471589, 'lr': 2.275e-05, 'params': 9588956, 'time_iter': 0.28634, 'accuracy': 0.97955, 'auc': 0.56957, 'ap': 0.02841}
2025-06-20 20:56:36,048 - INFO - val: {'epoch': 87, 'time_epoch': 13.83996, 'loss': 0.07468325, 'lr': 0, 'params': 9588956, 'time_iter': 0.16093, 'accuracy': 0.96442, 'auc': 0.53448, 'ap': 0.02678}
2025-06-20 20:56:49,227 - INFO - test: {'epoch': 87, 'time_epoch': 11.9566, 'loss': 0.07722582, 'lr': 0, 'params': 9588956, 'time_iter': 0.13903, 'accuracy': 0.96344, 'auc': 0.52, 'ap': 0.02691}
2025-06-20 20:56:49,229 - INFO - > Epoch 87: took 233.7s (avg 236.6s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 21:00:15,227 - INFO - train: {'epoch': 88, 'time_epoch': 196.61802, 'eta': 2208.46996, 'eta_hours': 0.61346, 'loss': 0.05471809, 'lr': 1.943e-05, 'params': 9588956, 'time_iter': 0.28703, 'accuracy': 0.97953, 'auc': 0.57184, 'ap': 0.02861}
2025-06-20 21:00:27,771 - INFO - val: {'epoch': 88, 'time_epoch': 11.06654, 'loss': 0.07615169, 'lr': 0, 'params': 9588956, 'time_iter': 0.12868, 'accuracy': 0.95926, 'auc': 0.53517, 'ap': 0.02681}
2025-06-20 21:00:41,067 - INFO - test: {'epoch': 88, 'time_epoch': 12.01951, 'loss': 0.07870623, 'lr': 0, 'params': 9588956, 'time_iter': 0.13976, 'accuracy': 0.95834, 'auc': 0.52132, 'ap': 0.02696}
2025-06-20 21:00:41,070 - INFO - > Epoch 88: took 231.8s (avg 236.6s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 21:04:08,867 - INFO - train: {'epoch': 89, 'time_epoch': 198.49469, 'eta': 2007.44715, 'eta_hours': 0.55762, 'loss': 0.05471801, 'lr': 1.636e-05, 'params': 9588956, 'time_iter': 0.28977, 'accuracy': 0.97955, 'auc': 0.57204, 'ap': 0.02858}
2025-06-20 21:04:21,164 - INFO - val: {'epoch': 89, 'time_epoch': 11.06048, 'loss': 0.07526861, 'lr': 0, 'params': 9588956, 'time_iter': 0.12861, 'accuracy': 0.96442, 'auc': 0.53405, 'ap': 0.02682}
2025-06-20 21:04:34,336 - INFO - test: {'epoch': 89, 'time_epoch': 11.93766, 'loss': 0.07781503, 'lr': 0, 'params': 9588956, 'time_iter': 0.13881, 'accuracy': 0.96344, 'auc': 0.52052, 'ap': 0.02691}
2025-06-20 21:04:34,338 - INFO - > Epoch 89: took 233.3s (avg 236.5s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 21:08:00,254 - INFO - train: {'epoch': 90, 'time_epoch': 196.62087, 'eta': 1806.29458, 'eta_hours': 0.50175, 'loss': 0.05472482, 'lr': 1.355e-05, 'params': 9588956, 'time_iter': 0.28704, 'accuracy': 0.97955, 'auc': 0.56986, 'ap': 0.02807}
2025-06-20 21:08:12,607 - INFO - val: {'epoch': 90, 'time_epoch': 11.09918, 'loss': 0.07388908, 'lr': 0, 'params': 9588956, 'time_iter': 0.12906, 'accuracy': 0.96982, 'auc': 0.53382, 'ap': 0.0266}
2025-06-20 21:08:25,845 - INFO - test: {'epoch': 90, 'time_epoch': 12.00621, 'loss': 0.0764174, 'lr': 0, 'params': 9588956, 'time_iter': 0.13961, 'accuracy': 0.96848, 'auc': 0.52082, 'ap': 0.02684}
2025-06-20 21:08:25,848 - INFO - > Epoch 90: took 231.5s (avg 236.5s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 21:11:53,939 - INFO - train: {'epoch': 91, 'time_epoch': 198.81851, 'eta': 1605.43163, 'eta_hours': 0.44595, 'loss': 0.05472754, 'lr': 1.099e-05, 'params': 9588956, 'time_iter': 0.29025, 'accuracy': 0.97957, 'auc': 0.57002, 'ap': 0.02855}
2025-06-20 21:12:06,328 - INFO - val: {'epoch': 91, 'time_epoch': 11.13644, 'loss': 0.07511384, 'lr': 0, 'params': 9588956, 'time_iter': 0.12949, 'accuracy': 0.96442, 'auc': 0.53449, 'ap': 0.02664}
2025-06-20 21:12:19,482 - INFO - test: {'epoch': 91, 'time_epoch': 11.93396, 'loss': 0.07765889, 'lr': 0, 'params': 9588956, 'time_iter': 0.13877, 'accuracy': 0.96344, 'auc': 0.52188, 'ap': 0.02684}
2025-06-20 21:12:19,485 - INFO - > Epoch 91: took 233.6s (avg 236.4s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 21:15:48,103 - INFO - train: {'epoch': 92, 'time_epoch': 199.26585, 'eta': 1404.64631, 'eta_hours': 0.39018, 'loss': 0.05472046, 'lr': 8.7e-06, 'params': 9588956, 'time_iter': 0.2909, 'accuracy': 0.97952, 'auc': 0.57236, 'ap': 0.0283}
2025-06-20 21:16:00,450 - INFO - val: {'epoch': 92, 'time_epoch': 11.08441, 'loss': 0.07377206, 'lr': 0, 'params': 9588956, 'time_iter': 0.12889, 'accuracy': 0.96982, 'auc': 0.53446, 'ap': 0.0267}
2025-06-20 21:16:13,693 - INFO - test: {'epoch': 92, 'time_epoch': 12.00189, 'loss': 0.07629812, 'lr': 0, 'params': 9588956, 'time_iter': 0.13956, 'accuracy': 0.96848, 'auc': 0.52189, 'ap': 0.0269}
2025-06-20 21:16:13,696 - INFO - > Epoch 92: took 234.2s (avg 236.4s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 21:19:39,782 - INFO - train: {'epoch': 93, 'time_epoch': 196.73206, 'eta': 1203.73159, 'eta_hours': 0.33437, 'loss': 0.05471229, 'lr': 6.67e-06, 'params': 9588956, 'time_iter': 0.2872, 'accuracy': 0.97953, 'auc': 0.57051, 'ap': 0.02856}
2025-06-20 21:19:52,112 - INFO - val: {'epoch': 93, 'time_epoch': 11.08052, 'loss': 0.07449101, 'lr': 0, 'params': 9588956, 'time_iter': 0.12884, 'accuracy': 0.96442, 'auc': 0.53459, 'ap': 0.02659}
2025-06-20 21:20:05,311 - INFO - test: {'epoch': 93, 'time_epoch': 11.98882, 'loss': 0.07702858, 'lr': 0, 'params': 9588956, 'time_iter': 0.1394, 'accuracy': 0.96344, 'auc': 0.52186, 'ap': 0.02683}
2025-06-20 21:20:05,313 - INFO - > Epoch 93: took 231.6s (avg 236.4s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 21:23:34,314 - INFO - train: {'epoch': 94, 'time_epoch': 199.62174, 'eta': 1003.05702, 'eta_hours': 0.27863, 'loss': 0.05471189, 'lr': 4.91e-06, 'params': 9588956, 'time_iter': 0.29142, 'accuracy': 0.97955, 'auc': 0.57179, 'ap': 0.02878}
2025-06-20 21:23:46,600 - INFO - val: {'epoch': 94, 'time_epoch': 11.04901, 'loss': 0.0733587, 'lr': 0, 'params': 9588956, 'time_iter': 0.12848, 'accuracy': 0.96982, 'auc': 0.53274, 'ap': 0.02655}
2025-06-20 21:23:59,805 - INFO - test: {'epoch': 94, 'time_epoch': 11.96164, 'loss': 0.0758817, 'lr': 0, 'params': 9588956, 'time_iter': 0.13909, 'accuracy': 0.96848, 'auc': 0.52056, 'ap': 0.02678}
2025-06-20 21:23:59,808 - INFO - > Epoch 94: took 234.5s (avg 236.3s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 21:27:26,277 - INFO - train: {'epoch': 95, 'time_epoch': 197.19783, 'eta': 802.30338, 'eta_hours': 0.22286, 'loss': 0.05471427, 'lr': 3.41e-06, 'params': 9588956, 'time_iter': 0.28788, 'accuracy': 0.97955, 'auc': 0.57067, 'ap': 0.0285}
2025-06-20 21:27:38,665 - INFO - val: {'epoch': 95, 'time_epoch': 11.13262, 'loss': 0.07367436, 'lr': 0, 'params': 9588956, 'time_iter': 0.12945, 'accuracy': 0.96982, 'auc': 0.5336, 'ap': 0.02654}
2025-06-20 21:27:51,903 - INFO - test: {'epoch': 95, 'time_epoch': 12.00051, 'loss': 0.0762, 'lr': 0, 'params': 9588956, 'time_iter': 0.13954, 'accuracy': 0.96848, 'auc': 0.52088, 'ap': 0.02675}
2025-06-20 21:27:51,906 - INFO - > Epoch 95: took 232.1s (avg 236.3s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 21:31:20,015 - INFO - train: {'epoch': 96, 'time_epoch': 198.74718, 'eta': 601.67098, 'eta_hours': 0.16713, 'loss': 0.05472407, 'lr': 2.18e-06, 'params': 9588956, 'time_iter': 0.29014, 'accuracy': 0.97958, 'auc': 0.57217, 'ap': 0.02831}
2025-06-20 21:31:32,361 - INFO - val: {'epoch': 96, 'time_epoch': 11.09119, 'loss': 0.07430896, 'lr': 0, 'params': 9588956, 'time_iter': 0.12897, 'accuracy': 0.96442, 'auc': 0.53437, 'ap': 0.02655}
2025-06-20 21:31:45,561 - INFO - test: {'epoch': 96, 'time_epoch': 11.96051, 'loss': 0.07684339, 'lr': 0, 'params': 9588956, 'time_iter': 0.13908, 'accuracy': 0.96344, 'auc': 0.52139, 'ap': 0.02678}
2025-06-20 21:31:45,563 - INFO - > Epoch 96: took 233.7s (avg 236.3s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 21:35:14,183 - INFO - train: {'epoch': 97, 'time_epoch': 199.34474, 'eta': 401.08925, 'eta_hours': 0.11141, 'loss': 0.05471951, 'lr': 1.23e-06, 'params': 9588956, 'time_iter': 0.29101, 'accuracy': 0.97954, 'auc': 0.56931, 'ap': 0.02836}
2025-06-20 21:35:26,562 - INFO - val: {'epoch': 97, 'time_epoch': 11.10346, 'loss': 0.07487487, 'lr': 0, 'params': 9588956, 'time_iter': 0.12911, 'accuracy': 0.96442, 'auc': 0.53482, 'ap': 0.02657}
2025-06-20 21:35:39,797 - INFO - test: {'epoch': 97, 'time_epoch': 11.9926, 'loss': 0.07741802, 'lr': 0, 'params': 9588956, 'time_iter': 0.13945, 'accuracy': 0.96344, 'auc': 0.52157, 'ap': 0.02681}
2025-06-20 21:35:39,799 - INFO - > Epoch 97: took 234.2s (avg 236.2s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 21:39:06,550 - INFO - train: {'epoch': 98, 'time_epoch': 197.43374, 'eta': 200.5132, 'eta_hours': 0.0557, 'loss': 0.05472676, 'lr': 5.5e-07, 'params': 9588956, 'time_iter': 0.28822, 'accuracy': 0.97958, 'auc': 0.57356, 'ap': 0.02874}
2025-06-20 21:39:18,881 - INFO - val: {'epoch': 98, 'time_epoch': 11.08561, 'loss': 0.07478973, 'lr': 0, 'params': 9588956, 'time_iter': 0.1289, 'accuracy': 0.96442, 'auc': 0.53412, 'ap': 0.02655}
2025-06-20 21:39:32,105 - INFO - test: {'epoch': 98, 'time_epoch': 11.97924, 'loss': 0.07733113, 'lr': 0, 'params': 9588956, 'time_iter': 0.13929, 'accuracy': 0.96344, 'auc': 0.52162, 'ap': 0.02679}
2025-06-20 21:39:32,108 - INFO - > Epoch 98: took 232.3s (avg 236.2s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 21:43:00,247 - INFO - train: {'epoch': 99, 'time_epoch': 198.80429, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.05472087, 'lr': 1.4e-07, 'params': 9588956, 'time_iter': 0.29023, 'accuracy': 0.97953, 'auc': 0.57104, 'ap': 0.02844}
2025-06-20 21:43:12,644 - INFO - val: {'epoch': 99, 'time_epoch': 11.14402, 'loss': 0.07362418, 'lr': 0, 'params': 9588956, 'time_iter': 0.12958, 'accuracy': 0.96982, 'auc': 0.53436, 'ap': 0.02652}
2025-06-20 21:43:25,865 - INFO - test: {'epoch': 99, 'time_epoch': 12.0092, 'loss': 0.07614659, 'lr': 0, 'params': 9588956, 'time_iter': 0.13964, 'accuracy': 0.96848, 'auc': 0.52149, 'ap': 0.0267}
2025-06-20 21:43:30,260 - INFO - > Epoch 99: took 233.8s (avg 236.2s) | Best so far: epoch 3	train_loss: 0.0533 train_ap: 0.0432	val_loss: 0.0705 val_ap: 0.0505	test_loss: 0.0728 test_ap: 0.0510
2025-06-20 21:43:30,260 - INFO - Avg time per epoch: 236.18s
2025-06-20 21:43:30,260 - INFO - Total train loop time: 6.56h
2025-06-20 21:43:30,420 - INFO - Task done, results saved in results/molpcba/molpcba-Vanilla-45
2025-06-20 21:43:30,421 - INFO - Total time: 24334.07s (6.76h)
2025-06-20 21:43:30,427 - INFO - Results aggregated across runs saved in results/molpcba/molpcba-Vanilla-45/agg
2025-06-20 21:43:30,427 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-06-20 21:43:30,427 - INFO - Results saved in: results/molpcba/molpcba-Vanilla-45
2025-06-20 21:43:30,427 - INFO - Test results JSON files saved in: results/molpcba/molpcba-Vanilla-45/test_results/
