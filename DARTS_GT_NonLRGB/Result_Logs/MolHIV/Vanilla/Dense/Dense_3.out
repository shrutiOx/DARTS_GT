Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          251Gi       8.7Gi       168Gi       2.4Gi        74Gi       237Gi
Swap:         1.9Gi        26Mi       1.8Gi
Sun Aug 17 02:28:15 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA TITAN RTX               On  |   00000000:1B:00.0 Off |                  N/A |
| 41%   38C    P8             34W /  280W |       1MiB /  24576MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 45
Starting training for seed 45...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/TRANS
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/TRANS/confignas.yaml
Using device: cuda
2025-08-17 02:28:43,672 - INFO - GPU Mem: 25.2GB
2025-08-17 02:28:43,672 - INFO - Run directory: results/molhiv/molhiv-Vanilla-45
2025-08-17 02:28:43,672 - INFO - Seed: 45
2025-08-17 02:28:43,672 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-17 02:28:43,672 - INFO - Routing mode: none
2025-08-17 02:28:43,672 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-17 02:28:43,672 - INFO - Number of layers: 15
2025-08-17 02:28:43,672 - INFO - Uncertainty enabled: False
2025-08-17 02:28:43,672 - INFO - Training mode: custom
2025-08-17 02:28:43,673 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-17 02:28:43,673 - INFO - Additional features: Router weights logging + JSON export
2025-08-17 02:28:51,671 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 02:28:51,684 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-17 02:28:51,766 - INFO -   undirected: True
2025-08-17 02:28:51,766 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 02:28:51,767 - INFO -   avg num_nodes/graph: 25
2025-08-17 02:28:51,767 - INFO -   num node features: 9
2025-08-17 02:28:51,767 - INFO -   num edge features: 3
2025-08-17 02:28:51,767 - INFO -   num tasks: 1
2025-08-17 02:28:51,767 - INFO -   num classes: 2
2025-08-17 02:28:51,768 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-17 02:28:51,768 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-17 02:28:51,771 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 19%|█▊        | 7689/41127 [00:10<00:43, 768.89it/s] 37%|███▋      | 15209/41127 [00:20<00:34, 758.92it/s] 55%|█████▌    | 22625/41127 [00:30<00:24, 750.99it/s] 73%|███████▎  | 30039/41127 [00:40<00:14, 747.17it/s] 92%|█████████▏| 37649/41127 [00:50<00:04, 752.14it/s]100%|██████████| 41127/41127 [00:55<00:00, 742.78it/s]
2025-08-17 02:29:48,100 - INFO - Done! Took 00:00:56.33
2025-08-17 02:29:48,238 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-17 02:29:48,608 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-17 02:29:48,609 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-08-17 02:29:48,609 - INFO - Inner model has get_darts_model: False
2025-08-17 02:29:48,612 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-08-17 02:29:48,615 - INFO - Number of parameters: 514,193
2025-08-17 02:29:48,615 - INFO - Starting optimized training: 2025-08-17 02:29:48.615486
2025-08-17 02:29:54,542 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 02:29:54,543 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-17 02:29:54,544 - INFO -   undirected: True
2025-08-17 02:29:54,544 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 02:29:54,545 - INFO -   avg num_nodes/graph: 25
2025-08-17 02:29:54,545 - INFO -   num node features: 9
2025-08-17 02:29:54,545 - INFO -   num edge features: 3
2025-08-17 02:29:54,545 - INFO -   num tasks: 1
2025-08-17 02:29:54,545 - INFO -   num classes: 2
2025-08-17 02:29:54,545 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-17 02:29:54,546 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-17 02:29:54,549 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 17%|█▋        | 6916/41127 [00:10<00:49, 691.57it/s] 34%|███▎      | 13823/41127 [00:20<00:39, 691.05it/s] 51%|█████     | 20856/41127 [00:30<00:29, 696.64it/s] 67%|██████▋   | 27698/41127 [00:40<00:19, 691.72it/s] 84%|████████▍ | 34557/41127 [00:50<00:09, 689.59it/s]100%|██████████| 41127/41127 [00:59<00:00, 691.71it/s]
2025-08-17 02:30:54,982 - INFO - Done! Took 00:01:00.44
2025-08-17 02:30:55,127 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-17 02:30:55,144 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-17 02:30:55,144 - INFO - Start from epoch 0
2025-08-17 02:32:13,201 - INFO - train: {'epoch': 0, 'time_epoch': 77.3958, 'eta': 7662.18381, 'eta_hours': 2.12838, 'loss': 0.76734916, 'lr': 0.0, 'params': 514193, 'time_iter': 0.07521, 'accuracy': 0.05231, 'precision': 0.03775, 'recall': 0.99269, 'f1': 0.07274, 'auc': 0.47526}
2025-08-17 02:32:13,209 - INFO - ...computing epoch stats took: 0.65s
2025-08-17 02:32:18,854 - INFO - val: {'epoch': 0, 'time_epoch': 5.63029, 'loss': 0.75830096, 'lr': 0, 'params': 514193, 'time_iter': 0.04365, 'accuracy': 0.0423, 'precision': 0.02015, 'recall': 1.0, 'f1': 0.0395, 'auc': 0.53335}
2025-08-17 02:32:18,856 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 02:32:24,053 - INFO - test: {'epoch': 0, 'time_epoch': 5.18268, 'loss': 0.75526104, 'lr': 0, 'params': 514193, 'time_iter': 0.04018, 'accuracy': 0.07416, 'precision': 0.03206, 'recall': 0.96923, 'f1': 0.06207, 'auc': 0.51533}
2025-08-17 02:32:24,055 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 02:32:24,056 - INFO - > Epoch 0: took 88.9s (avg 88.9s) | Best so far: epoch 0	train_loss: 0.7673 train_auc: 0.4753	val_loss: 0.7583 val_auc: 0.5333	test_loss: 0.7553 test_auc: 0.5153
2025-08-17 02:33:35,073 - INFO - train: {'epoch': 1, 'time_epoch': 70.95089, 'eta': 7268.98742, 'eta_hours': 2.01916, 'loss': 0.47989067, 'lr': 2e-05, 'params': 514193, 'time_iter': 0.06895, 'accuracy': 0.80229, 'precision': 0.0341, 'recall': 0.15666, 'f1': 0.05602, 'auc': 0.50475}
2025-08-17 02:33:35,080 - INFO - ...computing epoch stats took: 0.05s
2025-08-17 02:33:39,751 - INFO - val: {'epoch': 1, 'time_epoch': 4.65571, 'loss': 0.24448407, 'lr': 0, 'params': 514193, 'time_iter': 0.03609, 'accuracy': 0.97933, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.60852}
2025-08-17 02:33:39,753 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 02:33:44,441 - INFO - test: {'epoch': 1, 'time_epoch': 4.6731, 'loss': 0.24878573, 'lr': 0, 'params': 514193, 'time_iter': 0.03623, 'accuracy': 0.96815, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.59188}
2025-08-17 02:33:44,442 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 02:33:44,442 - INFO - > Epoch 1: took 80.4s (avg 84.6s) | Best so far: epoch 1	train_loss: 0.4799 train_auc: 0.5048	val_loss: 0.2445 val_auc: 0.6085	test_loss: 0.2488 test_auc: 0.5919
2025-08-17 02:34:54,618 - INFO - train: {'epoch': 2, 'time_epoch': 70.11309, 'eta': 7063.53267, 'eta_hours': 1.96209, 'loss': 0.18559035, 'lr': 4e-05, 'params': 514193, 'time_iter': 0.06814, 'accuracy': 0.96249, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6003}
2025-08-17 02:34:54,625 - INFO - ...computing epoch stats took: 0.05s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:34:59,316 - INFO - val: {'epoch': 2, 'time_epoch': 4.66583, 'loss': 0.10516917, 'lr': 0, 'params': 514193, 'time_iter': 0.03617, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.65251}
2025-08-17 02:34:59,318 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:35:03,993 - INFO - test: {'epoch': 2, 'time_epoch': 4.66072, 'loss': 0.13887846, 'lr': 0, 'params': 514193, 'time_iter': 0.03613, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66789}
2025-08-17 02:35:03,995 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 02:35:03,995 - INFO - > Epoch 2: took 79.6s (avg 83.0s) | Best so far: epoch 2	train_loss: 0.1856 train_auc: 0.6003	val_loss: 0.1052 val_auc: 0.6525	test_loss: 0.1389 test_auc: 0.6679
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:36:16,043 - INFO - train: {'epoch': 3, 'time_epoch': 71.99327, 'eta': 6970.87297, 'eta_hours': 1.93635, 'loss': 0.15474537, 'lr': 6e-05, 'params': 514193, 'time_iter': 0.06996, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.65819}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:36:20,945 - INFO - val: {'epoch': 3, 'time_epoch': 4.88076, 'loss': 0.09654591, 'lr': 0, 'params': 514193, 'time_iter': 0.03784, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72403}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:36:25,817 - INFO - test: {'epoch': 3, 'time_epoch': 4.85503, 'loss': 0.13317287, 'lr': 0, 'params': 514193, 'time_iter': 0.03764, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69046}
2025-08-17 02:36:25,819 - INFO - > Epoch 3: took 81.8s (avg 82.7s) | Best so far: epoch 3	train_loss: 0.1547 train_auc: 0.6582	val_loss: 0.0965 val_auc: 0.7240	test_loss: 0.1332 test_auc: 0.6905
2025-08-17 02:37:37,634 - INFO - train: {'epoch': 4, 'time_epoch': 71.75099, 'eta': 6881.87661, 'eta_hours': 1.91163, 'loss': 0.14652263, 'lr': 8e-05, 'params': 514193, 'time_iter': 0.06973, 'accuracy': 0.96271, 'precision': 0.85714, 'recall': 0.00487, 'f1': 0.00969, 'auc': 0.70883}
2025-08-17 02:37:42,403 - INFO - val: {'epoch': 4, 'time_epoch': 4.74521, 'loss': 0.0961144, 'lr': 0, 'params': 514193, 'time_iter': 0.03678, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.01235, 'f1': 0.0241, 'auc': 0.69023}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:37:47,158 - INFO - test: {'epoch': 4, 'time_epoch': 4.73643, 'loss': 0.1296029, 'lr': 0, 'params': 514193, 'time_iter': 0.03672, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72223}
2025-08-17 02:37:47,160 - INFO - > Epoch 4: took 81.3s (avg 82.4s) | Best so far: epoch 3	train_loss: 0.1547 train_auc: 0.6582	val_loss: 0.0965 val_auc: 0.7240	test_loss: 0.1332 test_auc: 0.6905
2025-08-17 02:38:56,611 - INFO - train: {'epoch': 5, 'time_epoch': 69.38892, 'eta': 6761.62291, 'eta_hours': 1.87823, 'loss': 0.14053437, 'lr': 0.0001, 'params': 514193, 'time_iter': 0.06743, 'accuracy': 0.96268, 'precision': 0.54762, 'recall': 0.01867, 'f1': 0.03611, 'auc': 0.73585}
2025-08-17 02:39:01,297 - INFO - val: {'epoch': 5, 'time_epoch': 4.66375, 'loss': 0.09130253, 'lr': 0, 'params': 514193, 'time_iter': 0.03615, 'accuracy': 0.98006, 'precision': 0.4, 'recall': 0.02469, 'f1': 0.04651, 'auc': 0.72141}
2025-08-17 02:39:05,971 - INFO - test: {'epoch': 5, 'time_epoch': 4.65702, 'loss': 0.12281365, 'lr': 0, 'params': 514193, 'time_iter': 0.0361, 'accuracy': 0.96815, 'precision': 0.42857, 'recall': 0.02308, 'f1': 0.0438, 'auc': 0.73757}
2025-08-17 02:39:05,974 - INFO - > Epoch 5: took 78.8s (avg 81.8s) | Best so far: epoch 3	train_loss: 0.1547 train_auc: 0.6582	val_loss: 0.0965 val_auc: 0.7240	test_loss: 0.1332 test_auc: 0.6905
2025-08-17 02:40:17,398 - INFO - train: {'epoch': 6, 'time_epoch': 71.36122, 'eta': 6682.10544, 'eta_hours': 1.85614, 'loss': 0.13738518, 'lr': 9.997e-05, 'params': 514193, 'time_iter': 0.06935, 'accuracy': 0.96337, 'precision': 0.608, 'recall': 0.06169, 'f1': 0.11201, 'auc': 0.74799}
2025-08-17 02:40:22,017 - INFO - val: {'epoch': 6, 'time_epoch': 4.59692, 'loss': 0.10515928, 'lr': 0, 'params': 514193, 'time_iter': 0.03564, 'accuracy': 0.97836, 'precision': 0.1, 'recall': 0.01235, 'f1': 0.02198, 'auc': 0.68859}
2025-08-17 02:40:26,644 - INFO - test: {'epoch': 6, 'time_epoch': 4.60964, 'loss': 0.13350352, 'lr': 0, 'params': 514193, 'time_iter': 0.03573, 'accuracy': 0.96523, 'precision': 0.15789, 'recall': 0.02308, 'f1': 0.04027, 'auc': 0.72258}
2025-08-17 02:40:26,645 - INFO - > Epoch 6: took 80.7s (avg 81.6s) | Best so far: epoch 3	train_loss: 0.1547 train_auc: 0.6582	val_loss: 0.0965 val_auc: 0.7240	test_loss: 0.1332 test_auc: 0.6905
2025-08-17 02:41:36,436 - INFO - train: {'epoch': 7, 'time_epoch': 69.7259, 'eta': 6585.82084, 'eta_hours': 1.82939, 'loss': 0.13473044, 'lr': 9.989e-05, 'params': 514193, 'time_iter': 0.06776, 'accuracy': 0.96356, 'precision': 0.59116, 'recall': 0.08685, 'f1': 0.15145, 'auc': 0.75734}
2025-08-17 02:41:41,246 - INFO - val: {'epoch': 7, 'time_epoch': 4.78758, 'loss': 0.09721901, 'lr': 0, 'params': 514193, 'time_iter': 0.03711, 'accuracy': 0.97933, 'precision': 0.44737, 'recall': 0.20988, 'f1': 0.28571, 'auc': 0.73015}
2025-08-17 02:41:46,028 - INFO - test: {'epoch': 7, 'time_epoch': 4.76446, 'loss': 0.12891933, 'lr': 0, 'params': 514193, 'time_iter': 0.03693, 'accuracy': 0.96426, 'precision': 0.33333, 'recall': 0.13077, 'f1': 0.18785, 'auc': 0.74576}
2025-08-17 02:41:46,030 - INFO - > Epoch 7: took 79.4s (avg 81.4s) | Best so far: epoch 7	train_loss: 0.1347 train_auc: 0.7573	val_loss: 0.0972 val_auc: 0.7301	test_loss: 0.1289 test_auc: 0.7458
2025-08-17 02:42:58,120 - INFO - train: {'epoch': 8, 'time_epoch': 72.0244, 'eta': 6518.67856, 'eta_hours': 1.81074, 'loss': 0.13135307, 'lr': 9.975e-05, 'params': 514193, 'time_iter': 0.06999, 'accuracy': 0.96389, 'precision': 0.59244, 'recall': 0.11445, 'f1': 0.19184, 'auc': 0.78347}
2025-08-17 02:43:02,948 - INFO - val: {'epoch': 8, 'time_epoch': 4.80569, 'loss': 0.08913422, 'lr': 0, 'params': 514193, 'time_iter': 0.03725, 'accuracy': 0.98128, 'precision': 0.57692, 'recall': 0.18519, 'f1': 0.28037, 'auc': 0.73288}
2025-08-17 02:43:07,746 - INFO - test: {'epoch': 8, 'time_epoch': 4.78048, 'loss': 0.12304496, 'lr': 0, 'params': 514193, 'time_iter': 0.03706, 'accuracy': 0.97009, 'precision': 0.58974, 'recall': 0.17692, 'f1': 0.27219, 'auc': 0.74386}
2025-08-17 02:43:07,749 - INFO - > Epoch 8: took 81.7s (avg 81.4s) | Best so far: epoch 8	train_loss: 0.1314 train_auc: 0.7835	val_loss: 0.0891 val_auc: 0.7329	test_loss: 0.1230 test_auc: 0.7439
2025-08-17 02:44:19,840 - INFO - train: {'epoch': 9, 'time_epoch': 72.0266, 'eta': 6450.57962, 'eta_hours': 1.79183, 'loss': 0.13026077, 'lr': 9.956e-05, 'params': 514193, 'time_iter': 0.07, 'accuracy': 0.96508, 'precision': 0.64068, 'recall': 0.15341, 'f1': 0.24754, 'auc': 0.77498}
2025-08-17 02:44:24,657 - INFO - val: {'epoch': 9, 'time_epoch': 4.79484, 'loss': 0.08481515, 'lr': 0, 'params': 514193, 'time_iter': 0.03717, 'accuracy': 0.98006, 'precision': 0.33333, 'recall': 0.01235, 'f1': 0.02381, 'auc': 0.76675}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:44:29,427 - INFO - test: {'epoch': 9, 'time_epoch': 4.75255, 'loss': 0.12266366, 'lr': 0, 'params': 514193, 'time_iter': 0.03684, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75973}
2025-08-17 02:44:29,429 - INFO - > Epoch 9: took 81.7s (avg 81.4s) | Best so far: epoch 9	train_loss: 0.1303 train_auc: 0.7750	val_loss: 0.0848 val_auc: 0.7668	test_loss: 0.1227 test_auc: 0.7597
2025-08-17 02:45:41,790 - INFO - train: {'epoch': 10, 'time_epoch': 72.29513, 'eta': 6383.93927, 'eta_hours': 1.77332, 'loss': 0.12703417, 'lr': 9.932e-05, 'params': 514193, 'time_iter': 0.07026, 'accuracy': 0.96517, 'precision': 0.62647, 'recall': 0.17289, 'f1': 0.27099, 'auc': 0.78808}
2025-08-17 02:45:46,623 - INFO - val: {'epoch': 10, 'time_epoch': 4.80879, 'loss': 0.09050827, 'lr': 0, 'params': 514193, 'time_iter': 0.03728, 'accuracy': 0.97788, 'precision': 0.375, 'recall': 0.18519, 'f1': 0.24793, 'auc': 0.74039}
2025-08-17 02:45:51,425 - INFO - test: {'epoch': 10, 'time_epoch': 4.78554, 'loss': 0.12289671, 'lr': 0, 'params': 514193, 'time_iter': 0.0371, 'accuracy': 0.96693, 'precision': 0.45312, 'recall': 0.22308, 'f1': 0.29897, 'auc': 0.75641}
2025-08-17 02:45:51,427 - INFO - > Epoch 10: took 82.0s (avg 81.5s) | Best so far: epoch 9	train_loss: 0.1303 train_auc: 0.7750	val_loss: 0.0848 val_auc: 0.7668	test_loss: 0.1227 test_auc: 0.7597
2025-08-17 02:47:03,944 - INFO - train: {'epoch': 11, 'time_epoch': 72.45137, 'eta': 6317.50216, 'eta_hours': 1.75486, 'loss': 0.12632021, 'lr': 9.902e-05, 'params': 514193, 'time_iter': 0.07041, 'accuracy': 0.96511, 'precision': 0.61602, 'recall': 0.18101, 'f1': 0.2798, 'auc': 0.79805}
2025-08-17 02:47:08,771 - INFO - val: {'epoch': 11, 'time_epoch': 4.80456, 'loss': 0.08773912, 'lr': 0, 'params': 514193, 'time_iter': 0.03724, 'accuracy': 0.9786, 'precision': 0.41026, 'recall': 0.19753, 'f1': 0.26667, 'auc': 0.72341}
2025-08-17 02:47:13,609 - INFO - test: {'epoch': 11, 'time_epoch': 4.81973, 'loss': 0.12501789, 'lr': 0, 'params': 514193, 'time_iter': 0.03736, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.16154, 'f1': 0.24419, 'auc': 0.743}
2025-08-17 02:47:13,611 - INFO - > Epoch 11: took 82.2s (avg 81.5s) | Best so far: epoch 9	train_loss: 0.1303 train_auc: 0.7750	val_loss: 0.0848 val_auc: 0.7668	test_loss: 0.1227 test_auc: 0.7597
2025-08-17 02:48:25,875 - INFO - train: {'epoch': 12, 'time_epoch': 72.2011, 'eta': 6248.46495, 'eta_hours': 1.73568, 'loss': 0.12292209, 'lr': 9.867e-05, 'params': 514193, 'time_iter': 0.07017, 'accuracy': 0.9662, 'precision': 0.64423, 'recall': 0.21753, 'f1': 0.32524, 'auc': 0.80356}
2025-08-17 02:48:30,630 - INFO - val: {'epoch': 12, 'time_epoch': 4.73098, 'loss': 0.08362487, 'lr': 0, 'params': 514193, 'time_iter': 0.03667, 'accuracy': 0.98177, 'precision': 0.625, 'recall': 0.18519, 'f1': 0.28571, 'auc': 0.74415}
2025-08-17 02:48:35,380 - INFO - test: {'epoch': 12, 'time_epoch': 4.73086, 'loss': 0.1178488, 'lr': 0, 'params': 514193, 'time_iter': 0.03667, 'accuracy': 0.96961, 'precision': 0.58065, 'recall': 0.13846, 'f1': 0.2236, 'auc': 0.76153}
2025-08-17 02:48:35,383 - INFO - > Epoch 12: took 81.8s (avg 81.6s) | Best so far: epoch 9	train_loss: 0.1303 train_auc: 0.7750	val_loss: 0.0848 val_auc: 0.7668	test_loss: 0.1227 test_auc: 0.7597
2025-08-17 02:49:47,033 - INFO - train: {'epoch': 13, 'time_epoch': 71.58533, 'eta': 6175.19316, 'eta_hours': 1.71533, 'loss': 0.12082454, 'lr': 9.826e-05, 'params': 514193, 'time_iter': 0.06957, 'accuracy': 0.96672, 'precision': 0.66118, 'recall': 0.22808, 'f1': 0.33917, 'auc': 0.81144}
2025-08-17 02:49:51,849 - INFO - val: {'epoch': 13, 'time_epoch': 4.79293, 'loss': 0.08236557, 'lr': 0, 'params': 514193, 'time_iter': 0.03715, 'accuracy': 0.9786, 'precision': 0.41463, 'recall': 0.20988, 'f1': 0.27869, 'auc': 0.76945}
2025-08-17 02:49:56,662 - INFO - test: {'epoch': 13, 'time_epoch': 4.79516, 'loss': 0.1237995, 'lr': 0, 'params': 514193, 'time_iter': 0.03717, 'accuracy': 0.96742, 'precision': 0.46429, 'recall': 0.2, 'f1': 0.27957, 'auc': 0.75444}
2025-08-17 02:49:56,664 - INFO - > Epoch 13: took 81.3s (avg 81.5s) | Best so far: epoch 13	train_loss: 0.1208 train_auc: 0.8114	val_loss: 0.0824 val_auc: 0.7694	test_loss: 0.1238 test_auc: 0.7544
2025-08-17 02:51:07,610 - INFO - train: {'epoch': 14, 'time_epoch': 70.88315, 'eta': 6098.16719, 'eta_hours': 1.69394, 'loss': 0.11907967, 'lr': 9.78e-05, 'params': 514193, 'time_iter': 0.06889, 'accuracy': 0.9669, 'precision': 0.65577, 'recall': 0.24432, 'f1': 0.356, 'auc': 0.82107}
2025-08-17 02:51:12,304 - INFO - val: {'epoch': 14, 'time_epoch': 4.67148, 'loss': 0.09142836, 'lr': 0, 'params': 514193, 'time_iter': 0.03621, 'accuracy': 0.97812, 'precision': 0.33333, 'recall': 0.11111, 'f1': 0.16667, 'auc': 0.71287}
2025-08-17 02:51:17,052 - INFO - test: {'epoch': 14, 'time_epoch': 4.73127, 'loss': 0.12280012, 'lr': 0, 'params': 514193, 'time_iter': 0.03668, 'accuracy': 0.96912, 'precision': 0.53333, 'recall': 0.18462, 'f1': 0.27429, 'auc': 0.75226}
2025-08-17 02:51:17,055 - INFO - > Epoch 14: took 80.4s (avg 81.5s) | Best so far: epoch 13	train_loss: 0.1208 train_auc: 0.8114	val_loss: 0.0824 val_auc: 0.7694	test_loss: 0.1238 test_auc: 0.7544
2025-08-17 02:52:27,417 - INFO - train: {'epoch': 15, 'time_epoch': 70.29859, 'eta': 6018.84014, 'eta_hours': 1.6719, 'loss': 0.11813576, 'lr': 9.729e-05, 'params': 514193, 'time_iter': 0.06832, 'accuracy': 0.96757, 'precision': 0.69504, 'recall': 0.23864, 'f1': 0.35529, 'auc': 0.8238}
2025-08-17 02:52:32,131 - INFO - val: {'epoch': 15, 'time_epoch': 4.69266, 'loss': 0.08755708, 'lr': 0, 'params': 514193, 'time_iter': 0.03638, 'accuracy': 0.97763, 'precision': 0.38298, 'recall': 0.22222, 'f1': 0.28125, 'auc': 0.77521}
2025-08-17 02:52:36,802 - INFO - test: {'epoch': 15, 'time_epoch': 4.65371, 'loss': 0.123058, 'lr': 0, 'params': 514193, 'time_iter': 0.03608, 'accuracy': 0.96548, 'precision': 0.40909, 'recall': 0.20769, 'f1': 0.27551, 'auc': 0.7684}
2025-08-17 02:52:36,805 - INFO - > Epoch 15: took 79.7s (avg 81.4s) | Best so far: epoch 15	train_loss: 0.1181 train_auc: 0.8238	val_loss: 0.0876 val_auc: 0.7752	test_loss: 0.1231 test_auc: 0.7684
2025-08-17 02:53:47,012 - INFO - train: {'epoch': 16, 'time_epoch': 70.14475, 'eta': 5939.82416, 'eta_hours': 1.64995, 'loss': 0.11749485, 'lr': 9.673e-05, 'params': 514193, 'time_iter': 0.06817, 'accuracy': 0.96806, 'precision': 0.70246, 'recall': 0.25487, 'f1': 0.37403, 'auc': 0.82198}
2025-08-17 02:53:51,658 - INFO - val: {'epoch': 16, 'time_epoch': 4.62186, 'loss': 0.08345161, 'lr': 0, 'params': 514193, 'time_iter': 0.03583, 'accuracy': 0.97933, 'precision': 0.45, 'recall': 0.22222, 'f1': 0.29752, 'auc': 0.78038}
2025-08-17 02:53:56,305 - INFO - test: {'epoch': 16, 'time_epoch': 4.6301, 'loss': 0.11976156, 'lr': 0, 'params': 514193, 'time_iter': 0.03589, 'accuracy': 0.96888, 'precision': 0.51316, 'recall': 0.3, 'f1': 0.37864, 'auc': 0.76355}
2025-08-17 02:53:56,307 - INFO - > Epoch 16: took 79.5s (avg 81.2s) | Best so far: epoch 16	train_loss: 0.1175 train_auc: 0.8220	val_loss: 0.0835 val_auc: 0.7804	test_loss: 0.1198 test_auc: 0.7635
2025-08-17 02:55:08,002 - INFO - train: {'epoch': 17, 'time_epoch': 71.63067, 'eta': 5868.56306, 'eta_hours': 1.63016, 'loss': 0.11492249, 'lr': 9.611e-05, 'params': 514193, 'time_iter': 0.06961, 'accuracy': 0.96812, 'precision': 0.68191, 'recall': 0.27841, 'f1': 0.39539, 'auc': 0.83688}
2025-08-17 02:55:12,698 - INFO - val: {'epoch': 17, 'time_epoch': 4.67106, 'loss': 0.08373313, 'lr': 0, 'params': 514193, 'time_iter': 0.03621, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.19753, 'f1': 0.28319, 'auc': 0.76833}
2025-08-17 02:55:17,427 - INFO - test: {'epoch': 17, 'time_epoch': 4.71194, 'loss': 0.12219545, 'lr': 0, 'params': 514193, 'time_iter': 0.03653, 'accuracy': 0.96888, 'precision': 0.52083, 'recall': 0.19231, 'f1': 0.2809, 'auc': 0.77352}
2025-08-17 02:55:17,429 - INFO - > Epoch 17: took 81.1s (avg 81.2s) | Best so far: epoch 16	train_loss: 0.1175 train_auc: 0.8220	val_loss: 0.0835 val_auc: 0.7804	test_loss: 0.1198 test_auc: 0.7635
2025-08-17 02:56:28,222 - INFO - train: {'epoch': 18, 'time_epoch': 70.73105, 'eta': 5793.42785, 'eta_hours': 1.60929, 'loss': 0.11314948, 'lr': 9.545e-05, 'params': 514193, 'time_iter': 0.06874, 'accuracy': 0.96833, 'precision': 0.69388, 'recall': 0.27597, 'f1': 0.39489, 'auc': 0.84473}
2025-08-17 02:56:32,922 - INFO - val: {'epoch': 18, 'time_epoch': 4.67804, 'loss': 0.08882131, 'lr': 0, 'params': 514193, 'time_iter': 0.03626, 'accuracy': 0.9786, 'precision': 0.42553, 'recall': 0.24691, 'f1': 0.3125, 'auc': 0.74584}
2025-08-17 02:56:37,599 - INFO - test: {'epoch': 18, 'time_epoch': 4.65996, 'loss': 0.12220034, 'lr': 0, 'params': 514193, 'time_iter': 0.03612, 'accuracy': 0.96693, 'precision': 0.45, 'recall': 0.20769, 'f1': 0.28421, 'auc': 0.76595}
2025-08-17 02:56:37,601 - INFO - > Epoch 18: took 80.2s (avg 81.2s) | Best so far: epoch 16	train_loss: 0.1175 train_auc: 0.8220	val_loss: 0.0835 val_auc: 0.7804	test_loss: 0.1198 test_auc: 0.7635
2025-08-17 02:57:48,309 - INFO - train: {'epoch': 19, 'time_epoch': 70.64416, 'eta': 5718.38549, 'eta_hours': 1.58844, 'loss': 0.11408795, 'lr': 9.474e-05, 'params': 514193, 'time_iter': 0.06865, 'accuracy': 0.96806, 'precision': 0.69296, 'recall': 0.2638, 'f1': 0.38213, 'auc': 0.84111}
2025-08-17 02:57:53,008 - INFO - val: {'epoch': 19, 'time_epoch': 4.67694, 'loss': 0.09113606, 'lr': 0, 'params': 514193, 'time_iter': 0.03626, 'accuracy': 0.97763, 'precision': 0.4, 'recall': 0.2716, 'f1': 0.32353, 'auc': 0.77098}
2025-08-17 02:57:57,689 - INFO - test: {'epoch': 19, 'time_epoch': 4.66465, 'loss': 0.12719317, 'lr': 0, 'params': 514193, 'time_iter': 0.03616, 'accuracy': 0.96377, 'precision': 0.4, 'recall': 0.29231, 'f1': 0.33778, 'auc': 0.77792}
2025-08-17 02:57:57,692 - INFO - > Epoch 19: took 80.1s (avg 81.1s) | Best so far: epoch 16	train_loss: 0.1175 train_auc: 0.8220	val_loss: 0.0835 val_auc: 0.7804	test_loss: 0.1198 test_auc: 0.7635
2025-08-17 02:59:08,198 - INFO - train: {'epoch': 20, 'time_epoch': 70.44387, 'eta': 5643.00852, 'eta_hours': 1.5675, 'loss': 0.11046402, 'lr': 9.397e-05, 'params': 514193, 'time_iter': 0.06846, 'accuracy': 0.969, 'precision': 0.70623, 'recall': 0.29464, 'f1': 0.41581, 'auc': 0.85508}
2025-08-17 02:59:12,891 - INFO - val: {'epoch': 20, 'time_epoch': 4.67049, 'loss': 0.08733783, 'lr': 0, 'params': 514193, 'time_iter': 0.03621, 'accuracy': 0.97763, 'precision': 0.39216, 'recall': 0.24691, 'f1': 0.30303, 'auc': 0.75877}
2025-08-17 02:59:17,603 - INFO - test: {'epoch': 20, 'time_epoch': 4.6949, 'loss': 0.12195002, 'lr': 0, 'params': 514193, 'time_iter': 0.03639, 'accuracy': 0.96791, 'precision': 0.4875, 'recall': 0.3, 'f1': 0.37143, 'auc': 0.76803}
2025-08-17 02:59:17,606 - INFO - > Epoch 20: took 79.9s (avg 81.1s) | Best so far: epoch 16	train_loss: 0.1175 train_auc: 0.8220	val_loss: 0.0835 val_auc: 0.7804	test_loss: 0.1198 test_auc: 0.7635
2025-08-17 03:00:28,403 - INFO - train: {'epoch': 21, 'time_epoch': 70.73435, 'eta': 5569.10989, 'eta_hours': 1.54697, 'loss': 0.11084741, 'lr': 9.316e-05, 'params': 514193, 'time_iter': 0.06874, 'accuracy': 0.96967, 'precision': 0.72587, 'recall': 0.30519, 'f1': 0.42971, 'auc': 0.85021}
2025-08-17 03:00:33,032 - INFO - val: {'epoch': 21, 'time_epoch': 4.60615, 'loss': 0.08548018, 'lr': 0, 'params': 514193, 'time_iter': 0.03571, 'accuracy': 0.98079, 'precision': 0.625, 'recall': 0.06173, 'f1': 0.11236, 'auc': 0.74887}
2025-08-17 03:00:37,678 - INFO - test: {'epoch': 21, 'time_epoch': 4.63037, 'loss': 0.12026283, 'lr': 0, 'params': 514193, 'time_iter': 0.03589, 'accuracy': 0.96766, 'precision': 0.2, 'recall': 0.00769, 'f1': 0.01481, 'auc': 0.74657}
2025-08-17 03:00:37,680 - INFO - > Epoch 21: took 80.1s (avg 81.0s) | Best so far: epoch 16	train_loss: 0.1175 train_auc: 0.8220	val_loss: 0.0835 val_auc: 0.7804	test_loss: 0.1198 test_auc: 0.7635
2025-08-17 03:01:49,249 - INFO - train: {'epoch': 22, 'time_epoch': 71.50447, 'eta': 5498.06466, 'eta_hours': 1.52724, 'loss': 0.1106349, 'lr': 9.23e-05, 'params': 514193, 'time_iter': 0.06949, 'accuracy': 0.96857, 'precision': 0.6988, 'recall': 0.28247, 'f1': 0.40231, 'auc': 0.85609}
2025-08-17 03:01:54,021 - INFO - val: {'epoch': 22, 'time_epoch': 4.75017, 'loss': 0.08185057, 'lr': 0, 'params': 514193, 'time_iter': 0.03682, 'accuracy': 0.97958, 'precision': 0.46341, 'recall': 0.23457, 'f1': 0.31148, 'auc': 0.78134}
2025-08-17 03:01:58,780 - INFO - test: {'epoch': 22, 'time_epoch': 4.74085, 'loss': 0.12196763, 'lr': 0, 'params': 514193, 'time_iter': 0.03675, 'accuracy': 0.96888, 'precision': 0.51786, 'recall': 0.22308, 'f1': 0.31183, 'auc': 0.76394}
2025-08-17 03:01:58,782 - INFO - > Epoch 22: took 81.1s (avg 81.0s) | Best so far: epoch 22	train_loss: 0.1106 train_auc: 0.8561	val_loss: 0.0819 val_auc: 0.7813	test_loss: 0.1220 test_auc: 0.7639
2025-08-17 03:03:10,319 - INFO - train: {'epoch': 23, 'time_epoch': 71.47008, 'eta': 5426.87227, 'eta_hours': 1.50746, 'loss': 0.1081967, 'lr': 9.14e-05, 'params': 514193, 'time_iter': 0.06946, 'accuracy': 0.96958, 'precision': 0.72, 'recall': 0.30682, 'f1': 0.43028, 'auc': 0.86202}
2025-08-17 03:03:15,075 - INFO - val: {'epoch': 23, 'time_epoch': 4.73274, 'loss': 0.09195726, 'lr': 0, 'params': 514193, 'time_iter': 0.03669, 'accuracy': 0.98055, 'precision': 0.51163, 'recall': 0.2716, 'f1': 0.35484, 'auc': 0.73654}
2025-08-17 03:03:19,749 - INFO - test: {'epoch': 23, 'time_epoch': 4.65787, 'loss': 0.12810638, 'lr': 0, 'params': 514193, 'time_iter': 0.03611, 'accuracy': 0.96693, 'precision': 0.45714, 'recall': 0.24615, 'f1': 0.32, 'auc': 0.75035}
2025-08-17 03:03:19,751 - INFO - > Epoch 23: took 81.0s (avg 81.0s) | Best so far: epoch 22	train_loss: 0.1106 train_auc: 0.8561	val_loss: 0.0819 val_auc: 0.7813	test_loss: 0.1220 test_auc: 0.7639
2025-08-17 03:04:30,228 - INFO - train: {'epoch': 24, 'time_epoch': 70.4138, 'eta': 5352.48881, 'eta_hours': 1.4868, 'loss': 0.10750538, 'lr': 9.045e-05, 'params': 514193, 'time_iter': 0.06843, 'accuracy': 0.96961, 'precision': 0.71887, 'recall': 0.30925, 'f1': 0.43246, 'auc': 0.86641}
2025-08-17 03:04:34,895 - INFO - val: {'epoch': 24, 'time_epoch': 4.64488, 'loss': 0.09235497, 'lr': 0, 'params': 514193, 'time_iter': 0.03601, 'accuracy': 0.97885, 'precision': 0.43478, 'recall': 0.24691, 'f1': 0.31496, 'auc': 0.75159}
2025-08-17 03:04:39,566 - INFO - test: {'epoch': 24, 'time_epoch': 4.65444, 'loss': 0.13052099, 'lr': 0, 'params': 514193, 'time_iter': 0.03608, 'accuracy': 0.96815, 'precision': 0.49231, 'recall': 0.24615, 'f1': 0.32821, 'auc': 0.74771}
2025-08-17 03:04:39,569 - INFO - > Epoch 24: took 79.8s (avg 81.0s) | Best so far: epoch 22	train_loss: 0.1106 train_auc: 0.8561	val_loss: 0.0819 val_auc: 0.7813	test_loss: 0.1220 test_auc: 0.7639
2025-08-17 03:05:50,168 - INFO - train: {'epoch': 25, 'time_epoch': 70.53527, 'eta': 5278.75643, 'eta_hours': 1.46632, 'loss': 0.10749952, 'lr': 8.946e-05, 'params': 514193, 'time_iter': 0.06855, 'accuracy': 0.96945, 'precision': 0.71619, 'recall': 0.30519, 'f1': 0.428, 'auc': 0.86676}
2025-08-17 03:05:54,851 - INFO - val: {'epoch': 25, 'time_epoch': 4.64854, 'loss': 0.08774212, 'lr': 0, 'params': 514193, 'time_iter': 0.03604, 'accuracy': 0.97933, 'precision': 0.45455, 'recall': 0.24691, 'f1': 0.32, 'auc': 0.75252}
2025-08-17 03:05:59,494 - INFO - test: {'epoch': 25, 'time_epoch': 4.6258, 'loss': 0.119939, 'lr': 0, 'params': 514193, 'time_iter': 0.03586, 'accuracy': 0.96937, 'precision': 0.53333, 'recall': 0.24615, 'f1': 0.33684, 'auc': 0.77052}
2025-08-17 03:05:59,496 - INFO - > Epoch 25: took 79.9s (avg 80.9s) | Best so far: epoch 22	train_loss: 0.1106 train_auc: 0.8561	val_loss: 0.0819 val_auc: 0.7813	test_loss: 0.1220 test_auc: 0.7639
2025-08-17 03:07:09,405 - INFO - train: {'epoch': 26, 'time_epoch': 69.84383, 'eta': 5203.39142, 'eta_hours': 1.44539, 'loss': 0.10529992, 'lr': 8.842e-05, 'params': 514193, 'time_iter': 0.06788, 'accuracy': 0.9704, 'precision': 0.73118, 'recall': 0.33117, 'f1': 0.45587, 'auc': 0.86895}
2025-08-17 03:07:14,072 - INFO - val: {'epoch': 26, 'time_epoch': 4.6444, 'loss': 0.07988534, 'lr': 0, 'params': 514193, 'time_iter': 0.036, 'accuracy': 0.98225, 'precision': 0.625, 'recall': 0.24691, 'f1': 0.35398, 'auc': 0.78143}
2025-08-17 03:07:18,704 - INFO - test: {'epoch': 26, 'time_epoch': 4.61442, 'loss': 0.12347981, 'lr': 0, 'params': 514193, 'time_iter': 0.03577, 'accuracy': 0.96742, 'precision': 0.46154, 'recall': 0.18462, 'f1': 0.26374, 'auc': 0.76773}
2025-08-17 03:07:18,707 - INFO - > Epoch 26: took 79.2s (avg 80.9s) | Best so far: epoch 26	train_loss: 0.1053 train_auc: 0.8690	val_loss: 0.0799 val_auc: 0.7814	test_loss: 0.1235 test_auc: 0.7677
2025-08-17 03:08:27,186 - INFO - train: {'epoch': 27, 'time_epoch': 68.41675, 'eta': 5124.75115, 'eta_hours': 1.42354, 'loss': 0.10452358, 'lr': 8.734e-05, 'params': 514193, 'time_iter': 0.06649, 'accuracy': 0.97024, 'precision': 0.7263, 'recall': 0.32955, 'f1': 0.45338, 'auc': 0.87378}
2025-08-17 03:08:31,548 - INFO - val: {'epoch': 27, 'time_epoch': 4.32953, 'loss': 0.0794395, 'lr': 0, 'params': 514193, 'time_iter': 0.03356, 'accuracy': 0.98079, 'precision': 0.52381, 'recall': 0.2716, 'f1': 0.35772, 'auc': 0.79626}
2025-08-17 03:08:35,813 - INFO - test: {'epoch': 27, 'time_epoch': 4.24874, 'loss': 0.12015553, 'lr': 0, 'params': 514193, 'time_iter': 0.03294, 'accuracy': 0.96912, 'precision': 0.52459, 'recall': 0.24615, 'f1': 0.33508, 'auc': 0.76539}
2025-08-17 03:08:35,816 - INFO - > Epoch 27: took 77.1s (avg 80.7s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:09:44,207 - INFO - train: {'epoch': 28, 'time_epoch': 68.32175, 'eta': 5046.58335, 'eta_hours': 1.40183, 'loss': 0.10273527, 'lr': 8.622e-05, 'params': 514193, 'time_iter': 0.0664, 'accuracy': 0.971, 'precision': 0.74645, 'recall': 0.34172, 'f1': 0.46882, 'auc': 0.8812}
2025-08-17 03:09:48,715 - INFO - val: {'epoch': 28, 'time_epoch': 4.48203, 'loss': 0.08259035, 'lr': 0, 'params': 514193, 'time_iter': 0.03474, 'accuracy': 0.97982, 'precision': 0.475, 'recall': 0.23457, 'f1': 0.31405, 'auc': 0.76684}
2025-08-17 03:09:53,059 - INFO - test: {'epoch': 28, 'time_epoch': 4.32691, 'loss': 0.12800125, 'lr': 0, 'params': 514193, 'time_iter': 0.03354, 'accuracy': 0.96596, 'precision': 0.38095, 'recall': 0.12308, 'f1': 0.18605, 'auc': 0.75185}
2025-08-17 03:09:53,062 - INFO - > Epoch 28: took 77.2s (avg 80.6s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:10:59,625 - INFO - train: {'epoch': 29, 'time_epoch': 66.50035, 'eta': 4964.82204, 'eta_hours': 1.37912, 'loss': 0.1014284, 'lr': 8.506e-05, 'params': 514193, 'time_iter': 0.06463, 'accuracy': 0.9707, 'precision': 0.72483, 'recall': 0.35065, 'f1': 0.47265, 'auc': 0.88781}
2025-08-17 03:11:04,262 - INFO - val: {'epoch': 29, 'time_epoch': 4.61543, 'loss': 0.08754376, 'lr': 0, 'params': 514193, 'time_iter': 0.03578, 'accuracy': 0.97982, 'precision': 0.47826, 'recall': 0.2716, 'f1': 0.34646, 'auc': 0.73737}
2025-08-17 03:11:08,931 - INFO - test: {'epoch': 29, 'time_epoch': 4.65233, 'loss': 0.12413043, 'lr': 0, 'params': 514193, 'time_iter': 0.03606, 'accuracy': 0.96815, 'precision': 0.49091, 'recall': 0.20769, 'f1': 0.29189, 'auc': 0.75478}
2025-08-17 03:11:08,936 - INFO - > Epoch 29: took 75.9s (avg 80.5s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:12:18,825 - INFO - train: {'epoch': 30, 'time_epoch': 69.82828, 'eta': 4891.45263, 'eta_hours': 1.35874, 'loss': 0.1007151, 'lr': 8.386e-05, 'params': 514193, 'time_iter': 0.06786, 'accuracy': 0.97094, 'precision': 0.72848, 'recall': 0.35714, 'f1': 0.4793, 'auc': 0.8851}
2025-08-17 03:12:23,465 - INFO - val: {'epoch': 30, 'time_epoch': 4.61685, 'loss': 0.08546471, 'lr': 0, 'params': 514193, 'time_iter': 0.03579, 'accuracy': 0.97982, 'precision': 0.47826, 'recall': 0.2716, 'f1': 0.34646, 'auc': 0.78122}
2025-08-17 03:12:28,099 - INFO - test: {'epoch': 30, 'time_epoch': 4.618, 'loss': 0.13135689, 'lr': 0, 'params': 514193, 'time_iter': 0.0358, 'accuracy': 0.96596, 'precision': 0.42424, 'recall': 0.21538, 'f1': 0.28571, 'auc': 0.77927}
2025-08-17 03:12:28,101 - INFO - > Epoch 30: took 79.2s (avg 80.4s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:13:37,298 - INFO - train: {'epoch': 31, 'time_epoch': 69.13414, 'eta': 4816.82949, 'eta_hours': 1.33801, 'loss': 0.10168122, 'lr': 8.263e-05, 'params': 514193, 'time_iter': 0.06719, 'accuracy': 0.97088, 'precision': 0.73379, 'recall': 0.34903, 'f1': 0.47305, 'auc': 0.88993}
2025-08-17 03:13:41,886 - INFO - val: {'epoch': 31, 'time_epoch': 4.56676, 'loss': 0.09449096, 'lr': 0, 'params': 514193, 'time_iter': 0.0354, 'accuracy': 0.97569, 'precision': 0.35385, 'recall': 0.28395, 'f1': 0.31507, 'auc': 0.78014}
2025-08-17 03:13:46,573 - INFO - test: {'epoch': 31, 'time_epoch': 4.56402, 'loss': 0.13177723, 'lr': 0, 'params': 514193, 'time_iter': 0.03538, 'accuracy': 0.96183, 'precision': 0.35165, 'recall': 0.24615, 'f1': 0.28959, 'auc': 0.78343}
2025-08-17 03:13:46,575 - INFO - > Epoch 31: took 78.5s (avg 80.4s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:14:54,924 - INFO - train: {'epoch': 32, 'time_epoch': 68.28737, 'eta': 4740.81982, 'eta_hours': 1.31689, 'loss': 0.09899982, 'lr': 8.136e-05, 'params': 514193, 'time_iter': 0.06636, 'accuracy': 0.97176, 'precision': 0.75986, 'recall': 0.35958, 'f1': 0.48815, 'auc': 0.897}
2025-08-17 03:14:59,529 - INFO - val: {'epoch': 32, 'time_epoch': 4.58396, 'loss': 0.08578186, 'lr': 0, 'params': 514193, 'time_iter': 0.03553, 'accuracy': 0.98006, 'precision': 0.48889, 'recall': 0.2716, 'f1': 0.34921, 'auc': 0.75899}
2025-08-17 03:15:04,271 - INFO - test: {'epoch': 32, 'time_epoch': 4.72407, 'loss': 0.12540694, 'lr': 0, 'params': 514193, 'time_iter': 0.03662, 'accuracy': 0.96742, 'precision': 0.47059, 'recall': 0.24615, 'f1': 0.32323, 'auc': 0.76665}
2025-08-17 03:15:04,273 - INFO - > Epoch 32: took 77.7s (avg 80.3s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:16:12,995 - INFO - train: {'epoch': 33, 'time_epoch': 68.66012, 'eta': 4665.98799, 'eta_hours': 1.29611, 'loss': 0.09792491, 'lr': 8.005e-05, 'params': 514193, 'time_iter': 0.06673, 'accuracy': 0.97173, 'precision': 0.74673, 'recall': 0.37094, 'f1': 0.49566, 'auc': 0.89751}
2025-08-17 03:16:17,631 - INFO - val: {'epoch': 33, 'time_epoch': 4.61458, 'loss': 0.08344301, 'lr': 0, 'params': 514193, 'time_iter': 0.03577, 'accuracy': 0.98079, 'precision': 0.52273, 'recall': 0.28395, 'f1': 0.368, 'auc': 0.78082}
2025-08-17 03:16:22,279 - INFO - test: {'epoch': 33, 'time_epoch': 4.63227, 'loss': 0.12220584, 'lr': 0, 'params': 514193, 'time_iter': 0.03591, 'accuracy': 0.96912, 'precision': 0.52308, 'recall': 0.26154, 'f1': 0.34872, 'auc': 0.77568}
2025-08-17 03:16:22,281 - INFO - > Epoch 33: took 78.0s (avg 80.2s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:17:31,319 - INFO - train: {'epoch': 34, 'time_epoch': 68.97627, 'eta': 4592.09595, 'eta_hours': 1.27558, 'loss': 0.0972602, 'lr': 7.872e-05, 'params': 514193, 'time_iter': 0.06703, 'accuracy': 0.97149, 'precision': 0.74178, 'recall': 0.36607, 'f1': 0.49022, 'auc': 0.89915}
2025-08-17 03:17:35,947 - INFO - val: {'epoch': 34, 'time_epoch': 4.60651, 'loss': 0.08681313, 'lr': 0, 'params': 514193, 'time_iter': 0.03571, 'accuracy': 0.97933, 'precision': 0.46, 'recall': 0.28395, 'f1': 0.35115, 'auc': 0.7828}
2025-08-17 03:17:40,491 - INFO - test: {'epoch': 34, 'time_epoch': 4.52796, 'loss': 0.1287194, 'lr': 0, 'params': 514193, 'time_iter': 0.0351, 'accuracy': 0.96693, 'precision': 0.45161, 'recall': 0.21538, 'f1': 0.29167, 'auc': 0.76729}
2025-08-17 03:17:40,493 - INFO - > Epoch 34: took 78.2s (avg 80.2s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:18:48,392 - INFO - train: {'epoch': 35, 'time_epoch': 67.83839, 'eta': 4516.45412, 'eta_hours': 1.25457, 'loss': 0.09611722, 'lr': 7.735e-05, 'params': 514193, 'time_iter': 0.06593, 'accuracy': 0.97222, 'precision': 0.75158, 'recall': 0.38555, 'f1': 0.50966, 'auc': 0.901}
2025-08-17 03:18:52,955 - INFO - val: {'epoch': 35, 'time_epoch': 4.54214, 'loss': 0.08638046, 'lr': 0, 'params': 514193, 'time_iter': 0.03521, 'accuracy': 0.97763, 'precision': 0.40351, 'recall': 0.28395, 'f1': 0.33333, 'auc': 0.7782}
2025-08-17 03:18:57,468 - INFO - test: {'epoch': 35, 'time_epoch': 4.49739, 'loss': 0.12856604, 'lr': 0, 'params': 514193, 'time_iter': 0.03486, 'accuracy': 0.96718, 'precision': 0.46479, 'recall': 0.25385, 'f1': 0.32836, 'auc': 0.75793}
2025-08-17 03:18:57,470 - INFO - > Epoch 35: took 77.0s (avg 80.1s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:20:05,507 - INFO - train: {'epoch': 36, 'time_epoch': 67.97609, 'eta': 4441.46855, 'eta_hours': 1.23374, 'loss': 0.09463981, 'lr': 7.595e-05, 'params': 514193, 'time_iter': 0.06606, 'accuracy': 0.9728, 'precision': 0.76287, 'recall': 0.39692, 'f1': 0.52216, 'auc': 0.9083}
2025-08-17 03:20:10,135 - INFO - val: {'epoch': 36, 'time_epoch': 4.60623, 'loss': 0.09003098, 'lr': 0, 'params': 514193, 'time_iter': 0.03571, 'accuracy': 0.97836, 'precision': 0.43103, 'recall': 0.30864, 'f1': 0.35971, 'auc': 0.77888}
2025-08-17 03:20:14,745 - INFO - test: {'epoch': 36, 'time_epoch': 4.59348, 'loss': 0.14017332, 'lr': 0, 'params': 514193, 'time_iter': 0.03561, 'accuracy': 0.96693, 'precision': 0.45588, 'recall': 0.23846, 'f1': 0.31313, 'auc': 0.75092}
2025-08-17 03:20:14,748 - INFO - > Epoch 36: took 77.3s (avg 80.0s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:21:23,447 - INFO - train: {'epoch': 37, 'time_epoch': 68.63901, 'eta': 4367.93352, 'eta_hours': 1.21331, 'loss': 0.09533467, 'lr': 7.452e-05, 'params': 514193, 'time_iter': 0.0667, 'accuracy': 0.97213, 'precision': 0.74343, 'recall': 0.39042, 'f1': 0.51197, 'auc': 0.90572}
2025-08-17 03:21:28,078 - INFO - val: {'epoch': 37, 'time_epoch': 4.60978, 'loss': 0.08999845, 'lr': 0, 'params': 514193, 'time_iter': 0.03573, 'accuracy': 0.97909, 'precision': 0.45283, 'recall': 0.2963, 'f1': 0.35821, 'auc': 0.78311}
2025-08-17 03:21:32,688 - INFO - test: {'epoch': 37, 'time_epoch': 4.59268, 'loss': 0.14778917, 'lr': 0, 'params': 514193, 'time_iter': 0.0356, 'accuracy': 0.9628, 'precision': 0.35443, 'recall': 0.21538, 'f1': 0.26794, 'auc': 0.74967}
2025-08-17 03:21:32,690 - INFO - > Epoch 37: took 77.9s (avg 79.9s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:22:41,625 - INFO - train: {'epoch': 38, 'time_epoch': 68.87418, 'eta': 4295.01739, 'eta_hours': 1.19306, 'loss': 0.09428248, 'lr': 7.307e-05, 'params': 514193, 'time_iter': 0.06693, 'accuracy': 0.97265, 'precision': 0.75076, 'recall': 0.40341, 'f1': 0.52482, 'auc': 0.90795}
2025-08-17 03:22:46,234 - INFO - val: {'epoch': 38, 'time_epoch': 4.58806, 'loss': 0.08023259, 'lr': 0, 'params': 514193, 'time_iter': 0.03557, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.22222, 'f1': 0.30769, 'auc': 0.79008}
2025-08-17 03:22:50,827 - INFO - test: {'epoch': 38, 'time_epoch': 4.57766, 'loss': 0.13820097, 'lr': 0, 'params': 514193, 'time_iter': 0.03549, 'accuracy': 0.9662, 'precision': 0.35484, 'recall': 0.08462, 'f1': 0.13665, 'auc': 0.74292}
2025-08-17 03:22:50,830 - INFO - > Epoch 38: took 78.1s (avg 79.9s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:23:59,459 - INFO - train: {'epoch': 39, 'time_epoch': 68.56834, 'eta': 4221.84459, 'eta_hours': 1.17273, 'loss': 0.0921967, 'lr': 7.159e-05, 'params': 514193, 'time_iter': 0.06664, 'accuracy': 0.97277, 'precision': 0.75846, 'recall': 0.40016, 'f1': 0.52391, 'auc': 0.91743}
2025-08-17 03:24:04,071 - INFO - val: {'epoch': 39, 'time_epoch': 4.59149, 'loss': 0.09669947, 'lr': 0, 'params': 514193, 'time_iter': 0.03559, 'accuracy': 0.97374, 'precision': 0.34118, 'recall': 0.35802, 'f1': 0.3494, 'auc': 0.78605}
2025-08-17 03:24:08,644 - INFO - test: {'epoch': 39, 'time_epoch': 4.55596, 'loss': 0.14955166, 'lr': 0, 'params': 514193, 'time_iter': 0.03532, 'accuracy': 0.95891, 'precision': 0.3211, 'recall': 0.26923, 'f1': 0.29289, 'auc': 0.76089}
2025-08-17 03:24:08,646 - INFO - > Epoch 39: took 77.8s (avg 79.8s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:25:19,808 - INFO - train: {'epoch': 40, 'time_epoch': 71.09934, 'eta': 4152.53858, 'eta_hours': 1.15348, 'loss': 0.09119049, 'lr': 7.008e-05, 'params': 514193, 'time_iter': 0.0691, 'accuracy': 0.97331, 'precision': 0.76818, 'recall': 0.41153, 'f1': 0.53594, 'auc': 0.91582}
2025-08-17 03:25:24,487 - INFO - val: {'epoch': 40, 'time_epoch': 4.65731, 'loss': 0.09174559, 'lr': 0, 'params': 514193, 'time_iter': 0.0361, 'accuracy': 0.97812, 'precision': 0.42623, 'recall': 0.32099, 'f1': 0.3662, 'auc': 0.77784}
2025-08-17 03:25:29,132 - INFO - test: {'epoch': 40, 'time_epoch': 4.62833, 'loss': 0.14226435, 'lr': 0, 'params': 514193, 'time_iter': 0.03588, 'accuracy': 0.96329, 'precision': 0.37647, 'recall': 0.24615, 'f1': 0.29767, 'auc': 0.75674}
2025-08-17 03:25:29,134 - INFO - > Epoch 40: took 80.5s (avg 79.9s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:26:38,437 - INFO - train: {'epoch': 41, 'time_epoch': 69.24099, 'eta': 4080.58087, 'eta_hours': 1.13349, 'loss': 0.0922778, 'lr': 6.856e-05, 'params': 514193, 'time_iter': 0.06729, 'accuracy': 0.97243, 'precision': 0.75272, 'recall': 0.39286, 'f1': 0.51627, 'auc': 0.91592}
2025-08-17 03:26:43,087 - INFO - val: {'epoch': 41, 'time_epoch': 4.62782, 'loss': 0.08590916, 'lr': 0, 'params': 514193, 'time_iter': 0.03587, 'accuracy': 0.97909, 'precision': 0.45283, 'recall': 0.2963, 'f1': 0.35821, 'auc': 0.7863}
2025-08-17 03:26:47,765 - INFO - test: {'epoch': 41, 'time_epoch': 4.66129, 'loss': 0.13578441, 'lr': 0, 'params': 514193, 'time_iter': 0.03613, 'accuracy': 0.96523, 'precision': 0.41558, 'recall': 0.24615, 'f1': 0.30918, 'auc': 0.75486}
2025-08-17 03:26:47,767 - INFO - > Epoch 41: took 78.6s (avg 79.8s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:27:57,523 - INFO - train: {'epoch': 42, 'time_epoch': 69.69303, 'eta': 4009.34874, 'eta_hours': 1.11371, 'loss': 0.08915641, 'lr': 6.701e-05, 'params': 514193, 'time_iter': 0.06773, 'accuracy': 0.97344, 'precision': 0.76479, 'recall': 0.41964, 'f1': 0.54193, 'auc': 0.9237}
2025-08-17 03:28:02,282 - INFO - val: {'epoch': 42, 'time_epoch': 4.73596, 'loss': 0.08782989, 'lr': 0, 'params': 514193, 'time_iter': 0.03671, 'accuracy': 0.97909, 'precision': 0.45763, 'recall': 0.33333, 'f1': 0.38571, 'auc': 0.78148}
2025-08-17 03:28:07,032 - INFO - test: {'epoch': 42, 'time_epoch': 4.73315, 'loss': 0.14145122, 'lr': 0, 'params': 514193, 'time_iter': 0.03669, 'accuracy': 0.96572, 'precision': 0.41791, 'recall': 0.21538, 'f1': 0.28426, 'auc': 0.75567}
2025-08-17 03:28:07,034 - INFO - > Epoch 42: took 79.3s (avg 79.8s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:29:16,277 - INFO - train: {'epoch': 43, 'time_epoch': 69.18217, 'eta': 3937.53638, 'eta_hours': 1.09376, 'loss': 0.09161768, 'lr': 6.545e-05, 'params': 514193, 'time_iter': 0.06723, 'accuracy': 0.97334, 'precision': 0.77865, 'recall': 0.4026, 'f1': 0.53077, 'auc': 0.91644}
2025-08-17 03:29:20,856 - INFO - val: {'epoch': 43, 'time_epoch': 4.55784, 'loss': 0.08131507, 'lr': 0, 'params': 514193, 'time_iter': 0.03533, 'accuracy': 0.98079, 'precision': 0.52174, 'recall': 0.2963, 'f1': 0.37795, 'auc': 0.78728}
2025-08-17 03:29:25,408 - INFO - test: {'epoch': 43, 'time_epoch': 4.53505, 'loss': 0.14337378, 'lr': 0, 'params': 514193, 'time_iter': 0.03516, 'accuracy': 0.96548, 'precision': 0.4, 'recall': 0.18462, 'f1': 0.25263, 'auc': 0.74062}
2025-08-17 03:29:25,410 - INFO - > Epoch 43: took 78.4s (avg 79.8s) | Best so far: epoch 27	train_loss: 0.1045 train_auc: 0.8738	val_loss: 0.0794 val_auc: 0.7963	test_loss: 0.1202 test_auc: 0.7654
2025-08-17 03:30:33,767 - INFO - train: {'epoch': 44, 'time_epoch': 68.29489, 'eta': 3864.75648, 'eta_hours': 1.07354, 'loss': 0.08853342, 'lr': 6.387e-05, 'params': 514193, 'time_iter': 0.06637, 'accuracy': 0.97383, 'precision': 0.77001, 'recall': 0.42938, 'f1': 0.55133, 'auc': 0.92457}
2025-08-17 03:30:38,333 - INFO - val: {'epoch': 44, 'time_epoch': 4.54483, 'loss': 0.08331767, 'lr': 0, 'params': 514193, 'time_iter': 0.03523, 'accuracy': 0.98079, 'precision': 0.51786, 'recall': 0.35802, 'f1': 0.42336, 'auc': 0.80428}
2025-08-17 03:30:42,906 - INFO - test: {'epoch': 44, 'time_epoch': 4.55595, 'loss': 0.14582617, 'lr': 0, 'params': 514193, 'time_iter': 0.03532, 'accuracy': 0.96499, 'precision': 0.39062, 'recall': 0.19231, 'f1': 0.25773, 'auc': 0.75597}
2025-08-17 03:30:42,908 - INFO - > Epoch 44: took 77.5s (avg 79.7s) | Best so far: epoch 44	train_loss: 0.0885 train_auc: 0.9246	val_loss: 0.0833 val_auc: 0.8043	test_loss: 0.1458 test_auc: 0.7560
2025-08-17 03:31:51,650 - INFO - train: {'epoch': 45, 'time_epoch': 68.68013, 'eta': 3792.62381, 'eta_hours': 1.05351, 'loss': 0.0868074, 'lr': 6.227e-05, 'params': 514193, 'time_iter': 0.06674, 'accuracy': 0.97426, 'precision': 0.78351, 'recall': 0.43182, 'f1': 0.55678, 'auc': 0.92786}
2025-08-17 03:31:56,385 - INFO - val: {'epoch': 45, 'time_epoch': 4.71233, 'loss': 0.08972891, 'lr': 0, 'params': 514193, 'time_iter': 0.03653, 'accuracy': 0.97836, 'precision': 0.43548, 'recall': 0.33333, 'f1': 0.37762, 'auc': 0.79562}
2025-08-17 03:32:01,011 - INFO - test: {'epoch': 45, 'time_epoch': 4.61042, 'loss': 0.14884948, 'lr': 0, 'params': 514193, 'time_iter': 0.03574, 'accuracy': 0.96304, 'precision': 0.36585, 'recall': 0.23077, 'f1': 0.28302, 'auc': 0.75611}
2025-08-17 03:32:01,014 - INFO - > Epoch 45: took 78.1s (avg 79.7s) | Best so far: epoch 44	train_loss: 0.0885 train_auc: 0.9246	val_loss: 0.0833 val_auc: 0.8043	test_loss: 0.1458 test_auc: 0.7560
2025-08-17 03:33:10,749 - INFO - train: {'epoch': 46, 'time_epoch': 69.67337, 'eta': 3721.75809, 'eta_hours': 1.03382, 'loss': 0.08832317, 'lr': 6.066e-05, 'params': 514193, 'time_iter': 0.06771, 'accuracy': 0.97386, 'precision': 0.76801, 'recall': 0.43263, 'f1': 0.55348, 'auc': 0.92693}
2025-08-17 03:33:15,376 - INFO - val: {'epoch': 46, 'time_epoch': 4.60579, 'loss': 0.08289474, 'lr': 0, 'params': 514193, 'time_iter': 0.0357, 'accuracy': 0.98006, 'precision': 0.49057, 'recall': 0.32099, 'f1': 0.38806, 'auc': 0.77593}
2025-08-17 03:33:19,965 - INFO - test: {'epoch': 46, 'time_epoch': 4.57239, 'loss': 0.14307342, 'lr': 0, 'params': 514193, 'time_iter': 0.03544, 'accuracy': 0.9662, 'precision': 0.41176, 'recall': 0.16154, 'f1': 0.23204, 'auc': 0.73059}
2025-08-17 03:33:19,967 - INFO - > Epoch 46: took 79.0s (avg 79.7s) | Best so far: epoch 44	train_loss: 0.0885 train_auc: 0.9246	val_loss: 0.0833 val_auc: 0.8043	test_loss: 0.1458 test_auc: 0.7560
2025-08-17 03:34:27,910 - INFO - train: {'epoch': 47, 'time_epoch': 67.88288, 'eta': 3649.00236, 'eta_hours': 1.01361, 'loss': 0.08628297, 'lr': 5.904e-05, 'params': 514193, 'time_iter': 0.06597, 'accuracy': 0.97432, 'precision': 0.77842, 'recall': 0.43912, 'f1': 0.56149, 'auc': 0.9311}
2025-08-17 03:34:32,480 - INFO - val: {'epoch': 47, 'time_epoch': 4.54872, 'loss': 0.08633858, 'lr': 0, 'params': 514193, 'time_iter': 0.03526, 'accuracy': 0.97909, 'precision': 0.45455, 'recall': 0.30864, 'f1': 0.36765, 'auc': 0.80449}
2025-08-17 03:34:37,037 - INFO - test: {'epoch': 47, 'time_epoch': 4.53993, 'loss': 0.14523018, 'lr': 0, 'params': 514193, 'time_iter': 0.03519, 'accuracy': 0.96475, 'precision': 0.39437, 'recall': 0.21538, 'f1': 0.27861, 'auc': 0.75573}
2025-08-17 03:34:37,039 - INFO - > Epoch 47: took 77.1s (avg 79.6s) | Best so far: epoch 47	train_loss: 0.0863 train_auc: 0.9311	val_loss: 0.0863 val_auc: 0.8045	test_loss: 0.1452 test_auc: 0.7557
2025-08-17 03:35:45,123 - INFO - train: {'epoch': 48, 'time_epoch': 68.02319, 'eta': 3576.59155, 'eta_hours': 0.9935, 'loss': 0.08447948, 'lr': 5.741e-05, 'params': 514193, 'time_iter': 0.06611, 'accuracy': 0.97432, 'precision': 0.77063, 'recall': 0.44724, 'f1': 0.566, 'auc': 0.93459}
2025-08-17 03:35:49,704 - INFO - val: {'epoch': 48, 'time_epoch': 4.56016, 'loss': 0.0832118, 'lr': 0, 'params': 514193, 'time_iter': 0.03535, 'accuracy': 0.98274, 'precision': 0.63158, 'recall': 0.2963, 'f1': 0.40336, 'auc': 0.78172}
2025-08-17 03:35:54,240 - INFO - test: {'epoch': 48, 'time_epoch': 4.51874, 'loss': 0.15110186, 'lr': 0, 'params': 514193, 'time_iter': 0.03503, 'accuracy': 0.96548, 'precision': 0.35714, 'recall': 0.11538, 'f1': 0.17442, 'auc': 0.74242}
2025-08-17 03:35:54,242 - INFO - > Epoch 48: took 77.2s (avg 79.6s) | Best so far: epoch 47	train_loss: 0.0863 train_auc: 0.9311	val_loss: 0.0863 val_auc: 0.8045	test_loss: 0.1452 test_auc: 0.7557
2025-08-17 03:37:03,710 - INFO - train: {'epoch': 49, 'time_epoch': 69.40719, 'eta': 3505.74025, 'eta_hours': 0.97382, 'loss': 0.08289045, 'lr': 5.577e-05, 'params': 514193, 'time_iter': 0.06745, 'accuracy': 0.97544, 'precision': 0.79363, 'recall': 0.4651, 'f1': 0.58649, 'auc': 0.93675}
2025-08-17 03:37:08,262 - INFO - val: {'epoch': 49, 'time_epoch': 4.53018, 'loss': 0.08125101, 'lr': 0, 'params': 514193, 'time_iter': 0.03512, 'accuracy': 0.98152, 'precision': 0.55319, 'recall': 0.32099, 'f1': 0.40625, 'auc': 0.791}
2025-08-17 03:37:12,817 - INFO - test: {'epoch': 49, 'time_epoch': 4.5382, 'loss': 0.14316842, 'lr': 0, 'params': 514193, 'time_iter': 0.03518, 'accuracy': 0.96693, 'precision': 0.4625, 'recall': 0.28462, 'f1': 0.35238, 'auc': 0.75317}
2025-08-17 03:37:12,820 - INFO - > Epoch 49: took 78.6s (avg 79.6s) | Best so far: epoch 47	train_loss: 0.0863 train_auc: 0.9311	val_loss: 0.0863 val_auc: 0.8045	test_loss: 0.1452 test_auc: 0.7557
2025-08-17 03:38:21,433 - INFO - train: {'epoch': 50, 'time_epoch': 68.55296, 'eta': 3434.12485, 'eta_hours': 0.95392, 'loss': 0.08430627, 'lr': 5.413e-05, 'params': 514193, 'time_iter': 0.06662, 'accuracy': 0.97438, 'precision': 0.76754, 'recall': 0.45292, 'f1': 0.56968, 'auc': 0.93827}
2025-08-17 03:38:26,062 - INFO - val: {'epoch': 50, 'time_epoch': 4.6078, 'loss': 0.08788973, 'lr': 0, 'params': 514193, 'time_iter': 0.03572, 'accuracy': 0.97836, 'precision': 0.42857, 'recall': 0.2963, 'f1': 0.35036, 'auc': 0.79436}
2025-08-17 03:38:30,666 - INFO - test: {'epoch': 50, 'time_epoch': 4.58709, 'loss': 0.14946836, 'lr': 0, 'params': 514193, 'time_iter': 0.03556, 'accuracy': 0.96377, 'precision': 0.38272, 'recall': 0.23846, 'f1': 0.29384, 'auc': 0.75125}
2025-08-17 03:38:30,668 - INFO - > Epoch 50: took 77.8s (avg 79.5s) | Best so far: epoch 47	train_loss: 0.0863 train_auc: 0.9311	val_loss: 0.0863 val_auc: 0.8045	test_loss: 0.1452 test_auc: 0.7557
2025-08-17 03:39:40,593 - INFO - train: {'epoch': 51, 'time_epoch': 69.86121, 'eta': 3363.83485, 'eta_hours': 0.9344, 'loss': 0.08298611, 'lr': 5.248e-05, 'params': 514193, 'time_iter': 0.06789, 'accuracy': 0.9745, 'precision': 0.77483, 'recall': 0.44968, 'f1': 0.56908, 'auc': 0.93909}
2025-08-17 03:39:45,205 - INFO - val: {'epoch': 51, 'time_epoch': 4.59094, 'loss': 0.08637316, 'lr': 0, 'params': 514193, 'time_iter': 0.03559, 'accuracy': 0.97958, 'precision': 0.47059, 'recall': 0.2963, 'f1': 0.36364, 'auc': 0.79109}
2025-08-17 03:39:49,765 - INFO - test: {'epoch': 51, 'time_epoch': 4.54352, 'loss': 0.1491705, 'lr': 0, 'params': 514193, 'time_iter': 0.03522, 'accuracy': 0.96499, 'precision': 0.40541, 'recall': 0.23077, 'f1': 0.29412, 'auc': 0.74437}
2025-08-17 03:39:49,767 - INFO - > Epoch 51: took 79.1s (avg 79.5s) | Best so far: epoch 47	train_loss: 0.0863 train_auc: 0.9311	val_loss: 0.0863 val_auc: 0.8045	test_loss: 0.1452 test_auc: 0.7557
2025-08-17 03:40:58,485 - INFO - train: {'epoch': 52, 'time_epoch': 68.65762, 'eta': 3292.49369, 'eta_hours': 0.91458, 'loss': 0.0809633, 'lr': 5.083e-05, 'params': 514193, 'time_iter': 0.06672, 'accuracy': 0.97477, 'precision': 0.76872, 'recall': 0.46672, 'f1': 0.58081, 'auc': 0.94137}
2025-08-17 03:41:03,044 - INFO - val: {'epoch': 52, 'time_epoch': 4.53816, 'loss': 0.08222907, 'lr': 0, 'params': 514193, 'time_iter': 0.03518, 'accuracy': 0.98104, 'precision': 0.53061, 'recall': 0.32099, 'f1': 0.4, 'auc': 0.78945}
2025-08-17 03:41:07,545 - INFO - test: {'epoch': 52, 'time_epoch': 4.48554, 'loss': 0.14270785, 'lr': 0, 'params': 514193, 'time_iter': 0.03477, 'accuracy': 0.96718, 'precision': 0.45283, 'recall': 0.18462, 'f1': 0.2623, 'auc': 0.75323}
2025-08-17 03:41:07,547 - INFO - > Epoch 52: took 77.8s (avg 79.5s) | Best so far: epoch 47	train_loss: 0.0863 train_auc: 0.9311	val_loss: 0.0863 val_auc: 0.8045	test_loss: 0.1452 test_auc: 0.7557
2025-08-17 03:42:16,179 - INFO - train: {'epoch': 53, 'time_epoch': 68.57164, 'eta': 3221.17868, 'eta_hours': 0.89477, 'loss': 0.08196981, 'lr': 4.917e-05, 'params': 514193, 'time_iter': 0.06664, 'accuracy': 0.97499, 'precision': 0.77158, 'recall': 0.47159, 'f1': 0.58539, 'auc': 0.9404}
2025-08-17 03:42:20,773 - INFO - val: {'epoch': 53, 'time_epoch': 4.57344, 'loss': 0.0880776, 'lr': 0, 'params': 514193, 'time_iter': 0.03545, 'accuracy': 0.97617, 'precision': 0.38028, 'recall': 0.33333, 'f1': 0.35526, 'auc': 0.80275}
2025-08-17 03:42:25,362 - INFO - test: {'epoch': 53, 'time_epoch': 4.57292, 'loss': 0.14884654, 'lr': 0, 'params': 514193, 'time_iter': 0.03545, 'accuracy': 0.96426, 'precision': 0.39759, 'recall': 0.25385, 'f1': 0.30986, 'auc': 0.75642}
2025-08-17 03:42:25,364 - INFO - > Epoch 53: took 77.8s (avg 79.4s) | Best so far: epoch 47	train_loss: 0.0863 train_auc: 0.9311	val_loss: 0.0863 val_auc: 0.8045	test_loss: 0.1452 test_auc: 0.7557
2025-08-17 03:43:34,257 - INFO - train: {'epoch': 54, 'time_epoch': 68.82981, 'eta': 3150.17466, 'eta_hours': 0.87505, 'loss': 0.08209958, 'lr': 4.752e-05, 'params': 514193, 'time_iter': 0.06689, 'accuracy': 0.97541, 'precision': 0.80085, 'recall': 0.45698, 'f1': 0.58191, 'auc': 0.94121}
2025-08-17 03:43:38,930 - INFO - val: {'epoch': 54, 'time_epoch': 4.65158, 'loss': 0.08648873, 'lr': 0, 'params': 514193, 'time_iter': 0.03606, 'accuracy': 0.97982, 'precision': 0.48148, 'recall': 0.32099, 'f1': 0.38519, 'auc': 0.78775}
2025-08-17 03:43:43,604 - INFO - test: {'epoch': 54, 'time_epoch': 4.65707, 'loss': 0.15420735, 'lr': 0, 'params': 514193, 'time_iter': 0.0361, 'accuracy': 0.96523, 'precision': 0.39344, 'recall': 0.18462, 'f1': 0.25131, 'auc': 0.75501}
2025-08-17 03:43:43,607 - INFO - > Epoch 54: took 78.2s (avg 79.4s) | Best so far: epoch 47	train_loss: 0.0863 train_auc: 0.9311	val_loss: 0.0863 val_auc: 0.8045	test_loss: 0.1452 test_auc: 0.7557
2025-08-17 03:44:52,657 - INFO - train: {'epoch': 55, 'time_epoch': 68.9891, 'eta': 3079.37346, 'eta_hours': 0.85538, 'loss': 0.07920812, 'lr': 4.587e-05, 'params': 514193, 'time_iter': 0.06704, 'accuracy': 0.97614, 'precision': 0.80244, 'recall': 0.48133, 'f1': 0.60173, 'auc': 0.94656}
2025-08-17 03:44:57,308 - INFO - val: {'epoch': 55, 'time_epoch': 4.62932, 'loss': 0.08609475, 'lr': 0, 'params': 514193, 'time_iter': 0.03589, 'accuracy': 0.98055, 'precision': 0.5102, 'recall': 0.30864, 'f1': 0.38462, 'auc': 0.78509}
2025-08-17 03:45:01,975 - INFO - test: {'epoch': 55, 'time_epoch': 4.64971, 'loss': 0.15697836, 'lr': 0, 'params': 514193, 'time_iter': 0.03604, 'accuracy': 0.96548, 'precision': 0.41429, 'recall': 0.22308, 'f1': 0.29, 'auc': 0.74686}
2025-08-17 03:45:01,977 - INFO - > Epoch 55: took 78.4s (avg 79.4s) | Best so far: epoch 47	train_loss: 0.0863 train_auc: 0.9311	val_loss: 0.0863 val_auc: 0.8045	test_loss: 0.1452 test_auc: 0.7557
2025-08-17 03:46:11,783 - INFO - train: {'epoch': 56, 'time_epoch': 69.74308, 'eta': 3009.20462, 'eta_hours': 0.83589, 'loss': 0.07957174, 'lr': 4.423e-05, 'params': 514193, 'time_iter': 0.06778, 'accuracy': 0.97568, 'precision': 0.79111, 'recall': 0.47646, 'f1': 0.59473, 'auc': 0.94845}
2025-08-17 03:46:16,449 - INFO - val: {'epoch': 56, 'time_epoch': 4.64462, 'loss': 0.0881745, 'lr': 0, 'params': 514193, 'time_iter': 0.036, 'accuracy': 0.9786, 'precision': 0.44615, 'recall': 0.35802, 'f1': 0.39726, 'auc': 0.79776}
2025-08-17 03:46:21,092 - INFO - test: {'epoch': 56, 'time_epoch': 4.6269, 'loss': 0.14949805, 'lr': 0, 'params': 514193, 'time_iter': 0.03587, 'accuracy': 0.96377, 'precision': 0.3956, 'recall': 0.27692, 'f1': 0.32579, 'auc': 0.76165}
2025-08-17 03:46:21,095 - INFO - > Epoch 56: took 79.1s (avg 79.4s) | Best so far: epoch 47	train_loss: 0.0863 train_auc: 0.9311	val_loss: 0.0863 val_auc: 0.8045	test_loss: 0.1452 test_auc: 0.7557
2025-08-17 03:47:29,822 - INFO - train: {'epoch': 57, 'time_epoch': 68.66534, 'eta': 2938.27004, 'eta_hours': 0.81619, 'loss': 0.07787182, 'lr': 4.259e-05, 'params': 514193, 'time_iter': 0.06673, 'accuracy': 0.97687, 'precision': 0.81192, 'recall': 0.49756, 'f1': 0.61701, 'auc': 0.94886}
2025-08-17 03:47:34,477 - INFO - val: {'epoch': 57, 'time_epoch': 4.63347, 'loss': 0.09630805, 'lr': 0, 'params': 514193, 'time_iter': 0.03592, 'accuracy': 0.97642, 'precision': 0.38571, 'recall': 0.33333, 'f1': 0.35762, 'auc': 0.79272}
2025-08-17 03:47:39,116 - INFO - test: {'epoch': 57, 'time_epoch': 4.62277, 'loss': 0.16481628, 'lr': 0, 'params': 514193, 'time_iter': 0.03584, 'accuracy': 0.9645, 'precision': 0.38889, 'recall': 0.21538, 'f1': 0.27723, 'auc': 0.74901}
2025-08-17 03:47:39,118 - INFO - > Epoch 57: took 78.0s (avg 79.4s) | Best so far: epoch 47	train_loss: 0.0863 train_auc: 0.9311	val_loss: 0.0863 val_auc: 0.8045	test_loss: 0.1452 test_auc: 0.7557
2025-08-17 03:48:47,860 - INFO - train: {'epoch': 58, 'time_epoch': 68.68147, 'eta': 2867.42359, 'eta_hours': 0.79651, 'loss': 0.07832994, 'lr': 4.096e-05, 'params': 514193, 'time_iter': 0.06675, 'accuracy': 0.97635, 'precision': 0.78807, 'recall': 0.50406, 'f1': 0.61485, 'auc': 0.94728}
2025-08-17 03:48:52,815 - INFO - val: {'epoch': 58, 'time_epoch': 4.5558, 'loss': 0.08680883, 'lr': 0, 'params': 514193, 'time_iter': 0.03532, 'accuracy': 0.98006, 'precision': 0.4898, 'recall': 0.2963, 'f1': 0.36923, 'auc': 0.80621}
2025-08-17 03:48:57,372 - INFO - test: {'epoch': 58, 'time_epoch': 4.5407, 'loss': 0.16418972, 'lr': 0, 'params': 514193, 'time_iter': 0.0352, 'accuracy': 0.96329, 'precision': 0.31579, 'recall': 0.13846, 'f1': 0.19251, 'auc': 0.74578}
2025-08-17 03:48:57,374 - INFO - > Epoch 58: took 78.3s (avg 79.4s) | Best so far: epoch 58	train_loss: 0.0783 train_auc: 0.9473	val_loss: 0.0868 val_auc: 0.8062	test_loss: 0.1642 test_auc: 0.7458
2025-08-17 03:50:05,647 - INFO - train: {'epoch': 59, 'time_epoch': 68.2115, 'eta': 2796.33598, 'eta_hours': 0.77676, 'loss': 0.07823801, 'lr': 3.934e-05, 'params': 514193, 'time_iter': 0.06629, 'accuracy': 0.97629, 'precision': 0.79815, 'recall': 0.49107, 'f1': 0.60804, 'auc': 0.9484}
2025-08-17 03:50:10,267 - INFO - val: {'epoch': 59, 'time_epoch': 4.59942, 'loss': 0.09271442, 'lr': 0, 'params': 514193, 'time_iter': 0.03565, 'accuracy': 0.97812, 'precision': 0.42373, 'recall': 0.30864, 'f1': 0.35714, 'auc': 0.77954}
2025-08-17 03:50:14,876 - INFO - test: {'epoch': 59, 'time_epoch': 4.59266, 'loss': 0.16461021, 'lr': 0, 'params': 514193, 'time_iter': 0.0356, 'accuracy': 0.96548, 'precision': 0.40625, 'recall': 0.2, 'f1': 0.26804, 'auc': 0.73813}
2025-08-17 03:50:14,878 - INFO - > Epoch 59: took 77.5s (avg 79.3s) | Best so far: epoch 58	train_loss: 0.0783 train_auc: 0.9473	val_loss: 0.0868 val_auc: 0.8062	test_loss: 0.1642 test_auc: 0.7458
2025-08-17 03:51:23,233 - INFO - train: {'epoch': 60, 'time_epoch': 68.29374, 'eta': 2725.39526, 'eta_hours': 0.75705, 'loss': 0.07688874, 'lr': 3.773e-05, 'params': 514193, 'time_iter': 0.06637, 'accuracy': 0.97657, 'precision': 0.80052, 'recall': 0.49838, 'f1': 0.61431, 'auc': 0.95281}
2025-08-17 03:51:27,870 - INFO - val: {'epoch': 60, 'time_epoch': 4.6156, 'loss': 0.08952386, 'lr': 0, 'params': 514193, 'time_iter': 0.03578, 'accuracy': 0.98055, 'precision': 0.5098, 'recall': 0.32099, 'f1': 0.39394, 'auc': 0.79604}
2025-08-17 03:51:32,485 - INFO - test: {'epoch': 60, 'time_epoch': 4.59766, 'loss': 0.1618836, 'lr': 0, 'params': 514193, 'time_iter': 0.03564, 'accuracy': 0.96742, 'precision': 0.47222, 'recall': 0.26154, 'f1': 0.33663, 'auc': 0.75596}
2025-08-17 03:51:32,486 - INFO - > Epoch 60: took 77.6s (avg 79.3s) | Best so far: epoch 58	train_loss: 0.0783 train_auc: 0.9473	val_loss: 0.0868 val_auc: 0.8062	test_loss: 0.1642 test_auc: 0.7458
2025-08-17 03:52:40,802 - INFO - train: {'epoch': 61, 'time_epoch': 68.25616, 'eta': 2654.51689, 'eta_hours': 0.73737, 'loss': 0.07621304, 'lr': 3.613e-05, 'params': 514193, 'time_iter': 0.06633, 'accuracy': 0.97605, 'precision': 0.78389, 'recall': 0.49756, 'f1': 0.60874, 'auc': 0.95423}
2025-08-17 03:52:45,348 - INFO - val: {'epoch': 61, 'time_epoch': 4.52492, 'loss': 0.09638916, 'lr': 0, 'params': 514193, 'time_iter': 0.03508, 'accuracy': 0.97423, 'precision': 0.34568, 'recall': 0.34568, 'f1': 0.34568, 'auc': 0.79405}
2025-08-17 03:52:49,896 - INFO - test: {'epoch': 61, 'time_epoch': 4.53153, 'loss': 0.16184904, 'lr': 0, 'params': 514193, 'time_iter': 0.03513, 'accuracy': 0.9628, 'precision': 0.37634, 'recall': 0.26923, 'f1': 0.3139, 'auc': 0.75454}
2025-08-17 03:52:49,899 - INFO - > Epoch 61: took 77.4s (avg 79.3s) | Best so far: epoch 58	train_loss: 0.0783 train_auc: 0.9473	val_loss: 0.0868 val_auc: 0.8062	test_loss: 0.1642 test_auc: 0.7458
2025-08-17 03:53:58,377 - INFO - train: {'epoch': 62, 'time_epoch': 68.41806, 'eta': 2583.81685, 'eta_hours': 0.71773, 'loss': 0.076075, 'lr': 3.455e-05, 'params': 514193, 'time_iter': 0.06649, 'accuracy': 0.97629, 'precision': 0.7825, 'recall': 0.50812, 'f1': 0.61614, 'auc': 0.9517}
2025-08-17 03:54:02,943 - INFO - val: {'epoch': 62, 'time_epoch': 4.54589, 'loss': 0.09244554, 'lr': 0, 'params': 514193, 'time_iter': 0.03524, 'accuracy': 0.97958, 'precision': 0.47273, 'recall': 0.32099, 'f1': 0.38235, 'auc': 0.78046}
2025-08-17 03:54:07,494 - INFO - test: {'epoch': 62, 'time_epoch': 4.53311, 'loss': 0.16771147, 'lr': 0, 'params': 514193, 'time_iter': 0.03514, 'accuracy': 0.96523, 'precision': 0.4058, 'recall': 0.21538, 'f1': 0.28141, 'auc': 0.74632}
2025-08-17 03:54:07,497 - INFO - > Epoch 62: took 77.6s (avg 79.2s) | Best so far: epoch 58	train_loss: 0.0783 train_auc: 0.9473	val_loss: 0.0868 val_auc: 0.8062	test_loss: 0.1642 test_auc: 0.7458
2025-08-17 03:55:17,104 - INFO - train: {'epoch': 63, 'time_epoch': 69.54568, 'eta': 2513.82241, 'eta_hours': 0.69828, 'loss': 0.07355921, 'lr': 3.299e-05, 'params': 514193, 'time_iter': 0.06759, 'accuracy': 0.97781, 'precision': 0.81612, 'recall': 0.52597, 'f1': 0.63968, 'auc': 0.95554}
2025-08-17 03:55:21,659 - INFO - val: {'epoch': 63, 'time_epoch': 4.53379, 'loss': 0.0891481, 'lr': 0, 'params': 514193, 'time_iter': 0.03515, 'accuracy': 0.97982, 'precision': 0.48276, 'recall': 0.34568, 'f1': 0.40288, 'auc': 0.79964}
2025-08-17 03:55:26,183 - INFO - test: {'epoch': 63, 'time_epoch': 4.50848, 'loss': 0.16425332, 'lr': 0, 'params': 514193, 'time_iter': 0.03495, 'accuracy': 0.96645, 'precision': 0.43548, 'recall': 0.20769, 'f1': 0.28125, 'auc': 0.75531}
2025-08-17 03:55:26,185 - INFO - > Epoch 63: took 78.7s (avg 79.2s) | Best so far: epoch 58	train_loss: 0.0783 train_auc: 0.9473	val_loss: 0.0868 val_auc: 0.8062	test_loss: 0.1642 test_auc: 0.7458
2025-08-17 03:56:34,800 - INFO - train: {'epoch': 64, 'time_epoch': 68.5557, 'eta': 2443.30871, 'eta_hours': 0.6787, 'loss': 0.07464962, 'lr': 3.144e-05, 'params': 514193, 'time_iter': 0.06662, 'accuracy': 0.97687, 'precision': 0.79924, 'recall': 0.51055, 'f1': 0.62308, 'auc': 0.95743}
2025-08-17 03:56:39,397 - INFO - val: {'epoch': 64, 'time_epoch': 4.57621, 'loss': 0.08944832, 'lr': 0, 'params': 514193, 'time_iter': 0.03547, 'accuracy': 0.97933, 'precision': 0.46667, 'recall': 0.34568, 'f1': 0.39716, 'auc': 0.79909}
2025-08-17 03:56:43,965 - INFO - test: {'epoch': 64, 'time_epoch': 4.55181, 'loss': 0.16536922, 'lr': 0, 'params': 514193, 'time_iter': 0.03529, 'accuracy': 0.96475, 'precision': 0.39726, 'recall': 0.22308, 'f1': 0.28571, 'auc': 0.75106}
2025-08-17 03:56:43,967 - INFO - > Epoch 64: took 77.8s (avg 79.2s) | Best so far: epoch 58	train_loss: 0.0783 train_auc: 0.9473	val_loss: 0.0868 val_auc: 0.8062	test_loss: 0.1642 test_auc: 0.7458
2025-08-17 03:57:51,896 - INFO - train: {'epoch': 65, 'time_epoch': 67.86947, 'eta': 2372.50083, 'eta_hours': 0.65903, 'loss': 0.07440727, 'lr': 2.992e-05, 'params': 514193, 'time_iter': 0.06596, 'accuracy': 0.97727, 'precision': 0.80025, 'recall': 0.52354, 'f1': 0.63297, 'auc': 0.95575}
2025-08-17 03:57:56,445 - INFO - val: {'epoch': 65, 'time_epoch': 4.52825, 'loss': 0.0893443, 'lr': 0, 'params': 514193, 'time_iter': 0.0351, 'accuracy': 0.97933, 'precision': 0.46429, 'recall': 0.32099, 'f1': 0.37956, 'auc': 0.79613}
2025-08-17 03:58:00,973 - INFO - test: {'epoch': 65, 'time_epoch': 4.51165, 'loss': 0.16582386, 'lr': 0, 'params': 514193, 'time_iter': 0.03497, 'accuracy': 0.96645, 'precision': 0.42308, 'recall': 0.16923, 'f1': 0.24176, 'auc': 0.74666}
2025-08-17 03:58:00,976 - INFO - > Epoch 65: took 77.0s (avg 79.2s) | Best so far: epoch 58	train_loss: 0.0783 train_auc: 0.9473	val_loss: 0.0868 val_auc: 0.8062	test_loss: 0.1642 test_auc: 0.7458
2025-08-17 03:59:09,053 - INFO - train: {'epoch': 66, 'time_epoch': 68.01895, 'eta': 2301.85429, 'eta_hours': 0.6394, 'loss': 0.07303833, 'lr': 2.841e-05, 'params': 514193, 'time_iter': 0.0661, 'accuracy': 0.97702, 'precision': 0.79825, 'recall': 0.51705, 'f1': 0.62759, 'auc': 0.95875}
2025-08-17 03:59:13,641 - INFO - val: {'epoch': 66, 'time_epoch': 4.56676, 'loss': 0.09807169, 'lr': 0, 'params': 514193, 'time_iter': 0.0354, 'accuracy': 0.97666, 'precision': 0.39726, 'recall': 0.35802, 'f1': 0.37662, 'auc': 0.79129}
2025-08-17 03:59:18,215 - INFO - test: {'epoch': 66, 'time_epoch': 4.55753, 'loss': 0.17300692, 'lr': 0, 'params': 514193, 'time_iter': 0.03533, 'accuracy': 0.9628, 'precision': 0.37634, 'recall': 0.26923, 'f1': 0.3139, 'auc': 0.75065}
2025-08-17 03:59:18,217 - INFO - > Epoch 66: took 77.2s (avg 79.2s) | Best so far: epoch 58	train_loss: 0.0783 train_auc: 0.9473	val_loss: 0.0868 val_auc: 0.8062	test_loss: 0.1642 test_auc: 0.7458
2025-08-17 04:00:27,336 - INFO - train: {'epoch': 67, 'time_epoch': 69.05897, 'eta': 2231.77445, 'eta_hours': 0.61994, 'loss': 0.07233513, 'lr': 2.693e-05, 'params': 514193, 'time_iter': 0.06711, 'accuracy': 0.97745, 'precision': 0.80473, 'recall': 0.52516, 'f1': 0.63556, 'auc': 0.95765}
2025-08-17 04:00:31,916 - INFO - val: {'epoch': 67, 'time_epoch': 4.55804, 'loss': 0.09341828, 'lr': 0, 'params': 514193, 'time_iter': 0.03533, 'accuracy': 0.97763, 'precision': 0.42857, 'recall': 0.40741, 'f1': 0.41772, 'auc': 0.80031}
2025-08-17 04:00:36,528 - INFO - test: {'epoch': 67, 'time_epoch': 4.59607, 'loss': 0.17446941, 'lr': 0, 'params': 514193, 'time_iter': 0.03563, 'accuracy': 0.96231, 'precision': 0.35632, 'recall': 0.23846, 'f1': 0.28571, 'auc': 0.75512}
2025-08-17 04:00:36,530 - INFO - > Epoch 67: took 78.3s (avg 79.1s) | Best so far: epoch 58	train_loss: 0.0783 train_auc: 0.9473	val_loss: 0.0868 val_auc: 0.8062	test_loss: 0.1642 test_auc: 0.7458
2025-08-17 04:01:45,601 - INFO - train: {'epoch': 68, 'time_epoch': 69.0087, 'eta': 2161.70162, 'eta_hours': 0.60047, 'loss': 0.07106366, 'lr': 2.548e-05, 'params': 514193, 'time_iter': 0.06706, 'accuracy': 0.97763, 'precision': 0.80244, 'recall': 0.53409, 'f1': 0.64133, 'auc': 0.96119}
2025-08-17 04:01:50,277 - INFO - val: {'epoch': 68, 'time_epoch': 4.65519, 'loss': 0.08898132, 'lr': 0, 'params': 514193, 'time_iter': 0.03609, 'accuracy': 0.98055, 'precision': 0.5102, 'recall': 0.30864, 'f1': 0.38462, 'auc': 0.79139}
2025-08-17 04:01:54,934 - INFO - test: {'epoch': 68, 'time_epoch': 4.63937, 'loss': 0.17126039, 'lr': 0, 'params': 514193, 'time_iter': 0.03596, 'accuracy': 0.96596, 'precision': 0.39583, 'recall': 0.14615, 'f1': 0.21348, 'auc': 0.74771}
2025-08-17 04:01:54,936 - INFO - > Epoch 68: took 78.4s (avg 79.1s) | Best so far: epoch 58	train_loss: 0.0783 train_auc: 0.9473	val_loss: 0.0868 val_auc: 0.8062	test_loss: 0.1642 test_auc: 0.7458
2025-08-17 04:03:04,018 - INFO - train: {'epoch': 69, 'time_epoch': 69.02138, 'eta': 2091.66463, 'eta_hours': 0.58102, 'loss': 0.06930698, 'lr': 2.405e-05, 'params': 514193, 'time_iter': 0.06708, 'accuracy': 0.97757, 'precision': 0.80049, 'recall': 0.53409, 'f1': 0.6407, 'auc': 0.96416}
2025-08-17 04:03:08,602 - INFO - val: {'epoch': 69, 'time_epoch': 4.56313, 'loss': 0.09125913, 'lr': 0, 'params': 514193, 'time_iter': 0.03537, 'accuracy': 0.9786, 'precision': 0.44615, 'recall': 0.35802, 'f1': 0.39726, 'auc': 0.80281}
2025-08-17 04:03:13,187 - INFO - test: {'epoch': 69, 'time_epoch': 4.56645, 'loss': 0.17281341, 'lr': 0, 'params': 514193, 'time_iter': 0.0354, 'accuracy': 0.96523, 'precision': 0.39344, 'recall': 0.18462, 'f1': 0.25131, 'auc': 0.75188}
2025-08-17 04:03:13,189 - INFO - > Epoch 69: took 78.3s (avg 79.1s) | Best so far: epoch 58	train_loss: 0.0783 train_auc: 0.9473	val_loss: 0.0868 val_auc: 0.8062	test_loss: 0.1642 test_auc: 0.7458
2025-08-17 04:04:22,867 - INFO - train: {'epoch': 70, 'time_epoch': 69.61541, 'eta': 2021.89887, 'eta_hours': 0.56164, 'loss': 0.07203687, 'lr': 2.265e-05, 'params': 514193, 'time_iter': 0.06765, 'accuracy': 0.97778, 'precision': 0.80217, 'recall': 0.53977, 'f1': 0.64532, 'auc': 0.95965}
2025-08-17 04:04:27,604 - INFO - val: {'epoch': 70, 'time_epoch': 4.71581, 'loss': 0.09501011, 'lr': 0, 'params': 514193, 'time_iter': 0.03656, 'accuracy': 0.97471, 'precision': 0.35443, 'recall': 0.34568, 'f1': 0.35, 'auc': 0.79749}
2025-08-17 04:04:32,342 - INFO - test: {'epoch': 70, 'time_epoch': 4.71969, 'loss': 0.17242328, 'lr': 0, 'params': 514193, 'time_iter': 0.03659, 'accuracy': 0.96231, 'precision': 0.35294, 'recall': 0.23077, 'f1': 0.27907, 'auc': 0.74755}
2025-08-17 04:04:32,344 - INFO - > Epoch 70: took 79.2s (avg 79.1s) | Best so far: epoch 58	train_loss: 0.0783 train_auc: 0.9473	val_loss: 0.0868 val_auc: 0.8062	test_loss: 0.1642 test_auc: 0.7458
2025-08-17 04:05:44,244 - INFO - train: {'epoch': 71, 'time_epoch': 71.83717, 'eta': 1953.00131, 'eta_hours': 0.5425, 'loss': 0.07176559, 'lr': 2.128e-05, 'params': 514193, 'time_iter': 0.06981, 'accuracy': 0.9779, 'precision': 0.82166, 'recall': 0.52354, 'f1': 0.63956, 'auc': 0.95935}
2025-08-17 04:05:48,961 - INFO - val: {'epoch': 71, 'time_epoch': 4.69535, 'loss': 0.08856474, 'lr': 0, 'params': 514193, 'time_iter': 0.0364, 'accuracy': 0.97763, 'precision': 0.42667, 'recall': 0.39506, 'f1': 0.41026, 'auc': 0.80769}
2025-08-17 04:05:53,681 - INFO - test: {'epoch': 71, 'time_epoch': 4.70251, 'loss': 0.16420775, 'lr': 0, 'params': 514193, 'time_iter': 0.03645, 'accuracy': 0.96499, 'precision': 0.41463, 'recall': 0.26154, 'f1': 0.32075, 'auc': 0.75418}
2025-08-17 04:05:53,683 - INFO - > Epoch 71: took 81.3s (avg 79.1s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:07:04,238 - INFO - train: {'epoch': 72, 'time_epoch': 70.49329, 'eta': 1883.52617, 'eta_hours': 0.5232, 'loss': 0.06975109, 'lr': 1.995e-05, 'params': 514193, 'time_iter': 0.06851, 'accuracy': 0.97766, 'precision': 0.80566, 'recall': 0.53166, 'f1': 0.64059, 'auc': 0.96459}
2025-08-17 04:07:08,926 - INFO - val: {'epoch': 72, 'time_epoch': 4.66695, 'loss': 0.09378965, 'lr': 0, 'params': 514193, 'time_iter': 0.03618, 'accuracy': 0.9769, 'precision': 0.4125, 'recall': 0.40741, 'f1': 0.40994, 'auc': 0.8005}
2025-08-17 04:07:13,531 - INFO - test: {'epoch': 72, 'time_epoch': 4.58796, 'loss': 0.17302596, 'lr': 0, 'params': 514193, 'time_iter': 0.03557, 'accuracy': 0.96207, 'precision': 0.3587, 'recall': 0.25385, 'f1': 0.2973, 'auc': 0.74633}
2025-08-17 04:07:13,533 - INFO - > Epoch 72: took 79.9s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:08:23,883 - INFO - train: {'epoch': 73, 'time_epoch': 70.28668, 'eta': 1813.95091, 'eta_hours': 0.50388, 'loss': 0.06946389, 'lr': 1.864e-05, 'params': 514193, 'time_iter': 0.06831, 'accuracy': 0.97806, 'precision': 0.81559, 'recall': 0.5349, 'f1': 0.64608, 'auc': 0.96662}
2025-08-17 04:08:28,656 - INFO - val: {'epoch': 73, 'time_epoch': 4.75198, 'loss': 0.09581083, 'lr': 0, 'params': 514193, 'time_iter': 0.03684, 'accuracy': 0.97739, 'precision': 0.41429, 'recall': 0.35802, 'f1': 0.38411, 'auc': 0.79867}
2025-08-17 04:08:33,383 - INFO - test: {'epoch': 73, 'time_epoch': 4.71006, 'loss': 0.17042286, 'lr': 0, 'params': 514193, 'time_iter': 0.03651, 'accuracy': 0.96523, 'precision': 0.41772, 'recall': 0.25385, 'f1': 0.31579, 'auc': 0.75379}
2025-08-17 04:08:33,385 - INFO - > Epoch 73: took 79.9s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:09:44,574 - INFO - train: {'epoch': 74, 'time_epoch': 71.125, 'eta': 1744.63612, 'eta_hours': 0.48462, 'loss': 0.06990191, 'lr': 1.737e-05, 'params': 514193, 'time_iter': 0.06912, 'accuracy': 0.97833, 'precision': 0.81227, 'recall': 0.54789, 'f1': 0.65439, 'auc': 0.96276}
2025-08-17 04:09:49,252 - INFO - val: {'epoch': 74, 'time_epoch': 4.65672, 'loss': 0.09425823, 'lr': 0, 'params': 514193, 'time_iter': 0.0361, 'accuracy': 0.97958, 'precision': 0.47458, 'recall': 0.34568, 'f1': 0.4, 'auc': 0.79067}
2025-08-17 04:09:53,907 - INFO - test: {'epoch': 74, 'time_epoch': 4.63808, 'loss': 0.18490029, 'lr': 0, 'params': 514193, 'time_iter': 0.03595, 'accuracy': 0.96377, 'precision': 0.34426, 'recall': 0.16154, 'f1': 0.2199, 'auc': 0.72886}
2025-08-17 04:09:53,910 - INFO - > Epoch 74: took 80.5s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:11:04,495 - INFO - train: {'epoch': 75, 'time_epoch': 70.52209, 'eta': 1675.0833, 'eta_hours': 0.4653, 'loss': 0.06917849, 'lr': 1.614e-05, 'params': 514193, 'time_iter': 0.06853, 'accuracy': 0.97866, 'precision': 0.81548, 'recall': 0.55601, 'f1': 0.6612, 'auc': 0.96576}
2025-08-17 04:11:09,240 - INFO - val: {'epoch': 75, 'time_epoch': 4.72264, 'loss': 0.09986079, 'lr': 0, 'params': 514193, 'time_iter': 0.03661, 'accuracy': 0.97763, 'precision': 0.42667, 'recall': 0.39506, 'f1': 0.41026, 'auc': 0.79796}
2025-08-17 04:11:13,977 - INFO - test: {'epoch': 75, 'time_epoch': 4.71981, 'loss': 0.19064755, 'lr': 0, 'params': 514193, 'time_iter': 0.03659, 'accuracy': 0.96572, 'precision': 0.40678, 'recall': 0.18462, 'f1': 0.25397, 'auc': 0.72905}
2025-08-17 04:11:13,979 - INFO - > Epoch 75: took 80.1s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:12:24,324 - INFO - train: {'epoch': 76, 'time_epoch': 70.28122, 'eta': 1605.43335, 'eta_hours': 0.44595, 'loss': 0.06808109, 'lr': 1.494e-05, 'params': 514193, 'time_iter': 0.0683, 'accuracy': 0.97863, 'precision': 0.81677, 'recall': 0.55357, 'f1': 0.65989, 'auc': 0.96722}
2025-08-17 04:12:29,062 - INFO - val: {'epoch': 76, 'time_epoch': 4.71496, 'loss': 0.09696308, 'lr': 0, 'params': 514193, 'time_iter': 0.03655, 'accuracy': 0.97544, 'precision': 0.37805, 'recall': 0.38272, 'f1': 0.38037, 'auc': 0.80411}
2025-08-17 04:12:33,790 - INFO - test: {'epoch': 76, 'time_epoch': 4.71026, 'loss': 0.1878221, 'lr': 0, 'params': 514193, 'time_iter': 0.03651, 'accuracy': 0.96256, 'precision': 0.35, 'recall': 0.21538, 'f1': 0.26667, 'auc': 0.73426}
2025-08-17 04:12:33,792 - INFO - > Epoch 76: took 79.8s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:13:44,131 - INFO - train: {'epoch': 77, 'time_epoch': 70.27559, 'eta': 1535.76564, 'eta_hours': 0.4266, 'loss': 0.06868, 'lr': 1.378e-05, 'params': 514193, 'time_iter': 0.0683, 'accuracy': 0.97824, 'precision': 0.81235, 'recall': 0.54464, 'f1': 0.65209, 'auc': 0.96489}
2025-08-17 04:13:48,875 - INFO - val: {'epoch': 77, 'time_epoch': 4.72199, 'loss': 0.09408414, 'lr': 0, 'params': 514193, 'time_iter': 0.0366, 'accuracy': 0.9786, 'precision': 0.45205, 'recall': 0.40741, 'f1': 0.42857, 'auc': 0.80524}
2025-08-17 04:13:53,590 - INFO - test: {'epoch': 77, 'time_epoch': 4.69824, 'loss': 0.18295874, 'lr': 0, 'params': 514193, 'time_iter': 0.03642, 'accuracy': 0.96475, 'precision': 0.3913, 'recall': 0.20769, 'f1': 0.27136, 'auc': 0.74134}
2025-08-17 04:13:53,591 - INFO - > Epoch 77: took 79.8s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:15:04,036 - INFO - train: {'epoch': 78, 'time_epoch': 70.38132, 'eta': 1466.11064, 'eta_hours': 0.40725, 'loss': 0.06630102, 'lr': 1.266e-05, 'params': 514193, 'time_iter': 0.0684, 'accuracy': 0.97912, 'precision': 0.82792, 'recall': 0.55844, 'f1': 0.66699, 'auc': 0.96944}
2025-08-17 04:15:08,832 - INFO - val: {'epoch': 78, 'time_epoch': 4.77249, 'loss': 0.09270736, 'lr': 0, 'params': 514193, 'time_iter': 0.037, 'accuracy': 0.97812, 'precision': 0.43478, 'recall': 0.37037, 'f1': 0.4, 'auc': 0.80534}
2025-08-17 04:15:13,606 - INFO - test: {'epoch': 78, 'time_epoch': 4.75626, 'loss': 0.18138351, 'lr': 0, 'params': 514193, 'time_iter': 0.03687, 'accuracy': 0.96207, 'precision': 0.34146, 'recall': 0.21538, 'f1': 0.26415, 'auc': 0.74668}
2025-08-17 04:15:13,608 - INFO - > Epoch 78: took 80.0s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:16:24,491 - INFO - train: {'epoch': 79, 'time_epoch': 70.81995, 'eta': 1396.54713, 'eta_hours': 0.38793, 'loss': 0.06649386, 'lr': 1.158e-05, 'params': 514193, 'time_iter': 0.06882, 'accuracy': 0.9783, 'precision': 0.79233, 'recall': 0.56981, 'f1': 0.66289, 'auc': 0.96883}
2025-08-17 04:16:29,257 - INFO - val: {'epoch': 79, 'time_epoch': 4.74419, 'loss': 0.10209654, 'lr': 0, 'params': 514193, 'time_iter': 0.03678, 'accuracy': 0.9769, 'precision': 0.41463, 'recall': 0.41975, 'f1': 0.41718, 'auc': 0.79777}
2025-08-17 04:16:34,014 - INFO - test: {'epoch': 79, 'time_epoch': 4.74104, 'loss': 0.18888965, 'lr': 0, 'params': 514193, 'time_iter': 0.03675, 'accuracy': 0.96329, 'precision': 0.36, 'recall': 0.20769, 'f1': 0.26341, 'auc': 0.73729}
2025-08-17 04:16:34,017 - INFO - > Epoch 79: took 80.4s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:17:44,919 - INFO - train: {'epoch': 80, 'time_epoch': 70.83809, 'eta': 1326.95686, 'eta_hours': 0.3686, 'loss': 0.06611404, 'lr': 1.054e-05, 'params': 514193, 'time_iter': 0.06884, 'accuracy': 0.97918, 'precision': 0.83152, 'recall': 0.55682, 'f1': 0.66699, 'auc': 0.9691}
2025-08-17 04:17:49,690 - INFO - val: {'epoch': 80, 'time_epoch': 4.74912, 'loss': 0.09716035, 'lr': 0, 'params': 514193, 'time_iter': 0.03681, 'accuracy': 0.97642, 'precision': 0.40476, 'recall': 0.41975, 'f1': 0.41212, 'auc': 0.80277}
2025-08-17 04:17:54,425 - INFO - test: {'epoch': 80, 'time_epoch': 4.71804, 'loss': 0.17744044, 'lr': 0, 'params': 514193, 'time_iter': 0.03657, 'accuracy': 0.96134, 'precision': 0.35052, 'recall': 0.26154, 'f1': 0.29956, 'auc': 0.75399}
2025-08-17 04:17:54,427 - INFO - > Epoch 80: took 80.4s (avg 79.3s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:19:05,344 - INFO - train: {'epoch': 81, 'time_epoch': 70.85263, 'eta': 1257.33935, 'eta_hours': 0.34926, 'loss': 0.06588275, 'lr': 9.55e-06, 'params': 514193, 'time_iter': 0.06886, 'accuracy': 0.97964, 'precision': 0.82674, 'recall': 0.57711, 'f1': 0.67973, 'auc': 0.96817}
2025-08-17 04:19:10,083 - INFO - val: {'epoch': 81, 'time_epoch': 4.71728, 'loss': 0.0949557, 'lr': 0, 'params': 514193, 'time_iter': 0.03657, 'accuracy': 0.97788, 'precision': 0.42424, 'recall': 0.34568, 'f1': 0.38095, 'auc': 0.79317}
2025-08-17 04:19:14,812 - INFO - test: {'epoch': 81, 'time_epoch': 4.71189, 'loss': 0.17836714, 'lr': 0, 'params': 514193, 'time_iter': 0.03653, 'accuracy': 0.96402, 'precision': 0.39024, 'recall': 0.24615, 'f1': 0.30189, 'auc': 0.73863}
2025-08-17 04:19:14,814 - INFO - > Epoch 81: took 80.4s (avg 79.3s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:20:24,902 - INFO - train: {'epoch': 82, 'time_epoch': 70.02517, 'eta': 1187.52259, 'eta_hours': 0.32987, 'loss': 0.06776375, 'lr': 8.6e-06, 'params': 514193, 'time_iter': 0.06805, 'accuracy': 0.97918, 'precision': 0.82676, 'recall': 0.56169, 'f1': 0.66892, 'auc': 0.96584}
2025-08-17 04:20:29,579 - INFO - val: {'epoch': 82, 'time_epoch': 4.65484, 'loss': 0.09739809, 'lr': 0, 'params': 514193, 'time_iter': 0.03608, 'accuracy': 0.97836, 'precision': 0.44118, 'recall': 0.37037, 'f1': 0.40268, 'auc': 0.79985}
2025-08-17 04:20:34,251 - INFO - test: {'epoch': 82, 'time_epoch': 4.65465, 'loss': 0.18435488, 'lr': 0, 'params': 514193, 'time_iter': 0.03608, 'accuracy': 0.96353, 'precision': 0.38372, 'recall': 0.25385, 'f1': 0.30556, 'auc': 0.74424}
2025-08-17 04:20:34,253 - INFO - > Epoch 82: took 79.4s (avg 79.3s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:21:44,447 - INFO - train: {'epoch': 83, 'time_epoch': 70.13114, 'eta': 1117.72106, 'eta_hours': 0.31048, 'loss': 0.06668652, 'lr': 7.7e-06, 'params': 514193, 'time_iter': 0.06815, 'accuracy': 0.97894, 'precision': 0.81013, 'recall': 0.57143, 'f1': 0.67016, 'auc': 0.96829}
2025-08-17 04:21:49,176 - INFO - val: {'epoch': 83, 'time_epoch': 4.70766, 'loss': 0.09795001, 'lr': 0, 'params': 514193, 'time_iter': 0.03649, 'accuracy': 0.9786, 'precision': 0.45205, 'recall': 0.40741, 'f1': 0.42857, 'auc': 0.80642}
2025-08-17 04:21:53,901 - INFO - test: {'epoch': 83, 'time_epoch': 4.70846, 'loss': 0.18132045, 'lr': 0, 'params': 514193, 'time_iter': 0.0365, 'accuracy': 0.96523, 'precision': 0.40845, 'recall': 0.22308, 'f1': 0.28856, 'auc': 0.74946}
2025-08-17 04:21:53,903 - INFO - > Epoch 83: took 79.6s (avg 79.3s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:23:02,700 - INFO - train: {'epoch': 84, 'time_epoch': 68.73525, 'eta': 1047.66544, 'eta_hours': 0.29102, 'loss': 0.06711224, 'lr': 6.84e-06, 'params': 514193, 'time_iter': 0.0668, 'accuracy': 0.97897, 'precision': 0.81991, 'recall': 0.56169, 'f1': 0.66667, 'auc': 0.96833}
2025-08-17 04:23:07,296 - INFO - val: {'epoch': 84, 'time_epoch': 4.57485, 'loss': 0.09897662, 'lr': 0, 'params': 514193, 'time_iter': 0.03546, 'accuracy': 0.9769, 'precision': 0.41026, 'recall': 0.39506, 'f1': 0.40252, 'auc': 0.79793}
2025-08-17 04:23:11,850 - INFO - test: {'epoch': 84, 'time_epoch': 4.53751, 'loss': 0.1818346, 'lr': 0, 'params': 514193, 'time_iter': 0.03517, 'accuracy': 0.96207, 'precision': 0.3617, 'recall': 0.26154, 'f1': 0.30357, 'auc': 0.74697}
2025-08-17 04:23:11,852 - INFO - > Epoch 84: took 77.9s (avg 79.3s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:24:20,793 - INFO - train: {'epoch': 85, 'time_epoch': 68.87903, 'eta': 977.66393, 'eta_hours': 0.27157, 'loss': 0.06508355, 'lr': 6.03e-06, 'params': 514193, 'time_iter': 0.06694, 'accuracy': 0.9793, 'precision': 0.82604, 'recall': 0.56656, 'f1': 0.67212, 'auc': 0.97059}
2025-08-17 04:24:25,427 - INFO - val: {'epoch': 85, 'time_epoch': 4.6129, 'loss': 0.10083962, 'lr': 0, 'params': 514193, 'time_iter': 0.03576, 'accuracy': 0.9735, 'precision': 0.35417, 'recall': 0.41975, 'f1': 0.38418, 'auc': 0.80164}
2025-08-17 04:24:30,029 - INFO - test: {'epoch': 85, 'time_epoch': 4.58514, 'loss': 0.18534279, 'lr': 0, 'params': 514193, 'time_iter': 0.03554, 'accuracy': 0.96159, 'precision': 0.34091, 'recall': 0.23077, 'f1': 0.27523, 'auc': 0.73399}
2025-08-17 04:24:30,032 - INFO - > Epoch 85: took 78.2s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:25:39,147 - INFO - train: {'epoch': 86, 'time_epoch': 69.05376, 'eta': 907.71433, 'eta_hours': 0.25214, 'loss': 0.06700422, 'lr': 5.26e-06, 'params': 514193, 'time_iter': 0.06711, 'accuracy': 0.97976, 'precision': 0.83771, 'recall': 0.56981, 'f1': 0.67826, 'auc': 0.96835}
2025-08-17 04:25:43,765 - INFO - val: {'epoch': 86, 'time_epoch': 4.59785, 'loss': 0.09868843, 'lr': 0, 'params': 514193, 'time_iter': 0.03564, 'accuracy': 0.97715, 'precision': 0.41333, 'recall': 0.38272, 'f1': 0.39744, 'auc': 0.80078}
2025-08-17 04:25:48,363 - INFO - test: {'epoch': 86, 'time_epoch': 4.58183, 'loss': 0.18479784, 'lr': 0, 'params': 514193, 'time_iter': 0.03552, 'accuracy': 0.9628, 'precision': 0.36782, 'recall': 0.24615, 'f1': 0.29493, 'auc': 0.74119}
2025-08-17 04:25:48,365 - INFO - > Epoch 86: took 78.3s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:26:57,382 - INFO - train: {'epoch': 87, 'time_epoch': 68.95394, 'eta': 837.77148, 'eta_hours': 0.23271, 'loss': 0.06596259, 'lr': 4.55e-06, 'params': 514193, 'time_iter': 0.06701, 'accuracy': 0.97872, 'precision': 0.80858, 'recall': 0.56575, 'f1': 0.66571, 'auc': 0.96796}
2025-08-17 04:27:02,135 - INFO - val: {'epoch': 87, 'time_epoch': 4.73198, 'loss': 0.09697775, 'lr': 0, 'params': 514193, 'time_iter': 0.03668, 'accuracy': 0.9769, 'precision': 0.40278, 'recall': 0.35802, 'f1': 0.37908, 'auc': 0.79857}
2025-08-17 04:27:06,850 - INFO - test: {'epoch': 87, 'time_epoch': 4.69861, 'loss': 0.1799988, 'lr': 0, 'params': 514193, 'time_iter': 0.03642, 'accuracy': 0.96426, 'precision': 0.39241, 'recall': 0.23846, 'f1': 0.29665, 'auc': 0.74503}
2025-08-17 04:27:06,853 - INFO - > Epoch 87: took 78.5s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:28:15,443 - INFO - train: {'epoch': 88, 'time_epoch': 68.52666, 'eta': 767.79805, 'eta_hours': 0.21328, 'loss': 0.0649224, 'lr': 3.89e-06, 'params': 514193, 'time_iter': 0.0666, 'accuracy': 0.97903, 'precision': 0.81221, 'recall': 0.57224, 'f1': 0.67143, 'auc': 0.96919}
2025-08-17 04:28:20,000 - INFO - val: {'epoch': 88, 'time_epoch': 4.5362, 'loss': 0.09880051, 'lr': 0, 'params': 514193, 'time_iter': 0.03516, 'accuracy': 0.9752, 'precision': 0.37647, 'recall': 0.39506, 'f1': 0.38554, 'auc': 0.8003}
2025-08-17 04:28:24,533 - INFO - test: {'epoch': 88, 'time_epoch': 4.51674, 'loss': 0.18229719, 'lr': 0, 'params': 514193, 'time_iter': 0.03501, 'accuracy': 0.96353, 'precision': 0.38636, 'recall': 0.26154, 'f1': 0.31193, 'auc': 0.74174}
2025-08-17 04:28:24,536 - INFO - > Epoch 88: took 77.7s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:29:33,236 - INFO - train: {'epoch': 89, 'time_epoch': 68.6394, 'eta': 697.86929, 'eta_hours': 0.19385, 'loss': 0.06482238, 'lr': 3.27e-06, 'params': 514193, 'time_iter': 0.0667, 'accuracy': 0.97915, 'precision': 0.81967, 'recall': 0.56818, 'f1': 0.67114, 'auc': 0.9708}
2025-08-17 04:29:37,804 - INFO - val: {'epoch': 89, 'time_epoch': 4.54616, 'loss': 0.0995767, 'lr': 0, 'params': 514193, 'time_iter': 0.03524, 'accuracy': 0.97666, 'precision': 0.39437, 'recall': 0.34568, 'f1': 0.36842, 'auc': 0.79065}
2025-08-17 04:29:42,353 - INFO - test: {'epoch': 89, 'time_epoch': 4.53204, 'loss': 0.18355588, 'lr': 0, 'params': 514193, 'time_iter': 0.03513, 'accuracy': 0.96426, 'precision': 0.39241, 'recall': 0.23846, 'f1': 0.29665, 'auc': 0.73638}
2025-08-17 04:29:42,355 - INFO - > Epoch 89: took 77.8s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:30:52,170 - INFO - train: {'epoch': 90, 'time_epoch': 69.75197, 'eta': 628.0789, 'eta_hours': 0.17447, 'loss': 0.06326801, 'lr': 2.71e-06, 'params': 514193, 'time_iter': 0.06779, 'accuracy': 0.97994, 'precision': 0.83179, 'recall': 0.58198, 'f1': 0.68481, 'auc': 0.97258}
2025-08-17 04:30:56,876 - INFO - val: {'epoch': 90, 'time_epoch': 4.68411, 'loss': 0.09865647, 'lr': 0, 'params': 514193, 'time_iter': 0.03631, 'accuracy': 0.9769, 'precision': 0.39706, 'recall': 0.33333, 'f1': 0.36242, 'auc': 0.79187}
2025-08-17 04:31:01,557 - INFO - test: {'epoch': 90, 'time_epoch': 4.66351, 'loss': 0.18230098, 'lr': 0, 'params': 514193, 'time_iter': 0.03615, 'accuracy': 0.96499, 'precision': 0.40789, 'recall': 0.23846, 'f1': 0.30097, 'auc': 0.74487}
2025-08-17 04:31:01,559 - INFO - > Epoch 90: took 79.2s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:32:12,199 - INFO - train: {'epoch': 91, 'time_epoch': 70.57834, 'eta': 558.36121, 'eta_hours': 0.1551, 'loss': 0.06420143, 'lr': 2.2e-06, 'params': 514193, 'time_iter': 0.06859, 'accuracy': 0.97985, 'precision': 0.83275, 'recall': 0.57792, 'f1': 0.68232, 'auc': 0.97095}
2025-08-17 04:32:16,901 - INFO - val: {'epoch': 91, 'time_epoch': 4.68013, 'loss': 0.10042661, 'lr': 0, 'params': 514193, 'time_iter': 0.03628, 'accuracy': 0.97642, 'precision': 0.39189, 'recall': 0.35802, 'f1': 0.37419, 'auc': 0.79263}
2025-08-17 04:32:21,593 - INFO - test: {'epoch': 91, 'time_epoch': 4.6746, 'loss': 0.18762407, 'lr': 0, 'params': 514193, 'time_iter': 0.03624, 'accuracy': 0.9645, 'precision': 0.4, 'recall': 0.24615, 'f1': 0.30476, 'auc': 0.74073}
2025-08-17 04:32:21,596 - INFO - > Epoch 91: took 80.0s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:33:30,669 - INFO - train: {'epoch': 92, 'time_epoch': 69.01057, 'eta': 488.507, 'eta_hours': 0.1357, 'loss': 0.0637386, 'lr': 1.74e-06, 'params': 514193, 'time_iter': 0.06707, 'accuracy': 0.97939, 'precision': 0.82512, 'recall': 0.57062, 'f1': 0.67466, 'auc': 0.97105}
2025-08-17 04:33:35,194 - INFO - val: {'epoch': 92, 'time_epoch': 4.50361, 'loss': 0.09824479, 'lr': 0, 'params': 514193, 'time_iter': 0.03491, 'accuracy': 0.97642, 'precision': 0.40244, 'recall': 0.40741, 'f1': 0.40491, 'auc': 0.79977}
2025-08-17 04:33:39,610 - INFO - test: {'epoch': 92, 'time_epoch': 4.39904, 'loss': 0.17987027, 'lr': 0, 'params': 514193, 'time_iter': 0.0341, 'accuracy': 0.9645, 'precision': 0.40244, 'recall': 0.25385, 'f1': 0.31132, 'auc': 0.7465}
2025-08-17 04:33:39,612 - INFO - > Epoch 92: took 78.0s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:34:48,996 - INFO - train: {'epoch': 93, 'time_epoch': 69.31987, 'eta': 418.69049, 'eta_hours': 0.1163, 'loss': 0.06325652, 'lr': 1.33e-06, 'params': 514193, 'time_iter': 0.06737, 'accuracy': 0.98006, 'precision': 0.83103, 'recall': 0.58685, 'f1': 0.68792, 'auc': 0.97233}
2025-08-17 04:34:53,673 - INFO - val: {'epoch': 93, 'time_epoch': 4.65543, 'loss': 0.09880458, 'lr': 0, 'params': 514193, 'time_iter': 0.03609, 'accuracy': 0.97593, 'precision': 0.38462, 'recall': 0.37037, 'f1': 0.37736, 'auc': 0.79979}
2025-08-17 04:34:58,357 - INFO - test: {'epoch': 93, 'time_epoch': 4.66451, 'loss': 0.18565735, 'lr': 0, 'params': 514193, 'time_iter': 0.03616, 'accuracy': 0.96377, 'precision': 0.3908, 'recall': 0.26154, 'f1': 0.31336, 'auc': 0.74015}
2025-08-17 04:34:58,360 - INFO - > Epoch 93: took 78.7s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:36:08,469 - INFO - train: {'epoch': 94, 'time_epoch': 70.04628, 'eta': 348.92267, 'eta_hours': 0.09692, 'loss': 0.06390416, 'lr': 9.8e-07, 'params': 514193, 'time_iter': 0.06807, 'accuracy': 0.97979, 'precision': 0.82474, 'recall': 0.58442, 'f1': 0.68409, 'auc': 0.97133}
2025-08-17 04:36:13,143 - INFO - val: {'epoch': 94, 'time_epoch': 4.65204, 'loss': 0.09939197, 'lr': 0, 'params': 514193, 'time_iter': 0.03606, 'accuracy': 0.9769, 'precision': 0.40789, 'recall': 0.38272, 'f1': 0.3949, 'auc': 0.80017}
2025-08-17 04:36:17,805 - INFO - test: {'epoch': 94, 'time_epoch': 4.64478, 'loss': 0.18341139, 'lr': 0, 'params': 514193, 'time_iter': 0.03601, 'accuracy': 0.96475, 'precision': 0.40741, 'recall': 0.25385, 'f1': 0.3128, 'auc': 0.74794}
2025-08-17 04:36:17,808 - INFO - > Epoch 94: took 79.4s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:37:27,803 - INFO - train: {'epoch': 95, 'time_epoch': 69.93194, 'eta': 279.14427, 'eta_hours': 0.07754, 'loss': 0.06261073, 'lr': 6.8e-07, 'params': 514193, 'time_iter': 0.06796, 'accuracy': 0.9803, 'precision': 0.84272, 'recall': 0.58279, 'f1': 0.68906, 'auc': 0.9732}
2025-08-17 04:37:32,472 - INFO - val: {'epoch': 95, 'time_epoch': 4.64793, 'loss': 0.10105729, 'lr': 0, 'params': 514193, 'time_iter': 0.03603, 'accuracy': 0.97739, 'precision': 0.42683, 'recall': 0.4321, 'f1': 0.42945, 'auc': 0.80349}
2025-08-17 04:37:37,134 - INFO - test: {'epoch': 95, 'time_epoch': 4.64466, 'loss': 0.1925259, 'lr': 0, 'params': 514193, 'time_iter': 0.03601, 'accuracy': 0.96523, 'precision': 0.41096, 'recall': 0.23077, 'f1': 0.29557, 'auc': 0.74404}
2025-08-17 04:37:37,136 - INFO - > Epoch 95: took 79.3s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:38:47,676 - INFO - train: {'epoch': 96, 'time_epoch': 70.47677, 'eta': 209.37957, 'eta_hours': 0.05816, 'loss': 0.06423777, 'lr': 4.4e-07, 'params': 514193, 'time_iter': 0.06849, 'accuracy': 0.97961, 'precision': 0.81695, 'recall': 0.58685, 'f1': 0.68304, 'auc': 0.97039}
2025-08-17 04:38:52,364 - INFO - val: {'epoch': 96, 'time_epoch': 4.66564, 'loss': 0.09762379, 'lr': 0, 'params': 514193, 'time_iter': 0.03617, 'accuracy': 0.97617, 'precision': 0.39241, 'recall': 0.38272, 'f1': 0.3875, 'auc': 0.79941}
2025-08-17 04:38:57,047 - INFO - test: {'epoch': 96, 'time_epoch': 4.66628, 'loss': 0.18345547, 'lr': 0, 'params': 514193, 'time_iter': 0.03617, 'accuracy': 0.96402, 'precision': 0.3875, 'recall': 0.23846, 'f1': 0.29524, 'auc': 0.7404}
2025-08-17 04:38:57,050 - INFO - > Epoch 96: took 79.9s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:40:08,017 - INFO - train: {'epoch': 97, 'time_epoch': 70.90024, 'eta': 139.60897, 'eta_hours': 0.03878, 'loss': 0.06313565, 'lr': 2.5e-07, 'params': 514193, 'time_iter': 0.0689, 'accuracy': 0.97939, 'precision': 0.81986, 'recall': 0.5763, 'f1': 0.67684, 'auc': 0.97228}
2025-08-17 04:40:12,829 - INFO - val: {'epoch': 97, 'time_epoch': 4.78912, 'loss': 0.10463009, 'lr': 0, 'params': 514193, 'time_iter': 0.03712, 'accuracy': 0.97496, 'precision': 0.36905, 'recall': 0.38272, 'f1': 0.37576, 'auc': 0.78351}
2025-08-17 04:40:17,647 - INFO - test: {'epoch': 97, 'time_epoch': 4.8007, 'loss': 0.18560682, 'lr': 0, 'params': 514193, 'time_iter': 0.03721, 'accuracy': 0.95988, 'precision': 0.31959, 'recall': 0.23846, 'f1': 0.27313, 'auc': 0.73731}
2025-08-17 04:40:17,650 - INFO - > Epoch 97: took 80.6s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:41:27,253 - INFO - train: {'epoch': 98, 'time_epoch': 69.53935, 'eta': 69.80181, 'eta_hours': 0.01939, 'loss': 0.06496729, 'lr': 1.1e-07, 'params': 514193, 'time_iter': 0.06758, 'accuracy': 0.97936, 'precision': 0.80963, 'recall': 0.58685, 'f1': 0.68047, 'auc': 0.9707}
2025-08-17 04:41:31,953 - INFO - val: {'epoch': 98, 'time_epoch': 4.67862, 'loss': 0.09970413, 'lr': 0, 'params': 514193, 'time_iter': 0.03627, 'accuracy': 0.97642, 'precision': 0.39189, 'recall': 0.35802, 'f1': 0.37419, 'auc': 0.79804}
2025-08-17 04:41:36,609 - INFO - test: {'epoch': 98, 'time_epoch': 4.63875, 'loss': 0.19019195, 'lr': 0, 'params': 514193, 'time_iter': 0.03596, 'accuracy': 0.96475, 'precision': 0.39437, 'recall': 0.21538, 'f1': 0.27861, 'auc': 0.74377}
2025-08-17 04:41:36,612 - INFO - > Epoch 98: took 79.0s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:42:46,801 - INFO - train: {'epoch': 99, 'time_epoch': 70.12724, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.0631379, 'lr': 3e-08, 'params': 514193, 'time_iter': 0.06815, 'accuracy': 0.9793, 'precision': 0.81998, 'recall': 0.57305, 'f1': 0.67463, 'auc': 0.97248}
2025-08-17 04:42:51,494 - INFO - val: {'epoch': 99, 'time_epoch': 4.67139, 'loss': 0.09741623, 'lr': 0, 'params': 514193, 'time_iter': 0.03621, 'accuracy': 0.97812, 'precision': 0.43478, 'recall': 0.37037, 'f1': 0.4, 'auc': 0.79977}
2025-08-17 04:42:56,150 - INFO - test: {'epoch': 99, 'time_epoch': 4.63833, 'loss': 0.18652075, 'lr': 0, 'params': 514193, 'time_iter': 0.03596, 'accuracy': 0.96523, 'precision': 0.4, 'recall': 0.2, 'f1': 0.26667, 'auc': 0.74415}
2025-08-17 04:42:56,312 - INFO - > Epoch 99: took 79.5s (avg 79.2s) | Best so far: epoch 71	train_loss: 0.0718 train_auc: 0.9594	val_loss: 0.0886 val_auc: 0.8077	test_loss: 0.1642 test_auc: 0.7542
2025-08-17 04:42:56,313 - INFO - Avg time per epoch: 79.21s
2025-08-17 04:42:56,313 - INFO - Total train loop time: 2.20h
2025-08-17 04:42:57,678 - INFO - ============================================================
2025-08-17 04:42:57,679 - INFO - Starting PK-Explainer Analysis (Enhanced Version)
2025-08-17 04:42:57,679 - INFO - ============================================================
2025-08-17 04:42:57,679 - INFO - Dataset: ogbg-molhiv
2025-08-17 04:42:57,679 - INFO - Model type: VanillaModel
2025-08-17 04:42:57,679 - INFO - GNN types available: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-17 04:42:57,785 - INFO - Saved model state to results/molhiv/molhiv-Vanilla-45/model_for_ablation.pt
2025-08-17 04:42:57,785 - INFO - 
Performing ablation study...
2025-08-17 04:42:57,864 - INFO - Getting baseline performance...
2025-08-17 04:42:57,896 - WARNING - Could not extract GNN mapping from optimal weights, attempting to infer from layers...
2025-08-17 04:42:57,896 - INFO - Final GNN mapping: {}
2025-08-17 04:43:02,649 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.7389, 'loss': 0.18652075, 'lr': 0, 'params': 514193, 'time_iter': 0.03674, 'accuracy': 0.96523, 'precision': 0.4, 'recall': 0.2, 'f1': 0.26667, 'auc': 0.74415}
2025-08-17 04:43:02,679 - INFO - ...computing epoch stats took: 0.04s
2025-08-17 04:43:02,679 - INFO - Baseline auc: 0.7441
2025-08-17 04:43:07,464 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.73723, 'loss': 0.18425394, 'lr': 0, 'params': 514193, 'time_iter': 0.03672, 'accuracy': 0.96426, 'precision': 0.39241, 'recall': 0.23846, 'f1': 0.29665, 'auc': 0.73927}
2025-08-17 04:43:07,467 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:43:07,467 - INFO - Layer 0 (Layer_0), Head 0: drop=0.0066
2025-08-17 04:43:12,038 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.51275, 'loss': 0.2005092, 'lr': 0, 'params': 514193, 'time_iter': 0.03498, 'accuracy': 0.96475, 'precision': 0.38095, 'recall': 0.18462, 'f1': 0.2487, 'auc': 0.72293}
2025-08-17 04:43:12,040 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:43:12,040 - INFO - Layer 0 (Layer_0), Head 1: drop=0.0285
2025-08-17 04:43:16,469 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3789, 'loss': 0.18482091, 'lr': 0, 'params': 514193, 'time_iter': 0.03394, 'accuracy': 0.96402, 'precision': 0.36765, 'recall': 0.19231, 'f1': 0.25253, 'auc': 0.73794}
2025-08-17 04:43:16,472 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:43:16,472 - INFO - Layer 0 (Layer_0), Head 2: drop=0.0083
2025-08-17 04:43:20,909 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3858, 'loss': 0.18675494, 'lr': 0, 'params': 514193, 'time_iter': 0.034, 'accuracy': 0.96572, 'precision': 0.4127, 'recall': 0.2, 'f1': 0.26943, 'auc': 0.74582}
2025-08-17 04:43:20,911 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:43:20,911 - INFO - Layer 0 (Layer_0), Head 3: drop=-0.0022
2025-08-17 04:43:25,305 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34585, 'loss': 0.18602979, 'lr': 0, 'params': 514193, 'time_iter': 0.03369, 'accuracy': 0.96353, 'precision': 0.36486, 'recall': 0.20769, 'f1': 0.26471, 'auc': 0.73691}
2025-08-17 04:43:25,310 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:43:25,310 - INFO - Layer 1 (Layer_1), Head 0: drop=0.0097
2025-08-17 04:43:29,741 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.38408, 'loss': 0.19019095, 'lr': 0, 'params': 514193, 'time_iter': 0.03399, 'accuracy': 0.96231, 'precision': 0.32394, 'recall': 0.17692, 'f1': 0.22886, 'auc': 0.72579}
2025-08-17 04:43:29,744 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:43:29,744 - INFO - Layer 1 (Layer_1), Head 1: drop=0.0247
2025-08-17 04:43:34,288 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.49659, 'loss': 0.18334636, 'lr': 0, 'params': 514193, 'time_iter': 0.03486, 'accuracy': 0.96402, 'precision': 0.33333, 'recall': 0.13846, 'f1': 0.19565, 'auc': 0.73767}
2025-08-17 04:43:34,291 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:43:34,291 - INFO - Layer 1 (Layer_1), Head 2: drop=0.0087
2025-08-17 04:43:39,196 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.46209, 'loss': 0.17917095, 'lr': 0, 'params': 514193, 'time_iter': 0.03459, 'accuracy': 0.96596, 'precision': 0.43056, 'recall': 0.23846, 'f1': 0.30693, 'auc': 0.75154}
2025-08-17 04:43:39,197 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:43:39,198 - INFO - Layer 1 (Layer_1), Head 3: drop=-0.0099
2025-08-17 04:43:43,619 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.37309, 'loss': 0.17971386, 'lr': 0, 'params': 514193, 'time_iter': 0.0339, 'accuracy': 0.96499, 'precision': 0.4, 'recall': 0.21538, 'f1': 0.28, 'auc': 0.75554}
2025-08-17 04:43:43,621 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:43:43,621 - INFO - Layer 2 (Layer_2), Head 0: drop=-0.0153
2025-08-17 04:43:48,110 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43843, 'loss': 0.17771375, 'lr': 0, 'params': 514193, 'time_iter': 0.03441, 'accuracy': 0.9611, 'precision': 0.35, 'recall': 0.26923, 'f1': 0.30435, 'auc': 0.74072}
2025-08-17 04:43:48,112 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:43:48,113 - INFO - Layer 2 (Layer_2), Head 1: drop=0.0046
2025-08-17 04:43:52,511 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34919, 'loss': 0.18064445, 'lr': 0, 'params': 514193, 'time_iter': 0.03371, 'accuracy': 0.96499, 'precision': 0.41026, 'recall': 0.24615, 'f1': 0.30769, 'auc': 0.75164}
2025-08-17 04:43:52,513 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:43:52,513 - INFO - Layer 2 (Layer_2), Head 2: drop=-0.0101
2025-08-17 04:43:57,070 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.50805, 'loss': 0.17901614, 'lr': 0, 'params': 514193, 'time_iter': 0.03495, 'accuracy': 0.96499, 'precision': 0.40541, 'recall': 0.23077, 'f1': 0.29412, 'auc': 0.74362}
2025-08-17 04:43:57,072 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:43:57,072 - INFO - Layer 2 (Layer_2), Head 3: drop=0.0007
2025-08-17 04:44:01,621 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.50285, 'loss': 0.18314187, 'lr': 0, 'params': 514193, 'time_iter': 0.03491, 'accuracy': 0.96256, 'precision': 0.33784, 'recall': 0.19231, 'f1': 0.2451, 'auc': 0.75108}
2025-08-17 04:44:01,623 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:44:01,624 - INFO - Layer 3 (Layer_3), Head 0: drop=-0.0093
2025-08-17 04:44:06,059 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.38738, 'loss': 0.18172599, 'lr': 0, 'params': 514193, 'time_iter': 0.03401, 'accuracy': 0.96596, 'precision': 0.43421, 'recall': 0.25385, 'f1': 0.32039, 'auc': 0.73969}
2025-08-17 04:44:06,062 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:44:06,063 - INFO - Layer 3 (Layer_3), Head 1: drop=0.0060
2025-08-17 04:44:10,332 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22561, 'loss': 0.18240869, 'lr': 0, 'params': 514193, 'time_iter': 0.03276, 'accuracy': 0.96426, 'precision': 0.4, 'recall': 0.26154, 'f1': 0.31628, 'auc': 0.75068}
2025-08-17 04:44:10,334 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:44:10,335 - INFO - Layer 3 (Layer_3), Head 2: drop=-0.0088
2025-08-17 04:44:14,785 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40137, 'loss': 0.184351, 'lr': 0, 'params': 514193, 'time_iter': 0.03412, 'accuracy': 0.96426, 'precision': 0.38667, 'recall': 0.22308, 'f1': 0.28293, 'auc': 0.74718}
2025-08-17 04:44:14,787 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:44:14,787 - INFO - Layer 3 (Layer_3), Head 3: drop=-0.0041
2025-08-17 04:44:19,230 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.39651, 'loss': 0.17814786, 'lr': 0, 'params': 514193, 'time_iter': 0.03408, 'accuracy': 0.96304, 'precision': 0.35526, 'recall': 0.20769, 'f1': 0.26214, 'auc': 0.75782}
2025-08-17 04:44:19,232 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:44:19,232 - INFO - Layer 4 (Layer_4), Head 0: drop=-0.0184
2025-08-17 04:44:23,486 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.20661, 'loss': 0.17864932, 'lr': 0, 'params': 514193, 'time_iter': 0.03261, 'accuracy': 0.96523, 'precision': 0.39344, 'recall': 0.18462, 'f1': 0.25131, 'auc': 0.75275}
2025-08-17 04:44:23,488 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:44:23,488 - INFO - Layer 4 (Layer_4), Head 1: drop=-0.0116
2025-08-17 04:44:27,930 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3953, 'loss': 0.18376115, 'lr': 0, 'params': 514193, 'time_iter': 0.03407, 'accuracy': 0.9645, 'precision': 0.38889, 'recall': 0.21538, 'f1': 0.27723, 'auc': 0.74346}
2025-08-17 04:44:27,933 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:44:27,933 - INFO - Layer 4 (Layer_4), Head 2: drop=0.0009
2025-08-17 04:44:32,267 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.28896, 'loss': 0.1824722, 'lr': 0, 'params': 514193, 'time_iter': 0.03325, 'accuracy': 0.96402, 'precision': 0.36765, 'recall': 0.19231, 'f1': 0.25253, 'auc': 0.74402}
2025-08-17 04:44:32,269 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:44:32,269 - INFO - Layer 4 (Layer_4), Head 3: drop=0.0002
2025-08-17 04:44:36,744 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.42558, 'loss': 0.175987, 'lr': 0, 'params': 514193, 'time_iter': 0.03431, 'accuracy': 0.9645, 'precision': 0.38235, 'recall': 0.2, 'f1': 0.26263, 'auc': 0.7516}
2025-08-17 04:44:36,747 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:44:36,747 - INFO - Layer 5 (Layer_5), Head 0: drop=-0.0100
2025-08-17 04:44:41,170 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3776, 'loss': 0.18677267, 'lr': 0, 'params': 514193, 'time_iter': 0.03393, 'accuracy': 0.95794, 'precision': 0.30275, 'recall': 0.25385, 'f1': 0.27615, 'auc': 0.74389}
2025-08-17 04:44:41,173 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:44:41,173 - INFO - Layer 5 (Layer_5), Head 1: drop=0.0003
2025-08-17 04:44:45,699 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.47902, 'loss': 0.19062607, 'lr': 0, 'params': 514193, 'time_iter': 0.03472, 'accuracy': 0.9645, 'precision': 0.37879, 'recall': 0.19231, 'f1': 0.2551, 'auc': 0.74821}
2025-08-17 04:44:45,701 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:44:45,701 - INFO - Layer 5 (Layer_5), Head 2: drop=-0.0055
2025-08-17 04:44:50,098 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35181, 'loss': 0.18714439, 'lr': 0, 'params': 514193, 'time_iter': 0.03373, 'accuracy': 0.96353, 'precision': 0.37805, 'recall': 0.23846, 'f1': 0.29245, 'auc': 0.74239}
2025-08-17 04:44:50,101 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:44:50,101 - INFO - Layer 5 (Layer_5), Head 3: drop=0.0024
2025-08-17 04:44:54,429 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27935, 'loss': 0.18579411, 'lr': 0, 'params': 514193, 'time_iter': 0.03317, 'accuracy': 0.96572, 'precision': 0.4127, 'recall': 0.2, 'f1': 0.26943, 'auc': 0.74066}
2025-08-17 04:44:54,431 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:44:54,431 - INFO - Layer 6 (Layer_6), Head 0: drop=0.0047
2025-08-17 04:44:58,786 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3083, 'loss': 0.17983192, 'lr': 0, 'params': 514193, 'time_iter': 0.0334, 'accuracy': 0.9645, 'precision': 0.39474, 'recall': 0.23077, 'f1': 0.29126, 'auc': 0.74142}
2025-08-17 04:44:58,788 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:44:58,788 - INFO - Layer 6 (Layer_6), Head 1: drop=0.0037
2025-08-17 04:45:03,233 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.39777, 'loss': 0.18150223, 'lr': 0, 'params': 514193, 'time_iter': 0.03409, 'accuracy': 0.96596, 'precision': 0.41667, 'recall': 0.19231, 'f1': 0.26316, 'auc': 0.74525}
2025-08-17 04:45:03,235 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:45:03,235 - INFO - Layer 6 (Layer_6), Head 2: drop=-0.0015
2025-08-17 04:45:07,843 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.55867, 'loss': 0.17794396, 'lr': 0, 'params': 514193, 'time_iter': 0.03534, 'accuracy': 0.9645, 'precision': 0.37879, 'recall': 0.19231, 'f1': 0.2551, 'auc': 0.7508}
2025-08-17 04:45:07,845 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:45:07,846 - INFO - Layer 6 (Layer_6), Head 3: drop=-0.0089
2025-08-17 04:45:12,278 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3819, 'loss': 0.1845618, 'lr': 0, 'params': 514193, 'time_iter': 0.03397, 'accuracy': 0.96402, 'precision': 0.36364, 'recall': 0.18462, 'f1': 0.2449, 'auc': 0.75268}
2025-08-17 04:45:12,280 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:45:12,280 - INFO - Layer 7 (Layer_7), Head 0: drop=-0.0115
2025-08-17 04:45:16,759 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43171, 'loss': 0.18350789, 'lr': 0, 'params': 514193, 'time_iter': 0.03435, 'accuracy': 0.96523, 'precision': 0.39344, 'recall': 0.18462, 'f1': 0.25131, 'auc': 0.74063}
2025-08-17 04:45:16,761 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:45:16,762 - INFO - Layer 7 (Layer_7), Head 1: drop=0.0047
2025-08-17 04:45:21,096 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.28431, 'loss': 0.18381792, 'lr': 0, 'params': 514193, 'time_iter': 0.03321, 'accuracy': 0.96596, 'precision': 0.42188, 'recall': 0.20769, 'f1': 0.27835, 'auc': 0.73781}
2025-08-17 04:45:21,098 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:45:21,098 - INFO - Layer 7 (Layer_7), Head 2: drop=0.0085
2025-08-17 04:45:25,482 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33518, 'loss': 0.19136634, 'lr': 0, 'params': 514193, 'time_iter': 0.03361, 'accuracy': 0.96377, 'precision': 0.33333, 'recall': 0.14615, 'f1': 0.20321, 'auc': 0.72333}
2025-08-17 04:45:25,487 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:45:25,487 - INFO - Layer 7 (Layer_7), Head 3: drop=0.0280
2025-08-17 04:45:29,876 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.344, 'loss': 0.18534584, 'lr': 0, 'params': 514193, 'time_iter': 0.03367, 'accuracy': 0.96475, 'precision': 0.38462, 'recall': 0.19231, 'f1': 0.25641, 'auc': 0.74257}
2025-08-17 04:45:29,879 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:45:29,880 - INFO - Layer 8 (Layer_8), Head 0: drop=0.0021
2025-08-17 04:45:34,219 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29172, 'loss': 0.1880795, 'lr': 0, 'params': 514193, 'time_iter': 0.03327, 'accuracy': 0.96572, 'precision': 0.41538, 'recall': 0.20769, 'f1': 0.27692, 'auc': 0.74491}
2025-08-17 04:45:34,221 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:45:34,221 - INFO - Layer 8 (Layer_8), Head 1: drop=-0.0010
2025-08-17 04:45:38,513 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24561, 'loss': 0.17768939, 'lr': 0, 'params': 514193, 'time_iter': 0.03291, 'accuracy': 0.96548, 'precision': 0.39655, 'recall': 0.17692, 'f1': 0.24468, 'auc': 0.73831}
2025-08-17 04:45:38,515 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:45:38,515 - INFO - Layer 8 (Layer_8), Head 2: drop=0.0078
2025-08-17 04:45:42,912 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3498, 'loss': 0.18356383, 'lr': 0, 'params': 514193, 'time_iter': 0.03372, 'accuracy': 0.96426, 'precision': 0.39506, 'recall': 0.24615, 'f1': 0.30332, 'auc': 0.73944}
2025-08-17 04:45:42,913 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:45:42,914 - INFO - Layer 8 (Layer_8), Head 3: drop=0.0063
2025-08-17 04:45:47,231 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.267, 'loss': 0.1852534, 'lr': 0, 'params': 514193, 'time_iter': 0.03308, 'accuracy': 0.96499, 'precision': 0.39062, 'recall': 0.19231, 'f1': 0.25773, 'auc': 0.74861}
2025-08-17 04:45:47,233 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:45:47,233 - INFO - Layer 9 (Layer_9), Head 0: drop=-0.0060
2025-08-17 04:45:51,585 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.30585, 'loss': 0.18374812, 'lr': 0, 'params': 514193, 'time_iter': 0.03338, 'accuracy': 0.96499, 'precision': 0.3871, 'recall': 0.18462, 'f1': 0.25, 'auc': 0.73713}
2025-08-17 04:45:51,587 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:45:51,587 - INFO - Layer 9 (Layer_9), Head 1: drop=0.0094
2025-08-17 04:45:55,896 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26088, 'loss': 0.18148059, 'lr': 0, 'params': 514193, 'time_iter': 0.03303, 'accuracy': 0.96548, 'precision': 0.41176, 'recall': 0.21538, 'f1': 0.28283, 'auc': 0.74673}
2025-08-17 04:45:55,898 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:45:55,898 - INFO - Layer 9 (Layer_9), Head 2: drop=-0.0035
2025-08-17 04:46:00,383 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.436, 'loss': 0.18312677, 'lr': 0, 'params': 514193, 'time_iter': 0.03439, 'accuracy': 0.96645, 'precision': 0.42593, 'recall': 0.17692, 'f1': 0.25, 'auc': 0.74255}
2025-08-17 04:46:00,385 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:00,385 - INFO - Layer 9 (Layer_9), Head 3: drop=0.0022
2025-08-17 04:46:04,688 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25519, 'loss': 0.18653766, 'lr': 0, 'params': 514193, 'time_iter': 0.03299, 'accuracy': 0.96523, 'precision': 0.4, 'recall': 0.2, 'f1': 0.26667, 'auc': 0.73868}
2025-08-17 04:46:04,691 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:04,691 - INFO - Layer 10 (Layer_10), Head 0: drop=0.0074
2025-08-17 04:46:09,086 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34656, 'loss': 0.18180156, 'lr': 0, 'params': 514193, 'time_iter': 0.03369, 'accuracy': 0.96523, 'precision': 0.4, 'recall': 0.2, 'f1': 0.26667, 'auc': 0.74475}
2025-08-17 04:46:09,089 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:09,089 - INFO - Layer 10 (Layer_10), Head 1: drop=-0.0008
2025-08-17 04:46:13,337 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.20172, 'loss': 0.18112532, 'lr': 0, 'params': 514193, 'time_iter': 0.03257, 'accuracy': 0.96499, 'precision': 0.39394, 'recall': 0.2, 'f1': 0.26531, 'auc': 0.74878}
2025-08-17 04:46:13,340 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:13,340 - INFO - Layer 10 (Layer_10), Head 2: drop=-0.0062
2025-08-17 04:46:17,681 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29334, 'loss': 0.18494512, 'lr': 0, 'params': 514193, 'time_iter': 0.03328, 'accuracy': 0.96475, 'precision': 0.38095, 'recall': 0.18462, 'f1': 0.2487, 'auc': 0.74272}
2025-08-17 04:46:17,683 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:17,683 - INFO - Layer 10 (Layer_10), Head 3: drop=0.0019
2025-08-17 04:46:22,138 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.4076, 'loss': 0.18441512, 'lr': 0, 'params': 514193, 'time_iter': 0.03417, 'accuracy': 0.96475, 'precision': 0.38806, 'recall': 0.2, 'f1': 0.26396, 'auc': 0.74441}
2025-08-17 04:46:22,140 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:22,140 - INFO - Layer 11 (Layer_11), Head 0: drop=-0.0003
2025-08-17 04:46:26,568 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.38033, 'loss': 0.1821555, 'lr': 0, 'params': 514193, 'time_iter': 0.03396, 'accuracy': 0.96475, 'precision': 0.38462, 'recall': 0.19231, 'f1': 0.25641, 'auc': 0.74451}
2025-08-17 04:46:26,571 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:26,571 - INFO - Layer 11 (Layer_11), Head 1: drop=-0.0005
2025-08-17 04:46:30,993 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.37742, 'loss': 0.18406334, 'lr': 0, 'params': 514193, 'time_iter': 0.03393, 'accuracy': 0.96523, 'precision': 0.40299, 'recall': 0.20769, 'f1': 0.27411, 'auc': 0.74644}
2025-08-17 04:46:30,995 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:30,996 - INFO - Layer 11 (Layer_11), Head 2: drop=-0.0031
2025-08-17 04:46:35,456 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.41271, 'loss': 0.18547515, 'lr': 0, 'params': 514193, 'time_iter': 0.03421, 'accuracy': 0.96499, 'precision': 0.39394, 'recall': 0.2, 'f1': 0.26531, 'auc': 0.74402}
2025-08-17 04:46:35,458 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:35,458 - INFO - Layer 11 (Layer_11), Head 3: drop=0.0002
2025-08-17 04:46:39,879 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.37203, 'loss': 0.18739065, 'lr': 0, 'params': 514193, 'time_iter': 0.03389, 'accuracy': 0.96499, 'precision': 0.39062, 'recall': 0.19231, 'f1': 0.25773, 'auc': 0.74502}
2025-08-17 04:46:39,881 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:39,881 - INFO - Layer 12 (Layer_12), Head 0: drop=-0.0012
2025-08-17 04:46:44,349 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.41932, 'loss': 0.17856159, 'lr': 0, 'params': 514193, 'time_iter': 0.03426, 'accuracy': 0.96548, 'precision': 0.40323, 'recall': 0.19231, 'f1': 0.26042, 'auc': 0.74438}
2025-08-17 04:46:44,351 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:44,352 - INFO - Layer 12 (Layer_12), Head 1: drop=-0.0003
2025-08-17 04:46:48,661 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26452, 'loss': 0.18662947, 'lr': 0, 'params': 514193, 'time_iter': 0.03306, 'accuracy': 0.96499, 'precision': 0.39062, 'recall': 0.19231, 'f1': 0.25773, 'auc': 0.7401}
2025-08-17 04:46:48,663 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:48,663 - INFO - Layer 12 (Layer_12), Head 2: drop=0.0054
2025-08-17 04:46:53,025 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.31473, 'loss': 0.18614998, 'lr': 0, 'params': 514193, 'time_iter': 0.03345, 'accuracy': 0.96475, 'precision': 0.38095, 'recall': 0.18462, 'f1': 0.2487, 'auc': 0.73765}
2025-08-17 04:46:53,027 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:53,027 - INFO - Layer 12 (Layer_12), Head 3: drop=0.0087
2025-08-17 04:46:57,523 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44791, 'loss': 0.18321716, 'lr': 0, 'params': 514193, 'time_iter': 0.03448, 'accuracy': 0.96548, 'precision': 0.40323, 'recall': 0.19231, 'f1': 0.26042, 'auc': 0.74071}
2025-08-17 04:46:57,525 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:57,525 - INFO - Layer 13 (Layer_13), Head 0: drop=0.0046
2025-08-17 04:47:01,932 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36242, 'loss': 0.18153751, 'lr': 0, 'params': 514193, 'time_iter': 0.03382, 'accuracy': 0.96523, 'precision': 0.39683, 'recall': 0.19231, 'f1': 0.25907, 'auc': 0.74474}
2025-08-17 04:47:01,934 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:47:01,934 - INFO - Layer 13 (Layer_13), Head 1: drop=-0.0008
2025-08-17 04:47:06,353 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.37166, 'loss': 0.1824704, 'lr': 0, 'params': 514193, 'time_iter': 0.03389, 'accuracy': 0.96499, 'precision': 0.39394, 'recall': 0.2, 'f1': 0.26531, 'auc': 0.74399}
2025-08-17 04:47:06,356 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:47:06,356 - INFO - Layer 13 (Layer_13), Head 2: drop=0.0002
2025-08-17 04:47:10,733 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33222, 'loss': 0.18460253, 'lr': 0, 'params': 514193, 'time_iter': 0.03358, 'accuracy': 0.96523, 'precision': 0.4, 'recall': 0.2, 'f1': 0.26667, 'auc': 0.74546}
2025-08-17 04:47:10,736 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:47:10,736 - INFO - Layer 13 (Layer_13), Head 3: drop=-0.0018
2025-08-17 04:47:15,233 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44992, 'loss': 0.18177528, 'lr': 0, 'params': 514193, 'time_iter': 0.0345, 'accuracy': 0.96475, 'precision': 0.38462, 'recall': 0.19231, 'f1': 0.25641, 'auc': 0.74231}
2025-08-17 04:47:15,235 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:47:15,235 - INFO - Layer 14 (Layer_14), Head 0: drop=0.0025
2025-08-17 04:47:19,584 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.30196, 'loss': 0.17765504, 'lr': 0, 'params': 514193, 'time_iter': 0.03335, 'accuracy': 0.96499, 'precision': 0.39062, 'recall': 0.19231, 'f1': 0.25773, 'auc': 0.74708}
2025-08-17 04:47:19,586 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:47:19,586 - INFO - Layer 14 (Layer_14), Head 1: drop=-0.0039
2025-08-17 04:47:24,009 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.37592, 'loss': 0.17946764, 'lr': 0, 'params': 514193, 'time_iter': 0.03392, 'accuracy': 0.96523, 'precision': 0.39683, 'recall': 0.19231, 'f1': 0.25907, 'auc': 0.7458}
2025-08-17 04:47:24,011 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:47:24,011 - INFO - Layer 14 (Layer_14), Head 2: drop=-0.0022
2025-08-17 04:47:28,366 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.30725, 'loss': 0.17972389, 'lr': 0, 'params': 514193, 'time_iter': 0.03339, 'accuracy': 0.96499, 'precision': 0.38333, 'recall': 0.17692, 'f1': 0.24211, 'auc': 0.74582}
2025-08-17 04:47:28,368 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:47:28,368 - INFO - Layer 14 (Layer_14), Head 3: drop=-0.0022
2025-08-17 04:47:28,373 - INFO - 
FIDELITY METRICS:
2025-08-17 04:47:28,374 - INFO - Fidelity (top 30 heads): 0.0070
2025-08-17 04:47:28,374 - INFO - Fidelity- (bottom 30 heads): -0.0054
2025-08-17 04:47:28,374 - INFO - 
GNN distribution in important heads:
2025-08-17 04:47:28,374 - INFO -   Layer_0: 3 heads
2025-08-17 04:47:28,374 - INFO -   Layer_7: 3 heads
2025-08-17 04:47:28,374 - INFO -   Layer_1: 3 heads
2025-08-17 04:47:28,374 - INFO -   Layer_8: 3 heads
2025-08-17 04:47:28,374 - INFO -   Layer_9: 2 heads
2025-08-17 04:47:28,374 - INFO -   Layer_12: 2 heads
2025-08-17 04:47:28,374 - INFO -   Layer_10: 2 heads
2025-08-17 04:47:28,374 - INFO -   Layer_6: 2 heads
2025-08-17 04:47:28,374 - INFO -   Layer_13: 2 heads
2025-08-17 04:47:28,374 - INFO -   Layer_2: 2 heads
2025-08-17 04:47:28,374 - INFO -   Layer_5: 2 heads
2025-08-17 04:47:28,374 - INFO -   Layer_4: 2 heads
2025-08-17 04:47:28,374 - INFO -   Layer_3: 1 heads
2025-08-17 04:47:28,374 - INFO -   Layer_14: 1 heads
2025-08-17 04:47:28,374 - INFO - 
Interpretability Analysis:
2025-08-17 04:47:28,374 - INFO -   Fidelity: 0.0070
2025-08-17 04:47:28,374 - INFO -   Fidelity-: -0.0054
2025-08-17 04:47:28,374 - INFO -   Total heads tested: 60
2025-08-17 04:47:32,313 - INFO - Excel results saved to results/molhiv/molhiv-Vanilla-45/pk_explainer_results.xlsx
2025-08-17 04:47:33,866 - INFO - Saved visualizations to results/molhiv/molhiv-Vanilla-45/pk_explainer_results
2025-08-17 04:47:33,869 - INFO - 
PK-Explainer results saved to:
2025-08-17 04:47:33,869 - INFO -   - Excel: results/molhiv/molhiv-Vanilla-45/pk_explainer_results.xlsx
2025-08-17 04:47:33,870 - INFO -   - JSON: results/molhiv/molhiv-Vanilla-45/pk_explainer_results.json
2025-08-17 04:47:33,870 - INFO -   - Visualizations: results/molhiv/molhiv-Vanilla-45/pk_explainer_results
2025-08-17 04:47:33,885 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-45
2025-08-17 04:47:33,885 - INFO - Total time: 8265.27s (2.30h)
2025-08-17 04:47:33,918 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-45/agg
2025-08-17 04:47:33,918 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-17 04:47:33,918 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-45
2025-08-17 04:47:33,918 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-45/test_results/
Completed seed 45. Results saved in results/molhiv/molhiv-Vanilla-45
----------------------------------------
Running experiment with seed: 47
Starting training for seed 47...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/TRANS
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/TRANS/confignas.yaml
Using device: cuda
2025-08-17 04:47:46,588 - INFO - GPU Mem: 25.2GB
2025-08-17 04:47:46,588 - INFO - Run directory: results/molhiv/molhiv-Vanilla-47
2025-08-17 04:47:46,588 - INFO - Seed: 47
2025-08-17 04:47:46,588 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-17 04:47:46,588 - INFO - Routing mode: none
2025-08-17 04:47:46,588 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-17 04:47:46,588 - INFO - Number of layers: 15
2025-08-17 04:47:46,588 - INFO - Uncertainty enabled: False
2025-08-17 04:47:46,588 - INFO - Training mode: custom
2025-08-17 04:47:46,588 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-17 04:47:46,588 - INFO - Additional features: Router weights logging + JSON export
2025-08-17 04:47:52,619 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 04:47:52,622 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-17 04:47:52,623 - INFO -   undirected: True
2025-08-17 04:47:52,623 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 04:47:52,623 - INFO -   avg num_nodes/graph: 25
2025-08-17 04:47:52,624 - INFO -   num node features: 9
2025-08-17 04:47:52,624 - INFO -   num edge features: 3
2025-08-17 04:47:52,624 - INFO -   num tasks: 1
2025-08-17 04:47:52,624 - INFO -   num classes: 2
2025-08-17 04:47:52,624 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-17 04:47:52,624 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-17 04:47:52,627 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 11%|█         | 4483/41127 [00:10<01:21, 448.24it/s] 16%|█▌        | 6539/41127 [00:21<02:01, 284.61it/s] 24%|██▍       | 9973/41127 [00:31<01:40, 309.09it/s] 33%|███▎      | 13662/41127 [00:41<01:22, 332.07it/s] 38%|███▊      | 15718/41127 [00:53<01:35, 265.41it/s] 45%|████▍     | 18381/41127 [01:03<01:25, 265.69it/s] 51%|█████▏    | 21135/41127 [01:13<01:14, 267.63it/s] 60%|█████▉    | 24568/41127 [01:23<00:56, 290.93it/s] 70%|███████   | 28791/41127 [01:33<00:37, 330.57it/s] 76%|███████▌  | 31092/41127 [01:43<00:33, 299.47it/s] 83%|████████▎ | 34057/41127 [01:53<00:23, 298.57it/s] 93%|█████████▎| 38399/41127 [02:03<00:08, 339.35it/s] 93%|█████████▎| 38399/41127 [02:14<00:08, 339.35it/s] 98%|█████████▊| 40107/41127 [02:14<00:03, 287.24it/s]100%|█████████▉| 41031/41127 [02:24<00:00, 228.04it/s]100%|██████████| 41127/41127 [02:24<00:00, 283.70it/s]
2025-08-17 04:50:18,760 - INFO - Done! Took 00:02:26.14
2025-08-17 04:50:18,910 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-17 04:50:19,100 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-17 04:50:19,101 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-08-17 04:50:19,101 - INFO - Inner model has get_darts_model: False
2025-08-17 04:50:19,103 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-08-17 04:50:19,106 - INFO - Number of parameters: 514,193
2025-08-17 04:50:19,106 - INFO - Starting optimized training: 2025-08-17 04:50:19.106547
2025-08-17 04:50:25,486 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 04:50:25,487 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-17 04:50:25,488 - INFO -   undirected: True
2025-08-17 04:50:25,488 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 04:50:25,489 - INFO -   avg num_nodes/graph: 25
2025-08-17 04:50:25,489 - INFO -   num node features: 9
2025-08-17 04:50:25,489 - INFO -   num edge features: 3
2025-08-17 04:50:25,489 - INFO -   num tasks: 1
2025-08-17 04:50:25,489 - INFO -   num classes: 2
2025-08-17 04:50:25,490 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-17 04:50:25,490 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-17 04:50:25,493 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  8%|▊         | 3436/41127 [00:10<01:51, 337.20it/s] 14%|█▎        | 5635/41127 [00:20<02:12, 267.03it/s] 14%|█▎        | 5635/41127 [00:31<02:12, 267.03it/s] 17%|█▋        | 6929/41127 [00:31<02:54, 196.25it/s] 24%|██▍       | 9804/41127 [00:41<02:15, 231.19it/s] 29%|██▉       | 12058/41127 [00:51<02:06, 229.14it/s] 35%|███▌      | 14540/41127 [01:01<01:53, 234.28it/s] 38%|███▊      | 15605/41127 [01:11<02:13, 191.78it/s] 41%|████      | 16850/41127 [01:21<02:22, 170.63it/s] 48%|████▊     | 19702/41127 [01:31<01:44, 204.76it/s] 54%|█████▍    | 22243/41127 [01:41<01:26, 219.41it/s] 60%|█████▉    | 24674/41127 [01:52<01:12, 225.64it/s] 67%|██████▋   | 27537/41127 [02:02<00:56, 242.56it/s] 71%|███████▏  | 29350/41127 [02:12<00:52, 223.61it/s] 76%|███████▌  | 31120/41127 [02:22<00:48, 208.46it/s] 81%|████████  | 33185/41127 [02:32<00:38, 207.87it/s] 85%|████████▍ | 34946/41127 [02:42<00:31, 197.86it/s] 89%|████████▉ | 36632/41127 [02:52<00:23, 189.11it/s] 95%|█████████▍| 39003/41127 [03:02<00:10, 202.67it/s] 98%|█████████▊| 40478/41127 [03:12<00:03, 186.13it/s]100%|██████████| 41127/41127 [03:21<00:00, 204.45it/s]
2025-08-17 04:53:47,880 - INFO - Done! Took 00:03:22.39
2025-08-17 04:53:48,031 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-17 04:53:48,327 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-17 04:53:48,327 - INFO - Start from epoch 0
2025-08-17 04:55:06,660 - INFO - train: {'epoch': 0, 'time_epoch': 78.15372, 'eta': 7737.21853, 'eta_hours': 2.14923, 'loss': 0.88289331, 'lr': 0.0, 'params': 514193, 'time_iter': 0.07595, 'accuracy': 0.03745, 'precision': 0.03745, 'recall': 1.0, 'f1': 0.07219, 'auc': 0.4606}
2025-08-17 04:55:06,672 - INFO - ...computing epoch stats took: 0.17s
2025-08-17 04:55:11,884 - INFO - val: {'epoch': 0, 'time_epoch': 5.19439, 'loss': 0.90027915, 'lr': 0, 'params': 514193, 'time_iter': 0.04027, 'accuracy': 0.01969, 'precision': 0.01969, 'recall': 1.0, 'f1': 0.03863, 'auc': 0.41857}
2025-08-17 04:55:11,888 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:55:16,987 - INFO - test: {'epoch': 0, 'time_epoch': 5.08127, 'loss': 0.91006904, 'lr': 0, 'params': 514193, 'time_iter': 0.03939, 'accuracy': 0.03161, 'precision': 0.03161, 'recall': 1.0, 'f1': 0.06128, 'auc': 0.3854}
2025-08-17 04:55:16,993 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:55:16,994 - INFO - > Epoch 0: took 88.7s (avg 88.7s) | Best so far: epoch 0	train_loss: 0.8829 train_auc: 0.4606	val_loss: 0.9003 val_auc: 0.4186	test_loss: 0.9101 test_auc: 0.3854
2025-08-17 04:56:29,507 - INFO - train: {'epoch': 1, 'time_epoch': 72.43714, 'eta': 7378.95213, 'eta_hours': 2.04971, 'loss': 0.7196214, 'lr': 2e-05, 'params': 514193, 'time_iter': 0.0704, 'accuracy': 0.30352, 'precision': 0.03907, 'recall': 0.74594, 'f1': 0.07425, 'auc': 0.51274}
2025-08-17 04:56:29,516 - INFO - ...computing epoch stats took: 0.06s
2025-08-17 04:56:34,015 - INFO - val: {'epoch': 1, 'time_epoch': 4.48323, 'loss': 0.5716202, 'lr': 0, 'params': 514193, 'time_iter': 0.03475, 'accuracy': 0.56236, 'precision': 0.02117, 'recall': 0.46914, 'f1': 0.04051, 'auc': 0.50576}
2025-08-17 04:56:34,018 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:56:38,407 - INFO - test: {'epoch': 1, 'time_epoch': 4.37321, 'loss': 0.5430011, 'lr': 0, 'params': 514193, 'time_iter': 0.0339, 'accuracy': 0.5964, 'precision': 0.03916, 'recall': 0.5, 'f1': 0.07263, 'auc': 0.54107}
2025-08-17 04:56:38,410 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:56:38,410 - INFO - > Epoch 1: took 81.4s (avg 85.0s) | Best so far: epoch 1	train_loss: 0.7196 train_auc: 0.5127	val_loss: 0.5716 val_auc: 0.5058	test_loss: 0.5430 test_auc: 0.5411
2025-08-17 04:57:47,660 - INFO - train: {'epoch': 2, 'time_epoch': 69.15913, 'eta': 7105.24978, 'eta_hours': 1.97368, 'loss': 0.32508967, 'lr': 4e-05, 'params': 514193, 'time_iter': 0.06721, 'accuracy': 0.86666, 'precision': 0.04761, 'recall': 0.13474, 'f1': 0.07035, 'auc': 0.57442}
2025-08-17 04:57:47,669 - INFO - ...computing epoch stats took: 0.08s
2025-08-17 04:57:52,203 - INFO - val: {'epoch': 2, 'time_epoch': 4.51658, 'loss': 0.16309929, 'lr': 0, 'params': 514193, 'time_iter': 0.03501, 'accuracy': 0.97496, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.59353}
2025-08-17 04:57:52,206 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:57:56,552 - INFO - test: {'epoch': 2, 'time_epoch': 4.32882, 'loss': 0.17259198, 'lr': 0, 'params': 514193, 'time_iter': 0.03356, 'accuracy': 0.96159, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66664}
2025-08-17 04:57:56,555 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:57:56,556 - INFO - > Epoch 2: took 78.1s (avg 82.7s) | Best so far: epoch 2	train_loss: 0.3251 train_auc: 0.5744	val_loss: 0.1631 val_auc: 0.5935	test_loss: 0.1726 test_auc: 0.6666
2025-08-17 04:59:05,872 - INFO - train: {'epoch': 3, 'time_epoch': 69.22343, 'eta': 6935.36219, 'eta_hours': 1.92649, 'loss': 0.17372867, 'lr': 6e-05, 'params': 514193, 'time_iter': 0.06727, 'accuracy': 0.96137, 'precision': 0.13208, 'recall': 0.00568, 'f1': 0.01089, 'auc': 0.60564}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 04:59:10,362 - INFO - val: {'epoch': 3, 'time_epoch': 4.46665, 'loss': 0.09882154, 'lr': 0, 'params': 514193, 'time_iter': 0.03463, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66853}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 04:59:14,762 - INFO - test: {'epoch': 3, 'time_epoch': 4.3815, 'loss': 0.13562407, 'lr': 0, 'params': 514193, 'time_iter': 0.03397, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67486}
2025-08-17 04:59:14,765 - INFO - > Epoch 3: took 78.2s (avg 81.6s) | Best so far: epoch 3	train_loss: 0.1737 train_auc: 0.6056	val_loss: 0.0988 val_auc: 0.6685	test_loss: 0.1356 test_auc: 0.6749
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:00:24,494 - INFO - train: {'epoch': 4, 'time_epoch': 69.6602, 'eta': 6814.0388, 'eta_hours': 1.89279, 'loss': 0.15949545, 'lr': 8e-05, 'params': 514193, 'time_iter': 0.0677, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.63784}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:00:28,900 - INFO - val: {'epoch': 4, 'time_epoch': 4.38447, 'loss': 0.09767073, 'lr': 0, 'params': 514193, 'time_iter': 0.03399, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67731}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:00:33,276 - INFO - test: {'epoch': 4, 'time_epoch': 4.35903, 'loss': 0.13126656, 'lr': 0, 'params': 514193, 'time_iter': 0.03379, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69763}
2025-08-17 05:00:33,278 - INFO - > Epoch 4: took 78.5s (avg 81.0s) | Best so far: epoch 4	train_loss: 0.1595 train_auc: 0.6378	val_loss: 0.0977 val_auc: 0.6773	test_loss: 0.1313 test_auc: 0.6976
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:01:42,597 - INFO - train: {'epoch': 5, 'time_epoch': 69.24595, 'eta': 6703.4466, 'eta_hours': 1.86207, 'loss': 0.15502059, 'lr': 0.0001, 'params': 514193, 'time_iter': 0.06729, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.65959}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:01:47,101 - INFO - val: {'epoch': 5, 'time_epoch': 4.48264, 'loss': 0.09681578, 'lr': 0, 'params': 514193, 'time_iter': 0.03475, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70203}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:01:51,462 - INFO - test: {'epoch': 5, 'time_epoch': 4.34503, 'loss': 0.13249639, 'lr': 0, 'params': 514193, 'time_iter': 0.03368, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71318}
2025-08-17 05:01:51,465 - INFO - > Epoch 5: took 78.2s (avg 80.5s) | Best so far: epoch 5	train_loss: 0.1550 train_auc: 0.6596	val_loss: 0.0968 val_auc: 0.7020	test_loss: 0.1325 test_auc: 0.7132
2025-08-17 05:02:59,342 - INFO - train: {'epoch': 6, 'time_epoch': 67.79372, 'eta': 6585.37372, 'eta_hours': 1.82927, 'loss': 0.1475728, 'lr': 9.997e-05, 'params': 514193, 'time_iter': 0.06588, 'accuracy': 0.96258, 'precision': 0.66667, 'recall': 0.00162, 'f1': 0.00324, 'auc': 0.70539}
2025-08-17 05:03:03,840 - INFO - val: {'epoch': 6, 'time_epoch': 4.47488, 'loss': 0.09166916, 'lr': 0, 'params': 514193, 'time_iter': 0.03469, 'accuracy': 0.98128, 'precision': 0.64286, 'recall': 0.11111, 'f1': 0.18947, 'auc': 0.68929}
2025-08-17 05:03:08,199 - INFO - test: {'epoch': 6, 'time_epoch': 4.29414, 'loss': 0.12642433, 'lr': 0, 'params': 514193, 'time_iter': 0.03329, 'accuracy': 0.96888, 'precision': 0.66667, 'recall': 0.03077, 'f1': 0.05882, 'auc': 0.71072}
2025-08-17 05:03:08,201 - INFO - > Epoch 6: took 76.7s (avg 80.0s) | Best so far: epoch 5	train_loss: 0.1550 train_auc: 0.6596	val_loss: 0.0968 val_auc: 0.7020	test_loss: 0.1325 test_auc: 0.7132
2025-08-17 05:04:15,461 - INFO - train: {'epoch': 7, 'time_epoch': 67.17574, 'eta': 6472.76388, 'eta_hours': 1.79799, 'loss': 0.14279858, 'lr': 9.989e-05, 'params': 514193, 'time_iter': 0.06528, 'accuracy': 0.96246, 'precision': 0.48387, 'recall': 0.03653, 'f1': 0.06792, 'auc': 0.72031}
2025-08-17 05:04:19,937 - INFO - val: {'epoch': 7, 'time_epoch': 4.45299, 'loss': 0.0968416, 'lr': 0, 'params': 514193, 'time_iter': 0.03452, 'accuracy': 0.9786, 'precision': 0.37931, 'recall': 0.1358, 'f1': 0.2, 'auc': 0.70349}
2025-08-17 05:04:24,331 - INFO - test: {'epoch': 7, 'time_epoch': 4.37756, 'loss': 0.12161563, 'lr': 0, 'params': 514193, 'time_iter': 0.03393, 'accuracy': 0.96718, 'precision': 0.45902, 'recall': 0.21538, 'f1': 0.29319, 'auc': 0.76594}
2025-08-17 05:04:24,334 - INFO - > Epoch 7: took 76.1s (avg 79.5s) | Best so far: epoch 7	train_loss: 0.1428 train_auc: 0.7203	val_loss: 0.0968 val_auc: 0.7035	test_loss: 0.1216 test_auc: 0.7659
2025-08-17 05:05:31,694 - INFO - train: {'epoch': 8, 'time_epoch': 67.27912, 'eta': 6371.29581, 'eta_hours': 1.7698, 'loss': 0.14007556, 'lr': 9.975e-05, 'params': 514193, 'time_iter': 0.06538, 'accuracy': 0.96234, 'precision': 0.47009, 'recall': 0.04464, 'f1': 0.08154, 'auc': 0.73101}
2025-08-17 05:05:36,079 - INFO - val: {'epoch': 8, 'time_epoch': 4.36277, 'loss': 0.09522061, 'lr': 0, 'params': 514193, 'time_iter': 0.03382, 'accuracy': 0.97812, 'precision': 0.36364, 'recall': 0.14815, 'f1': 0.21053, 'auc': 0.71997}
2025-08-17 05:05:40,427 - INFO - test: {'epoch': 8, 'time_epoch': 4.31712, 'loss': 0.1265655, 'lr': 0, 'params': 514193, 'time_iter': 0.03347, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.21538, 'f1': 0.30108, 'auc': 0.73789}
2025-08-17 05:05:40,439 - INFO - > Epoch 8: took 76.1s (avg 79.1s) | Best so far: epoch 8	train_loss: 0.1401 train_auc: 0.7310	val_loss: 0.0952 val_auc: 0.7200	test_loss: 0.1266 test_auc: 0.7379
2025-08-17 05:06:48,557 - INFO - train: {'epoch': 9, 'time_epoch': 68.03013, 'eta': 6283.42459, 'eta_hours': 1.7454, 'loss': 0.13628334, 'lr': 9.956e-05, 'params': 514193, 'time_iter': 0.06611, 'accuracy': 0.96356, 'precision': 0.58291, 'recall': 0.09416, 'f1': 0.16212, 'auc': 0.75412}
2025-08-17 05:06:52,971 - INFO - val: {'epoch': 9, 'time_epoch': 4.38913, 'loss': 0.08928415, 'lr': 0, 'params': 514193, 'time_iter': 0.03402, 'accuracy': 0.98104, 'precision': 0.58824, 'recall': 0.12346, 'f1': 0.20408, 'auc': 0.71299}
2025-08-17 05:06:57,222 - INFO - test: {'epoch': 9, 'time_epoch': 4.23251, 'loss': 0.12455925, 'lr': 0, 'params': 514193, 'time_iter': 0.03281, 'accuracy': 0.96864, 'precision': 0.53333, 'recall': 0.06154, 'f1': 0.11034, 'auc': 0.712}
2025-08-17 05:06:57,225 - INFO - > Epoch 9: took 76.8s (avg 78.9s) | Best so far: epoch 8	train_loss: 0.1401 train_auc: 0.7310	val_loss: 0.0952 val_auc: 0.7200	test_loss: 0.1266 test_auc: 0.7379
2025-08-17 05:08:06,759 - INFO - train: {'epoch': 10, 'time_epoch': 69.45382, 'eta': 6210.67979, 'eta_hours': 1.72519, 'loss': 0.13237803, 'lr': 9.932e-05, 'params': 514193, 'time_iter': 0.0675, 'accuracy': 0.96401, 'precision': 0.58276, 'recall': 0.13718, 'f1': 0.22208, 'auc': 0.7652}
2025-08-17 05:08:11,143 - INFO - val: {'epoch': 10, 'time_epoch': 4.35987, 'loss': 0.09142783, 'lr': 0, 'params': 514193, 'time_iter': 0.0338, 'accuracy': 0.98006, 'precision': 0.44444, 'recall': 0.04938, 'f1': 0.08889, 'auc': 0.69404}
2025-08-17 05:08:15,478 - INFO - test: {'epoch': 10, 'time_epoch': 4.31792, 'loss': 0.11857574, 'lr': 0, 'params': 514193, 'time_iter': 0.03347, 'accuracy': 0.97034, 'precision': 0.72222, 'recall': 0.1, 'f1': 0.17568, 'auc': 0.75077}
2025-08-17 05:08:15,481 - INFO - > Epoch 10: took 78.3s (avg 78.8s) | Best so far: epoch 8	train_loss: 0.1401 train_auc: 0.7310	val_loss: 0.0952 val_auc: 0.7200	test_loss: 0.1266 test_auc: 0.7379
2025-08-17 05:09:22,586 - INFO - train: {'epoch': 11, 'time_epoch': 67.02279, 'eta': 6120.65594, 'eta_hours': 1.70018, 'loss': 0.13062374, 'lr': 9.902e-05, 'params': 514193, 'time_iter': 0.06513, 'accuracy': 0.96505, 'precision': 0.65414, 'recall': 0.14123, 'f1': 0.23231, 'auc': 0.77239}
2025-08-17 05:09:26,905 - INFO - val: {'epoch': 11, 'time_epoch': 4.29713, 'loss': 0.09423829, 'lr': 0, 'params': 514193, 'time_iter': 0.03331, 'accuracy': 0.97642, 'precision': 0.35714, 'recall': 0.24691, 'f1': 0.29197, 'auc': 0.73108}
2025-08-17 05:09:31,093 - INFO - test: {'epoch': 11, 'time_epoch': 4.17101, 'loss': 0.13248459, 'lr': 0, 'params': 514193, 'time_iter': 0.03233, 'accuracy': 0.96231, 'precision': 0.35955, 'recall': 0.24615, 'f1': 0.29224, 'auc': 0.74525}
2025-08-17 05:09:31,096 - INFO - > Epoch 11: took 75.6s (avg 78.6s) | Best so far: epoch 11	train_loss: 0.1306 train_auc: 0.7724	val_loss: 0.0942 val_auc: 0.7311	test_loss: 0.1325 test_auc: 0.7452
2025-08-17 05:10:39,249 - INFO - train: {'epoch': 12, 'time_epoch': 68.06031, 'eta': 6041.11413, 'eta_hours': 1.67809, 'loss': 0.12826382, 'lr': 9.867e-05, 'params': 514193, 'time_iter': 0.06614, 'accuracy': 0.96505, 'precision': 0.61517, 'recall': 0.17776, 'f1': 0.27582, 'auc': 0.78255}
2025-08-17 05:10:43,625 - INFO - val: {'epoch': 12, 'time_epoch': 4.35444, 'loss': 0.10049761, 'lr': 0, 'params': 514193, 'time_iter': 0.03376, 'accuracy': 0.96864, 'precision': 0.21429, 'recall': 0.22222, 'f1': 0.21818, 'auc': 0.73898}
2025-08-17 05:10:47,829 - INFO - test: {'epoch': 12, 'time_epoch': 4.18749, 'loss': 0.1252884, 'lr': 0, 'params': 514193, 'time_iter': 0.03246, 'accuracy': 0.96402, 'precision': 0.4, 'recall': 0.27692, 'f1': 0.32727, 'auc': 0.74499}
2025-08-17 05:10:47,832 - INFO - > Epoch 12: took 76.7s (avg 78.4s) | Best so far: epoch 12	train_loss: 0.1283 train_auc: 0.7825	val_loss: 0.1005 val_auc: 0.7390	test_loss: 0.1253 test_auc: 0.7450
2025-08-17 05:11:54,794 - INFO - train: {'epoch': 13, 'time_epoch': 66.88071, 'eta': 5955.96642, 'eta_hours': 1.65444, 'loss': 0.1276837, 'lr': 9.826e-05, 'params': 514193, 'time_iter': 0.065, 'accuracy': 0.96544, 'precision': 0.6361, 'recall': 0.18019, 'f1': 0.28083, 'auc': 0.78497}
2025-08-17 05:11:59,219 - INFO - val: {'epoch': 13, 'time_epoch': 4.40061, 'loss': 0.08360064, 'lr': 0, 'params': 514193, 'time_iter': 0.03411, 'accuracy': 0.98128, 'precision': 0.61111, 'recall': 0.1358, 'f1': 0.22222, 'auc': 0.77324}
2025-08-17 05:12:03,536 - INFO - test: {'epoch': 13, 'time_epoch': 4.29778, 'loss': 0.11794118, 'lr': 0, 'params': 514193, 'time_iter': 0.03332, 'accuracy': 0.97131, 'precision': 0.8, 'recall': 0.12308, 'f1': 0.21333, 'auc': 0.74817}
2025-08-17 05:12:03,539 - INFO - > Epoch 13: took 75.7s (avg 78.2s) | Best so far: epoch 13	train_loss: 0.1277 train_auc: 0.7850	val_loss: 0.0836 val_auc: 0.7732	test_loss: 0.1179 test_auc: 0.7482
2025-08-17 05:13:10,475 - INFO - train: {'epoch': 14, 'time_epoch': 66.8462, 'eta': 5873.05871, 'eta_hours': 1.63141, 'loss': 0.12614201, 'lr': 9.78e-05, 'params': 514193, 'time_iter': 0.06496, 'accuracy': 0.96556, 'precision': 0.62222, 'recall': 0.20455, 'f1': 0.30788, 'auc': 0.78575}
2025-08-17 05:13:14,919 - INFO - val: {'epoch': 14, 'time_epoch': 4.41802, 'loss': 0.09031788, 'lr': 0, 'params': 514193, 'time_iter': 0.03425, 'accuracy': 0.97982, 'precision': 0.46875, 'recall': 0.18519, 'f1': 0.26549, 'auc': 0.71815}
2025-08-17 05:13:19,194 - INFO - test: {'epoch': 14, 'time_epoch': 4.25666, 'loss': 0.12314742, 'lr': 0, 'params': 514193, 'time_iter': 0.033, 'accuracy': 0.97107, 'precision': 0.6, 'recall': 0.25385, 'f1': 0.35676, 'auc': 0.70062}
2025-08-17 05:13:19,196 - INFO - > Epoch 14: took 75.7s (avg 78.1s) | Best so far: epoch 13	train_loss: 0.1277 train_auc: 0.7850	val_loss: 0.0836 val_auc: 0.7732	test_loss: 0.1179 test_auc: 0.7482
2025-08-17 05:14:28,149 - INFO - train: {'epoch': 15, 'time_epoch': 68.86385, 'eta': 5802.75139, 'eta_hours': 1.61188, 'loss': 0.12180174, 'lr': 9.729e-05, 'params': 514193, 'time_iter': 0.06692, 'accuracy': 0.96623, 'precision': 0.65012, 'recall': 0.21266, 'f1': 0.32049, 'auc': 0.8054}
2025-08-17 05:14:32,543 - INFO - val: {'epoch': 15, 'time_epoch': 4.36804, 'loss': 0.08601576, 'lr': 0, 'params': 514193, 'time_iter': 0.03386, 'accuracy': 0.98128, 'precision': 0.58333, 'recall': 0.17284, 'f1': 0.26667, 'auc': 0.71922}
2025-08-17 05:14:36,792 - INFO - test: {'epoch': 15, 'time_epoch': 4.22945, 'loss': 0.11855163, 'lr': 0, 'params': 514193, 'time_iter': 0.03279, 'accuracy': 0.97082, 'precision': 0.67857, 'recall': 0.14615, 'f1': 0.24051, 'auc': 0.74153}
2025-08-17 05:14:36,795 - INFO - > Epoch 15: took 77.6s (avg 78.0s) | Best so far: epoch 13	train_loss: 0.1277 train_auc: 0.7850	val_loss: 0.0836 val_auc: 0.7732	test_loss: 0.1179 test_auc: 0.7482
2025-08-17 05:15:47,176 - INFO - train: {'epoch': 16, 'time_epoch': 70.28792, 'eta': 5739.56668, 'eta_hours': 1.59432, 'loss': 0.12116311, 'lr': 9.673e-05, 'params': 514193, 'time_iter': 0.06831, 'accuracy': 0.96669, 'precision': 0.65888, 'recall': 0.2289, 'f1': 0.33976, 'auc': 0.81126}
2025-08-17 05:15:51,581 - INFO - val: {'epoch': 16, 'time_epoch': 4.34316, 'loss': 0.08701841, 'lr': 0, 'params': 514193, 'time_iter': 0.03367, 'accuracy': 0.97909, 'precision': 0.44444, 'recall': 0.24691, 'f1': 0.31746, 'auc': 0.77321}
2025-08-17 05:15:55,817 - INFO - test: {'epoch': 16, 'time_epoch': 4.21808, 'loss': 0.12176208, 'lr': 0, 'params': 514193, 'time_iter': 0.0327, 'accuracy': 0.96693, 'precision': 0.44643, 'recall': 0.19231, 'f1': 0.26882, 'auc': 0.75115}
2025-08-17 05:15:55,819 - INFO - > Epoch 16: took 79.0s (avg 78.1s) | Best so far: epoch 13	train_loss: 0.1277 train_auc: 0.7850	val_loss: 0.0836 val_auc: 0.7732	test_loss: 0.1179 test_auc: 0.7482
2025-08-17 05:17:04,974 - INFO - train: {'epoch': 17, 'time_epoch': 69.07092, 'eta': 5670.04862, 'eta_hours': 1.57501, 'loss': 0.11964477, 'lr': 9.611e-05, 'params': 514193, 'time_iter': 0.06712, 'accuracy': 0.96714, 'precision': 0.65503, 'recall': 0.25893, 'f1': 0.37115, 'auc': 0.81012}
2025-08-17 05:17:09,403 - INFO - val: {'epoch': 17, 'time_epoch': 4.40545, 'loss': 0.08786479, 'lr': 0, 'params': 514193, 'time_iter': 0.03415, 'accuracy': 0.97788, 'precision': 0.40741, 'recall': 0.2716, 'f1': 0.32593, 'auc': 0.76798}
2025-08-17 05:17:13,746 - INFO - test: {'epoch': 17, 'time_epoch': 4.32638, 'loss': 0.12841598, 'lr': 0, 'params': 514193, 'time_iter': 0.03354, 'accuracy': 0.96475, 'precision': 0.38462, 'recall': 0.19231, 'f1': 0.25641, 'auc': 0.74228}
2025-08-17 05:17:13,749 - INFO - > Epoch 17: took 77.9s (avg 78.1s) | Best so far: epoch 13	train_loss: 0.1277 train_auc: 0.7850	val_loss: 0.0836 val_auc: 0.7732	test_loss: 0.1179 test_auc: 0.7482
2025-08-17 05:18:23,279 - INFO - train: {'epoch': 18, 'time_epoch': 69.44654, 'eta': 5602.17894, 'eta_hours': 1.55616, 'loss': 0.11812228, 'lr': 9.545e-05, 'params': 514193, 'time_iter': 0.06749, 'accuracy': 0.96763, 'precision': 0.67288, 'recall': 0.2638, 'f1': 0.37901, 'auc': 0.81712}
2025-08-17 05:18:27,640 - INFO - val: {'epoch': 18, 'time_epoch': 4.33974, 'loss': 0.08394628, 'lr': 0, 'params': 514193, 'time_iter': 0.03364, 'accuracy': 0.98128, 'precision': 0.55263, 'recall': 0.25926, 'f1': 0.35294, 'auc': 0.74206}
2025-08-17 05:18:31,813 - INFO - test: {'epoch': 18, 'time_epoch': 4.15609, 'loss': 0.12373259, 'lr': 0, 'params': 514193, 'time_iter': 0.03222, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.16923, 'f1': 0.25287, 'auc': 0.74354}
2025-08-17 05:18:31,816 - INFO - > Epoch 18: took 78.1s (avg 78.1s) | Best so far: epoch 13	train_loss: 0.1277 train_auc: 0.7850	val_loss: 0.0836 val_auc: 0.7732	test_loss: 0.1179 test_auc: 0.7482
2025-08-17 05:19:40,563 - INFO - train: {'epoch': 19, 'time_epoch': 68.66382, 'eta': 5531.0207, 'eta_hours': 1.53639, 'loss': 0.11780771, 'lr': 9.474e-05, 'params': 514193, 'time_iter': 0.06673, 'accuracy': 0.96757, 'precision': 0.68132, 'recall': 0.25162, 'f1': 0.36752, 'auc': 0.82515}
2025-08-17 05:19:45,180 - INFO - val: {'epoch': 19, 'time_epoch': 4.59078, 'loss': 0.08015936, 'lr': 0, 'params': 514193, 'time_iter': 0.03559, 'accuracy': 0.98079, 'precision': 0.53125, 'recall': 0.20988, 'f1': 0.30088, 'auc': 0.7934}
2025-08-17 05:19:49,647 - INFO - test: {'epoch': 19, 'time_epoch': 4.44598, 'loss': 0.11855867, 'lr': 0, 'params': 514193, 'time_iter': 0.03446, 'accuracy': 0.97155, 'precision': 0.68571, 'recall': 0.18462, 'f1': 0.29091, 'auc': 0.75921}
2025-08-17 05:19:49,651 - INFO - > Epoch 19: took 77.8s (avg 78.1s) | Best so far: epoch 19	train_loss: 0.1178 train_auc: 0.8252	val_loss: 0.0802 val_auc: 0.7934	test_loss: 0.1186 test_auc: 0.7592
2025-08-17 05:21:00,282 - INFO - train: {'epoch': 20, 'time_epoch': 70.54527, 'eta': 5467.17785, 'eta_hours': 1.51866, 'loss': 0.11622534, 'lr': 9.397e-05, 'params': 514193, 'time_iter': 0.06856, 'accuracy': 0.96839, 'precision': 0.68972, 'recall': 0.28328, 'f1': 0.40161, 'auc': 0.82304}
2025-08-17 05:21:04,782 - INFO - val: {'epoch': 20, 'time_epoch': 4.47709, 'loss': 0.08243989, 'lr': 0, 'params': 514193, 'time_iter': 0.03471, 'accuracy': 0.97885, 'precision': 0.42857, 'recall': 0.22222, 'f1': 0.29268, 'auc': 0.77082}
2025-08-17 05:21:09,170 - INFO - test: {'epoch': 20, 'time_epoch': 4.33097, 'loss': 0.12550383, 'lr': 0, 'params': 514193, 'time_iter': 0.03357, 'accuracy': 0.96912, 'precision': 0.53488, 'recall': 0.17692, 'f1': 0.2659, 'auc': 0.73766}
2025-08-17 05:21:09,173 - INFO - > Epoch 20: took 79.5s (avg 78.1s) | Best so far: epoch 19	train_loss: 0.1178 train_auc: 0.8252	val_loss: 0.0802 val_auc: 0.7934	test_loss: 0.1186 test_auc: 0.7592
2025-08-17 05:22:19,483 - INFO - train: {'epoch': 21, 'time_epoch': 70.22688, 'eta': 5401.59686, 'eta_hours': 1.50044, 'loss': 0.11708109, 'lr': 9.316e-05, 'params': 514193, 'time_iter': 0.06825, 'accuracy': 0.9673, 'precision': 0.66049, 'recall': 0.26055, 'f1': 0.37369, 'auc': 0.83015}
2025-08-17 05:22:23,958 - INFO - val: {'epoch': 21, 'time_epoch': 4.4527, 'loss': 0.08345499, 'lr': 0, 'params': 514193, 'time_iter': 0.03452, 'accuracy': 0.97958, 'precision': 0.4717, 'recall': 0.30864, 'f1': 0.37313, 'auc': 0.78559}
2025-08-17 05:22:28,307 - INFO - test: {'epoch': 21, 'time_epoch': 4.33168, 'loss': 0.12413196, 'lr': 0, 'params': 514193, 'time_iter': 0.03358, 'accuracy': 0.96937, 'precision': 0.53846, 'recall': 0.21538, 'f1': 0.30769, 'auc': 0.73316}
2025-08-17 05:22:28,309 - INFO - > Epoch 21: took 79.1s (avg 78.2s) | Best so far: epoch 19	train_loss: 0.1178 train_auc: 0.8252	val_loss: 0.0802 val_auc: 0.7934	test_loss: 0.1186 test_auc: 0.7592
2025-08-17 05:23:37,668 - INFO - train: {'epoch': 22, 'time_epoch': 69.27356, 'eta': 5332.42032, 'eta_hours': 1.48123, 'loss': 0.11314152, 'lr': 9.23e-05, 'params': 514193, 'time_iter': 0.06732, 'accuracy': 0.96839, 'precision': 0.692, 'recall': 0.28084, 'f1': 0.39954, 'auc': 0.83811}
2025-08-17 05:23:42,064 - INFO - val: {'epoch': 22, 'time_epoch': 4.37413, 'loss': 0.08000769, 'lr': 0, 'params': 514193, 'time_iter': 0.03391, 'accuracy': 0.98152, 'precision': 0.56757, 'recall': 0.25926, 'f1': 0.35593, 'auc': 0.80091}
2025-08-17 05:23:46,255 - INFO - test: {'epoch': 22, 'time_epoch': 4.1745, 'loss': 0.11610474, 'lr': 0, 'params': 514193, 'time_iter': 0.03236, 'accuracy': 0.96985, 'precision': 0.5625, 'recall': 0.20769, 'f1': 0.30337, 'auc': 0.75285}
2025-08-17 05:23:46,258 - INFO - > Epoch 22: took 77.9s (avg 78.2s) | Best so far: epoch 22	train_loss: 0.1131 train_auc: 0.8381	val_loss: 0.0800 val_auc: 0.8009	test_loss: 0.1161 test_auc: 0.7529
2025-08-17 05:24:54,647 - INFO - train: {'epoch': 23, 'time_epoch': 68.29981, 'eta': 5260.15218, 'eta_hours': 1.46115, 'loss': 0.11364772, 'lr': 9.14e-05, 'params': 514193, 'time_iter': 0.06637, 'accuracy': 0.96851, 'precision': 0.69066, 'recall': 0.28815, 'f1': 0.40664, 'auc': 0.83511}
2025-08-17 05:24:59,098 - INFO - val: {'epoch': 23, 'time_epoch': 4.4268, 'loss': 0.08285313, 'lr': 0, 'params': 514193, 'time_iter': 0.03432, 'accuracy': 0.97958, 'precision': 0.47368, 'recall': 0.33333, 'f1': 0.3913, 'auc': 0.78859}
2025-08-17 05:25:03,304 - INFO - test: {'epoch': 23, 'time_epoch': 4.18766, 'loss': 0.12611545, 'lr': 0, 'params': 514193, 'time_iter': 0.03246, 'accuracy': 0.9662, 'precision': 0.42857, 'recall': 0.20769, 'f1': 0.27979, 'auc': 0.72847}
2025-08-17 05:25:03,306 - INFO - > Epoch 23: took 77.0s (avg 78.1s) | Best so far: epoch 22	train_loss: 0.1131 train_auc: 0.8381	val_loss: 0.0800 val_auc: 0.8009	test_loss: 0.1161 test_auc: 0.7529
2025-08-17 05:26:12,109 - INFO - train: {'epoch': 24, 'time_epoch': 68.71225, 'eta': 5189.43883, 'eta_hours': 1.44151, 'loss': 0.10963941, 'lr': 9.045e-05, 'params': 514193, 'time_iter': 0.06678, 'accuracy': 0.96942, 'precision': 0.71082, 'recall': 0.30925, 'f1': 0.431, 'auc': 0.85316}
2025-08-17 05:26:16,396 - INFO - val: {'epoch': 24, 'time_epoch': 4.26122, 'loss': 0.08560798, 'lr': 0, 'params': 514193, 'time_iter': 0.03303, 'accuracy': 0.97812, 'precision': 0.41176, 'recall': 0.25926, 'f1': 0.31818, 'auc': 0.79774}
2025-08-17 05:26:20,632 - INFO - test: {'epoch': 24, 'time_epoch': 4.21831, 'loss': 0.12670048, 'lr': 0, 'params': 514193, 'time_iter': 0.0327, 'accuracy': 0.96596, 'precision': 0.43243, 'recall': 0.24615, 'f1': 0.31373, 'auc': 0.72968}
2025-08-17 05:26:20,635 - INFO - > Epoch 24: took 77.3s (avg 78.1s) | Best so far: epoch 22	train_loss: 0.1131 train_auc: 0.8381	val_loss: 0.0800 val_auc: 0.8009	test_loss: 0.1161 test_auc: 0.7529
2025-08-17 05:27:28,603 - INFO - train: {'epoch': 25, 'time_epoch': 67.88614, 'eta': 5116.52815, 'eta_hours': 1.42126, 'loss': 0.10996619, 'lr': 8.946e-05, 'params': 514193, 'time_iter': 0.06597, 'accuracy': 0.96964, 'precision': 0.7122, 'recall': 0.31737, 'f1': 0.43908, 'auc': 0.85129}
2025-08-17 05:27:32,993 - INFO - val: {'epoch': 25, 'time_epoch': 4.36606, 'loss': 0.08623759, 'lr': 0, 'params': 514193, 'time_iter': 0.03385, 'accuracy': 0.9786, 'precision': 0.42553, 'recall': 0.24691, 'f1': 0.3125, 'auc': 0.77935}
2025-08-17 05:27:37,208 - INFO - test: {'epoch': 25, 'time_epoch': 4.19656, 'loss': 0.1232617, 'lr': 0, 'params': 514193, 'time_iter': 0.03253, 'accuracy': 0.96766, 'precision': 0.47273, 'recall': 0.2, 'f1': 0.28108, 'auc': 0.74246}
2025-08-17 05:27:37,212 - INFO - > Epoch 25: took 76.6s (avg 78.0s) | Best so far: epoch 22	train_loss: 0.1131 train_auc: 0.8381	val_loss: 0.0800 val_auc: 0.8009	test_loss: 0.1161 test_auc: 0.7529
2025-08-17 05:28:44,262 - INFO - train: {'epoch': 26, 'time_epoch': 66.96796, 'eta': 5041.50717, 'eta_hours': 1.40042, 'loss': 0.10809288, 'lr': 8.842e-05, 'params': 514193, 'time_iter': 0.06508, 'accuracy': 0.97021, 'precision': 0.71649, 'recall': 0.33847, 'f1': 0.45976, 'auc': 0.85594}
2025-08-17 05:28:48,564 - INFO - val: {'epoch': 26, 'time_epoch': 4.28109, 'loss': 0.07927908, 'lr': 0, 'params': 514193, 'time_iter': 0.03319, 'accuracy': 0.98055, 'precision': 0.51111, 'recall': 0.28395, 'f1': 0.36508, 'auc': 0.79267}
2025-08-17 05:28:52,743 - INFO - test: {'epoch': 26, 'time_epoch': 4.16272, 'loss': 0.12308327, 'lr': 0, 'params': 514193, 'time_iter': 0.03227, 'accuracy': 0.9662, 'precision': 0.44944, 'recall': 0.30769, 'f1': 0.3653, 'auc': 0.74851}
2025-08-17 05:28:52,746 - INFO - > Epoch 26: took 75.5s (avg 77.9s) | Best so far: epoch 22	train_loss: 0.1131 train_auc: 0.8381	val_loss: 0.0800 val_auc: 0.8009	test_loss: 0.1161 test_auc: 0.7529
2025-08-17 05:29:59,111 - INFO - train: {'epoch': 27, 'time_epoch': 66.28465, 'eta': 4965.30434, 'eta_hours': 1.37925, 'loss': 0.10759474, 'lr': 8.734e-05, 'params': 514193, 'time_iter': 0.06442, 'accuracy': 0.96973, 'precision': 0.69667, 'recall': 0.33929, 'f1': 0.45633, 'auc': 0.85669}
2025-08-17 05:30:03,396 - INFO - val: {'epoch': 27, 'time_epoch': 4.26433, 'loss': 0.07783932, 'lr': 0, 'params': 514193, 'time_iter': 0.03306, 'accuracy': 0.98177, 'precision': 0.58333, 'recall': 0.25926, 'f1': 0.35897, 'auc': 0.7836}
2025-08-17 05:30:07,588 - INFO - test: {'epoch': 27, 'time_epoch': 4.17578, 'loss': 0.12231743, 'lr': 0, 'params': 514193, 'time_iter': 0.03237, 'accuracy': 0.96912, 'precision': 0.52459, 'recall': 0.24615, 'f1': 0.33508, 'auc': 0.73274}
2025-08-17 05:30:07,591 - INFO - > Epoch 27: took 74.8s (avg 77.8s) | Best so far: epoch 22	train_loss: 0.1131 train_auc: 0.8381	val_loss: 0.0800 val_auc: 0.8009	test_loss: 0.1161 test_auc: 0.7529
2025-08-17 05:31:13,041 - INFO - train: {'epoch': 28, 'time_epoch': 65.36257, 'eta': 4887.528, 'eta_hours': 1.35765, 'loss': 0.10664201, 'lr': 8.622e-05, 'params': 514193, 'time_iter': 0.06352, 'accuracy': 0.96997, 'precision': 0.70819, 'recall': 0.33685, 'f1': 0.45655, 'auc': 0.86332}
2025-08-17 05:31:17,379 - INFO - val: {'epoch': 28, 'time_epoch': 4.31487, 'loss': 0.08759802, 'lr': 0, 'params': 514193, 'time_iter': 0.03345, 'accuracy': 0.97666, 'precision': 0.36364, 'recall': 0.24691, 'f1': 0.29412, 'auc': 0.79965}
2025-08-17 05:31:21,474 - INFO - test: {'epoch': 28, 'time_epoch': 4.07026, 'loss': 0.12926403, 'lr': 0, 'params': 514193, 'time_iter': 0.03155, 'accuracy': 0.96572, 'precision': 0.4127, 'recall': 0.2, 'f1': 0.26943, 'auc': 0.73519}
2025-08-17 05:31:21,505 - INFO - > Epoch 28: took 73.9s (avg 77.7s) | Best so far: epoch 22	train_loss: 0.1131 train_auc: 0.8381	val_loss: 0.0800 val_auc: 0.8009	test_loss: 0.1161 test_auc: 0.7529
2025-08-17 05:32:26,720 - INFO - train: {'epoch': 29, 'time_epoch': 65.12936, 'eta': 4810.0351, 'eta_hours': 1.33612, 'loss': 0.10533162, 'lr': 8.506e-05, 'params': 514193, 'time_iter': 0.06329, 'accuracy': 0.97149, 'precision': 0.74831, 'recall': 0.35958, 'f1': 0.48575, 'auc': 0.86361}
2025-08-17 05:32:31,163 - INFO - val: {'epoch': 29, 'time_epoch': 4.4216, 'loss': 0.07689602, 'lr': 0, 'params': 514193, 'time_iter': 0.03428, 'accuracy': 0.98298, 'precision': 0.66667, 'recall': 0.2716, 'f1': 0.38596, 'auc': 0.79811}
2025-08-17 05:32:35,387 - INFO - test: {'epoch': 29, 'time_epoch': 4.20439, 'loss': 0.12267083, 'lr': 0, 'params': 514193, 'time_iter': 0.03259, 'accuracy': 0.96864, 'precision': 0.51064, 'recall': 0.18462, 'f1': 0.27119, 'auc': 0.74753}
2025-08-17 05:32:35,390 - INFO - > Epoch 29: took 73.9s (avg 77.6s) | Best so far: epoch 22	train_loss: 0.1131 train_auc: 0.8381	val_loss: 0.0800 val_auc: 0.8009	test_loss: 0.1161 test_auc: 0.7529
2025-08-17 05:33:40,791 - INFO - train: {'epoch': 30, 'time_epoch': 65.32124, 'eta': 4733.76692, 'eta_hours': 1.31494, 'loss': 0.10414977, 'lr': 8.386e-05, 'params': 514193, 'time_iter': 0.06348, 'accuracy': 0.97021, 'precision': 0.71356, 'recall': 0.34172, 'f1': 0.46213, 'auc': 0.87569}
2025-08-17 05:33:45,127 - INFO - val: {'epoch': 30, 'time_epoch': 4.31046, 'loss': 0.08008905, 'lr': 0, 'params': 514193, 'time_iter': 0.03341, 'accuracy': 0.97982, 'precision': 0.47917, 'recall': 0.28395, 'f1': 0.35659, 'auc': 0.80327}
2025-08-17 05:33:49,402 - INFO - test: {'epoch': 30, 'time_epoch': 4.17414, 'loss': 0.12784645, 'lr': 0, 'params': 514193, 'time_iter': 0.03236, 'accuracy': 0.96766, 'precision': 0.47059, 'recall': 0.18462, 'f1': 0.26519, 'auc': 0.74486}
2025-08-17 05:33:49,404 - INFO - > Epoch 30: took 74.0s (avg 77.5s) | Best so far: epoch 30	train_loss: 0.1041 train_auc: 0.8757	val_loss: 0.0801 val_auc: 0.8033	test_loss: 0.1278 test_auc: 0.7449
2025-08-17 05:34:55,240 - INFO - train: {'epoch': 31, 'time_epoch': 65.75435, 'eta': 4659.1033, 'eta_hours': 1.2942, 'loss': 0.10344033, 'lr': 8.263e-05, 'params': 514193, 'time_iter': 0.0639, 'accuracy': 0.97085, 'precision': 0.73254, 'recall': 0.34903, 'f1': 0.47279, 'auc': 0.87391}
2025-08-17 05:34:59,584 - INFO - val: {'epoch': 31, 'time_epoch': 4.32374, 'loss': 0.08753003, 'lr': 0, 'params': 514193, 'time_iter': 0.03352, 'accuracy': 0.97715, 'precision': 0.39683, 'recall': 0.30864, 'f1': 0.34722, 'auc': 0.76209}
2025-08-17 05:35:03,841 - INFO - test: {'epoch': 31, 'time_epoch': 4.23955, 'loss': 0.13185917, 'lr': 0, 'params': 514193, 'time_iter': 0.03286, 'accuracy': 0.9645, 'precision': 0.40476, 'recall': 0.26154, 'f1': 0.31776, 'auc': 0.72783}
2025-08-17 05:35:03,843 - INFO - > Epoch 31: took 74.4s (avg 77.4s) | Best so far: epoch 30	train_loss: 0.1041 train_auc: 0.8757	val_loss: 0.0801 val_auc: 0.8033	test_loss: 0.1278 test_auc: 0.7449
2025-08-17 05:36:09,333 - INFO - train: {'epoch': 32, 'time_epoch': 65.40976, 'eta': 4584.28001, 'eta_hours': 1.27341, 'loss': 0.10300596, 'lr': 8.136e-05, 'params': 514193, 'time_iter': 0.06357, 'accuracy': 0.97119, 'precision': 0.73279, 'recall': 0.36282, 'f1': 0.48534, 'auc': 0.87059}
2025-08-17 05:36:13,540 - INFO - val: {'epoch': 32, 'time_epoch': 4.18667, 'loss': 0.07757318, 'lr': 0, 'params': 514193, 'time_iter': 0.03245, 'accuracy': 0.98225, 'precision': 0.61111, 'recall': 0.2716, 'f1': 0.37607, 'auc': 0.78284}
2025-08-17 05:36:17,641 - INFO - test: {'epoch': 32, 'time_epoch': 4.08498, 'loss': 0.12206034, 'lr': 0, 'params': 514193, 'time_iter': 0.03167, 'accuracy': 0.96864, 'precision': 0.5098, 'recall': 0.2, 'f1': 0.28729, 'auc': 0.74572}
2025-08-17 05:36:17,644 - INFO - > Epoch 32: took 73.8s (avg 77.3s) | Best so far: epoch 30	train_loss: 0.1041 train_auc: 0.8757	val_loss: 0.0801 val_auc: 0.8033	test_loss: 0.1278 test_auc: 0.7449
2025-08-17 05:37:24,018 - INFO - train: {'epoch': 33, 'time_epoch': 66.29501, 'eta': 4511.72888, 'eta_hours': 1.25326, 'loss': 0.10079209, 'lr': 8.005e-05, 'params': 514193, 'time_iter': 0.06443, 'accuracy': 0.97146, 'precision': 0.73667, 'recall': 0.37013, 'f1': 0.49271, 'auc': 0.88406}
2025-08-17 05:37:28,241 - INFO - val: {'epoch': 33, 'time_epoch': 4.20266, 'loss': 0.08573513, 'lr': 0, 'params': 514193, 'time_iter': 0.03258, 'accuracy': 0.98006, 'precision': 0.4898, 'recall': 0.2963, 'f1': 0.36923, 'auc': 0.76734}
2025-08-17 05:37:32,344 - INFO - test: {'epoch': 33, 'time_epoch': 4.08486, 'loss': 0.12800813, 'lr': 0, 'params': 514193, 'time_iter': 0.03167, 'accuracy': 0.96548, 'precision': 0.43333, 'recall': 0.3, 'f1': 0.35455, 'auc': 0.75264}
2025-08-17 05:37:32,346 - INFO - > Epoch 33: took 74.7s (avg 77.2s) | Best so far: epoch 30	train_loss: 0.1041 train_auc: 0.8757	val_loss: 0.0801 val_auc: 0.8033	test_loss: 0.1278 test_auc: 0.7449
2025-08-17 05:38:37,891 - INFO - train: {'epoch': 34, 'time_epoch': 65.46456, 'eta': 4437.99298, 'eta_hours': 1.23278, 'loss': 0.10000716, 'lr': 7.872e-05, 'params': 514193, 'time_iter': 0.06362, 'accuracy': 0.97265, 'precision': 0.75538, 'recall': 0.39854, 'f1': 0.52179, 'auc': 0.88256}
2025-08-17 05:38:42,156 - INFO - val: {'epoch': 34, 'time_epoch': 4.24385, 'loss': 0.07885244, 'lr': 0, 'params': 514193, 'time_iter': 0.0329, 'accuracy': 0.98079, 'precision': 0.52381, 'recall': 0.2716, 'f1': 0.35772, 'auc': 0.79816}
2025-08-17 05:38:46,308 - INFO - test: {'epoch': 34, 'time_epoch': 4.13565, 'loss': 0.12438056, 'lr': 0, 'params': 514193, 'time_iter': 0.03206, 'accuracy': 0.96937, 'precision': 0.54, 'recall': 0.20769, 'f1': 0.3, 'auc': 0.75867}
2025-08-17 05:38:46,311 - INFO - > Epoch 34: took 74.0s (avg 77.1s) | Best so far: epoch 30	train_loss: 0.1041 train_auc: 0.8757	val_loss: 0.0801 val_auc: 0.8033	test_loss: 0.1278 test_auc: 0.7449
2025-08-17 05:39:52,869 - INFO - train: {'epoch': 35, 'time_epoch': 66.47706, 'eta': 4366.51661, 'eta_hours': 1.21292, 'loss': 0.10025274, 'lr': 7.735e-05, 'params': 514193, 'time_iter': 0.0646, 'accuracy': 0.97201, 'precision': 0.74411, 'recall': 0.38474, 'f1': 0.50722, 'auc': 0.88313}
2025-08-17 05:39:57,094 - INFO - val: {'epoch': 35, 'time_epoch': 4.20408, 'loss': 0.09409512, 'lr': 0, 'params': 514193, 'time_iter': 0.03259, 'accuracy': 0.97326, 'precision': 0.31169, 'recall': 0.2963, 'f1': 0.3038, 'auc': 0.77999}
2025-08-17 05:40:01,214 - INFO - test: {'epoch': 35, 'time_epoch': 4.10368, 'loss': 0.13634034, 'lr': 0, 'params': 514193, 'time_iter': 0.03181, 'accuracy': 0.95842, 'precision': 0.29293, 'recall': 0.22308, 'f1': 0.25328, 'auc': 0.75488}
2025-08-17 05:40:01,216 - INFO - > Epoch 35: took 74.9s (avg 77.0s) | Best so far: epoch 30	train_loss: 0.1041 train_auc: 0.8757	val_loss: 0.0801 val_auc: 0.8033	test_loss: 0.1278 test_auc: 0.7449
2025-08-17 05:41:07,854 - INFO - train: {'epoch': 36, 'time_epoch': 66.55568, 'eta': 4295.44433, 'eta_hours': 1.19318, 'loss': 0.09926946, 'lr': 7.595e-05, 'params': 514193, 'time_iter': 0.06468, 'accuracy': 0.97201, 'precision': 0.7504, 'recall': 0.37825, 'f1': 0.50297, 'auc': 0.89271}
2025-08-17 05:41:12,214 - INFO - val: {'epoch': 36, 'time_epoch': 4.33769, 'loss': 0.08000136, 'lr': 0, 'params': 514193, 'time_iter': 0.03363, 'accuracy': 0.98152, 'precision': 0.5641, 'recall': 0.2716, 'f1': 0.36667, 'auc': 0.79512}
2025-08-17 05:41:16,452 - INFO - test: {'epoch': 36, 'time_epoch': 4.2214, 'loss': 0.13554549, 'lr': 0, 'params': 514193, 'time_iter': 0.03272, 'accuracy': 0.96815, 'precision': 0.49057, 'recall': 0.2, 'f1': 0.28415, 'auc': 0.73017}
2025-08-17 05:41:16,454 - INFO - > Epoch 36: took 75.2s (avg 77.0s) | Best so far: epoch 30	train_loss: 0.1041 train_auc: 0.8757	val_loss: 0.0801 val_auc: 0.8033	test_loss: 0.1278 test_auc: 0.7449
2025-08-17 05:42:24,103 - INFO - train: {'epoch': 37, 'time_epoch': 67.56656, 'eta': 4226.2591, 'eta_hours': 1.17396, 'loss': 0.09662108, 'lr': 7.452e-05, 'params': 514193, 'time_iter': 0.06566, 'accuracy': 0.97237, 'precision': 0.74656, 'recall': 0.39692, 'f1': 0.51828, 'auc': 0.8994}
2025-08-17 05:42:28,484 - INFO - val: {'epoch': 37, 'time_epoch': 4.35961, 'loss': 0.08306851, 'lr': 0, 'params': 514193, 'time_iter': 0.0338, 'accuracy': 0.97982, 'precision': 0.48077, 'recall': 0.30864, 'f1': 0.37594, 'auc': 0.79437}
2025-08-17 05:42:32,760 - INFO - test: {'epoch': 37, 'time_epoch': 4.25909, 'loss': 0.13478955, 'lr': 0, 'params': 514193, 'time_iter': 0.03302, 'accuracy': 0.96548, 'precision': 0.41429, 'recall': 0.22308, 'f1': 0.29, 'auc': 0.7448}
2025-08-17 05:42:32,763 - INFO - > Epoch 37: took 76.3s (avg 77.0s) | Best so far: epoch 30	train_loss: 0.1041 train_auc: 0.8757	val_loss: 0.0801 val_auc: 0.8033	test_loss: 0.1278 test_auc: 0.7449
2025-08-17 05:43:38,533 - INFO - train: {'epoch': 38, 'time_epoch': 65.68243, 'eta': 4154.2099, 'eta_hours': 1.15395, 'loss': 0.09535023, 'lr': 7.307e-05, 'params': 514193, 'time_iter': 0.06383, 'accuracy': 0.97289, 'precision': 0.75373, 'recall': 0.4099, 'f1': 0.53102, 'auc': 0.90371}
2025-08-17 05:43:42,829 - INFO - val: {'epoch': 38, 'time_epoch': 4.27072, 'loss': 0.0898211, 'lr': 0, 'params': 514193, 'time_iter': 0.03311, 'accuracy': 0.97788, 'precision': 0.41935, 'recall': 0.32099, 'f1': 0.36364, 'auc': 0.79767}
2025-08-17 05:43:46,998 - INFO - test: {'epoch': 38, 'time_epoch': 4.1511, 'loss': 0.13917513, 'lr': 0, 'params': 514193, 'time_iter': 0.03218, 'accuracy': 0.96134, 'precision': 0.35052, 'recall': 0.26154, 'f1': 0.29956, 'auc': 0.74687}
2025-08-17 05:43:47,001 - INFO - > Epoch 38: took 74.2s (avg 76.9s) | Best so far: epoch 30	train_loss: 0.1041 train_auc: 0.8757	val_loss: 0.0801 val_auc: 0.8033	test_loss: 0.1278 test_auc: 0.7449
2025-08-17 05:44:52,758 - INFO - train: {'epoch': 39, 'time_epoch': 65.67777, 'eta': 4082.47205, 'eta_hours': 1.13402, 'loss': 0.09484557, 'lr': 7.159e-05, 'params': 514193, 'time_iter': 0.06383, 'accuracy': 0.97265, 'precision': 0.75538, 'recall': 0.39854, 'f1': 0.52179, 'auc': 0.90194}
2025-08-17 05:44:56,971 - INFO - val: {'epoch': 39, 'time_epoch': 4.19194, 'loss': 0.07656857, 'lr': 0, 'params': 514193, 'time_iter': 0.0325, 'accuracy': 0.98152, 'precision': 0.56098, 'recall': 0.28395, 'f1': 0.37705, 'auc': 0.81041}
2025-08-17 05:45:01,039 - INFO - test: {'epoch': 39, 'time_epoch': 4.05141, 'loss': 0.13153155, 'lr': 0, 'params': 514193, 'time_iter': 0.03141, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.16923, 'f1': 0.25287, 'auc': 0.73441}
2025-08-17 05:45:01,041 - INFO - > Epoch 39: took 74.0s (avg 76.8s) | Best so far: epoch 39	train_loss: 0.0948 train_auc: 0.9019	val_loss: 0.0766 val_auc: 0.8104	test_loss: 0.1315 test_auc: 0.7344
2025-08-17 05:46:08,022 - INFO - train: {'epoch': 40, 'time_epoch': 66.90115, 'eta': 4012.79029, 'eta_hours': 1.11466, 'loss': 0.09519572, 'lr': 7.008e-05, 'params': 514193, 'time_iter': 0.06502, 'accuracy': 0.97219, 'precision': 0.73979, 'recall': 0.39692, 'f1': 0.51664, 'auc': 0.9043}
2025-08-17 05:46:12,375 - INFO - val: {'epoch': 40, 'time_epoch': 4.32953, 'loss': 0.08551934, 'lr': 0, 'params': 514193, 'time_iter': 0.03356, 'accuracy': 0.97885, 'precision': 0.45, 'recall': 0.33333, 'f1': 0.38298, 'auc': 0.80278}
2025-08-17 05:46:16,590 - INFO - test: {'epoch': 40, 'time_epoch': 4.19751, 'loss': 0.13620428, 'lr': 0, 'params': 514193, 'time_iter': 0.03254, 'accuracy': 0.96329, 'precision': 0.3871, 'recall': 0.27692, 'f1': 0.32287, 'auc': 0.73864}
2025-08-17 05:46:16,593 - INFO - > Epoch 40: took 75.6s (avg 76.8s) | Best so far: epoch 39	train_loss: 0.0948 train_auc: 0.9019	val_loss: 0.0766 val_auc: 0.8104	test_loss: 0.1315 test_auc: 0.7344
2025-08-17 05:47:22,746 - INFO - train: {'epoch': 41, 'time_epoch': 66.07086, 'eta': 3942.09434, 'eta_hours': 1.09503, 'loss': 0.09584256, 'lr': 6.856e-05, 'params': 514193, 'time_iter': 0.06421, 'accuracy': 0.97255, 'precision': 0.74811, 'recall': 0.4026, 'f1': 0.52348, 'auc': 0.9018}
2025-08-17 05:47:27,044 - INFO - val: {'epoch': 41, 'time_epoch': 4.27655, 'loss': 0.07882677, 'lr': 0, 'params': 514193, 'time_iter': 0.03315, 'accuracy': 0.98104, 'precision': 0.53488, 'recall': 0.28395, 'f1': 0.37097, 'auc': 0.81549}
2025-08-17 05:47:31,224 - INFO - test: {'epoch': 41, 'time_epoch': 4.16396, 'loss': 0.1331203, 'lr': 0, 'params': 514193, 'time_iter': 0.03228, 'accuracy': 0.96645, 'precision': 0.42593, 'recall': 0.17692, 'f1': 0.25, 'auc': 0.73793}
2025-08-17 05:47:31,227 - INFO - > Epoch 41: took 74.6s (avg 76.7s) | Best so far: epoch 41	train_loss: 0.0958 train_auc: 0.9018	val_loss: 0.0788 val_auc: 0.8155	test_loss: 0.1331 test_auc: 0.7379
2025-08-17 05:48:38,012 - INFO - train: {'epoch': 42, 'time_epoch': 66.6963, 'eta': 3872.44259, 'eta_hours': 1.07568, 'loss': 0.09075011, 'lr': 6.701e-05, 'params': 514193, 'time_iter': 0.06482, 'accuracy': 0.97344, 'precision': 0.76246, 'recall': 0.42208, 'f1': 0.54336, 'auc': 0.9148}
2025-08-17 05:48:42,269 - INFO - val: {'epoch': 42, 'time_epoch': 4.23269, 'loss': 0.08695392, 'lr': 0, 'params': 514193, 'time_iter': 0.03281, 'accuracy': 0.97617, 'precision': 0.36508, 'recall': 0.28395, 'f1': 0.31944, 'auc': 0.80093}
2025-08-17 05:48:46,438 - INFO - test: {'epoch': 42, 'time_epoch': 4.15022, 'loss': 0.13604945, 'lr': 0, 'params': 514193, 'time_iter': 0.03217, 'accuracy': 0.96499, 'precision': 0.39394, 'recall': 0.2, 'f1': 0.26531, 'auc': 0.74438}
2025-08-17 05:48:46,441 - INFO - > Epoch 42: took 75.2s (avg 76.7s) | Best so far: epoch 41	train_loss: 0.0958 train_auc: 0.9018	val_loss: 0.0788 val_auc: 0.8155	test_loss: 0.1331 test_auc: 0.7379
2025-08-17 05:49:52,526 - INFO - train: {'epoch': 43, 'time_epoch': 66.00108, 'eta': 3802.04035, 'eta_hours': 1.05612, 'loss': 0.09335036, 'lr': 6.545e-05, 'params': 514193, 'time_iter': 0.06414, 'accuracy': 0.97307, 'precision': 0.74928, 'recall': 0.42208, 'f1': 0.53998, 'auc': 0.91181}
2025-08-17 05:49:56,796 - INFO - val: {'epoch': 43, 'time_epoch': 4.24626, 'loss': 0.09043056, 'lr': 0, 'params': 514193, 'time_iter': 0.03292, 'accuracy': 0.97812, 'precision': 0.42623, 'recall': 0.32099, 'f1': 0.3662, 'auc': 0.78523}
2025-08-17 05:50:00,941 - INFO - test: {'epoch': 43, 'time_epoch': 4.12762, 'loss': 0.13810053, 'lr': 0, 'params': 514193, 'time_iter': 0.032, 'accuracy': 0.96377, 'precision': 0.37662, 'recall': 0.22308, 'f1': 0.28019, 'auc': 0.7607}
2025-08-17 05:50:00,944 - INFO - > Epoch 43: took 74.5s (avg 76.7s) | Best so far: epoch 41	train_loss: 0.0958 train_auc: 0.9018	val_loss: 0.0788 val_auc: 0.8155	test_loss: 0.1331 test_auc: 0.7379
2025-08-17 05:51:07,517 - INFO - train: {'epoch': 44, 'time_epoch': 66.48635, 'eta': 3732.42683, 'eta_hours': 1.03679, 'loss': 0.09140452, 'lr': 6.387e-05, 'params': 514193, 'time_iter': 0.06461, 'accuracy': 0.97353, 'precision': 0.75387, 'recall': 0.43506, 'f1': 0.55172, 'auc': 0.91309}
2025-08-17 05:51:11,789 - INFO - val: {'epoch': 44, 'time_epoch': 4.24815, 'loss': 0.09501149, 'lr': 0, 'params': 514193, 'time_iter': 0.03293, 'accuracy': 0.97326, 'precision': 0.31646, 'recall': 0.30864, 'f1': 0.3125, 'auc': 0.79096}
2025-08-17 05:51:15,971 - INFO - test: {'epoch': 44, 'time_epoch': 4.16449, 'loss': 0.13951372, 'lr': 0, 'params': 514193, 'time_iter': 0.03228, 'accuracy': 0.96159, 'precision': 0.35714, 'recall': 0.26923, 'f1': 0.30702, 'auc': 0.75761}
2025-08-17 05:51:15,974 - INFO - > Epoch 44: took 75.0s (avg 76.6s) | Best so far: epoch 41	train_loss: 0.0958 train_auc: 0.9018	val_loss: 0.0788 val_auc: 0.8155	test_loss: 0.1331 test_auc: 0.7379
2025-08-17 05:52:20,568 - INFO - train: {'epoch': 45, 'time_epoch': 64.51561, 'eta': 3660.63579, 'eta_hours': 1.01684, 'loss': 0.091148, 'lr': 6.227e-05, 'params': 514193, 'time_iter': 0.0627, 'accuracy': 0.97362, 'precision': 0.77003, 'recall': 0.42127, 'f1': 0.5446, 'auc': 0.91606}
2025-08-17 05:52:24,747 - INFO - val: {'epoch': 45, 'time_epoch': 4.15843, 'loss': 0.08044567, 'lr': 0, 'params': 514193, 'time_iter': 0.03224, 'accuracy': 0.97788, 'precision': 0.42188, 'recall': 0.33333, 'f1': 0.37241, 'auc': 0.80764}
2025-08-17 05:52:28,823 - INFO - test: {'epoch': 45, 'time_epoch': 4.05898, 'loss': 0.14371371, 'lr': 0, 'params': 514193, 'time_iter': 0.03146, 'accuracy': 0.96475, 'precision': 0.38095, 'recall': 0.18462, 'f1': 0.2487, 'auc': 0.73837}
2025-08-17 05:52:28,825 - INFO - > Epoch 45: took 72.9s (avg 76.5s) | Best so far: epoch 41	train_loss: 0.0958 train_auc: 0.9018	val_loss: 0.0788 val_auc: 0.8155	test_loss: 0.1331 test_auc: 0.7379
2025-08-17 05:53:34,203 - INFO - train: {'epoch': 46, 'time_epoch': 65.28575, 'eta': 3590.02281, 'eta_hours': 0.99723, 'loss': 0.0907172, 'lr': 6.066e-05, 'params': 514193, 'time_iter': 0.06345, 'accuracy': 0.97331, 'precision': 0.76029, 'recall': 0.41964, 'f1': 0.54079, 'auc': 0.91785}
2025-08-17 05:53:38,487 - INFO - val: {'epoch': 46, 'time_epoch': 4.26051, 'loss': 0.08192654, 'lr': 0, 'params': 514193, 'time_iter': 0.03303, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.2716, 'f1': 0.352, 'auc': 0.82384}
2025-08-17 05:53:42,656 - INFO - test: {'epoch': 46, 'time_epoch': 4.15167, 'loss': 0.13548979, 'lr': 0, 'params': 514193, 'time_iter': 0.03218, 'accuracy': 0.96645, 'precision': 0.43103, 'recall': 0.19231, 'f1': 0.26596, 'auc': 0.76217}
2025-08-17 05:53:42,659 - INFO - > Epoch 46: took 73.8s (avg 76.5s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 05:54:48,593 - INFO - train: {'epoch': 47, 'time_epoch': 65.85207, 'eta': 3520.2453, 'eta_hours': 0.97785, 'loss': 0.0897941, 'lr': 5.904e-05, 'params': 514193, 'time_iter': 0.064, 'accuracy': 0.97435, 'precision': 0.78363, 'recall': 0.43506, 'f1': 0.5595, 'auc': 0.91824}
2025-08-17 05:54:52,783 - INFO - val: {'epoch': 47, 'time_epoch': 4.16776, 'loss': 0.09308053, 'lr': 0, 'params': 514193, 'time_iter': 0.03231, 'accuracy': 0.97155, 'precision': 0.29545, 'recall': 0.32099, 'f1': 0.30769, 'auc': 0.79783}
2025-08-17 05:54:56,853 - INFO - test: {'epoch': 47, 'time_epoch': 4.05317, 'loss': 0.14563296, 'lr': 0, 'params': 514193, 'time_iter': 0.03142, 'accuracy': 0.95867, 'precision': 0.30769, 'recall': 0.24615, 'f1': 0.2735, 'auc': 0.75318}
2025-08-17 05:54:56,856 - INFO - > Epoch 47: took 74.2s (avg 76.4s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 05:56:01,861 - INFO - train: {'epoch': 48, 'time_epoch': 64.92262, 'eta': 3449.66063, 'eta_hours': 0.95824, 'loss': 0.08942824, 'lr': 5.741e-05, 'params': 514193, 'time_iter': 0.06309, 'accuracy': 0.97426, 'precision': 0.78102, 'recall': 0.43425, 'f1': 0.55816, 'auc': 0.9232}
2025-08-17 05:56:06,227 - INFO - val: {'epoch': 48, 'time_epoch': 4.34377, 'loss': 0.08698683, 'lr': 0, 'params': 514193, 'time_iter': 0.03367, 'accuracy': 0.97763, 'precision': 0.40678, 'recall': 0.2963, 'f1': 0.34286, 'auc': 0.79566}
2025-08-17 05:56:10,434 - INFO - test: {'epoch': 48, 'time_epoch': 4.19034, 'loss': 0.13307013, 'lr': 0, 'params': 514193, 'time_iter': 0.03248, 'accuracy': 0.96572, 'precision': 0.42667, 'recall': 0.24615, 'f1': 0.3122, 'auc': 0.76315}
2025-08-17 05:56:10,437 - INFO - > Epoch 48: took 73.6s (avg 76.4s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 05:57:15,692 - INFO - train: {'epoch': 49, 'time_epoch': 65.17521, 'eta': 3379.55502, 'eta_hours': 0.93877, 'loss': 0.08687804, 'lr': 5.577e-05, 'params': 514193, 'time_iter': 0.06334, 'accuracy': 0.97407, 'precision': 0.7643, 'recall': 0.44481, 'f1': 0.56234, 'auc': 0.92752}
2025-08-17 05:57:19,936 - INFO - val: {'epoch': 49, 'time_epoch': 4.22299, 'loss': 0.08743363, 'lr': 0, 'params': 514193, 'time_iter': 0.03274, 'accuracy': 0.97763, 'precision': 0.40351, 'recall': 0.28395, 'f1': 0.33333, 'auc': 0.7973}
2025-08-17 05:57:24,085 - INFO - test: {'epoch': 49, 'time_epoch': 4.13261, 'loss': 0.13854639, 'lr': 0, 'params': 514193, 'time_iter': 0.03204, 'accuracy': 0.96669, 'precision': 0.44444, 'recall': 0.21538, 'f1': 0.29016, 'auc': 0.75351}
2025-08-17 05:57:24,087 - INFO - > Epoch 49: took 73.7s (avg 76.3s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 05:58:29,941 - INFO - train: {'epoch': 50, 'time_epoch': 65.76908, 'eta': 3310.21336, 'eta_hours': 0.9195, 'loss': 0.08646174, 'lr': 5.413e-05, 'params': 514193, 'time_iter': 0.06392, 'accuracy': 0.97508, 'precision': 0.77763, 'recall': 0.46834, 'f1': 0.5846, 'auc': 0.92672}
2025-08-17 05:58:34,227 - INFO - val: {'epoch': 50, 'time_epoch': 4.26203, 'loss': 0.09465926, 'lr': 0, 'params': 514193, 'time_iter': 0.03304, 'accuracy': 0.97326, 'precision': 0.32941, 'recall': 0.34568, 'f1': 0.33735, 'auc': 0.80411}
2025-08-17 05:58:38,372 - INFO - test: {'epoch': 50, 'time_epoch': 4.12654, 'loss': 0.14488038, 'lr': 0, 'params': 514193, 'time_iter': 0.03199, 'accuracy': 0.95867, 'precision': 0.31132, 'recall': 0.25385, 'f1': 0.27966, 'auc': 0.75996}
2025-08-17 05:58:38,375 - INFO - > Epoch 50: took 74.3s (avg 76.3s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 05:59:43,943 - INFO - train: {'epoch': 51, 'time_epoch': 65.4786, 'eta': 3240.74096, 'eta_hours': 0.90021, 'loss': 0.08674348, 'lr': 5.248e-05, 'params': 514193, 'time_iter': 0.06363, 'accuracy': 0.97416, 'precision': 0.76602, 'recall': 0.44643, 'f1': 0.5641, 'auc': 0.93107}
2025-08-17 05:59:48,236 - INFO - val: {'epoch': 51, 'time_epoch': 4.2694, 'loss': 0.0840484, 'lr': 0, 'params': 514193, 'time_iter': 0.0331, 'accuracy': 0.98128, 'precision': 0.54, 'recall': 0.33333, 'f1': 0.41221, 'auc': 0.8111}
2025-08-17 05:59:52,384 - INFO - test: {'epoch': 51, 'time_epoch': 4.12954, 'loss': 0.13689325, 'lr': 0, 'params': 514193, 'time_iter': 0.03201, 'accuracy': 0.96669, 'precision': 0.43396, 'recall': 0.17692, 'f1': 0.25137, 'auc': 0.76924}
2025-08-17 05:59:52,387 - INFO - > Epoch 51: took 74.0s (avg 76.2s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:00:58,555 - INFO - train: {'epoch': 52, 'time_epoch': 66.08775, 'eta': 3171.95946, 'eta_hours': 0.8811, 'loss': 0.08575528, 'lr': 5.083e-05, 'params': 514193, 'time_iter': 0.06423, 'accuracy': 0.97465, 'precision': 0.78107, 'recall': 0.44886, 'f1': 0.5701, 'auc': 0.93044}
2025-08-17 06:01:02,767 - INFO - val: {'epoch': 52, 'time_epoch': 4.19182, 'loss': 0.09792709, 'lr': 0, 'params': 514193, 'time_iter': 0.03249, 'accuracy': 0.97301, 'precision': 0.33333, 'recall': 0.37037, 'f1': 0.35088, 'auc': 0.80151}
2025-08-17 06:01:06,831 - INFO - test: {'epoch': 52, 'time_epoch': 4.04797, 'loss': 0.14619766, 'lr': 0, 'params': 514193, 'time_iter': 0.03138, 'accuracy': 0.95964, 'precision': 0.33333, 'recall': 0.27692, 'f1': 0.30252, 'auc': 0.77219}
2025-08-17 06:01:06,833 - INFO - > Epoch 52: took 74.4s (avg 76.2s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:02:11,685 - INFO - train: {'epoch': 53, 'time_epoch': 64.7653, 'eta': 3102.1512, 'eta_hours': 0.86171, 'loss': 0.08444663, 'lr': 4.917e-05, 'params': 514193, 'time_iter': 0.06294, 'accuracy': 0.97468, 'precision': 0.78218, 'recall': 0.44886, 'f1': 0.5704, 'auc': 0.93384}
2025-08-17 06:02:15,991 - INFO - val: {'epoch': 53, 'time_epoch': 4.28352, 'loss': 0.09882068, 'lr': 0, 'params': 514193, 'time_iter': 0.03321, 'accuracy': 0.9735, 'precision': 0.32927, 'recall': 0.33333, 'f1': 0.33129, 'auc': 0.77118}
2025-08-17 06:02:20,140 - INFO - test: {'epoch': 53, 'time_epoch': 4.13277, 'loss': 0.14775621, 'lr': 0, 'params': 514193, 'time_iter': 0.03204, 'accuracy': 0.96256, 'precision': 0.37234, 'recall': 0.26923, 'f1': 0.3125, 'auc': 0.76487}
2025-08-17 06:02:20,143 - INFO - > Epoch 53: took 73.3s (avg 76.1s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:03:26,044 - INFO - train: {'epoch': 54, 'time_epoch': 65.82153, 'eta': 3033.39051, 'eta_hours': 0.84261, 'loss': 0.08489129, 'lr': 4.752e-05, 'params': 514193, 'time_iter': 0.06397, 'accuracy': 0.9748, 'precision': 0.7834, 'recall': 0.45211, 'f1': 0.57334, 'auc': 0.93448}
2025-08-17 06:03:30,298 - INFO - val: {'epoch': 54, 'time_epoch': 4.23263, 'loss': 0.08567271, 'lr': 0, 'params': 514193, 'time_iter': 0.03281, 'accuracy': 0.9786, 'precision': 0.43636, 'recall': 0.2963, 'f1': 0.35294, 'auc': 0.79827}
2025-08-17 06:03:34,433 - INFO - test: {'epoch': 54, 'time_epoch': 4.11788, 'loss': 0.13582874, 'lr': 0, 'params': 514193, 'time_iter': 0.03192, 'accuracy': 0.96669, 'precision': 0.44068, 'recall': 0.2, 'f1': 0.27513, 'auc': 0.76045}
2025-08-17 06:03:34,435 - INFO - > Epoch 54: took 74.3s (avg 76.1s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:04:40,001 - INFO - train: {'epoch': 55, 'time_epoch': 65.48973, 'eta': 2964.47409, 'eta_hours': 0.82347, 'loss': 0.08371664, 'lr': 4.587e-05, 'params': 514193, 'time_iter': 0.06364, 'accuracy': 0.97517, 'precision': 0.79021, 'recall': 0.4586, 'f1': 0.58038, 'auc': 0.93886}
2025-08-17 06:04:44,220 - INFO - val: {'epoch': 55, 'time_epoch': 4.19757, 'loss': 0.09029385, 'lr': 0, 'params': 514193, 'time_iter': 0.03254, 'accuracy': 0.97958, 'precision': 0.46939, 'recall': 0.28395, 'f1': 0.35385, 'auc': 0.77606}
2025-08-17 06:04:48,515 - INFO - test: {'epoch': 55, 'time_epoch': 4.27781, 'loss': 0.14606855, 'lr': 0, 'params': 514193, 'time_iter': 0.03316, 'accuracy': 0.96742, 'precision': 0.46, 'recall': 0.17692, 'f1': 0.25556, 'auc': 0.73542}
2025-08-17 06:04:48,518 - INFO - > Epoch 55: took 74.1s (avg 76.1s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:05:53,968 - INFO - train: {'epoch': 56, 'time_epoch': 65.36537, 'eta': 2895.58409, 'eta_hours': 0.80433, 'loss': 0.08240763, 'lr': 4.423e-05, 'params': 514193, 'time_iter': 0.06352, 'accuracy': 0.97547, 'precision': 0.7923, 'recall': 0.46753, 'f1': 0.58806, 'auc': 0.93758}
2025-08-17 06:05:58,384 - INFO - val: {'epoch': 56, 'time_epoch': 4.39485, 'loss': 0.09142619, 'lr': 0, 'params': 514193, 'time_iter': 0.03407, 'accuracy': 0.97933, 'precision': 0.46296, 'recall': 0.30864, 'f1': 0.37037, 'auc': 0.79139}
2025-08-17 06:06:02,666 - INFO - test: {'epoch': 56, 'time_epoch': 4.26536, 'loss': 0.14507816, 'lr': 0, 'params': 514193, 'time_iter': 0.03306, 'accuracy': 0.96548, 'precision': 0.40625, 'recall': 0.2, 'f1': 0.26804, 'auc': 0.75465}
2025-08-17 06:06:02,668 - INFO - > Epoch 56: took 74.1s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:07:08,316 - INFO - train: {'epoch': 57, 'time_epoch': 65.57026, 'eta': 2826.96399, 'eta_hours': 0.78527, 'loss': 0.08235752, 'lr': 4.259e-05, 'params': 514193, 'time_iter': 0.06372, 'accuracy': 0.97559, 'precision': 0.78869, 'recall': 0.47565, 'f1': 0.59342, 'auc': 0.9368}
2025-08-17 06:07:12,602 - INFO - val: {'epoch': 57, 'time_epoch': 4.26534, 'loss': 0.09437886, 'lr': 0, 'params': 514193, 'time_iter': 0.03306, 'accuracy': 0.97253, 'precision': 0.31395, 'recall': 0.33333, 'f1': 0.32335, 'auc': 0.81569}
2025-08-17 06:07:16,877 - INFO - test: {'epoch': 57, 'time_epoch': 4.25838, 'loss': 0.15930018, 'lr': 0, 'params': 514193, 'time_iter': 0.03301, 'accuracy': 0.95842, 'precision': 0.26966, 'recall': 0.18462, 'f1': 0.21918, 'auc': 0.73711}
2025-08-17 06:07:16,880 - INFO - > Epoch 57: took 74.2s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:08:24,497 - INFO - train: {'epoch': 58, 'time_epoch': 67.53365, 'eta': 2759.81167, 'eta_hours': 0.76661, 'loss': 0.08417077, 'lr': 4.096e-05, 'params': 514193, 'time_iter': 0.06563, 'accuracy': 0.97553, 'precision': 0.80028, 'recall': 0.46185, 'f1': 0.58569, 'auc': 0.93371}
2025-08-17 06:08:28,991 - INFO - val: {'epoch': 58, 'time_epoch': 4.47217, 'loss': 0.08598696, 'lr': 0, 'params': 514193, 'time_iter': 0.03467, 'accuracy': 0.97836, 'precision': 0.43103, 'recall': 0.30864, 'f1': 0.35971, 'auc': 0.80734}
2025-08-17 06:08:33,425 - INFO - test: {'epoch': 58, 'time_epoch': 4.41609, 'loss': 0.14781796, 'lr': 0, 'params': 514193, 'time_iter': 0.03423, 'accuracy': 0.96475, 'precision': 0.38462, 'recall': 0.19231, 'f1': 0.25641, 'auc': 0.73677}
2025-08-17 06:08:33,427 - INFO - > Epoch 58: took 76.5s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:09:42,388 - INFO - train: {'epoch': 59, 'time_epoch': 68.87485, 'eta': 2693.54077, 'eta_hours': 0.74821, 'loss': 0.08172523, 'lr': 3.934e-05, 'params': 514193, 'time_iter': 0.06693, 'accuracy': 0.97489, 'precision': 0.77507, 'recall': 0.46429, 'f1': 0.58071, 'auc': 0.94122}
2025-08-17 06:09:46,920 - INFO - val: {'epoch': 59, 'time_epoch': 4.50887, 'loss': 0.09365495, 'lr': 0, 'params': 514193, 'time_iter': 0.03495, 'accuracy': 0.9752, 'precision': 0.36, 'recall': 0.33333, 'f1': 0.34615, 'auc': 0.81446}
2025-08-17 06:09:51,457 - INFO - test: {'epoch': 59, 'time_epoch': 4.51855, 'loss': 0.15735845, 'lr': 0, 'params': 514193, 'time_iter': 0.03503, 'accuracy': 0.96207, 'precision': 0.33333, 'recall': 0.2, 'f1': 0.25, 'auc': 0.74404}
2025-08-17 06:09:51,459 - INFO - > Epoch 59: took 78.0s (avg 76.1s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:10:58,761 - INFO - train: {'epoch': 60, 'time_epoch': 67.21957, 'eta': 2626.1262, 'eta_hours': 0.72948, 'loss': 0.07839374, 'lr': 3.773e-05, 'params': 514193, 'time_iter': 0.06533, 'accuracy': 0.97605, 'precision': 0.80081, 'recall': 0.47971, 'f1': 0.6, 'auc': 0.94762}
2025-08-17 06:11:03,142 - INFO - val: {'epoch': 60, 'time_epoch': 4.35842, 'loss': 0.08987462, 'lr': 0, 'params': 514193, 'time_iter': 0.03379, 'accuracy': 0.9769, 'precision': 0.40278, 'recall': 0.35802, 'f1': 0.37908, 'auc': 0.804}
2025-08-17 06:11:07,450 - INFO - test: {'epoch': 60, 'time_epoch': 4.292, 'loss': 0.15282717, 'lr': 0, 'params': 514193, 'time_iter': 0.03327, 'accuracy': 0.96329, 'precision': 0.35616, 'recall': 0.2, 'f1': 0.25616, 'auc': 0.7474}
2025-08-17 06:11:07,453 - INFO - > Epoch 60: took 76.0s (avg 76.1s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:12:12,038 - INFO - train: {'epoch': 61, 'time_epoch': 64.50915, 'eta': 2557.0567, 'eta_hours': 0.71029, 'loss': 0.08012629, 'lr': 3.613e-05, 'params': 514193, 'time_iter': 0.06269, 'accuracy': 0.97599, 'precision': 0.78927, 'recall': 0.48945, 'f1': 0.60421, 'auc': 0.94371}
2025-08-17 06:12:16,311 - INFO - val: {'epoch': 61, 'time_epoch': 4.25242, 'loss': 0.09122157, 'lr': 0, 'params': 514193, 'time_iter': 0.03296, 'accuracy': 0.9769, 'precision': 0.39394, 'recall': 0.32099, 'f1': 0.35374, 'auc': 0.78941}
2025-08-17 06:12:20,437 - INFO - test: {'epoch': 61, 'time_epoch': 4.11006, 'loss': 0.15374363, 'lr': 0, 'params': 514193, 'time_iter': 0.03186, 'accuracy': 0.96353, 'precision': 0.34848, 'recall': 0.17692, 'f1': 0.23469, 'auc': 0.7327}
2025-08-17 06:12:20,439 - INFO - > Epoch 61: took 73.0s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:13:27,904 - INFO - train: {'epoch': 62, 'time_epoch': 67.37629, 'eta': 2489.81584, 'eta_hours': 0.69162, 'loss': 0.07898238, 'lr': 3.455e-05, 'params': 514193, 'time_iter': 0.06548, 'accuracy': 0.97626, 'precision': 0.79789, 'recall': 0.49026, 'f1': 0.60734, 'auc': 0.94551}
2025-08-17 06:13:32,106 - INFO - val: {'epoch': 62, 'time_epoch': 4.1781, 'loss': 0.09244495, 'lr': 0, 'params': 514193, 'time_iter': 0.03239, 'accuracy': 0.9769, 'precision': 0.39706, 'recall': 0.33333, 'f1': 0.36242, 'auc': 0.79505}
2025-08-17 06:13:36,240 - INFO - test: {'epoch': 62, 'time_epoch': 4.11662, 'loss': 0.15293297, 'lr': 0, 'params': 514193, 'time_iter': 0.03191, 'accuracy': 0.96402, 'precision': 0.375, 'recall': 0.20769, 'f1': 0.26733, 'auc': 0.75709}
2025-08-17 06:13:36,243 - INFO - > Epoch 62: took 75.8s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:14:41,473 - INFO - train: {'epoch': 63, 'time_epoch': 65.14974, 'eta': 2421.31832, 'eta_hours': 0.67259, 'loss': 0.07776838, 'lr': 3.299e-05, 'params': 514193, 'time_iter': 0.06331, 'accuracy': 0.9766, 'precision': 0.79615, 'recall': 0.50406, 'f1': 0.6173, 'auc': 0.94905}
2025-08-17 06:14:45,732 - INFO - val: {'epoch': 63, 'time_epoch': 4.23826, 'loss': 0.09850031, 'lr': 0, 'params': 514193, 'time_iter': 0.03285, 'accuracy': 0.97423, 'precision': 0.3494, 'recall': 0.35802, 'f1': 0.35366, 'auc': 0.80269}
2025-08-17 06:14:49,822 - INFO - test: {'epoch': 63, 'time_epoch': 4.07351, 'loss': 0.16396183, 'lr': 0, 'params': 514193, 'time_iter': 0.03158, 'accuracy': 0.95964, 'precision': 0.30851, 'recall': 0.22308, 'f1': 0.25893, 'auc': 0.74281}
2025-08-17 06:14:49,824 - INFO - > Epoch 63: took 73.6s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:15:57,348 - INFO - train: {'epoch': 64, 'time_epoch': 67.43581, 'eta': 2354.15477, 'eta_hours': 0.65393, 'loss': 0.07879018, 'lr': 3.144e-05, 'params': 514193, 'time_iter': 0.06554, 'accuracy': 0.97614, 'precision': 0.7992, 'recall': 0.48458, 'f1': 0.60334, 'auc': 0.94897}
2025-08-17 06:16:01,610 - INFO - val: {'epoch': 64, 'time_epoch': 4.23994, 'loss': 0.09084819, 'lr': 0, 'params': 514193, 'time_iter': 0.03287, 'accuracy': 0.97642, 'precision': 0.38889, 'recall': 0.34568, 'f1': 0.36601, 'auc': 0.80708}
2025-08-17 06:16:05,733 - INFO - test: {'epoch': 64, 'time_epoch': 4.10465, 'loss': 0.15403342, 'lr': 0, 'params': 514193, 'time_iter': 0.03182, 'accuracy': 0.96231, 'precision': 0.36264, 'recall': 0.25385, 'f1': 0.29864, 'auc': 0.74593}
2025-08-17 06:16:05,736 - INFO - > Epoch 64: took 75.9s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:17:13,818 - INFO - train: {'epoch': 65, 'time_epoch': 68.00058, 'eta': 2287.27391, 'eta_hours': 0.63535, 'loss': 0.07713528, 'lr': 2.992e-05, 'params': 514193, 'time_iter': 0.06608, 'accuracy': 0.97629, 'precision': 0.8079, 'recall': 0.48133, 'f1': 0.60326, 'auc': 0.95255}
2025-08-17 06:17:18,019 - INFO - val: {'epoch': 65, 'time_epoch': 4.17625, 'loss': 0.08739386, 'lr': 0, 'params': 514193, 'time_iter': 0.03237, 'accuracy': 0.97763, 'precision': 0.40984, 'recall': 0.30864, 'f1': 0.35211, 'auc': 0.81525}
2025-08-17 06:17:22,137 - INFO - test: {'epoch': 65, 'time_epoch': 4.10079, 'loss': 0.1489623, 'lr': 0, 'params': 514193, 'time_iter': 0.03179, 'accuracy': 0.96596, 'precision': 0.41071, 'recall': 0.17692, 'f1': 0.24731, 'auc': 0.74979}
2025-08-17 06:17:22,140 - INFO - > Epoch 65: took 76.4s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:18:28,074 - INFO - train: {'epoch': 66, 'time_epoch': 65.84559, 'eta': 2219.29821, 'eta_hours': 0.61647, 'loss': 0.07654291, 'lr': 2.841e-05, 'params': 514193, 'time_iter': 0.06399, 'accuracy': 0.97663, 'precision': 0.79641, 'recall': 0.50487, 'f1': 0.61798, 'auc': 0.95208}
2025-08-17 06:18:32,367 - INFO - val: {'epoch': 66, 'time_epoch': 4.26983, 'loss': 0.0883075, 'lr': 0, 'params': 514193, 'time_iter': 0.0331, 'accuracy': 0.97885, 'precision': 0.45312, 'recall': 0.35802, 'f1': 0.4, 'auc': 0.79796}
2025-08-17 06:18:36,540 - INFO - test: {'epoch': 66, 'time_epoch': 4.15487, 'loss': 0.15186377, 'lr': 0, 'params': 514193, 'time_iter': 0.03221, 'accuracy': 0.96402, 'precision': 0.36765, 'recall': 0.19231, 'f1': 0.25253, 'auc': 0.75001}
2025-08-17 06:18:36,543 - INFO - > Epoch 66: took 74.4s (avg 75.9s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:19:42,961 - INFO - train: {'epoch': 67, 'time_epoch': 66.33365, 'eta': 2151.61484, 'eta_hours': 0.59767, 'loss': 0.07563672, 'lr': 2.693e-05, 'params': 514193, 'time_iter': 0.06446, 'accuracy': 0.97663, 'precision': 0.79641, 'recall': 0.50487, 'f1': 0.61798, 'auc': 0.95209}
2025-08-17 06:19:47,222 - INFO - val: {'epoch': 67, 'time_epoch': 4.23849, 'loss': 0.10233799, 'lr': 0, 'params': 514193, 'time_iter': 0.03286, 'accuracy': 0.97301, 'precision': 0.33333, 'recall': 0.37037, 'f1': 0.35088, 'auc': 0.80102}
2025-08-17 06:19:51,350 - INFO - test: {'epoch': 67, 'time_epoch': 4.10987, 'loss': 0.16770562, 'lr': 0, 'params': 514193, 'time_iter': 0.03186, 'accuracy': 0.95964, 'precision': 0.32, 'recall': 0.24615, 'f1': 0.27826, 'auc': 0.74112}
2025-08-17 06:19:51,352 - INFO - > Epoch 67: took 74.8s (avg 75.9s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:20:58,089 - INFO - train: {'epoch': 68, 'time_epoch': 66.65375, 'eta': 2084.1144, 'eta_hours': 0.57892, 'loss': 0.07663279, 'lr': 2.548e-05, 'params': 514193, 'time_iter': 0.06478, 'accuracy': 0.97669, 'precision': 0.80472, 'recall': 0.49838, 'f1': 0.61554, 'auc': 0.95339}
2025-08-17 06:21:02,463 - INFO - val: {'epoch': 68, 'time_epoch': 4.35282, 'loss': 0.09317822, 'lr': 0, 'params': 514193, 'time_iter': 0.03374, 'accuracy': 0.97739, 'precision': 0.41176, 'recall': 0.34568, 'f1': 0.37584, 'auc': 0.80203}
2025-08-17 06:21:06,678 - INFO - test: {'epoch': 68, 'time_epoch': 4.19855, 'loss': 0.15891271, 'lr': 0, 'params': 514193, 'time_iter': 0.03255, 'accuracy': 0.96183, 'precision': 0.35789, 'recall': 0.26154, 'f1': 0.30222, 'auc': 0.73945}
2025-08-17 06:21:06,681 - INFO - > Epoch 68: took 75.3s (avg 75.9s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:22:14,377 - INFO - train: {'epoch': 69, 'time_epoch': 67.61504, 'eta': 2017.05014, 'eta_hours': 0.56029, 'loss': 0.07721871, 'lr': 2.405e-05, 'params': 514193, 'time_iter': 0.06571, 'accuracy': 0.97635, 'precision': 0.80026, 'recall': 0.49107, 'f1': 0.60865, 'auc': 0.9505}
2025-08-17 06:22:18,703 - INFO - val: {'epoch': 69, 'time_epoch': 4.30428, 'loss': 0.09469243, 'lr': 0, 'params': 514193, 'time_iter': 0.03337, 'accuracy': 0.97617, 'precision': 0.38667, 'recall': 0.35802, 'f1': 0.37179, 'auc': 0.80292}
2025-08-17 06:22:22,911 - INFO - test: {'epoch': 69, 'time_epoch': 4.18434, 'loss': 0.16237322, 'lr': 0, 'params': 514193, 'time_iter': 0.03244, 'accuracy': 0.96207, 'precision': 0.37255, 'recall': 0.29231, 'f1': 0.32759, 'auc': 0.74419}
2025-08-17 06:22:22,914 - INFO - > Epoch 69: took 76.2s (avg 75.9s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:23:30,260 - INFO - train: {'epoch': 70, 'time_epoch': 67.26058, 'eta': 1949.82558, 'eta_hours': 0.54162, 'loss': 0.07484572, 'lr': 2.265e-05, 'params': 514193, 'time_iter': 0.06536, 'accuracy': 0.97736, 'precision': 0.81747, 'recall': 0.50893, 'f1': 0.62731, 'auc': 0.95434}
2025-08-17 06:23:34,717 - INFO - val: {'epoch': 70, 'time_epoch': 4.43247, 'loss': 0.11119553, 'lr': 0, 'params': 514193, 'time_iter': 0.03436, 'accuracy': 0.97034, 'precision': 0.31193, 'recall': 0.41975, 'f1': 0.35789, 'auc': 0.80182}
2025-08-17 06:23:39,046 - INFO - test: {'epoch': 70, 'time_epoch': 4.30484, 'loss': 0.1804603, 'lr': 0, 'params': 514193, 'time_iter': 0.03337, 'accuracy': 0.95137, 'precision': 0.24638, 'recall': 0.26154, 'f1': 0.25373, 'auc': 0.73657}
2025-08-17 06:23:39,058 - INFO - > Epoch 70: took 76.1s (avg 75.9s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:24:47,022 - INFO - train: {'epoch': 71, 'time_epoch': 67.88314, 'eta': 1882.84213, 'eta_hours': 0.52301, 'loss': 0.07430825, 'lr': 2.128e-05, 'params': 514193, 'time_iter': 0.06597, 'accuracy': 0.97678, 'precision': 0.79923, 'recall': 0.50731, 'f1': 0.62066, 'auc': 0.95728}
2025-08-17 06:24:51,234 - INFO - val: {'epoch': 71, 'time_epoch': 4.19056, 'loss': 0.0943808, 'lr': 0, 'params': 514193, 'time_iter': 0.03248, 'accuracy': 0.97593, 'precision': 0.38158, 'recall': 0.35802, 'f1': 0.36943, 'auc': 0.80764}
2025-08-17 06:24:55,329 - INFO - test: {'epoch': 71, 'time_epoch': 4.07828, 'loss': 0.16818452, 'lr': 0, 'params': 514193, 'time_iter': 0.03161, 'accuracy': 0.96329, 'precision': 0.37647, 'recall': 0.24615, 'f1': 0.29767, 'auc': 0.7307}
2025-08-17 06:24:55,331 - INFO - > Epoch 71: took 76.3s (avg 75.9s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:26:03,268 - INFO - train: {'epoch': 72, 'time_epoch': 67.85262, 'eta': 1815.82274, 'eta_hours': 0.5044, 'loss': 0.07382065, 'lr': 1.995e-05, 'params': 514193, 'time_iter': 0.06594, 'accuracy': 0.9776, 'precision': 0.81609, 'recall': 0.51867, 'f1': 0.63424, 'auc': 0.95449}
2025-08-17 06:26:07,690 - INFO - val: {'epoch': 72, 'time_epoch': 4.39801, 'loss': 0.09906918, 'lr': 0, 'params': 514193, 'time_iter': 0.03409, 'accuracy': 0.9735, 'precision': 0.33721, 'recall': 0.35802, 'f1': 0.34731, 'auc': 0.80432}
2025-08-17 06:26:12,031 - INFO - test: {'epoch': 72, 'time_epoch': 4.31863, 'loss': 0.16714841, 'lr': 0, 'params': 514193, 'time_iter': 0.03348, 'accuracy': 0.95915, 'precision': 0.31, 'recall': 0.23846, 'f1': 0.26957, 'auc': 0.74736}
2025-08-17 06:26:12,034 - INFO - > Epoch 72: took 76.7s (avg 75.9s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:27:20,857 - INFO - train: {'epoch': 73, 'time_epoch': 68.73805, 'eta': 1749.09192, 'eta_hours': 0.48586, 'loss': 0.07150721, 'lr': 1.864e-05, 'params': 514193, 'time_iter': 0.0668, 'accuracy': 0.9773, 'precision': 0.80735, 'recall': 0.51705, 'f1': 0.63038, 'auc': 0.96226}
2025-08-17 06:27:25,252 - INFO - val: {'epoch': 73, 'time_epoch': 4.37004, 'loss': 0.09543875, 'lr': 0, 'params': 514193, 'time_iter': 0.03388, 'accuracy': 0.97617, 'precision': 0.38667, 'recall': 0.35802, 'f1': 0.37179, 'auc': 0.80552}
2025-08-17 06:27:29,531 - INFO - test: {'epoch': 73, 'time_epoch': 4.26041, 'loss': 0.16725312, 'lr': 0, 'params': 514193, 'time_iter': 0.03303, 'accuracy': 0.96329, 'precision': 0.38462, 'recall': 0.26923, 'f1': 0.31674, 'auc': 0.73702}
2025-08-17 06:27:29,534 - INFO - > Epoch 73: took 77.5s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:28:37,185 - INFO - train: {'epoch': 74, 'time_epoch': 67.56369, 'eta': 1681.91613, 'eta_hours': 0.4672, 'loss': 0.07310973, 'lr': 1.737e-05, 'params': 514193, 'time_iter': 0.06566, 'accuracy': 0.97806, 'precision': 0.82116, 'recall': 0.52922, 'f1': 0.64363, 'auc': 0.95639}
2025-08-17 06:28:41,591 - INFO - val: {'epoch': 74, 'time_epoch': 4.38444, 'loss': 0.10635635, 'lr': 0, 'params': 514193, 'time_iter': 0.03399, 'accuracy': 0.9735, 'precision': 0.34091, 'recall': 0.37037, 'f1': 0.35503, 'auc': 0.80278}
2025-08-17 06:28:45,851 - INFO - test: {'epoch': 74, 'time_epoch': 4.24242, 'loss': 0.17576091, 'lr': 0, 'params': 514193, 'time_iter': 0.03289, 'accuracy': 0.95794, 'precision': 0.29524, 'recall': 0.23846, 'f1': 0.26383, 'auc': 0.73924}
2025-08-17 06:28:45,854 - INFO - > Epoch 74: took 76.3s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:29:54,124 - INFO - train: {'epoch': 75, 'time_epoch': 68.18698, 'eta': 1614.92696, 'eta_hours': 0.44859, 'loss': 0.07186431, 'lr': 1.614e-05, 'params': 514193, 'time_iter': 0.06627, 'accuracy': 0.97766, 'precision': 0.80566, 'recall': 0.53166, 'f1': 0.64059, 'auc': 0.9601}
2025-08-17 06:29:58,591 - INFO - val: {'epoch': 75, 'time_epoch': 4.44532, 'loss': 0.09638558, 'lr': 0, 'params': 514193, 'time_iter': 0.03446, 'accuracy': 0.97593, 'precision': 0.38158, 'recall': 0.35802, 'f1': 0.36943, 'auc': 0.80133}
2025-08-17 06:30:02,967 - INFO - test: {'epoch': 75, 'time_epoch': 4.35778, 'loss': 0.17290331, 'lr': 0, 'params': 514193, 'time_iter': 0.03378, 'accuracy': 0.96256, 'precision': 0.34615, 'recall': 0.20769, 'f1': 0.25962, 'auc': 0.72291}
2025-08-17 06:30:02,970 - INFO - > Epoch 75: took 77.1s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:31:11,828 - INFO - train: {'epoch': 76, 'time_epoch': 68.776, 'eta': 1548.08262, 'eta_hours': 0.43002, 'loss': 0.07134654, 'lr': 1.494e-05, 'params': 514193, 'time_iter': 0.06684, 'accuracy': 0.97699, 'precision': 0.79357, 'recall': 0.5211, 'f1': 0.6291, 'auc': 0.96325}
2025-08-17 06:31:16,148 - INFO - val: {'epoch': 76, 'time_epoch': 4.29629, 'loss': 0.09510339, 'lr': 0, 'params': 514193, 'time_iter': 0.0333, 'accuracy': 0.97739, 'precision': 0.41429, 'recall': 0.35802, 'f1': 0.38411, 'auc': 0.80166}
2025-08-17 06:31:20,350 - INFO - test: {'epoch': 76, 'time_epoch': 4.18041, 'loss': 0.1665861, 'lr': 0, 'params': 514193, 'time_iter': 0.03241, 'accuracy': 0.96329, 'precision': 0.36709, 'recall': 0.22308, 'f1': 0.27751, 'auc': 0.74098}
2025-08-17 06:31:20,352 - INFO - > Epoch 76: took 77.4s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:32:27,981 - INFO - train: {'epoch': 77, 'time_epoch': 67.54328, 'eta': 1480.84106, 'eta_hours': 0.41134, 'loss': 0.07280658, 'lr': 1.378e-05, 'params': 514193, 'time_iter': 0.06564, 'accuracy': 0.97766, 'precision': 0.80268, 'recall': 0.5349, 'f1': 0.64199, 'auc': 0.95946}
2025-08-17 06:32:32,523 - INFO - val: {'epoch': 77, 'time_epoch': 4.51597, 'loss': 0.10094563, 'lr': 0, 'params': 514193, 'time_iter': 0.03501, 'accuracy': 0.97398, 'precision': 0.34884, 'recall': 0.37037, 'f1': 0.35928, 'auc': 0.79118}
2025-08-17 06:32:36,964 - INFO - test: {'epoch': 77, 'time_epoch': 4.42141, 'loss': 0.17164283, 'lr': 0, 'params': 514193, 'time_iter': 0.03427, 'accuracy': 0.96061, 'precision': 0.33333, 'recall': 0.24615, 'f1': 0.28319, 'auc': 0.73355}
2025-08-17 06:32:36,966 - INFO - > Epoch 77: took 76.6s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:33:45,589 - INFO - train: {'epoch': 78, 'time_epoch': 68.53849, 'eta': 1413.85641, 'eta_hours': 0.39274, 'loss': 0.07203625, 'lr': 1.266e-05, 'params': 514193, 'time_iter': 0.06661, 'accuracy': 0.97827, 'precision': 0.81563, 'recall': 0.54221, 'f1': 0.65139, 'auc': 0.96023}
2025-08-17 06:33:49,932 - INFO - val: {'epoch': 78, 'time_epoch': 4.31862, 'loss': 0.09911712, 'lr': 0, 'params': 514193, 'time_iter': 0.03348, 'accuracy': 0.97496, 'precision': 0.35526, 'recall': 0.33333, 'f1': 0.34395, 'auc': 0.80729}
2025-08-17 06:33:54,171 - INFO - test: {'epoch': 78, 'time_epoch': 4.21927, 'loss': 0.17072902, 'lr': 0, 'params': 514193, 'time_iter': 0.03271, 'accuracy': 0.96256, 'precision': 0.35366, 'recall': 0.22308, 'f1': 0.27358, 'auc': 0.73467}
2025-08-17 06:33:54,174 - INFO - > Epoch 78: took 77.2s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:35:01,095 - INFO - train: {'epoch': 79, 'time_epoch': 66.84108, 'eta': 1346.40856, 'eta_hours': 0.374, 'loss': 0.07040885, 'lr': 1.158e-05, 'params': 514193, 'time_iter': 0.06496, 'accuracy': 0.97821, 'precision': 0.81673, 'recall': 0.53896, 'f1': 0.64939, 'auc': 0.96239}
2025-08-17 06:35:05,346 - INFO - val: {'epoch': 79, 'time_epoch': 4.23061, 'loss': 0.10312285, 'lr': 0, 'params': 514193, 'time_iter': 0.0328, 'accuracy': 0.97544, 'precision': 0.37179, 'recall': 0.35802, 'f1': 0.36478, 'auc': 0.80913}
2025-08-17 06:35:09,443 - INFO - test: {'epoch': 79, 'time_epoch': 4.08007, 'loss': 0.17645862, 'lr': 0, 'params': 514193, 'time_iter': 0.03163, 'accuracy': 0.95915, 'precision': 0.31, 'recall': 0.23846, 'f1': 0.26957, 'auc': 0.73682}
2025-08-17 06:35:09,445 - INFO - > Epoch 79: took 75.3s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:36:18,052 - INFO - train: {'epoch': 80, 'time_epoch': 68.52019, 'eta': 1279.36955, 'eta_hours': 0.35538, 'loss': 0.07158419, 'lr': 1.054e-05, 'params': 514193, 'time_iter': 0.06659, 'accuracy': 0.97812, 'precision': 0.81841, 'recall': 0.53409, 'f1': 0.64637, 'auc': 0.95954}
2025-08-17 06:36:22,448 - INFO - val: {'epoch': 80, 'time_epoch': 4.37236, 'loss': 0.1050322, 'lr': 0, 'params': 514193, 'time_iter': 0.03389, 'accuracy': 0.9718, 'precision': 0.31959, 'recall': 0.38272, 'f1': 0.34831, 'auc': 0.80705}
2025-08-17 06:36:26,733 - INFO - test: {'epoch': 80, 'time_epoch': 4.26699, 'loss': 0.17300655, 'lr': 0, 'params': 514193, 'time_iter': 0.03308, 'accuracy': 0.95867, 'precision': 0.31132, 'recall': 0.25385, 'f1': 0.27966, 'auc': 0.74814}
2025-08-17 06:36:26,735 - INFO - > Epoch 80: took 77.3s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:37:35,117 - INFO - train: {'epoch': 81, 'time_epoch': 68.29656, 'eta': 1212.24534, 'eta_hours': 0.33673, 'loss': 0.07247789, 'lr': 9.55e-06, 'params': 514193, 'time_iter': 0.06637, 'accuracy': 0.9776, 'precision': 0.80899, 'recall': 0.52597, 'f1': 0.63748, 'auc': 0.96002}
2025-08-17 06:37:39,499 - INFO - val: {'epoch': 81, 'time_epoch': 4.36147, 'loss': 0.10796366, 'lr': 0, 'params': 514193, 'time_iter': 0.03381, 'accuracy': 0.97277, 'precision': 0.32967, 'recall': 0.37037, 'f1': 0.34884, 'auc': 0.8042}
2025-08-17 06:37:43,849 - INFO - test: {'epoch': 81, 'time_epoch': 4.33238, 'loss': 0.18129382, 'lr': 0, 'params': 514193, 'time_iter': 0.03358, 'accuracy': 0.95624, 'precision': 0.2807, 'recall': 0.24615, 'f1': 0.2623, 'auc': 0.74633}
2025-08-17 06:37:43,851 - INFO - > Epoch 81: took 77.1s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:38:50,754 - INFO - train: {'epoch': 82, 'time_epoch': 66.82129, 'eta': 1144.7907, 'eta_hours': 0.318, 'loss': 0.07233807, 'lr': 8.6e-06, 'params': 514193, 'time_iter': 0.06494, 'accuracy': 0.97781, 'precision': 0.82513, 'recall': 0.51705, 'f1': 0.63573, 'auc': 0.96181}
2025-08-17 06:38:55,079 - INFO - val: {'epoch': 82, 'time_epoch': 4.30277, 'loss': 0.10653646, 'lr': 0, 'params': 514193, 'time_iter': 0.03335, 'accuracy': 0.9718, 'precision': 0.31959, 'recall': 0.38272, 'f1': 0.34831, 'auc': 0.8052}
2025-08-17 06:38:59,304 - INFO - test: {'epoch': 82, 'time_epoch': 4.20813, 'loss': 0.1779019, 'lr': 0, 'params': 514193, 'time_iter': 0.03262, 'accuracy': 0.95526, 'precision': 0.275, 'recall': 0.25385, 'f1': 0.264, 'auc': 0.74744}
2025-08-17 06:38:59,307 - INFO - > Epoch 82: took 75.5s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:40:05,964 - INFO - train: {'epoch': 83, 'time_epoch': 66.57042, 'eta': 1077.30337, 'eta_hours': 0.29925, 'loss': 0.06931664, 'lr': 7.7e-06, 'params': 514193, 'time_iter': 0.06469, 'accuracy': 0.9776, 'precision': 0.8, 'recall': 0.53571, 'f1': 0.64171, 'auc': 0.96647}
2025-08-17 06:40:10,373 - INFO - val: {'epoch': 83, 'time_epoch': 4.38356, 'loss': 0.10427774, 'lr': 0, 'params': 514193, 'time_iter': 0.03398, 'accuracy': 0.97447, 'precision': 0.35366, 'recall': 0.35802, 'f1': 0.35583, 'auc': 0.8041}
2025-08-17 06:40:14,748 - INFO - test: {'epoch': 83, 'time_epoch': 4.35603, 'loss': 0.17936737, 'lr': 0, 'params': 514193, 'time_iter': 0.03377, 'accuracy': 0.96037, 'precision': 0.33333, 'recall': 0.25385, 'f1': 0.28821, 'auc': 0.73554}
2025-08-17 06:40:14,751 - INFO - > Epoch 83: took 75.4s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:41:22,596 - INFO - train: {'epoch': 84, 'time_epoch': 67.76024, 'eta': 1010.04757, 'eta_hours': 0.28057, 'loss': 0.07067265, 'lr': 6.84e-06, 'params': 514193, 'time_iter': 0.06585, 'accuracy': 0.97806, 'precision': 0.81481, 'recall': 0.53571, 'f1': 0.64643, 'auc': 0.96258}
2025-08-17 06:41:26,829 - INFO - val: {'epoch': 84, 'time_epoch': 4.2121, 'loss': 0.10281568, 'lr': 0, 'params': 514193, 'time_iter': 0.03265, 'accuracy': 0.97544, 'precision': 0.375, 'recall': 0.37037, 'f1': 0.37267, 'auc': 0.80555}
2025-08-17 06:41:30,982 - INFO - test: {'epoch': 84, 'time_epoch': 4.13555, 'loss': 0.17842872, 'lr': 0, 'params': 514193, 'time_iter': 0.03206, 'accuracy': 0.9611, 'precision': 0.33696, 'recall': 0.23846, 'f1': 0.27928, 'auc': 0.73129}
2025-08-17 06:41:30,984 - INFO - > Epoch 84: took 76.2s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:42:37,336 - INFO - train: {'epoch': 85, 'time_epoch': 66.27068, 'eta': 942.53756, 'eta_hours': 0.26182, 'loss': 0.0700625, 'lr': 6.03e-06, 'params': 514193, 'time_iter': 0.0644, 'accuracy': 0.97824, 'precision': 0.81618, 'recall': 0.54058, 'f1': 0.65039, 'auc': 0.96453}
2025-08-17 06:42:41,751 - INFO - val: {'epoch': 85, 'time_epoch': 4.39214, 'loss': 0.09960433, 'lr': 0, 'params': 514193, 'time_iter': 0.03405, 'accuracy': 0.97544, 'precision': 0.375, 'recall': 0.37037, 'f1': 0.37267, 'auc': 0.80995}
2025-08-17 06:42:46,052 - INFO - test: {'epoch': 85, 'time_epoch': 4.28247, 'loss': 0.17613996, 'lr': 0, 'params': 514193, 'time_iter': 0.0332, 'accuracy': 0.95915, 'precision': 0.31373, 'recall': 0.24615, 'f1': 0.27586, 'auc': 0.73566}
2025-08-17 06:42:46,055 - INFO - > Epoch 85: took 75.1s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:43:53,544 - INFO - train: {'epoch': 86, 'time_epoch': 67.40382, 'eta': 875.22536, 'eta_hours': 0.24312, 'loss': 0.07024162, 'lr': 5.26e-06, 'params': 514193, 'time_iter': 0.0655, 'accuracy': 0.9783, 'precision': 0.82134, 'recall': 0.53734, 'f1': 0.64966, 'auc': 0.96293}
2025-08-17 06:43:57,977 - INFO - val: {'epoch': 86, 'time_epoch': 4.4113, 'loss': 0.10375994, 'lr': 0, 'params': 514193, 'time_iter': 0.0342, 'accuracy': 0.97398, 'precision': 0.34884, 'recall': 0.37037, 'f1': 0.35928, 'auc': 0.81119}
2025-08-17 06:44:02,301 - INFO - test: {'epoch': 86, 'time_epoch': 4.30681, 'loss': 0.18041773, 'lr': 0, 'params': 514193, 'time_iter': 0.03339, 'accuracy': 0.95891, 'precision': 0.29897, 'recall': 0.22308, 'f1': 0.25551, 'auc': 0.74049}
2025-08-17 06:44:02,303 - INFO - > Epoch 86: took 76.2s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:45:08,764 - INFO - train: {'epoch': 87, 'time_epoch': 66.38021, 'eta': 807.7715, 'eta_hours': 0.22438, 'loss': 0.06794777, 'lr': 4.55e-06, 'params': 514193, 'time_iter': 0.06451, 'accuracy': 0.97878, 'precision': 0.82324, 'recall': 0.55195, 'f1': 0.66084, 'auc': 0.96635}
2025-08-17 06:45:12,979 - INFO - val: {'epoch': 87, 'time_epoch': 4.1943, 'loss': 0.10137108, 'lr': 0, 'params': 514193, 'time_iter': 0.03251, 'accuracy': 0.97496, 'precision': 0.36585, 'recall': 0.37037, 'f1': 0.3681, 'auc': 0.81217}
2025-08-17 06:45:17,144 - INFO - test: {'epoch': 87, 'time_epoch': 4.1482, 'loss': 0.17465995, 'lr': 0, 'params': 514193, 'time_iter': 0.03216, 'accuracy': 0.96037, 'precision': 0.32632, 'recall': 0.23846, 'f1': 0.27556, 'auc': 0.7368}
2025-08-17 06:45:17,146 - INFO - > Epoch 87: took 74.8s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:46:23,877 - INFO - train: {'epoch': 88, 'time_epoch': 66.64491, 'eta': 740.37447, 'eta_hours': 0.20566, 'loss': 0.07068225, 'lr': 3.89e-06, 'params': 514193, 'time_iter': 0.06477, 'accuracy': 0.97878, 'precision': 0.82403, 'recall': 0.55114, 'f1': 0.66051, 'auc': 0.96091}
2025-08-17 06:46:28,318 - INFO - val: {'epoch': 88, 'time_epoch': 4.41396, 'loss': 0.1004593, 'lr': 0, 'params': 514193, 'time_iter': 0.03422, 'accuracy': 0.97471, 'precision': 0.36145, 'recall': 0.37037, 'f1': 0.36585, 'auc': 0.80946}
2025-08-17 06:46:32,592 - INFO - test: {'epoch': 88, 'time_epoch': 4.25556, 'loss': 0.17613973, 'lr': 0, 'params': 514193, 'time_iter': 0.03299, 'accuracy': 0.96159, 'precision': 0.33721, 'recall': 0.22308, 'f1': 0.26852, 'auc': 0.73279}
2025-08-17 06:46:32,595 - INFO - > Epoch 88: took 75.4s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:47:39,393 - INFO - train: {'epoch': 89, 'time_epoch': 66.72153, 'eta': 673.00267, 'eta_hours': 0.18695, 'loss': 0.06904251, 'lr': 3.27e-06, 'params': 514193, 'time_iter': 0.06484, 'accuracy': 0.97875, 'precision': 0.83438, 'recall': 0.53977, 'f1': 0.6555, 'auc': 0.96445}
2025-08-17 06:47:43,682 - INFO - val: {'epoch': 89, 'time_epoch': 4.26738, 'loss': 0.10303175, 'lr': 0, 'params': 514193, 'time_iter': 0.03308, 'accuracy': 0.97374, 'precision': 0.34483, 'recall': 0.37037, 'f1': 0.35714, 'auc': 0.80715}
2025-08-17 06:47:47,831 - INFO - test: {'epoch': 89, 'time_epoch': 4.13286, 'loss': 0.1799213, 'lr': 0, 'params': 514193, 'time_iter': 0.03204, 'accuracy': 0.95818, 'precision': 0.30909, 'recall': 0.26154, 'f1': 0.28333, 'auc': 0.73648}
2025-08-17 06:47:47,833 - INFO - > Epoch 89: took 75.2s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:48:53,550 - INFO - train: {'epoch': 90, 'time_epoch': 65.63844, 'eta': 605.53805, 'eta_hours': 0.16821, 'loss': 0.07071138, 'lr': 2.71e-06, 'params': 514193, 'time_iter': 0.06379, 'accuracy': 0.97839, 'precision': 0.81807, 'recall': 0.54383, 'f1': 0.65334, 'auc': 0.96191}
2025-08-17 06:48:57,778 - INFO - val: {'epoch': 90, 'time_epoch': 4.2074, 'loss': 0.09804125, 'lr': 0, 'params': 514193, 'time_iter': 0.03262, 'accuracy': 0.97593, 'precision': 0.38158, 'recall': 0.35802, 'f1': 0.36943, 'auc': 0.80571}
2025-08-17 06:49:01,941 - INFO - test: {'epoch': 90, 'time_epoch': 4.14607, 'loss': 0.17194113, 'lr': 0, 'params': 514193, 'time_iter': 0.03214, 'accuracy': 0.96377, 'precision': 0.37662, 'recall': 0.22308, 'f1': 0.28019, 'auc': 0.73384}
2025-08-17 06:49:01,944 - INFO - > Epoch 90: took 74.1s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:50:07,392 - INFO - train: {'epoch': 91, 'time_epoch': 65.37701, 'eta': 538.09039, 'eta_hours': 0.14947, 'loss': 0.06765907, 'lr': 2.2e-06, 'params': 514193, 'time_iter': 0.06353, 'accuracy': 0.97833, 'precision': 0.82642, 'recall': 0.53328, 'f1': 0.64825, 'auc': 0.96704}
2025-08-17 06:50:11,596 - INFO - val: {'epoch': 91, 'time_epoch': 4.18367, 'loss': 0.10329439, 'lr': 0, 'params': 514193, 'time_iter': 0.03243, 'accuracy': 0.97374, 'precision': 0.34483, 'recall': 0.37037, 'f1': 0.35714, 'auc': 0.8106}
2025-08-17 06:50:15,729 - INFO - test: {'epoch': 91, 'time_epoch': 4.11619, 'loss': 0.17773292, 'lr': 0, 'params': 514193, 'time_iter': 0.03191, 'accuracy': 0.9594, 'precision': 0.32381, 'recall': 0.26154, 'f1': 0.28936, 'auc': 0.74021}
2025-08-17 06:50:15,733 - INFO - > Epoch 91: took 73.8s (avg 75.9s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:51:21,851 - INFO - train: {'epoch': 92, 'time_epoch': 66.02978, 'eta': 470.7364, 'eta_hours': 0.13076, 'loss': 0.06919436, 'lr': 1.74e-06, 'params': 514193, 'time_iter': 0.06417, 'accuracy': 0.97812, 'precision': 0.81144, 'recall': 0.5414, 'f1': 0.64946, 'auc': 0.96433}
2025-08-17 06:51:26,217 - INFO - val: {'epoch': 92, 'time_epoch': 4.34185, 'loss': 0.10280724, 'lr': 0, 'params': 514193, 'time_iter': 0.03366, 'accuracy': 0.97496, 'precision': 0.36585, 'recall': 0.37037, 'f1': 0.3681, 'auc': 0.80693}
2025-08-17 06:51:30,487 - INFO - test: {'epoch': 92, 'time_epoch': 4.24979, 'loss': 0.17782856, 'lr': 0, 'params': 514193, 'time_iter': 0.03294, 'accuracy': 0.95915, 'precision': 0.31, 'recall': 0.23846, 'f1': 0.26957, 'auc': 0.73969}
2025-08-17 06:51:30,490 - INFO - > Epoch 92: took 74.8s (avg 75.9s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:52:36,470 - INFO - train: {'epoch': 93, 'time_epoch': 65.90366, 'eta': 403.40253, 'eta_hours': 0.11206, 'loss': 0.06801125, 'lr': 1.33e-06, 'params': 514193, 'time_iter': 0.06405, 'accuracy': 0.97863, 'precision': 0.82295, 'recall': 0.54708, 'f1': 0.65724, 'auc': 0.96585}
2025-08-17 06:52:40,705 - INFO - val: {'epoch': 93, 'time_epoch': 4.20947, 'loss': 0.10309745, 'lr': 0, 'params': 514193, 'time_iter': 0.03263, 'accuracy': 0.97301, 'precision': 0.33333, 'recall': 0.37037, 'f1': 0.35088, 'auc': 0.80679}
2025-08-17 06:52:44,876 - INFO - test: {'epoch': 93, 'time_epoch': 4.15294, 'loss': 0.1752267, 'lr': 0, 'params': 514193, 'time_iter': 0.03219, 'accuracy': 0.95915, 'precision': 0.31731, 'recall': 0.25385, 'f1': 0.28205, 'auc': 0.74384}
2025-08-17 06:52:44,879 - INFO - > Epoch 93: took 74.4s (avg 75.9s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:53:50,985 - INFO - train: {'epoch': 94, 'time_epoch': 66.01952, 'eta': 336.10487, 'eta_hours': 0.09336, 'loss': 0.06635964, 'lr': 9.8e-07, 'params': 514193, 'time_iter': 0.06416, 'accuracy': 0.97897, 'precision': 0.82374, 'recall': 0.55763, 'f1': 0.66505, 'auc': 0.96822}
2025-08-17 06:53:55,376 - INFO - val: {'epoch': 94, 'time_epoch': 4.3664, 'loss': 0.10638291, 'lr': 0, 'params': 514193, 'time_iter': 0.03385, 'accuracy': 0.97544, 'precision': 0.375, 'recall': 0.37037, 'f1': 0.37267, 'auc': 0.80493}
2025-08-17 06:53:59,639 - INFO - test: {'epoch': 94, 'time_epoch': 4.24629, 'loss': 0.18441322, 'lr': 0, 'params': 514193, 'time_iter': 0.03292, 'accuracy': 0.95891, 'precision': 0.30693, 'recall': 0.23846, 'f1': 0.2684, 'auc': 0.73091}
2025-08-17 06:53:59,642 - INFO - > Epoch 94: took 74.8s (avg 75.9s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:55:10,218 - INFO - train: {'epoch': 95, 'time_epoch': 70.48655, 'eta': 269.01996, 'eta_hours': 0.07473, 'loss': 0.06739647, 'lr': 6.8e-07, 'params': 514193, 'time_iter': 0.0685, 'accuracy': 0.97882, 'precision': 0.81959, 'recall': 0.55682, 'f1': 0.66312, 'auc': 0.96826}
2025-08-17 06:55:14,540 - INFO - val: {'epoch': 95, 'time_epoch': 4.29828, 'loss': 0.10559533, 'lr': 0, 'params': 514193, 'time_iter': 0.03332, 'accuracy': 0.97301, 'precision': 0.33333, 'recall': 0.37037, 'f1': 0.35088, 'auc': 0.80331}
2025-08-17 06:55:18,709 - INFO - test: {'epoch': 95, 'time_epoch': 4.15141, 'loss': 0.18111278, 'lr': 0, 'params': 514193, 'time_iter': 0.03218, 'accuracy': 0.95721, 'precision': 0.29464, 'recall': 0.25385, 'f1': 0.27273, 'auc': 0.73639}
2025-08-17 06:55:18,712 - INFO - > Epoch 95: took 79.1s (avg 75.9s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:56:29,978 - INFO - train: {'epoch': 96, 'time_epoch': 71.17824, 'eta': 201.88631, 'eta_hours': 0.05608, 'loss': 0.06751102, 'lr': 4.4e-07, 'params': 514193, 'time_iter': 0.06917, 'accuracy': 0.97891, 'precision': 0.81647, 'recall': 0.56331, 'f1': 0.66667, 'auc': 0.96815}
2025-08-17 06:56:34,103 - INFO - val: {'epoch': 96, 'time_epoch': 4.10256, 'loss': 0.11336695, 'lr': 0, 'params': 514193, 'time_iter': 0.0318, 'accuracy': 0.97155, 'precision': 0.3125, 'recall': 0.37037, 'f1': 0.33898, 'auc': 0.80083}
2025-08-17 06:56:38,240 - INFO - test: {'epoch': 96, 'time_epoch': 4.11759, 'loss': 0.18768409, 'lr': 0, 'params': 514193, 'time_iter': 0.03192, 'accuracy': 0.95502, 'precision': 0.26891, 'recall': 0.24615, 'f1': 0.25703, 'auc': 0.74033}
2025-08-17 06:56:38,243 - INFO - > Epoch 96: took 79.5s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:57:45,727 - INFO - train: {'epoch': 97, 'time_epoch': 67.40238, 'eta': 134.59305, 'eta_hours': 0.03739, 'loss': 0.06809735, 'lr': 2.5e-07, 'params': 514193, 'time_iter': 0.0655, 'accuracy': 0.97857, 'precision': 0.82252, 'recall': 0.54545, 'f1': 0.65593, 'auc': 0.96715}
2025-08-17 06:57:50,031 - INFO - val: {'epoch': 97, 'time_epoch': 4.28311, 'loss': 0.10642714, 'lr': 0, 'params': 514193, 'time_iter': 0.0332, 'accuracy': 0.9735, 'precision': 0.34091, 'recall': 0.37037, 'f1': 0.35503, 'auc': 0.80457}
2025-08-17 06:57:54,238 - INFO - test: {'epoch': 97, 'time_epoch': 4.19012, 'loss': 0.18041954, 'lr': 0, 'params': 514193, 'time_iter': 0.03248, 'accuracy': 0.95891, 'precision': 0.31429, 'recall': 0.25385, 'f1': 0.28085, 'auc': 0.73381}
2025-08-17 06:57:54,240 - INFO - > Epoch 97: took 76.0s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 06:58:59,724 - INFO - train: {'epoch': 98, 'time_epoch': 65.40199, 'eta': 67.27739, 'eta_hours': 0.01869, 'loss': 0.06801254, 'lr': 1.1e-07, 'params': 514193, 'time_iter': 0.06356, 'accuracy': 0.97851, 'precision': 0.82051, 'recall': 0.54545, 'f1': 0.65529, 'auc': 0.96613}
2025-08-17 06:59:04,064 - INFO - val: {'epoch': 98, 'time_epoch': 4.31942, 'loss': 0.10435966, 'lr': 0, 'params': 514193, 'time_iter': 0.03348, 'accuracy': 0.97496, 'precision': 0.36585, 'recall': 0.37037, 'f1': 0.3681, 'auc': 0.80404}
2025-08-17 06:59:08,249 - INFO - test: {'epoch': 98, 'time_epoch': 4.16723, 'loss': 0.17831882, 'lr': 0, 'params': 514193, 'time_iter': 0.0323, 'accuracy': 0.95915, 'precision': 0.31731, 'recall': 0.25385, 'f1': 0.28205, 'auc': 0.74018}
2025-08-17 06:59:08,251 - INFO - > Epoch 98: took 74.0s (avg 76.0s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 07:00:14,207 - INFO - train: {'epoch': 99, 'time_epoch': 65.8765, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.06777956, 'lr': 3e-08, 'params': 514193, 'time_iter': 0.06402, 'accuracy': 0.97872, 'precision': 0.81894, 'recall': 0.55438, 'f1': 0.66118, 'auc': 0.9643}
2025-08-17 07:00:18,478 - INFO - val: {'epoch': 99, 'time_epoch': 4.25104, 'loss': 0.10179664, 'lr': 0, 'params': 514193, 'time_iter': 0.03295, 'accuracy': 0.97593, 'precision': 0.38462, 'recall': 0.37037, 'f1': 0.37736, 'auc': 0.80908}
2025-08-17 07:00:22,633 - INFO - test: {'epoch': 99, 'time_epoch': 4.13835, 'loss': 0.18223473, 'lr': 0, 'params': 514193, 'time_iter': 0.03208, 'accuracy': 0.96061, 'precision': 0.32979, 'recall': 0.23846, 'f1': 0.27679, 'auc': 0.73733}
2025-08-17 07:00:22,840 - INFO - > Epoch 99: took 74.4s (avg 75.9s) | Best so far: epoch 46	train_loss: 0.0907 train_auc: 0.9179	val_loss: 0.0819 val_auc: 0.8238	test_loss: 0.1355 test_auc: 0.7622
2025-08-17 07:00:22,841 - INFO - Avg time per epoch: 75.94s
2025-08-17 07:00:22,841 - INFO - Total train loop time: 2.11h
2025-08-17 07:00:22,936 - INFO - ============================================================
2025-08-17 07:00:22,937 - INFO - Starting PK-Explainer Analysis (Enhanced Version)
2025-08-17 07:00:22,937 - INFO - ============================================================
2025-08-17 07:00:22,937 - INFO - Dataset: ogbg-molhiv
2025-08-17 07:00:22,937 - INFO - Model type: VanillaModel
2025-08-17 07:00:22,937 - INFO - GNN types available: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-17 07:00:23,033 - INFO - Saved model state to results/molhiv/molhiv-Vanilla-47/model_for_ablation.pt
2025-08-17 07:00:23,033 - INFO - 
Performing ablation study...
2025-08-17 07:00:23,077 - INFO - Getting baseline performance...
2025-08-17 07:00:23,107 - WARNING - Could not extract GNN mapping from optimal weights, attempting to infer from layers...
2025-08-17 07:00:23,107 - INFO - Final GNN mapping: {}
2025-08-17 07:00:27,259 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.1374, 'loss': 0.18223473, 'lr': 0, 'params': 514193, 'time_iter': 0.03207, 'accuracy': 0.96061, 'precision': 0.32979, 'recall': 0.23846, 'f1': 0.27679, 'auc': 0.73733}
2025-08-17 07:00:27,261 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:00:27,261 - INFO - Baseline auc: 0.7373
2025-08-17 07:00:31,439 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.13306, 'loss': 0.18194885, 'lr': 0, 'params': 514193, 'time_iter': 0.03204, 'accuracy': 0.95867, 'precision': 0.30769, 'recall': 0.24615, 'f1': 0.2735, 'auc': 0.74123}
2025-08-17 07:00:31,454 - INFO - ...computing epoch stats took: 0.03s
2025-08-17 07:00:31,455 - INFO - Layer 0 (Layer_0), Head 0: drop=-0.0053
2025-08-17 07:00:35,656 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.14056, 'loss': 0.18521555, 'lr': 0, 'params': 514193, 'time_iter': 0.0321, 'accuracy': 0.96159, 'precision': 0.33721, 'recall': 0.22308, 'f1': 0.26852, 'auc': 0.71802}
2025-08-17 07:00:35,658 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:00:35,658 - INFO - Layer 0 (Layer_0), Head 1: drop=0.0262
2025-08-17 07:00:39,828 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.12546, 'loss': 0.18815743, 'lr': 0, 'params': 514193, 'time_iter': 0.03198, 'accuracy': 0.96086, 'precision': 0.32584, 'recall': 0.22308, 'f1': 0.26484, 'auc': 0.732}
2025-08-17 07:00:39,830 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:00:39,830 - INFO - Layer 0 (Layer_0), Head 2: drop=0.0072
2025-08-17 07:00:44,069 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.19459, 'loss': 0.18424106, 'lr': 0, 'params': 514193, 'time_iter': 0.03252, 'accuracy': 0.96086, 'precision': 0.34021, 'recall': 0.25385, 'f1': 0.29075, 'auc': 0.74256}
2025-08-17 07:00:44,071 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:00:44,072 - INFO - Layer 0 (Layer_0), Head 3: drop=-0.0071
2025-08-17 07:00:48,438 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.31918, 'loss': 0.18152979, 'lr': 0, 'params': 514193, 'time_iter': 0.03348, 'accuracy': 0.95867, 'precision': 0.31132, 'recall': 0.25385, 'f1': 0.27966, 'auc': 0.73071}
2025-08-17 07:00:48,440 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:00:48,440 - INFO - Layer 1 (Layer_1), Head 0: drop=0.0090
2025-08-17 07:00:52,886 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.39827, 'loss': 0.17854333, 'lr': 0, 'params': 514193, 'time_iter': 0.0341, 'accuracy': 0.96231, 'precision': 0.36559, 'recall': 0.26154, 'f1': 0.30493, 'auc': 0.74479}
2025-08-17 07:00:52,888 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:00:52,888 - INFO - Layer 1 (Layer_1), Head 1: drop=-0.0101
2025-08-17 07:00:57,320 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.38505, 'loss': 0.18063173, 'lr': 0, 'params': 514193, 'time_iter': 0.03399, 'accuracy': 0.9611, 'precision': 0.33696, 'recall': 0.23846, 'f1': 0.27928, 'auc': 0.73322}
2025-08-17 07:00:57,322 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:00:57,323 - INFO - Layer 1 (Layer_1), Head 2: drop=0.0056
2025-08-17 07:01:01,709 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33922, 'loss': 0.18316646, 'lr': 0, 'params': 514193, 'time_iter': 0.03364, 'accuracy': 0.9611, 'precision': 0.35, 'recall': 0.26923, 'f1': 0.30435, 'auc': 0.74044}
2025-08-17 07:01:01,711 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:01:01,711 - INFO - Layer 1 (Layer_1), Head 3: drop=-0.0042
2025-08-17 07:01:06,081 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32251, 'loss': 0.18170701, 'lr': 0, 'params': 514193, 'time_iter': 0.03351, 'accuracy': 0.96037, 'precision': 0.33981, 'recall': 0.26923, 'f1': 0.30043, 'auc': 0.73919}
2025-08-17 07:01:06,083 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:01:06,083 - INFO - Layer 2 (Layer_2), Head 0: drop=-0.0025
2025-08-17 07:01:10,485 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35543, 'loss': 0.18455093, 'lr': 0, 'params': 514193, 'time_iter': 0.03376, 'accuracy': 0.95648, 'precision': 0.28696, 'recall': 0.25385, 'f1': 0.26939, 'auc': 0.73057}
2025-08-17 07:01:10,487 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:01:10,487 - INFO - Layer 2 (Layer_2), Head 1: drop=0.0092
2025-08-17 07:01:14,935 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40078, 'loss': 0.18391679, 'lr': 0, 'params': 514193, 'time_iter': 0.03411, 'accuracy': 0.96304, 'precision': 0.37209, 'recall': 0.24615, 'f1': 0.2963, 'auc': 0.73935}
2025-08-17 07:01:14,937 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:01:14,937 - INFO - Layer 2 (Layer_2), Head 2: drop=-0.0027
2025-08-17 07:01:19,340 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35586, 'loss': 0.17945935, 'lr': 0, 'params': 514193, 'time_iter': 0.03377, 'accuracy': 0.9594, 'precision': 0.3271, 'recall': 0.26923, 'f1': 0.29536, 'auc': 0.74268}
2025-08-17 07:01:19,342 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:01:19,342 - INFO - Layer 2 (Layer_2), Head 3: drop=-0.0073
2025-08-17 07:01:23,729 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34033, 'loss': 0.18288741, 'lr': 0, 'params': 514193, 'time_iter': 0.03365, 'accuracy': 0.95332, 'precision': 0.28169, 'recall': 0.30769, 'f1': 0.29412, 'auc': 0.73568}
2025-08-17 07:01:23,731 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:01:23,732 - INFO - Layer 3 (Layer_3), Head 0: drop=0.0022
2025-08-17 07:01:28,098 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3195, 'loss': 0.18224554, 'lr': 0, 'params': 514193, 'time_iter': 0.03348, 'accuracy': 0.96134, 'precision': 0.35354, 'recall': 0.26923, 'f1': 0.30568, 'auc': 0.74626}
2025-08-17 07:01:28,100 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:01:28,100 - INFO - Layer 3 (Layer_3), Head 1: drop=-0.0121
2025-08-17 07:01:32,481 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33365, 'loss': 0.17398233, 'lr': 0, 'params': 514193, 'time_iter': 0.03359, 'accuracy': 0.96086, 'precision': 0.32967, 'recall': 0.23077, 'f1': 0.27149, 'auc': 0.74575}
2025-08-17 07:01:32,483 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:01:32,483 - INFO - Layer 3 (Layer_3), Head 2: drop=-0.0114
2025-08-17 07:01:36,916 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.38621, 'loss': 0.18754446, 'lr': 0, 'params': 514193, 'time_iter': 0.034, 'accuracy': 0.95672, 'precision': 0.29661, 'recall': 0.26923, 'f1': 0.28226, 'auc': 0.72165}
2025-08-17 07:01:36,917 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:01:36,918 - INFO - Layer 3 (Layer_3), Head 3: drop=0.0213
2025-08-17 07:01:41,343 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.37887, 'loss': 0.18896172, 'lr': 0, 'params': 514193, 'time_iter': 0.03394, 'accuracy': 0.95502, 'precision': 0.24299, 'recall': 0.2, 'f1': 0.21941, 'auc': 0.73034}
2025-08-17 07:01:41,345 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:01:41,345 - INFO - Layer 4 (Layer_4), Head 0: drop=0.0095
2025-08-17 07:01:45,719 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32688, 'loss': 0.19315793, 'lr': 0, 'params': 514193, 'time_iter': 0.03354, 'accuracy': 0.9577, 'precision': 0.28, 'recall': 0.21538, 'f1': 0.24348, 'auc': 0.72183}
2025-08-17 07:01:45,721 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:01:45,721 - INFO - Layer 4 (Layer_4), Head 1: drop=0.0210
2025-08-17 07:01:50,034 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26771, 'loss': 0.17559427, 'lr': 0, 'params': 514193, 'time_iter': 0.03308, 'accuracy': 0.96304, 'precision': 0.38298, 'recall': 0.27692, 'f1': 0.32143, 'auc': 0.74094}
2025-08-17 07:01:50,036 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:01:50,037 - INFO - Layer 4 (Layer_4), Head 2: drop=-0.0049
2025-08-17 07:01:54,370 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.28746, 'loss': 0.18428075, 'lr': 0, 'params': 514193, 'time_iter': 0.03324, 'accuracy': 0.95648, 'precision': 0.26214, 'recall': 0.20769, 'f1': 0.23176, 'auc': 0.72032}
2025-08-17 07:01:54,372 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:01:54,372 - INFO - Layer 4 (Layer_4), Head 3: drop=0.0231
2025-08-17 07:01:58,689 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27017, 'loss': 0.17533386, 'lr': 0, 'params': 514193, 'time_iter': 0.0331, 'accuracy': 0.9611, 'precision': 0.32558, 'recall': 0.21538, 'f1': 0.25926, 'auc': 0.74529}
2025-08-17 07:01:58,691 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:01:58,691 - INFO - Layer 5 (Layer_5), Head 0: drop=-0.0108
2025-08-17 07:02:02,992 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25453, 'loss': 0.17681353, 'lr': 0, 'params': 514193, 'time_iter': 0.03298, 'accuracy': 0.96159, 'precision': 0.34444, 'recall': 0.23846, 'f1': 0.28182, 'auc': 0.73464}
2025-08-17 07:02:02,994 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:02:02,994 - INFO - Layer 5 (Layer_5), Head 1: drop=0.0036
2025-08-17 07:02:07,331 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29112, 'loss': 0.17640952, 'lr': 0, 'params': 514193, 'time_iter': 0.03326, 'accuracy': 0.96475, 'precision': 0.39726, 'recall': 0.22308, 'f1': 0.28571, 'auc': 0.74181}
2025-08-17 07:02:07,333 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:02:07,333 - INFO - Layer 5 (Layer_5), Head 2: drop=-0.0061
2025-08-17 07:02:11,604 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22616, 'loss': 0.18069531, 'lr': 0, 'params': 514193, 'time_iter': 0.03276, 'accuracy': 0.96304, 'precision': 0.37209, 'recall': 0.24615, 'f1': 0.2963, 'auc': 0.74326}
2025-08-17 07:02:11,607 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:02:11,607 - INFO - Layer 5 (Layer_5), Head 3: drop=-0.0080
2025-08-17 07:02:15,908 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25693, 'loss': 0.18163944, 'lr': 0, 'params': 514193, 'time_iter': 0.033, 'accuracy': 0.96183, 'precision': 0.34483, 'recall': 0.23077, 'f1': 0.2765, 'auc': 0.74997}
2025-08-17 07:02:15,911 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:02:15,911 - INFO - Layer 6 (Layer_6), Head 0: drop=-0.0171
2025-08-17 07:02:20,165 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.20842, 'loss': 0.17743299, 'lr': 0, 'params': 514193, 'time_iter': 0.03262, 'accuracy': 0.96329, 'precision': 0.36364, 'recall': 0.21538, 'f1': 0.27053, 'auc': 0.74031}
2025-08-17 07:02:20,167 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:02:20,167 - INFO - Layer 6 (Layer_6), Head 1: drop=-0.0040
2025-08-17 07:02:24,397 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.18432, 'loss': 0.1767033, 'lr': 0, 'params': 514193, 'time_iter': 0.03244, 'accuracy': 0.96256, 'precision': 0.36047, 'recall': 0.23846, 'f1': 0.28704, 'auc': 0.72952}
2025-08-17 07:02:24,399 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:02:24,400 - INFO - Layer 6 (Layer_6), Head 2: drop=0.0106
2025-08-17 07:02:28,601 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.15603, 'loss': 0.18653943, 'lr': 0, 'params': 514193, 'time_iter': 0.03222, 'accuracy': 0.94797, 'precision': 0.23077, 'recall': 0.27692, 'f1': 0.25175, 'auc': 0.75946}
2025-08-17 07:02:28,603 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:02:28,603 - INFO - Layer 6 (Layer_6), Head 3: drop=-0.0300
2025-08-17 07:02:32,825 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.17785, 'loss': 0.17025367, 'lr': 0, 'params': 514193, 'time_iter': 0.03239, 'accuracy': 0.96548, 'precision': 0.42105, 'recall': 0.24615, 'f1': 0.31068, 'auc': 0.73625}
2025-08-17 07:02:32,827 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:02:32,827 - INFO - Layer 7 (Layer_7), Head 0: drop=0.0015
2025-08-17 07:02:37,053 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.1815, 'loss': 0.17631322, 'lr': 0, 'params': 514193, 'time_iter': 0.03241, 'accuracy': 0.96183, 'precision': 0.34831, 'recall': 0.23846, 'f1': 0.28311, 'auc': 0.74346}
2025-08-17 07:02:37,055 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:02:37,056 - INFO - Layer 7 (Layer_7), Head 1: drop=-0.0083
2025-08-17 07:02:41,289 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.18871, 'loss': 0.17823097, 'lr': 0, 'params': 514193, 'time_iter': 0.03247, 'accuracy': 0.96329, 'precision': 0.37349, 'recall': 0.23846, 'f1': 0.29108, 'auc': 0.72455}
2025-08-17 07:02:41,290 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:02:41,291 - INFO - Layer 7 (Layer_7), Head 2: drop=0.0173
2025-08-17 07:02:45,511 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.17658, 'loss': 0.17943461, 'lr': 0, 'params': 514193, 'time_iter': 0.03238, 'accuracy': 0.96183, 'precision': 0.34483, 'recall': 0.23077, 'f1': 0.2765, 'auc': 0.74461}
2025-08-17 07:02:45,513 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:02:45,513 - INFO - Layer 7 (Layer_7), Head 3: drop=-0.0099
2025-08-17 07:02:49,720 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.1619, 'loss': 0.16938687, 'lr': 0, 'params': 514193, 'time_iter': 0.03226, 'accuracy': 0.96256, 'precision': 0.36047, 'recall': 0.23846, 'f1': 0.28704, 'auc': 0.74665}
2025-08-17 07:02:49,722 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:02:49,722 - INFO - Layer 8 (Layer_8), Head 0: drop=-0.0126
2025-08-17 07:02:53,933 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.16695, 'loss': 0.18153095, 'lr': 0, 'params': 514193, 'time_iter': 0.0323, 'accuracy': 0.95964, 'precision': 0.32353, 'recall': 0.25385, 'f1': 0.28448, 'auc': 0.72986}
2025-08-17 07:02:53,935 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:02:53,936 - INFO - Layer 8 (Layer_8), Head 1: drop=0.0101
2025-08-17 07:02:58,133 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.15304, 'loss': 0.17815193, 'lr': 0, 'params': 514193, 'time_iter': 0.03219, 'accuracy': 0.96377, 'precision': 0.37975, 'recall': 0.23077, 'f1': 0.28708, 'auc': 0.73614}
2025-08-17 07:02:58,135 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:02:58,135 - INFO - Layer 8 (Layer_8), Head 2: drop=0.0016
2025-08-17 07:03:02,344 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.16411, 'loss': 0.17657328, 'lr': 0, 'params': 514193, 'time_iter': 0.03228, 'accuracy': 0.96329, 'precision': 0.37647, 'recall': 0.24615, 'f1': 0.29767, 'auc': 0.74136}
2025-08-17 07:03:02,346 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:03:02,346 - INFO - Layer 8 (Layer_8), Head 3: drop=-0.0055
2025-08-17 07:03:06,566 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.17514, 'loss': 0.1749911, 'lr': 0, 'params': 514193, 'time_iter': 0.03237, 'accuracy': 0.96256, 'precision': 0.35714, 'recall': 0.23077, 'f1': 0.28037, 'auc': 0.74259}
2025-08-17 07:03:06,568 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:03:06,568 - INFO - Layer 9 (Layer_9), Head 0: drop=-0.0071
2025-08-17 07:03:10,751 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.13529, 'loss': 0.17867686, 'lr': 0, 'params': 514193, 'time_iter': 0.03206, 'accuracy': 0.96377, 'precision': 0.37975, 'recall': 0.23077, 'f1': 0.28708, 'auc': 0.73001}
2025-08-17 07:03:10,753 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:03:10,754 - INFO - Layer 9 (Layer_9), Head 1: drop=0.0099
2025-08-17 07:03:15,029 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22896, 'loss': 0.17943109, 'lr': 0, 'params': 514193, 'time_iter': 0.03278, 'accuracy': 0.9611, 'precision': 0.33696, 'recall': 0.23846, 'f1': 0.27928, 'auc': 0.73879}
2025-08-17 07:03:15,031 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:03:15,032 - INFO - Layer 9 (Layer_9), Head 2: drop=-0.0020
2025-08-17 07:03:19,178 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.10239, 'loss': 0.18102577, 'lr': 0, 'params': 514193, 'time_iter': 0.0318, 'accuracy': 0.96086, 'precision': 0.33333, 'recall': 0.23846, 'f1': 0.27803, 'auc': 0.73318}
2025-08-17 07:03:19,181 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:03:19,181 - INFO - Layer 9 (Layer_9), Head 3: drop=0.0056
2025-08-17 07:03:23,348 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.12238, 'loss': 0.17955561, 'lr': 0, 'params': 514193, 'time_iter': 0.03196, 'accuracy': 0.96134, 'precision': 0.34409, 'recall': 0.24615, 'f1': 0.287, 'auc': 0.73999}
2025-08-17 07:03:23,350 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:03:23,351 - INFO - Layer 10 (Layer_10), Head 0: drop=-0.0036
2025-08-17 07:03:27,499 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.10412, 'loss': 0.17479552, 'lr': 0, 'params': 514193, 'time_iter': 0.03181, 'accuracy': 0.96256, 'precision': 0.35366, 'recall': 0.22308, 'f1': 0.27358, 'auc': 0.73747}
2025-08-17 07:03:27,501 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:03:27,501 - INFO - Layer 10 (Layer_10), Head 1: drop=-0.0002
2025-08-17 07:03:31,622 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.07719, 'loss': 0.17781326, 'lr': 0, 'params': 514193, 'time_iter': 0.03161, 'accuracy': 0.96207, 'precision': 0.34524, 'recall': 0.22308, 'f1': 0.27103, 'auc': 0.73634}
2025-08-17 07:03:31,624 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:03:31,624 - INFO - Layer 10 (Layer_10), Head 2: drop=0.0013
2025-08-17 07:03:35,748 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.08005, 'loss': 0.17988552, 'lr': 0, 'params': 514193, 'time_iter': 0.03163, 'accuracy': 0.96086, 'precision': 0.33333, 'recall': 0.23846, 'f1': 0.27803, 'auc': 0.73657}
2025-08-17 07:03:35,751 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:03:35,751 - INFO - Layer 10 (Layer_10), Head 3: drop=0.0010
2025-08-17 07:03:39,883 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.08792, 'loss': 0.18079304, 'lr': 0, 'params': 514193, 'time_iter': 0.03169, 'accuracy': 0.96207, 'precision': 0.34884, 'recall': 0.23077, 'f1': 0.27778, 'auc': 0.73609}
2025-08-17 07:03:39,885 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:03:39,885 - INFO - Layer 11 (Layer_11), Head 0: drop=0.0017
2025-08-17 07:03:44,064 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.1341, 'loss': 0.18391948, 'lr': 0, 'params': 514193, 'time_iter': 0.03205, 'accuracy': 0.95964, 'precision': 0.31633, 'recall': 0.23846, 'f1': 0.27193, 'auc': 0.73532}
2025-08-17 07:03:44,066 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:03:44,066 - INFO - Layer 11 (Layer_11), Head 1: drop=0.0027
2025-08-17 07:03:48,350 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2384, 'loss': 0.17764659, 'lr': 0, 'params': 514193, 'time_iter': 0.03286, 'accuracy': 0.96304, 'precision': 0.3625, 'recall': 0.22308, 'f1': 0.27619, 'auc': 0.73976}
2025-08-17 07:03:48,353 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:03:48,353 - INFO - Layer 11 (Layer_11), Head 2: drop=-0.0033
2025-08-17 07:03:52,601 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.20192, 'loss': 0.18143992, 'lr': 0, 'params': 514193, 'time_iter': 0.03257, 'accuracy': 0.96086, 'precision': 0.33333, 'recall': 0.23846, 'f1': 0.27803, 'auc': 0.73512}
2025-08-17 07:03:52,603 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:03:52,603 - INFO - Layer 11 (Layer_11), Head 3: drop=0.0030
2025-08-17 07:03:56,899 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25075, 'loss': 0.17590653, 'lr': 0, 'params': 514193, 'time_iter': 0.03295, 'accuracy': 0.9628, 'precision': 0.35802, 'recall': 0.22308, 'f1': 0.27488, 'auc': 0.73941}
2025-08-17 07:03:56,901 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:03:56,901 - INFO - Layer 12 (Layer_12), Head 0: drop=-0.0028
2025-08-17 07:04:01,180 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23249, 'loss': 0.17988261, 'lr': 0, 'params': 514193, 'time_iter': 0.03281, 'accuracy': 0.96304, 'precision': 0.36585, 'recall': 0.23077, 'f1': 0.28302, 'auc': 0.73533}
2025-08-17 07:04:01,182 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:04:01,182 - INFO - Layer 12 (Layer_12), Head 1: drop=0.0027
2025-08-17 07:04:05,449 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22057, 'loss': 0.18065519, 'lr': 0, 'params': 514193, 'time_iter': 0.03272, 'accuracy': 0.9611, 'precision': 0.33333, 'recall': 0.23077, 'f1': 0.27273, 'auc': 0.73738}
2025-08-17 07:04:05,451 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:04:05,451 - INFO - Layer 12 (Layer_12), Head 2: drop=-0.0001
2025-08-17 07:04:09,715 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21765, 'loss': 0.18120215, 'lr': 0, 'params': 514193, 'time_iter': 0.03269, 'accuracy': 0.96231, 'precision': 0.35632, 'recall': 0.23846, 'f1': 0.28571, 'auc': 0.73393}
2025-08-17 07:04:09,717 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:04:09,717 - INFO - Layer 12 (Layer_12), Head 3: drop=0.0046
2025-08-17 07:04:14,011 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24807, 'loss': 0.17815281, 'lr': 0, 'params': 514193, 'time_iter': 0.03293, 'accuracy': 0.96061, 'precision': 0.33333, 'recall': 0.24615, 'f1': 0.28319, 'auc': 0.7391}
2025-08-17 07:04:14,014 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:04:14,014 - INFO - Layer 13 (Layer_13), Head 0: drop=-0.0024
2025-08-17 07:04:18,280 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22007, 'loss': 0.17701972, 'lr': 0, 'params': 514193, 'time_iter': 0.03271, 'accuracy': 0.9628, 'precision': 0.35802, 'recall': 0.22308, 'f1': 0.27488, 'auc': 0.73812}
2025-08-17 07:04:18,282 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:04:18,282 - INFO - Layer 13 (Layer_13), Head 1: drop=-0.0011
2025-08-17 07:04:22,556 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22828, 'loss': 0.17867707, 'lr': 0, 'params': 514193, 'time_iter': 0.03278, 'accuracy': 0.96256, 'precision': 0.36047, 'recall': 0.23846, 'f1': 0.28704, 'auc': 0.73516}
2025-08-17 07:04:22,559 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:04:22,560 - INFO - Layer 13 (Layer_13), Head 2: drop=0.0029
2025-08-17 07:04:26,802 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.19693, 'loss': 0.17620785, 'lr': 0, 'params': 514193, 'time_iter': 0.03253, 'accuracy': 0.96183, 'precision': 0.34831, 'recall': 0.23846, 'f1': 0.28311, 'auc': 0.73735}
2025-08-17 07:04:26,804 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:04:26,804 - INFO - Layer 13 (Layer_13), Head 3: drop=-0.0000
2025-08-17 07:04:31,058 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.20826, 'loss': 0.17334234, 'lr': 0, 'params': 514193, 'time_iter': 0.03262, 'accuracy': 0.96304, 'precision': 0.3625, 'recall': 0.22308, 'f1': 0.27619, 'auc': 0.73734}
2025-08-17 07:04:31,061 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:04:31,061 - INFO - Layer 14 (Layer_14), Head 0: drop=-0.0000
2025-08-17 07:04:35,305 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.19871, 'loss': 0.17569073, 'lr': 0, 'params': 514193, 'time_iter': 0.03255, 'accuracy': 0.96329, 'precision': 0.37349, 'recall': 0.23846, 'f1': 0.29108, 'auc': 0.73746}
2025-08-17 07:04:35,307 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:04:35,308 - INFO - Layer 14 (Layer_14), Head 1: drop=-0.0002
2025-08-17 07:04:39,479 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.12593, 'loss': 0.17641718, 'lr': 0, 'params': 514193, 'time_iter': 0.03198, 'accuracy': 0.96353, 'precision': 0.37179, 'recall': 0.22308, 'f1': 0.27885, 'auc': 0.73755}
2025-08-17 07:04:39,481 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:04:39,481 - INFO - Layer 14 (Layer_14), Head 2: drop=-0.0003
2025-08-17 07:04:43,705 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.18003, 'loss': 0.17361775, 'lr': 0, 'params': 514193, 'time_iter': 0.0324, 'accuracy': 0.96304, 'precision': 0.3625, 'recall': 0.22308, 'f1': 0.27619, 'auc': 0.7375}
2025-08-17 07:04:43,707 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:04:43,707 - INFO - Layer 14 (Layer_14), Head 3: drop=-0.0002
2025-08-17 07:04:43,710 - INFO - 
FIDELITY METRICS:
2025-08-17 07:04:43,711 - INFO - Fidelity (top 30 heads): 0.0071
2025-08-17 07:04:43,711 - INFO - Fidelity- (bottom 30 heads): -0.0068
2025-08-17 07:04:43,711 - INFO - 
GNN distribution in important heads:
2025-08-17 07:04:43,711 - INFO -   Layer_4: 3 heads
2025-08-17 07:04:43,711 - INFO -   Layer_12: 3 heads
2025-08-17 07:04:43,711 - INFO -   Layer_11: 3 heads
2025-08-17 07:04:43,711 - INFO -   Layer_0: 2 heads
2025-08-17 07:04:43,711 - INFO -   Layer_3: 2 heads
2025-08-17 07:04:43,711 - INFO -   Layer_7: 2 heads
2025-08-17 07:04:43,711 - INFO -   Layer_8: 2 heads
2025-08-17 07:04:43,711 - INFO -   Layer_9: 2 heads
2025-08-17 07:04:43,711 - INFO -   Layer_1: 2 heads
2025-08-17 07:04:43,711 - INFO -   Layer_13: 2 heads
2025-08-17 07:04:43,711 - INFO -   Layer_10: 2 heads
2025-08-17 07:04:43,711 - INFO -   Layer_14: 2 heads
2025-08-17 07:04:43,711 - INFO -   Layer_6: 1 heads
2025-08-17 07:04:43,711 - INFO -   Layer_2: 1 heads
2025-08-17 07:04:43,711 - INFO -   Layer_5: 1 heads
2025-08-17 07:04:43,711 - INFO - 
Interpretability Analysis:
2025-08-17 07:04:43,711 - INFO -   Fidelity: 0.0071
2025-08-17 07:04:43,711 - INFO -   Fidelity-: -0.0068
2025-08-17 07:04:43,711 - INFO -   Total heads tested: 60
2025-08-17 07:04:44,151 - INFO - Excel results saved to results/molhiv/molhiv-Vanilla-47/pk_explainer_results.xlsx
2025-08-17 07:04:45,368 - INFO - Saved visualizations to results/molhiv/molhiv-Vanilla-47/pk_explainer_results
2025-08-17 07:04:45,377 - INFO - 
PK-Explainer results saved to:
2025-08-17 07:04:45,377 - INFO -   - Excel: results/molhiv/molhiv-Vanilla-47/pk_explainer_results.xlsx
2025-08-17 07:04:45,377 - INFO -   - JSON: results/molhiv/molhiv-Vanilla-47/pk_explainer_results.json
2025-08-17 07:04:45,377 - INFO -   - Visualizations: results/molhiv/molhiv-Vanilla-47/pk_explainer_results
2025-08-17 07:04:45,697 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-47
2025-08-17 07:04:45,698 - INFO - Total time: 8066.59s (2.24h)
2025-08-17 07:04:45,758 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-47/agg
2025-08-17 07:04:45,758 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-17 07:04:45,758 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-47
2025-08-17 07:04:45,758 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-47/test_results/
Completed seed 47. Results saved in results/molhiv/molhiv-Vanilla-47
----------------------------------------
Running experiment with seed: 49
Starting training for seed 49...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/TRANS
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/TRANS/confignas.yaml
Using device: cuda
2025-08-17 07:05:09,119 - INFO - GPU Mem: 25.2GB
2025-08-17 07:05:09,119 - INFO - Run directory: results/molhiv/molhiv-Vanilla-49
2025-08-17 07:05:09,119 - INFO - Seed: 49
2025-08-17 07:05:09,119 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-17 07:05:09,119 - INFO - Routing mode: none
2025-08-17 07:05:09,119 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-17 07:05:09,119 - INFO - Number of layers: 15
2025-08-17 07:05:09,119 - INFO - Uncertainty enabled: False
2025-08-17 07:05:09,119 - INFO - Training mode: custom
2025-08-17 07:05:09,119 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-17 07:05:09,119 - INFO - Additional features: Router weights logging + JSON export
2025-08-17 07:05:15,578 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 07:05:15,580 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-17 07:05:15,581 - INFO -   undirected: True
2025-08-17 07:05:15,581 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 07:05:15,582 - INFO -   avg num_nodes/graph: 25
2025-08-17 07:05:15,582 - INFO -   num node features: 9
2025-08-17 07:05:15,582 - INFO -   num edge features: 3
2025-08-17 07:05:15,582 - INFO -   num tasks: 1
2025-08-17 07:05:15,582 - INFO -   num classes: 2
2025-08-17 07:05:15,583 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-17 07:05:15,583 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-17 07:05:15,586 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 11%|█         | 4340/41127 [00:10<01:24, 433.98it/s] 16%|█▌        | 6396/41127 [00:20<01:57, 296.36it/s] 22%|██▏       | 9067/41127 [00:30<01:53, 283.06it/s] 30%|███       | 12374/41127 [00:40<01:35, 300.26it/s] 36%|███▌      | 14787/41127 [00:50<01:34, 279.11it/s] 41%|████      | 16843/41127 [01:01<01:38, 246.08it/s] 50%|█████     | 20632/41127 [01:11<01:11, 288.30it/s] 58%|█████▊    | 23731/41127 [01:21<00:59, 294.83it/s] 67%|██████▋   | 27610/41127 [01:31<00:41, 323.56it/s] 74%|███████▎  | 30328/41127 [01:41<00:35, 307.24it/s] 80%|████████  | 32904/41127 [01:51<00:28, 290.99it/s] 86%|████████▌ | 35433/41127 [02:01<00:20, 278.83it/s] 94%|█████████▍| 38725/41127 [02:11<00:08, 292.87it/s] 94%|█████████▍| 38725/41127 [02:23<00:08, 292.87it/s] 99%|█████████▊| 40570/41127 [02:23<00:02, 245.83it/s]100%|██████████| 41127/41127 [02:29<00:00, 274.54it/s]
2025-08-17 07:07:46,469 - INFO - Done! Took 00:02:30.89
2025-08-17 07:07:46,598 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-17 07:07:46,781 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-17 07:07:46,781 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-08-17 07:07:46,781 - INFO - Inner model has get_darts_model: False
2025-08-17 07:07:46,785 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-08-17 07:07:46,787 - INFO - Number of parameters: 514,193
2025-08-17 07:07:46,788 - INFO - Starting optimized training: 2025-08-17 07:07:46.788002
2025-08-17 07:07:52,511 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 07:07:52,512 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-17 07:07:52,512 - INFO -   undirected: True
2025-08-17 07:07:52,512 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 07:07:52,513 - INFO -   avg num_nodes/graph: 25
2025-08-17 07:07:52,513 - INFO -   num node features: 9
2025-08-17 07:07:52,513 - INFO -   num edge features: 3
2025-08-17 07:07:52,513 - INFO -   num tasks: 1
2025-08-17 07:07:52,514 - INFO -   num classes: 2
2025-08-17 07:07:52,514 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-17 07:07:52,514 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-17 07:07:52,517 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 10%|█         | 4232/41127 [00:10<01:27, 423.16it/s] 15%|█▌        | 6351/41127 [00:20<01:56, 298.87it/s] 22%|██▏       | 8964/41127 [00:30<01:54, 281.70it/s] 30%|███       | 12417/41127 [00:40<01:33, 306.80it/s] 36%|███▌      | 14756/41127 [00:50<01:34, 280.28it/s] 41%|████      | 16812/41127 [01:03<01:47, 226.89it/s] 50%|████▉     | 20517/41127 [01:13<01:16, 270.21it/s] 57%|█████▋    | 23575/41127 [01:23<01:02, 280.69it/s] 65%|██████▍   | 26608/41127 [01:33<00:50, 287.32it/s] 71%|███████▏  | 29351/41127 [01:43<00:41, 282.64it/s] 77%|███████▋  | 31588/41127 [01:53<00:36, 264.63it/s] 84%|████████▍ | 34478/41127 [02:03<00:24, 271.49it/s] 89%|████████▉ | 36534/41127 [02:15<00:19, 239.04it/s] 95%|█████████▍| 39003/41127 [02:25<00:08, 240.53it/s] 95%|█████████▍| 39003/41127 [02:36<00:08, 240.53it/s] 99%|█████████▉| 40909/41127 [02:36<00:00, 219.50it/s]100%|██████████| 41127/41127 [02:40<00:00, 256.71it/s]
2025-08-17 07:10:33,846 - INFO - Done! Took 00:02:41.33
2025-08-17 07:10:33,984 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-17 07:10:34,131 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-17 07:10:34,131 - INFO - Start from epoch 0
2025-08-17 07:11:50,764 - INFO - train: {'epoch': 0, 'time_epoch': 76.4993, 'eta': 7573.43023, 'eta_hours': 2.10373, 'loss': 0.73744273, 'lr': 0.0, 'params': 514193, 'time_iter': 0.07434, 'accuracy': 0.04811, 'precision': 0.03765, 'recall': 0.99432, 'f1': 0.07255, 'auc': 0.55096}
2025-08-17 07:11:50,839 - INFO - ...computing epoch stats took: 0.18s
2025-08-17 07:11:56,401 - INFO - val: {'epoch': 0, 'time_epoch': 5.5425, 'loss': 0.73886241, 'lr': 0, 'params': 514193, 'time_iter': 0.04297, 'accuracy': 0.03671, 'precision': 0.02003, 'recall': 1.0, 'f1': 0.03928, 'auc': 0.45575}
2025-08-17 07:11:56,442 - INFO - ...computing epoch stats took: 0.06s
2025-08-17 07:12:01,696 - INFO - test: {'epoch': 0, 'time_epoch': 5.23546, 'loss': 0.73417242, 'lr': 0, 'params': 514193, 'time_iter': 0.04058, 'accuracy': 0.05981, 'precision': 0.03206, 'recall': 0.98462, 'f1': 0.06209, 'auc': 0.51012}
2025-08-17 07:12:01,749 - INFO - ...computing epoch stats took: 0.07s
2025-08-17 07:12:01,749 - INFO - > Epoch 0: took 87.6s (avg 87.6s) | Best so far: epoch 0	train_loss: 0.7374 train_auc: 0.5510	val_loss: 0.7389 val_auc: 0.4557	test_loss: 0.7342 test_auc: 0.5101
2025-08-17 07:13:15,212 - INFO - train: {'epoch': 1, 'time_epoch': 73.35697, 'eta': 7342.95685, 'eta_hours': 2.03971, 'loss': 0.41932053, 'lr': 2e-05, 'params': 514193, 'time_iter': 0.07129, 'accuracy': 0.88283, 'precision': 0.03902, 'recall': 0.0901, 'f1': 0.05445, 'auc': 0.54996}
2025-08-17 07:13:15,225 - INFO - ...computing epoch stats took: 0.10s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:13:19,980 - INFO - val: {'epoch': 1, 'time_epoch': 4.73648, 'loss': 0.18978067, 'lr': 0, 'params': 514193, 'time_iter': 0.03672, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.62867}
2025-08-17 07:13:19,984 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:13:24,779 - INFO - test: {'epoch': 1, 'time_epoch': 4.77933, 'loss': 0.20327582, 'lr': 0, 'params': 514193, 'time_iter': 0.03705, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66784}
2025-08-17 07:13:24,781 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:13:24,781 - INFO - > Epoch 1: took 83.0s (avg 85.3s) | Best so far: epoch 1	train_loss: 0.4193 train_auc: 0.5500	val_loss: 0.1898 val_auc: 0.6287	test_loss: 0.2033 test_auc: 0.6678
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:14:38,226 - INFO - train: {'epoch': 2, 'time_epoch': 73.35131, 'eta': 7217.04483, 'eta_hours': 2.00473, 'loss': 0.16816421, 'lr': 4e-05, 'params': 514193, 'time_iter': 0.07128, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.62234}
2025-08-17 07:14:38,235 - INFO - ...computing epoch stats took: 0.08s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:14:43,123 - INFO - val: {'epoch': 2, 'time_epoch': 4.86882, 'loss': 0.09856676, 'lr': 0, 'params': 514193, 'time_iter': 0.03774, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68666}
2025-08-17 07:14:43,131 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:14:47,998 - INFO - test: {'epoch': 2, 'time_epoch': 4.85022, 'loss': 0.13549263, 'lr': 0, 'params': 514193, 'time_iter': 0.0376, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70077}
2025-08-17 07:14:48,004 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:14:48,004 - INFO - > Epoch 2: took 83.2s (avg 84.6s) | Best so far: epoch 2	train_loss: 0.1682 train_auc: 0.6223	val_loss: 0.0986 val_auc: 0.6867	test_loss: 0.1355 test_auc: 0.7008
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:16:01,268 - INFO - train: {'epoch': 3, 'time_epoch': 73.13007, 'eta': 7112.10352, 'eta_hours': 1.97558, 'loss': 0.15332367, 'lr': 6e-05, 'params': 514193, 'time_iter': 0.07107, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67308}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:16:06,143 - INFO - val: {'epoch': 3, 'time_epoch': 4.84486, 'loss': 0.096792, 'lr': 0, 'params': 514193, 'time_iter': 0.03756, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73413}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:16:10,923 - INFO - test: {'epoch': 3, 'time_epoch': 4.72186, 'loss': 0.1291056, 'lr': 0, 'params': 514193, 'time_iter': 0.0366, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74996}
2025-08-17 07:16:10,934 - INFO - > Epoch 3: took 82.9s (avg 84.2s) | Best so far: epoch 3	train_loss: 0.1533 train_auc: 0.6731	val_loss: 0.0968 val_auc: 0.7341	test_loss: 0.1291 test_auc: 0.7500
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:17:20,427 - INFO - train: {'epoch': 4, 'time_epoch': 69.41939, 'eta': 6949.38362, 'eta_hours': 1.93038, 'loss': 0.14651478, 'lr': 8e-05, 'params': 514193, 'time_iter': 0.06746, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71329}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:17:25,012 - INFO - val: {'epoch': 4, 'time_epoch': 4.5601, 'loss': 0.08785371, 'lr': 0, 'params': 514193, 'time_iter': 0.03535, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71558}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:17:29,507 - INFO - test: {'epoch': 4, 'time_epoch': 4.47527, 'loss': 0.12326382, 'lr': 0, 'params': 514193, 'time_iter': 0.03469, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73435}
2025-08-17 07:17:29,568 - INFO - > Epoch 4: took 78.6s (avg 83.1s) | Best so far: epoch 3	train_loss: 0.1533 train_auc: 0.6731	val_loss: 0.0968 val_auc: 0.7341	test_loss: 0.1291 test_auc: 0.7500
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:18:41,572 - INFO - train: {'epoch': 5, 'time_epoch': 71.91258, 'eta': 6856.82397, 'eta_hours': 1.90467, 'loss': 0.14242042, 'lr': 0.0001, 'params': 514193, 'time_iter': 0.06989, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72294}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:18:46,253 - INFO - val: {'epoch': 5, 'time_epoch': 4.55611, 'loss': 0.09695082, 'lr': 0, 'params': 514193, 'time_iter': 0.03532, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.65528}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:18:50,677 - INFO - test: {'epoch': 5, 'time_epoch': 4.40734, 'loss': 0.12676303, 'lr': 0, 'params': 514193, 'time_iter': 0.03417, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72072}
2025-08-17 07:18:50,679 - INFO - > Epoch 5: took 81.1s (avg 82.8s) | Best so far: epoch 3	train_loss: 0.1533 train_auc: 0.6731	val_loss: 0.0968 val_auc: 0.7341	test_loss: 0.1291 test_auc: 0.7500
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:20:02,114 - INFO - train: {'epoch': 6, 'time_epoch': 71.36262, 'eta': 6762.85682, 'eta_hours': 1.87857, 'loss': 0.1374874, 'lr': 9.997e-05, 'params': 514193, 'time_iter': 0.06935, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74521}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:20:06,542 - INFO - val: {'epoch': 6, 'time_epoch': 4.40632, 'loss': 0.09916887, 'lr': 0, 'params': 514193, 'time_iter': 0.03416, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68561}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:20:10,923 - INFO - test: {'epoch': 6, 'time_epoch': 4.36608, 'loss': 0.12522858, 'lr': 0, 'params': 514193, 'time_iter': 0.03385, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7475}
2025-08-17 07:20:10,926 - INFO - > Epoch 6: took 80.2s (avg 82.4s) | Best so far: epoch 3	train_loss: 0.1533 train_auc: 0.6731	val_loss: 0.0968 val_auc: 0.7341	test_loss: 0.1291 test_auc: 0.7500
2025-08-17 07:21:21,213 - INFO - train: {'epoch': 7, 'time_epoch': 70.20399, 'eta': 6661.21662, 'eta_hours': 1.85034, 'loss': 0.13448811, 'lr': 9.989e-05, 'params': 514193, 'time_iter': 0.06823, 'accuracy': 0.9638, 'precision': 0.78082, 'recall': 0.04627, 'f1': 0.08736, 'auc': 0.75841}
2025-08-17 07:21:25,693 - INFO - val: {'epoch': 7, 'time_epoch': 4.45632, 'loss': 0.09567318, 'lr': 0, 'params': 514193, 'time_iter': 0.03455, 'accuracy': 0.98152, 'precision': 0.77778, 'recall': 0.08642, 'f1': 0.15556, 'auc': 0.69791}
2025-08-17 07:21:30,060 - INFO - test: {'epoch': 7, 'time_epoch': 4.34889, 'loss': 0.1273385, 'lr': 0, 'params': 514193, 'time_iter': 0.03371, 'accuracy': 0.97082, 'precision': 0.75, 'recall': 0.11538, 'f1': 0.2, 'auc': 0.73553}
2025-08-17 07:21:30,063 - INFO - > Epoch 7: took 79.1s (avg 82.0s) | Best so far: epoch 3	train_loss: 0.1533 train_auc: 0.6731	val_loss: 0.0968 val_auc: 0.7341	test_loss: 0.1291 test_auc: 0.7500
2025-08-17 07:22:42,296 - INFO - train: {'epoch': 8, 'time_epoch': 72.14291, 'eta': 6586.16686, 'eta_hours': 1.82949, 'loss': 0.13170809, 'lr': 9.975e-05, 'params': 514193, 'time_iter': 0.07011, 'accuracy': 0.9642, 'precision': 0.64516, 'recall': 0.0974, 'f1': 0.16925, 'auc': 0.77738}
2025-08-17 07:22:46,748 - INFO - val: {'epoch': 8, 'time_epoch': 4.42755, 'loss': 0.08997228, 'lr': 0, 'params': 514193, 'time_iter': 0.03432, 'accuracy': 0.98225, 'precision': 0.78571, 'recall': 0.1358, 'f1': 0.23158, 'auc': 0.7412}
2025-08-17 07:22:51,189 - INFO - test: {'epoch': 8, 'time_epoch': 4.4216, 'loss': 0.1259784, 'lr': 0, 'params': 514193, 'time_iter': 0.03428, 'accuracy': 0.96961, 'precision': 0.69231, 'recall': 0.06923, 'f1': 0.12587, 'auc': 0.74647}
2025-08-17 07:22:51,193 - INFO - > Epoch 8: took 81.1s (avg 81.9s) | Best so far: epoch 8	train_loss: 0.1317 train_auc: 0.7774	val_loss: 0.0900 val_auc: 0.7412	test_loss: 0.1260 test_auc: 0.7465
2025-08-17 07:24:02,699 - INFO - train: {'epoch': 9, 'time_epoch': 71.42212, 'eta': 6505.21134, 'eta_hours': 1.807, 'loss': 0.12876495, 'lr': 9.956e-05, 'params': 514193, 'time_iter': 0.06941, 'accuracy': 0.96453, 'precision': 0.61017, 'recall': 0.1461, 'f1': 0.23576, 'auc': 0.78699}
2025-08-17 07:24:07,047 - INFO - val: {'epoch': 9, 'time_epoch': 4.32315, 'loss': 0.08560441, 'lr': 0, 'params': 514193, 'time_iter': 0.03351, 'accuracy': 0.98128, 'precision': 0.57692, 'recall': 0.18519, 'f1': 0.28037, 'auc': 0.71893}
2025-08-17 07:24:11,350 - INFO - test: {'epoch': 9, 'time_epoch': 4.28466, 'loss': 0.12264093, 'lr': 0, 'params': 514193, 'time_iter': 0.03321, 'accuracy': 0.97009, 'precision': 0.58537, 'recall': 0.18462, 'f1': 0.2807, 'auc': 0.74757}
2025-08-17 07:24:11,352 - INFO - > Epoch 9: took 80.2s (avg 81.7s) | Best so far: epoch 8	train_loss: 0.1317 train_auc: 0.7774	val_loss: 0.0900 val_auc: 0.7412	test_loss: 0.1260 test_auc: 0.7465
2025-08-17 07:25:22,602 - INFO - train: {'epoch': 10, 'time_epoch': 71.16575, 'eta': 6423.91486, 'eta_hours': 1.78442, 'loss': 0.12635527, 'lr': 9.932e-05, 'params': 514193, 'time_iter': 0.06916, 'accuracy': 0.96489, 'precision': 0.61032, 'recall': 0.17289, 'f1': 0.26945, 'auc': 0.79377}
2025-08-17 07:25:27,067 - INFO - val: {'epoch': 10, 'time_epoch': 4.44097, 'loss': 0.09075, 'lr': 0, 'params': 514193, 'time_iter': 0.03443, 'accuracy': 0.97958, 'precision': 0.46154, 'recall': 0.22222, 'f1': 0.3, 'auc': 0.72794}
2025-08-17 07:25:31,378 - INFO - test: {'epoch': 10, 'time_epoch': 4.29328, 'loss': 0.12460591, 'lr': 0, 'params': 514193, 'time_iter': 0.03328, 'accuracy': 0.96523, 'precision': 0.38182, 'recall': 0.16154, 'f1': 0.22703, 'auc': 0.75182}
2025-08-17 07:25:31,386 - INFO - > Epoch 10: took 80.0s (avg 81.6s) | Best so far: epoch 8	train_loss: 0.1317 train_auc: 0.7774	val_loss: 0.0900 val_auc: 0.7412	test_loss: 0.1260 test_auc: 0.7465
2025-08-17 07:26:43,478 - INFO - train: {'epoch': 11, 'time_epoch': 72.00836, 'eta': 6350.48604, 'eta_hours': 1.76402, 'loss': 0.12597603, 'lr': 9.902e-05, 'params': 514193, 'time_iter': 0.06998, 'accuracy': 0.96468, 'precision': 0.58454, 'recall': 0.19643, 'f1': 0.29405, 'auc': 0.79203}
2025-08-17 07:26:47,854 - INFO - val: {'epoch': 11, 'time_epoch': 4.35308, 'loss': 0.08828186, 'lr': 0, 'params': 514193, 'time_iter': 0.03374, 'accuracy': 0.98006, 'precision': 0.48571, 'recall': 0.20988, 'f1': 0.2931, 'auc': 0.72961}
2025-08-17 07:26:52,150 - INFO - test: {'epoch': 11, 'time_epoch': 4.27828, 'loss': 0.12157925, 'lr': 0, 'params': 514193, 'time_iter': 0.03316, 'accuracy': 0.96864, 'precision': 0.50909, 'recall': 0.21538, 'f1': 0.3027, 'auc': 0.74514}
2025-08-17 07:26:52,152 - INFO - > Epoch 11: took 80.8s (avg 81.5s) | Best so far: epoch 8	train_loss: 0.1317 train_auc: 0.7774	val_loss: 0.0900 val_auc: 0.7412	test_loss: 0.1260 test_auc: 0.7465
2025-08-17 07:28:03,846 - INFO - train: {'epoch': 12, 'time_epoch': 71.59726, 'eta': 6274.52454, 'eta_hours': 1.74292, 'loss': 0.12305557, 'lr': 9.867e-05, 'params': 514193, 'time_iter': 0.06958, 'accuracy': 0.96538, 'precision': 0.61045, 'recall': 0.2086, 'f1': 0.31095, 'auc': 0.80729}
2025-08-17 07:28:08,322 - INFO - val: {'epoch': 12, 'time_epoch': 4.45125, 'loss': 0.09022798, 'lr': 0, 'params': 514193, 'time_iter': 0.03451, 'accuracy': 0.97788, 'precision': 0.3913, 'recall': 0.22222, 'f1': 0.28346, 'auc': 0.74215}
2025-08-17 07:28:12,861 - INFO - test: {'epoch': 12, 'time_epoch': 4.51984, 'loss': 0.12570795, 'lr': 0, 'params': 514193, 'time_iter': 0.03504, 'accuracy': 0.96596, 'precision': 0.43243, 'recall': 0.24615, 'f1': 0.31373, 'auc': 0.72825}
2025-08-17 07:28:12,865 - INFO - > Epoch 12: took 80.7s (avg 81.4s) | Best so far: epoch 12	train_loss: 0.1231 train_auc: 0.8073	val_loss: 0.0902 val_auc: 0.7421	test_loss: 0.1257 test_auc: 0.7282
2025-08-17 07:29:25,011 - INFO - train: {'epoch': 13, 'time_epoch': 72.06463, 'eta': 6202.05749, 'eta_hours': 1.72279, 'loss': 0.12137522, 'lr': 9.826e-05, 'params': 514193, 'time_iter': 0.07003, 'accuracy': 0.96602, 'precision': 0.63256, 'recall': 0.22078, 'f1': 0.32732, 'auc': 0.81387}
2025-08-17 07:29:29,499 - INFO - val: {'epoch': 13, 'time_epoch': 4.46551, 'loss': 0.08073732, 'lr': 0, 'params': 514193, 'time_iter': 0.03462, 'accuracy': 0.98201, 'precision': 0.64, 'recall': 0.19753, 'f1': 0.30189, 'auc': 0.74028}
2025-08-17 07:29:34,017 - INFO - test: {'epoch': 13, 'time_epoch': 4.50068, 'loss': 0.11924816, 'lr': 0, 'params': 514193, 'time_iter': 0.03489, 'accuracy': 0.97034, 'precision': 0.6, 'recall': 0.18462, 'f1': 0.28235, 'auc': 0.72887}
2025-08-17 07:29:34,020 - INFO - > Epoch 13: took 81.2s (avg 81.4s) | Best so far: epoch 12	train_loss: 0.1231 train_auc: 0.8073	val_loss: 0.0902 val_auc: 0.7421	test_loss: 0.1257 test_auc: 0.7282
2025-08-17 07:30:44,818 - INFO - train: {'epoch': 14, 'time_epoch': 70.71129, 'eta': 6121.97515, 'eta_hours': 1.70055, 'loss': 0.11952881, 'lr': 9.78e-05, 'params': 514193, 'time_iter': 0.06872, 'accuracy': 0.96675, 'precision': 0.64619, 'recall': 0.24756, 'f1': 0.35798, 'auc': 0.81823}
2025-08-17 07:30:49,375 - INFO - val: {'epoch': 14, 'time_epoch': 4.5324, 'loss': 0.08450346, 'lr': 0, 'params': 514193, 'time_iter': 0.03513, 'accuracy': 0.98079, 'precision': 0.52632, 'recall': 0.24691, 'f1': 0.33613, 'auc': 0.74081}
2025-08-17 07:30:53,996 - INFO - test: {'epoch': 14, 'time_epoch': 4.60184, 'loss': 0.12033715, 'lr': 0, 'params': 514193, 'time_iter': 0.03567, 'accuracy': 0.96766, 'precision': 0.47368, 'recall': 0.20769, 'f1': 0.28877, 'auc': 0.75355}
2025-08-17 07:30:53,999 - INFO - > Epoch 14: took 80.0s (avg 81.3s) | Best so far: epoch 12	train_loss: 0.1231 train_auc: 0.8073	val_loss: 0.0902 val_auc: 0.7421	test_loss: 0.1257 test_auc: 0.7282
2025-08-17 07:32:05,533 - INFO - train: {'epoch': 15, 'time_epoch': 71.44741, 'eta': 6046.92884, 'eta_hours': 1.6797, 'loss': 0.11829263, 'lr': 9.729e-05, 'params': 514193, 'time_iter': 0.06943, 'accuracy': 0.96693, 'precision': 0.65517, 'recall': 0.24675, 'f1': 0.35849, 'auc': 0.82187}
2025-08-17 07:32:10,063 - INFO - val: {'epoch': 15, 'time_epoch': 4.50714, 'loss': 0.0857546, 'lr': 0, 'params': 514193, 'time_iter': 0.03494, 'accuracy': 0.97958, 'precision': 0.45946, 'recall': 0.20988, 'f1': 0.28814, 'auc': 0.76633}
2025-08-17 07:32:14,582 - INFO - test: {'epoch': 15, 'time_epoch': 4.50237, 'loss': 0.11507172, 'lr': 0, 'params': 514193, 'time_iter': 0.0349, 'accuracy': 0.97034, 'precision': 0.55405, 'recall': 0.31538, 'f1': 0.40196, 'auc': 0.76595}
2025-08-17 07:32:14,585 - INFO - > Epoch 15: took 80.6s (avg 81.3s) | Best so far: epoch 15	train_loss: 0.1183 train_auc: 0.8219	val_loss: 0.0858 val_auc: 0.7663	test_loss: 0.1151 test_auc: 0.7660
2025-08-17 07:33:25,724 - INFO - train: {'epoch': 16, 'time_epoch': 71.04854, 'eta': 5970.35847, 'eta_hours': 1.65843, 'loss': 0.11716687, 'lr': 9.673e-05, 'params': 514193, 'time_iter': 0.06905, 'accuracy': 0.96648, 'precision': 0.62524, 'recall': 0.26136, 'f1': 0.36863, 'auc': 0.83026}
2025-08-17 07:33:30,199 - INFO - val: {'epoch': 16, 'time_epoch': 4.45134, 'loss': 0.08372483, 'lr': 0, 'params': 514193, 'time_iter': 0.03451, 'accuracy': 0.98006, 'precision': 0.4878, 'recall': 0.24691, 'f1': 0.32787, 'auc': 0.75036}
2025-08-17 07:33:34,655 - INFO - test: {'epoch': 16, 'time_epoch': 4.43889, 'loss': 0.11967746, 'lr': 0, 'params': 514193, 'time_iter': 0.03441, 'accuracy': 0.96864, 'precision': 0.50667, 'recall': 0.29231, 'f1': 0.37073, 'auc': 0.75774}
2025-08-17 07:33:34,658 - INFO - > Epoch 16: took 80.1s (avg 81.2s) | Best so far: epoch 15	train_loss: 0.1183 train_auc: 0.8219	val_loss: 0.0858 val_auc: 0.7663	test_loss: 0.1151 test_auc: 0.7660
2025-08-17 07:34:45,794 - INFO - train: {'epoch': 17, 'time_epoch': 71.05123, 'eta': 5894.41391, 'eta_hours': 1.63734, 'loss': 0.11549171, 'lr': 9.611e-05, 'params': 514193, 'time_iter': 0.06905, 'accuracy': 0.96717, 'precision': 0.64394, 'recall': 0.27597, 'f1': 0.38636, 'auc': 0.83203}
2025-08-17 07:34:50,279 - INFO - val: {'epoch': 17, 'time_epoch': 4.46146, 'loss': 0.08260242, 'lr': 0, 'params': 514193, 'time_iter': 0.03458, 'accuracy': 0.97958, 'precision': 0.46341, 'recall': 0.23457, 'f1': 0.31148, 'auc': 0.76636}
2025-08-17 07:34:54,814 - INFO - test: {'epoch': 17, 'time_epoch': 4.51481, 'loss': 0.11906248, 'lr': 0, 'params': 514193, 'time_iter': 0.035, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.25385, 'f1': 0.33673, 'auc': 0.76511}
2025-08-17 07:34:54,818 - INFO - > Epoch 17: took 80.2s (avg 81.1s) | Best so far: epoch 17	train_loss: 0.1155 train_auc: 0.8320	val_loss: 0.0826 val_auc: 0.7664	test_loss: 0.1191 test_auc: 0.7651
2025-08-17 07:36:06,047 - INFO - train: {'epoch': 18, 'time_epoch': 71.14208, 'eta': 5819.37174, 'eta_hours': 1.61649, 'loss': 0.11375257, 'lr': 9.545e-05, 'params': 514193, 'time_iter': 0.06914, 'accuracy': 0.96875, 'precision': 0.69245, 'recall': 0.29789, 'f1': 0.41657, 'auc': 0.83597}
2025-08-17 07:36:10,440 - INFO - val: {'epoch': 18, 'time_epoch': 4.37123, 'loss': 0.08693322, 'lr': 0, 'params': 514193, 'time_iter': 0.03389, 'accuracy': 0.97788, 'precision': 0.39583, 'recall': 0.23457, 'f1': 0.29457, 'auc': 0.77563}
2025-08-17 07:36:14,810 - INFO - test: {'epoch': 18, 'time_epoch': 4.35103, 'loss': 0.12314047, 'lr': 0, 'params': 514193, 'time_iter': 0.03373, 'accuracy': 0.96791, 'precision': 0.4875, 'recall': 0.3, 'f1': 0.37143, 'auc': 0.76747}
2025-08-17 07:36:14,813 - INFO - > Epoch 18: took 80.0s (avg 81.1s) | Best so far: epoch 18	train_loss: 0.1138 train_auc: 0.8360	val_loss: 0.0869 val_auc: 0.7756	test_loss: 0.1231 test_auc: 0.7675
2025-08-17 07:37:24,398 - INFO - train: {'epoch': 19, 'time_epoch': 69.49643, 'eta': 5738.137, 'eta_hours': 1.59393, 'loss': 0.11290688, 'lr': 9.474e-05, 'params': 514193, 'time_iter': 0.06754, 'accuracy': 0.96836, 'precision': 0.68616, 'recall': 0.28571, 'f1': 0.40344, 'auc': 0.83652}
2025-08-17 07:37:28,875 - INFO - val: {'epoch': 19, 'time_epoch': 4.45254, 'loss': 0.0848587, 'lr': 0, 'params': 514193, 'time_iter': 0.03452, 'accuracy': 0.97909, 'precision': 0.44444, 'recall': 0.24691, 'f1': 0.31746, 'auc': 0.75459}
2025-08-17 07:37:33,319 - INFO - test: {'epoch': 19, 'time_epoch': 4.426, 'loss': 0.11838255, 'lr': 0, 'params': 514193, 'time_iter': 0.03431, 'accuracy': 0.96815, 'precision': 0.49123, 'recall': 0.21538, 'f1': 0.29947, 'auc': 0.75596}
2025-08-17 07:37:33,322 - INFO - > Epoch 19: took 78.5s (avg 81.0s) | Best so far: epoch 18	train_loss: 0.1138 train_auc: 0.8360	val_loss: 0.0869 val_auc: 0.7756	test_loss: 0.1231 test_auc: 0.7675
2025-08-17 07:38:44,399 - INFO - train: {'epoch': 20, 'time_epoch': 70.99361, 'eta': 5663.65244, 'eta_hours': 1.57324, 'loss': 0.11003443, 'lr': 9.397e-05, 'params': 514193, 'time_iter': 0.06899, 'accuracy': 0.96958, 'precision': 0.71271, 'recall': 0.31412, 'f1': 0.43606, 'auc': 0.85077}
2025-08-17 07:38:48,836 - INFO - val: {'epoch': 20, 'time_epoch': 4.4068, 'loss': 0.08972068, 'lr': 0, 'params': 514193, 'time_iter': 0.03416, 'accuracy': 0.97836, 'precision': 0.42593, 'recall': 0.28395, 'f1': 0.34074, 'auc': 0.74356}
2025-08-17 07:38:53,341 - INFO - test: {'epoch': 20, 'time_epoch': 4.48504, 'loss': 0.12199877, 'lr': 0, 'params': 514193, 'time_iter': 0.03477, 'accuracy': 0.96523, 'precision': 0.42857, 'recall': 0.3, 'f1': 0.35294, 'auc': 0.76128}
2025-08-17 07:38:53,343 - INFO - > Epoch 20: took 80.0s (avg 80.9s) | Best so far: epoch 18	train_loss: 0.1138 train_auc: 0.8360	val_loss: 0.0869 val_auc: 0.7756	test_loss: 0.1231 test_auc: 0.7675
2025-08-17 07:40:04,482 - INFO - train: {'epoch': 21, 'time_epoch': 71.0456, 'eta': 5589.66955, 'eta_hours': 1.55269, 'loss': 0.10928222, 'lr': 9.316e-05, 'params': 514193, 'time_iter': 0.06904, 'accuracy': 0.96879, 'precision': 0.68468, 'recall': 0.30844, 'f1': 0.42529, 'auc': 0.85372}
2025-08-17 07:40:09,033 - INFO - val: {'epoch': 21, 'time_epoch': 4.52508, 'loss': 0.08583124, 'lr': 0, 'params': 514193, 'time_iter': 0.03508, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.2716, 'f1': 0.352, 'auc': 0.75176}
2025-08-17 07:40:13,547 - INFO - test: {'epoch': 21, 'time_epoch': 4.49486, 'loss': 0.1258091, 'lr': 0, 'params': 514193, 'time_iter': 0.03484, 'accuracy': 0.96645, 'precision': 0.44118, 'recall': 0.23077, 'f1': 0.30303, 'auc': 0.73175}
2025-08-17 07:40:13,550 - INFO - > Epoch 21: took 80.2s (avg 80.9s) | Best so far: epoch 18	train_loss: 0.1138 train_auc: 0.8360	val_loss: 0.0869 val_auc: 0.7756	test_loss: 0.1231 test_auc: 0.7675
2025-08-17 07:41:21,823 - INFO - train: {'epoch': 22, 'time_epoch': 68.18955, 'eta': 5506.38053, 'eta_hours': 1.52955, 'loss': 0.10869867, 'lr': 9.23e-05, 'params': 514193, 'time_iter': 0.06627, 'accuracy': 0.96903, 'precision': 0.69399, 'recall': 0.30925, 'f1': 0.42785, 'auc': 0.85624}
2025-08-17 07:41:26,207 - INFO - val: {'epoch': 22, 'time_epoch': 4.36022, 'loss': 0.08797598, 'lr': 0, 'params': 514193, 'time_iter': 0.0338, 'accuracy': 0.97885, 'precision': 0.44643, 'recall': 0.30864, 'f1': 0.36496, 'auc': 0.75537}
2025-08-17 07:41:30,751 - INFO - test: {'epoch': 22, 'time_epoch': 4.52712, 'loss': 0.12698282, 'lr': 0, 'params': 514193, 'time_iter': 0.03509, 'accuracy': 0.96426, 'precision': 0.39759, 'recall': 0.25385, 'f1': 0.30986, 'auc': 0.76205}
2025-08-17 07:41:30,754 - INFO - > Epoch 22: took 77.2s (avg 80.7s) | Best so far: epoch 18	train_loss: 0.1138 train_auc: 0.8360	val_loss: 0.0869 val_auc: 0.7756	test_loss: 0.1231 test_auc: 0.7675
2025-08-17 07:42:42,078 - INFO - train: {'epoch': 23, 'time_epoch': 71.19936, 'eta': 5433.88087, 'eta_hours': 1.50941, 'loss': 0.10764042, 'lr': 9.14e-05, 'params': 514193, 'time_iter': 0.06919, 'accuracy': 0.96997, 'precision': 0.72344, 'recall': 0.32062, 'f1': 0.44432, 'auc': 0.85909}
2025-08-17 07:42:46,633 - INFO - val: {'epoch': 23, 'time_epoch': 4.51856, 'loss': 0.08358679, 'lr': 0, 'params': 514193, 'time_iter': 0.03503, 'accuracy': 0.97909, 'precision': 0.46032, 'recall': 0.35802, 'f1': 0.40278, 'auc': 0.78706}
2025-08-17 07:42:51,206 - INFO - test: {'epoch': 23, 'time_epoch': 4.55363, 'loss': 0.12345481, 'lr': 0, 'params': 514193, 'time_iter': 0.0353, 'accuracy': 0.96596, 'precision': 0.44318, 'recall': 0.3, 'f1': 0.3578, 'auc': 0.75444}
2025-08-17 07:42:51,209 - INFO - > Epoch 23: took 80.5s (avg 80.7s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 07:44:02,745 - INFO - train: {'epoch': 24, 'time_epoch': 71.44905, 'eta': 5362.23429, 'eta_hours': 1.48951, 'loss': 0.10617061, 'lr': 9.045e-05, 'params': 514193, 'time_iter': 0.06944, 'accuracy': 0.96979, 'precision': 0.71326, 'recall': 0.32305, 'f1': 0.44469, 'auc': 0.86932}
2025-08-17 07:44:07,240 - INFO - val: {'epoch': 24, 'time_epoch': 4.46677, 'loss': 0.07816427, 'lr': 0, 'params': 514193, 'time_iter': 0.03463, 'accuracy': 0.98104, 'precision': 0.53846, 'recall': 0.25926, 'f1': 0.35, 'auc': 0.78394}
2025-08-17 07:44:11,627 - INFO - test: {'epoch': 24, 'time_epoch': 4.36976, 'loss': 0.12456797, 'lr': 0, 'params': 514193, 'time_iter': 0.03387, 'accuracy': 0.96937, 'precision': 0.53704, 'recall': 0.22308, 'f1': 0.31522, 'auc': 0.74439}
2025-08-17 07:44:11,630 - INFO - > Epoch 24: took 80.4s (avg 80.7s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 07:45:21,699 - INFO - train: {'epoch': 25, 'time_epoch': 69.97772, 'eta': 5286.41528, 'eta_hours': 1.46845, 'loss': 0.10534147, 'lr': 8.946e-05, 'params': 514193, 'time_iter': 0.06801, 'accuracy': 0.96982, 'precision': 0.7022, 'recall': 0.33685, 'f1': 0.45529, 'auc': 0.87083}
2025-08-17 07:45:26,102 - INFO - val: {'epoch': 25, 'time_epoch': 4.37678, 'loss': 0.07894361, 'lr': 0, 'params': 514193, 'time_iter': 0.03393, 'accuracy': 0.98079, 'precision': 0.52941, 'recall': 0.22222, 'f1': 0.31304, 'auc': 0.7829}
2025-08-17 07:45:30,453 - INFO - test: {'epoch': 25, 'time_epoch': 4.33065, 'loss': 0.12174656, 'lr': 0, 'params': 514193, 'time_iter': 0.03357, 'accuracy': 0.97131, 'precision': 0.65, 'recall': 0.2, 'f1': 0.30588, 'auc': 0.7645}
2025-08-17 07:45:30,456 - INFO - > Epoch 25: took 78.8s (avg 80.6s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 07:46:39,544 - INFO - train: {'epoch': 26, 'time_epoch': 68.95667, 'eta': 5208.26833, 'eta_hours': 1.44674, 'loss': 0.10403667, 'lr': 8.842e-05, 'params': 514193, 'time_iter': 0.06701, 'accuracy': 0.97094, 'precision': 0.73232, 'recall': 0.35308, 'f1': 0.47645, 'auc': 0.8697}
2025-08-17 07:46:44,055 - INFO - val: {'epoch': 26, 'time_epoch': 4.48822, 'loss': 0.09171274, 'lr': 0, 'params': 514193, 'time_iter': 0.03479, 'accuracy': 0.97617, 'precision': 0.37681, 'recall': 0.32099, 'f1': 0.34667, 'auc': 0.78545}
2025-08-17 07:46:48,594 - INFO - test: {'epoch': 26, 'time_epoch': 4.5206, 'loss': 0.13945428, 'lr': 0, 'params': 514193, 'time_iter': 0.03504, 'accuracy': 0.96086, 'precision': 0.36036, 'recall': 0.30769, 'f1': 0.33195, 'auc': 0.7558}
2025-08-17 07:46:48,597 - INFO - > Epoch 26: took 78.1s (avg 80.5s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 07:47:58,015 - INFO - train: {'epoch': 27, 'time_epoch': 69.33767, 'eta': 5131.75754, 'eta_hours': 1.42549, 'loss': 0.10198246, 'lr': 8.734e-05, 'params': 514193, 'time_iter': 0.06738, 'accuracy': 0.97103, 'precision': 0.72757, 'recall': 0.36201, 'f1': 0.48347, 'auc': 0.8828}
2025-08-17 07:48:02,581 - INFO - val: {'epoch': 27, 'time_epoch': 4.54127, 'loss': 0.09133975, 'lr': 0, 'params': 514193, 'time_iter': 0.0352, 'accuracy': 0.97763, 'precision': 0.40678, 'recall': 0.2963, 'f1': 0.34286, 'auc': 0.77615}
2025-08-17 07:48:07,084 - INFO - test: {'epoch': 27, 'time_epoch': 4.48006, 'loss': 0.1310846, 'lr': 0, 'params': 514193, 'time_iter': 0.03473, 'accuracy': 0.96475, 'precision': 0.41935, 'recall': 0.3, 'f1': 0.34978, 'auc': 0.75997}
2025-08-17 07:48:07,087 - INFO - > Epoch 27: took 78.5s (avg 80.5s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 07:49:15,112 - INFO - train: {'epoch': 28, 'time_epoch': 67.89634, 'eta': 5052.21269, 'eta_hours': 1.40339, 'loss': 0.10093308, 'lr': 8.622e-05, 'params': 514193, 'time_iter': 0.06598, 'accuracy': 0.97085, 'precision': 0.73333, 'recall': 0.34821, 'f1': 0.47221, 'auc': 0.88632}
2025-08-17 07:49:19,630 - INFO - val: {'epoch': 28, 'time_epoch': 4.47444, 'loss': 0.08980426, 'lr': 0, 'params': 514193, 'time_iter': 0.03469, 'accuracy': 0.97933, 'precision': 0.46296, 'recall': 0.30864, 'f1': 0.37037, 'auc': 0.77065}
2025-08-17 07:49:24,059 - INFO - test: {'epoch': 28, 'time_epoch': 4.40956, 'loss': 0.13807737, 'lr': 0, 'params': 514193, 'time_iter': 0.03418, 'accuracy': 0.96402, 'precision': 0.37838, 'recall': 0.21538, 'f1': 0.27451, 'auc': 0.71988}
2025-08-17 07:49:24,063 - INFO - > Epoch 28: took 77.0s (avg 80.3s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 07:50:31,673 - INFO - train: {'epoch': 29, 'time_epoch': 67.51887, 'eta': 4972.56364, 'eta_hours': 1.38127, 'loss': 0.10098264, 'lr': 8.506e-05, 'params': 514193, 'time_iter': 0.06562, 'accuracy': 0.97082, 'precision': 0.72222, 'recall': 0.35877, 'f1': 0.47939, 'auc': 0.88631}
2025-08-17 07:50:36,042 - INFO - val: {'epoch': 29, 'time_epoch': 4.34168, 'loss': 0.08068206, 'lr': 0, 'params': 514193, 'time_iter': 0.03366, 'accuracy': 0.98079, 'precision': 0.53846, 'recall': 0.17284, 'f1': 0.26168, 'auc': 0.75069}
2025-08-17 07:50:40,406 - INFO - test: {'epoch': 29, 'time_epoch': 4.3473, 'loss': 0.13155609, 'lr': 0, 'params': 514193, 'time_iter': 0.0337, 'accuracy': 0.9662, 'precision': 0.30435, 'recall': 0.05385, 'f1': 0.0915, 'auc': 0.73404}
2025-08-17 07:50:40,408 - INFO - > Epoch 29: took 76.3s (avg 80.2s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 07:51:48,248 - INFO - train: {'epoch': 30, 'time_epoch': 67.75426, 'eta': 4894.22112, 'eta_hours': 1.35951, 'loss': 0.09999967, 'lr': 8.386e-05, 'params': 514193, 'time_iter': 0.06584, 'accuracy': 0.97113, 'precision': 0.72452, 'recall': 0.36932, 'f1': 0.48925, 'auc': 0.88998}
2025-08-17 07:51:52,609 - INFO - val: {'epoch': 30, 'time_epoch': 4.33907, 'loss': 0.0845706, 'lr': 0, 'params': 514193, 'time_iter': 0.03364, 'accuracy': 0.98006, 'precision': 0.4902, 'recall': 0.30864, 'f1': 0.37879, 'auc': 0.75286}
2025-08-17 07:51:56,881 - INFO - test: {'epoch': 30, 'time_epoch': 4.25432, 'loss': 0.13089569, 'lr': 0, 'params': 514193, 'time_iter': 0.03298, 'accuracy': 0.9645, 'precision': 0.40698, 'recall': 0.26923, 'f1': 0.32407, 'auc': 0.74098}
2025-08-17 07:51:56,883 - INFO - > Epoch 30: took 76.5s (avg 80.1s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 07:53:05,099 - INFO - train: {'epoch': 31, 'time_epoch': 68.13933, 'eta': 4817.35862, 'eta_hours': 1.33816, 'loss': 0.09806736, 'lr': 8.263e-05, 'params': 514193, 'time_iter': 0.06622, 'accuracy': 0.97161, 'precision': 0.73955, 'recall': 0.37338, 'f1': 0.49622, 'auc': 0.89397}
2025-08-17 07:53:09,376 - INFO - val: {'epoch': 31, 'time_epoch': 4.25602, 'loss': 0.08961625, 'lr': 0, 'params': 514193, 'time_iter': 0.03299, 'accuracy': 0.97715, 'precision': 0.4, 'recall': 0.32099, 'f1': 0.35616, 'auc': 0.74938}
2025-08-17 07:53:13,593 - INFO - test: {'epoch': 31, 'time_epoch': 4.19919, 'loss': 0.13770542, 'lr': 0, 'params': 514193, 'time_iter': 0.03255, 'accuracy': 0.96329, 'precision': 0.37349, 'recall': 0.23846, 'f1': 0.29108, 'auc': 0.73503}
2025-08-17 07:53:13,618 - INFO - > Epoch 31: took 76.7s (avg 80.0s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 07:54:22,617 - INFO - train: {'epoch': 32, 'time_epoch': 68.90932, 'eta': 4742.58813, 'eta_hours': 1.31739, 'loss': 0.09966994, 'lr': 8.136e-05, 'params': 514193, 'time_iter': 0.06697, 'accuracy': 0.97176, 'precision': 0.75377, 'recall': 0.36526, 'f1': 0.49207, 'auc': 0.88979}
2025-08-17 07:54:26,974 - INFO - val: {'epoch': 32, 'time_epoch': 4.3333, 'loss': 0.08845655, 'lr': 0, 'params': 514193, 'time_iter': 0.03359, 'accuracy': 0.97933, 'precision': 0.46154, 'recall': 0.2963, 'f1': 0.3609, 'auc': 0.76022}
2025-08-17 07:54:31,397 - INFO - test: {'epoch': 32, 'time_epoch': 4.40591, 'loss': 0.13334105, 'lr': 0, 'params': 514193, 'time_iter': 0.03415, 'accuracy': 0.96718, 'precision': 0.46914, 'recall': 0.29231, 'f1': 0.36019, 'auc': 0.74954}
2025-08-17 07:54:31,400 - INFO - > Epoch 32: took 77.8s (avg 79.9s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 07:55:42,061 - INFO - train: {'epoch': 33, 'time_epoch': 70.5766, 'eta': 4671.39888, 'eta_hours': 1.29761, 'loss': 0.09845458, 'lr': 8.005e-05, 'params': 514193, 'time_iter': 0.06859, 'accuracy': 0.97094, 'precision': 0.72697, 'recall': 0.35877, 'f1': 0.48043, 'auc': 0.89362}
2025-08-17 07:55:46,491 - INFO - val: {'epoch': 33, 'time_epoch': 4.40483, 'loss': 0.08542964, 'lr': 0, 'params': 514193, 'time_iter': 0.03415, 'accuracy': 0.98079, 'precision': 0.52273, 'recall': 0.28395, 'f1': 0.368, 'auc': 0.75715}
2025-08-17 07:55:50,938 - INFO - test: {'epoch': 33, 'time_epoch': 4.42711, 'loss': 0.13426612, 'lr': 0, 'params': 514193, 'time_iter': 0.03432, 'accuracy': 0.96499, 'precision': 0.40541, 'recall': 0.23077, 'f1': 0.29412, 'auc': 0.74148}
2025-08-17 07:55:50,940 - INFO - > Epoch 33: took 79.5s (avg 79.9s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 07:57:00,030 - INFO - train: {'epoch': 34, 'time_epoch': 69.0065, 'eta': 4597.32875, 'eta_hours': 1.27704, 'loss': 0.09569491, 'lr': 7.872e-05, 'params': 514193, 'time_iter': 0.06706, 'accuracy': 0.97225, 'precision': 0.75851, 'recall': 0.37987, 'f1': 0.50622, 'auc': 0.90763}
2025-08-17 07:57:04,345 - INFO - val: {'epoch': 34, 'time_epoch': 4.29314, 'loss': 0.08476981, 'lr': 0, 'params': 514193, 'time_iter': 0.03328, 'accuracy': 0.98201, 'precision': 0.58974, 'recall': 0.28395, 'f1': 0.38333, 'auc': 0.75497}
2025-08-17 07:57:08,694 - INFO - test: {'epoch': 34, 'time_epoch': 4.3323, 'loss': 0.13656953, 'lr': 0, 'params': 514193, 'time_iter': 0.03358, 'accuracy': 0.96791, 'precision': 0.48077, 'recall': 0.19231, 'f1': 0.27473, 'auc': 0.72321}
2025-08-17 07:57:08,696 - INFO - > Epoch 34: took 77.8s (avg 79.8s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 07:58:17,466 - INFO - train: {'epoch': 35, 'time_epoch': 68.68059, 'eta': 4522.96055, 'eta_hours': 1.25638, 'loss': 0.09458583, 'lr': 7.735e-05, 'params': 514193, 'time_iter': 0.06674, 'accuracy': 0.97313, 'precision': 0.78155, 'recall': 0.39205, 'f1': 0.52216, 'auc': 0.90488}
2025-08-17 07:58:21,945 - INFO - val: {'epoch': 35, 'time_epoch': 4.45447, 'loss': 0.09215204, 'lr': 0, 'params': 514193, 'time_iter': 0.03453, 'accuracy': 0.9786, 'precision': 0.43636, 'recall': 0.2963, 'f1': 0.35294, 'auc': 0.76432}
2025-08-17 07:58:26,378 - INFO - test: {'epoch': 35, 'time_epoch': 4.41559, 'loss': 0.13390097, 'lr': 0, 'params': 514193, 'time_iter': 0.03423, 'accuracy': 0.96791, 'precision': 0.48485, 'recall': 0.24615, 'f1': 0.32653, 'auc': 0.76357}
2025-08-17 07:58:26,381 - INFO - > Epoch 35: took 77.7s (avg 79.8s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 07:59:35,976 - INFO - train: {'epoch': 36, 'time_epoch': 69.50927, 'eta': 4450.31077, 'eta_hours': 1.2362, 'loss': 0.0942494, 'lr': 7.595e-05, 'params': 514193, 'time_iter': 0.06755, 'accuracy': 0.97261, 'precision': 0.76651, 'recall': 0.38636, 'f1': 0.51376, 'auc': 0.90895}
2025-08-17 07:59:40,574 - INFO - val: {'epoch': 36, 'time_epoch': 4.57373, 'loss': 0.10426212, 'lr': 0, 'params': 514193, 'time_iter': 0.03546, 'accuracy': 0.97301, 'precision': 0.32558, 'recall': 0.34568, 'f1': 0.33533, 'auc': 0.76236}
2025-08-17 07:59:45,071 - INFO - test: {'epoch': 36, 'time_epoch': 4.47952, 'loss': 0.15061941, 'lr': 0, 'params': 514193, 'time_iter': 0.03472, 'accuracy': 0.96134, 'precision': 0.34066, 'recall': 0.23846, 'f1': 0.28054, 'auc': 0.75529}
2025-08-17 07:59:45,074 - INFO - > Epoch 36: took 78.7s (avg 79.8s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:00:54,494 - INFO - train: {'epoch': 37, 'time_epoch': 69.33003, 'eta': 4377.53383, 'eta_hours': 1.21598, 'loss': 0.09215471, 'lr': 7.452e-05, 'params': 514193, 'time_iter': 0.06738, 'accuracy': 0.97307, 'precision': 0.77287, 'recall': 0.39773, 'f1': 0.52519, 'auc': 0.91582}
2025-08-17 08:00:58,758 - INFO - val: {'epoch': 37, 'time_epoch': 4.24045, 'loss': 0.09528996, 'lr': 0, 'params': 514193, 'time_iter': 0.03287, 'accuracy': 0.9769, 'precision': 0.40541, 'recall': 0.37037, 'f1': 0.3871, 'auc': 0.75478}
2025-08-17 08:01:02,991 - INFO - test: {'epoch': 37, 'time_epoch': 4.21709, 'loss': 0.14201369, 'lr': 0, 'params': 514193, 'time_iter': 0.03269, 'accuracy': 0.96353, 'precision': 0.38636, 'recall': 0.26154, 'f1': 0.31193, 'auc': 0.75596}
2025-08-17 08:01:02,994 - INFO - > Epoch 37: took 77.9s (avg 79.7s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:02:12,387 - INFO - train: {'epoch': 38, 'time_epoch': 69.30066, 'eta': 4304.88772, 'eta_hours': 1.1958, 'loss': 0.09255601, 'lr': 7.307e-05, 'params': 514193, 'time_iter': 0.06735, 'accuracy': 0.97271, 'precision': 0.75932, 'recall': 0.39692, 'f1': 0.52132, 'auc': 0.91611}
2025-08-17 08:02:16,732 - INFO - val: {'epoch': 38, 'time_epoch': 4.32047, 'loss': 0.0961133, 'lr': 0, 'params': 514193, 'time_iter': 0.03349, 'accuracy': 0.9769, 'precision': 0.39706, 'recall': 0.33333, 'f1': 0.36242, 'auc': 0.76023}
2025-08-17 08:02:20,982 - INFO - test: {'epoch': 38, 'time_epoch': 4.23285, 'loss': 0.1424188, 'lr': 0, 'params': 514193, 'time_iter': 0.03281, 'accuracy': 0.96304, 'precision': 0.35135, 'recall': 0.2, 'f1': 0.2549, 'auc': 0.75956}
2025-08-17 08:02:20,985 - INFO - > Epoch 38: took 78.0s (avg 79.7s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:03:29,101 - INFO - train: {'epoch': 39, 'time_epoch': 68.02885, 'eta': 4230.50118, 'eta_hours': 1.17514, 'loss': 0.09038746, 'lr': 7.159e-05, 'params': 514193, 'time_iter': 0.06611, 'accuracy': 0.9738, 'precision': 0.77448, 'recall': 0.4237, 'f1': 0.54774, 'auc': 0.91835}
2025-08-17 08:03:33,315 - INFO - val: {'epoch': 39, 'time_epoch': 4.18869, 'loss': 0.08983321, 'lr': 0, 'params': 514193, 'time_iter': 0.03247, 'accuracy': 0.97909, 'precision': 0.44898, 'recall': 0.2716, 'f1': 0.33846, 'auc': 0.75286}
2025-08-17 08:03:37,543 - INFO - test: {'epoch': 39, 'time_epoch': 4.20993, 'loss': 0.14717928, 'lr': 0, 'params': 514193, 'time_iter': 0.03264, 'accuracy': 0.96718, 'precision': 0.44681, 'recall': 0.16154, 'f1': 0.23729, 'auc': 0.72455}
2025-08-17 08:03:37,546 - INFO - > Epoch 39: took 76.6s (avg 79.6s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:04:44,996 - INFO - train: {'epoch': 40, 'time_epoch': 67.36923, 'eta': 4155.47555, 'eta_hours': 1.1543, 'loss': 0.09164309, 'lr': 7.008e-05, 'params': 514193, 'time_iter': 0.06547, 'accuracy': 0.97322, 'precision': 0.77901, 'recall': 0.39773, 'f1': 0.5266, 'auc': 0.91721}
2025-08-17 08:04:49,436 - INFO - val: {'epoch': 40, 'time_epoch': 4.41504, 'loss': 0.11350084, 'lr': 0, 'params': 514193, 'time_iter': 0.03423, 'accuracy': 0.97082, 'precision': 0.30693, 'recall': 0.38272, 'f1': 0.34066, 'auc': 0.75968}
2025-08-17 08:04:53,789 - INFO - test: {'epoch': 40, 'time_epoch': 4.33549, 'loss': 0.16465957, 'lr': 0, 'params': 514193, 'time_iter': 0.03361, 'accuracy': 0.95672, 'precision': 0.29661, 'recall': 0.26923, 'f1': 0.28226, 'auc': 0.7309}
2025-08-17 08:04:53,791 - INFO - > Epoch 40: took 76.2s (avg 79.5s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:06:03,436 - INFO - train: {'epoch': 41, 'time_epoch': 69.55905, 'eta': 4083.83855, 'eta_hours': 1.1344, 'loss': 0.08843125, 'lr': 6.856e-05, 'params': 514193, 'time_iter': 0.0676, 'accuracy': 0.97404, 'precision': 0.78042, 'recall': 0.42695, 'f1': 0.55194, 'auc': 0.92561}
2025-08-17 08:06:07,731 - INFO - val: {'epoch': 41, 'time_epoch': 4.27295, 'loss': 0.10179363, 'lr': 0, 'params': 514193, 'time_iter': 0.03312, 'accuracy': 0.97593, 'precision': 0.375, 'recall': 0.33333, 'f1': 0.35294, 'auc': 0.75871}
2025-08-17 08:06:12,091 - INFO - test: {'epoch': 41, 'time_epoch': 4.34278, 'loss': 0.14806576, 'lr': 0, 'params': 514193, 'time_iter': 0.03366, 'accuracy': 0.96353, 'precision': 0.38095, 'recall': 0.24615, 'f1': 0.29907, 'auc': 0.75521}
2025-08-17 08:06:12,095 - INFO - > Epoch 41: took 78.3s (avg 79.5s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:07:18,628 - INFO - train: {'epoch': 42, 'time_epoch': 66.45205, 'eta': 4008.17962, 'eta_hours': 1.11338, 'loss': 0.08957038, 'lr': 6.701e-05, 'params': 514193, 'time_iter': 0.06458, 'accuracy': 0.97319, 'precision': 0.75072, 'recall': 0.42532, 'f1': 0.54301, 'auc': 0.92225}
2025-08-17 08:07:22,956 - INFO - val: {'epoch': 42, 'time_epoch': 4.30727, 'loss': 0.09538403, 'lr': 0, 'params': 514193, 'time_iter': 0.03339, 'accuracy': 0.97666, 'precision': 0.38806, 'recall': 0.32099, 'f1': 0.35135, 'auc': 0.73887}
2025-08-17 08:07:27,252 - INFO - test: {'epoch': 42, 'time_epoch': 4.27942, 'loss': 0.14219694, 'lr': 0, 'params': 514193, 'time_iter': 0.03317, 'accuracy': 0.9662, 'precision': 0.43836, 'recall': 0.24615, 'f1': 0.31527, 'auc': 0.75928}
2025-08-17 08:07:27,255 - INFO - > Epoch 42: took 75.2s (avg 79.4s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:08:35,318 - INFO - train: {'epoch': 43, 'time_epoch': 67.97491, 'eta': 3934.87737, 'eta_hours': 1.09302, 'loss': 0.08761121, 'lr': 6.545e-05, 'params': 514193, 'time_iter': 0.06606, 'accuracy': 0.9741, 'precision': 0.77066, 'recall': 0.43912, 'f1': 0.55946, 'auc': 0.92783}
2025-08-17 08:08:39,750 - INFO - val: {'epoch': 43, 'time_epoch': 4.40776, 'loss': 0.09799962, 'lr': 0, 'params': 514193, 'time_iter': 0.03417, 'accuracy': 0.97836, 'precision': 0.43548, 'recall': 0.33333, 'f1': 0.37762, 'auc': 0.74894}
2025-08-17 08:08:44,083 - INFO - test: {'epoch': 43, 'time_epoch': 4.31549, 'loss': 0.15029588, 'lr': 0, 'params': 514193, 'time_iter': 0.03345, 'accuracy': 0.96523, 'precision': 0.41975, 'recall': 0.26154, 'f1': 0.32227, 'auc': 0.73483}
2025-08-17 08:08:44,085 - INFO - > Epoch 43: took 76.8s (avg 79.3s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:09:52,221 - INFO - train: {'epoch': 44, 'time_epoch': 68.05155, 'eta': 3861.90556, 'eta_hours': 1.07275, 'loss': 0.08706917, 'lr': 6.387e-05, 'params': 514193, 'time_iter': 0.06613, 'accuracy': 0.97413, 'precision': 0.76495, 'recall': 0.44643, 'f1': 0.56381, 'auc': 0.9279}
2025-08-17 08:09:56,510 - INFO - val: {'epoch': 44, 'time_epoch': 4.26556, 'loss': 0.08745457, 'lr': 0, 'params': 514193, 'time_iter': 0.03307, 'accuracy': 0.98104, 'precision': 0.53333, 'recall': 0.2963, 'f1': 0.38095, 'auc': 0.75611}
2025-08-17 08:10:00,822 - INFO - test: {'epoch': 44, 'time_epoch': 4.29456, 'loss': 0.13911029, 'lr': 0, 'params': 514193, 'time_iter': 0.03329, 'accuracy': 0.96693, 'precision': 0.45161, 'recall': 0.21538, 'f1': 0.29167, 'auc': 0.7545}
2025-08-17 08:10:00,824 - INFO - > Epoch 44: took 76.7s (avg 79.3s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:11:09,781 - INFO - train: {'epoch': 45, 'time_epoch': 68.87289, 'eta': 3790.11185, 'eta_hours': 1.05281, 'loss': 0.08654365, 'lr': 6.227e-05, 'params': 514193, 'time_iter': 0.06693, 'accuracy': 0.97441, 'precision': 0.77465, 'recall': 0.44643, 'f1': 0.56643, 'auc': 0.93022}
2025-08-17 08:11:14,212 - INFO - val: {'epoch': 45, 'time_epoch': 4.40792, 'loss': 0.10343636, 'lr': 0, 'params': 514193, 'time_iter': 0.03417, 'accuracy': 0.97617, 'precision': 0.38356, 'recall': 0.34568, 'f1': 0.36364, 'auc': 0.73811}
2025-08-17 08:11:18,600 - INFO - test: {'epoch': 45, 'time_epoch': 4.36965, 'loss': 0.15460878, 'lr': 0, 'params': 514193, 'time_iter': 0.03387, 'accuracy': 0.96086, 'precision': 0.32967, 'recall': 0.23077, 'f1': 0.27149, 'auc': 0.7464}
2025-08-17 08:11:18,602 - INFO - > Epoch 45: took 77.8s (avg 79.2s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:12:27,969 - INFO - train: {'epoch': 46, 'time_epoch': 69.28179, 'eta': 3718.90353, 'eta_hours': 1.03303, 'loss': 0.08544819, 'lr': 6.066e-05, 'params': 514193, 'time_iter': 0.06733, 'accuracy': 0.97423, 'precision': 0.76593, 'recall': 0.44886, 'f1': 0.56602, 'auc': 0.93387}
2025-08-17 08:12:32,513 - INFO - val: {'epoch': 46, 'time_epoch': 4.35644, 'loss': 0.10648409, 'lr': 0, 'params': 514193, 'time_iter': 0.03377, 'accuracy': 0.97715, 'precision': 0.41096, 'recall': 0.37037, 'f1': 0.38961, 'auc': 0.7245}
2025-08-17 08:12:36,952 - INFO - test: {'epoch': 46, 'time_epoch': 4.4197, 'loss': 0.15671502, 'lr': 0, 'params': 514193, 'time_iter': 0.03426, 'accuracy': 0.96231, 'precision': 0.36264, 'recall': 0.25385, 'f1': 0.29864, 'auc': 0.739}
2025-08-17 08:12:37,002 - INFO - > Epoch 46: took 78.4s (avg 79.2s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:13:44,998 - INFO - train: {'epoch': 47, 'time_epoch': 67.89945, 'eta': 3646.27795, 'eta_hours': 1.01285, 'loss': 0.08521245, 'lr': 5.904e-05, 'params': 514193, 'time_iter': 0.06599, 'accuracy': 0.97462, 'precision': 0.77997, 'recall': 0.44886, 'f1': 0.56981, 'auc': 0.93318}
2025-08-17 08:13:49,308 - INFO - val: {'epoch': 47, 'time_epoch': 4.28855, 'loss': 0.09834846, 'lr': 0, 'params': 514193, 'time_iter': 0.03324, 'accuracy': 0.97958, 'precision': 0.47273, 'recall': 0.32099, 'f1': 0.38235, 'auc': 0.7343}
2025-08-17 08:13:53,651 - INFO - test: {'epoch': 47, 'time_epoch': 4.32517, 'loss': 0.15867008, 'lr': 0, 'params': 514193, 'time_iter': 0.03353, 'accuracy': 0.96548, 'precision': 0.41429, 'recall': 0.22308, 'f1': 0.29, 'auc': 0.73493}
2025-08-17 08:13:53,653 - INFO - > Epoch 47: took 76.7s (avg 79.2s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:15:01,525 - INFO - train: {'epoch': 48, 'time_epoch': 67.78909, 'eta': 3573.73041, 'eta_hours': 0.9927, 'loss': 0.08476884, 'lr': 5.741e-05, 'params': 514193, 'time_iter': 0.06588, 'accuracy': 0.97511, 'precision': 0.79798, 'recall': 0.44886, 'f1': 0.57455, 'auc': 0.93349}
2025-08-17 08:15:06,019 - INFO - val: {'epoch': 48, 'time_epoch': 4.47135, 'loss': 0.10662405, 'lr': 0, 'params': 514193, 'time_iter': 0.03466, 'accuracy': 0.97398, 'precision': 0.34884, 'recall': 0.37037, 'f1': 0.35928, 'auc': 0.74665}
2025-08-17 08:15:10,588 - INFO - test: {'epoch': 48, 'time_epoch': 4.55181, 'loss': 0.16837846, 'lr': 0, 'params': 514193, 'time_iter': 0.03529, 'accuracy': 0.95551, 'precision': 0.288, 'recall': 0.27692, 'f1': 0.28235, 'auc': 0.73674}
2025-08-17 08:15:10,591 - INFO - > Epoch 48: took 76.9s (avg 79.1s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:16:19,325 - INFO - train: {'epoch': 49, 'time_epoch': 68.64413, 'eta': 3502.22825, 'eta_hours': 0.97284, 'loss': 0.08289545, 'lr': 5.577e-05, 'params': 514193, 'time_iter': 0.06671, 'accuracy': 0.97474, 'precision': 0.77058, 'recall': 0.46347, 'f1': 0.57881, 'auc': 0.93817}
2025-08-17 08:16:23,966 - INFO - val: {'epoch': 49, 'time_epoch': 4.60206, 'loss': 0.10389619, 'lr': 0, 'params': 514193, 'time_iter': 0.03567, 'accuracy': 0.97642, 'precision': 0.38235, 'recall': 0.32099, 'f1': 0.34899, 'auc': 0.72772}
2025-08-17 08:16:28,320 - INFO - test: {'epoch': 49, 'time_epoch': 4.33723, 'loss': 0.15864358, 'lr': 0, 'params': 514193, 'time_iter': 0.03362, 'accuracy': 0.96523, 'precision': 0.4, 'recall': 0.2, 'f1': 0.26667, 'auc': 0.72656}
2025-08-17 08:16:28,323 - INFO - > Epoch 49: took 77.7s (avg 79.1s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:17:36,400 - INFO - train: {'epoch': 50, 'time_epoch': 67.99175, 'eta': 3430.21137, 'eta_hours': 0.95284, 'loss': 0.08388168, 'lr': 5.413e-05, 'params': 514193, 'time_iter': 0.06608, 'accuracy': 0.97471, 'precision': 0.77933, 'recall': 0.45292, 'f1': 0.5729, 'auc': 0.9371}
2025-08-17 08:17:40,732 - INFO - val: {'epoch': 50, 'time_epoch': 4.30981, 'loss': 0.10268447, 'lr': 0, 'params': 514193, 'time_iter': 0.03341, 'accuracy': 0.97666, 'precision': 0.39437, 'recall': 0.34568, 'f1': 0.36842, 'auc': 0.75795}
2025-08-17 08:17:45,090 - INFO - test: {'epoch': 50, 'time_epoch': 4.3409, 'loss': 0.15278969, 'lr': 0, 'params': 514193, 'time_iter': 0.03365, 'accuracy': 0.96231, 'precision': 0.37374, 'recall': 0.28462, 'f1': 0.32314, 'auc': 0.75453}
2025-08-17 08:17:45,093 - INFO - > Epoch 50: took 76.8s (avg 79.0s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:18:52,535 - INFO - train: {'epoch': 51, 'time_epoch': 67.32322, 'eta': 3357.7322, 'eta_hours': 0.9327, 'loss': 0.08124977, 'lr': 5.248e-05, 'params': 514193, 'time_iter': 0.06543, 'accuracy': 0.97517, 'precision': 0.78231, 'recall': 0.46672, 'f1': 0.58465, 'auc': 0.94133}
2025-08-17 08:18:56,872 - INFO - val: {'epoch': 51, 'time_epoch': 4.31522, 'loss': 0.12122175, 'lr': 0, 'params': 514193, 'time_iter': 0.03345, 'accuracy': 0.96888, 'precision': 0.27619, 'recall': 0.35802, 'f1': 0.31183, 'auc': 0.74797}
2025-08-17 08:19:01,156 - INFO - test: {'epoch': 51, 'time_epoch': 4.26569, 'loss': 0.17702006, 'lr': 0, 'params': 514193, 'time_iter': 0.03307, 'accuracy': 0.95526, 'precision': 0.30147, 'recall': 0.31538, 'f1': 0.30827, 'auc': 0.74195}
2025-08-17 08:19:01,158 - INFO - > Epoch 51: took 76.1s (avg 79.0s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:20:08,536 - INFO - train: {'epoch': 52, 'time_epoch': 67.29602, 'eta': 3285.42347, 'eta_hours': 0.91262, 'loss': 0.08064868, 'lr': 5.083e-05, 'params': 514193, 'time_iter': 0.0654, 'accuracy': 0.97581, 'precision': 0.78989, 'recall': 0.48214, 'f1': 0.59879, 'auc': 0.94424}
2025-08-17 08:20:12,709 - INFO - val: {'epoch': 52, 'time_epoch': 4.15196, 'loss': 0.09578887, 'lr': 0, 'params': 514193, 'time_iter': 0.03219, 'accuracy': 0.97812, 'precision': 0.42857, 'recall': 0.33333, 'f1': 0.375, 'auc': 0.7702}
2025-08-17 08:20:17,037 - INFO - test: {'epoch': 52, 'time_epoch': 4.31096, 'loss': 0.15632779, 'lr': 0, 'params': 514193, 'time_iter': 0.03342, 'accuracy': 0.96548, 'precision': 0.41429, 'recall': 0.22308, 'f1': 0.29, 'auc': 0.74727}
2025-08-17 08:20:17,040 - INFO - > Epoch 52: took 75.9s (avg 78.9s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:21:24,847 - INFO - train: {'epoch': 53, 'time_epoch': 67.73087, 'eta': 3213.67082, 'eta_hours': 0.89269, 'loss': 0.08040225, 'lr': 4.917e-05, 'params': 514193, 'time_iter': 0.06582, 'accuracy': 0.97514, 'precision': 0.77973, 'recall': 0.46834, 'f1': 0.58519, 'auc': 0.94517}
2025-08-17 08:21:29,127 - INFO - val: {'epoch': 53, 'time_epoch': 4.25783, 'loss': 0.1108024, 'lr': 0, 'params': 514193, 'time_iter': 0.03301, 'accuracy': 0.97642, 'precision': 0.39474, 'recall': 0.37037, 'f1': 0.38217, 'auc': 0.74485}
2025-08-17 08:21:33,437 - INFO - test: {'epoch': 53, 'time_epoch': 4.29268, 'loss': 0.17536316, 'lr': 0, 'params': 514193, 'time_iter': 0.03328, 'accuracy': 0.9594, 'precision': 0.30108, 'recall': 0.21538, 'f1': 0.25112, 'auc': 0.72405}
2025-08-17 08:21:33,440 - INFO - > Epoch 53: took 76.4s (avg 78.9s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:22:42,362 - INFO - train: {'epoch': 54, 'time_epoch': 68.84021, 'eta': 3142.97207, 'eta_hours': 0.87305, 'loss': 0.07954993, 'lr': 4.752e-05, 'params': 514193, 'time_iter': 0.0669, 'accuracy': 0.97559, 'precision': 0.78562, 'recall': 0.4789, 'f1': 0.59506, 'auc': 0.94816}
2025-08-17 08:22:46,701 - INFO - val: {'epoch': 54, 'time_epoch': 4.31666, 'loss': 0.09776947, 'lr': 0, 'params': 514193, 'time_iter': 0.03346, 'accuracy': 0.9769, 'precision': 0.39706, 'recall': 0.33333, 'f1': 0.36242, 'auc': 0.76351}
2025-08-17 08:22:51,018 - INFO - test: {'epoch': 54, 'time_epoch': 4.29937, 'loss': 0.15170593, 'lr': 0, 'params': 514193, 'time_iter': 0.03333, 'accuracy': 0.96329, 'precision': 0.36709, 'recall': 0.22308, 'f1': 0.27751, 'auc': 0.75552}
2025-08-17 08:22:51,020 - INFO - > Epoch 54: took 77.6s (avg 78.9s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:23:58,717 - INFO - train: {'epoch': 55, 'time_epoch': 67.61314, 'eta': 3071.37557, 'eta_hours': 0.85316, 'loss': 0.07987853, 'lr': 4.587e-05, 'params': 514193, 'time_iter': 0.06571, 'accuracy': 0.97486, 'precision': 0.77778, 'recall': 0.46023, 'f1': 0.57828, 'auc': 0.94835}
2025-08-17 08:24:03,069 - INFO - val: {'epoch': 55, 'time_epoch': 4.32684, 'loss': 0.10275892, 'lr': 0, 'params': 514193, 'time_iter': 0.03354, 'accuracy': 0.97326, 'precision': 0.33708, 'recall': 0.37037, 'f1': 0.35294, 'auc': 0.78688}
2025-08-17 08:24:07,487 - INFO - test: {'epoch': 55, 'time_epoch': 4.3909, 'loss': 0.16567333, 'lr': 0, 'params': 514193, 'time_iter': 0.03404, 'accuracy': 0.9611, 'precision': 0.35849, 'recall': 0.29231, 'f1': 0.32203, 'auc': 0.75493}
2025-08-17 08:24:07,490 - INFO - > Epoch 55: took 76.5s (avg 78.8s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:25:16,771 - INFO - train: {'epoch': 56, 'time_epoch': 69.19903, 'eta': 3001.1152, 'eta_hours': 0.83364, 'loss': 0.07917107, 'lr': 4.423e-05, 'params': 514193, 'time_iter': 0.06725, 'accuracy': 0.9762, 'precision': 0.79501, 'recall': 0.49107, 'f1': 0.60712, 'auc': 0.94718}
2025-08-17 08:25:21,073 - INFO - val: {'epoch': 56, 'time_epoch': 4.27968, 'loss': 0.11205096, 'lr': 0, 'params': 514193, 'time_iter': 0.03318, 'accuracy': 0.97301, 'precision': 0.33696, 'recall': 0.38272, 'f1': 0.35838, 'auc': 0.76244}
2025-08-17 08:25:25,505 - INFO - test: {'epoch': 56, 'time_epoch': 4.41418, 'loss': 0.16896932, 'lr': 0, 'params': 514193, 'time_iter': 0.03422, 'accuracy': 0.95915, 'precision': 0.31, 'recall': 0.23846, 'f1': 0.26957, 'auc': 0.75254}
2025-08-17 08:25:25,507 - INFO - > Epoch 56: took 78.0s (avg 78.8s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:26:33,903 - INFO - train: {'epoch': 57, 'time_epoch': 68.31371, 'eta': 2930.25034, 'eta_hours': 0.81396, 'loss': 0.07661287, 'lr': 4.259e-05, 'params': 514193, 'time_iter': 0.06639, 'accuracy': 0.97608, 'precision': 0.7871, 'recall': 0.49513, 'f1': 0.60787, 'auc': 0.95262}
2025-08-17 08:26:38,209 - INFO - val: {'epoch': 57, 'time_epoch': 4.28512, 'loss': 0.11397583, 'lr': 0, 'params': 514193, 'time_iter': 0.03322, 'accuracy': 0.97253, 'precision': 0.32979, 'recall': 0.38272, 'f1': 0.35429, 'auc': 0.74686}
2025-08-17 08:26:42,449 - INFO - test: {'epoch': 57, 'time_epoch': 4.22292, 'loss': 0.17003294, 'lr': 0, 'params': 514193, 'time_iter': 0.03274, 'accuracy': 0.96304, 'precision': 0.36905, 'recall': 0.23846, 'f1': 0.28972, 'auc': 0.74137}
2025-08-17 08:26:42,452 - INFO - > Epoch 57: took 76.9s (avg 78.8s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:27:49,929 - INFO - train: {'epoch': 58, 'time_epoch': 67.39434, 'eta': 2858.83308, 'eta_hours': 0.79412, 'loss': 0.07744524, 'lr': 4.096e-05, 'params': 514193, 'time_iter': 0.06549, 'accuracy': 0.97568, 'precision': 0.8, 'recall': 0.46753, 'f1': 0.59016, 'auc': 0.95049}
2025-08-17 08:27:54,349 - INFO - val: {'epoch': 58, 'time_epoch': 4.39829, 'loss': 0.11256502, 'lr': 0, 'params': 514193, 'time_iter': 0.0341, 'accuracy': 0.97642, 'precision': 0.39474, 'recall': 0.37037, 'f1': 0.38217, 'auc': 0.73785}
2025-08-17 08:27:58,891 - INFO - test: {'epoch': 58, 'time_epoch': 4.52228, 'loss': 0.16761129, 'lr': 0, 'params': 514193, 'time_iter': 0.03506, 'accuracy': 0.96304, 'precision': 0.35897, 'recall': 0.21538, 'f1': 0.26923, 'auc': 0.74093}
2025-08-17 08:27:58,893 - INFO - > Epoch 58: took 76.4s (avg 78.7s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:29:06,653 - INFO - train: {'epoch': 59, 'time_epoch': 67.67583, 'eta': 2787.73757, 'eta_hours': 0.77437, 'loss': 0.07671949, 'lr': 3.934e-05, 'params': 514193, 'time_iter': 0.06577, 'accuracy': 0.97593, 'precision': 0.80303, 'recall': 0.47321, 'f1': 0.59551, 'auc': 0.95101}
2025-08-17 08:29:10,983 - INFO - val: {'epoch': 59, 'time_epoch': 4.30746, 'loss': 0.10220904, 'lr': 0, 'params': 514193, 'time_iter': 0.03339, 'accuracy': 0.97933, 'precision': 0.4697, 'recall': 0.38272, 'f1': 0.42177, 'auc': 0.73535}
2025-08-17 08:29:15,486 - INFO - test: {'epoch': 59, 'time_epoch': 4.4843, 'loss': 0.16066265, 'lr': 0, 'params': 514193, 'time_iter': 0.03476, 'accuracy': 0.9662, 'precision': 0.42623, 'recall': 0.2, 'f1': 0.27225, 'auc': 0.7504}
2025-08-17 08:29:15,488 - INFO - > Epoch 59: took 76.6s (avg 78.7s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:30:21,802 - INFO - train: {'epoch': 60, 'time_epoch': 66.23267, 'eta': 2715.83151, 'eta_hours': 0.7544, 'loss': 0.07544225, 'lr': 3.773e-05, 'params': 514193, 'time_iter': 0.06437, 'accuracy': 0.9766, 'precision': 0.8, 'recall': 0.5, 'f1': 0.61538, 'auc': 0.95212}
2025-08-17 08:30:25,969 - INFO - val: {'epoch': 60, 'time_epoch': 4.14583, 'loss': 0.11461078, 'lr': 0, 'params': 514193, 'time_iter': 0.03214, 'accuracy': 0.97836, 'precision': 0.43939, 'recall': 0.35802, 'f1': 0.39456, 'auc': 0.71626}
2025-08-17 08:30:30,127 - INFO - test: {'epoch': 60, 'time_epoch': 4.1415, 'loss': 0.17520371, 'lr': 0, 'params': 514193, 'time_iter': 0.0321, 'accuracy': 0.96402, 'precision': 0.3875, 'recall': 0.23846, 'f1': 0.29524, 'auc': 0.72159}
2025-08-17 08:30:30,130 - INFO - > Epoch 60: took 74.6s (avg 78.6s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:31:36,957 - INFO - train: {'epoch': 61, 'time_epoch': 66.74762, 'eta': 2644.42408, 'eta_hours': 0.73456, 'loss': 0.07748028, 'lr': 3.613e-05, 'params': 514193, 'time_iter': 0.06487, 'accuracy': 0.97611, 'precision': 0.79973, 'recall': 0.48295, 'f1': 0.60223, 'auc': 0.95128}
2025-08-17 08:31:41,327 - INFO - val: {'epoch': 61, 'time_epoch': 4.34605, 'loss': 0.11884512, 'lr': 0, 'params': 514193, 'time_iter': 0.03369, 'accuracy': 0.96937, 'precision': 0.28155, 'recall': 0.35802, 'f1': 0.31522, 'auc': 0.73891}
2025-08-17 08:31:45,627 - INFO - test: {'epoch': 61, 'time_epoch': 4.28075, 'loss': 0.1705411, 'lr': 0, 'params': 514193, 'time_iter': 0.03318, 'accuracy': 0.95794, 'precision': 0.30631, 'recall': 0.26154, 'f1': 0.28216, 'auc': 0.74794}
2025-08-17 08:31:45,629 - INFO - > Epoch 61: took 75.5s (avg 78.6s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:32:53,299 - INFO - train: {'epoch': 62, 'time_epoch': 67.58242, 'eta': 2573.65485, 'eta_hours': 0.7149, 'loss': 0.07518646, 'lr': 3.455e-05, 'params': 514193, 'time_iter': 0.06568, 'accuracy': 0.97669, 'precision': 0.80156, 'recall': 0.50162, 'f1': 0.61707, 'auc': 0.95329}
2025-08-17 08:32:57,822 - INFO - val: {'epoch': 62, 'time_epoch': 4.50012, 'loss': 0.11265108, 'lr': 0, 'params': 514193, 'time_iter': 0.03488, 'accuracy': 0.97398, 'precision': 0.35227, 'recall': 0.38272, 'f1': 0.36686, 'auc': 0.76017}
2025-08-17 08:33:02,348 - INFO - test: {'epoch': 62, 'time_epoch': 4.50777, 'loss': 0.16702273, 'lr': 0, 'params': 514193, 'time_iter': 0.03494, 'accuracy': 0.96256, 'precision': 0.36047, 'recall': 0.23846, 'f1': 0.28704, 'auc': 0.74635}
2025-08-17 08:33:02,350 - INFO - > Epoch 62: took 76.7s (avg 78.5s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:34:10,513 - INFO - train: {'epoch': 63, 'time_epoch': 68.08052, 'eta': 2503.26539, 'eta_hours': 0.69535, 'loss': 0.07492527, 'lr': 3.299e-05, 'params': 514193, 'time_iter': 0.06616, 'accuracy': 0.97717, 'precision': 0.80482, 'recall': 0.51542, 'f1': 0.6284, 'auc': 0.9562}
2025-08-17 08:34:14,771 - INFO - val: {'epoch': 63, 'time_epoch': 4.23715, 'loss': 0.11123889, 'lr': 0, 'params': 514193, 'time_iter': 0.03285, 'accuracy': 0.97788, 'precision': 0.43056, 'recall': 0.38272, 'f1': 0.40523, 'auc': 0.75292}
2025-08-17 08:34:19,052 - INFO - test: {'epoch': 63, 'time_epoch': 4.26376, 'loss': 0.16775171, 'lr': 0, 'params': 514193, 'time_iter': 0.03305, 'accuracy': 0.96353, 'precision': 0.375, 'recall': 0.23077, 'f1': 0.28571, 'auc': 0.74412}
2025-08-17 08:34:19,055 - INFO - > Epoch 63: took 76.7s (avg 78.5s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:35:26,780 - INFO - train: {'epoch': 64, 'time_epoch': 67.64272, 'eta': 2432.71124, 'eta_hours': 0.67575, 'loss': 0.07400376, 'lr': 3.144e-05, 'params': 514193, 'time_iter': 0.06574, 'accuracy': 0.97632, 'precision': 0.79151, 'recall': 0.49919, 'f1': 0.61224, 'auc': 0.95737}
2025-08-17 08:35:31,115 - INFO - val: {'epoch': 64, 'time_epoch': 4.31441, 'loss': 0.11704123, 'lr': 0, 'params': 514193, 'time_iter': 0.03345, 'accuracy': 0.97131, 'precision': 0.31313, 'recall': 0.38272, 'f1': 0.34444, 'auc': 0.76345}
2025-08-17 08:35:35,505 - INFO - test: {'epoch': 64, 'time_epoch': 4.37133, 'loss': 0.17398909, 'lr': 0, 'params': 514193, 'time_iter': 0.03389, 'accuracy': 0.95721, 'precision': 0.32031, 'recall': 0.31538, 'f1': 0.31783, 'auc': 0.7554}
2025-08-17 08:35:35,507 - INFO - > Epoch 64: took 76.5s (avg 78.5s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:36:44,201 - INFO - train: {'epoch': 65, 'time_epoch': 68.61064, 'eta': 2362.74394, 'eta_hours': 0.65632, 'loss': 0.07193306, 'lr': 2.992e-05, 'params': 514193, 'time_iter': 0.06668, 'accuracy': 0.97766, 'precision': 0.80416, 'recall': 0.53328, 'f1': 0.64129, 'auc': 0.96008}
2025-08-17 08:36:48,502 - INFO - val: {'epoch': 65, 'time_epoch': 4.27928, 'loss': 0.12821271, 'lr': 0, 'params': 514193, 'time_iter': 0.03317, 'accuracy': 0.97058, 'precision': 0.30392, 'recall': 0.38272, 'f1': 0.3388, 'auc': 0.74844}
2025-08-17 08:36:52,823 - INFO - test: {'epoch': 65, 'time_epoch': 4.30524, 'loss': 0.18058659, 'lr': 0, 'params': 514193, 'time_iter': 0.03337, 'accuracy': 0.95867, 'precision': 0.32143, 'recall': 0.27692, 'f1': 0.29752, 'auc': 0.7333}
2025-08-17 08:36:52,826 - INFO - > Epoch 65: took 77.3s (avg 78.5s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:38:00,644 - INFO - train: {'epoch': 66, 'time_epoch': 67.73245, 'eta': 2292.3846, 'eta_hours': 0.63677, 'loss': 0.07423237, 'lr': 2.841e-05, 'params': 514193, 'time_iter': 0.06582, 'accuracy': 0.97647, 'precision': 0.78769, 'recall': 0.50893, 'f1': 0.61834, 'auc': 0.95758}
2025-08-17 08:38:05,010 - INFO - val: {'epoch': 66, 'time_epoch': 4.34357, 'loss': 0.11166663, 'lr': 0, 'params': 514193, 'time_iter': 0.03367, 'accuracy': 0.97374, 'precision': 0.34831, 'recall': 0.38272, 'f1': 0.36471, 'auc': 0.76509}
2025-08-17 08:38:09,399 - INFO - test: {'epoch': 66, 'time_epoch': 4.37065, 'loss': 0.16813585, 'lr': 0, 'params': 514193, 'time_iter': 0.03388, 'accuracy': 0.96037, 'precision': 0.3299, 'recall': 0.24615, 'f1': 0.28194, 'auc': 0.74601}
2025-08-17 08:38:09,458 - INFO - > Epoch 66: took 76.6s (avg 78.4s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:39:18,818 - INFO - train: {'epoch': 67, 'time_epoch': 69.27414, 'eta': 2222.82801, 'eta_hours': 0.61745, 'loss': 0.07192703, 'lr': 2.693e-05, 'params': 514193, 'time_iter': 0.06732, 'accuracy': 0.97742, 'precision': 0.80373, 'recall': 0.52516, 'f1': 0.63525, 'auc': 0.9626}
2025-08-17 08:39:23,280 - INFO - val: {'epoch': 67, 'time_epoch': 4.43889, 'loss': 0.11658565, 'lr': 0, 'params': 514193, 'time_iter': 0.03441, 'accuracy': 0.97569, 'precision': 0.36986, 'recall': 0.33333, 'f1': 0.35065, 'auc': 0.73946}
2025-08-17 08:39:27,805 - INFO - test: {'epoch': 67, 'time_epoch': 4.50781, 'loss': 0.16703685, 'lr': 0, 'params': 514193, 'time_iter': 0.03494, 'accuracy': 0.9662, 'precision': 0.44, 'recall': 0.25385, 'f1': 0.32195, 'auc': 0.75049}
2025-08-17 08:39:27,809 - INFO - > Epoch 67: took 78.4s (avg 78.4s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:40:35,736 - INFO - train: {'epoch': 68, 'time_epoch': 67.83343, 'eta': 2152.63234, 'eta_hours': 0.59795, 'loss': 0.07112845, 'lr': 2.548e-05, 'params': 514193, 'time_iter': 0.06592, 'accuracy': 0.97723, 'precision': 0.79632, 'recall': 0.52679, 'f1': 0.6341, 'auc': 0.96057}
2025-08-17 08:40:40,118 - INFO - val: {'epoch': 68, 'time_epoch': 4.35848, 'loss': 0.10887702, 'lr': 0, 'params': 514193, 'time_iter': 0.03379, 'accuracy': 0.97715, 'precision': 0.41333, 'recall': 0.38272, 'f1': 0.39744, 'auc': 0.75709}
2025-08-17 08:40:44,547 - INFO - test: {'epoch': 68, 'time_epoch': 4.41054, 'loss': 0.16860656, 'lr': 0, 'params': 514193, 'time_iter': 0.03419, 'accuracy': 0.96572, 'precision': 0.42667, 'recall': 0.24615, 'f1': 0.3122, 'auc': 0.74927}
2025-08-17 08:40:44,549 - INFO - > Epoch 68: took 76.7s (avg 78.4s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:41:53,808 - INFO - train: {'epoch': 69, 'time_epoch': 69.17697, 'eta': 2083.07997, 'eta_hours': 0.57863, 'loss': 0.07183684, 'lr': 2.405e-05, 'params': 514193, 'time_iter': 0.06723, 'accuracy': 0.97733, 'precision': 0.80838, 'recall': 0.51705, 'f1': 0.63069, 'auc': 0.96217}
2025-08-17 08:41:58,126 - INFO - val: {'epoch': 69, 'time_epoch': 4.2963, 'loss': 0.11942797, 'lr': 0, 'params': 514193, 'time_iter': 0.0333, 'accuracy': 0.97228, 'precision': 0.32258, 'recall': 0.37037, 'f1': 0.34483, 'auc': 0.75606}
2025-08-17 08:42:02,483 - INFO - test: {'epoch': 69, 'time_epoch': 4.33981, 'loss': 0.18881569, 'lr': 0, 'params': 514193, 'time_iter': 0.03364, 'accuracy': 0.96013, 'precision': 0.33962, 'recall': 0.27692, 'f1': 0.30508, 'auc': 0.73645}
2025-08-17 08:42:02,486 - INFO - > Epoch 69: took 77.9s (avg 78.4s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:43:10,111 - INFO - train: {'epoch': 70, 'time_epoch': 67.543, 'eta': 2012.87078, 'eta_hours': 0.55913, 'loss': 0.06988059, 'lr': 2.265e-05, 'params': 514193, 'time_iter': 0.06564, 'accuracy': 0.97812, 'precision': 0.8145, 'recall': 0.53815, 'f1': 0.64809, 'auc': 0.9637}
2025-08-17 08:43:14,549 - INFO - val: {'epoch': 70, 'time_epoch': 4.41571, 'loss': 0.10916208, 'lr': 0, 'params': 514193, 'time_iter': 0.03423, 'accuracy': 0.9752, 'precision': 0.37349, 'recall': 0.38272, 'f1': 0.37805, 'auc': 0.76335}
2025-08-17 08:43:18,985 - INFO - test: {'epoch': 70, 'time_epoch': 4.41687, 'loss': 0.17860118, 'lr': 0, 'params': 514193, 'time_iter': 0.03424, 'accuracy': 0.95964, 'precision': 0.33019, 'recall': 0.26923, 'f1': 0.29661, 'auc': 0.74781}
2025-08-17 08:43:18,988 - INFO - > Epoch 70: took 76.5s (avg 78.4s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:44:27,402 - INFO - train: {'epoch': 71, 'time_epoch': 68.29786, 'eta': 1943.0292, 'eta_hours': 0.53973, 'loss': 0.06870057, 'lr': 2.128e-05, 'params': 514193, 'time_iter': 0.06637, 'accuracy': 0.97857, 'precision': 0.82252, 'recall': 0.54545, 'f1': 0.65593, 'auc': 0.96496}
2025-08-17 08:44:31,744 - INFO - val: {'epoch': 71, 'time_epoch': 4.31876, 'loss': 0.10926774, 'lr': 0, 'params': 514193, 'time_iter': 0.03348, 'accuracy': 0.97885, 'precision': 0.45588, 'recall': 0.38272, 'f1': 0.41611, 'auc': 0.74504}
2025-08-17 08:44:36,006 - INFO - test: {'epoch': 71, 'time_epoch': 4.24556, 'loss': 0.17930152, 'lr': 0, 'params': 514193, 'time_iter': 0.03291, 'accuracy': 0.96304, 'precision': 0.35135, 'recall': 0.2, 'f1': 0.2549, 'auc': 0.73319}
2025-08-17 08:44:36,008 - INFO - > Epoch 71: took 77.0s (avg 78.4s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:45:45,134 - INFO - train: {'epoch': 72, 'time_epoch': 69.00535, 'eta': 1873.49159, 'eta_hours': 0.52041, 'loss': 0.0674443, 'lr': 1.995e-05, 'params': 514193, 'time_iter': 0.06706, 'accuracy': 0.97891, 'precision': 0.81647, 'recall': 0.56331, 'f1': 0.66667, 'auc': 0.96761}
2025-08-17 08:45:49,499 - INFO - val: {'epoch': 72, 'time_epoch': 4.34145, 'loss': 0.1201508, 'lr': 0, 'params': 514193, 'time_iter': 0.03365, 'accuracy': 0.97617, 'precision': 0.39241, 'recall': 0.38272, 'f1': 0.3875, 'auc': 0.73356}
2025-08-17 08:45:53,804 - INFO - test: {'epoch': 72, 'time_epoch': 4.28755, 'loss': 0.18432835, 'lr': 0, 'params': 514193, 'time_iter': 0.03324, 'accuracy': 0.96183, 'precision': 0.35165, 'recall': 0.24615, 'f1': 0.28959, 'auc': 0.74184}
2025-08-17 08:45:53,806 - INFO - > Epoch 72: took 77.8s (avg 78.4s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:47:01,669 - INFO - train: {'epoch': 73, 'time_epoch': 67.78122, 'eta': 1803.53826, 'eta_hours': 0.50098, 'loss': 0.06795272, 'lr': 1.864e-05, 'params': 514193, 'time_iter': 0.06587, 'accuracy': 0.979, 'precision': 0.82012, 'recall': 0.5625, 'f1': 0.66731, 'auc': 0.96745}
2025-08-17 08:47:05,828 - INFO - val: {'epoch': 73, 'time_epoch': 4.13843, 'loss': 0.12175042, 'lr': 0, 'params': 514193, 'time_iter': 0.03208, 'accuracy': 0.9735, 'precision': 0.34444, 'recall': 0.38272, 'f1': 0.36257, 'auc': 0.73663}
2025-08-17 08:47:09,940 - INFO - test: {'epoch': 73, 'time_epoch': 4.09557, 'loss': 0.17541558, 'lr': 0, 'params': 514193, 'time_iter': 0.03175, 'accuracy': 0.96086, 'precision': 0.34653, 'recall': 0.26923, 'f1': 0.30303, 'auc': 0.7513}
2025-08-17 08:47:09,943 - INFO - > Epoch 73: took 76.1s (avg 78.3s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:48:17,872 - INFO - train: {'epoch': 74, 'time_epoch': 67.83416, 'eta': 1733.66051, 'eta_hours': 0.48157, 'loss': 0.06802075, 'lr': 1.737e-05, 'params': 514193, 'time_iter': 0.06592, 'accuracy': 0.97845, 'precision': 0.81929, 'recall': 0.54464, 'f1': 0.65431, 'auc': 0.96669}
2025-08-17 08:48:22,255 - INFO - val: {'epoch': 74, 'time_epoch': 4.36206, 'loss': 0.10583035, 'lr': 0, 'params': 514193, 'time_iter': 0.03381, 'accuracy': 0.97763, 'precision': 0.42254, 'recall': 0.37037, 'f1': 0.39474, 'auc': 0.75508}
2025-08-17 08:48:26,646 - INFO - test: {'epoch': 74, 'time_epoch': 4.37354, 'loss': 0.17229215, 'lr': 0, 'params': 514193, 'time_iter': 0.0339, 'accuracy': 0.96426, 'precision': 0.38356, 'recall': 0.21538, 'f1': 0.27586, 'auc': 0.74914}
2025-08-17 08:48:26,648 - INFO - > Epoch 74: took 76.7s (avg 78.3s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:49:34,798 - INFO - train: {'epoch': 75, 'time_epoch': 68.06757, 'eta': 1663.91024, 'eta_hours': 0.4622, 'loss': 0.068844, 'lr': 1.614e-05, 'params': 514193, 'time_iter': 0.06615, 'accuracy': 0.9786, 'precision': 0.82039, 'recall': 0.5487, 'f1': 0.65759, 'auc': 0.96552}
2025-08-17 08:49:39,172 - INFO - val: {'epoch': 75, 'time_epoch': 4.35247, 'loss': 0.11467513, 'lr': 0, 'params': 514193, 'time_iter': 0.03374, 'accuracy': 0.97739, 'precision': 0.41667, 'recall': 0.37037, 'f1': 0.39216, 'auc': 0.74481}
2025-08-17 08:49:43,495 - INFO - test: {'epoch': 75, 'time_epoch': 4.30622, 'loss': 0.17836771, 'lr': 0, 'params': 514193, 'time_iter': 0.03338, 'accuracy': 0.96231, 'precision': 0.36559, 'recall': 0.26154, 'f1': 0.30493, 'auc': 0.74801}
2025-08-17 08:49:43,497 - INFO - > Epoch 75: took 76.8s (avg 78.3s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:50:50,233 - INFO - train: {'epoch': 76, 'time_epoch': 66.64964, 'eta': 1593.78014, 'eta_hours': 0.44272, 'loss': 0.06742326, 'lr': 1.494e-05, 'params': 514193, 'time_iter': 0.06477, 'accuracy': 0.97872, 'precision': 0.82518, 'recall': 0.54789, 'f1': 0.65854, 'auc': 0.96759}
2025-08-17 08:50:54,591 - INFO - val: {'epoch': 76, 'time_epoch': 4.33582, 'loss': 0.11499657, 'lr': 0, 'params': 514193, 'time_iter': 0.03361, 'accuracy': 0.97398, 'precision': 0.34884, 'recall': 0.37037, 'f1': 0.35928, 'auc': 0.75261}
2025-08-17 08:50:58,881 - INFO - test: {'epoch': 76, 'time_epoch': 4.27258, 'loss': 0.17312688, 'lr': 0, 'params': 514193, 'time_iter': 0.03312, 'accuracy': 0.96037, 'precision': 0.35398, 'recall': 0.30769, 'f1': 0.32922, 'auc': 0.76236}
2025-08-17 08:50:58,883 - INFO - > Epoch 76: took 75.4s (avg 78.2s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:52:07,606 - INFO - train: {'epoch': 77, 'time_epoch': 68.62942, 'eta': 1524.29768, 'eta_hours': 0.42342, 'loss': 0.06813106, 'lr': 1.378e-05, 'params': 514193, 'time_iter': 0.0667, 'accuracy': 0.97875, 'precision': 0.8184, 'recall': 0.55601, 'f1': 0.66216, 'auc': 0.96732}
2025-08-17 08:52:11,956 - INFO - val: {'epoch': 77, 'time_epoch': 4.32513, 'loss': 0.11714097, 'lr': 0, 'params': 514193, 'time_iter': 0.03353, 'accuracy': 0.9735, 'precision': 0.34444, 'recall': 0.38272, 'f1': 0.36257, 'auc': 0.75926}
2025-08-17 08:52:16,421 - INFO - test: {'epoch': 77, 'time_epoch': 4.44723, 'loss': 0.18220809, 'lr': 0, 'params': 514193, 'time_iter': 0.03447, 'accuracy': 0.95867, 'precision': 0.32759, 'recall': 0.29231, 'f1': 0.30894, 'auc': 0.75611}
2025-08-17 08:52:16,424 - INFO - > Epoch 77: took 77.5s (avg 78.2s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:53:24,697 - INFO - train: {'epoch': 78, 'time_epoch': 68.18582, 'eta': 1454.7189, 'eta_hours': 0.40409, 'loss': 0.06832663, 'lr': 1.266e-05, 'params': 514193, 'time_iter': 0.06626, 'accuracy': 0.97872, 'precision': 0.81002, 'recall': 0.56412, 'f1': 0.66507, 'auc': 0.96677}
2025-08-17 08:53:29,176 - INFO - val: {'epoch': 78, 'time_epoch': 4.45659, 'loss': 0.13094236, 'lr': 0, 'params': 514193, 'time_iter': 0.03455, 'accuracy': 0.97155, 'precision': 0.31633, 'recall': 0.38272, 'f1': 0.34637, 'auc': 0.74844}
2025-08-17 08:53:33,563 - INFO - test: {'epoch': 78, 'time_epoch': 4.36799, 'loss': 0.18935409, 'lr': 0, 'params': 514193, 'time_iter': 0.03386, 'accuracy': 0.95867, 'precision': 0.31818, 'recall': 0.26923, 'f1': 0.29167, 'auc': 0.75732}
2025-08-17 08:53:33,565 - INFO - > Epoch 78: took 77.1s (avg 78.2s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:54:42,359 - INFO - train: {'epoch': 79, 'time_epoch': 68.70221, 'eta': 1385.30405, 'eta_hours': 0.38481, 'loss': 0.06823341, 'lr': 1.158e-05, 'params': 514193, 'time_iter': 0.06677, 'accuracy': 0.9786, 'precision': 0.81579, 'recall': 0.55357, 'f1': 0.65957, 'auc': 0.96544}
2025-08-17 08:54:46,790 - INFO - val: {'epoch': 79, 'time_epoch': 4.40741, 'loss': 0.12577159, 'lr': 0, 'params': 514193, 'time_iter': 0.03417, 'accuracy': 0.9735, 'precision': 0.34444, 'recall': 0.38272, 'f1': 0.36257, 'auc': 0.74445}
2025-08-17 08:54:51,142 - INFO - test: {'epoch': 79, 'time_epoch': 4.33396, 'loss': 0.1854217, 'lr': 0, 'params': 514193, 'time_iter': 0.0336, 'accuracy': 0.95988, 'precision': 0.34234, 'recall': 0.29231, 'f1': 0.31535, 'auc': 0.75324}
2025-08-17 08:54:51,144 - INFO - > Epoch 79: took 77.6s (avg 78.2s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:55:59,742 - INFO - train: {'epoch': 80, 'time_epoch': 68.51066, 'eta': 1315.86185, 'eta_hours': 0.36552, 'loss': 0.065869, 'lr': 1.054e-05, 'params': 514193, 'time_iter': 0.06658, 'accuracy': 0.97894, 'precision': 0.82588, 'recall': 0.55438, 'f1': 0.66343, 'auc': 0.96927}
2025-08-17 08:56:04,075 - INFO - val: {'epoch': 80, 'time_epoch': 4.30665, 'loss': 0.12177682, 'lr': 0, 'params': 514193, 'time_iter': 0.03338, 'accuracy': 0.97204, 'precision': 0.32292, 'recall': 0.38272, 'f1': 0.35028, 'auc': 0.74784}
2025-08-17 08:56:08,420 - INFO - test: {'epoch': 80, 'time_epoch': 4.328, 'loss': 0.18042616, 'lr': 0, 'params': 514193, 'time_iter': 0.03355, 'accuracy': 0.9611, 'precision': 0.35849, 'recall': 0.29231, 'f1': 0.32203, 'auc': 0.75396}
2025-08-17 08:56:08,422 - INFO - > Epoch 80: took 77.3s (avg 78.2s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:57:15,344 - INFO - train: {'epoch': 81, 'time_epoch': 66.82601, 'eta': 1246.07258, 'eta_hours': 0.34613, 'loss': 0.0674824, 'lr': 9.55e-06, 'params': 514193, 'time_iter': 0.06494, 'accuracy': 0.97836, 'precision': 0.79954, 'recall': 0.56331, 'f1': 0.66095, 'auc': 0.96818}
2025-08-17 08:57:19,710 - INFO - val: {'epoch': 81, 'time_epoch': 4.34516, 'loss': 0.11638659, 'lr': 0, 'params': 514193, 'time_iter': 0.03368, 'accuracy': 0.97374, 'precision': 0.34831, 'recall': 0.38272, 'f1': 0.36471, 'auc': 0.74564}
2025-08-17 08:57:24,016 - INFO - test: {'epoch': 81, 'time_epoch': 4.28894, 'loss': 0.17903927, 'lr': 0, 'params': 514193, 'time_iter': 0.03325, 'accuracy': 0.96086, 'precision': 0.34343, 'recall': 0.26154, 'f1': 0.29694, 'auc': 0.74389}
2025-08-17 08:57:24,018 - INFO - > Epoch 81: took 75.6s (avg 78.2s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:58:32,525 - INFO - train: {'epoch': 82, 'time_epoch': 68.3868, 'eta': 1176.67439, 'eta_hours': 0.32685, 'loss': 0.06505922, 'lr': 8.6e-06, 'params': 514193, 'time_iter': 0.06646, 'accuracy': 0.97964, 'precision': 0.83774, 'recall': 0.56575, 'f1': 0.67539, 'auc': 0.96964}
2025-08-17 08:58:36,959 - INFO - val: {'epoch': 82, 'time_epoch': 4.41041, 'loss': 0.12115223, 'lr': 0, 'params': 514193, 'time_iter': 0.03419, 'accuracy': 0.9735, 'precision': 0.34444, 'recall': 0.38272, 'f1': 0.36257, 'auc': 0.73852}
2025-08-17 08:58:41,396 - INFO - test: {'epoch': 82, 'time_epoch': 4.41971, 'loss': 0.19400937, 'lr': 0, 'params': 514193, 'time_iter': 0.03426, 'accuracy': 0.95842, 'precision': 0.32773, 'recall': 0.3, 'f1': 0.31325, 'auc': 0.7428}
2025-08-17 08:58:41,399 - INFO - > Epoch 82: took 77.4s (avg 78.2s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 08:59:50,566 - INFO - train: {'epoch': 83, 'time_epoch': 69.08338, 'eta': 1107.43296, 'eta_hours': 0.30762, 'loss': 0.06366248, 'lr': 7.7e-06, 'params': 514193, 'time_iter': 0.06714, 'accuracy': 0.97967, 'precision': 0.82319, 'recall': 0.58198, 'f1': 0.68188, 'auc': 0.97175}
2025-08-17 08:59:54,861 - INFO - val: {'epoch': 83, 'time_epoch': 4.27453, 'loss': 0.13133745, 'lr': 0, 'params': 514193, 'time_iter': 0.03314, 'accuracy': 0.9718, 'precision': 0.31959, 'recall': 0.38272, 'f1': 0.34831, 'auc': 0.73446}
2025-08-17 08:59:59,213 - INFO - test: {'epoch': 83, 'time_epoch': 4.33519, 'loss': 0.19337709, 'lr': 0, 'params': 514193, 'time_iter': 0.03361, 'accuracy': 0.95867, 'precision': 0.33051, 'recall': 0.3, 'f1': 0.31452, 'auc': 0.75105}
2025-08-17 08:59:59,216 - INFO - > Epoch 83: took 77.8s (avg 78.2s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:01:06,636 - INFO - train: {'epoch': 84, 'time_epoch': 67.33107, 'eta': 1037.88602, 'eta_hours': 0.2883, 'loss': 0.06523618, 'lr': 6.84e-06, 'params': 514193, 'time_iter': 0.06543, 'accuracy': 0.97885, 'precision': 0.80876, 'recall': 0.56981, 'f1': 0.66857, 'auc': 0.97122}
2025-08-17 09:01:11,028 - INFO - val: {'epoch': 84, 'time_epoch': 4.36783, 'loss': 0.12290201, 'lr': 0, 'params': 514193, 'time_iter': 0.03386, 'accuracy': 0.97496, 'precision': 0.36905, 'recall': 0.38272, 'f1': 0.37576, 'auc': 0.73722}
2025-08-17 09:01:15,430 - INFO - test: {'epoch': 84, 'time_epoch': 4.38315, 'loss': 0.18454231, 'lr': 0, 'params': 514193, 'time_iter': 0.03398, 'accuracy': 0.96231, 'precision': 0.38095, 'recall': 0.30769, 'f1': 0.34043, 'auc': 0.7547}
2025-08-17 09:01:15,432 - INFO - > Epoch 84: took 76.2s (avg 78.1s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:02:24,273 - INFO - train: {'epoch': 85, 'time_epoch': 68.7581, 'eta': 968.62292, 'eta_hours': 0.26906, 'loss': 0.06623504, 'lr': 6.03e-06, 'params': 514193, 'time_iter': 0.06682, 'accuracy': 0.97951, 'precision': 0.83294, 'recall': 0.56656, 'f1': 0.6744, 'auc': 0.96743}
2025-08-17 09:02:28,592 - INFO - val: {'epoch': 85, 'time_epoch': 4.297, 'loss': 0.12293729, 'lr': 0, 'params': 514193, 'time_iter': 0.03331, 'accuracy': 0.9769, 'precision': 0.40789, 'recall': 0.38272, 'f1': 0.3949, 'auc': 0.73744}
2025-08-17 09:02:32,944 - INFO - test: {'epoch': 85, 'time_epoch': 4.33342, 'loss': 0.19202609, 'lr': 0, 'params': 514193, 'time_iter': 0.03359, 'accuracy': 0.9645, 'precision': 0.40476, 'recall': 0.26154, 'f1': 0.31776, 'auc': 0.75114}
2025-08-17 09:02:32,946 - INFO - > Epoch 85: took 77.5s (avg 78.1s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:03:40,785 - INFO - train: {'epoch': 86, 'time_epoch': 67.7578, 'eta': 899.22195, 'eta_hours': 0.24978, 'loss': 0.06402187, 'lr': 5.26e-06, 'params': 514193, 'time_iter': 0.06585, 'accuracy': 0.97991, 'precision': 0.83082, 'recall': 0.58198, 'f1': 0.68449, 'auc': 0.97126}
2025-08-17 09:03:45,038 - INFO - val: {'epoch': 86, 'time_epoch': 4.23187, 'loss': 0.12489711, 'lr': 0, 'params': 514193, 'time_iter': 0.03281, 'accuracy': 0.97398, 'precision': 0.35227, 'recall': 0.38272, 'f1': 0.36686, 'auc': 0.74089}
2025-08-17 09:03:49,353 - INFO - test: {'epoch': 86, 'time_epoch': 4.29819, 'loss': 0.19237966, 'lr': 0, 'params': 514193, 'time_iter': 0.03332, 'accuracy': 0.95964, 'precision': 0.32692, 'recall': 0.26154, 'f1': 0.2906, 'auc': 0.75132}
2025-08-17 09:03:49,356 - INFO - > Epoch 86: took 76.4s (avg 78.1s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:04:57,923 - INFO - train: {'epoch': 87, 'time_epoch': 68.48364, 'eta': 829.95731, 'eta_hours': 0.23054, 'loss': 0.06506992, 'lr': 4.55e-06, 'params': 514193, 'time_iter': 0.06655, 'accuracy': 0.9793, 'precision': 0.81558, 'recall': 0.57792, 'f1': 0.67648, 'auc': 0.97032}
2025-08-17 09:05:02,286 - INFO - val: {'epoch': 87, 'time_epoch': 4.34042, 'loss': 0.12821086, 'lr': 0, 'params': 514193, 'time_iter': 0.03365, 'accuracy': 0.97326, 'precision': 0.34066, 'recall': 0.38272, 'f1': 0.36047, 'auc': 0.73825}
2025-08-17 09:05:06,565 - INFO - test: {'epoch': 87, 'time_epoch': 4.18804, 'loss': 0.18765737, 'lr': 0, 'params': 514193, 'time_iter': 0.03247, 'accuracy': 0.95915, 'precision': 0.33333, 'recall': 0.29231, 'f1': 0.31148, 'auc': 0.75345}
2025-08-17 09:05:06,598 - INFO - > Epoch 87: took 77.2s (avg 78.1s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:06:14,435 - INFO - train: {'epoch': 88, 'time_epoch': 67.75276, 'eta': 760.61989, 'eta_hours': 0.21128, 'loss': 0.06613733, 'lr': 3.89e-06, 'params': 514193, 'time_iter': 0.06584, 'accuracy': 0.97927, 'precision': 0.82126, 'recall': 0.57062, 'f1': 0.67337, 'auc': 0.96785}
2025-08-17 09:06:18,955 - INFO - val: {'epoch': 88, 'time_epoch': 4.49705, 'loss': 0.12128968, 'lr': 0, 'params': 514193, 'time_iter': 0.03486, 'accuracy': 0.97569, 'precision': 0.38272, 'recall': 0.38272, 'f1': 0.38272, 'auc': 0.73475}
2025-08-17 09:06:23,368 - INFO - test: {'epoch': 88, 'time_epoch': 4.39559, 'loss': 0.18743704, 'lr': 0, 'params': 514193, 'time_iter': 0.03407, 'accuracy': 0.96086, 'precision': 0.34021, 'recall': 0.25385, 'f1': 0.29075, 'auc': 0.75052}
2025-08-17 09:06:23,372 - INFO - > Epoch 88: took 76.8s (avg 78.1s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:07:31,726 - INFO - train: {'epoch': 89, 'time_epoch': 68.26687, 'eta': 691.37481, 'eta_hours': 0.19205, 'loss': 0.06369658, 'lr': 3.27e-06, 'params': 514193, 'time_iter': 0.06634, 'accuracy': 0.97964, 'precision': 0.82299, 'recall': 0.58117, 'f1': 0.68126, 'auc': 0.97197}
2025-08-17 09:07:36,071 - INFO - val: {'epoch': 89, 'time_epoch': 4.32022, 'loss': 0.12649554, 'lr': 0, 'params': 514193, 'time_iter': 0.03349, 'accuracy': 0.97253, 'precision': 0.32979, 'recall': 0.38272, 'f1': 0.35429, 'auc': 0.74103}
2025-08-17 09:07:40,525 - INFO - test: {'epoch': 89, 'time_epoch': 4.43601, 'loss': 0.18571694, 'lr': 0, 'params': 514193, 'time_iter': 0.03439, 'accuracy': 0.95988, 'precision': 0.33945, 'recall': 0.28462, 'f1': 0.30962, 'auc': 0.75258}
2025-08-17 09:07:40,529 - INFO - > Epoch 89: took 77.2s (avg 78.1s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:08:49,651 - INFO - train: {'epoch': 90, 'time_epoch': 69.02657, 'eta': 622.22636, 'eta_hours': 0.17284, 'loss': 0.06667263, 'lr': 2.71e-06, 'params': 514193, 'time_iter': 0.06708, 'accuracy': 0.97915, 'precision': 0.82423, 'recall': 0.56331, 'f1': 0.66924, 'auc': 0.96842}
2025-08-17 09:08:54,123 - INFO - val: {'epoch': 90, 'time_epoch': 4.4478, 'loss': 0.12520542, 'lr': 0, 'params': 514193, 'time_iter': 0.03448, 'accuracy': 0.97423, 'precision': 0.35632, 'recall': 0.38272, 'f1': 0.36905, 'auc': 0.73756}
2025-08-17 09:08:58,578 - INFO - test: {'epoch': 90, 'time_epoch': 4.43697, 'loss': 0.19133494, 'lr': 0, 'params': 514193, 'time_iter': 0.0344, 'accuracy': 0.96086, 'precision': 0.34653, 'recall': 0.26923, 'f1': 0.30303, 'auc': 0.75109}
2025-08-17 09:08:58,582 - INFO - > Epoch 90: took 78.1s (avg 78.1s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:10:07,357 - INFO - train: {'epoch': 91, 'time_epoch': 68.68689, 'eta': 553.05102, 'eta_hours': 0.15363, 'loss': 0.06358869, 'lr': 2.2e-06, 'params': 514193, 'time_iter': 0.06675, 'accuracy': 0.97945, 'precision': 0.81448, 'recall': 0.58442, 'f1': 0.68053, 'auc': 0.97297}
2025-08-17 09:10:11,714 - INFO - val: {'epoch': 91, 'time_epoch': 4.32656, 'loss': 0.12405242, 'lr': 0, 'params': 514193, 'time_iter': 0.03354, 'accuracy': 0.97374, 'precision': 0.34831, 'recall': 0.38272, 'f1': 0.36471, 'auc': 0.74796}
2025-08-17 09:10:16,072 - INFO - test: {'epoch': 91, 'time_epoch': 4.34009, 'loss': 0.18961904, 'lr': 0, 'params': 514193, 'time_iter': 0.03364, 'accuracy': 0.96061, 'precision': 0.35185, 'recall': 0.29231, 'f1': 0.31933, 'auc': 0.75325}
2025-08-17 09:10:16,075 - INFO - > Epoch 91: took 77.5s (avg 78.1s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:11:24,642 - INFO - train: {'epoch': 92, 'time_epoch': 68.4867, 'eta': 483.87112, 'eta_hours': 0.13441, 'loss': 0.0640916, 'lr': 1.74e-06, 'params': 514193, 'time_iter': 0.06656, 'accuracy': 0.97885, 'precision': 0.81455, 'recall': 0.56331, 'f1': 0.66603, 'auc': 0.97319}
2025-08-17 09:11:28,992 - INFO - val: {'epoch': 92, 'time_epoch': 4.32725, 'loss': 0.12392268, 'lr': 0, 'params': 514193, 'time_iter': 0.03354, 'accuracy': 0.97253, 'precision': 0.32979, 'recall': 0.38272, 'f1': 0.35429, 'auc': 0.74554}
2025-08-17 09:11:33,382 - INFO - test: {'epoch': 92, 'time_epoch': 4.37058, 'loss': 0.18766496, 'lr': 0, 'params': 514193, 'time_iter': 0.03388, 'accuracy': 0.95964, 'precision': 0.33929, 'recall': 0.29231, 'f1': 0.31405, 'auc': 0.75602}
2025-08-17 09:11:33,384 - INFO - > Epoch 92: took 77.3s (avg 78.1s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:12:42,199 - INFO - train: {'epoch': 93, 'time_epoch': 68.732, 'eta': 414.72162, 'eta_hours': 0.1152, 'loss': 0.06532831, 'lr': 1.33e-06, 'params': 514193, 'time_iter': 0.06679, 'accuracy': 0.97918, 'precision': 0.82214, 'recall': 0.56656, 'f1': 0.67083, 'auc': 0.96954}
2025-08-17 09:12:46,638 - INFO - val: {'epoch': 93, 'time_epoch': 4.41631, 'loss': 0.12520524, 'lr': 0, 'params': 514193, 'time_iter': 0.03423, 'accuracy': 0.97228, 'precision': 0.32258, 'recall': 0.37037, 'f1': 0.34483, 'auc': 0.74468}
2025-08-17 09:12:51,095 - INFO - test: {'epoch': 93, 'time_epoch': 4.44006, 'loss': 0.19215987, 'lr': 0, 'params': 514193, 'time_iter': 0.03442, 'accuracy': 0.95842, 'precision': 0.32479, 'recall': 0.29231, 'f1': 0.30769, 'auc': 0.75101}
2025-08-17 09:12:51,097 - INFO - > Epoch 93: took 77.7s (avg 78.1s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:13:58,991 - INFO - train: {'epoch': 94, 'time_epoch': 67.81965, 'eta': 345.5329, 'eta_hours': 0.09598, 'loss': 0.06479895, 'lr': 9.8e-07, 'params': 514193, 'time_iter': 0.06591, 'accuracy': 0.97951, 'precision': 0.81633, 'recall': 0.58442, 'f1': 0.68117, 'auc': 0.97088}
2025-08-17 09:14:03,340 - INFO - val: {'epoch': 94, 'time_epoch': 4.32746, 'loss': 0.12612279, 'lr': 0, 'params': 514193, 'time_iter': 0.03355, 'accuracy': 0.97131, 'precision': 0.31313, 'recall': 0.38272, 'f1': 0.34444, 'auc': 0.74539}
2025-08-17 09:14:07,624 - INFO - test: {'epoch': 94, 'time_epoch': 4.26708, 'loss': 0.18671212, 'lr': 0, 'params': 514193, 'time_iter': 0.03308, 'accuracy': 0.95915, 'precision': 0.33036, 'recall': 0.28462, 'f1': 0.30579, 'auc': 0.75355}
2025-08-17 09:14:07,626 - INFO - > Epoch 94: took 76.5s (avg 78.0s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:15:15,546 - INFO - train: {'epoch': 95, 'time_epoch': 67.83008, 'eta': 276.37313, 'eta_hours': 0.07677, 'loss': 0.06206723, 'lr': 6.8e-07, 'params': 514193, 'time_iter': 0.06592, 'accuracy': 0.97997, 'precision': 0.82893, 'recall': 0.58604, 'f1': 0.68664, 'auc': 0.97447}
2025-08-17 09:15:19,915 - INFO - val: {'epoch': 95, 'time_epoch': 4.34575, 'loss': 0.12631132, 'lr': 0, 'params': 514193, 'time_iter': 0.03369, 'accuracy': 0.97423, 'precision': 0.35632, 'recall': 0.38272, 'f1': 0.36905, 'auc': 0.74271}
2025-08-17 09:15:24,311 - INFO - test: {'epoch': 95, 'time_epoch': 4.37889, 'loss': 0.19054886, 'lr': 0, 'params': 514193, 'time_iter': 0.03394, 'accuracy': 0.95964, 'precision': 0.33929, 'recall': 0.29231, 'f1': 0.31405, 'auc': 0.75546}
2025-08-17 09:15:24,314 - INFO - > Epoch 95: took 76.7s (avg 78.0s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:16:32,565 - INFO - train: {'epoch': 96, 'time_epoch': 68.16922, 'eta': 207.25127, 'eta_hours': 0.05757, 'loss': 0.06433864, 'lr': 4.4e-07, 'params': 514193, 'time_iter': 0.06625, 'accuracy': 0.98012, 'precision': 0.82472, 'recall': 0.59578, 'f1': 0.6918, 'auc': 0.97017}
2025-08-17 09:16:37,034 - INFO - val: {'epoch': 96, 'time_epoch': 4.44708, 'loss': 0.1228416, 'lr': 0, 'params': 514193, 'time_iter': 0.03447, 'accuracy': 0.97398, 'precision': 0.35227, 'recall': 0.38272, 'f1': 0.36686, 'auc': 0.74541}
2025-08-17 09:16:41,416 - INFO - test: {'epoch': 96, 'time_epoch': 4.36327, 'loss': 0.18749519, 'lr': 0, 'params': 514193, 'time_iter': 0.03382, 'accuracy': 0.95964, 'precision': 0.33929, 'recall': 0.29231, 'f1': 0.31405, 'auc': 0.75421}
2025-08-17 09:16:41,418 - INFO - > Epoch 96: took 77.1s (avg 78.0s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:17:50,966 - INFO - train: {'epoch': 97, 'time_epoch': 69.46301, 'eta': 138.17525, 'eta_hours': 0.03838, 'loss': 0.06635682, 'lr': 2.5e-07, 'params': 514193, 'time_iter': 0.06751, 'accuracy': 0.97918, 'precision': 0.82754, 'recall': 0.56088, 'f1': 0.6686, 'auc': 0.9677}
2025-08-17 09:17:55,335 - INFO - val: {'epoch': 97, 'time_epoch': 4.34556, 'loss': 0.12480127, 'lr': 0, 'params': 514193, 'time_iter': 0.03369, 'accuracy': 0.97398, 'precision': 0.35227, 'recall': 0.38272, 'f1': 0.36686, 'auc': 0.74626}
2025-08-17 09:17:59,680 - INFO - test: {'epoch': 97, 'time_epoch': 4.32859, 'loss': 0.18770883, 'lr': 0, 'params': 514193, 'time_iter': 0.03355, 'accuracy': 0.96086, 'precision': 0.35514, 'recall': 0.29231, 'f1': 0.32068, 'auc': 0.75614}
2025-08-17 09:17:59,683 - INFO - > Epoch 97: took 78.3s (avg 78.0s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:19:08,986 - INFO - train: {'epoch': 98, 'time_epoch': 69.19706, 'eta': 69.08873, 'eta_hours': 0.01919, 'loss': 0.06556208, 'lr': 1.1e-07, 'params': 514193, 'time_iter': 0.06725, 'accuracy': 0.97924, 'precision': 0.81734, 'recall': 0.57386, 'f1': 0.6743, 'auc': 0.97087}
2025-08-17 09:19:13,280 - INFO - val: {'epoch': 98, 'time_epoch': 4.27248, 'loss': 0.12583856, 'lr': 0, 'params': 514193, 'time_iter': 0.03312, 'accuracy': 0.97496, 'precision': 0.36905, 'recall': 0.38272, 'f1': 0.37576, 'auc': 0.74233}
2025-08-17 09:19:17,580 - INFO - test: {'epoch': 98, 'time_epoch': 4.28449, 'loss': 0.18901737, 'lr': 0, 'params': 514193, 'time_iter': 0.03321, 'accuracy': 0.96183, 'precision': 0.36082, 'recall': 0.26923, 'f1': 0.30837, 'auc': 0.75771}
2025-08-17 09:19:17,583 - INFO - > Epoch 98: took 77.9s (avg 78.0s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:20:26,844 - INFO - train: {'epoch': 99, 'time_epoch': 69.13915, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.06204018, 'lr': 3e-08, 'params': 514193, 'time_iter': 0.06719, 'accuracy': 0.98015, 'precision': 0.82786, 'recall': 0.59334, 'f1': 0.69125, 'auc': 0.97292}
2025-08-17 09:20:31,339 - INFO - val: {'epoch': 99, 'time_epoch': 4.45548, 'loss': 0.12889903, 'lr': 0, 'params': 514193, 'time_iter': 0.03454, 'accuracy': 0.97253, 'precision': 0.32979, 'recall': 0.38272, 'f1': 0.35429, 'auc': 0.73874}
2025-08-17 09:20:35,841 - INFO - test: {'epoch': 99, 'time_epoch': 4.48403, 'loss': 0.19312077, 'lr': 0, 'params': 514193, 'time_iter': 0.03476, 'accuracy': 0.96013, 'precision': 0.35088, 'recall': 0.30769, 'f1': 0.32787, 'auc': 0.75098}
2025-08-17 09:20:36,101 - INFO - > Epoch 99: took 78.3s (avg 78.0s) | Best so far: epoch 23	train_loss: 0.1076 train_auc: 0.8591	val_loss: 0.0836 val_auc: 0.7871	test_loss: 0.1235 test_auc: 0.7544
2025-08-17 09:20:36,101 - INFO - Avg time per epoch: 78.02s
2025-08-17 09:20:36,101 - INFO - Total train loop time: 2.17h
2025-08-17 09:20:36,172 - INFO - ============================================================
2025-08-17 09:20:36,172 - INFO - Starting PK-Explainer Analysis (Enhanced Version)
2025-08-17 09:20:36,172 - INFO - ============================================================
2025-08-17 09:20:36,172 - INFO - Dataset: ogbg-molhiv
2025-08-17 09:20:36,172 - INFO - Model type: VanillaModel
2025-08-17 09:20:36,172 - INFO - GNN types available: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-17 09:20:36,215 - INFO - Saved model state to results/molhiv/molhiv-Vanilla-49/model_for_ablation.pt
2025-08-17 09:20:36,215 - INFO - 
Performing ablation study...
2025-08-17 09:20:36,278 - INFO - Getting baseline performance...
2025-08-17 09:20:36,310 - WARNING - Could not extract GNN mapping from optimal weights, attempting to infer from layers...
2025-08-17 09:20:36,310 - INFO - Final GNN mapping: {}
2025-08-17 09:20:40,767 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44095, 'loss': 0.19312077, 'lr': 0, 'params': 514193, 'time_iter': 0.03443, 'accuracy': 0.96013, 'precision': 0.35088, 'recall': 0.30769, 'f1': 0.32787, 'auc': 0.75098}
2025-08-17 09:20:40,770 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:20:40,770 - INFO - Baseline auc: 0.7510
2025-08-17 09:20:45,187 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36761, 'loss': 0.20224123, 'lr': 0, 'params': 514193, 'time_iter': 0.03386, 'accuracy': 0.95575, 'precision': 0.30303, 'recall': 0.30769, 'f1': 0.30534, 'auc': 0.74204}
2025-08-17 09:20:45,260 - INFO - ...computing epoch stats took: 0.09s
2025-08-17 09:20:45,261 - INFO - Layer 0 (Layer_0), Head 0: drop=0.0119
2025-08-17 09:20:49,686 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36799, 'loss': 0.19950158, 'lr': 0, 'params': 514193, 'time_iter': 0.03386, 'accuracy': 0.95745, 'precision': 0.31707, 'recall': 0.3, 'f1': 0.3083, 'auc': 0.75742}
2025-08-17 09:20:49,688 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:20:49,688 - INFO - Layer 0 (Layer_0), Head 1: drop=-0.0086
2025-08-17 09:20:54,107 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36984, 'loss': 0.19830185, 'lr': 0, 'params': 514193, 'time_iter': 0.03387, 'accuracy': 0.95624, 'precision': 0.30159, 'recall': 0.29231, 'f1': 0.29688, 'auc': 0.74067}
2025-08-17 09:20:54,109 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:20:54,109 - INFO - Layer 0 (Layer_0), Head 2: drop=0.0137
2025-08-17 09:20:58,523 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36499, 'loss': 0.19668208, 'lr': 0, 'params': 514193, 'time_iter': 0.03384, 'accuracy': 0.95697, 'precision': 0.31496, 'recall': 0.30769, 'f1': 0.31128, 'auc': 0.75439}
2025-08-17 09:20:58,536 - INFO - ...computing epoch stats took: 0.03s
2025-08-17 09:20:58,536 - INFO - Layer 0 (Layer_0), Head 3: drop=-0.0045
2025-08-17 09:21:02,946 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36198, 'loss': 0.19056766, 'lr': 0, 'params': 514193, 'time_iter': 0.03381, 'accuracy': 0.95624, 'precision': 0.31061, 'recall': 0.31538, 'f1': 0.31298, 'auc': 0.76288}
2025-08-17 09:21:02,947 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:21:02,948 - INFO - Layer 1 (Layer_1), Head 0: drop=-0.0158
2025-08-17 09:21:07,354 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35672, 'loss': 0.20131871, 'lr': 0, 'params': 514193, 'time_iter': 0.03377, 'accuracy': 0.95308, 'precision': 0.28571, 'recall': 0.32308, 'f1': 0.30325, 'auc': 0.74175}
2025-08-17 09:21:07,357 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:21:07,357 - INFO - Layer 1 (Layer_1), Head 1: drop=0.0123
2025-08-17 09:21:11,752 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3466, 'loss': 0.19499037, 'lr': 0, 'params': 514193, 'time_iter': 0.03369, 'accuracy': 0.95818, 'precision': 0.32203, 'recall': 0.29231, 'f1': 0.30645, 'auc': 0.74679}
2025-08-17 09:21:11,755 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:21:11,755 - INFO - Layer 1 (Layer_1), Head 2: drop=0.0056
2025-08-17 09:21:16,167 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36225, 'loss': 0.19219483, 'lr': 0, 'params': 514193, 'time_iter': 0.03382, 'accuracy': 0.95599, 'precision': 0.31655, 'recall': 0.33846, 'f1': 0.32714, 'auc': 0.75485}
2025-08-17 09:21:16,170 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:21:16,170 - INFO - Layer 1 (Layer_1), Head 3: drop=-0.0052
2025-08-17 09:21:20,585 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3663, 'loss': 0.1960191, 'lr': 0, 'params': 514193, 'time_iter': 0.03385, 'accuracy': 0.95259, 'precision': 0.28188, 'recall': 0.32308, 'f1': 0.30108, 'auc': 0.75055}
2025-08-17 09:21:20,590 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:21:20,590 - INFO - Layer 2 (Layer_2), Head 0: drop=0.0006
2025-08-17 09:21:25,001 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3609, 'loss': 0.19822594, 'lr': 0, 'params': 514193, 'time_iter': 0.03381, 'accuracy': 0.96013, 'precision': 0.34821, 'recall': 0.3, 'f1': 0.32231, 'auc': 0.74238}
2025-08-17 09:21:25,003 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:21:25,003 - INFO - Layer 2 (Layer_2), Head 1: drop=0.0115
2025-08-17 09:21:29,409 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35828, 'loss': 0.19535394, 'lr': 0, 'params': 514193, 'time_iter': 0.03379, 'accuracy': 0.9577, 'precision': 0.31356, 'recall': 0.28462, 'f1': 0.29839, 'auc': 0.75118}
2025-08-17 09:21:29,412 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:21:29,412 - INFO - Layer 2 (Layer_2), Head 2: drop=-0.0003
2025-08-17 09:21:33,837 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.37629, 'loss': 0.19350794, 'lr': 0, 'params': 514193, 'time_iter': 0.03392, 'accuracy': 0.95721, 'precision': 0.32308, 'recall': 0.32308, 'f1': 0.32308, 'auc': 0.7481}
2025-08-17 09:21:33,840 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:21:33,840 - INFO - Layer 2 (Layer_2), Head 3: drop=0.0038
2025-08-17 09:21:38,254 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36647, 'loss': 0.19227264, 'lr': 0, 'params': 514193, 'time_iter': 0.03385, 'accuracy': 0.95988, 'precision': 0.35537, 'recall': 0.33077, 'f1': 0.34263, 'auc': 0.74678}
2025-08-17 09:21:38,257 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:21:38,257 - INFO - Layer 3 (Layer_3), Head 0: drop=0.0056
2025-08-17 09:21:42,688 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.38248, 'loss': 0.18768211, 'lr': 0, 'params': 514193, 'time_iter': 0.03397, 'accuracy': 0.95721, 'precision': 0.33333, 'recall': 0.35385, 'f1': 0.34328, 'auc': 0.75748}
2025-08-17 09:21:42,690 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:21:42,690 - INFO - Layer 3 (Layer_3), Head 1: drop=-0.0087
2025-08-17 09:21:47,075 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33654, 'loss': 0.18556465, 'lr': 0, 'params': 514193, 'time_iter': 0.03362, 'accuracy': 0.95842, 'precision': 0.33858, 'recall': 0.33077, 'f1': 0.33463, 'auc': 0.75806}
2025-08-17 09:21:47,077 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:21:47,077 - INFO - Layer 3 (Layer_3), Head 2: drop=-0.0094
2025-08-17 09:21:51,530 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40301, 'loss': 0.18695664, 'lr': 0, 'params': 514193, 'time_iter': 0.03413, 'accuracy': 0.95915, 'precision': 0.32407, 'recall': 0.26923, 'f1': 0.29412, 'auc': 0.76023}
2025-08-17 09:21:51,532 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:21:51,532 - INFO - Layer 3 (Layer_3), Head 3: drop=-0.0123
2025-08-17 09:21:55,945 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36454, 'loss': 0.19171119, 'lr': 0, 'params': 514193, 'time_iter': 0.03383, 'accuracy': 0.95891, 'precision': 0.344, 'recall': 0.33077, 'f1': 0.33725, 'auc': 0.75006}
2025-08-17 09:21:55,947 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:21:55,947 - INFO - Layer 4 (Layer_4), Head 0: drop=0.0012
2025-08-17 09:22:00,386 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.38927, 'loss': 0.19493746, 'lr': 0, 'params': 514193, 'time_iter': 0.03403, 'accuracy': 0.96159, 'precision': 0.37037, 'recall': 0.30769, 'f1': 0.33613, 'auc': 0.74362}
2025-08-17 09:22:00,388 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:22:00,388 - INFO - Layer 4 (Layer_4), Head 1: drop=0.0098
2025-08-17 09:22:04,780 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34319, 'loss': 0.21859034, 'lr': 0, 'params': 514193, 'time_iter': 0.03367, 'accuracy': 0.94141, 'precision': 0.22388, 'recall': 0.34615, 'f1': 0.2719, 'auc': 0.74961}
2025-08-17 09:22:04,782 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:22:04,782 - INFO - Layer 4 (Layer_4), Head 2: drop=0.0018
2025-08-17 09:22:09,215 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.38259, 'loss': 0.19916209, 'lr': 0, 'params': 514193, 'time_iter': 0.03397, 'accuracy': 0.95745, 'precision': 0.31707, 'recall': 0.3, 'f1': 0.3083, 'auc': 0.74659}
2025-08-17 09:22:09,217 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:22:09,217 - INFO - Layer 4 (Layer_4), Head 3: drop=0.0058
2025-08-17 09:22:13,614 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34815, 'loss': 0.19637485, 'lr': 0, 'params': 514193, 'time_iter': 0.03371, 'accuracy': 0.95721, 'precision': 0.32576, 'recall': 0.33077, 'f1': 0.32824, 'auc': 0.75355}
2025-08-17 09:22:13,616 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:22:13,616 - INFO - Layer 5 (Layer_5), Head 0: drop=-0.0034
2025-08-17 09:22:18,026 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35928, 'loss': 0.20297255, 'lr': 0, 'params': 514193, 'time_iter': 0.03379, 'accuracy': 0.94991, 'precision': 0.27907, 'recall': 0.36923, 'f1': 0.31788, 'auc': 0.75002}
2025-08-17 09:22:18,028 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:22:18,028 - INFO - Layer 5 (Layer_5), Head 1: drop=0.0013
2025-08-17 09:22:22,375 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2976, 'loss': 0.19019415, 'lr': 0, 'params': 514193, 'time_iter': 0.03331, 'accuracy': 0.95697, 'precision': 0.31496, 'recall': 0.30769, 'f1': 0.31128, 'auc': 0.75458}
2025-08-17 09:22:22,377 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:22:22,377 - INFO - Layer 5 (Layer_5), Head 2: drop=-0.0048
2025-08-17 09:22:26,733 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.30814, 'loss': 0.1930442, 'lr': 0, 'params': 514193, 'time_iter': 0.0334, 'accuracy': 0.95891, 'precision': 0.33884, 'recall': 0.31538, 'f1': 0.32669, 'auc': 0.74929}
2025-08-17 09:22:26,735 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:22:26,735 - INFO - Layer 5 (Layer_5), Head 3: drop=0.0023
2025-08-17 09:22:31,075 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29288, 'loss': 0.18445138, 'lr': 0, 'params': 514193, 'time_iter': 0.03328, 'accuracy': 0.96086, 'precision': 0.35514, 'recall': 0.29231, 'f1': 0.32068, 'auc': 0.75497}
2025-08-17 09:22:31,078 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:22:31,078 - INFO - Layer 6 (Layer_6), Head 0: drop=-0.0053
2025-08-17 09:22:35,419 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2924, 'loss': 0.19530458, 'lr': 0, 'params': 514193, 'time_iter': 0.03327, 'accuracy': 0.95818, 'precision': 0.3125, 'recall': 0.26923, 'f1': 0.28926, 'auc': 0.7406}
2025-08-17 09:22:35,420 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:22:35,420 - INFO - Layer 6 (Layer_6), Head 1: drop=0.0138
2025-08-17 09:22:39,705 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23643, 'loss': 0.18859583, 'lr': 0, 'params': 514193, 'time_iter': 0.03284, 'accuracy': 0.96159, 'precision': 0.36792, 'recall': 0.3, 'f1': 0.33051, 'auc': 0.75292}
2025-08-17 09:22:39,707 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:22:39,707 - INFO - Layer 6 (Layer_6), Head 2: drop=-0.0026
2025-08-17 09:22:43,997 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24335, 'loss': 0.18209166, 'lr': 0, 'params': 514193, 'time_iter': 0.03289, 'accuracy': 0.95648, 'precision': 0.304, 'recall': 0.29231, 'f1': 0.29804, 'auc': 0.75367}
2025-08-17 09:22:43,999 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:22:43,999 - INFO - Layer 6 (Layer_6), Head 3: drop=-0.0036
2025-08-17 09:22:48,293 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24799, 'loss': 0.19748799, 'lr': 0, 'params': 514193, 'time_iter': 0.03293, 'accuracy': 0.95818, 'precision': 0.33065, 'recall': 0.31538, 'f1': 0.32283, 'auc': 0.74466}
2025-08-17 09:22:48,295 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:22:48,295 - INFO - Layer 7 (Layer_7), Head 0: drop=0.0084
2025-08-17 09:22:52,578 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23617, 'loss': 0.1922041, 'lr': 0, 'params': 514193, 'time_iter': 0.03284, 'accuracy': 0.95988, 'precision': 0.3301, 'recall': 0.26154, 'f1': 0.29185, 'auc': 0.74841}
2025-08-17 09:22:52,579 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:22:52,580 - INFO - Layer 7 (Layer_7), Head 1: drop=0.0034
2025-08-17 09:22:56,910 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.28215, 'loss': 0.18772646, 'lr': 0, 'params': 514193, 'time_iter': 0.03319, 'accuracy': 0.95867, 'precision': 0.33333, 'recall': 0.30769, 'f1': 0.32, 'auc': 0.76125}
2025-08-17 09:22:56,912 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:22:56,912 - INFO - Layer 7 (Layer_7), Head 2: drop=-0.0137
2025-08-17 09:23:01,189 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22906, 'loss': 0.1857662, 'lr': 0, 'params': 514193, 'time_iter': 0.03278, 'accuracy': 0.96037, 'precision': 0.35135, 'recall': 0.3, 'f1': 0.32365, 'auc': 0.75202}
2025-08-17 09:23:01,191 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:23:01,191 - INFO - Layer 7 (Layer_7), Head 3: drop=-0.0014
2025-08-17 09:23:05,488 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24988, 'loss': 0.18102763, 'lr': 0, 'params': 514193, 'time_iter': 0.03294, 'accuracy': 0.96183, 'precision': 0.36364, 'recall': 0.27692, 'f1': 0.31441, 'auc': 0.75745}
2025-08-17 09:23:05,490 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:23:05,490 - INFO - Layer 8 (Layer_8), Head 0: drop=-0.0086
2025-08-17 09:23:09,730 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.19437, 'loss': 0.18626336, 'lr': 0, 'params': 514193, 'time_iter': 0.03251, 'accuracy': 0.96159, 'precision': 0.37037, 'recall': 0.30769, 'f1': 0.33613, 'auc': 0.7502}
2025-08-17 09:23:09,733 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:23:09,733 - INFO - Layer 8 (Layer_8), Head 1: drop=0.0010
2025-08-17 09:23:14,031 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25121, 'loss': 0.18835539, 'lr': 0, 'params': 514193, 'time_iter': 0.03296, 'accuracy': 0.96207, 'precision': 0.37736, 'recall': 0.30769, 'f1': 0.33898, 'auc': 0.75217}
2025-08-17 09:23:14,033 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:23:14,033 - INFO - Layer 8 (Layer_8), Head 2: drop=-0.0016
2025-08-17 09:23:18,293 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21227, 'loss': 0.18837645, 'lr': 0, 'params': 514193, 'time_iter': 0.03265, 'accuracy': 0.96086, 'precision': 0.3578, 'recall': 0.3, 'f1': 0.32636, 'auc': 0.75297}
2025-08-17 09:23:18,297 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:23:18,297 - INFO - Layer 8 (Layer_8), Head 3: drop=-0.0026
2025-08-17 09:23:22,581 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23717, 'loss': 0.18432134, 'lr': 0, 'params': 514193, 'time_iter': 0.03285, 'accuracy': 0.96134, 'precision': 0.35644, 'recall': 0.27692, 'f1': 0.31169, 'auc': 0.75265}
2025-08-17 09:23:22,583 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:23:22,583 - INFO - Layer 9 (Layer_9), Head 0: drop=-0.0022
2025-08-17 09:23:26,887 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25658, 'loss': 0.19312348, 'lr': 0, 'params': 514193, 'time_iter': 0.033, 'accuracy': 0.95988, 'precision': 0.34783, 'recall': 0.30769, 'f1': 0.32653, 'auc': 0.7467}
2025-08-17 09:23:26,889 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:23:26,889 - INFO - Layer 9 (Layer_9), Head 1: drop=0.0057
2025-08-17 09:23:31,314 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.37566, 'loss': 0.18800879, 'lr': 0, 'params': 514193, 'time_iter': 0.03392, 'accuracy': 0.96183, 'precision': 0.36364, 'recall': 0.27692, 'f1': 0.31441, 'auc': 0.74937}
2025-08-17 09:23:31,317 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:23:31,317 - INFO - Layer 9 (Layer_9), Head 2: drop=0.0021
2025-08-17 09:23:35,684 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.31991, 'loss': 0.19348596, 'lr': 0, 'params': 514193, 'time_iter': 0.03349, 'accuracy': 0.96013, 'precision': 0.35345, 'recall': 0.31538, 'f1': 0.33333, 'auc': 0.75049}
2025-08-17 09:23:35,686 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:23:35,686 - INFO - Layer 9 (Layer_9), Head 3: drop=0.0007
2025-08-17 09:23:39,967 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2327, 'loss': 0.19142633, 'lr': 0, 'params': 514193, 'time_iter': 0.03281, 'accuracy': 0.95964, 'precision': 0.34483, 'recall': 0.30769, 'f1': 0.3252, 'auc': 0.75389}
2025-08-17 09:23:39,972 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:23:39,972 - INFO - Layer 10 (Layer_10), Head 0: drop=-0.0039
2025-08-17 09:23:44,334 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.31544, 'loss': 0.19049131, 'lr': 0, 'params': 514193, 'time_iter': 0.03345, 'accuracy': 0.9611, 'precision': 0.36111, 'recall': 0.3, 'f1': 0.32773, 'auc': 0.74742}
2025-08-17 09:23:44,336 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:23:44,336 - INFO - Layer 10 (Layer_10), Head 1: drop=0.0047
2025-08-17 09:23:48,673 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29007, 'loss': 0.19517348, 'lr': 0, 'params': 514193, 'time_iter': 0.03326, 'accuracy': 0.96061, 'precision': 0.35714, 'recall': 0.30769, 'f1': 0.33058, 'auc': 0.74814}
2025-08-17 09:23:48,676 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:23:48,676 - INFO - Layer 10 (Layer_10), Head 2: drop=0.0038
2025-08-17 09:23:53,017 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29434, 'loss': 0.18495472, 'lr': 0, 'params': 514193, 'time_iter': 0.03329, 'accuracy': 0.96013, 'precision': 0.34821, 'recall': 0.3, 'f1': 0.32231, 'auc': 0.75746}
2025-08-17 09:23:53,019 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:23:53,019 - INFO - Layer 10 (Layer_10), Head 3: drop=-0.0086
2025-08-17 09:23:57,392 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32576, 'loss': 0.18928482, 'lr': 0, 'params': 514193, 'time_iter': 0.03353, 'accuracy': 0.9611, 'precision': 0.35849, 'recall': 0.29231, 'f1': 0.32203, 'auc': 0.74869}
2025-08-17 09:23:57,394 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:23:57,394 - INFO - Layer 11 (Layer_11), Head 0: drop=0.0030
2025-08-17 09:24:01,710 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26879, 'loss': 0.18691894, 'lr': 0, 'params': 514193, 'time_iter': 0.03309, 'accuracy': 0.96061, 'precision': 0.35185, 'recall': 0.29231, 'f1': 0.31933, 'auc': 0.75378}
2025-08-17 09:24:01,712 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:24:01,712 - INFO - Layer 11 (Layer_11), Head 1: drop=-0.0037
2025-08-17 09:24:06,060 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29971, 'loss': 0.19011581, 'lr': 0, 'params': 514193, 'time_iter': 0.03333, 'accuracy': 0.95964, 'precision': 0.35, 'recall': 0.32308, 'f1': 0.336, 'auc': 0.75408}
2025-08-17 09:24:06,062 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:24:06,062 - INFO - Layer 11 (Layer_11), Head 2: drop=-0.0041
2025-08-17 09:24:10,427 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.31747, 'loss': 0.18603214, 'lr': 0, 'params': 514193, 'time_iter': 0.03347, 'accuracy': 0.96037, 'precision': 0.34862, 'recall': 0.29231, 'f1': 0.31799, 'auc': 0.7534}
2025-08-17 09:24:10,429 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:24:10,430 - INFO - Layer 11 (Layer_11), Head 3: drop=-0.0032
2025-08-17 09:24:14,727 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25083, 'loss': 0.18727888, 'lr': 0, 'params': 514193, 'time_iter': 0.03295, 'accuracy': 0.96037, 'precision': 0.35398, 'recall': 0.30769, 'f1': 0.32922, 'auc': 0.75499}
2025-08-17 09:24:14,729 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:24:14,729 - INFO - Layer 12 (Layer_12), Head 0: drop=-0.0053
2025-08-17 09:24:19,012 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23594, 'loss': 0.18982197, 'lr': 0, 'params': 514193, 'time_iter': 0.03284, 'accuracy': 0.96061, 'precision': 0.35185, 'recall': 0.29231, 'f1': 0.31933, 'auc': 0.7497}
2025-08-17 09:24:19,014 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:24:19,014 - INFO - Layer 12 (Layer_12), Head 1: drop=0.0017
2025-08-17 09:24:23,339 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27754, 'loss': 0.18253789, 'lr': 0, 'params': 514193, 'time_iter': 0.03316, 'accuracy': 0.96134, 'precision': 0.3619, 'recall': 0.29231, 'f1': 0.3234, 'auc': 0.75124}
2025-08-17 09:24:23,340 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:24:23,340 - INFO - Layer 12 (Layer_12), Head 2: drop=-0.0003
2025-08-17 09:24:27,693 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.30561, 'loss': 0.18751644, 'lr': 0, 'params': 514193, 'time_iter': 0.03338, 'accuracy': 0.95964, 'precision': 0.33929, 'recall': 0.29231, 'f1': 0.31405, 'auc': 0.75079}
2025-08-17 09:24:27,696 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:24:27,696 - INFO - Layer 12 (Layer_12), Head 3: drop=0.0003
2025-08-17 09:24:32,021 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27863, 'loss': 0.18664387, 'lr': 0, 'params': 514193, 'time_iter': 0.03317, 'accuracy': 0.96037, 'precision': 0.34862, 'recall': 0.29231, 'f1': 0.31799, 'auc': 0.75069}
2025-08-17 09:24:32,024 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:24:32,024 - INFO - Layer 13 (Layer_13), Head 0: drop=0.0004
2025-08-17 09:24:36,364 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29153, 'loss': 0.18494346, 'lr': 0, 'params': 514193, 'time_iter': 0.03327, 'accuracy': 0.96061, 'precision': 0.35185, 'recall': 0.29231, 'f1': 0.31933, 'auc': 0.75372}
2025-08-17 09:24:36,366 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:24:36,366 - INFO - Layer 13 (Layer_13), Head 1: drop=-0.0036
2025-08-17 09:24:40,704 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.28917, 'loss': 0.18428032, 'lr': 0, 'params': 514193, 'time_iter': 0.03325, 'accuracy': 0.96159, 'precision': 0.36275, 'recall': 0.28462, 'f1': 0.31897, 'auc': 0.75259}
2025-08-17 09:24:40,707 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 09:24:40,707 - INFO - Layer 13 (Layer_13), Head 2: drop=-0.0021
2025-08-17 09:24:45,067 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.31226, 'loss': 0.19033136, 'lr': 0, 'params': 514193, 'time_iter': 0.03343, 'accuracy': 0.96037, 'precision': 0.34862, 'recall': 0.29231, 'f1': 0.31799, 'auc': 0.74517}
2025-08-17 09:24:45,070 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:24:45,070 - INFO - Layer 13 (Layer_13), Head 3: drop=0.0077
2025-08-17 09:24:49,414 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29709, 'loss': 0.18539014, 'lr': 0, 'params': 514193, 'time_iter': 0.03331, 'accuracy': 0.96086, 'precision': 0.35238, 'recall': 0.28462, 'f1': 0.31489, 'auc': 0.74677}
2025-08-17 09:24:49,416 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:24:49,416 - INFO - Layer 14 (Layer_14), Head 0: drop=0.0056
2025-08-17 09:24:53,796 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33147, 'loss': 0.18377213, 'lr': 0, 'params': 514193, 'time_iter': 0.03358, 'accuracy': 0.96061, 'precision': 0.34906, 'recall': 0.28462, 'f1': 0.31356, 'auc': 0.75157}
2025-08-17 09:24:53,798 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:24:53,798 - INFO - Layer 14 (Layer_14), Head 1: drop=-0.0008
2025-08-17 09:24:58,230 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.38178, 'loss': 0.18614926, 'lr': 0, 'params': 514193, 'time_iter': 0.03397, 'accuracy': 0.9611, 'precision': 0.35577, 'recall': 0.28462, 'f1': 0.31624, 'auc': 0.75174}
2025-08-17 09:24:58,231 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:24:58,232 - INFO - Layer 14 (Layer_14), Head 2: drop=-0.0010
2025-08-17 09:25:02,588 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.30835, 'loss': 0.18153681, 'lr': 0, 'params': 514193, 'time_iter': 0.0334, 'accuracy': 0.9611, 'precision': 0.35577, 'recall': 0.28462, 'f1': 0.31624, 'auc': 0.75097}
2025-08-17 09:25:02,589 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 09:25:02,589 - INFO - Layer 14 (Layer_14), Head 3: drop=0.0000
2025-08-17 09:25:02,594 - INFO - 
FIDELITY METRICS:
2025-08-17 09:25:02,594 - INFO - Fidelity (top 30 heads): 0.0050
2025-08-17 09:25:02,595 - INFO - Fidelity- (bottom 30 heads): -0.0050
2025-08-17 09:25:02,595 - INFO - 
GNN distribution in important heads:
2025-08-17 09:25:02,595 - INFO -   Layer_4: 4 heads
2025-08-17 09:25:02,595 - INFO -   Layer_2: 3 heads
2025-08-17 09:25:02,595 - INFO -   Layer_9: 3 heads
2025-08-17 09:25:02,595 - INFO -   Layer_0: 2 heads
2025-08-17 09:25:02,595 - INFO -   Layer_1: 2 heads
2025-08-17 09:25:02,595 - INFO -   Layer_7: 2 heads
2025-08-17 09:25:02,595 - INFO -   Layer_13: 2 heads
2025-08-17 09:25:02,595 - INFO -   Layer_14: 2 heads
2025-08-17 09:25:02,595 - INFO -   Layer_10: 2 heads
2025-08-17 09:25:02,595 - INFO -   Layer_5: 2 heads
2025-08-17 09:25:02,595 - INFO -   Layer_12: 2 heads
2025-08-17 09:25:02,595 - INFO -   Layer_6: 1 heads
2025-08-17 09:25:02,595 - INFO -   Layer_3: 1 heads
2025-08-17 09:25:02,595 - INFO -   Layer_11: 1 heads
2025-08-17 09:25:02,595 - INFO -   Layer_8: 1 heads
2025-08-17 09:25:02,595 - INFO - 
Interpretability Analysis:
2025-08-17 09:25:02,595 - INFO -   Fidelity: 0.0050
2025-08-17 09:25:02,595 - INFO -   Fidelity-: -0.0050
2025-08-17 09:25:02,595 - INFO -   Total heads tested: 60
2025-08-17 09:25:02,920 - INFO - Excel results saved to results/molhiv/molhiv-Vanilla-49/pk_explainer_results.xlsx
2025-08-17 09:25:04,310 - INFO - Saved visualizations to results/molhiv/molhiv-Vanilla-49/pk_explainer_results
2025-08-17 09:25:04,449 - INFO - 
PK-Explainer results saved to:
2025-08-17 09:25:04,449 - INFO -   - Excel: results/molhiv/molhiv-Vanilla-49/pk_explainer_results.xlsx
2025-08-17 09:25:04,450 - INFO -   - JSON: results/molhiv/molhiv-Vanilla-49/pk_explainer_results.json
2025-08-17 09:25:04,450 - INFO -   - Visualizations: results/molhiv/molhiv-Vanilla-49/pk_explainer_results
2025-08-17 09:25:04,468 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-49
2025-08-17 09:25:04,468 - INFO - Total time: 8237.68s (2.29h)
2025-08-17 09:25:04,543 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-49/agg
2025-08-17 09:25:04,543 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-17 09:25:04,543 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-49
2025-08-17 09:25:04,543 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-49/test_results/
Completed seed 49. Results saved in results/molhiv/molhiv-Vanilla-49
----------------------------------------
All experiments completed!
