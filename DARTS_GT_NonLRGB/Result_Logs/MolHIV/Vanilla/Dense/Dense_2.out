Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          376Gi        18Gi       340Gi       1.4Gi        17Gi       353Gi
Swap:         1.9Gi       657Mi       1.2Gi
Sat Aug 16 02:57:13 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:1D:00.0 Off |                    0 |
| N/A   31C    P0             41W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 41
Starting training for seed 41...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/TRANS
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/TRANS/confignas.yaml
Using device: cuda
2025-08-16 02:57:22,509 - INFO - GPU Mem: 34.1GB
2025-08-16 02:57:22,509 - INFO - Run directory: results/molhiv/molhiv-Vanilla-41
2025-08-16 02:57:22,509 - INFO - Seed: 41
2025-08-16 02:57:22,510 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-16 02:57:22,510 - INFO - Routing mode: none
2025-08-16 02:57:22,510 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 02:57:22,510 - INFO - Number of layers: 15
2025-08-16 02:57:22,510 - INFO - Uncertainty enabled: False
2025-08-16 02:57:22,510 - INFO - Training mode: custom
2025-08-16 02:57:22,510 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-16 02:57:22,510 - INFO - Additional features: Router weights logging + JSON export
Downloading http://snap.stanford.edu/ogb/data/graphproppred/csv_mol_download/hiv.zip
  0%|          | 0/3 [00:00<?, ?it/s]Downloaded 0.00 GB:   0%|          | 0/3 [00:02<?, ?it/s]Downloaded 0.00 GB:  33%|███▎      | 1/3 [00:02<00:04,  2.00s/it]Downloaded 0.00 GB:  33%|███▎      | 1/3 [00:02<00:04,  2.00s/it]Downloaded 0.00 GB:  67%|██████▋   | 2/3 [00:02<00:01,  1.19s/it]Downloaded 0.00 GB:  67%|██████▋   | 2/3 [00:02<00:01,  1.19s/it]Downloaded 0.00 GB: 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]
Extracting ./datasets/hiv.zip
Processing...
Loading necessary files...
This might take a while.
Processing graphs...
  0%|          | 0/41127 [00:00<?, ?it/s] 28%|██▊       | 11456/41127 [00:00<00:00, 114542.09it/s] 56%|█████▌    | 22911/41127 [00:00<00:00, 112136.99it/s] 83%|████████▎ | 34129/41127 [00:00<00:00, 108842.49it/s]100%|██████████| 41127/41127 [00:00<00:00, 108350.12it/s]
Converting graphs into PyG objects...
  0%|          | 0/41127 [00:00<?, ?it/s]  3%|▎         | 1305/41127 [00:00<00:06, 5827.56it/s] 15%|█▍        | 6005/41127 [00:00<00:01, 21861.87it/s] 26%|██▌       | 10717/41127 [00:00<00:00, 30888.98it/s] 35%|███▌      | 14501/41127 [00:00<00:01, 22561.10it/s] 47%|████▋     | 19213/41127 [00:00<00:00, 28622.81it/s] 58%|█████▊    | 23705/41127 [00:00<00:00, 32869.92it/s] 67%|██████▋   | 27583/41127 [00:01<00:00, 23149.33it/s] 78%|███████▊  | 32042/41127 [00:01<00:00, 27577.14it/s] 89%|████████▊ | 36463/41127 [00:01<00:00, 31365.25it/s] 99%|█████████▉| 40855/41127 [00:01<00:00, 34447.06it/s]100%|██████████| 41127/41127 [00:01<00:00, 28346.88it/s]
Saving...
Done!
2025-08-16 02:57:39,698 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 02:57:39,700 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 02:57:39,702 - INFO -   undirected: True
2025-08-16 02:57:39,702 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 02:57:39,702 - INFO -   avg num_nodes/graph: 25
2025-08-16 02:57:39,702 - INFO -   num node features: 9
2025-08-16 02:57:39,703 - INFO -   num edge features: 3
2025-08-16 02:57:39,703 - INFO -   num tasks: 1
2025-08-16 02:57:39,703 - INFO -   num classes: 2
2025-08-16 02:57:39,703 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 02:57:39,703 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 02:57:39,706 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 19%|█▊        | 7697/41127 [00:10<00:43, 769.67it/s] 37%|███▋      | 15121/41127 [00:20<00:34, 753.63it/s] 55%|█████▌    | 22719/41127 [00:30<00:24, 756.44it/s] 73%|███████▎  | 30069/41127 [00:40<00:14, 747.97it/s] 91%|█████████ | 37326/41127 [00:50<00:05, 739.93it/s]100%|██████████| 41127/41127 [00:55<00:00, 746.78it/s]
2025-08-16 02:58:35,786 - INFO - Done! Took 00:00:56.08
2025-08-16 02:58:35,936 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 02:58:36,059 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-16 02:58:36,059 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-08-16 02:58:36,059 - INFO - Inner model has get_darts_model: False
2025-08-16 02:58:36,061 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-08-16 02:58:36,063 - INFO - Number of parameters: 514,193
2025-08-16 02:58:36,064 - INFO - Starting optimized training: 2025-08-16 02:58:36.063995
2025-08-16 02:58:42,073 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 02:58:42,073 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 02:58:42,074 - INFO -   undirected: True
2025-08-16 02:58:42,074 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 02:58:42,074 - INFO -   avg num_nodes/graph: 25
2025-08-16 02:58:42,074 - INFO -   num node features: 9
2025-08-16 02:58:42,075 - INFO -   num edge features: 3
2025-08-16 02:58:42,075 - INFO -   num tasks: 1
2025-08-16 02:58:42,075 - INFO -   num classes: 2
2025-08-16 02:58:42,075 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 02:58:42,075 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 02:58:42,078 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 18%|█▊        | 7568/41127 [00:10<00:44, 756.74it/s] 37%|███▋      | 15042/41127 [00:20<00:35, 742.91it/s] 55%|█████▌    | 22621/41127 [00:30<00:24, 749.69it/s] 73%|███████▎  | 30011/41127 [00:40<00:14, 745.48it/s] 91%|█████████ | 37282/41127 [00:50<00:05, 738.84it/s]100%|██████████| 41127/41127 [00:55<00:00, 743.32it/s]
2025-08-16 02:59:38,389 - INFO - Done! Took 00:00:56.31
2025-08-16 02:59:38,539 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 02:59:38,635 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-16 02:59:38,635 - INFO - Start from epoch 0
2025-08-16 03:00:55,853 - INFO - train: {'epoch': 0, 'time_epoch': 76.81495, 'eta': 7604.68054, 'eta_hours': 2.11241, 'loss': 0.6298949, 'lr': 0.0, 'params': 514193, 'time_iter': 0.07465, 'accuracy': 0.95739, 'precision': 0.01705, 'recall': 0.00244, 'f1': 0.00426, 'auc': 0.50323}
2025-08-16 03:00:55,948 - INFO - ...computing epoch stats took: 0.47s
2025-08-16 03:01:01,274 - INFO - val: {'epoch': 0, 'time_epoch': 5.30603, 'loss': 0.62671198, 'lr': 0, 'params': 514193, 'time_iter': 0.04113, 'accuracy': 0.96961, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.49311}
2025-08-16 03:01:01,374 - INFO - ...computing epoch stats took: 0.12s
2025-08-16 03:01:06,467 - INFO - test: {'epoch': 0, 'time_epoch': 5.07385, 'loss': 0.62562415, 'lr': 0, 'params': 514193, 'time_iter': 0.03933, 'accuracy': 0.95478, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.56209}
2025-08-16 03:01:06,541 - INFO - ...computing epoch stats took: 0.09s
2025-08-16 03:01:06,541 - INFO - > Epoch 0: took 87.9s (avg 87.9s) | Best so far: epoch 0	train_loss: 0.6299 train_auc: 0.5032	val_loss: 0.6267 val_auc: 0.4931	test_loss: 0.6256 test_auc: 0.5621
2025-08-16 03:02:18,530 - INFO - train: {'epoch': 1, 'time_epoch': 71.91921, 'eta': 7287.97432, 'eta_hours': 2.02444, 'loss': 0.35977862, 'lr': 2e-05, 'params': 514193, 'time_iter': 0.06989, 'accuracy': 0.9624, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.52996}
2025-08-16 03:02:18,538 - INFO - ...computing epoch stats took: 0.05s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:02:23,074 - INFO - val: {'epoch': 1, 'time_epoch': 4.50146, 'loss': 0.17219264, 'lr': 0, 'params': 514193, 'time_iter': 0.0349, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.58033}
2025-08-16 03:02:23,078 - INFO - ...computing epoch stats took: 0.04s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:02:27,581 - INFO - test: {'epoch': 1, 'time_epoch': 4.48665, 'loss': 0.18760659, 'lr': 0, 'params': 514193, 'time_iter': 0.03478, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.61622}
2025-08-16 03:02:27,583 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 03:02:27,583 - INFO - > Epoch 1: took 81.0s (avg 84.5s) | Best so far: epoch 1	train_loss: 0.3598 train_auc: 0.5300	val_loss: 0.1722 val_auc: 0.5803	test_loss: 0.1876 test_auc: 0.6162
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:03:39,667 - INFO - train: {'epoch': 2, 'time_epoch': 72.02662, 'eta': 7137.93227, 'eta_hours': 1.98276, 'loss': 0.16406907, 'lr': 4e-05, 'params': 514193, 'time_iter': 0.07, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.64055}
2025-08-16 03:03:39,675 - INFO - ...computing epoch stats took: 0.04s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:03:44,151 - INFO - val: {'epoch': 2, 'time_epoch': 4.46101, 'loss': 0.09726041, 'lr': 0, 'params': 514193, 'time_iter': 0.03458, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72346}
2025-08-16 03:03:44,154 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:03:48,529 - INFO - test: {'epoch': 2, 'time_epoch': 4.35976, 'loss': 0.1307292, 'lr': 0, 'params': 514193, 'time_iter': 0.0338, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71813}
2025-08-16 03:03:48,531 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 03:03:48,531 - INFO - > Epoch 2: took 80.9s (avg 83.3s) | Best so far: epoch 2	train_loss: 0.1641 train_auc: 0.6405	val_loss: 0.0973 val_auc: 0.7235	test_loss: 0.1307 test_auc: 0.7181
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:05:00,721 - INFO - train: {'epoch': 3, 'time_epoch': 72.12889, 'eta': 7029.35246, 'eta_hours': 1.9526, 'loss': 0.14779496, 'lr': 6e-05, 'params': 514193, 'time_iter': 0.0701, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70314}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:05:07,011 - INFO - val: {'epoch': 3, 'time_epoch': 4.5247, 'loss': 0.09342881, 'lr': 0, 'params': 514193, 'time_iter': 0.03508, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72846}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:05:11,330 - INFO - test: {'epoch': 3, 'time_epoch': 4.30264, 'loss': 0.12592586, 'lr': 0, 'params': 514193, 'time_iter': 0.03335, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72757}
2025-08-16 03:05:11,332 - INFO - > Epoch 3: took 82.8s (avg 83.2s) | Best so far: epoch 3	train_loss: 0.1478 train_auc: 0.7031	val_loss: 0.0934 val_auc: 0.7285	test_loss: 0.1259 test_auc: 0.7276
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:06:22,572 - INFO - train: {'epoch': 4, 'time_epoch': 71.18457, 'eta': 6917.41077, 'eta_hours': 1.9215, 'loss': 0.14434911, 'lr': 8e-05, 'params': 514193, 'time_iter': 0.06918, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72945}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:06:27,052 - INFO - val: {'epoch': 4, 'time_epoch': 4.458, 'loss': 0.08937873, 'lr': 0, 'params': 514193, 'time_iter': 0.03456, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72086}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:06:31,597 - INFO - test: {'epoch': 4, 'time_epoch': 4.42534, 'loss': 0.1266114, 'lr': 0, 'params': 514193, 'time_iter': 0.0343, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73473}
2025-08-16 03:06:31,667 - INFO - > Epoch 4: took 80.3s (avg 82.6s) | Best so far: epoch 3	train_loss: 0.1478 train_auc: 0.7031	val_loss: 0.0934 val_auc: 0.7285	test_loss: 0.1259 test_auc: 0.7276
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:07:45,232 - INFO - train: {'epoch': 5, 'time_epoch': 73.50503, 'eta': 6855.40875, 'eta_hours': 1.90428, 'loss': 0.14032736, 'lr': 0.0001, 'params': 514193, 'time_iter': 0.07143, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74156}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:07:49,822 - INFO - val: {'epoch': 5, 'time_epoch': 4.56726, 'loss': 0.09210467, 'lr': 0, 'params': 514193, 'time_iter': 0.03541, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71672}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:07:54,327 - INFO - test: {'epoch': 5, 'time_epoch': 4.48542, 'loss': 0.12835425, 'lr': 0, 'params': 514193, 'time_iter': 0.03477, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71787}
2025-08-16 03:07:54,330 - INFO - > Epoch 5: took 82.7s (avg 82.6s) | Best so far: epoch 3	train_loss: 0.1478 train_auc: 0.7031	val_loss: 0.0934 val_auc: 0.7285	test_loss: 0.1259 test_auc: 0.7276
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:09:07,289 - INFO - train: {'epoch': 6, 'time_epoch': 72.90211, 'eta': 6782.10996, 'eta_hours': 1.88392, 'loss': 0.1360627, 'lr': 9.997e-05, 'params': 514193, 'time_iter': 0.07085, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7628}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:09:11,750 - INFO - val: {'epoch': 6, 'time_epoch': 4.43986, 'loss': 0.08807683, 'lr': 0, 'params': 514193, 'time_iter': 0.03442, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73826}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:09:16,104 - INFO - test: {'epoch': 6, 'time_epoch': 4.33711, 'loss': 0.12861337, 'lr': 0, 'params': 514193, 'time_iter': 0.03362, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70768}
2025-08-16 03:09:16,106 - INFO - > Epoch 6: took 81.8s (avg 82.5s) | Best so far: epoch 6	train_loss: 0.1361 train_auc: 0.7628	val_loss: 0.0881 val_auc: 0.7383	test_loss: 0.1286 test_auc: 0.7077
2025-08-16 03:10:26,865 - INFO - train: {'epoch': 7, 'time_epoch': 70.69083, 'eta': 6683.48057, 'eta_hours': 1.85652, 'loss': 0.13306452, 'lr': 9.989e-05, 'params': 514193, 'time_iter': 0.0687, 'accuracy': 0.96268, 'precision': 0.57143, 'recall': 0.01299, 'f1': 0.0254, 'auc': 0.77065}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:10:31,277 - INFO - val: {'epoch': 7, 'time_epoch': 4.38974, 'loss': 0.08552517, 'lr': 0, 'params': 514193, 'time_iter': 0.03403, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73271}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:10:35,595 - INFO - test: {'epoch': 7, 'time_epoch': 4.30113, 'loss': 0.1332635, 'lr': 0, 'params': 514193, 'time_iter': 0.03334, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69519}
2025-08-16 03:10:35,597 - INFO - > Epoch 7: took 79.5s (avg 82.1s) | Best so far: epoch 6	train_loss: 0.1361 train_auc: 0.7628	val_loss: 0.0881 val_auc: 0.7383	test_loss: 0.1286 test_auc: 0.7077
2025-08-16 03:11:48,138 - INFO - train: {'epoch': 8, 'time_epoch': 72.47011, 'eta': 6609.05026, 'eta_hours': 1.83585, 'loss': 0.12931767, 'lr': 9.975e-05, 'params': 514193, 'time_iter': 0.07043, 'accuracy': 0.96413, 'precision': 0.66667, 'recall': 0.08442, 'f1': 0.14986, 'auc': 0.79155}
2025-08-16 03:11:52,682 - INFO - val: {'epoch': 8, 'time_epoch': 4.52038, 'loss': 0.08871344, 'lr': 0, 'params': 514193, 'time_iter': 0.03504, 'accuracy': 0.97933, 'precision': 0.42857, 'recall': 0.14815, 'f1': 0.22018, 'auc': 0.74471}
2025-08-16 03:11:57,061 - INFO - test: {'epoch': 8, 'time_epoch': 4.36079, 'loss': 0.12754397, 'lr': 0, 'params': 514193, 'time_iter': 0.0338, 'accuracy': 0.97082, 'precision': 0.66667, 'recall': 0.15385, 'f1': 0.25, 'auc': 0.72231}
2025-08-16 03:11:57,063 - INFO - > Epoch 8: took 81.5s (avg 82.0s) | Best so far: epoch 8	train_loss: 0.1293 train_auc: 0.7915	val_loss: 0.0887 val_auc: 0.7447	test_loss: 0.1275 test_auc: 0.7223
2025-08-16 03:13:08,981 - INFO - train: {'epoch': 9, 'time_epoch': 71.84753, 'eta': 6529.40875, 'eta_hours': 1.81372, 'loss': 0.12735079, 'lr': 9.956e-05, 'params': 514193, 'time_iter': 0.06982, 'accuracy': 0.9645, 'precision': 0.60191, 'recall': 0.15341, 'f1': 0.2445, 'auc': 0.79551}
2025-08-16 03:13:13,491 - INFO - val: {'epoch': 9, 'time_epoch': 4.487, 'loss': 0.09215376, 'lr': 0, 'params': 514193, 'time_iter': 0.03478, 'accuracy': 0.97642, 'precision': 0.30952, 'recall': 0.16049, 'f1': 0.21138, 'auc': 0.74363}
2025-08-16 03:13:17,899 - INFO - test: {'epoch': 9, 'time_epoch': 4.38911, 'loss': 0.12342563, 'lr': 0, 'params': 514193, 'time_iter': 0.03402, 'accuracy': 0.96669, 'precision': 0.43396, 'recall': 0.17692, 'f1': 0.25137, 'auc': 0.7569}
2025-08-16 03:13:17,901 - INFO - > Epoch 9: took 80.8s (avg 81.9s) | Best so far: epoch 8	train_loss: 0.1293 train_auc: 0.7915	val_loss: 0.0887 val_auc: 0.7447	test_loss: 0.1275 test_auc: 0.7223
2025-08-16 03:14:29,679 - INFO - train: {'epoch': 10, 'time_epoch': 71.70127, 'eta': 6450.00097, 'eta_hours': 1.79167, 'loss': 0.12552202, 'lr': 9.932e-05, 'params': 514193, 'time_iter': 0.06968, 'accuracy': 0.96514, 'precision': 0.62391, 'recall': 0.1737, 'f1': 0.27175, 'auc': 0.80315}
2025-08-16 03:14:34,308 - INFO - val: {'epoch': 10, 'time_epoch': 4.60452, 'loss': 0.08442353, 'lr': 0, 'params': 514193, 'time_iter': 0.03569, 'accuracy': 0.98152, 'precision': 0.61905, 'recall': 0.16049, 'f1': 0.2549, 'auc': 0.72914}
2025-08-16 03:14:38,829 - INFO - test: {'epoch': 10, 'time_epoch': 4.49895, 'loss': 0.1193196, 'lr': 0, 'params': 514193, 'time_iter': 0.03488, 'accuracy': 0.97009, 'precision': 0.73333, 'recall': 0.08462, 'f1': 0.15172, 'auc': 0.75562}
2025-08-16 03:14:38,833 - INFO - > Epoch 10: took 80.9s (avg 81.8s) | Best so far: epoch 8	train_loss: 0.1293 train_auc: 0.7915	val_loss: 0.0887 val_auc: 0.7447	test_loss: 0.1275 test_auc: 0.7223
2025-08-16 03:15:51,032 - INFO - train: {'epoch': 11, 'time_epoch': 72.13049, 'eta': 6375.02526, 'eta_hours': 1.77084, 'loss': 0.12140437, 'lr': 9.902e-05, 'params': 514193, 'time_iter': 0.0701, 'accuracy': 0.96626, 'precision': 0.65722, 'recall': 0.20698, 'f1': 0.31481, 'auc': 0.813}
2025-08-16 03:15:55,458 - INFO - val: {'epoch': 11, 'time_epoch': 4.40008, 'loss': 0.08898005, 'lr': 0, 'params': 514193, 'time_iter': 0.03411, 'accuracy': 0.97909, 'precision': 0.41935, 'recall': 0.16049, 'f1': 0.23214, 'auc': 0.74094}
2025-08-16 03:15:59,764 - INFO - test: {'epoch': 11, 'time_epoch': 4.28823, 'loss': 0.12255376, 'lr': 0, 'params': 514193, 'time_iter': 0.03324, 'accuracy': 0.96718, 'precision': 0.45763, 'recall': 0.20769, 'f1': 0.28571, 'auc': 0.75938}
2025-08-16 03:15:59,767 - INFO - > Epoch 11: took 80.9s (avg 81.8s) | Best so far: epoch 8	train_loss: 0.1293 train_auc: 0.7915	val_loss: 0.0887 val_auc: 0.7447	test_loss: 0.1275 test_auc: 0.7223
2025-08-16 03:17:09,865 - INFO - train: {'epoch': 12, 'time_epoch': 70.03219, 'eta': 6286.44475, 'eta_hours': 1.74623, 'loss': 0.11998033, 'lr': 9.867e-05, 'params': 514193, 'time_iter': 0.06806, 'accuracy': 0.96724, 'precision': 0.67342, 'recall': 0.24269, 'f1': 0.3568, 'auc': 0.82037}
2025-08-16 03:17:14,300 - INFO - val: {'epoch': 12, 'time_epoch': 4.41141, 'loss': 0.08664795, 'lr': 0, 'params': 514193, 'time_iter': 0.0342, 'accuracy': 0.98079, 'precision': 0.54167, 'recall': 0.16049, 'f1': 0.24762, 'auc': 0.70978}
2025-08-16 03:17:18,625 - INFO - test: {'epoch': 12, 'time_epoch': 4.30623, 'loss': 0.12521494, 'lr': 0, 'params': 514193, 'time_iter': 0.03338, 'accuracy': 0.97034, 'precision': 0.7, 'recall': 0.10769, 'f1': 0.18667, 'auc': 0.7369}
2025-08-16 03:17:18,627 - INFO - > Epoch 12: took 78.9s (avg 81.5s) | Best so far: epoch 8	train_loss: 0.1293 train_auc: 0.7915	val_loss: 0.0887 val_auc: 0.7447	test_loss: 0.1275 test_auc: 0.7223
2025-08-16 03:18:29,668 - INFO - train: {'epoch': 13, 'time_epoch': 70.97339, 'eta': 6206.29565, 'eta_hours': 1.72397, 'loss': 0.12038863, 'lr': 9.826e-05, 'params': 514193, 'time_iter': 0.06897, 'accuracy': 0.96632, 'precision': 0.64554, 'recall': 0.22321, 'f1': 0.33172, 'auc': 0.81862}
2025-08-16 03:18:34,036 - INFO - val: {'epoch': 13, 'time_epoch': 4.34559, 'loss': 0.08377684, 'lr': 0, 'params': 514193, 'time_iter': 0.03369, 'accuracy': 0.97958, 'precision': 0.45946, 'recall': 0.20988, 'f1': 0.28814, 'auc': 0.75421}
2025-08-16 03:18:38,315 - INFO - test: {'epoch': 13, 'time_epoch': 4.26068, 'loss': 0.11988286, 'lr': 0, 'params': 514193, 'time_iter': 0.03303, 'accuracy': 0.96961, 'precision': 0.57576, 'recall': 0.14615, 'f1': 0.23313, 'auc': 0.7641}
2025-08-16 03:18:38,317 - INFO - > Epoch 13: took 79.7s (avg 81.4s) | Best so far: epoch 13	train_loss: 0.1204 train_auc: 0.8186	val_loss: 0.0838 val_auc: 0.7542	test_loss: 0.1199 test_auc: 0.7641
2025-08-16 03:19:47,290 - INFO - train: {'epoch': 14, 'time_epoch': 68.90698, 'eta': 6115.66037, 'eta_hours': 1.69879, 'loss': 0.11846793, 'lr': 9.78e-05, 'params': 514193, 'time_iter': 0.06696, 'accuracy': 0.96678, 'precision': 0.65688, 'recall': 0.2362, 'f1': 0.34746, 'auc': 0.82536}
2025-08-16 03:19:51,694 - INFO - val: {'epoch': 14, 'time_epoch': 4.38111, 'loss': 0.07898923, 'lr': 0, 'params': 514193, 'time_iter': 0.03396, 'accuracy': 0.98177, 'precision': 0.59375, 'recall': 0.23457, 'f1': 0.33628, 'auc': 0.76075}
2025-08-16 03:19:56,063 - INFO - test: {'epoch': 14, 'time_epoch': 4.35037, 'loss': 0.1111777, 'lr': 0, 'params': 514193, 'time_iter': 0.03372, 'accuracy': 0.97009, 'precision': 0.57447, 'recall': 0.20769, 'f1': 0.30508, 'auc': 0.78495}
2025-08-16 03:19:56,065 - INFO - > Epoch 14: took 77.7s (avg 81.2s) | Best so far: epoch 14	train_loss: 0.1185 train_auc: 0.8254	val_loss: 0.0790 val_auc: 0.7608	test_loss: 0.1112 test_auc: 0.7850
2025-08-16 03:21:05,587 - INFO - train: {'epoch': 15, 'time_epoch': 69.45608, 'eta': 6030.62386, 'eta_hours': 1.67517, 'loss': 0.11579386, 'lr': 9.729e-05, 'params': 514193, 'time_iter': 0.0675, 'accuracy': 0.96763, 'precision': 0.6736, 'recall': 0.26299, 'f1': 0.37828, 'auc': 0.83452}
2025-08-16 03:21:09,947 - INFO - val: {'epoch': 15, 'time_epoch': 4.33773, 'loss': 0.08613464, 'lr': 0, 'params': 514193, 'time_iter': 0.03363, 'accuracy': 0.98006, 'precision': 0.48889, 'recall': 0.2716, 'f1': 0.34921, 'auc': 0.75806}
2025-08-16 03:21:14,211 - INFO - test: {'epoch': 15, 'time_epoch': 4.24734, 'loss': 0.12040733, 'lr': 0, 'params': 514193, 'time_iter': 0.03293, 'accuracy': 0.96791, 'precision': 0.48649, 'recall': 0.27692, 'f1': 0.35294, 'auc': 0.77806}
2025-08-16 03:21:14,214 - INFO - > Epoch 15: took 78.1s (avg 81.0s) | Best so far: epoch 14	train_loss: 0.1185 train_auc: 0.8254	val_loss: 0.0790 val_auc: 0.7608	test_loss: 0.1112 test_auc: 0.7850
2025-08-16 03:22:23,126 - INFO - train: {'epoch': 16, 'time_epoch': 68.84635, 'eta': 5944.44345, 'eta_hours': 1.65123, 'loss': 0.11503042, 'lr': 9.673e-05, 'params': 514193, 'time_iter': 0.06691, 'accuracy': 0.96848, 'precision': 0.70789, 'recall': 0.26948, 'f1': 0.39036, 'auc': 0.83518}
2025-08-16 03:22:27,551 - INFO - val: {'epoch': 16, 'time_epoch': 4.27932, 'loss': 0.08552072, 'lr': 0, 'params': 514193, 'time_iter': 0.03317, 'accuracy': 0.98079, 'precision': 0.52778, 'recall': 0.23457, 'f1': 0.32479, 'auc': 0.73218}
2025-08-16 03:22:31,772 - INFO - test: {'epoch': 16, 'time_epoch': 4.20385, 'loss': 0.1201056, 'lr': 0, 'params': 514193, 'time_iter': 0.03259, 'accuracy': 0.96766, 'precision': 0.45161, 'recall': 0.10769, 'f1': 0.17391, 'auc': 0.77812}
2025-08-16 03:22:31,774 - INFO - > Epoch 16: took 77.6s (avg 80.8s) | Best so far: epoch 14	train_loss: 0.1185 train_auc: 0.8254	val_loss: 0.0790 val_auc: 0.7608	test_loss: 0.1112 test_auc: 0.7850
2025-08-16 03:23:43,704 - INFO - train: {'epoch': 17, 'time_epoch': 71.85774, 'eta': 5873.90761, 'eta_hours': 1.63164, 'loss': 0.11302872, 'lr': 9.611e-05, 'params': 514193, 'time_iter': 0.06983, 'accuracy': 0.96714, 'precision': 0.65314, 'recall': 0.26136, 'f1': 0.37333, 'auc': 0.84372}
2025-08-16 03:23:48,163 - INFO - val: {'epoch': 17, 'time_epoch': 4.4349, 'loss': 0.08314249, 'lr': 0, 'params': 514193, 'time_iter': 0.03438, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.20988, 'f1': 0.29565, 'auc': 0.76239}
2025-08-16 03:23:52,573 - INFO - test: {'epoch': 17, 'time_epoch': 4.39, 'loss': 0.11792211, 'lr': 0, 'params': 514193, 'time_iter': 0.03403, 'accuracy': 0.96961, 'precision': 0.54717, 'recall': 0.22308, 'f1': 0.31694, 'auc': 0.76007}
2025-08-16 03:23:52,575 - INFO - > Epoch 17: took 80.8s (avg 80.8s) | Best so far: epoch 17	train_loss: 0.1130 train_auc: 0.8437	val_loss: 0.0831 val_auc: 0.7624	test_loss: 0.1179 test_auc: 0.7601
2025-08-16 03:25:04,042 - INFO - train: {'epoch': 18, 'time_epoch': 71.39247, 'eta': 5801.24908, 'eta_hours': 1.61146, 'loss': 0.11116441, 'lr': 9.545e-05, 'params': 514193, 'time_iter': 0.06938, 'accuracy': 0.96857, 'precision': 0.68401, 'recall': 0.2987, 'f1': 0.41582, 'auc': 0.84914}
2025-08-16 03:25:08,467 - INFO - val: {'epoch': 18, 'time_epoch': 4.40145, 'loss': 0.08721075, 'lr': 0, 'params': 514193, 'time_iter': 0.03412, 'accuracy': 0.97763, 'precision': 0.37778, 'recall': 0.20988, 'f1': 0.26984, 'auc': 0.75227}
2025-08-16 03:25:12,814 - INFO - test: {'epoch': 18, 'time_epoch': 4.3297, 'loss': 0.12673827, 'lr': 0, 'params': 514193, 'time_iter': 0.03356, 'accuracy': 0.96572, 'precision': 0.40351, 'recall': 0.17692, 'f1': 0.24599, 'auc': 0.75014}
2025-08-16 03:25:12,817 - INFO - > Epoch 18: took 80.2s (avg 80.7s) | Best so far: epoch 17	train_loss: 0.1130 train_auc: 0.8437	val_loss: 0.0831 val_auc: 0.7624	test_loss: 0.1179 test_auc: 0.7601
2025-08-16 03:26:22,279 - INFO - train: {'epoch': 19, 'time_epoch': 69.39464, 'eta': 5720.72583, 'eta_hours': 1.58909, 'loss': 0.10870681, 'lr': 9.474e-05, 'params': 514193, 'time_iter': 0.06744, 'accuracy': 0.96954, 'precision': 0.71536, 'recall': 0.31006, 'f1': 0.43262, 'auc': 0.85981}
2025-08-16 03:26:26,640 - INFO - val: {'epoch': 19, 'time_epoch': 4.33852, 'loss': 0.08313925, 'lr': 0, 'params': 514193, 'time_iter': 0.03363, 'accuracy': 0.98128, 'precision': 0.55882, 'recall': 0.23457, 'f1': 0.33043, 'auc': 0.75427}
2025-08-16 03:26:30,908 - INFO - test: {'epoch': 19, 'time_epoch': 4.24891, 'loss': 0.11817978, 'lr': 0, 'params': 514193, 'time_iter': 0.03294, 'accuracy': 0.97034, 'precision': 0.58, 'recall': 0.22308, 'f1': 0.32222, 'auc': 0.75361}
2025-08-16 03:26:30,911 - INFO - > Epoch 19: took 78.1s (avg 80.6s) | Best so far: epoch 17	train_loss: 0.1130 train_auc: 0.8437	val_loss: 0.0831 val_auc: 0.7624	test_loss: 0.1179 test_auc: 0.7601
2025-08-16 03:27:39,181 - INFO - train: {'epoch': 20, 'time_epoch': 68.20425, 'eta': 5636.78434, 'eta_hours': 1.56577, 'loss': 0.11000973, 'lr': 9.397e-05, 'params': 514193, 'time_iter': 0.06628, 'accuracy': 0.96903, 'precision': 0.70923, 'recall': 0.29302, 'f1': 0.4147, 'auc': 0.85368}
2025-08-16 03:27:43,551 - INFO - val: {'epoch': 20, 'time_epoch': 4.34743, 'loss': 0.08123619, 'lr': 0, 'params': 514193, 'time_iter': 0.0337, 'accuracy': 0.98104, 'precision': 0.53846, 'recall': 0.25926, 'f1': 0.35, 'auc': 0.78163}
2025-08-16 03:27:47,834 - INFO - test: {'epoch': 20, 'time_epoch': 4.26551, 'loss': 0.12271795, 'lr': 0, 'params': 514193, 'time_iter': 0.03307, 'accuracy': 0.96815, 'precision': 0.49091, 'recall': 0.20769, 'f1': 0.29189, 'auc': 0.76851}
2025-08-16 03:27:47,837 - INFO - > Epoch 20: took 76.9s (avg 80.4s) | Best so far: epoch 20	train_loss: 0.1100 train_auc: 0.8537	val_loss: 0.0812 val_auc: 0.7816	test_loss: 0.1227 test_auc: 0.7685
2025-08-16 03:28:56,059 - INFO - train: {'epoch': 21, 'time_epoch': 68.15792, 'eta': 5554.10922, 'eta_hours': 1.54281, 'loss': 0.10772594, 'lr': 9.316e-05, 'params': 514193, 'time_iter': 0.06624, 'accuracy': 0.9697, 'precision': 0.71248, 'recall': 0.31981, 'f1': 0.44146, 'auc': 0.86044}
2025-08-16 03:29:00,453 - INFO - val: {'epoch': 21, 'time_epoch': 4.37142, 'loss': 0.08299587, 'lr': 0, 'params': 514193, 'time_iter': 0.03389, 'accuracy': 0.97788, 'precision': 0.40741, 'recall': 0.2716, 'f1': 0.32593, 'auc': 0.79112}
2025-08-16 03:29:04,734 - INFO - test: {'epoch': 21, 'time_epoch': 4.26313, 'loss': 0.12796748, 'lr': 0, 'params': 514193, 'time_iter': 0.03305, 'accuracy': 0.96693, 'precision': 0.44828, 'recall': 0.2, 'f1': 0.2766, 'auc': 0.75318}
2025-08-16 03:29:04,737 - INFO - > Epoch 21: took 76.9s (avg 80.3s) | Best so far: epoch 21	train_loss: 0.1077 train_auc: 0.8604	val_loss: 0.0830 val_auc: 0.7911	test_loss: 0.1280 test_auc: 0.7532
2025-08-16 03:30:12,698 - INFO - train: {'epoch': 22, 'time_epoch': 67.89654, 'eta': 5471.82142, 'eta_hours': 1.51995, 'loss': 0.10775337, 'lr': 9.23e-05, 'params': 514193, 'time_iter': 0.06598, 'accuracy': 0.96958, 'precision': 0.71193, 'recall': 0.31494, 'f1': 0.43669, 'auc': 0.86062}
2025-08-16 03:30:17,028 - INFO - val: {'epoch': 22, 'time_epoch': 4.30758, 'loss': 0.08208051, 'lr': 0, 'params': 514193, 'time_iter': 0.03339, 'accuracy': 0.98006, 'precision': 0.48837, 'recall': 0.25926, 'f1': 0.33871, 'auc': 0.78336}
2025-08-16 03:30:21,263 - INFO - test: {'epoch': 22, 'time_epoch': 4.21693, 'loss': 0.12436916, 'lr': 0, 'params': 514193, 'time_iter': 0.03269, 'accuracy': 0.96864, 'precision': 0.5122, 'recall': 0.16154, 'f1': 0.24561, 'auc': 0.7734}
2025-08-16 03:30:21,266 - INFO - > Epoch 22: took 76.5s (avg 80.1s) | Best so far: epoch 21	train_loss: 0.1077 train_auc: 0.8604	val_loss: 0.0830 val_auc: 0.7911	test_loss: 0.1280 test_auc: 0.7532
2025-08-16 03:31:29,804 - INFO - train: {'epoch': 23, 'time_epoch': 68.47192, 'eta': 5392.55492, 'eta_hours': 1.49793, 'loss': 0.10475578, 'lr': 9.14e-05, 'params': 514193, 'time_iter': 0.06654, 'accuracy': 0.97082, 'precision': 0.73208, 'recall': 0.34821, 'f1': 0.47195, 'auc': 0.87279}
2025-08-16 03:31:34,144 - INFO - val: {'epoch': 23, 'time_epoch': 4.31824, 'loss': 0.08424434, 'lr': 0, 'params': 514193, 'time_iter': 0.03347, 'accuracy': 0.98128, 'precision': 0.55556, 'recall': 0.24691, 'f1': 0.34188, 'auc': 0.77158}
2025-08-16 03:31:38,393 - INFO - test: {'epoch': 23, 'time_epoch': 4.23168, 'loss': 0.12874063, 'lr': 0, 'params': 514193, 'time_iter': 0.0328, 'accuracy': 0.96742, 'precision': 0.45238, 'recall': 0.14615, 'f1': 0.22093, 'auc': 0.77363}
2025-08-16 03:31:38,396 - INFO - > Epoch 23: took 77.1s (avg 80.0s) | Best so far: epoch 21	train_loss: 0.1077 train_auc: 0.8604	val_loss: 0.0830 val_auc: 0.7911	test_loss: 0.1280 test_auc: 0.7532
2025-08-16 03:32:47,562 - INFO - train: {'epoch': 24, 'time_epoch': 69.10044, 'eta': 5316.03755, 'eta_hours': 1.47668, 'loss': 0.10428435, 'lr': 9.045e-05, 'params': 514193, 'time_iter': 0.06715, 'accuracy': 0.9704, 'precision': 0.73201, 'recall': 0.33036, 'f1': 0.45526, 'auc': 0.87768}
2025-08-16 03:32:51,931 - INFO - val: {'epoch': 24, 'time_epoch': 4.34656, 'loss': 0.08065203, 'lr': 0, 'params': 514193, 'time_iter': 0.03369, 'accuracy': 0.98104, 'precision': 0.53488, 'recall': 0.28395, 'f1': 0.37097, 'auc': 0.77459}
2025-08-16 03:32:56,202 - INFO - test: {'epoch': 24, 'time_epoch': 4.253, 'loss': 0.12087148, 'lr': 0, 'params': 514193, 'time_iter': 0.03297, 'accuracy': 0.96961, 'precision': 0.53846, 'recall': 0.26923, 'f1': 0.35897, 'auc': 0.78175}
2025-08-16 03:32:56,205 - INFO - > Epoch 24: took 77.8s (avg 79.9s) | Best so far: epoch 21	train_loss: 0.1077 train_auc: 0.8604	val_loss: 0.0830 val_auc: 0.7911	test_loss: 0.1280 test_auc: 0.7532
2025-08-16 03:34:04,483 - INFO - train: {'epoch': 25, 'time_epoch': 68.21343, 'eta': 5237.56615, 'eta_hours': 1.45488, 'loss': 0.10365526, 'lr': 8.946e-05, 'params': 514193, 'time_iter': 0.06629, 'accuracy': 0.96967, 'precision': 0.70242, 'recall': 0.32955, 'f1': 0.44862, 'auc': 0.88022}
2025-08-16 03:34:08,834 - INFO - val: {'epoch': 25, 'time_epoch': 4.32867, 'loss': 0.08317695, 'lr': 0, 'params': 514193, 'time_iter': 0.03356, 'accuracy': 0.98128, 'precision': 0.55556, 'recall': 0.24691, 'f1': 0.34188, 'auc': 0.7657}
2025-08-16 03:34:13,120 - INFO - test: {'epoch': 25, 'time_epoch': 4.25244, 'loss': 0.12462076, 'lr': 0, 'params': 514193, 'time_iter': 0.03296, 'accuracy': 0.96815, 'precision': 0.49057, 'recall': 0.2, 'f1': 0.28415, 'auc': 0.77835}
2025-08-16 03:34:13,129 - INFO - > Epoch 25: took 76.9s (avg 79.8s) | Best so far: epoch 21	train_loss: 0.1077 train_auc: 0.8604	val_loss: 0.0830 val_auc: 0.7911	test_loss: 0.1280 test_auc: 0.7532
2025-08-16 03:35:21,471 - INFO - train: {'epoch': 26, 'time_epoch': 68.26985, 'eta': 5160.00714, 'eta_hours': 1.43334, 'loss': 0.10260076, 'lr': 8.842e-05, 'params': 514193, 'time_iter': 0.06635, 'accuracy': 0.97061, 'precision': 0.7212, 'recall': 0.35065, 'f1': 0.47187, 'auc': 0.88268}
2025-08-16 03:35:25,803 - INFO - val: {'epoch': 26, 'time_epoch': 4.31036, 'loss': 0.08507446, 'lr': 0, 'params': 514193, 'time_iter': 0.03341, 'accuracy': 0.98079, 'precision': 0.52381, 'recall': 0.2716, 'f1': 0.35772, 'auc': 0.77917}
2025-08-16 03:35:30,050 - INFO - test: {'epoch': 26, 'time_epoch': 4.22845, 'loss': 0.1253803, 'lr': 0, 'params': 514193, 'time_iter': 0.03278, 'accuracy': 0.96864, 'precision': 0.50769, 'recall': 0.25385, 'f1': 0.33846, 'auc': 0.77254}
2025-08-16 03:35:30,052 - INFO - > Epoch 26: took 76.9s (avg 79.7s) | Best so far: epoch 21	train_loss: 0.1077 train_auc: 0.8604	val_loss: 0.0830 val_auc: 0.7911	test_loss: 0.1280 test_auc: 0.7532
2025-08-16 03:36:38,185 - INFO - train: {'epoch': 27, 'time_epoch': 68.06835, 'eta': 5082.5935, 'eta_hours': 1.41183, 'loss': 0.10130319, 'lr': 8.734e-05, 'params': 514193, 'time_iter': 0.06615, 'accuracy': 0.97061, 'precision': 0.72964, 'recall': 0.34172, 'f1': 0.46545, 'auc': 0.88695}
2025-08-16 03:36:42,519 - INFO - val: {'epoch': 27, 'time_epoch': 4.31176, 'loss': 0.08751667, 'lr': 0, 'params': 514193, 'time_iter': 0.03342, 'accuracy': 0.97836, 'precision': 0.42857, 'recall': 0.2963, 'f1': 0.35036, 'auc': 0.75321}
2025-08-16 03:36:46,762 - INFO - test: {'epoch': 27, 'time_epoch': 4.22624, 'loss': 0.13486153, 'lr': 0, 'params': 514193, 'time_iter': 0.03276, 'accuracy': 0.96523, 'precision': 0.42169, 'recall': 0.26923, 'f1': 0.32864, 'auc': 0.73411}
2025-08-16 03:36:46,765 - INFO - > Epoch 27: took 76.7s (avg 79.6s) | Best so far: epoch 21	train_loss: 0.1077 train_auc: 0.8604	val_loss: 0.0830 val_auc: 0.7911	test_loss: 0.1280 test_auc: 0.7532
2025-08-16 03:37:55,848 - INFO - train: {'epoch': 28, 'time_epoch': 69.0174, 'eta': 5008.14791, 'eta_hours': 1.39115, 'loss': 0.09971515, 'lr': 8.622e-05, 'params': 514193, 'time_iter': 0.06707, 'accuracy': 0.97185, 'precision': 0.75164, 'recall': 0.37094, 'f1': 0.49674, 'auc': 0.88839}
2025-08-16 03:38:00,185 - INFO - val: {'epoch': 28, 'time_epoch': 4.31503, 'loss': 0.07844929, 'lr': 0, 'params': 514193, 'time_iter': 0.03345, 'accuracy': 0.98079, 'precision': 0.52778, 'recall': 0.23457, 'f1': 0.32479, 'auc': 0.78371}
2025-08-16 03:38:04,438 - INFO - test: {'epoch': 28, 'time_epoch': 4.23599, 'loss': 0.13024152, 'lr': 0, 'params': 514193, 'time_iter': 0.03284, 'accuracy': 0.96791, 'precision': 0.46154, 'recall': 0.09231, 'f1': 0.15385, 'auc': 0.76097}
2025-08-16 03:38:04,440 - INFO - > Epoch 28: took 77.7s (avg 79.5s) | Best so far: epoch 21	train_loss: 0.1077 train_auc: 0.8604	val_loss: 0.0830 val_auc: 0.7911	test_loss: 0.1280 test_auc: 0.7532
2025-08-16 03:39:15,419 - INFO - train: {'epoch': 29, 'time_epoch': 70.91019, 'eta': 4938.4807, 'eta_hours': 1.3718, 'loss': 0.09855309, 'lr': 8.506e-05, 'params': 514193, 'time_iter': 0.06891, 'accuracy': 0.97073, 'precision': 0.72605, 'recall': 0.35065, 'f1': 0.47291, 'auc': 0.89863}
2025-08-16 03:39:19,928 - INFO - val: {'epoch': 29, 'time_epoch': 4.48677, 'loss': 0.08042279, 'lr': 0, 'params': 514193, 'time_iter': 0.03478, 'accuracy': 0.97933, 'precision': 0.45455, 'recall': 0.24691, 'f1': 0.32, 'auc': 0.80133}
2025-08-16 03:39:24,390 - INFO - test: {'epoch': 29, 'time_epoch': 4.44172, 'loss': 0.12499626, 'lr': 0, 'params': 514193, 'time_iter': 0.03443, 'accuracy': 0.96645, 'precision': 0.44286, 'recall': 0.23846, 'f1': 0.31, 'auc': 0.77406}
2025-08-16 03:39:24,392 - INFO - > Epoch 29: took 80.0s (avg 79.5s) | Best so far: epoch 29	train_loss: 0.0986 train_auc: 0.8986	val_loss: 0.0804 val_auc: 0.8013	test_loss: 0.1250 test_auc: 0.7741
2025-08-16 03:40:35,950 - INFO - train: {'epoch': 30, 'time_epoch': 71.48858, 'eta': 4870.02069, 'eta_hours': 1.35278, 'loss': 0.0983925, 'lr': 8.386e-05, 'params': 514193, 'time_iter': 0.06947, 'accuracy': 0.97192, 'precision': 0.7637, 'recall': 0.36201, 'f1': 0.49119, 'auc': 0.8986}
2025-08-16 03:40:40,468 - INFO - val: {'epoch': 30, 'time_epoch': 4.49411, 'loss': 0.08204228, 'lr': 0, 'params': 514193, 'time_iter': 0.03484, 'accuracy': 0.98055, 'precision': 0.5102, 'recall': 0.30864, 'f1': 0.38462, 'auc': 0.79085}
2025-08-16 03:40:44,875 - INFO - test: {'epoch': 30, 'time_epoch': 4.38809, 'loss': 0.12333015, 'lr': 0, 'params': 514193, 'time_iter': 0.03402, 'accuracy': 0.96766, 'precision': 0.48101, 'recall': 0.29231, 'f1': 0.36364, 'auc': 0.78152}
2025-08-16 03:40:44,877 - INFO - > Epoch 30: took 80.5s (avg 79.6s) | Best so far: epoch 29	train_loss: 0.0986 train_auc: 0.8986	val_loss: 0.0804 val_auc: 0.8013	test_loss: 0.1250 test_auc: 0.7741
2025-08-16 03:41:56,207 - INFO - train: {'epoch': 31, 'time_epoch': 71.26156, 'eta': 4800.88897, 'eta_hours': 1.33358, 'loss': 0.09789839, 'lr': 8.263e-05, 'params': 514193, 'time_iter': 0.06925, 'accuracy': 0.97213, 'precision': 0.76294, 'recall': 0.37094, 'f1': 0.49918, 'auc': 0.89778}
2025-08-16 03:42:00,645 - INFO - val: {'epoch': 31, 'time_epoch': 4.41467, 'loss': 0.08091837, 'lr': 0, 'params': 514193, 'time_iter': 0.03422, 'accuracy': 0.98201, 'precision': 0.57778, 'recall': 0.32099, 'f1': 0.4127, 'auc': 0.78226}
2025-08-16 03:42:04,989 - INFO - test: {'epoch': 31, 'time_epoch': 4.32659, 'loss': 0.13011388, 'lr': 0, 'params': 514193, 'time_iter': 0.03354, 'accuracy': 0.96815, 'precision': 0.49091, 'recall': 0.20769, 'f1': 0.29189, 'auc': 0.76512}
2025-08-16 03:42:04,992 - INFO - > Epoch 31: took 80.1s (avg 79.6s) | Best so far: epoch 29	train_loss: 0.0986 train_auc: 0.8986	val_loss: 0.0804 val_auc: 0.8013	test_loss: 0.1250 test_auc: 0.7741
2025-08-16 03:43:15,405 - INFO - train: {'epoch': 32, 'time_epoch': 70.34437, 'eta': 4729.766, 'eta_hours': 1.31382, 'loss': 0.09705483, 'lr': 8.136e-05, 'params': 514193, 'time_iter': 0.06836, 'accuracy': 0.97149, 'precision': 0.73786, 'recall': 0.37013, 'f1': 0.49297, 'auc': 0.90141}
2025-08-16 03:43:19,850 - INFO - val: {'epoch': 32, 'time_epoch': 4.42196, 'loss': 0.0802193, 'lr': 0, 'params': 514193, 'time_iter': 0.03428, 'accuracy': 0.98249, 'precision': 0.64516, 'recall': 0.24691, 'f1': 0.35714, 'auc': 0.78361}
2025-08-16 03:43:24,377 - INFO - test: {'epoch': 32, 'time_epoch': 4.50699, 'loss': 0.12985382, 'lr': 0, 'params': 514193, 'time_iter': 0.03494, 'accuracy': 0.96864, 'precision': 0.50794, 'recall': 0.24615, 'f1': 0.33161, 'auc': 0.77218}
2025-08-16 03:43:24,379 - INFO - > Epoch 32: took 79.4s (avg 79.6s) | Best so far: epoch 29	train_loss: 0.0986 train_auc: 0.8986	val_loss: 0.0804 val_auc: 0.8013	test_loss: 0.1250 test_auc: 0.7741
2025-08-16 03:44:35,620 - INFO - train: {'epoch': 33, 'time_epoch': 71.17006, 'eta': 4660.29164, 'eta_hours': 1.29453, 'loss': 0.09513926, 'lr': 8.005e-05, 'params': 514193, 'time_iter': 0.06916, 'accuracy': 0.97207, 'precision': 0.74802, 'recall': 0.38312, 'f1': 0.50671, 'auc': 0.90554}
2025-08-16 03:44:40,130 - INFO - val: {'epoch': 33, 'time_epoch': 4.4866, 'loss': 0.07931337, 'lr': 0, 'params': 514193, 'time_iter': 0.03478, 'accuracy': 0.98079, 'precision': 0.52381, 'recall': 0.2716, 'f1': 0.35772, 'auc': 0.80367}
2025-08-16 03:44:44,735 - INFO - test: {'epoch': 33, 'time_epoch': 4.58519, 'loss': 0.13591125, 'lr': 0, 'params': 514193, 'time_iter': 0.03554, 'accuracy': 0.96791, 'precision': 0.48485, 'recall': 0.24615, 'f1': 0.32653, 'auc': 0.75846}
2025-08-16 03:44:44,737 - INFO - > Epoch 33: took 80.4s (avg 79.6s) | Best so far: epoch 33	train_loss: 0.0951 train_auc: 0.9055	val_loss: 0.0793 val_auc: 0.8037	test_loss: 0.1359 test_auc: 0.7585
2025-08-16 03:45:55,762 - INFO - train: {'epoch': 34, 'time_epoch': 70.95765, 'eta': 4590.32591, 'eta_hours': 1.27509, 'loss': 0.09533696, 'lr': 7.872e-05, 'params': 514193, 'time_iter': 0.06896, 'accuracy': 0.97283, 'precision': 0.76489, 'recall': 0.3961, 'f1': 0.52193, 'auc': 0.90392}
2025-08-16 03:46:00,514 - INFO - val: {'epoch': 34, 'time_epoch': 4.72732, 'loss': 0.08030593, 'lr': 0, 'params': 514193, 'time_iter': 0.03665, 'accuracy': 0.98128, 'precision': 0.55263, 'recall': 0.25926, 'f1': 0.35294, 'auc': 0.79561}
2025-08-16 03:46:05,159 - INFO - test: {'epoch': 34, 'time_epoch': 4.62568, 'loss': 0.13263577, 'lr': 0, 'params': 514193, 'time_iter': 0.03586, 'accuracy': 0.96791, 'precision': 0.48718, 'recall': 0.29231, 'f1': 0.36538, 'auc': 0.75967}
2025-08-16 03:46:05,162 - INFO - > Epoch 34: took 80.4s (avg 79.6s) | Best so far: epoch 33	train_loss: 0.0951 train_auc: 0.9055	val_loss: 0.0793 val_auc: 0.8037	test_loss: 0.1359 test_auc: 0.7585
2025-08-16 03:47:15,743 - INFO - train: {'epoch': 35, 'time_epoch': 70.51257, 'eta': 4519.51381, 'eta_hours': 1.25542, 'loss': 0.09308118, 'lr': 7.735e-05, 'params': 514193, 'time_iter': 0.06853, 'accuracy': 0.97237, 'precision': 0.76519, 'recall': 0.37825, 'f1': 0.50625, 'auc': 0.91715}
2025-08-16 03:47:20,131 - INFO - val: {'epoch': 35, 'time_epoch': 4.36566, 'loss': 0.08846781, 'lr': 0, 'params': 514193, 'time_iter': 0.03384, 'accuracy': 0.97715, 'precision': 0.40845, 'recall': 0.35802, 'f1': 0.38158, 'auc': 0.78278}
2025-08-16 03:47:24,442 - INFO - test: {'epoch': 35, 'time_epoch': 4.29277, 'loss': 0.13376334, 'lr': 0, 'params': 514193, 'time_iter': 0.03328, 'accuracy': 0.9662, 'precision': 0.45161, 'recall': 0.32308, 'f1': 0.37668, 'auc': 0.78047}
2025-08-16 03:47:24,445 - INFO - > Epoch 35: took 79.3s (avg 79.6s) | Best so far: epoch 33	train_loss: 0.0951 train_auc: 0.9055	val_loss: 0.0793 val_auc: 0.8037	test_loss: 0.1359 test_auc: 0.7585
2025-08-16 03:48:33,785 - INFO - train: {'epoch': 36, 'time_epoch': 69.27314, 'eta': 4446.60753, 'eta_hours': 1.23517, 'loss': 0.09466856, 'lr': 7.595e-05, 'params': 514193, 'time_iter': 0.06732, 'accuracy': 0.97134, 'precision': 0.72543, 'recall': 0.37744, 'f1': 0.49653, 'auc': 0.9118}
2025-08-16 03:48:38,180 - INFO - val: {'epoch': 36, 'time_epoch': 4.37184, 'loss': 0.08770978, 'lr': 0, 'params': 514193, 'time_iter': 0.03389, 'accuracy': 0.98006, 'precision': 0.48889, 'recall': 0.2716, 'f1': 0.34921, 'auc': 0.7704}
2025-08-16 03:48:42,467 - INFO - test: {'epoch': 36, 'time_epoch': 4.26989, 'loss': 0.1312854, 'lr': 0, 'params': 514193, 'time_iter': 0.0331, 'accuracy': 0.96523, 'precision': 0.41096, 'recall': 0.23077, 'f1': 0.29557, 'auc': 0.77964}
2025-08-16 03:48:42,470 - INFO - > Epoch 36: took 78.0s (avg 79.6s) | Best so far: epoch 33	train_loss: 0.0951 train_auc: 0.9055	val_loss: 0.0793 val_auc: 0.8037	test_loss: 0.1359 test_auc: 0.7585
2025-08-16 03:49:53,402 - INFO - train: {'epoch': 37, 'time_epoch': 70.86353, 'eta': 4376.48731, 'eta_hours': 1.21569, 'loss': 0.09082993, 'lr': 7.452e-05, 'params': 514193, 'time_iter': 0.06887, 'accuracy': 0.97268, 'precision': 0.75342, 'recall': 0.40179, 'f1': 0.52409, 'auc': 0.91986}
2025-08-16 03:49:57,791 - INFO - val: {'epoch': 37, 'time_epoch': 4.36543, 'loss': 0.08648473, 'lr': 0, 'params': 514193, 'time_iter': 0.03384, 'accuracy': 0.98201, 'precision': 0.6, 'recall': 0.25926, 'f1': 0.36207, 'auc': 0.74551}
2025-08-16 03:50:02,158 - INFO - test: {'epoch': 37, 'time_epoch': 4.34411, 'loss': 0.14226462, 'lr': 0, 'params': 514193, 'time_iter': 0.03368, 'accuracy': 0.96912, 'precision': 0.54545, 'recall': 0.13846, 'f1': 0.22086, 'auc': 0.72802}
2025-08-16 03:50:02,161 - INFO - > Epoch 37: took 79.7s (avg 79.6s) | Best so far: epoch 33	train_loss: 0.0951 train_auc: 0.9055	val_loss: 0.0793 val_auc: 0.8037	test_loss: 0.1359 test_auc: 0.7585
2025-08-16 03:51:14,912 - INFO - train: {'epoch': 38, 'time_epoch': 72.68, 'eta': 4309.17011, 'eta_hours': 1.19699, 'loss': 0.09009684, 'lr': 7.307e-05, 'params': 514193, 'time_iter': 0.07063, 'accuracy': 0.97298, 'precision': 0.75407, 'recall': 0.41315, 'f1': 0.53382, 'auc': 0.92049}
2025-08-16 03:51:19,398 - INFO - val: {'epoch': 38, 'time_epoch': 4.46018, 'loss': 0.08900212, 'lr': 0, 'params': 514193, 'time_iter': 0.03458, 'accuracy': 0.98152, 'precision': 0.56757, 'recall': 0.25926, 'f1': 0.35593, 'auc': 0.73666}
2025-08-16 03:51:23,794 - INFO - test: {'epoch': 38, 'time_epoch': 4.37435, 'loss': 0.14043294, 'lr': 0, 'params': 514193, 'time_iter': 0.03391, 'accuracy': 0.96815, 'precision': 0.49057, 'recall': 0.2, 'f1': 0.28415, 'auc': 0.74638}
2025-08-16 03:51:23,798 - INFO - > Epoch 38: took 81.6s (avg 79.6s) | Best so far: epoch 33	train_loss: 0.0951 train_auc: 0.9055	val_loss: 0.0793 val_auc: 0.8037	test_loss: 0.1359 test_auc: 0.7585
2025-08-16 03:52:35,511 - INFO - train: {'epoch': 39, 'time_epoch': 71.63703, 'eta': 4240.02032, 'eta_hours': 1.17778, 'loss': 0.0901206, 'lr': 7.159e-05, 'params': 514193, 'time_iter': 0.06962, 'accuracy': 0.97334, 'precision': 0.76692, 'recall': 0.41396, 'f1': 0.53769, 'auc': 0.92213}
2025-08-16 03:52:40,088 - INFO - val: {'epoch': 39, 'time_epoch': 4.55297, 'loss': 0.0857871, 'lr': 0, 'params': 514193, 'time_iter': 0.03529, 'accuracy': 0.97909, 'precision': 0.45283, 'recall': 0.2963, 'f1': 0.35821, 'auc': 0.80632}
2025-08-16 03:52:44,581 - INFO - test: {'epoch': 39, 'time_epoch': 4.47467, 'loss': 0.14051291, 'lr': 0, 'params': 514193, 'time_iter': 0.03469, 'accuracy': 0.96353, 'precision': 0.35714, 'recall': 0.19231, 'f1': 0.25, 'auc': 0.75605}
2025-08-16 03:52:44,584 - INFO - > Epoch 39: took 80.8s (avg 79.6s) | Best so far: epoch 39	train_loss: 0.0901 train_auc: 0.9221	val_loss: 0.0858 val_auc: 0.8063	test_loss: 0.1405 test_auc: 0.7560
2025-08-16 03:53:56,607 - INFO - train: {'epoch': 40, 'time_epoch': 71.95274, 'eta': 4171.20352, 'eta_hours': 1.15867, 'loss': 0.0896356, 'lr': 7.008e-05, 'params': 514193, 'time_iter': 0.06992, 'accuracy': 0.97374, 'precision': 0.7875, 'recall': 0.40909, 'f1': 0.53846, 'auc': 0.92557}
2025-08-16 03:54:01,135 - INFO - val: {'epoch': 40, 'time_epoch': 4.50409, 'loss': 0.08680653, 'lr': 0, 'params': 514193, 'time_iter': 0.03492, 'accuracy': 0.97958, 'precision': 0.46512, 'recall': 0.24691, 'f1': 0.32258, 'auc': 0.76905}
2025-08-16 03:54:05,576 - INFO - test: {'epoch': 40, 'time_epoch': 4.42096, 'loss': 0.13697962, 'lr': 0, 'params': 514193, 'time_iter': 0.03427, 'accuracy': 0.96596, 'precision': 0.4359, 'recall': 0.26154, 'f1': 0.32692, 'auc': 0.76147}
2025-08-16 03:54:05,578 - INFO - > Epoch 40: took 81.0s (avg 79.7s) | Best so far: epoch 39	train_loss: 0.0901 train_auc: 0.9221	val_loss: 0.0858 val_auc: 0.8063	test_loss: 0.1405 test_auc: 0.7560
2025-08-16 03:55:17,294 - INFO - train: {'epoch': 41, 'time_epoch': 71.64417, 'eta': 4101.81126, 'eta_hours': 1.13939, 'loss': 0.0872124, 'lr': 6.856e-05, 'params': 514193, 'time_iter': 0.06963, 'accuracy': 0.97337, 'precision': 0.76647, 'recall': 0.41558, 'f1': 0.53895, 'auc': 0.93053}
2025-08-16 03:55:21,844 - INFO - val: {'epoch': 41, 'time_epoch': 4.52428, 'loss': 0.09139889, 'lr': 0, 'params': 514193, 'time_iter': 0.03507, 'accuracy': 0.97933, 'precision': 0.46154, 'recall': 0.2963, 'f1': 0.3609, 'auc': 0.78269}
2025-08-16 03:55:26,300 - INFO - test: {'epoch': 41, 'time_epoch': 4.43766, 'loss': 0.14738943, 'lr': 0, 'params': 514193, 'time_iter': 0.0344, 'accuracy': 0.96669, 'precision': 0.45679, 'recall': 0.28462, 'f1': 0.35071, 'auc': 0.76521}
2025-08-16 03:55:26,303 - INFO - > Epoch 41: took 80.7s (avg 79.7s) | Best so far: epoch 39	train_loss: 0.0901 train_auc: 0.9221	val_loss: 0.0858 val_auc: 0.8063	test_loss: 0.1405 test_auc: 0.7560
2025-08-16 03:56:37,272 - INFO - train: {'epoch': 42, 'time_epoch': 70.89982, 'eta': 4031.32757, 'eta_hours': 1.11981, 'loss': 0.08915621, 'lr': 6.701e-05, 'params': 514193, 'time_iter': 0.0689, 'accuracy': 0.97328, 'precision': 0.76462, 'recall': 0.41396, 'f1': 0.53712, 'auc': 0.92468}
2025-08-16 03:56:41,807 - INFO - val: {'epoch': 42, 'time_epoch': 4.512, 'loss': 0.08247332, 'lr': 0, 'params': 514193, 'time_iter': 0.03498, 'accuracy': 0.98128, 'precision': 0.55263, 'recall': 0.25926, 'f1': 0.35294, 'auc': 0.79383}
2025-08-16 03:56:46,262 - INFO - test: {'epoch': 42, 'time_epoch': 4.43573, 'loss': 0.14023558, 'lr': 0, 'params': 514193, 'time_iter': 0.03439, 'accuracy': 0.96766, 'precision': 0.47887, 'recall': 0.26154, 'f1': 0.33831, 'auc': 0.76207}
2025-08-16 03:56:46,264 - INFO - > Epoch 42: took 80.0s (avg 79.7s) | Best so far: epoch 39	train_loss: 0.0901 train_auc: 0.9221	val_loss: 0.0858 val_auc: 0.8063	test_loss: 0.1405 test_auc: 0.7560
2025-08-16 03:57:58,808 - INFO - train: {'epoch': 43, 'time_epoch': 72.47231, 'eta': 3962.82631, 'eta_hours': 1.10079, 'loss': 0.08790842, 'lr': 6.545e-05, 'params': 514193, 'time_iter': 0.07043, 'accuracy': 0.97389, 'precision': 0.7856, 'recall': 0.4164, 'f1': 0.5443, 'auc': 0.93028}
2025-08-16 03:58:03,372 - INFO - val: {'epoch': 43, 'time_epoch': 4.54039, 'loss': 0.09124897, 'lr': 0, 'params': 514193, 'time_iter': 0.0352, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.34568, 'f1': 0.40876, 'auc': 0.7785}
2025-08-16 03:58:07,852 - INFO - test: {'epoch': 43, 'time_epoch': 4.46081, 'loss': 0.15352454, 'lr': 0, 'params': 514193, 'time_iter': 0.03458, 'accuracy': 0.96402, 'precision': 0.39286, 'recall': 0.25385, 'f1': 0.30841, 'auc': 0.75489}
2025-08-16 03:58:07,855 - INFO - > Epoch 43: took 81.6s (avg 79.8s) | Best so far: epoch 39	train_loss: 0.0901 train_auc: 0.9221	val_loss: 0.0858 val_auc: 0.8063	test_loss: 0.1405 test_auc: 0.7560
2025-08-16 03:59:19,550 - INFO - train: {'epoch': 44, 'time_epoch': 71.62279, 'eta': 3893.11027, 'eta_hours': 1.08142, 'loss': 0.08610295, 'lr': 6.387e-05, 'params': 514193, 'time_iter': 0.0696, 'accuracy': 0.97447, 'precision': 0.78571, 'recall': 0.4375, 'f1': 0.56204, 'auc': 0.93166}
2025-08-16 03:59:24,016 - INFO - val: {'epoch': 44, 'time_epoch': 4.44078, 'loss': 0.08729951, 'lr': 0, 'params': 514193, 'time_iter': 0.03442, 'accuracy': 0.98079, 'precision': 0.52273, 'recall': 0.28395, 'f1': 0.368, 'auc': 0.7751}
2025-08-16 03:59:28,367 - INFO - test: {'epoch': 44, 'time_epoch': 4.33296, 'loss': 0.15045217, 'lr': 0, 'params': 514193, 'time_iter': 0.03359, 'accuracy': 0.96645, 'precision': 0.39474, 'recall': 0.11538, 'f1': 0.17857, 'auc': 0.73798}
2025-08-16 03:59:28,370 - INFO - > Epoch 44: took 80.5s (avg 79.8s) | Best so far: epoch 39	train_loss: 0.0901 train_auc: 0.9221	val_loss: 0.0858 val_auc: 0.8063	test_loss: 0.1405 test_auc: 0.7560
2025-08-16 04:00:38,706 - INFO - train: {'epoch': 45, 'time_epoch': 70.26774, 'eta': 3821.72061, 'eta_hours': 1.06159, 'loss': 0.08418227, 'lr': 6.227e-05, 'params': 514193, 'time_iter': 0.06829, 'accuracy': 0.97398, 'precision': 0.77089, 'recall': 0.43425, 'f1': 0.55556, 'auc': 0.93729}
2025-08-16 04:00:43,080 - INFO - val: {'epoch': 45, 'time_epoch': 4.35141, 'loss': 0.08767187, 'lr': 0, 'params': 514193, 'time_iter': 0.03373, 'accuracy': 0.97982, 'precision': 0.48214, 'recall': 0.33333, 'f1': 0.39416, 'auc': 0.80357}
2025-08-16 04:00:47,404 - INFO - test: {'epoch': 45, 'time_epoch': 4.30442, 'loss': 0.1417258, 'lr': 0, 'params': 514193, 'time_iter': 0.03337, 'accuracy': 0.96475, 'precision': 0.3913, 'recall': 0.20769, 'f1': 0.27136, 'auc': 0.77878}
2025-08-16 04:00:47,407 - INFO - > Epoch 45: took 79.0s (avg 79.8s) | Best so far: epoch 39	train_loss: 0.0901 train_auc: 0.9221	val_loss: 0.0858 val_auc: 0.8063	test_loss: 0.1405 test_auc: 0.7560
2025-08-16 04:01:59,137 - INFO - train: {'epoch': 46, 'time_epoch': 71.65418, 'eta': 3751.94212, 'eta_hours': 1.04221, 'loss': 0.08436739, 'lr': 6.066e-05, 'params': 514193, 'time_iter': 0.06963, 'accuracy': 0.9738, 'precision': 0.77612, 'recall': 0.42208, 'f1': 0.54679, 'auc': 0.93801}
2025-08-16 04:02:03,698 - INFO - val: {'epoch': 46, 'time_epoch': 4.53883, 'loss': 0.08843117, 'lr': 0, 'params': 514193, 'time_iter': 0.03518, 'accuracy': 0.97909, 'precision': 0.45763, 'recall': 0.33333, 'f1': 0.38571, 'auc': 0.80052}
2025-08-16 04:02:07,991 - INFO - test: {'epoch': 46, 'time_epoch': 4.27374, 'loss': 0.14345705, 'lr': 0, 'params': 514193, 'time_iter': 0.03313, 'accuracy': 0.96207, 'precision': 0.35227, 'recall': 0.23846, 'f1': 0.2844, 'auc': 0.77348}
2025-08-16 04:02:07,994 - INFO - > Epoch 46: took 80.6s (avg 79.8s) | Best so far: epoch 39	train_loss: 0.0901 train_auc: 0.9221	val_loss: 0.0858 val_auc: 0.8063	test_loss: 0.1405 test_auc: 0.7560
2025-08-16 04:03:18,964 - INFO - train: {'epoch': 47, 'time_epoch': 70.89949, 'eta': 3681.2679, 'eta_hours': 1.02257, 'loss': 0.08305218, 'lr': 5.904e-05, 'params': 514193, 'time_iter': 0.0689, 'accuracy': 0.9745, 'precision': 0.7733, 'recall': 0.4513, 'f1': 0.56996, 'auc': 0.93902}
2025-08-16 04:03:23,449 - INFO - val: {'epoch': 47, 'time_epoch': 4.46145, 'loss': 0.08714936, 'lr': 0, 'params': 514193, 'time_iter': 0.03458, 'accuracy': 0.9786, 'precision': 0.44444, 'recall': 0.34568, 'f1': 0.38889, 'auc': 0.80048}
2025-08-16 04:03:27,824 - INFO - test: {'epoch': 47, 'time_epoch': 4.35667, 'loss': 0.15281005, 'lr': 0, 'params': 514193, 'time_iter': 0.03377, 'accuracy': 0.96377, 'precision': 0.37975, 'recall': 0.23077, 'f1': 0.28708, 'auc': 0.74247}
2025-08-16 04:03:27,826 - INFO - > Epoch 47: took 79.8s (avg 79.8s) | Best so far: epoch 39	train_loss: 0.0901 train_auc: 0.9221	val_loss: 0.0858 val_auc: 0.8063	test_loss: 0.1405 test_auc: 0.7560
2025-08-16 04:04:39,424 - INFO - train: {'epoch': 48, 'time_epoch': 71.52912, 'eta': 3611.23982, 'eta_hours': 1.00312, 'loss': 0.08203909, 'lr': 5.741e-05, 'params': 514193, 'time_iter': 0.06951, 'accuracy': 0.97508, 'precision': 0.80473, 'recall': 0.44156, 'f1': 0.57023, 'auc': 0.9426}
2025-08-16 04:04:43,884 - INFO - val: {'epoch': 48, 'time_epoch': 4.43759, 'loss': 0.08662207, 'lr': 0, 'params': 514193, 'time_iter': 0.0344, 'accuracy': 0.97958, 'precision': 0.47368, 'recall': 0.33333, 'f1': 0.3913, 'auc': 0.8004}
2025-08-16 04:04:48,247 - INFO - test: {'epoch': 48, 'time_epoch': 4.34492, 'loss': 0.14474281, 'lr': 0, 'params': 514193, 'time_iter': 0.03368, 'accuracy': 0.9628, 'precision': 0.35065, 'recall': 0.20769, 'f1': 0.26087, 'auc': 0.77225}
2025-08-16 04:04:48,249 - INFO - > Epoch 48: took 80.4s (avg 79.8s) | Best so far: epoch 39	train_loss: 0.0901 train_auc: 0.9221	val_loss: 0.0858 val_auc: 0.8063	test_loss: 0.1405 test_auc: 0.7560
2025-08-16 04:06:00,107 - INFO - train: {'epoch': 49, 'time_epoch': 71.78646, 'eta': 3541.40903, 'eta_hours': 0.98372, 'loss': 0.0795533, 'lr': 5.577e-05, 'params': 514193, 'time_iter': 0.06976, 'accuracy': 0.97556, 'precision': 0.79805, 'recall': 0.4651, 'f1': 0.58769, 'auc': 0.94591}
2025-08-16 04:06:04,557 - INFO - val: {'epoch': 49, 'time_epoch': 4.42663, 'loss': 0.08895051, 'lr': 0, 'params': 514193, 'time_iter': 0.03431, 'accuracy': 0.97909, 'precision': 0.45763, 'recall': 0.33333, 'f1': 0.38571, 'auc': 0.79105}
2025-08-16 04:06:08,913 - INFO - test: {'epoch': 49, 'time_epoch': 4.33789, 'loss': 0.14843368, 'lr': 0, 'params': 514193, 'time_iter': 0.03363, 'accuracy': 0.96304, 'precision': 0.36905, 'recall': 0.23846, 'f1': 0.28972, 'auc': 0.77156}
2025-08-16 04:06:08,915 - INFO - > Epoch 49: took 80.7s (avg 79.8s) | Best so far: epoch 39	train_loss: 0.0901 train_auc: 0.9221	val_loss: 0.0858 val_auc: 0.8063	test_loss: 0.1405 test_auc: 0.7560
2025-08-16 04:07:21,375 - INFO - train: {'epoch': 50, 'time_epoch': 72.38436, 'eta': 3472.076, 'eta_hours': 0.96447, 'loss': 0.08119939, 'lr': 5.413e-05, 'params': 514193, 'time_iter': 0.07034, 'accuracy': 0.97499, 'precision': 0.80296, 'recall': 0.43994, 'f1': 0.56843, 'auc': 0.94451}
2025-08-16 04:07:26,088 - INFO - val: {'epoch': 50, 'time_epoch': 4.68616, 'loss': 0.09212909, 'lr': 0, 'params': 514193, 'time_iter': 0.03633, 'accuracy': 0.97617, 'precision': 0.37681, 'recall': 0.32099, 'f1': 0.34667, 'auc': 0.80216}
2025-08-16 04:07:30,703 - INFO - test: {'epoch': 50, 'time_epoch': 4.59375, 'loss': 0.15229692, 'lr': 0, 'params': 514193, 'time_iter': 0.03561, 'accuracy': 0.96499, 'precision': 0.4125, 'recall': 0.25385, 'f1': 0.31429, 'auc': 0.77741}
2025-08-16 04:07:30,705 - INFO - > Epoch 50: took 81.8s (avg 79.8s) | Best so far: epoch 39	train_loss: 0.0901 train_auc: 0.9221	val_loss: 0.0858 val_auc: 0.8063	test_loss: 0.1405 test_auc: 0.7560
2025-08-16 04:08:41,455 - INFO - train: {'epoch': 51, 'time_epoch': 70.68061, 'eta': 3401.05293, 'eta_hours': 0.94474, 'loss': 0.08085918, 'lr': 5.248e-05, 'params': 514193, 'time_iter': 0.06869, 'accuracy': 0.97547, 'precision': 0.79804, 'recall': 0.46185, 'f1': 0.58509, 'auc': 0.94207}
2025-08-16 04:08:45,889 - INFO - val: {'epoch': 51, 'time_epoch': 4.41103, 'loss': 0.08552941, 'lr': 0, 'params': 514193, 'time_iter': 0.03419, 'accuracy': 0.97836, 'precision': 0.43103, 'recall': 0.30864, 'f1': 0.35971, 'auc': 0.81979}
2025-08-16 04:08:50,235 - INFO - test: {'epoch': 51, 'time_epoch': 4.32747, 'loss': 0.14717399, 'lr': 0, 'params': 514193, 'time_iter': 0.03355, 'accuracy': 0.96523, 'precision': 0.41558, 'recall': 0.24615, 'f1': 0.30918, 'auc': 0.77493}
2025-08-16 04:08:50,237 - INFO - > Epoch 51: took 79.5s (avg 79.8s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:10:01,650 - INFO - train: {'epoch': 52, 'time_epoch': 71.34054, 'eta': 3330.62799, 'eta_hours': 0.92517, 'loss': 0.07884358, 'lr': 5.083e-05, 'params': 514193, 'time_iter': 0.06933, 'accuracy': 0.97556, 'precision': 0.79972, 'recall': 0.46347, 'f1': 0.58684, 'auc': 0.94731}
2025-08-16 04:10:06,093 - INFO - val: {'epoch': 52, 'time_epoch': 4.41923, 'loss': 0.09711967, 'lr': 0, 'params': 514193, 'time_iter': 0.03426, 'accuracy': 0.97958, 'precision': 0.47887, 'recall': 0.41975, 'f1': 0.44737, 'auc': 0.77501}
2025-08-16 04:10:10,477 - INFO - test: {'epoch': 52, 'time_epoch': 4.36517, 'loss': 0.16064905, 'lr': 0, 'params': 514193, 'time_iter': 0.03384, 'accuracy': 0.96329, 'precision': 0.38202, 'recall': 0.26154, 'f1': 0.3105, 'auc': 0.76489}
2025-08-16 04:10:10,479 - INFO - > Epoch 52: took 80.2s (avg 79.8s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:11:19,116 - INFO - train: {'epoch': 53, 'time_epoch': 68.57046, 'eta': 3257.80945, 'eta_hours': 0.90495, 'loss': 0.07944627, 'lr': 4.917e-05, 'params': 514193, 'time_iter': 0.06664, 'accuracy': 0.97541, 'precision': 0.78697, 'recall': 0.47078, 'f1': 0.58913, 'auc': 0.94735}
2025-08-16 04:11:23,518 - INFO - val: {'epoch': 53, 'time_epoch': 4.37882, 'loss': 0.09042378, 'lr': 0, 'params': 514193, 'time_iter': 0.03394, 'accuracy': 0.97909, 'precision': 0.45614, 'recall': 0.32099, 'f1': 0.37681, 'auc': 0.80504}
2025-08-16 04:11:27,814 - INFO - test: {'epoch': 53, 'time_epoch': 4.27841, 'loss': 0.14632951, 'lr': 0, 'params': 514193, 'time_iter': 0.03317, 'accuracy': 0.96475, 'precision': 0.40964, 'recall': 0.26154, 'f1': 0.31925, 'auc': 0.7786}
2025-08-16 04:11:27,816 - INFO - > Epoch 53: took 77.3s (avg 79.8s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:12:37,649 - INFO - train: {'epoch': 54, 'time_epoch': 69.76493, 'eta': 3186.12267, 'eta_hours': 0.88503, 'loss': 0.07952083, 'lr': 4.752e-05, 'params': 514193, 'time_iter': 0.0678, 'accuracy': 0.97489, 'precision': 0.79, 'recall': 0.44886, 'f1': 0.57246, 'auc': 0.94748}
2025-08-16 04:12:42,155 - INFO - val: {'epoch': 54, 'time_epoch': 4.44033, 'loss': 0.10246642, 'lr': 0, 'params': 514193, 'time_iter': 0.03442, 'accuracy': 0.97423, 'precision': 0.34568, 'recall': 0.34568, 'f1': 0.34568, 'auc': 0.77776}
2025-08-16 04:12:46,504 - INFO - test: {'epoch': 54, 'time_epoch': 4.33083, 'loss': 0.15597737, 'lr': 0, 'params': 514193, 'time_iter': 0.03357, 'accuracy': 0.96231, 'precision': 0.37374, 'recall': 0.28462, 'f1': 0.32314, 'auc': 0.77307}
2025-08-16 04:12:46,507 - INFO - > Epoch 54: took 78.7s (avg 79.8s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:13:57,719 - INFO - train: {'epoch': 55, 'time_epoch': 71.14204, 'eta': 3115.58655, 'eta_hours': 0.86544, 'loss': 0.07771445, 'lr': 4.587e-05, 'params': 514193, 'time_iter': 0.06914, 'accuracy': 0.97572, 'precision': 0.79617, 'recall': 0.4724, 'f1': 0.59297, 'auc': 0.95122}
2025-08-16 04:14:02,219 - INFO - val: {'epoch': 55, 'time_epoch': 4.47643, 'loss': 0.09383494, 'lr': 0, 'params': 514193, 'time_iter': 0.0347, 'accuracy': 0.97933, 'precision': 0.46, 'recall': 0.28395, 'f1': 0.35115, 'auc': 0.79234}
2025-08-16 04:14:06,648 - INFO - test: {'epoch': 55, 'time_epoch': 4.4104, 'loss': 0.15246499, 'lr': 0, 'params': 514193, 'time_iter': 0.03419, 'accuracy': 0.96499, 'precision': 0.40789, 'recall': 0.23846, 'f1': 0.30097, 'auc': 0.76869}
2025-08-16 04:14:06,651 - INFO - > Epoch 55: took 80.1s (avg 79.8s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:15:19,272 - INFO - train: {'epoch': 56, 'time_epoch': 72.54967, 'eta': 3046.09107, 'eta_hours': 0.84614, 'loss': 0.07758355, 'lr': 4.423e-05, 'params': 514193, 'time_iter': 0.07051, 'accuracy': 0.97611, 'precision': 0.81145, 'recall': 0.47159, 'f1': 0.59651, 'auc': 0.95}
2025-08-16 04:15:23,808 - INFO - val: {'epoch': 56, 'time_epoch': 4.51184, 'loss': 0.09321042, 'lr': 0, 'params': 514193, 'time_iter': 0.03498, 'accuracy': 0.97933, 'precision': 0.45652, 'recall': 0.25926, 'f1': 0.33071, 'auc': 0.78035}
2025-08-16 04:15:28,237 - INFO - test: {'epoch': 56, 'time_epoch': 4.40943, 'loss': 0.1582581, 'lr': 0, 'params': 514193, 'time_iter': 0.03418, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.2, 'f1': 0.28571, 'auc': 0.75508}
2025-08-16 04:15:28,239 - INFO - > Epoch 56: took 81.6s (avg 79.8s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:16:40,442 - INFO - train: {'epoch': 57, 'time_epoch': 72.12652, 'eta': 2976.18384, 'eta_hours': 0.82672, 'loss': 0.07757435, 'lr': 4.259e-05, 'params': 514193, 'time_iter': 0.07009, 'accuracy': 0.97605, 'precision': 0.80245, 'recall': 0.47808, 'f1': 0.59919, 'auc': 0.95149}
2025-08-16 04:16:45,191 - INFO - val: {'epoch': 57, 'time_epoch': 4.72304, 'loss': 0.09270993, 'lr': 0, 'params': 514193, 'time_iter': 0.03661, 'accuracy': 0.9769, 'precision': 0.39394, 'recall': 0.32099, 'f1': 0.35374, 'auc': 0.8034}
2025-08-16 04:16:49,855 - INFO - test: {'epoch': 57, 'time_epoch': 4.64417, 'loss': 0.14860198, 'lr': 0, 'params': 514193, 'time_iter': 0.036, 'accuracy': 0.96475, 'precision': 0.40506, 'recall': 0.24615, 'f1': 0.30622, 'auc': 0.77265}
2025-08-16 04:16:49,858 - INFO - > Epoch 57: took 81.6s (avg 79.8s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:18:03,619 - INFO - train: {'epoch': 58, 'time_epoch': 73.69015, 'eta': 2907.28798, 'eta_hours': 0.80758, 'loss': 0.07436953, 'lr': 4.096e-05, 'params': 514193, 'time_iter': 0.07161, 'accuracy': 0.97617, 'precision': 0.7963, 'recall': 0.48864, 'f1': 0.60563, 'auc': 0.95684}
2025-08-16 04:18:08,317 - INFO - val: {'epoch': 58, 'time_epoch': 4.67322, 'loss': 0.10016328, 'lr': 0, 'params': 514193, 'time_iter': 0.03623, 'accuracy': 0.97617, 'precision': 0.37681, 'recall': 0.32099, 'f1': 0.34667, 'auc': 0.77706}
2025-08-16 04:18:12,962 - INFO - test: {'epoch': 58, 'time_epoch': 4.62524, 'loss': 0.16649403, 'lr': 0, 'params': 514193, 'time_iter': 0.03585, 'accuracy': 0.96061, 'precision': 0.32609, 'recall': 0.23077, 'f1': 0.27027, 'auc': 0.75905}
2025-08-16 04:18:12,965 - INFO - > Epoch 58: took 83.1s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:19:24,797 - INFO - train: {'epoch': 59, 'time_epoch': 71.76172, 'eta': 2836.94669, 'eta_hours': 0.78804, 'loss': 0.07542318, 'lr': 3.934e-05, 'params': 514193, 'time_iter': 0.06974, 'accuracy': 0.97666, 'precision': 0.81099, 'recall': 0.49107, 'f1': 0.61173, 'auc': 0.95441}
2025-08-16 04:19:29,245 - INFO - val: {'epoch': 59, 'time_epoch': 4.42396, 'loss': 0.09445729, 'lr': 0, 'params': 514193, 'time_iter': 0.03429, 'accuracy': 0.97739, 'precision': 0.40323, 'recall': 0.30864, 'f1': 0.34965, 'auc': 0.81404}
2025-08-16 04:19:33,700 - INFO - test: {'epoch': 59, 'time_epoch': 4.43626, 'loss': 0.16452844, 'lr': 0, 'params': 514193, 'time_iter': 0.03439, 'accuracy': 0.96402, 'precision': 0.39286, 'recall': 0.25385, 'f1': 0.30841, 'auc': 0.7612}
2025-08-16 04:19:33,703 - INFO - > Epoch 59: took 80.7s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:20:44,651 - INFO - train: {'epoch': 60, 'time_epoch': 70.88022, 'eta': 2765.99525, 'eta_hours': 0.76833, 'loss': 0.07452561, 'lr': 3.773e-05, 'params': 514193, 'time_iter': 0.06888, 'accuracy': 0.97623, 'precision': 0.79145, 'recall': 0.49594, 'f1': 0.60978, 'auc': 0.957}
2025-08-16 04:20:49,020 - INFO - val: {'epoch': 60, 'time_epoch': 4.34639, 'loss': 0.09488168, 'lr': 0, 'params': 514193, 'time_iter': 0.03369, 'accuracy': 0.97763, 'precision': 0.42254, 'recall': 0.37037, 'f1': 0.39474, 'auc': 0.80095}
2025-08-16 04:20:53,324 - INFO - test: {'epoch': 60, 'time_epoch': 4.28641, 'loss': 0.16154035, 'lr': 0, 'params': 514193, 'time_iter': 0.03323, 'accuracy': 0.96183, 'precision': 0.35789, 'recall': 0.26154, 'f1': 0.30222, 'auc': 0.77028}
2025-08-16 04:20:53,326 - INFO - > Epoch 60: took 79.6s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:22:03,590 - INFO - train: {'epoch': 61, 'time_epoch': 70.19218, 'eta': 2694.6244, 'eta_hours': 0.74851, 'loss': 0.07452561, 'lr': 3.613e-05, 'params': 514193, 'time_iter': 0.06821, 'accuracy': 0.97632, 'precision': 0.8008, 'recall': 0.48945, 'f1': 0.60756, 'auc': 0.95638}
2025-08-16 04:22:08,206 - INFO - val: {'epoch': 61, 'time_epoch': 4.593, 'loss': 0.09593582, 'lr': 0, 'params': 514193, 'time_iter': 0.0356, 'accuracy': 0.97982, 'precision': 0.48276, 'recall': 0.34568, 'f1': 0.40288, 'auc': 0.79196}
2025-08-16 04:22:12,725 - INFO - test: {'epoch': 61, 'time_epoch': 4.49871, 'loss': 0.16895627, 'lr': 0, 'params': 514193, 'time_iter': 0.03487, 'accuracy': 0.9645, 'precision': 0.36667, 'recall': 0.16923, 'f1': 0.23158, 'auc': 0.76858}
2025-08-16 04:22:12,727 - INFO - > Epoch 61: took 79.4s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:23:23,138 - INFO - train: {'epoch': 62, 'time_epoch': 70.34284, 'eta': 2623.37945, 'eta_hours': 0.72872, 'loss': 0.07302051, 'lr': 3.455e-05, 'params': 514193, 'time_iter': 0.06836, 'accuracy': 0.97666, 'precision': 0.79897, 'recall': 0.50325, 'f1': 0.61753, 'auc': 0.95973}
2025-08-16 04:23:27,517 - INFO - val: {'epoch': 62, 'time_epoch': 4.35675, 'loss': 0.09934965, 'lr': 0, 'params': 514193, 'time_iter': 0.03377, 'accuracy': 0.97909, 'precision': 0.44898, 'recall': 0.2716, 'f1': 0.33846, 'auc': 0.7804}
2025-08-16 04:23:31,975 - INFO - test: {'epoch': 62, 'time_epoch': 4.32581, 'loss': 0.17011187, 'lr': 0, 'params': 514193, 'time_iter': 0.03353, 'accuracy': 0.96475, 'precision': 0.4, 'recall': 0.23077, 'f1': 0.29268, 'auc': 0.7521}
2025-08-16 04:23:31,977 - INFO - > Epoch 62: took 79.2s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:24:42,093 - INFO - train: {'epoch': 63, 'time_epoch': 70.04623, 'eta': 2551.99585, 'eta_hours': 0.70889, 'loss': 0.0734069, 'lr': 3.299e-05, 'params': 514193, 'time_iter': 0.06807, 'accuracy': 0.97711, 'precision': 0.82409, 'recall': 0.49432, 'f1': 0.61796, 'auc': 0.9588}
2025-08-16 04:24:46,507 - INFO - val: {'epoch': 63, 'time_epoch': 4.39126, 'loss': 0.10039949, 'lr': 0, 'params': 514193, 'time_iter': 0.03404, 'accuracy': 0.97933, 'precision': 0.46, 'recall': 0.28395, 'f1': 0.35115, 'auc': 0.76895}
2025-08-16 04:24:50,828 - INFO - test: {'epoch': 63, 'time_epoch': 4.30227, 'loss': 0.1631752, 'lr': 0, 'params': 514193, 'time_iter': 0.03335, 'accuracy': 0.96523, 'precision': 0.4058, 'recall': 0.21538, 'f1': 0.28141, 'auc': 0.76319}
2025-08-16 04:24:50,831 - INFO - > Epoch 63: took 78.9s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:25:59,927 - INFO - train: {'epoch': 64, 'time_epoch': 69.02976, 'eta': 2480.10607, 'eta_hours': 0.68892, 'loss': 0.07248003, 'lr': 3.144e-05, 'params': 514193, 'time_iter': 0.06708, 'accuracy': 0.97641, 'precision': 0.8, 'recall': 0.49351, 'f1': 0.61044, 'auc': 0.96016}
2025-08-16 04:26:04,273 - INFO - val: {'epoch': 64, 'time_epoch': 4.32371, 'loss': 0.09693292, 'lr': 0, 'params': 514193, 'time_iter': 0.03352, 'accuracy': 0.98055, 'precision': 0.51111, 'recall': 0.28395, 'f1': 0.36508, 'auc': 0.78433}
2025-08-16 04:26:08,521 - INFO - test: {'epoch': 64, 'time_epoch': 4.23073, 'loss': 0.16539294, 'lr': 0, 'params': 514193, 'time_iter': 0.0328, 'accuracy': 0.96377, 'precision': 0.37662, 'recall': 0.22308, 'f1': 0.28019, 'auc': 0.7613}
2025-08-16 04:26:08,524 - INFO - > Epoch 64: took 77.7s (avg 79.8s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:27:17,310 - INFO - train: {'epoch': 65, 'time_epoch': 68.71853, 'eta': 2408.14263, 'eta_hours': 0.66893, 'loss': 0.07095066, 'lr': 2.992e-05, 'params': 514193, 'time_iter': 0.06678, 'accuracy': 0.97757, 'precision': 0.82078, 'recall': 0.51299, 'f1': 0.63137, 'auc': 0.96266}
2025-08-16 04:27:21,763 - INFO - val: {'epoch': 65, 'time_epoch': 4.42794, 'loss': 0.09718961, 'lr': 0, 'params': 514193, 'time_iter': 0.03433, 'accuracy': 0.98006, 'precision': 0.4902, 'recall': 0.30864, 'f1': 0.37879, 'auc': 0.79247}
2025-08-16 04:27:26,054 - INFO - test: {'epoch': 65, 'time_epoch': 4.27353, 'loss': 0.16043889, 'lr': 0, 'params': 514193, 'time_iter': 0.03313, 'accuracy': 0.96523, 'precision': 0.40845, 'recall': 0.22308, 'f1': 0.28856, 'auc': 0.76662}
2025-08-16 04:27:26,057 - INFO - > Epoch 65: took 77.5s (avg 79.8s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:28:39,809 - INFO - train: {'epoch': 66, 'time_epoch': 73.67707, 'eta': 2338.71831, 'eta_hours': 0.64964, 'loss': 0.07266334, 'lr': 2.841e-05, 'params': 514193, 'time_iter': 0.0716, 'accuracy': 0.97693, 'precision': 0.80595, 'recall': 0.50568, 'f1': 0.62145, 'auc': 0.95983}
2025-08-16 04:28:44,453 - INFO - val: {'epoch': 66, 'time_epoch': 4.57425, 'loss': 0.09999623, 'lr': 0, 'params': 514193, 'time_iter': 0.03546, 'accuracy': 0.97812, 'precision': 0.42105, 'recall': 0.2963, 'f1': 0.34783, 'auc': 0.79617}
2025-08-16 04:28:49,023 - INFO - test: {'epoch': 66, 'time_epoch': 4.48674, 'loss': 0.17208912, 'lr': 0, 'params': 514193, 'time_iter': 0.03478, 'accuracy': 0.9645, 'precision': 0.39189, 'recall': 0.22308, 'f1': 0.28431, 'auc': 0.76683}
2025-08-16 04:28:49,043 - INFO - > Epoch 66: took 83.0s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:30:02,167 - INFO - train: {'epoch': 67, 'time_epoch': 73.05322, 'eta': 2268.87534, 'eta_hours': 0.63024, 'loss': 0.06971818, 'lr': 2.693e-05, 'params': 514193, 'time_iter': 0.07099, 'accuracy': 0.97763, 'precision': 0.81633, 'recall': 0.51948, 'f1': 0.63492, 'auc': 0.96478}
2025-08-16 04:30:06,659 - INFO - val: {'epoch': 67, 'time_epoch': 4.4682, 'loss': 0.10666786, 'lr': 0, 'params': 514193, 'time_iter': 0.03464, 'accuracy': 0.97739, 'precision': 0.4, 'recall': 0.2963, 'f1': 0.34043, 'auc': 0.76587}
2025-08-16 04:30:11,075 - INFO - test: {'epoch': 67, 'time_epoch': 4.3978, 'loss': 0.17083953, 'lr': 0, 'params': 514193, 'time_iter': 0.03409, 'accuracy': 0.96353, 'precision': 0.38372, 'recall': 0.25385, 'f1': 0.30556, 'auc': 0.75804}
2025-08-16 04:30:11,078 - INFO - > Epoch 67: took 82.0s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:31:23,771 - INFO - train: {'epoch': 68, 'time_epoch': 72.62158, 'eta': 2198.74539, 'eta_hours': 0.61076, 'loss': 0.06975654, 'lr': 2.548e-05, 'params': 514193, 'time_iter': 0.07057, 'accuracy': 0.97778, 'precision': 0.82074, 'recall': 0.52029, 'f1': 0.63686, 'auc': 0.96315}
2025-08-16 04:31:28,218 - INFO - val: {'epoch': 68, 'time_epoch': 4.42355, 'loss': 0.11056102, 'lr': 0, 'params': 514193, 'time_iter': 0.03429, 'accuracy': 0.97423, 'precision': 0.33333, 'recall': 0.30864, 'f1': 0.32051, 'auc': 0.76553}
2025-08-16 04:31:32,579 - INFO - test: {'epoch': 68, 'time_epoch': 4.34262, 'loss': 0.17347389, 'lr': 0, 'params': 514193, 'time_iter': 0.03366, 'accuracy': 0.96159, 'precision': 0.35714, 'recall': 0.26923, 'f1': 0.30702, 'auc': 0.76055}
2025-08-16 04:31:32,581 - INFO - > Epoch 68: took 81.5s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:32:42,027 - INFO - train: {'epoch': 69, 'time_epoch': 69.37865, 'eta': 2127.15443, 'eta_hours': 0.59088, 'loss': 0.06915381, 'lr': 2.405e-05, 'params': 514193, 'time_iter': 0.06742, 'accuracy': 0.97793, 'precision': 0.8139, 'recall': 0.53247, 'f1': 0.64377, 'auc': 0.96433}
2025-08-16 04:32:46,480 - INFO - val: {'epoch': 69, 'time_epoch': 4.42955, 'loss': 0.10670435, 'lr': 0, 'params': 514193, 'time_iter': 0.03434, 'accuracy': 0.97739, 'precision': 0.4, 'recall': 0.2963, 'f1': 0.34043, 'auc': 0.77042}
2025-08-16 04:32:50,855 - INFO - test: {'epoch': 69, 'time_epoch': 4.34555, 'loss': 0.17618795, 'lr': 0, 'params': 514193, 'time_iter': 0.03369, 'accuracy': 0.96426, 'precision': 0.38667, 'recall': 0.22308, 'f1': 0.28293, 'auc': 0.76268}
2025-08-16 04:32:50,858 - INFO - > Epoch 69: took 78.3s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:34:02,914 - INFO - train: {'epoch': 70, 'time_epoch': 71.98336, 'eta': 2056.68967, 'eta_hours': 0.5713, 'loss': 0.0698012, 'lr': 2.265e-05, 'params': 514193, 'time_iter': 0.06995, 'accuracy': 0.97769, 'precision': 0.8097, 'recall': 0.52841, 'f1': 0.63949, 'auc': 0.96576}
2025-08-16 04:34:07,503 - INFO - val: {'epoch': 70, 'time_epoch': 4.56427, 'loss': 0.10326252, 'lr': 0, 'params': 514193, 'time_iter': 0.03538, 'accuracy': 0.97958, 'precision': 0.4717, 'recall': 0.30864, 'f1': 0.37313, 'auc': 0.76799}
2025-08-16 04:34:12,013 - INFO - test: {'epoch': 70, 'time_epoch': 4.49096, 'loss': 0.17483918, 'lr': 0, 'params': 514193, 'time_iter': 0.03481, 'accuracy': 0.96377, 'precision': 0.36232, 'recall': 0.19231, 'f1': 0.25126, 'auc': 0.75576}
2025-08-16 04:34:12,016 - INFO - > Epoch 70: took 81.2s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:35:23,574 - INFO - train: {'epoch': 71, 'time_epoch': 71.48829, 'eta': 1985.99021, 'eta_hours': 0.55166, 'loss': 0.06850403, 'lr': 2.128e-05, 'params': 514193, 'time_iter': 0.06947, 'accuracy': 0.97772, 'precision': 0.81227, 'recall': 0.52679, 'f1': 0.63909, 'auc': 0.96761}
2025-08-16 04:35:28,020 - INFO - val: {'epoch': 71, 'time_epoch': 4.42293, 'loss': 0.11872654, 'lr': 0, 'params': 514193, 'time_iter': 0.03429, 'accuracy': 0.97398, 'precision': 0.3375, 'recall': 0.33333, 'f1': 0.3354, 'auc': 0.77728}
2025-08-16 04:35:32,382 - INFO - test: {'epoch': 71, 'time_epoch': 4.34414, 'loss': 0.18752498, 'lr': 0, 'params': 514193, 'time_iter': 0.03368, 'accuracy': 0.96061, 'precision': 0.33673, 'recall': 0.25385, 'f1': 0.28947, 'auc': 0.75361}
2025-08-16 04:35:32,385 - INFO - > Epoch 71: took 80.4s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:36:43,554 - INFO - train: {'epoch': 72, 'time_epoch': 71.0974, 'eta': 1915.12456, 'eta_hours': 0.53198, 'loss': 0.06694639, 'lr': 1.995e-05, 'params': 514193, 'time_iter': 0.06909, 'accuracy': 0.97839, 'precision': 0.81423, 'recall': 0.54789, 'f1': 0.65502, 'auc': 0.96664}
2025-08-16 04:36:48,001 - INFO - val: {'epoch': 72, 'time_epoch': 4.42354, 'loss': 0.10291687, 'lr': 0, 'params': 514193, 'time_iter': 0.03429, 'accuracy': 0.97933, 'precision': 0.45833, 'recall': 0.2716, 'f1': 0.34109, 'auc': 0.77689}
2025-08-16 04:36:52,380 - INFO - test: {'epoch': 72, 'time_epoch': 4.3615, 'loss': 0.1720735, 'lr': 0, 'params': 514193, 'time_iter': 0.03381, 'accuracy': 0.96499, 'precision': 0.39706, 'recall': 0.20769, 'f1': 0.27273, 'auc': 0.76599}
2025-08-16 04:36:52,383 - INFO - > Epoch 72: took 80.0s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:38:03,949 - INFO - train: {'epoch': 73, 'time_epoch': 71.49012, 'eta': 1844.39063, 'eta_hours': 0.51233, 'loss': 0.06908348, 'lr': 1.864e-05, 'params': 514193, 'time_iter': 0.06948, 'accuracy': 0.9776, 'precision': 0.80899, 'recall': 0.52597, 'f1': 0.63748, 'auc': 0.96608}
2025-08-16 04:38:08,690 - INFO - val: {'epoch': 73, 'time_epoch': 4.71496, 'loss': 0.10120345, 'lr': 0, 'params': 514193, 'time_iter': 0.03655, 'accuracy': 0.97763, 'precision': 0.41791, 'recall': 0.34568, 'f1': 0.37838, 'auc': 0.79763}
2025-08-16 04:38:13,255 - INFO - test: {'epoch': 73, 'time_epoch': 4.54475, 'loss': 0.17301257, 'lr': 0, 'params': 514193, 'time_iter': 0.03523, 'accuracy': 0.96377, 'precision': 0.38824, 'recall': 0.25385, 'f1': 0.30698, 'auc': 0.767}
2025-08-16 04:38:13,258 - INFO - > Epoch 73: took 80.9s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:39:26,857 - INFO - train: {'epoch': 74, 'time_epoch': 73.52682, 'eta': 1774.31544, 'eta_hours': 0.49287, 'loss': 0.065806, 'lr': 1.737e-05, 'params': 514193, 'time_iter': 0.07145, 'accuracy': 0.97845, 'precision': 0.82007, 'recall': 0.54383, 'f1': 0.65398, 'auc': 0.97047}
2025-08-16 04:39:31,423 - INFO - val: {'epoch': 74, 'time_epoch': 4.54229, 'loss': 0.10277015, 'lr': 0, 'params': 514193, 'time_iter': 0.03521, 'accuracy': 0.97812, 'precision': 0.42623, 'recall': 0.32099, 'f1': 0.3662, 'auc': 0.78094}
2025-08-16 04:39:35,893 - INFO - test: {'epoch': 74, 'time_epoch': 4.45151, 'loss': 0.17093252, 'lr': 0, 'params': 514193, 'time_iter': 0.03451, 'accuracy': 0.96329, 'precision': 0.37647, 'recall': 0.24615, 'f1': 0.29767, 'auc': 0.76565}
2025-08-16 04:39:35,896 - INFO - > Epoch 74: took 82.6s (avg 80.0s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:40:46,145 - INFO - train: {'epoch': 75, 'time_epoch': 70.17952, 'eta': 1703.09237, 'eta_hours': 0.47308, 'loss': 0.06754502, 'lr': 1.614e-05, 'params': 514193, 'time_iter': 0.0682, 'accuracy': 0.97888, 'precision': 0.83271, 'recall': 0.54545, 'f1': 0.65915, 'auc': 0.96655}
2025-08-16 04:40:50,650 - INFO - val: {'epoch': 75, 'time_epoch': 4.48178, 'loss': 0.10155502, 'lr': 0, 'params': 514193, 'time_iter': 0.03474, 'accuracy': 0.97617, 'precision': 0.36923, 'recall': 0.2963, 'f1': 0.32877, 'auc': 0.79816}
2025-08-16 04:40:55,111 - INFO - test: {'epoch': 75, 'time_epoch': 4.44258, 'loss': 0.17797495, 'lr': 0, 'params': 514193, 'time_iter': 0.03444, 'accuracy': 0.9628, 'precision': 0.35065, 'recall': 0.20769, 'f1': 0.26087, 'auc': 0.76702}
2025-08-16 04:40:55,114 - INFO - > Epoch 75: took 79.2s (avg 80.0s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:42:09,656 - INFO - train: {'epoch': 76, 'time_epoch': 74.46295, 'eta': 1633.17587, 'eta_hours': 0.45366, 'loss': 0.06676367, 'lr': 1.494e-05, 'params': 514193, 'time_iter': 0.07236, 'accuracy': 0.97824, 'precision': 0.81159, 'recall': 0.54545, 'f1': 0.65243, 'auc': 0.97021}
2025-08-16 04:42:14,548 - INFO - val: {'epoch': 76, 'time_epoch': 4.86593, 'loss': 0.10319786, 'lr': 0, 'params': 514193, 'time_iter': 0.03772, 'accuracy': 0.97617, 'precision': 0.38028, 'recall': 0.33333, 'f1': 0.35526, 'auc': 0.78674}
2025-08-16 04:42:19,105 - INFO - test: {'epoch': 76, 'time_epoch': 4.5371, 'loss': 0.17422626, 'lr': 0, 'params': 514193, 'time_iter': 0.03517, 'accuracy': 0.96134, 'precision': 0.33708, 'recall': 0.23077, 'f1': 0.27397, 'auc': 0.76376}
2025-08-16 04:42:19,108 - INFO - > Epoch 76: took 84.0s (avg 80.0s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:43:28,749 - INFO - train: {'epoch': 77, 'time_epoch': 69.57468, 'eta': 1561.76405, 'eta_hours': 0.43382, 'loss': 0.0669226, 'lr': 1.378e-05, 'params': 514193, 'time_iter': 0.06761, 'accuracy': 0.9779, 'precision': 0.81289, 'recall': 0.53247, 'f1': 0.64345, 'auc': 0.96844}
2025-08-16 04:43:33,184 - INFO - val: {'epoch': 77, 'time_epoch': 4.40926, 'loss': 0.10474606, 'lr': 0, 'params': 514193, 'time_iter': 0.03418, 'accuracy': 0.97788, 'precision': 0.42424, 'recall': 0.34568, 'f1': 0.38095, 'auc': 0.79186}
2025-08-16 04:43:37,510 - INFO - test: {'epoch': 77, 'time_epoch': 4.30796, 'loss': 0.1808542, 'lr': 0, 'params': 514193, 'time_iter': 0.0334, 'accuracy': 0.96329, 'precision': 0.37647, 'recall': 0.24615, 'f1': 0.29767, 'auc': 0.76779}
2025-08-16 04:43:37,512 - INFO - > Epoch 77: took 78.4s (avg 80.0s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:44:46,708 - INFO - train: {'epoch': 78, 'time_epoch': 69.12911, 'eta': 1490.2803, 'eta_hours': 0.41397, 'loss': 0.06407961, 'lr': 1.266e-05, 'params': 514193, 'time_iter': 0.06718, 'accuracy': 0.97964, 'precision': 0.84019, 'recall': 0.56331, 'f1': 0.67444, 'auc': 0.9707}
2025-08-16 04:44:51,024 - INFO - val: {'epoch': 78, 'time_epoch': 4.29422, 'loss': 0.10455214, 'lr': 0, 'params': 514193, 'time_iter': 0.03329, 'accuracy': 0.9769, 'precision': 0.3871, 'recall': 0.2963, 'f1': 0.33566, 'auc': 0.78665}
2025-08-16 04:44:55,260 - INFO - test: {'epoch': 78, 'time_epoch': 4.21945, 'loss': 0.18179691, 'lr': 0, 'params': 514193, 'time_iter': 0.03271, 'accuracy': 0.96329, 'precision': 0.36364, 'recall': 0.21538, 'f1': 0.27053, 'auc': 0.75548}
2025-08-16 04:44:55,262 - INFO - > Epoch 78: took 77.7s (avg 80.0s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:46:04,024 - INFO - train: {'epoch': 79, 'time_epoch': 68.69442, 'eta': 1418.74675, 'eta_hours': 0.3941, 'loss': 0.06591047, 'lr': 1.158e-05, 'params': 514193, 'time_iter': 0.06676, 'accuracy': 0.97806, 'precision': 0.81174, 'recall': 0.53896, 'f1': 0.6478, 'auc': 0.97042}
2025-08-16 04:46:08,366 - INFO - val: {'epoch': 79, 'time_epoch': 4.31987, 'loss': 0.10289053, 'lr': 0, 'params': 514193, 'time_iter': 0.03349, 'accuracy': 0.97666, 'precision': 0.38462, 'recall': 0.30864, 'f1': 0.34247, 'auc': 0.78871}
2025-08-16 04:46:12,674 - INFO - test: {'epoch': 79, 'time_epoch': 4.29018, 'loss': 0.18101578, 'lr': 0, 'params': 514193, 'time_iter': 0.03326, 'accuracy': 0.96304, 'precision': 0.37209, 'recall': 0.24615, 'f1': 0.2963, 'auc': 0.75509}
2025-08-16 04:46:12,677 - INFO - > Epoch 79: took 77.4s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:47:23,458 - INFO - train: {'epoch': 80, 'time_epoch': 70.70555, 'eta': 1347.75504, 'eta_hours': 0.37438, 'loss': 0.06467164, 'lr': 1.054e-05, 'params': 514193, 'time_iter': 0.06871, 'accuracy': 0.97933, 'precision': 0.83577, 'recall': 0.55763, 'f1': 0.66894, 'auc': 0.97135}
2025-08-16 04:47:28,124 - INFO - val: {'epoch': 80, 'time_epoch': 4.62467, 'loss': 0.11078039, 'lr': 0, 'params': 514193, 'time_iter': 0.03585, 'accuracy': 0.9752, 'precision': 0.37349, 'recall': 0.38272, 'f1': 0.37805, 'auc': 0.79179}
2025-08-16 04:47:32,758 - INFO - test: {'epoch': 80, 'time_epoch': 4.61002, 'loss': 0.18697969, 'lr': 0, 'params': 514193, 'time_iter': 0.03574, 'accuracy': 0.9611, 'precision': 0.34694, 'recall': 0.26154, 'f1': 0.29825, 'auc': 0.76453}
2025-08-16 04:47:32,761 - INFO - > Epoch 80: took 80.1s (avg 79.9s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:48:48,902 - INFO - train: {'epoch': 81, 'time_epoch': 76.06387, 'eta': 1277.94653, 'eta_hours': 0.35499, 'loss': 0.06463019, 'lr': 9.55e-06, 'params': 514193, 'time_iter': 0.07392, 'accuracy': 0.97875, 'precision': 0.8117, 'recall': 0.56331, 'f1': 0.66507, 'auc': 0.97262}
2025-08-16 04:48:53,538 - INFO - val: {'epoch': 81, 'time_epoch': 4.61177, 'loss': 0.10633833, 'lr': 0, 'params': 514193, 'time_iter': 0.03575, 'accuracy': 0.97812, 'precision': 0.42105, 'recall': 0.2963, 'f1': 0.34783, 'auc': 0.78457}
2025-08-16 04:48:58,347 - INFO - test: {'epoch': 81, 'time_epoch': 4.56797, 'loss': 0.18351933, 'lr': 0, 'params': 514193, 'time_iter': 0.03541, 'accuracy': 0.96475, 'precision': 0.4026, 'recall': 0.23846, 'f1': 0.29952, 'auc': 0.75817}
2025-08-16 04:48:58,350 - INFO - > Epoch 81: took 85.6s (avg 80.0s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:50:12,374 - INFO - train: {'epoch': 82, 'time_epoch': 73.95122, 'eta': 1207.55457, 'eta_hours': 0.33543, 'loss': 0.06375203, 'lr': 8.6e-06, 'params': 514193, 'time_iter': 0.07187, 'accuracy': 0.97948, 'precision': 0.83274, 'recall': 0.56575, 'f1': 0.67376, 'auc': 0.97189}
2025-08-16 04:50:16,987 - INFO - val: {'epoch': 82, 'time_epoch': 4.58307, 'loss': 0.10258158, 'lr': 0, 'params': 514193, 'time_iter': 0.03553, 'accuracy': 0.97836, 'precision': 0.43548, 'recall': 0.33333, 'f1': 0.37762, 'auc': 0.79863}
2025-08-16 04:50:21,471 - INFO - test: {'epoch': 82, 'time_epoch': 4.46312, 'loss': 0.18706691, 'lr': 0, 'params': 514193, 'time_iter': 0.0346, 'accuracy': 0.96353, 'precision': 0.36486, 'recall': 0.20769, 'f1': 0.26471, 'auc': 0.75138}
2025-08-16 04:50:21,474 - INFO - > Epoch 82: took 83.1s (avg 80.0s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:51:35,690 - INFO - train: {'epoch': 83, 'time_epoch': 74.14179, 'eta': 1137.11418, 'eta_hours': 0.31587, 'loss': 0.06498636, 'lr': 7.7e-06, 'params': 514193, 'time_iter': 0.07205, 'accuracy': 0.97927, 'precision': 0.83133, 'recall': 0.56006, 'f1': 0.66925, 'auc': 0.97098}
2025-08-16 04:51:40,303 - INFO - val: {'epoch': 83, 'time_epoch': 4.58932, 'loss': 0.10654671, 'lr': 0, 'params': 514193, 'time_iter': 0.03558, 'accuracy': 0.97471, 'precision': 0.35802, 'recall': 0.35802, 'f1': 0.35802, 'auc': 0.79548}
2025-08-16 04:51:44,822 - INFO - test: {'epoch': 83, 'time_epoch': 4.49999, 'loss': 0.18659877, 'lr': 0, 'params': 514193, 'time_iter': 0.03488, 'accuracy': 0.96037, 'precision': 0.3299, 'recall': 0.24615, 'f1': 0.28194, 'auc': 0.75486}
2025-08-16 04:51:44,825 - INFO - > Epoch 83: took 83.4s (avg 80.1s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:53:01,314 - INFO - train: {'epoch': 84, 'time_epoch': 76.40687, 'eta': 1066.9864, 'eta_hours': 0.29639, 'loss': 0.06463065, 'lr': 6.84e-06, 'params': 514193, 'time_iter': 0.07425, 'accuracy': 0.97906, 'precision': 0.82909, 'recall': 0.55519, 'f1': 0.66505, 'auc': 0.97253}
2025-08-16 04:53:05,890 - INFO - val: {'epoch': 84, 'time_epoch': 4.5493, 'loss': 0.10685381, 'lr': 0, 'params': 514193, 'time_iter': 0.03527, 'accuracy': 0.97739, 'precision': 0.40625, 'recall': 0.32099, 'f1': 0.35862, 'auc': 0.78481}
2025-08-16 04:53:10,429 - INFO - test: {'epoch': 84, 'time_epoch': 4.5042, 'loss': 0.18741329, 'lr': 0, 'params': 514193, 'time_iter': 0.03492, 'accuracy': 0.96377, 'precision': 0.38272, 'recall': 0.23846, 'f1': 0.29384, 'auc': 0.75489}
2025-08-16 04:53:10,433 - INFO - > Epoch 84: took 85.6s (avg 80.1s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:54:23,300 - INFO - train: {'epoch': 85, 'time_epoch': 72.79667, 'eta': 996.1249, 'eta_hours': 0.2767, 'loss': 0.06181084, 'lr': 6.03e-06, 'params': 514193, 'time_iter': 0.07075, 'accuracy': 0.97939, 'precision': 0.82976, 'recall': 0.56575, 'f1': 0.67278, 'auc': 0.97523}
2025-08-16 04:54:27,818 - INFO - val: {'epoch': 85, 'time_epoch': 4.49337, 'loss': 0.10317849, 'lr': 0, 'params': 514193, 'time_iter': 0.03483, 'accuracy': 0.97763, 'precision': 0.40678, 'recall': 0.2963, 'f1': 0.34286, 'auc': 0.793}
2025-08-16 04:54:32,271 - INFO - test: {'epoch': 85, 'time_epoch': 4.43436, 'loss': 0.18462928, 'lr': 0, 'params': 514193, 'time_iter': 0.03437, 'accuracy': 0.96353, 'precision': 0.38372, 'recall': 0.25385, 'f1': 0.30556, 'auc': 0.75252}
2025-08-16 04:54:32,275 - INFO - > Epoch 85: took 81.8s (avg 80.2s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:55:44,439 - INFO - train: {'epoch': 86, 'time_epoch': 72.09417, 'eta': 925.11394, 'eta_hours': 0.25698, 'loss': 0.06331469, 'lr': 5.26e-06, 'params': 514193, 'time_iter': 0.07006, 'accuracy': 0.97945, 'precision': 0.82861, 'recall': 0.56899, 'f1': 0.67469, 'auc': 0.97293}
2025-08-16 04:55:48,868 - INFO - val: {'epoch': 86, 'time_epoch': 4.40627, 'loss': 0.10296521, 'lr': 0, 'params': 514193, 'time_iter': 0.03416, 'accuracy': 0.97715, 'precision': 0.40299, 'recall': 0.33333, 'f1': 0.36486, 'auc': 0.79829}
2025-08-16 04:55:53,245 - INFO - test: {'epoch': 86, 'time_epoch': 4.3591, 'loss': 0.1856311, 'lr': 0, 'params': 514193, 'time_iter': 0.03379, 'accuracy': 0.96329, 'precision': 0.36364, 'recall': 0.21538, 'f1': 0.27053, 'auc': 0.75714}
2025-08-16 04:55:53,248 - INFO - > Epoch 86: took 81.0s (avg 80.2s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:57:02,802 - INFO - train: {'epoch': 87, 'time_epoch': 69.48732, 'eta': 853.72288, 'eta_hours': 0.23715, 'loss': 0.0626925, 'lr': 4.55e-06, 'params': 514193, 'time_iter': 0.06753, 'accuracy': 0.97878, 'precision': 0.82091, 'recall': 0.55438, 'f1': 0.66182, 'auc': 0.97394}
2025-08-16 04:57:07,220 - INFO - val: {'epoch': 87, 'time_epoch': 4.39414, 'loss': 0.10955233, 'lr': 0, 'params': 514193, 'time_iter': 0.03406, 'accuracy': 0.97544, 'precision': 0.37805, 'recall': 0.38272, 'f1': 0.38037, 'auc': 0.79304}
2025-08-16 04:57:11,547 - INFO - test: {'epoch': 87, 'time_epoch': 4.30843, 'loss': 0.1901365, 'lr': 0, 'params': 514193, 'time_iter': 0.0334, 'accuracy': 0.9611, 'precision': 0.34694, 'recall': 0.26154, 'f1': 0.29825, 'auc': 0.75765}
2025-08-16 04:57:11,550 - INFO - > Epoch 87: took 78.3s (avg 80.1s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:58:23,870 - INFO - train: {'epoch': 88, 'time_epoch': 72.24471, 'eta': 782.7154, 'eta_hours': 0.21742, 'loss': 0.06111795, 'lr': 3.89e-06, 'params': 514193, 'time_iter': 0.07021, 'accuracy': 0.98003, 'precision': 0.84024, 'recall': 0.5763, 'f1': 0.68368, 'auc': 0.97522}
2025-08-16 04:58:28,568 - INFO - val: {'epoch': 88, 'time_epoch': 4.67341, 'loss': 0.1103057, 'lr': 0, 'params': 514193, 'time_iter': 0.03623, 'accuracy': 0.97812, 'precision': 0.42857, 'recall': 0.33333, 'f1': 0.375, 'auc': 0.78792}
2025-08-16 04:58:33,179 - INFO - test: {'epoch': 88, 'time_epoch': 4.59081, 'loss': 0.18830337, 'lr': 0, 'params': 514193, 'time_iter': 0.03559, 'accuracy': 0.96256, 'precision': 0.35, 'recall': 0.21538, 'f1': 0.26667, 'auc': 0.75474}
2025-08-16 04:58:33,181 - INFO - > Epoch 88: took 81.6s (avg 80.2s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 04:59:46,405 - INFO - train: {'epoch': 89, 'time_epoch': 73.15284, 'eta': 711.78133, 'eta_hours': 0.19772, 'loss': 0.06117826, 'lr': 3.27e-06, 'params': 514193, 'time_iter': 0.07109, 'accuracy': 0.98021, 'precision': 0.84874, 'recall': 0.57386, 'f1': 0.68475, 'auc': 0.97628}
2025-08-16 04:59:50,978 - INFO - val: {'epoch': 89, 'time_epoch': 4.54855, 'loss': 0.10923827, 'lr': 0, 'params': 514193, 'time_iter': 0.03526, 'accuracy': 0.97788, 'precision': 0.42647, 'recall': 0.35802, 'f1': 0.38926, 'auc': 0.7962}
2025-08-16 04:59:55,446 - INFO - test: {'epoch': 89, 'time_epoch': 4.44869, 'loss': 0.19265311, 'lr': 0, 'params': 514193, 'time_iter': 0.03449, 'accuracy': 0.96231, 'precision': 0.35294, 'recall': 0.23077, 'f1': 0.27907, 'auc': 0.75629}
2025-08-16 04:59:55,449 - INFO - > Epoch 89: took 82.3s (avg 80.2s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 05:01:08,355 - INFO - train: {'epoch': 90, 'time_epoch': 72.83031, 'eta': 640.7666, 'eta_hours': 0.17799, 'loss': 0.06213403, 'lr': 2.71e-06, 'params': 514193, 'time_iter': 0.07078, 'accuracy': 0.97942, 'precision': 0.82996, 'recall': 0.56656, 'f1': 0.67342, 'auc': 0.97551}
2025-08-16 05:01:13,093 - INFO - val: {'epoch': 90, 'time_epoch': 4.71278, 'loss': 0.11538165, 'lr': 0, 'params': 514193, 'time_iter': 0.03653, 'accuracy': 0.9769, 'precision': 0.4, 'recall': 0.34568, 'f1': 0.37086, 'auc': 0.78958}
2025-08-16 05:01:17,731 - INFO - test: {'epoch': 90, 'time_epoch': 4.61938, 'loss': 0.19132091, 'lr': 0, 'params': 514193, 'time_iter': 0.03581, 'accuracy': 0.96207, 'precision': 0.3587, 'recall': 0.25385, 'f1': 0.2973, 'auc': 0.75711}
2025-08-16 05:01:17,734 - INFO - > Epoch 90: took 82.3s (avg 80.2s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 05:02:30,591 - INFO - train: {'epoch': 91, 'time_epoch': 72.78696, 'eta': 569.70863, 'eta_hours': 0.15825, 'loss': 0.06229102, 'lr': 2.2e-06, 'params': 514193, 'time_iter': 0.07074, 'accuracy': 0.97936, 'precision': 0.81672, 'recall': 0.57873, 'f1': 0.67743, 'auc': 0.97473}
2025-08-16 05:02:34,928 - INFO - val: {'epoch': 91, 'time_epoch': 4.3147, 'loss': 0.10417442, 'lr': 0, 'params': 514193, 'time_iter': 0.03345, 'accuracy': 0.97836, 'precision': 0.43333, 'recall': 0.32099, 'f1': 0.36879, 'auc': 0.79133}
2025-08-16 05:02:39,229 - INFO - test: {'epoch': 91, 'time_epoch': 4.28254, 'loss': 0.18641937, 'lr': 0, 'params': 514193, 'time_iter': 0.0332, 'accuracy': 0.96377, 'precision': 0.38824, 'recall': 0.25385, 'f1': 0.30698, 'auc': 0.75936}
2025-08-16 05:02:39,232 - INFO - > Epoch 91: took 81.5s (avg 80.2s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 05:03:49,593 - INFO - train: {'epoch': 92, 'time_epoch': 70.29236, 'eta': 498.42571, 'eta_hours': 0.13845, 'loss': 0.06314223, 'lr': 1.74e-06, 'params': 514193, 'time_iter': 0.06831, 'accuracy': 0.97948, 'precision': 0.82959, 'recall': 0.56899, 'f1': 0.67501, 'auc': 0.97404}
2025-08-16 05:03:54,019 - INFO - val: {'epoch': 92, 'time_epoch': 4.40321, 'loss': 0.10551588, 'lr': 0, 'params': 514193, 'time_iter': 0.03413, 'accuracy': 0.97715, 'precision': 0.40299, 'recall': 0.33333, 'f1': 0.36486, 'auc': 0.8029}
2025-08-16 05:03:58,348 - INFO - test: {'epoch': 92, 'time_epoch': 4.30954, 'loss': 0.18800354, 'lr': 0, 'params': 514193, 'time_iter': 0.03341, 'accuracy': 0.96329, 'precision': 0.37931, 'recall': 0.25385, 'f1': 0.30415, 'auc': 0.76463}
2025-08-16 05:03:58,351 - INFO - > Epoch 92: took 79.1s (avg 80.2s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 05:05:08,941 - INFO - train: {'epoch': 93, 'time_epoch': 70.5229, 'eta': 427.17859, 'eta_hours': 0.11866, 'loss': 0.05927531, 'lr': 1.33e-06, 'params': 514193, 'time_iter': 0.06854, 'accuracy': 0.9807, 'precision': 0.84429, 'recall': 0.59416, 'f1': 0.69747, 'auc': 0.9772}
2025-08-16 05:05:13,335 - INFO - val: {'epoch': 93, 'time_epoch': 4.3717, 'loss': 0.10718308, 'lr': 0, 'params': 514193, 'time_iter': 0.03389, 'accuracy': 0.97763, 'precision': 0.41791, 'recall': 0.34568, 'f1': 0.37838, 'auc': 0.79558}
2025-08-16 05:05:17,639 - INFO - test: {'epoch': 93, 'time_epoch': 4.28491, 'loss': 0.18978077, 'lr': 0, 'params': 514193, 'time_iter': 0.03322, 'accuracy': 0.96304, 'precision': 0.375, 'recall': 0.25385, 'f1': 0.30275, 'auc': 0.76262}
2025-08-16 05:05:17,642 - INFO - > Epoch 93: took 79.3s (avg 80.2s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 05:06:26,964 - INFO - train: {'epoch': 94, 'time_epoch': 69.25483, 'eta': 355.87997, 'eta_hours': 0.09886, 'loss': 0.06228204, 'lr': 9.8e-07, 'params': 514193, 'time_iter': 0.0673, 'accuracy': 0.97967, 'precision': 0.83079, 'recall': 0.57386, 'f1': 0.67883, 'auc': 0.97348}
2025-08-16 05:06:31,340 - INFO - val: {'epoch': 94, 'time_epoch': 4.35312, 'loss': 0.11264653, 'lr': 0, 'params': 514193, 'time_iter': 0.03375, 'accuracy': 0.97666, 'precision': 0.39726, 'recall': 0.35802, 'f1': 0.37662, 'auc': 0.79106}
2025-08-16 05:06:35,623 - INFO - test: {'epoch': 94, 'time_epoch': 4.26416, 'loss': 0.19331312, 'lr': 0, 'params': 514193, 'time_iter': 0.03306, 'accuracy': 0.96134, 'precision': 0.35052, 'recall': 0.26154, 'f1': 0.29956, 'auc': 0.75543}
2025-08-16 05:06:35,626 - INFO - > Epoch 94: took 78.0s (avg 80.2s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 05:07:46,014 - INFO - train: {'epoch': 95, 'time_epoch': 70.31542, 'eta': 284.66812, 'eta_hours': 0.07907, 'loss': 0.06321464, 'lr': 6.8e-07, 'params': 514193, 'time_iter': 0.06833, 'accuracy': 0.97954, 'precision': 0.82238, 'recall': 0.57873, 'f1': 0.67937, 'auc': 0.97042}
2025-08-16 05:07:50,580 - INFO - val: {'epoch': 95, 'time_epoch': 4.54194, 'loss': 0.10946954, 'lr': 0, 'params': 514193, 'time_iter': 0.03521, 'accuracy': 0.97763, 'precision': 0.41791, 'recall': 0.34568, 'f1': 0.37838, 'auc': 0.79671}
2025-08-16 05:07:55,069 - INFO - test: {'epoch': 95, 'time_epoch': 4.4676, 'loss': 0.19154062, 'lr': 0, 'params': 514193, 'time_iter': 0.03463, 'accuracy': 0.96231, 'precision': 0.35632, 'recall': 0.23846, 'f1': 0.28571, 'auc': 0.75494}
2025-08-16 05:07:55,071 - INFO - > Epoch 95: took 79.4s (avg 80.2s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 05:09:07,574 - INFO - train: {'epoch': 96, 'time_epoch': 72.4292, 'eta': 213.54012, 'eta_hours': 0.05932, 'loss': 0.06241862, 'lr': 4.4e-07, 'params': 514193, 'time_iter': 0.07039, 'accuracy': 0.97967, 'precision': 0.81952, 'recall': 0.58604, 'f1': 0.68339, 'auc': 0.97179}
2025-08-16 05:09:12,248 - INFO - val: {'epoch': 96, 'time_epoch': 4.64895, 'loss': 0.10809182, 'lr': 0, 'params': 514193, 'time_iter': 0.03604, 'accuracy': 0.97423, 'precision': 0.35294, 'recall': 0.37037, 'f1': 0.36145, 'auc': 0.79196}
2025-08-16 05:09:16,781 - INFO - test: {'epoch': 96, 'time_epoch': 4.51449, 'loss': 0.18405756, 'lr': 0, 'params': 514193, 'time_iter': 0.035, 'accuracy': 0.96134, 'precision': 0.35354, 'recall': 0.26923, 'f1': 0.30568, 'auc': 0.75721}
2025-08-16 05:09:16,784 - INFO - > Epoch 96: took 81.7s (avg 80.2s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 05:10:28,504 - INFO - train: {'epoch': 97, 'time_epoch': 71.64923, 'eta': 142.36966, 'eta_hours': 0.03955, 'loss': 0.06139576, 'lr': 2.5e-07, 'params': 514193, 'time_iter': 0.06963, 'accuracy': 0.98012, 'precision': 0.84242, 'recall': 0.57711, 'f1': 0.68497, 'auc': 0.97475}
2025-08-16 05:10:33,007 - INFO - val: {'epoch': 97, 'time_epoch': 4.47942, 'loss': 0.10791363, 'lr': 0, 'params': 514193, 'time_iter': 0.03472, 'accuracy': 0.97763, 'precision': 0.4127, 'recall': 0.32099, 'f1': 0.36111, 'auc': 0.79194}
2025-08-16 05:10:37,402 - INFO - test: {'epoch': 97, 'time_epoch': 4.3756, 'loss': 0.18509712, 'lr': 0, 'params': 514193, 'time_iter': 0.03392, 'accuracy': 0.96231, 'precision': 0.35632, 'recall': 0.23846, 'f1': 0.28571, 'auc': 0.75745}
2025-08-16 05:10:37,405 - INFO - > Epoch 97: took 80.6s (avg 80.2s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 05:11:49,072 - INFO - train: {'epoch': 98, 'time_epoch': 71.5955, 'eta': 71.18898, 'eta_hours': 0.01977, 'loss': 0.06219315, 'lr': 1.1e-07, 'params': 514193, 'time_iter': 0.06958, 'accuracy': 0.97936, 'precision': 0.81965, 'recall': 0.57549, 'f1': 0.6762, 'auc': 0.97448}
2025-08-16 05:11:53,514 - INFO - val: {'epoch': 98, 'time_epoch': 4.41969, 'loss': 0.10543668, 'lr': 0, 'params': 514193, 'time_iter': 0.03426, 'accuracy': 0.9769, 'precision': 0.39706, 'recall': 0.33333, 'f1': 0.36242, 'auc': 0.79703}
2025-08-16 05:11:57,913 - INFO - test: {'epoch': 98, 'time_epoch': 4.38131, 'loss': 0.184947, 'lr': 0, 'params': 514193, 'time_iter': 0.03396, 'accuracy': 0.96329, 'precision': 0.37647, 'recall': 0.24615, 'f1': 0.29767, 'auc': 0.75425}
2025-08-16 05:11:57,915 - INFO - > Epoch 98: took 80.5s (avg 80.2s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 05:13:10,147 - INFO - train: {'epoch': 99, 'time_epoch': 72.15295, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.06280686, 'lr': 3e-08, 'params': 514193, 'time_iter': 0.07012, 'accuracy': 0.97967, 'precision': 0.8188, 'recall': 0.58685, 'f1': 0.68369, 'auc': 0.97284}
2025-08-16 05:13:14,796 - INFO - val: {'epoch': 99, 'time_epoch': 4.6005, 'loss': 0.10824787, 'lr': 0, 'params': 514193, 'time_iter': 0.03566, 'accuracy': 0.97739, 'precision': 0.4, 'recall': 0.2963, 'f1': 0.34043, 'auc': 0.78853}
2025-08-16 05:13:19,242 - INFO - test: {'epoch': 99, 'time_epoch': 4.42803, 'loss': 0.18680906, 'lr': 0, 'params': 514193, 'time_iter': 0.03433, 'accuracy': 0.96256, 'precision': 0.36364, 'recall': 0.24615, 'f1': 0.29358, 'auc': 0.7627}
2025-08-16 05:13:19,483 - INFO - > Epoch 99: took 81.3s (avg 80.2s) | Best so far: epoch 51	train_loss: 0.0809 train_auc: 0.9421	val_loss: 0.0855 val_auc: 0.8198	test_loss: 0.1472 test_auc: 0.7749
2025-08-16 05:13:19,483 - INFO - Avg time per epoch: 80.21s
2025-08-16 05:13:19,483 - INFO - Total train loop time: 2.23h
2025-08-16 05:13:21,004 - INFO - ============================================================
2025-08-16 05:13:21,004 - INFO - Starting PK-Explainer Analysis (Enhanced Version)
2025-08-16 05:13:21,005 - INFO - ============================================================
2025-08-16 05:13:21,005 - INFO - Dataset: ogbg-molhiv
2025-08-16 05:13:21,005 - INFO - Model type: VanillaModel
2025-08-16 05:13:21,005 - INFO - GNN types available: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 05:13:21,049 - INFO - Saved model state to results/molhiv/molhiv-Vanilla-41/model_for_ablation.pt
2025-08-16 05:13:21,049 - INFO - 
Performing ablation study...
2025-08-16 05:13:21,355 - INFO - Getting baseline performance...
2025-08-16 05:13:21,390 - WARNING - Could not extract GNN mapping from optimal weights, attempting to infer from layers...
2025-08-16 05:13:21,390 - INFO - Final GNN mapping: {}
2025-08-16 05:13:25,945 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.53836, 'loss': 0.18680906, 'lr': 0, 'params': 514193, 'time_iter': 0.03518, 'accuracy': 0.96256, 'precision': 0.36364, 'recall': 0.24615, 'f1': 0.29358, 'auc': 0.7627}
2025-08-16 05:13:25,947 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:13:25,947 - INFO - Baseline auc: 0.7627
2025-08-16 05:13:30,457 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.45711, 'loss': 0.18403995, 'lr': 0, 'params': 514193, 'time_iter': 0.03455, 'accuracy': 0.96304, 'precision': 0.36585, 'recall': 0.23077, 'f1': 0.28302, 'auc': 0.76512}
2025-08-16 05:13:30,459 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:13:30,459 - INFO - Layer 0 (Layer_0), Head 0: drop=-0.0032
2025-08-16 05:13:34,879 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35184, 'loss': 0.18546247, 'lr': 0, 'params': 514193, 'time_iter': 0.03374, 'accuracy': 0.96207, 'precision': 0.36458, 'recall': 0.26923, 'f1': 0.30973, 'auc': 0.76469}
2025-08-16 05:13:34,881 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:13:34,881 - INFO - Layer 0 (Layer_0), Head 1: drop=-0.0026
2025-08-16 05:13:39,207 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27401, 'loss': 0.19101754, 'lr': 0, 'params': 514193, 'time_iter': 0.03313, 'accuracy': 0.96134, 'precision': 0.34737, 'recall': 0.25385, 'f1': 0.29333, 'auc': 0.7574}
2025-08-16 05:13:39,209 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:13:39,209 - INFO - Layer 0 (Layer_0), Head 2: drop=0.0069
2025-08-16 05:13:43,525 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26586, 'loss': 0.18779642, 'lr': 0, 'params': 514193, 'time_iter': 0.03307, 'accuracy': 0.96256, 'precision': 0.35714, 'recall': 0.23077, 'f1': 0.28037, 'auc': 0.75902}
2025-08-16 05:13:43,527 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:13:43,527 - INFO - Layer 0 (Layer_0), Head 3: drop=0.0048
2025-08-16 05:13:47,836 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25972, 'loss': 0.18417419, 'lr': 0, 'params': 514193, 'time_iter': 0.03302, 'accuracy': 0.96231, 'precision': 0.35632, 'recall': 0.23846, 'f1': 0.28571, 'auc': 0.74339}
2025-08-16 05:13:47,838 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:13:47,838 - INFO - Layer 1 (Layer_1), Head 0: drop=0.0253
2025-08-16 05:13:52,169 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2811, 'loss': 0.19083196, 'lr': 0, 'params': 514193, 'time_iter': 0.03319, 'accuracy': 0.96134, 'precision': 0.33708, 'recall': 0.23077, 'f1': 0.27397, 'auc': 0.74627}
2025-08-16 05:13:52,171 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:13:52,171 - INFO - Layer 1 (Layer_1), Head 1: drop=0.0215
2025-08-16 05:13:56,542 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32, 'loss': 0.18147297, 'lr': 0, 'params': 514193, 'time_iter': 0.03349, 'accuracy': 0.96134, 'precision': 0.34737, 'recall': 0.25385, 'f1': 0.29333, 'auc': 0.767}
2025-08-16 05:13:56,545 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:13:56,545 - INFO - Layer 1 (Layer_1), Head 2: drop=-0.0056
2025-08-16 05:14:00,929 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33226, 'loss': 0.18358336, 'lr': 0, 'params': 514193, 'time_iter': 0.03358, 'accuracy': 0.96231, 'precision': 0.35294, 'recall': 0.23077, 'f1': 0.27907, 'auc': 0.75519}
2025-08-16 05:14:00,931 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:00,931 - INFO - Layer 1 (Layer_1), Head 3: drop=0.0098
2025-08-16 05:14:05,279 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29745, 'loss': 0.18203256, 'lr': 0, 'params': 514193, 'time_iter': 0.03331, 'accuracy': 0.96353, 'precision': 0.37805, 'recall': 0.23846, 'f1': 0.29245, 'auc': 0.75715}
2025-08-16 05:14:05,281 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:05,281 - INFO - Layer 2 (Layer_2), Head 0: drop=0.0073
2025-08-16 05:14:09,640 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.30814, 'loss': 0.18944301, 'lr': 0, 'params': 514193, 'time_iter': 0.0334, 'accuracy': 0.95964, 'precision': 0.3125, 'recall': 0.23077, 'f1': 0.26549, 'auc': 0.76227}
2025-08-16 05:14:09,642 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:09,643 - INFO - Layer 2 (Layer_2), Head 1: drop=0.0006
2025-08-16 05:14:14,020 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32807, 'loss': 0.1785778, 'lr': 0, 'params': 514193, 'time_iter': 0.03355, 'accuracy': 0.96377, 'precision': 0.38554, 'recall': 0.24615, 'f1': 0.30047, 'auc': 0.75848}
2025-08-16 05:14:14,022 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:14,022 - INFO - Layer 2 (Layer_2), Head 2: drop=0.0055
2025-08-16 05:14:18,383 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.31081, 'loss': 0.18673171, 'lr': 0, 'params': 514193, 'time_iter': 0.03342, 'accuracy': 0.96231, 'precision': 0.36264, 'recall': 0.25385, 'f1': 0.29864, 'auc': 0.77316}
2025-08-16 05:14:18,385 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:18,385 - INFO - Layer 2 (Layer_2), Head 3: drop=-0.0137
2025-08-16 05:14:22,762 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32595, 'loss': 0.18328277, 'lr': 0, 'params': 514193, 'time_iter': 0.03353, 'accuracy': 0.96183, 'precision': 0.35165, 'recall': 0.24615, 'f1': 0.28959, 'auc': 0.77009}
2025-08-16 05:14:22,764 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:22,764 - INFO - Layer 3 (Layer_3), Head 0: drop=-0.0097
2025-08-16 05:14:27,154 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33809, 'loss': 0.18463719, 'lr': 0, 'params': 514193, 'time_iter': 0.03363, 'accuracy': 0.96061, 'precision': 0.33333, 'recall': 0.24615, 'f1': 0.28319, 'auc': 0.75955}
2025-08-16 05:14:27,156 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:27,156 - INFO - Layer 3 (Layer_3), Head 1: drop=0.0041
2025-08-16 05:14:31,554 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34446, 'loss': 0.18085782, 'lr': 0, 'params': 514193, 'time_iter': 0.03368, 'accuracy': 0.96037, 'precision': 0.32632, 'recall': 0.23846, 'f1': 0.27556, 'auc': 0.77071}
2025-08-16 05:14:31,556 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:14:31,556 - INFO - Layer 3 (Layer_3), Head 2: drop=-0.0105
2025-08-16 05:14:35,914 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.30699, 'loss': 0.17812487, 'lr': 0, 'params': 514193, 'time_iter': 0.03339, 'accuracy': 0.96231, 'precision': 0.36842, 'recall': 0.26923, 'f1': 0.31111, 'auc': 0.76812}
2025-08-16 05:14:35,916 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:35,916 - INFO - Layer 3 (Layer_3), Head 3: drop=-0.0071
2025-08-16 05:14:40,258 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29293, 'loss': 0.20411648, 'lr': 0, 'params': 514193, 'time_iter': 0.03328, 'accuracy': 0.94967, 'precision': 0.25786, 'recall': 0.31538, 'f1': 0.28374, 'auc': 0.73352}
2025-08-16 05:14:40,260 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:40,260 - INFO - Layer 4 (Layer_4), Head 0: drop=0.0383
2025-08-16 05:14:44,672 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36261, 'loss': 0.18475489, 'lr': 0, 'params': 514193, 'time_iter': 0.03382, 'accuracy': 0.96086, 'precision': 0.32967, 'recall': 0.23077, 'f1': 0.27149, 'auc': 0.75836}
2025-08-16 05:14:44,674 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:44,674 - INFO - Layer 4 (Layer_4), Head 1: drop=0.0057
2025-08-16 05:14:49,037 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.31158, 'loss': 0.18401863, 'lr': 0, 'params': 514193, 'time_iter': 0.03342, 'accuracy': 0.96231, 'precision': 0.36264, 'recall': 0.25385, 'f1': 0.29864, 'auc': 0.7574}
2025-08-16 05:14:49,039 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:49,039 - INFO - Layer 4 (Layer_4), Head 2: drop=0.0069
2025-08-16 05:14:53,458 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36726, 'loss': 0.18325568, 'lr': 0, 'params': 514193, 'time_iter': 0.03385, 'accuracy': 0.96353, 'precision': 0.38636, 'recall': 0.26154, 'f1': 0.31193, 'auc': 0.75925}
2025-08-16 05:14:53,460 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:14:53,460 - INFO - Layer 4 (Layer_4), Head 3: drop=0.0045
2025-08-16 05:14:57,910 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.39937, 'loss': 0.18355717, 'lr': 0, 'params': 514193, 'time_iter': 0.0341, 'accuracy': 0.96304, 'precision': 0.37209, 'recall': 0.24615, 'f1': 0.2963, 'auc': 0.75892}
2025-08-16 05:14:57,912 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:14:57,912 - INFO - Layer 5 (Layer_5), Head 0: drop=0.0050
2025-08-16 05:15:02,431 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.46955, 'loss': 0.17767688, 'lr': 0, 'params': 514193, 'time_iter': 0.03465, 'accuracy': 0.96256, 'precision': 0.36667, 'recall': 0.25385, 'f1': 0.3, 'auc': 0.76227}
2025-08-16 05:15:02,433 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:15:02,433 - INFO - Layer 5 (Layer_5), Head 1: drop=0.0006
2025-08-16 05:15:06,752 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26895, 'loss': 0.1871985, 'lr': 0, 'params': 514193, 'time_iter': 0.03309, 'accuracy': 0.96207, 'precision': 0.35227, 'recall': 0.23846, 'f1': 0.2844, 'auc': 0.75394}
2025-08-16 05:15:06,754 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:15:06,754 - INFO - Layer 5 (Layer_5), Head 2: drop=0.0115
2025-08-16 05:15:11,097 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29336, 'loss': 0.17309352, 'lr': 0, 'params': 514193, 'time_iter': 0.03328, 'accuracy': 0.96353, 'precision': 0.38636, 'recall': 0.26154, 'f1': 0.31193, 'auc': 0.77507}
2025-08-16 05:15:11,099 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:15:11,099 - INFO - Layer 5 (Layer_5), Head 3: drop=-0.0162
2025-08-16 05:15:15,415 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26535, 'loss': 0.18623874, 'lr': 0, 'params': 514193, 'time_iter': 0.03306, 'accuracy': 0.95964, 'precision': 0.32353, 'recall': 0.25385, 'f1': 0.28448, 'auc': 0.75337}
2025-08-16 05:15:15,418 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:15:15,418 - INFO - Layer 6 (Layer_6), Head 0: drop=0.0122
2025-08-16 05:15:19,850 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.38019, 'loss': 0.18590475, 'lr': 0, 'params': 514193, 'time_iter': 0.03395, 'accuracy': 0.96256, 'precision': 0.36957, 'recall': 0.26154, 'f1': 0.30631, 'auc': 0.76396}
2025-08-16 05:15:19,852 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:15:19,852 - INFO - Layer 6 (Layer_6), Head 1: drop=-0.0017
2025-08-16 05:15:24,283 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.37636, 'loss': 0.17643779, 'lr': 0, 'params': 514193, 'time_iter': 0.03393, 'accuracy': 0.96256, 'precision': 0.35714, 'recall': 0.23077, 'f1': 0.28037, 'auc': 0.76323}
2025-08-16 05:15:24,284 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:15:24,284 - INFO - Layer 6 (Layer_6), Head 2: drop=-0.0007
2025-08-16 05:15:28,786 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44911, 'loss': 0.18483999, 'lr': 0, 'params': 514193, 'time_iter': 0.03449, 'accuracy': 0.96304, 'precision': 0.37209, 'recall': 0.24615, 'f1': 0.2963, 'auc': 0.76155}
2025-08-16 05:15:28,788 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:15:28,788 - INFO - Layer 6 (Layer_6), Head 3: drop=0.0015
2025-08-16 05:15:33,261 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.41759, 'loss': 0.18898917, 'lr': 0, 'params': 514193, 'time_iter': 0.03424, 'accuracy': 0.96329, 'precision': 0.37647, 'recall': 0.24615, 'f1': 0.29767, 'auc': 0.7552}
2025-08-16 05:15:33,262 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:15:33,263 - INFO - Layer 7 (Layer_7), Head 0: drop=0.0098
2025-08-16 05:15:37,713 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40041, 'loss': 0.18085751, 'lr': 0, 'params': 514193, 'time_iter': 0.03411, 'accuracy': 0.96353, 'precision': 0.37179, 'recall': 0.22308, 'f1': 0.27885, 'auc': 0.76727}
2025-08-16 05:15:37,714 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:15:37,714 - INFO - Layer 7 (Layer_7), Head 1: drop=-0.0060
2025-08-16 05:15:42,161 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.39672, 'loss': 0.18494246, 'lr': 0, 'params': 514193, 'time_iter': 0.03408, 'accuracy': 0.96183, 'precision': 0.35789, 'recall': 0.26154, 'f1': 0.30222, 'auc': 0.76555}
2025-08-16 05:15:42,163 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:15:42,163 - INFO - Layer 7 (Layer_7), Head 2: drop=-0.0037
2025-08-16 05:15:46,595 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.37967, 'loss': 0.17915946, 'lr': 0, 'params': 514193, 'time_iter': 0.03395, 'accuracy': 0.96231, 'precision': 0.35632, 'recall': 0.23846, 'f1': 0.28571, 'auc': 0.76916}
2025-08-16 05:15:46,597 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:15:46,597 - INFO - Layer 7 (Layer_7), Head 3: drop=-0.0085
2025-08-16 05:15:51,082 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43117, 'loss': 0.18565623, 'lr': 0, 'params': 514193, 'time_iter': 0.03435, 'accuracy': 0.9628, 'precision': 0.36471, 'recall': 0.23846, 'f1': 0.28837, 'auc': 0.7604}
2025-08-16 05:15:51,084 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:15:51,084 - INFO - Layer 8 (Layer_8), Head 0: drop=0.0030
2025-08-16 05:15:55,552 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.41524, 'loss': 0.17785322, 'lr': 0, 'params': 514193, 'time_iter': 0.03423, 'accuracy': 0.96377, 'precision': 0.38272, 'recall': 0.23846, 'f1': 0.29384, 'auc': 0.75534}
2025-08-16 05:15:55,553 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:15:55,554 - INFO - Layer 8 (Layer_8), Head 1: drop=0.0096
2025-08-16 05:16:00,038 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43218, 'loss': 0.1769454, 'lr': 0, 'params': 514193, 'time_iter': 0.03436, 'accuracy': 0.96426, 'precision': 0.38961, 'recall': 0.23077, 'f1': 0.28986, 'auc': 0.76581}
2025-08-16 05:16:00,040 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:16:00,040 - INFO - Layer 8 (Layer_8), Head 2: drop=-0.0041
2025-08-16 05:16:04,497 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40244, 'loss': 0.18350789, 'lr': 0, 'params': 514193, 'time_iter': 0.03413, 'accuracy': 0.96304, 'precision': 0.37209, 'recall': 0.24615, 'f1': 0.2963, 'auc': 0.7631}
2025-08-16 05:16:04,499 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:04,499 - INFO - Layer 8 (Layer_8), Head 3: drop=-0.0005
2025-08-16 05:16:08,959 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40768, 'loss': 0.18264773, 'lr': 0, 'params': 514193, 'time_iter': 0.03417, 'accuracy': 0.96183, 'precision': 0.34483, 'recall': 0.23077, 'f1': 0.2765, 'auc': 0.76261}
2025-08-16 05:16:08,961 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:08,961 - INFO - Layer 9 (Layer_9), Head 0: drop=0.0001
2025-08-16 05:16:13,463 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44952, 'loss': 0.18078508, 'lr': 0, 'params': 514193, 'time_iter': 0.03449, 'accuracy': 0.96475, 'precision': 0.40741, 'recall': 0.25385, 'f1': 0.3128, 'auc': 0.7637}
2025-08-16 05:16:13,464 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:13,465 - INFO - Layer 9 (Layer_9), Head 1: drop=-0.0013
2025-08-16 05:16:18,069 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.55155, 'loss': 0.18415811, 'lr': 0, 'params': 514193, 'time_iter': 0.03528, 'accuracy': 0.96231, 'precision': 0.35294, 'recall': 0.23077, 'f1': 0.27907, 'auc': 0.76067}
2025-08-16 05:16:18,071 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:16:18,071 - INFO - Layer 9 (Layer_9), Head 2: drop=0.0027
2025-08-16 05:16:22,591 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.46213, 'loss': 0.1814063, 'lr': 0, 'params': 514193, 'time_iter': 0.03459, 'accuracy': 0.9628, 'precision': 0.36782, 'recall': 0.24615, 'f1': 0.29493, 'auc': 0.76527}
2025-08-16 05:16:22,593 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:16:22,594 - INFO - Layer 9 (Layer_9), Head 3: drop=-0.0034
2025-08-16 05:16:27,130 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.48533, 'loss': 0.1813757, 'lr': 0, 'params': 514193, 'time_iter': 0.03477, 'accuracy': 0.96256, 'precision': 0.35366, 'recall': 0.22308, 'f1': 0.27358, 'auc': 0.76326}
2025-08-16 05:16:27,133 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:16:27,133 - INFO - Layer 10 (Layer_10), Head 0: drop=-0.0007
2025-08-16 05:16:31,503 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3169, 'loss': 0.18343373, 'lr': 0, 'params': 514193, 'time_iter': 0.03346, 'accuracy': 0.96256, 'precision': 0.36364, 'recall': 0.24615, 'f1': 0.29358, 'auc': 0.76358}
2025-08-16 05:16:31,505 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:31,505 - INFO - Layer 10 (Layer_10), Head 1: drop=-0.0012
2025-08-16 05:16:35,829 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27419, 'loss': 0.18604919, 'lr': 0, 'params': 514193, 'time_iter': 0.03313, 'accuracy': 0.96231, 'precision': 0.35955, 'recall': 0.24615, 'f1': 0.29224, 'auc': 0.76422}
2025-08-16 05:16:35,830 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:35,831 - INFO - Layer 10 (Layer_10), Head 2: drop=-0.0020
2025-08-16 05:16:40,176 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29627, 'loss': 0.19122903, 'lr': 0, 'params': 514193, 'time_iter': 0.0333, 'accuracy': 0.96086, 'precision': 0.34343, 'recall': 0.26154, 'f1': 0.29694, 'auc': 0.76718}
2025-08-16 05:16:40,178 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:40,178 - INFO - Layer 10 (Layer_10), Head 3: drop=-0.0059
2025-08-16 05:16:44,499 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2693, 'loss': 0.17868402, 'lr': 0, 'params': 514193, 'time_iter': 0.0331, 'accuracy': 0.9628, 'precision': 0.36471, 'recall': 0.23846, 'f1': 0.28837, 'auc': 0.76478}
2025-08-16 05:16:44,501 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:44,501 - INFO - Layer 11 (Layer_11), Head 0: drop=-0.0027
2025-08-16 05:16:48,830 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27785, 'loss': 0.18113681, 'lr': 0, 'params': 514193, 'time_iter': 0.03316, 'accuracy': 0.9628, 'precision': 0.36471, 'recall': 0.23846, 'f1': 0.28837, 'auc': 0.76108}
2025-08-16 05:16:48,832 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:48,832 - INFO - Layer 11 (Layer_11), Head 1: drop=0.0021
2025-08-16 05:16:53,154 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2734, 'loss': 0.18429156, 'lr': 0, 'params': 514193, 'time_iter': 0.03313, 'accuracy': 0.96207, 'precision': 0.35556, 'recall': 0.24615, 'f1': 0.29091, 'auc': 0.76029}
2025-08-16 05:16:53,156 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:53,156 - INFO - Layer 11 (Layer_11), Head 2: drop=0.0032
2025-08-16 05:16:57,460 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25369, 'loss': 0.18151034, 'lr': 0, 'params': 514193, 'time_iter': 0.03297, 'accuracy': 0.96256, 'precision': 0.36364, 'recall': 0.24615, 'f1': 0.29358, 'auc': 0.7653}
2025-08-16 05:16:57,462 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:57,463 - INFO - Layer 11 (Layer_11), Head 3: drop=-0.0034
2025-08-16 05:17:01,776 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26272, 'loss': 0.1826939, 'lr': 0, 'params': 514193, 'time_iter': 0.03304, 'accuracy': 0.96231, 'precision': 0.35955, 'recall': 0.24615, 'f1': 0.29224, 'auc': 0.76621}
2025-08-16 05:17:01,778 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:01,778 - INFO - Layer 12 (Layer_12), Head 0: drop=-0.0046
2025-08-16 05:17:06,095 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2688, 'loss': 0.18255892, 'lr': 0, 'params': 514193, 'time_iter': 0.03309, 'accuracy': 0.96207, 'precision': 0.34884, 'recall': 0.23077, 'f1': 0.27778, 'auc': 0.76255}
2025-08-16 05:17:06,097 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:06,097 - INFO - Layer 12 (Layer_12), Head 1: drop=0.0002
2025-08-16 05:17:10,430 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.28313, 'loss': 0.18056357, 'lr': 0, 'params': 514193, 'time_iter': 0.0332, 'accuracy': 0.96256, 'precision': 0.36364, 'recall': 0.24615, 'f1': 0.29358, 'auc': 0.76338}
2025-08-16 05:17:10,432 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:17:10,432 - INFO - Layer 12 (Layer_12), Head 2: drop=-0.0009
2025-08-16 05:17:14,749 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26491, 'loss': 0.17987613, 'lr': 0, 'params': 514193, 'time_iter': 0.03306, 'accuracy': 0.96256, 'precision': 0.35366, 'recall': 0.22308, 'f1': 0.27358, 'auc': 0.76558}
2025-08-16 05:17:14,751 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:14,751 - INFO - Layer 12 (Layer_12), Head 3: drop=-0.0038
2025-08-16 05:17:19,076 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27361, 'loss': 0.1809288, 'lr': 0, 'params': 514193, 'time_iter': 0.03313, 'accuracy': 0.96256, 'precision': 0.36047, 'recall': 0.23846, 'f1': 0.28704, 'auc': 0.7646}
2025-08-16 05:17:19,078 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:19,078 - INFO - Layer 13 (Layer_13), Head 0: drop=-0.0025
2025-08-16 05:17:23,400 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27287, 'loss': 0.18042432, 'lr': 0, 'params': 514193, 'time_iter': 0.03312, 'accuracy': 0.9628, 'precision': 0.36471, 'recall': 0.23846, 'f1': 0.28837, 'auc': 0.76529}
2025-08-16 05:17:23,402 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:23,402 - INFO - Layer 13 (Layer_13), Head 1: drop=-0.0034
2025-08-16 05:17:27,705 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25338, 'loss': 0.18028328, 'lr': 0, 'params': 514193, 'time_iter': 0.03297, 'accuracy': 0.9628, 'precision': 0.36782, 'recall': 0.24615, 'f1': 0.29493, 'auc': 0.76383}
2025-08-16 05:17:27,707 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:17:27,708 - INFO - Layer 13 (Layer_13), Head 2: drop=-0.0015
2025-08-16 05:17:32,024 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26776, 'loss': 0.18105536, 'lr': 0, 'params': 514193, 'time_iter': 0.03308, 'accuracy': 0.96329, 'precision': 0.37037, 'recall': 0.23077, 'f1': 0.28436, 'auc': 0.76074}
2025-08-16 05:17:32,026 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:32,026 - INFO - Layer 13 (Layer_13), Head 3: drop=0.0026
2025-08-16 05:17:36,375 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29806, 'loss': 0.18263163, 'lr': 0, 'params': 514193, 'time_iter': 0.03332, 'accuracy': 0.96207, 'precision': 0.35227, 'recall': 0.23846, 'f1': 0.2844, 'auc': 0.76295}
2025-08-16 05:17:36,377 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:36,377 - INFO - Layer 14 (Layer_14), Head 0: drop=-0.0003
2025-08-16 05:17:40,785 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35578, 'loss': 0.17892387, 'lr': 0, 'params': 514193, 'time_iter': 0.03377, 'accuracy': 0.96329, 'precision': 0.36364, 'recall': 0.21538, 'f1': 0.27053, 'auc': 0.7604}
2025-08-16 05:17:40,787 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:40,787 - INFO - Layer 14 (Layer_14), Head 1: drop=0.0030
2025-08-16 05:17:45,170 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3324, 'loss': 0.18234224, 'lr': 0, 'params': 514193, 'time_iter': 0.03358, 'accuracy': 0.96207, 'precision': 0.34884, 'recall': 0.23077, 'f1': 0.27778, 'auc': 0.76467}
2025-08-16 05:17:45,172 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:45,172 - INFO - Layer 14 (Layer_14), Head 2: drop=-0.0026
2025-08-16 05:17:49,532 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.30843, 'loss': 0.17895953, 'lr': 0, 'params': 514193, 'time_iter': 0.0334, 'accuracy': 0.96329, 'precision': 0.37349, 'recall': 0.23846, 'f1': 0.29108, 'auc': 0.76374}
2025-08-16 05:17:49,534 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:49,534 - INFO - Layer 14 (Layer_14), Head 3: drop=-0.0014
2025-08-16 05:17:49,537 - INFO - 
FIDELITY METRICS:
2025-08-16 05:17:49,538 - INFO - Fidelity (top 30 heads): 0.0069
2025-08-16 05:17:49,538 - INFO - Fidelity- (bottom 30 heads): -0.0045
2025-08-16 05:17:49,538 - INFO - 
GNN distribution in important heads:
2025-08-16 05:17:49,538 - INFO -   Layer_4: 4 heads
2025-08-16 05:17:49,538 - INFO -   Layer_1: 3 heads
2025-08-16 05:17:49,538 - INFO -   Layer_5: 3 heads
2025-08-16 05:17:49,538 - INFO -   Layer_8: 3 heads
2025-08-16 05:17:49,538 - INFO -   Layer_2: 3 heads
2025-08-16 05:17:49,538 - INFO -   Layer_6: 2 heads
2025-08-16 05:17:49,538 - INFO -   Layer_0: 2 heads
2025-08-16 05:17:49,538 - INFO -   Layer_11: 2 heads
2025-08-16 05:17:49,538 - INFO -   Layer_14: 2 heads
2025-08-16 05:17:49,538 - INFO -   Layer_9: 2 heads
2025-08-16 05:17:49,538 - INFO -   Layer_7: 1 heads
2025-08-16 05:17:49,538 - INFO -   Layer_3: 1 heads
2025-08-16 05:17:49,538 - INFO -   Layer_13: 1 heads
2025-08-16 05:17:49,538 - INFO -   Layer_12: 1 heads
2025-08-16 05:17:49,539 - INFO - 
Interpretability Analysis:
2025-08-16 05:17:49,539 - INFO -   Fidelity: 0.0069
2025-08-16 05:17:49,539 - INFO -   Fidelity-: -0.0045
2025-08-16 05:17:49,539 - INFO -   Total heads tested: 60
2025-08-16 05:17:52,892 - INFO - Excel results saved to results/molhiv/molhiv-Vanilla-41/pk_explainer_results.xlsx
2025-08-16 05:17:54,910 - INFO - Saved visualizations to results/molhiv/molhiv-Vanilla-41/pk_explainer_results
2025-08-16 05:17:54,912 - INFO - 
PK-Explainer results saved to:
2025-08-16 05:17:54,912 - INFO -   - Excel: results/molhiv/molhiv-Vanilla-41/pk_explainer_results.xlsx
2025-08-16 05:17:54,912 - INFO -   - JSON: results/molhiv/molhiv-Vanilla-41/pk_explainer_results.json
2025-08-16 05:17:54,913 - INFO -   - Visualizations: results/molhiv/molhiv-Vanilla-41/pk_explainer_results
2025-08-16 05:17:54,983 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-41
2025-08-16 05:17:54,983 - INFO - Total time: 8358.92s (2.32h)
2025-08-16 05:17:55,008 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-41/agg
2025-08-16 05:17:55,008 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-16 05:17:55,008 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-41
2025-08-16 05:17:55,008 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-41/test_results/
Completed seed 41. Results saved in results/molhiv/molhiv-Vanilla-41
----------------------------------------
Running experiment with seed: 45
Starting training for seed 45...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/TRANS
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/TRANS/confignas.yaml
Using device: cuda
2025-08-16 05:18:07,112 - INFO - GPU Mem: 34.1GB
2025-08-16 05:18:07,113 - INFO - Run directory: results/molhiv/molhiv-Vanilla-45
2025-08-16 05:18:07,113 - INFO - Seed: 45
2025-08-16 05:18:07,113 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-16 05:18:07,113 - INFO - Routing mode: none
2025-08-16 05:18:07,113 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 05:18:07,113 - INFO - Number of layers: 15
2025-08-16 05:18:07,113 - INFO - Uncertainty enabled: False
2025-08-16 05:18:07,113 - INFO - Training mode: custom
2025-08-16 05:18:07,113 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-16 05:18:07,113 - INFO - Additional features: Router weights logging + JSON export
2025-08-16 05:18:13,933 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 05:18:13,935 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 05:18:13,936 - INFO -   undirected: True
2025-08-16 05:18:13,936 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 05:18:13,936 - INFO -   avg num_nodes/graph: 25
2025-08-16 05:18:13,937 - INFO -   num node features: 9
2025-08-16 05:18:13,937 - INFO -   num edge features: 3
2025-08-16 05:18:13,937 - INFO -   num tasks: 1
2025-08-16 05:18:13,937 - INFO -   num classes: 2
2025-08-16 05:18:13,937 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 05:18:13,937 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 05:18:13,940 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  6%|▌         | 2411/41127 [00:10<02:46, 231.90it/s] 11%|█▏        | 4704/41127 [00:20<02:39, 228.31it/s] 11%|█▏        | 4704/41127 [00:33<02:39, 228.31it/s] 14%|█▍        | 5957/41127 [00:33<03:37, 161.79it/s] 16%|█▌        | 6447/41127 [00:43<04:48, 120.18it/s] 17%|█▋        | 6922/41127 [00:53<06:02, 94.28it/s]  22%|██▏       | 8871/41127 [01:03<04:14, 126.98it/s] 26%|██▌       | 10631/41127 [01:14<03:35, 141.52it/s] 29%|██▉       | 11994/41127 [01:24<03:30, 138.62it/s] 34%|███▎      | 13835/41127 [01:34<03:00, 150.98it/s] 36%|███▌      | 14750/41127 [01:44<03:19, 132.45it/s] 38%|███▊      | 15508/41127 [01:55<03:44, 114.28it/s] 40%|███▉      | 16306/41127 [02:05<04:01, 102.99it/s] 40%|████      | 16479/41127 [02:15<05:17, 77.56it/s]  45%|████▍     | 18469/41127 [02:25<03:20, 113.16it/s] 48%|████▊     | 19702/41127 [02:35<03:05, 115.76it/s] 51%|█████▏    | 21129/41127 [02:45<02:42, 122.98it/s] 56%|█████▌    | 22920/41127 [02:56<02:11, 138.66it/s] 60%|█████▉    | 24481/41127 [03:06<01:56, 142.60it/s] 64%|██████▍   | 26389/41127 [03:16<01:35, 154.95it/s] 69%|██████▉   | 28441/41127 [03:27<01:15, 168.85it/s] 71%|███████▏  | 29330/41127 [03:37<01:22, 143.55it/s] 74%|███████▍  | 30351/41127 [03:47<01:22, 130.15it/s] 76%|███████▌  | 31127/41127 [03:58<01:28, 113.31it/s] 79%|███████▉  | 32535/41127 [04:08<01:11, 120.15it/s] 83%|████████▎ | 34181/41127 [04:18<00:52, 131.78it/s] 85%|████████▍ | 34759/41127 [04:29<00:58, 109.64it/s] 86%|████████▋ | 35474/41127 [04:39<00:57, 97.57it/s]  90%|████████▉ | 36969/41127 [04:49<00:36, 112.84it/s] 93%|█████████▎| 38405/41127 [04:59<00:22, 121.36it/s] 96%|█████████▌| 39405/41127 [05:09<00:15, 113.58it/s] 97%|█████████▋| 40068/41127 [05:20<00:10, 98.90it/s]  99%|█████████▉| 40712/41127 [05:30<00:04, 88.20it/s]100%|█████████▉| 41019/41127 [05:40<00:01, 70.90it/s]100%|██████████| 41127/41127 [05:44<00:00, 119.23it/s]
2025-08-16 05:24:00,072 - INFO - Done! Took 00:05:46.13
2025-08-16 05:24:00,216 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 05:24:00,354 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-16 05:24:00,354 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-08-16 05:24:00,355 - INFO - Inner model has get_darts_model: False
2025-08-16 05:24:00,357 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-08-16 05:24:00,359 - INFO - Number of parameters: 514,193
2025-08-16 05:24:00,359 - INFO - Starting optimized training: 2025-08-16 05:24:00.359862
2025-08-16 05:24:06,357 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 05:24:06,359 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 05:24:06,359 - INFO -   undirected: True
2025-08-16 05:24:06,360 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 05:24:06,360 - INFO -   avg num_nodes/graph: 25
2025-08-16 05:24:06,360 - INFO -   num node features: 9
2025-08-16 05:24:06,360 - INFO -   num edge features: 3
2025-08-16 05:24:06,360 - INFO -   num tasks: 1
2025-08-16 05:24:06,361 - INFO -   num classes: 2
2025-08-16 05:24:06,361 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 05:24:06,361 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 05:24:06,364 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  6%|▌         | 2411/41127 [00:10<02:42, 238.31it/s] 12%|█▏        | 5021/41127 [00:20<02:26, 246.09it/s] 12%|█▏        | 5021/41127 [00:30<02:26, 246.09it/s] 14%|█▍        | 5670/41127 [00:31<03:41, 160.22it/s] 16%|█▌        | 6446/41127 [00:41<04:33, 126.62it/s] 17%|█▋        | 6842/41127 [00:51<05:59, 95.32it/s]  22%|██▏       | 8879/41127 [01:02<04:08, 129.87it/s] 26%|██▌       | 10634/41127 [01:12<03:31, 144.38it/s] 30%|███       | 12453/41127 [01:22<03:04, 155.23it/s] 34%|███▍      | 13921/41127 [01:32<02:59, 151.24it/s] 36%|███▌      | 14753/41127 [01:42<03:22, 130.35it/s] 38%|███▊      | 15512/41127 [01:52<03:46, 113.20it/s] 40%|███▉      | 16308/41127 [02:02<04:00, 103.06it/s] 40%|████      | 16499/41127 [02:13<05:18, 77.33it/s]  45%|████▌     | 18576/41127 [02:23<03:16, 114.93it/s] 48%|████▊     | 19786/41127 [02:33<03:02, 116.73it/s] 51%|█████▏    | 21135/41127 [02:43<02:44, 121.19it/s] 56%|█████▌    | 23109/41127 [02:54<02:06, 142.30it/s] 60%|█████▉    | 24482/41127 [03:04<01:58, 140.54it/s] 64%|██████▍   | 26390/41127 [03:14<01:36, 153.51it/s] 70%|███████   | 28790/41127 [03:24<01:09, 177.16it/s] 71%|███████▏  | 29331/41127 [03:34<01:23, 140.64it/s] 74%|███████▍  | 30351/41127 [03:45<01:24, 128.06it/s] 76%|███████▌  | 31127/41127 [03:55<01:29, 111.98it/s] 79%|███████▉  | 32535/41127 [04:05<01:11, 120.18it/s] 83%|████████▎ | 34217/41127 [04:15<00:51, 133.52it/s] 85%|████████▍ | 34908/41127 [04:26<00:54, 113.29it/s] 86%|████████▋ | 35506/41127 [04:36<00:58, 96.40it/s]  90%|█████████ | 37187/41127 [04:46<00:33, 117.38it/s] 94%|█████████▍| 38726/41127 [04:56<00:18, 127.58it/s] 96%|█████████▌| 39550/41127 [05:07<00:13, 113.38it/s] 98%|█████████▊| 40156/41127 [05:17<00:09, 97.63it/s]  99%|█████████▉| 40747/41127 [05:27<00:04, 85.02it/s]100%|█████████▉| 41032/41127 [05:38<00:01, 67.49it/s]100%|██████████| 41127/41127 [05:39<00:00, 121.12it/s]
2025-08-16 05:29:47,118 - INFO - Done! Took 00:05:40.76
2025-08-16 05:29:47,257 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 05:29:47,388 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-16 05:29:47,388 - INFO - Start from epoch 0
2025-08-16 05:31:03,897 - INFO - train: {'epoch': 0, 'time_epoch': 76.3711, 'eta': 7560.73894, 'eta_hours': 2.10021, 'loss': 0.76728933, 'lr': 0.0, 'params': 514193, 'time_iter': 0.07422, 'accuracy': 0.05225, 'precision': 0.03775, 'recall': 0.99269, 'f1': 0.07274, 'auc': 0.48063}
2025-08-16 05:31:03,952 - INFO - ...computing epoch stats took: 0.17s
2025-08-16 05:31:09,749 - INFO - val: {'epoch': 0, 'time_epoch': 5.77938, 'loss': 0.75785626, 'lr': 0, 'params': 514193, 'time_iter': 0.0448, 'accuracy': 0.04303, 'precision': 0.02016, 'recall': 1.0, 'f1': 0.03953, 'auc': 0.53654}
2025-08-16 05:31:09,779 - INFO - ...computing epoch stats took: 0.04s
2025-08-16 05:31:15,026 - INFO - test: {'epoch': 0, 'time_epoch': 5.23165, 'loss': 0.75474552, 'lr': 0, 'params': 514193, 'time_iter': 0.04056, 'accuracy': 0.07464, 'precision': 0.03208, 'recall': 0.96923, 'f1': 0.0621, 'auc': 0.51916}
2025-08-16 05:31:15,070 - INFO - ...computing epoch stats took: 0.06s
2025-08-16 05:31:15,070 - INFO - > Epoch 0: took 87.7s (avg 87.7s) | Best so far: epoch 0	train_loss: 0.7673 train_auc: 0.4806	val_loss: 0.7579 val_auc: 0.5365	test_loss: 0.7547 test_auc: 0.5192
2025-08-16 05:32:28,514 - INFO - train: {'epoch': 1, 'time_epoch': 73.29805, 'eta': 7333.78841, 'eta_hours': 2.03716, 'loss': 0.48154534, 'lr': 2e-05, 'params': 514193, 'time_iter': 0.07123, 'accuracy': 0.80204, 'precision': 0.03439, 'recall': 0.15828, 'f1': 0.0565, 'auc': 0.50322}
2025-08-16 05:32:28,524 - INFO - ...computing epoch stats took: 0.13s
2025-08-16 05:32:34,197 - INFO - val: {'epoch': 1, 'time_epoch': 5.64558, 'loss': 0.24545878, 'lr': 0, 'params': 514193, 'time_iter': 0.04376, 'accuracy': 0.97933, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.59509}
2025-08-16 05:32:34,201 - INFO - ...computing epoch stats took: 0.03s
2025-08-16 05:32:39,716 - INFO - test: {'epoch': 1, 'time_epoch': 5.49226, 'loss': 0.25119249, 'lr': 0, 'params': 514193, 'time_iter': 0.04258, 'accuracy': 0.9662, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.58439}
2025-08-16 05:32:39,719 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:32:39,719 - INFO - > Epoch 1: took 84.6s (avg 86.2s) | Best so far: epoch 1	train_loss: 0.4815 train_auc: 0.5032	val_loss: 0.2455 val_auc: 0.5951	test_loss: 0.2512 test_auc: 0.5844
2025-08-16 05:34:02,859 - INFO - train: {'epoch': 2, 'time_epoch': 83.00737, 'eta': 7523.20754, 'eta_hours': 2.08978, 'loss': 0.18728865, 'lr': 4e-05, 'params': 514193, 'time_iter': 0.08067, 'accuracy': 0.96252, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.5938}
2025-08-16 05:34:02,868 - INFO - ...computing epoch stats took: 0.11s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:34:07,573 - INFO - val: {'epoch': 2, 'time_epoch': 4.68642, 'loss': 0.09954731, 'lr': 0, 'params': 514193, 'time_iter': 0.03633, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66881}
2025-08-16 05:34:07,575 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:34:12,182 - INFO - test: {'epoch': 2, 'time_epoch': 4.58711, 'loss': 0.13416758, 'lr': 0, 'params': 514193, 'time_iter': 0.03556, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67715}
2025-08-16 05:34:12,184 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:34:12,184 - INFO - > Epoch 2: took 92.5s (avg 88.3s) | Best so far: epoch 2	train_loss: 0.1873 train_auc: 0.5938	val_loss: 0.0995 val_auc: 0.6688	test_loss: 0.1342 test_auc: 0.6772
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:35:26,302 - INFO - train: {'epoch': 3, 'time_epoch': 73.99804, 'eta': 7360.18948, 'eta_hours': 2.0445, 'loss': 0.15355123, 'lr': 6e-05, 'params': 514193, 'time_iter': 0.07191, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66395}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:35:30,910 - INFO - val: {'epoch': 3, 'time_epoch': 4.58565, 'loss': 0.09476508, 'lr': 0, 'params': 514193, 'time_iter': 0.03555, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71173}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:35:35,324 - INFO - test: {'epoch': 3, 'time_epoch': 4.39694, 'loss': 0.12821744, 'lr': 0, 'params': 514193, 'time_iter': 0.03408, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72016}
2025-08-16 05:35:35,326 - INFO - > Epoch 3: took 83.1s (avg 87.0s) | Best so far: epoch 3	train_loss: 0.1536 train_auc: 0.6640	val_loss: 0.0948 val_auc: 0.7117	test_loss: 0.1282 test_auc: 0.7202
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:36:48,823 - INFO - train: {'epoch': 4, 'time_epoch': 73.39239, 'eta': 7221.27206, 'eta_hours': 2.00591, 'loss': 0.14645263, 'lr': 8e-05, 'params': 514193, 'time_iter': 0.07132, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71012}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:36:53,542 - INFO - val: {'epoch': 4, 'time_epoch': 4.69544, 'loss': 0.10081996, 'lr': 0, 'params': 514193, 'time_iter': 0.0364, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68222}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:36:58,133 - INFO - test: {'epoch': 4, 'time_epoch': 4.55906, 'loss': 0.12926004, 'lr': 0, 'params': 514193, 'time_iter': 0.03534, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73201}
2025-08-16 05:36:58,136 - INFO - > Epoch 4: took 82.8s (avg 86.1s) | Best so far: epoch 3	train_loss: 0.1536 train_auc: 0.6640	val_loss: 0.0948 val_auc: 0.7117	test_loss: 0.1282 test_auc: 0.7202
2025-08-16 05:38:12,654 - INFO - train: {'epoch': 5, 'time_epoch': 74.37858, 'eta': 7119.64667, 'eta_hours': 1.97768, 'loss': 0.14127709, 'lr': 0.0001, 'params': 514193, 'time_iter': 0.07228, 'accuracy': 0.9628, 'precision': 0.68182, 'recall': 0.01218, 'f1': 0.02392, 'auc': 0.7287}
2025-08-16 05:38:17,369 - INFO - val: {'epoch': 5, 'time_epoch': 4.68777, 'loss': 0.09260647, 'lr': 0, 'params': 514193, 'time_iter': 0.03634, 'accuracy': 0.98006, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67826}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:38:21,960 - INFO - test: {'epoch': 5, 'time_epoch': 4.57146, 'loss': 0.12367667, 'lr': 0, 'params': 514193, 'time_iter': 0.03544, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73649}
2025-08-16 05:38:21,963 - INFO - > Epoch 5: took 83.8s (avg 85.8s) | Best so far: epoch 3	train_loss: 0.1536 train_auc: 0.6640	val_loss: 0.0948 val_auc: 0.7117	test_loss: 0.1282 test_auc: 0.7202
2025-08-16 05:39:30,379 - INFO - train: {'epoch': 6, 'time_epoch': 68.30245, 'eta': 6945.08034, 'eta_hours': 1.92919, 'loss': 0.13822939, 'lr': 9.997e-05, 'params': 514193, 'time_iter': 0.06638, 'accuracy': 0.96298, 'precision': 0.56731, 'recall': 0.04789, 'f1': 0.08832, 'auc': 0.74451}
2025-08-16 05:39:34,815 - INFO - val: {'epoch': 6, 'time_epoch': 4.40942, 'loss': 0.11194213, 'lr': 0, 'params': 514193, 'time_iter': 0.03418, 'accuracy': 0.97788, 'precision': 0.22222, 'recall': 0.04938, 'f1': 0.08081, 'auc': 0.66804}
2025-08-16 05:39:38,990 - INFO - test: {'epoch': 6, 'time_epoch': 4.15577, 'loss': 0.13646531, 'lr': 0, 'params': 514193, 'time_iter': 0.03222, 'accuracy': 0.96548, 'precision': 0.2, 'recall': 0.03077, 'f1': 0.05333, 'auc': 0.72776}
2025-08-16 05:39:38,992 - INFO - > Epoch 6: took 77.0s (avg 84.5s) | Best so far: epoch 3	train_loss: 0.1536 train_auc: 0.6640	val_loss: 0.0948 val_auc: 0.7117	test_loss: 0.1282 test_auc: 0.7202
2025-08-16 05:40:44,597 - INFO - train: {'epoch': 7, 'time_epoch': 65.49972, 'eta': 6764.84856, 'eta_hours': 1.87912, 'loss': 0.13502983, 'lr': 9.989e-05, 'params': 514193, 'time_iter': 0.06365, 'accuracy': 0.96365, 'precision': 0.62676, 'recall': 0.07224, 'f1': 0.12955, 'auc': 0.76054}
2025-08-16 05:40:48,829 - INFO - val: {'epoch': 7, 'time_epoch': 4.2108, 'loss': 0.10204512, 'lr': 0, 'params': 514193, 'time_iter': 0.03264, 'accuracy': 0.98055, 'precision': 0.51852, 'recall': 0.17284, 'f1': 0.25926, 'auc': 0.73073}
2025-08-16 05:40:52,990 - INFO - test: {'epoch': 7, 'time_epoch': 4.14518, 'loss': 0.12759555, 'lr': 0, 'params': 514193, 'time_iter': 0.03213, 'accuracy': 0.97009, 'precision': 0.62963, 'recall': 0.13077, 'f1': 0.21656, 'auc': 0.75339}
2025-08-16 05:40:52,992 - INFO - > Epoch 7: took 74.0s (avg 83.2s) | Best so far: epoch 7	train_loss: 0.1350 train_auc: 0.7605	val_loss: 0.1020 val_auc: 0.7307	test_loss: 0.1276 test_auc: 0.7534
2025-08-16 05:41:58,226 - INFO - train: {'epoch': 8, 'time_epoch': 65.13001, 'eta': 6606.37463, 'eta_hours': 1.8351, 'loss': 0.13156463, 'lr': 9.975e-05, 'params': 514193, 'time_iter': 0.06329, 'accuracy': 0.96374, 'precision': 0.5933, 'recall': 0.10065, 'f1': 0.1721, 'auc': 0.78195}
2025-08-16 05:42:02,444 - INFO - val: {'epoch': 8, 'time_epoch': 4.19693, 'loss': 0.08932909, 'lr': 0, 'params': 514193, 'time_iter': 0.03253, 'accuracy': 0.98152, 'precision': 0.6087, 'recall': 0.17284, 'f1': 0.26923, 'auc': 0.7069}
2025-08-16 05:42:06,560 - INFO - test: {'epoch': 8, 'time_epoch': 4.09893, 'loss': 0.11986305, 'lr': 0, 'params': 514193, 'time_iter': 0.03177, 'accuracy': 0.97034, 'precision': 0.58696, 'recall': 0.20769, 'f1': 0.30682, 'auc': 0.75473}
2025-08-16 05:42:06,563 - INFO - > Epoch 8: took 73.6s (avg 82.1s) | Best so far: epoch 7	train_loss: 0.1350 train_auc: 0.7605	val_loss: 0.1020 val_auc: 0.7307	test_loss: 0.1276 test_auc: 0.7534
2025-08-16 05:43:11,694 - INFO - train: {'epoch': 9, 'time_epoch': 65.02537, 'eta': 6465.62774, 'eta_hours': 1.79601, 'loss': 0.12935633, 'lr': 9.956e-05, 'params': 514193, 'time_iter': 0.06319, 'accuracy': 0.96453, 'precision': 0.61168, 'recall': 0.14448, 'f1': 0.23375, 'auc': 0.78333}
2025-08-16 05:43:15,970 - INFO - val: {'epoch': 9, 'time_epoch': 4.2553, 'loss': 0.08552373, 'lr': 0, 'params': 514193, 'time_iter': 0.03299, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.01235, 'f1': 0.0241, 'auc': 0.71745}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:43:20,110 - INFO - test: {'epoch': 9, 'time_epoch': 4.1243, 'loss': 0.12642282, 'lr': 0, 'params': 514193, 'time_iter': 0.03197, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7638}
2025-08-16 05:43:20,112 - INFO - > Epoch 9: took 73.5s (avg 81.3s) | Best so far: epoch 7	train_loss: 0.1350 train_auc: 0.7605	val_loss: 0.1020 val_auc: 0.7307	test_loss: 0.1276 test_auc: 0.7534
2025-08-16 05:44:25,809 - INFO - train: {'epoch': 10, 'time_epoch': 65.59306, 'eta': 6343.2415, 'eta_hours': 1.76201, 'loss': 0.12723789, 'lr': 9.932e-05, 'params': 514193, 'time_iter': 0.06374, 'accuracy': 0.96544, 'precision': 0.64615, 'recall': 0.17045, 'f1': 0.26975, 'auc': 0.79551}
2025-08-16 05:44:30,025 - INFO - val: {'epoch': 10, 'time_epoch': 4.19501, 'loss': 0.09490785, 'lr': 0, 'params': 514193, 'time_iter': 0.03252, 'accuracy': 0.9786, 'precision': 0.41026, 'recall': 0.19753, 'f1': 0.26667, 'auc': 0.7098}
2025-08-16 05:44:34,143 - INFO - test: {'epoch': 10, 'time_epoch': 4.10141, 'loss': 0.12196736, 'lr': 0, 'params': 514193, 'time_iter': 0.03179, 'accuracy': 0.96693, 'precision': 0.45833, 'recall': 0.25385, 'f1': 0.32673, 'auc': 0.7513}
2025-08-16 05:44:34,145 - INFO - > Epoch 10: took 74.0s (avg 80.6s) | Best so far: epoch 7	train_loss: 0.1350 train_auc: 0.7605	val_loss: 0.1020 val_auc: 0.7307	test_loss: 0.1276 test_auc: 0.7534
2025-08-16 05:45:39,704 - INFO - train: {'epoch': 11, 'time_epoch': 65.45403, 'eta': 6229.30122, 'eta_hours': 1.73036, 'loss': 0.12582773, 'lr': 9.902e-05, 'params': 514193, 'time_iter': 0.06361, 'accuracy': 0.96596, 'precision': 0.66279, 'recall': 0.18506, 'f1': 0.28934, 'auc': 0.79896}
2025-08-16 05:45:43,951 - INFO - val: {'epoch': 11, 'time_epoch': 4.22629, 'loss': 0.08913527, 'lr': 0, 'params': 514193, 'time_iter': 0.03276, 'accuracy': 0.9786, 'precision': 0.41026, 'recall': 0.19753, 'f1': 0.26667, 'auc': 0.71481}
2025-08-16 05:45:48,086 - INFO - test: {'epoch': 11, 'time_epoch': 4.11738, 'loss': 0.12402329, 'lr': 0, 'params': 514193, 'time_iter': 0.03192, 'accuracy': 0.96791, 'precision': 0.47368, 'recall': 0.13846, 'f1': 0.21429, 'auc': 0.74815}
2025-08-16 05:45:48,088 - INFO - > Epoch 11: took 73.9s (avg 80.1s) | Best so far: epoch 7	train_loss: 0.1350 train_auc: 0.7605	val_loss: 0.1020 val_auc: 0.7307	test_loss: 0.1276 test_auc: 0.7534
2025-08-16 05:46:53,653 - INFO - train: {'epoch': 12, 'time_epoch': 65.45494, 'eta': 6122.82645, 'eta_hours': 1.70079, 'loss': 0.12351658, 'lr': 9.867e-05, 'params': 514193, 'time_iter': 0.06361, 'accuracy': 0.96581, 'precision': 0.62768, 'recall': 0.21347, 'f1': 0.31859, 'auc': 0.80148}
2025-08-16 05:46:58,101 - INFO - val: {'epoch': 12, 'time_epoch': 4.42637, 'loss': 0.08625779, 'lr': 0, 'params': 514193, 'time_iter': 0.03431, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.19753, 'f1': 0.28319, 'auc': 0.72819}
2025-08-16 05:47:02,415 - INFO - test: {'epoch': 12, 'time_epoch': 4.29812, 'loss': 0.11716297, 'lr': 0, 'params': 514193, 'time_iter': 0.03332, 'accuracy': 0.96961, 'precision': 0.55319, 'recall': 0.2, 'f1': 0.29379, 'auc': 0.76657}
2025-08-16 05:47:02,418 - INFO - > Epoch 12: took 74.3s (avg 79.6s) | Best so far: epoch 7	train_loss: 0.1350 train_auc: 0.7605	val_loss: 0.1020 val_auc: 0.7307	test_loss: 0.1276 test_auc: 0.7534
2025-08-16 05:48:08,602 - INFO - train: {'epoch': 13, 'time_epoch': 66.07831, 'eta': 6026.04093, 'eta_hours': 1.6739, 'loss': 0.1220876, 'lr': 9.826e-05, 'params': 514193, 'time_iter': 0.06422, 'accuracy': 0.96675, 'precision': 0.66587, 'recall': 0.22484, 'f1': 0.33617, 'auc': 0.80968}
2025-08-16 05:48:12,824 - INFO - val: {'epoch': 13, 'time_epoch': 4.20142, 'loss': 0.09032837, 'lr': 0, 'params': 514193, 'time_iter': 0.03257, 'accuracy': 0.9786, 'precision': 0.41463, 'recall': 0.20988, 'f1': 0.27869, 'auc': 0.72127}
2025-08-16 05:48:16,909 - INFO - test: {'epoch': 13, 'time_epoch': 4.06799, 'loss': 0.12390246, 'lr': 0, 'params': 514193, 'time_iter': 0.03153, 'accuracy': 0.9645, 'precision': 0.38571, 'recall': 0.20769, 'f1': 0.27, 'auc': 0.76579}
2025-08-16 05:48:16,912 - INFO - > Epoch 13: took 74.5s (avg 79.3s) | Best so far: epoch 7	train_loss: 0.1350 train_auc: 0.7605	val_loss: 0.1020 val_auc: 0.7307	test_loss: 0.1276 test_auc: 0.7534
2025-08-16 05:49:21,521 - INFO - train: {'epoch': 14, 'time_epoch': 64.50457, 'eta': 5924.43189, 'eta_hours': 1.64568, 'loss': 0.1201327, 'lr': 9.78e-05, 'params': 514193, 'time_iter': 0.06269, 'accuracy': 0.96654, 'precision': 0.64523, 'recall': 0.2362, 'f1': 0.34581, 'auc': 0.82051}
2025-08-16 05:49:25,683 - INFO - val: {'epoch': 14, 'time_epoch': 4.13932, 'loss': 0.08821376, 'lr': 0, 'params': 514193, 'time_iter': 0.03209, 'accuracy': 0.98055, 'precision': 0.51724, 'recall': 0.18519, 'f1': 0.27273, 'auc': 0.69922}
2025-08-16 05:49:29,819 - INFO - test: {'epoch': 14, 'time_epoch': 4.11943, 'loss': 0.1204668, 'lr': 0, 'params': 514193, 'time_iter': 0.03193, 'accuracy': 0.96791, 'precision': 0.48, 'recall': 0.18462, 'f1': 0.26667, 'auc': 0.76781}
2025-08-16 05:49:29,821 - INFO - > Epoch 14: took 72.9s (avg 78.8s) | Best so far: epoch 7	train_loss: 0.1350 train_auc: 0.7605	val_loss: 0.1020 val_auc: 0.7307	test_loss: 0.1276 test_auc: 0.7534
2025-08-16 05:50:35,599 - INFO - train: {'epoch': 15, 'time_epoch': 65.67061, 'eta': 5833.58262, 'eta_hours': 1.62044, 'loss': 0.11960001, 'lr': 9.729e-05, 'params': 514193, 'time_iter': 0.06382, 'accuracy': 0.96669, 'precision': 0.65385, 'recall': 0.23458, 'f1': 0.34528, 'auc': 0.81512}
2025-08-16 05:50:39,839 - INFO - val: {'epoch': 15, 'time_epoch': 4.21595, 'loss': 0.08645916, 'lr': 0, 'params': 514193, 'time_iter': 0.03268, 'accuracy': 0.9786, 'precision': 0.4186, 'recall': 0.22222, 'f1': 0.29032, 'auc': 0.77776}
2025-08-16 05:50:44,012 - INFO - test: {'epoch': 15, 'time_epoch': 4.15607, 'loss': 0.12259935, 'lr': 0, 'params': 514193, 'time_iter': 0.03222, 'accuracy': 0.96596, 'precision': 0.43902, 'recall': 0.27692, 'f1': 0.33962, 'auc': 0.76635}
2025-08-16 05:50:44,015 - INFO - > Epoch 15: took 74.2s (avg 78.5s) | Best so far: epoch 15	train_loss: 0.1196 train_auc: 0.8151	val_loss: 0.0865 val_auc: 0.7778	test_loss: 0.1226 test_auc: 0.7663
2025-08-16 05:51:49,372 - INFO - train: {'epoch': 16, 'time_epoch': 65.25191, 'eta': 5743.65127, 'eta_hours': 1.59546, 'loss': 0.11744896, 'lr': 9.673e-05, 'params': 514193, 'time_iter': 0.06341, 'accuracy': 0.96754, 'precision': 0.67904, 'recall': 0.25244, 'f1': 0.36805, 'auc': 0.82659}
2025-08-16 05:51:53,711 - INFO - val: {'epoch': 16, 'time_epoch': 4.2444, 'loss': 0.08867794, 'lr': 0, 'params': 514193, 'time_iter': 0.0329, 'accuracy': 0.97788, 'precision': 0.41379, 'recall': 0.2963, 'f1': 0.34532, 'auc': 0.74742}
2025-08-16 05:51:57,849 - INFO - test: {'epoch': 16, 'time_epoch': 4.12061, 'loss': 0.12374996, 'lr': 0, 'params': 514193, 'time_iter': 0.03194, 'accuracy': 0.9628, 'precision': 0.4065, 'recall': 0.38462, 'f1': 0.39526, 'auc': 0.7707}
2025-08-16 05:51:57,851 - INFO - > Epoch 16: took 73.8s (avg 78.3s) | Best so far: epoch 15	train_loss: 0.1196 train_auc: 0.8151	val_loss: 0.0865 val_auc: 0.7778	test_loss: 0.1226 test_auc: 0.7663
2025-08-16 05:53:04,822 - INFO - train: {'epoch': 17, 'time_epoch': 66.86589, 'eta': 5663.81469, 'eta_hours': 1.57328, 'loss': 0.11603354, 'lr': 9.611e-05, 'params': 514193, 'time_iter': 0.06498, 'accuracy': 0.96754, 'precision': 0.67083, 'recall': 0.26136, 'f1': 0.37617, 'auc': 0.83484}
2025-08-16 05:53:09,023 - INFO - val: {'epoch': 17, 'time_epoch': 4.17949, 'loss': 0.08649373, 'lr': 0, 'params': 514193, 'time_iter': 0.0324, 'accuracy': 0.97982, 'precision': 0.47222, 'recall': 0.20988, 'f1': 0.2906, 'auc': 0.75606}
2025-08-16 05:53:13,153 - INFO - test: {'epoch': 17, 'time_epoch': 4.11391, 'loss': 0.12337684, 'lr': 0, 'params': 514193, 'time_iter': 0.03189, 'accuracy': 0.96742, 'precision': 0.46429, 'recall': 0.2, 'f1': 0.27957, 'auc': 0.77636}
2025-08-16 05:53:13,155 - INFO - > Epoch 17: took 75.3s (avg 78.1s) | Best so far: epoch 15	train_loss: 0.1196 train_auc: 0.8151	val_loss: 0.0865 val_auc: 0.7778	test_loss: 0.1226 test_auc: 0.7663
2025-08-16 05:54:18,288 - INFO - train: {'epoch': 18, 'time_epoch': 65.02713, 'eta': 5577.50452, 'eta_hours': 1.54931, 'loss': 0.11424607, 'lr': 9.545e-05, 'params': 514193, 'time_iter': 0.06319, 'accuracy': 0.96751, 'precision': 0.66139, 'recall': 0.2711, 'f1': 0.38457, 'auc': 0.84345}
2025-08-16 05:54:22,422 - INFO - val: {'epoch': 18, 'time_epoch': 4.11255, 'loss': 0.08410724, 'lr': 0, 'params': 514193, 'time_iter': 0.03188, 'accuracy': 0.98152, 'precision': 0.57576, 'recall': 0.23457, 'f1': 0.33333, 'auc': 0.75361}
2025-08-16 05:54:26,538 - INFO - test: {'epoch': 18, 'time_epoch': 4.09954, 'loss': 0.1180656, 'lr': 0, 'params': 514193, 'time_iter': 0.03178, 'accuracy': 0.96961, 'precision': 0.55814, 'recall': 0.18462, 'f1': 0.27746, 'auc': 0.77377}
2025-08-16 05:54:26,540 - INFO - > Epoch 18: took 73.4s (avg 77.8s) | Best so far: epoch 15	train_loss: 0.1196 train_auc: 0.8151	val_loss: 0.0865 val_auc: 0.7778	test_loss: 0.1226 test_auc: 0.7663
2025-08-16 05:55:31,817 - INFO - train: {'epoch': 19, 'time_epoch': 65.17157, 'eta': 5493.9004, 'eta_hours': 1.52608, 'loss': 0.11352273, 'lr': 9.474e-05, 'params': 514193, 'time_iter': 0.06333, 'accuracy': 0.96745, 'precision': 0.66068, 'recall': 0.26867, 'f1': 0.382, 'auc': 0.84613}
2025-08-16 05:55:36,096 - INFO - val: {'epoch': 19, 'time_epoch': 4.25552, 'loss': 0.09030294, 'lr': 0, 'params': 514193, 'time_iter': 0.03299, 'accuracy': 0.97788, 'precision': 0.42188, 'recall': 0.33333, 'f1': 0.37241, 'auc': 0.77436}
2025-08-16 05:55:40,198 - INFO - test: {'epoch': 19, 'time_epoch': 4.08263, 'loss': 0.13229669, 'lr': 0, 'params': 514193, 'time_iter': 0.03165, 'accuracy': 0.9611, 'precision': 0.33333, 'recall': 0.23077, 'f1': 0.27273, 'auc': 0.75959}
2025-08-16 05:55:40,201 - INFO - > Epoch 19: took 73.7s (avg 77.6s) | Best so far: epoch 15	train_loss: 0.1196 train_auc: 0.8151	val_loss: 0.0865 val_auc: 0.7778	test_loss: 0.1226 test_auc: 0.7663
2025-08-16 05:56:45,751 - INFO - train: {'epoch': 20, 'time_epoch': 65.44416, 'eta': 5413.07721, 'eta_hours': 1.50363, 'loss': 0.11085158, 'lr': 9.397e-05, 'params': 514193, 'time_iter': 0.0636, 'accuracy': 0.9693, 'precision': 0.71183, 'recall': 0.30276, 'f1': 0.42483, 'auc': 0.85122}
2025-08-16 05:56:49,969 - INFO - val: {'epoch': 20, 'time_epoch': 4.1971, 'loss': 0.09154929, 'lr': 0, 'params': 514193, 'time_iter': 0.03254, 'accuracy': 0.97326, 'precision': 0.31169, 'recall': 0.2963, 'f1': 0.3038, 'auc': 0.77828}
2025-08-16 05:56:54,085 - INFO - test: {'epoch': 20, 'time_epoch': 4.09943, 'loss': 0.12884471, 'lr': 0, 'params': 514193, 'time_iter': 0.03178, 'accuracy': 0.96061, 'precision': 0.35455, 'recall': 0.3, 'f1': 0.325, 'auc': 0.77024}
2025-08-16 05:56:54,088 - INFO - > Epoch 20: took 73.9s (avg 77.5s) | Best so far: epoch 20	train_loss: 0.1109 train_auc: 0.8512	val_loss: 0.0915 val_auc: 0.7783	test_loss: 0.1288 test_auc: 0.7702
2025-08-16 05:57:59,184 - INFO - train: {'epoch': 21, 'time_epoch': 64.98943, 'eta': 5332.0399, 'eta_hours': 1.48112, 'loss': 0.11060667, 'lr': 9.316e-05, 'params': 514193, 'time_iter': 0.06316, 'accuracy': 0.96903, 'precision': 0.69981, 'recall': 0.30276, 'f1': 0.42266, 'auc': 0.85237}
2025-08-16 05:58:03,425 - INFO - val: {'epoch': 21, 'time_epoch': 4.21971, 'loss': 0.07965006, 'lr': 0, 'params': 514193, 'time_iter': 0.03271, 'accuracy': 0.98249, 'precision': 0.66667, 'recall': 0.22222, 'f1': 0.33333, 'auc': 0.77031}
2025-08-16 05:58:07,551 - INFO - test: {'epoch': 21, 'time_epoch': 4.109, 'loss': 0.11727523, 'lr': 0, 'params': 514193, 'time_iter': 0.03185, 'accuracy': 0.97009, 'precision': 0.68421, 'recall': 0.1, 'f1': 0.1745, 'auc': 0.76739}
2025-08-16 05:58:07,553 - INFO - > Epoch 21: took 73.5s (avg 77.3s) | Best so far: epoch 20	train_loss: 0.1109 train_auc: 0.8512	val_loss: 0.0915 val_auc: 0.7783	test_loss: 0.1288 test_auc: 0.7702
2025-08-16 05:59:13,006 - INFO - train: {'epoch': 22, 'time_epoch': 65.34783, 'eta': 5253.59792, 'eta_hours': 1.45933, 'loss': 0.10997387, 'lr': 9.23e-05, 'params': 514193, 'time_iter': 0.06351, 'accuracy': 0.96891, 'precision': 0.70775, 'recall': 0.28896, 'f1': 0.41037, 'auc': 0.85904}
2025-08-16 05:59:17,192 - INFO - val: {'epoch': 22, 'time_epoch': 4.16511, 'loss': 0.08473206, 'lr': 0, 'params': 514193, 'time_iter': 0.03229, 'accuracy': 0.97885, 'precision': 0.44, 'recall': 0.2716, 'f1': 0.33588, 'auc': 0.75701}
2025-08-16 05:59:21,322 - INFO - test: {'epoch': 22, 'time_epoch': 4.11329, 'loss': 0.12543844, 'lr': 0, 'params': 514193, 'time_iter': 0.03189, 'accuracy': 0.96693, 'precision': 0.4625, 'recall': 0.28462, 'f1': 0.35238, 'auc': 0.75298}
2025-08-16 05:59:21,325 - INFO - > Epoch 22: took 73.8s (avg 77.1s) | Best so far: epoch 20	train_loss: 0.1109 train_auc: 0.8512	val_loss: 0.0915 val_auc: 0.7783	test_loss: 0.1288 test_auc: 0.7702
2025-08-16 06:00:26,632 - INFO - train: {'epoch': 23, 'time_epoch': 65.19915, 'eta': 5175.7763, 'eta_hours': 1.43772, 'loss': 0.10777045, 'lr': 9.14e-05, 'params': 514193, 'time_iter': 0.06336, 'accuracy': 0.9697, 'precision': 0.7102, 'recall': 0.32224, 'f1': 0.44333, 'auc': 0.86152}
2025-08-16 06:00:30,990 - INFO - val: {'epoch': 23, 'time_epoch': 4.33381, 'loss': 0.1034338, 'lr': 0, 'params': 514193, 'time_iter': 0.0336, 'accuracy': 0.9718, 'precision': 0.30769, 'recall': 0.34568, 'f1': 0.32558, 'auc': 0.7513}
2025-08-16 06:00:35,126 - INFO - test: {'epoch': 23, 'time_epoch': 4.11811, 'loss': 0.1469971, 'lr': 0, 'params': 514193, 'time_iter': 0.03192, 'accuracy': 0.95551, 'precision': 0.30075, 'recall': 0.30769, 'f1': 0.30418, 'auc': 0.73718}
2025-08-16 06:00:35,129 - INFO - > Epoch 23: took 73.8s (avg 77.0s) | Best so far: epoch 20	train_loss: 0.1109 train_auc: 0.8512	val_loss: 0.0915 val_auc: 0.7783	test_loss: 0.1288 test_auc: 0.7702
2025-08-16 06:01:40,640 - INFO - train: {'epoch': 24, 'time_epoch': 65.40625, 'eta': 5099.58576, 'eta_hours': 1.41655, 'loss': 0.10831646, 'lr': 9.045e-05, 'params': 514193, 'time_iter': 0.06356, 'accuracy': 0.96948, 'precision': 0.70956, 'recall': 0.31331, 'f1': 0.43468, 'auc': 0.86342}
2025-08-16 06:01:44,838 - INFO - val: {'epoch': 24, 'time_epoch': 4.17595, 'loss': 0.08322489, 'lr': 0, 'params': 514193, 'time_iter': 0.03237, 'accuracy': 0.98225, 'precision': 0.61111, 'recall': 0.2716, 'f1': 0.37607, 'auc': 0.76032}
2025-08-16 06:01:48,979 - INFO - test: {'epoch': 24, 'time_epoch': 4.12435, 'loss': 0.12243791, 'lr': 0, 'params': 514193, 'time_iter': 0.03197, 'accuracy': 0.97058, 'precision': 0.60976, 'recall': 0.19231, 'f1': 0.2924, 'auc': 0.76014}
2025-08-16 06:01:48,981 - INFO - > Epoch 24: took 73.9s (avg 76.9s) | Best so far: epoch 20	train_loss: 0.1109 train_auc: 0.8512	val_loss: 0.0915 val_auc: 0.7783	test_loss: 0.1288 test_auc: 0.7702
2025-08-16 06:02:53,895 - INFO - train: {'epoch': 25, 'time_epoch': 64.80002, 'eta': 5022.49938, 'eta_hours': 1.39514, 'loss': 0.1067244, 'lr': 8.946e-05, 'params': 514193, 'time_iter': 0.06297, 'accuracy': 0.97, 'precision': 0.72727, 'recall': 0.31818, 'f1': 0.44269, 'auc': 0.8637}
2025-08-16 06:02:58,049 - INFO - val: {'epoch': 25, 'time_epoch': 4.13185, 'loss': 0.09171033, 'lr': 0, 'params': 514193, 'time_iter': 0.03203, 'accuracy': 0.9752, 'precision': 0.35616, 'recall': 0.32099, 'f1': 0.33766, 'auc': 0.77123}
2025-08-16 06:03:02,173 - INFO - test: {'epoch': 25, 'time_epoch': 4.10801, 'loss': 0.13225464, 'lr': 0, 'params': 514193, 'time_iter': 0.03185, 'accuracy': 0.96231, 'precision': 0.37113, 'recall': 0.27692, 'f1': 0.31718, 'auc': 0.76494}
2025-08-16 06:03:02,176 - INFO - > Epoch 25: took 73.2s (avg 76.7s) | Best so far: epoch 20	train_loss: 0.1109 train_auc: 0.8512	val_loss: 0.0915 val_auc: 0.7783	test_loss: 0.1288 test_auc: 0.7702
2025-08-16 06:04:07,407 - INFO - train: {'epoch': 26, 'time_epoch': 65.12663, 'eta': 4947.20615, 'eta_hours': 1.37422, 'loss': 0.10484775, 'lr': 8.842e-05, 'params': 514193, 'time_iter': 0.06329, 'accuracy': 0.97015, 'precision': 0.71186, 'recall': 0.34091, 'f1': 0.46103, 'auc': 0.8716}
2025-08-16 06:04:11,457 - INFO - val: {'epoch': 26, 'time_epoch': 4.02846, 'loss': 0.07928983, 'lr': 0, 'params': 514193, 'time_iter': 0.03123, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.76926}
2025-08-16 06:04:15,407 - INFO - test: {'epoch': 26, 'time_epoch': 3.93463, 'loss': 0.12873772, 'lr': 0, 'params': 514193, 'time_iter': 0.0305, 'accuracy': 0.96669, 'precision': 0.44068, 'recall': 0.2, 'f1': 0.27513, 'auc': 0.74837}
2025-08-16 06:04:15,411 - INFO - > Epoch 26: took 73.2s (avg 76.6s) | Best so far: epoch 20	train_loss: 0.1109 train_auc: 0.8512	val_loss: 0.0915 val_auc: 0.7783	test_loss: 0.1288 test_auc: 0.7702
2025-08-16 06:05:19,704 - INFO - train: {'epoch': 27, 'time_epoch': 64.17991, 'eta': 4870.20467, 'eta_hours': 1.35283, 'loss': 0.10535077, 'lr': 8.734e-05, 'params': 514193, 'time_iter': 0.06237, 'accuracy': 0.97012, 'precision': 0.72432, 'recall': 0.3263, 'f1': 0.44992, 'auc': 0.87516}
2025-08-16 06:05:23,974 - INFO - val: {'epoch': 27, 'time_epoch': 4.24584, 'loss': 0.07967988, 'lr': 0, 'params': 514193, 'time_iter': 0.03291, 'accuracy': 0.98152, 'precision': 0.5641, 'recall': 0.2716, 'f1': 0.36667, 'auc': 0.79048}
2025-08-16 06:05:28,171 - INFO - test: {'epoch': 27, 'time_epoch': 4.17744, 'loss': 0.11968601, 'lr': 0, 'params': 514193, 'time_iter': 0.03238, 'accuracy': 0.96912, 'precision': 0.5283, 'recall': 0.21538, 'f1': 0.30601, 'auc': 0.77698}
2025-08-16 06:05:28,174 - INFO - > Epoch 27: took 72.8s (avg 76.5s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:06:34,067 - INFO - train: {'epoch': 28, 'time_epoch': 65.78864, 'eta': 4798.02606, 'eta_hours': 1.33279, 'loss': 0.10287336, 'lr': 8.622e-05, 'params': 514193, 'time_iter': 0.06393, 'accuracy': 0.97058, 'precision': 0.73322, 'recall': 0.33685, 'f1': 0.46162, 'auc': 0.8816}
2025-08-16 06:06:38,085 - INFO - val: {'epoch': 28, 'time_epoch': 3.99581, 'loss': 0.08014536, 'lr': 0, 'params': 514193, 'time_iter': 0.03098, 'accuracy': 0.98347, 'precision': 0.69697, 'recall': 0.28395, 'f1': 0.40351, 'auc': 0.78937}
2025-08-16 06:06:42,156 - INFO - test: {'epoch': 28, 'time_epoch': 4.05426, 'loss': 0.12871628, 'lr': 0, 'params': 514193, 'time_iter': 0.03143, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.07692, 'f1': 0.13333, 'auc': 0.74699}
2025-08-16 06:06:42,159 - INFO - > Epoch 28: took 74.0s (avg 76.4s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:07:47,164 - INFO - train: {'epoch': 29, 'time_epoch': 64.8716, 'eta': 4724.13368, 'eta_hours': 1.31226, 'loss': 0.10345656, 'lr': 8.506e-05, 'params': 514193, 'time_iter': 0.06304, 'accuracy': 0.96997, 'precision': 0.70819, 'recall': 0.33685, 'f1': 0.45655, 'auc': 0.88218}
2025-08-16 06:07:51,456 - INFO - val: {'epoch': 29, 'time_epoch': 4.26869, 'loss': 0.09328826, 'lr': 0, 'params': 514193, 'time_iter': 0.03309, 'accuracy': 0.97666, 'precision': 0.39726, 'recall': 0.35802, 'f1': 0.37662, 'auc': 0.74163}
2025-08-16 06:07:55,674 - INFO - test: {'epoch': 29, 'time_epoch': 4.20027, 'loss': 0.13640246, 'lr': 0, 'params': 514193, 'time_iter': 0.03256, 'accuracy': 0.96329, 'precision': 0.38947, 'recall': 0.28462, 'f1': 0.32889, 'auc': 0.74614}
2025-08-16 06:07:55,676 - INFO - > Epoch 29: took 73.5s (avg 76.3s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:09:03,532 - INFO - train: {'epoch': 30, 'time_epoch': 67.74345, 'eta': 4657.21548, 'eta_hours': 1.29367, 'loss': 0.10174973, 'lr': 8.386e-05, 'params': 514193, 'time_iter': 0.06583, 'accuracy': 0.9707, 'precision': 0.72185, 'recall': 0.3539, 'f1': 0.47495, 'auc': 0.88889}
2025-08-16 06:09:07,765 - INFO - val: {'epoch': 30, 'time_epoch': 4.20666, 'loss': 0.07954366, 'lr': 0, 'params': 514193, 'time_iter': 0.03261, 'accuracy': 0.98128, 'precision': 0.54762, 'recall': 0.28395, 'f1': 0.37398, 'auc': 0.78208}
2025-08-16 06:09:11,899 - INFO - test: {'epoch': 30, 'time_epoch': 4.11253, 'loss': 0.12914117, 'lr': 0, 'params': 514193, 'time_iter': 0.03188, 'accuracy': 0.96718, 'precision': 0.45614, 'recall': 0.2, 'f1': 0.27807, 'auc': 0.74155}
2025-08-16 06:09:11,903 - INFO - > Epoch 30: took 76.2s (avg 76.3s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:10:16,693 - INFO - train: {'epoch': 31, 'time_epoch': 64.67585, 'eta': 4583.72704, 'eta_hours': 1.27326, 'loss': 0.09976455, 'lr': 8.263e-05, 'params': 514193, 'time_iter': 0.06285, 'accuracy': 0.97046, 'precision': 0.70312, 'recall': 0.36526, 'f1': 0.48077, 'auc': 0.89495}
2025-08-16 06:10:20,829 - INFO - val: {'epoch': 31, 'time_epoch': 4.11377, 'loss': 0.09888641, 'lr': 0, 'params': 514193, 'time_iter': 0.03189, 'accuracy': 0.97277, 'precision': 0.32184, 'recall': 0.34568, 'f1': 0.33333, 'auc': 0.769}
2025-08-16 06:10:24,897 - INFO - test: {'epoch': 31, 'time_epoch': 4.05153, 'loss': 0.13344161, 'lr': 0, 'params': 514193, 'time_iter': 0.03141, 'accuracy': 0.96304, 'precision': 0.38298, 'recall': 0.27692, 'f1': 0.32143, 'auc': 0.76405}
2025-08-16 06:10:24,901 - INFO - > Epoch 31: took 73.0s (avg 76.2s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:11:29,479 - INFO - train: {'epoch': 32, 'time_epoch': 64.46884, 'eta': 4510.35241, 'eta_hours': 1.25288, 'loss': 0.09881148, 'lr': 8.136e-05, 'params': 514193, 'time_iter': 0.06265, 'accuracy': 0.97113, 'precision': 0.72964, 'recall': 0.36364, 'f1': 0.48537, 'auc': 0.8983}
2025-08-16 06:11:33,607 - INFO - val: {'epoch': 32, 'time_epoch': 4.09903, 'loss': 0.08189944, 'lr': 0, 'params': 514193, 'time_iter': 0.03178, 'accuracy': 0.98055, 'precision': 0.5098, 'recall': 0.32099, 'f1': 0.39394, 'auc': 0.78726}
2025-08-16 06:11:37,678 - INFO - test: {'epoch': 32, 'time_epoch': 4.05501, 'loss': 0.13134572, 'lr': 0, 'params': 514193, 'time_iter': 0.03143, 'accuracy': 0.96572, 'precision': 0.43038, 'recall': 0.26154, 'f1': 0.32536, 'auc': 0.75809}
2025-08-16 06:11:37,680 - INFO - > Epoch 32: took 72.8s (avg 76.1s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:12:42,225 - INFO - train: {'epoch': 33, 'time_epoch': 64.43912, 'eta': 4437.44397, 'eta_hours': 1.23262, 'loss': 0.09839967, 'lr': 8.005e-05, 'params': 514193, 'time_iter': 0.06262, 'accuracy': 0.97182, 'precision': 0.74322, 'recall': 0.37825, 'f1': 0.50134, 'auc': 0.8964}
2025-08-16 06:12:46,381 - INFO - val: {'epoch': 33, 'time_epoch': 4.13569, 'loss': 0.09116738, 'lr': 0, 'params': 514193, 'time_iter': 0.03206, 'accuracy': 0.97642, 'precision': 0.38571, 'recall': 0.33333, 'f1': 0.35762, 'auc': 0.7894}
2025-08-16 06:12:50,467 - INFO - test: {'epoch': 33, 'time_epoch': 4.06725, 'loss': 0.14031917, 'lr': 0, 'params': 514193, 'time_iter': 0.03153, 'accuracy': 0.96134, 'precision': 0.36449, 'recall': 0.3, 'f1': 0.32911, 'auc': 0.75113}
2025-08-16 06:12:50,469 - INFO - > Epoch 33: took 72.8s (avg 76.0s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:13:54,548 - INFO - train: {'epoch': 34, 'time_epoch': 63.96432, 'eta': 4364.1377, 'eta_hours': 1.21226, 'loss': 0.09786947, 'lr': 7.872e-05, 'params': 514193, 'time_iter': 0.06216, 'accuracy': 0.97189, 'precision': 0.75712, 'recall': 0.36688, 'f1': 0.49426, 'auc': 0.89414}
2025-08-16 06:13:58,540 - INFO - val: {'epoch': 34, 'time_epoch': 3.97107, 'loss': 0.08481479, 'lr': 0, 'params': 514193, 'time_iter': 0.03078, 'accuracy': 0.98152, 'precision': 0.55814, 'recall': 0.2963, 'f1': 0.3871, 'auc': 0.75655}
2025-08-16 06:14:02,462 - INFO - test: {'epoch': 34, 'time_epoch': 3.90579, 'loss': 0.13044409, 'lr': 0, 'params': 514193, 'time_iter': 0.03028, 'accuracy': 0.96742, 'precision': 0.46296, 'recall': 0.19231, 'f1': 0.27174, 'auc': 0.74475}
2025-08-16 06:14:02,464 - INFO - > Epoch 34: took 72.0s (avg 75.9s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:15:05,457 - INFO - train: {'epoch': 35, 'time_epoch': 62.88803, 'eta': 4289.43703, 'eta_hours': 1.19151, 'loss': 0.09556154, 'lr': 7.735e-05, 'params': 514193, 'time_iter': 0.06112, 'accuracy': 0.97189, 'precision': 0.73872, 'recall': 0.38555, 'f1': 0.50667, 'auc': 0.902}
2025-08-16 06:15:09,634 - INFO - val: {'epoch': 35, 'time_epoch': 4.15147, 'loss': 0.08696917, 'lr': 0, 'params': 514193, 'time_iter': 0.03218, 'accuracy': 0.97982, 'precision': 0.48148, 'recall': 0.32099, 'f1': 0.38519, 'auc': 0.75398}
2025-08-16 06:15:13,788 - INFO - test: {'epoch': 35, 'time_epoch': 4.13751, 'loss': 0.13912387, 'lr': 0, 'params': 514193, 'time_iter': 0.03207, 'accuracy': 0.96548, 'precision': 0.42105, 'recall': 0.24615, 'f1': 0.31068, 'auc': 0.72459}
2025-08-16 06:15:13,790 - INFO - > Epoch 35: took 71.3s (avg 75.7s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:16:17,911 - INFO - train: {'epoch': 36, 'time_epoch': 64.01752, 'eta': 4217.29806, 'eta_hours': 1.17147, 'loss': 0.09500979, 'lr': 7.595e-05, 'params': 514193, 'time_iter': 0.06221, 'accuracy': 0.97261, 'precision': 0.75501, 'recall': 0.39773, 'f1': 0.521, 'auc': 0.90185}
2025-08-16 06:16:22,039 - INFO - val: {'epoch': 36, 'time_epoch': 4.10773, 'loss': 0.08371128, 'lr': 0, 'params': 514193, 'time_iter': 0.03184, 'accuracy': 0.98104, 'precision': 0.53061, 'recall': 0.32099, 'f1': 0.4, 'auc': 0.7626}
2025-08-16 06:16:26,096 - INFO - test: {'epoch': 36, 'time_epoch': 4.03903, 'loss': 0.1391198, 'lr': 0, 'params': 514193, 'time_iter': 0.03131, 'accuracy': 0.96426, 'precision': 0.37313, 'recall': 0.19231, 'f1': 0.25381, 'auc': 0.73261}
2025-08-16 06:16:26,098 - INFO - > Epoch 36: took 72.3s (avg 75.6s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:17:30,038 - INFO - train: {'epoch': 37, 'time_epoch': 63.82965, 'eta': 4145.28001, 'eta_hours': 1.15147, 'loss': 0.09512782, 'lr': 7.452e-05, 'params': 514193, 'time_iter': 0.06203, 'accuracy': 0.97192, 'precision': 0.74759, 'recall': 0.37744, 'f1': 0.50162, 'auc': 0.90786}
2025-08-16 06:17:34,337 - INFO - val: {'epoch': 37, 'time_epoch': 4.27785, 'loss': 0.0876704, 'lr': 0, 'params': 514193, 'time_iter': 0.03316, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.2963, 'f1': 0.37209, 'auc': 0.7594}
2025-08-16 06:17:38,474 - INFO - test: {'epoch': 37, 'time_epoch': 4.12115, 'loss': 0.14169961, 'lr': 0, 'params': 514193, 'time_iter': 0.03195, 'accuracy': 0.96475, 'precision': 0.36842, 'recall': 0.16154, 'f1': 0.2246, 'auc': 0.7155}
2025-08-16 06:17:38,477 - INFO - > Epoch 37: took 72.4s (avg 75.6s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:18:44,220 - INFO - train: {'epoch': 38, 'time_epoch': 65.63972, 'eta': 4076.51302, 'eta_hours': 1.13236, 'loss': 0.09351438, 'lr': 7.307e-05, 'params': 514193, 'time_iter': 0.06379, 'accuracy': 0.97277, 'precision': 0.75846, 'recall': 0.40016, 'f1': 0.52391, 'auc': 0.90932}
2025-08-16 06:18:48,199 - INFO - val: {'epoch': 38, 'time_epoch': 3.95863, 'loss': 0.07973371, 'lr': 0, 'params': 514193, 'time_iter': 0.03069, 'accuracy': 0.98347, 'precision': 0.68571, 'recall': 0.2963, 'f1': 0.41379, 'auc': 0.76872}
2025-08-16 06:18:52,265 - INFO - test: {'epoch': 38, 'time_epoch': 4.05054, 'loss': 0.1318673, 'lr': 0, 'params': 514193, 'time_iter': 0.0314, 'accuracy': 0.96937, 'precision': 0.54762, 'recall': 0.17692, 'f1': 0.26744, 'auc': 0.74296}
2025-08-16 06:18:52,269 - INFO - > Epoch 38: took 73.8s (avg 75.5s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:19:56,090 - INFO - train: {'epoch': 39, 'time_epoch': 63.72015, 'eta': 4005.02304, 'eta_hours': 1.11251, 'loss': 0.09286579, 'lr': 7.159e-05, 'params': 514193, 'time_iter': 0.06192, 'accuracy': 0.97289, 'precision': 0.76562, 'recall': 0.39773, 'f1': 0.5235, 'auc': 0.90989}
2025-08-16 06:20:00,201 - INFO - val: {'epoch': 39, 'time_epoch': 4.09072, 'loss': 0.08816261, 'lr': 0, 'params': 514193, 'time_iter': 0.03171, 'accuracy': 0.97885, 'precision': 0.45, 'recall': 0.33333, 'f1': 0.38298, 'auc': 0.77565}
2025-08-16 06:20:04,276 - INFO - test: {'epoch': 39, 'time_epoch': 4.05663, 'loss': 0.14108664, 'lr': 0, 'params': 514193, 'time_iter': 0.03145, 'accuracy': 0.96329, 'precision': 0.37647, 'recall': 0.24615, 'f1': 0.29767, 'auc': 0.75054}
2025-08-16 06:20:04,279 - INFO - > Epoch 39: took 72.0s (avg 75.4s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:21:07,689 - INFO - train: {'epoch': 40, 'time_epoch': 63.30603, 'eta': 3933.31614, 'eta_hours': 1.09259, 'loss': 0.09186719, 'lr': 7.008e-05, 'params': 514193, 'time_iter': 0.06152, 'accuracy': 0.97313, 'precision': 0.76364, 'recall': 0.40909, 'f1': 0.53277, 'auc': 0.91301}
2025-08-16 06:21:11,758 - INFO - val: {'epoch': 40, 'time_epoch': 4.0477, 'loss': 0.09785878, 'lr': 0, 'params': 514193, 'time_iter': 0.03138, 'accuracy': 0.97447, 'precision': 0.34615, 'recall': 0.33333, 'f1': 0.33962, 'auc': 0.76532}
2025-08-16 06:21:15,782 - INFO - test: {'epoch': 40, 'time_epoch': 4.0021, 'loss': 0.14746995, 'lr': 0, 'params': 514193, 'time_iter': 0.03102, 'accuracy': 0.9611, 'precision': 0.36607, 'recall': 0.31538, 'f1': 0.33884, 'auc': 0.74809}
2025-08-16 06:21:15,788 - INFO - > Epoch 40: took 71.5s (avg 75.3s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:22:19,374 - INFO - train: {'epoch': 41, 'time_epoch': 63.47986, 'eta': 3862.24934, 'eta_hours': 1.07285, 'loss': 0.09018625, 'lr': 6.856e-05, 'params': 514193, 'time_iter': 0.06169, 'accuracy': 0.97304, 'precision': 0.75632, 'recall': 0.41315, 'f1': 0.53438, 'auc': 0.9201}
2025-08-16 06:22:23,472 - INFO - val: {'epoch': 41, 'time_epoch': 4.0736, 'loss': 0.08652272, 'lr': 0, 'params': 514193, 'time_iter': 0.03158, 'accuracy': 0.97982, 'precision': 0.48077, 'recall': 0.30864, 'f1': 0.37594, 'auc': 0.77019}
2025-08-16 06:22:27,544 - INFO - test: {'epoch': 41, 'time_epoch': 4.05647, 'loss': 0.13586817, 'lr': 0, 'params': 514193, 'time_iter': 0.03145, 'accuracy': 0.96475, 'precision': 0.38462, 'recall': 0.19231, 'f1': 0.25641, 'auc': 0.7392}
2025-08-16 06:22:27,547 - INFO - > Epoch 41: took 71.8s (avg 75.2s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:23:32,001 - INFO - train: {'epoch': 42, 'time_epoch': 64.34915, 'eta': 3792.68773, 'eta_hours': 1.05352, 'loss': 0.091722, 'lr': 6.701e-05, 'params': 514193, 'time_iter': 0.06254, 'accuracy': 0.97316, 'precision': 0.76084, 'recall': 0.41315, 'f1': 0.53551, 'auc': 0.91586}
2025-08-16 06:23:36,050 - INFO - val: {'epoch': 42, 'time_epoch': 4.02918, 'loss': 0.08500006, 'lr': 0, 'params': 514193, 'time_iter': 0.03123, 'accuracy': 0.98152, 'precision': 0.55814, 'recall': 0.2963, 'f1': 0.3871, 'auc': 0.77476}
2025-08-16 06:23:40,081 - INFO - test: {'epoch': 42, 'time_epoch': 4.01235, 'loss': 0.13461267, 'lr': 0, 'params': 514193, 'time_iter': 0.0311, 'accuracy': 0.96791, 'precision': 0.48148, 'recall': 0.2, 'f1': 0.28261, 'auc': 0.73234}
2025-08-16 06:23:40,083 - INFO - > Epoch 42: took 72.5s (avg 75.2s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:24:43,444 - INFO - train: {'epoch': 43, 'time_epoch': 63.25789, 'eta': 3721.97418, 'eta_hours': 1.03388, 'loss': 0.09122422, 'lr': 6.545e-05, 'params': 514193, 'time_iter': 0.06148, 'accuracy': 0.97286, 'precision': 0.75957, 'recall': 0.4026, 'f1': 0.52626, 'auc': 0.9176}
2025-08-16 06:24:47,541 - INFO - val: {'epoch': 43, 'time_epoch': 4.07624, 'loss': 0.08528619, 'lr': 0, 'params': 514193, 'time_iter': 0.0316, 'accuracy': 0.98128, 'precision': 0.54348, 'recall': 0.30864, 'f1': 0.3937, 'auc': 0.77157}
2025-08-16 06:24:51,627 - INFO - test: {'epoch': 43, 'time_epoch': 4.06872, 'loss': 0.13731689, 'lr': 0, 'params': 514193, 'time_iter': 0.03154, 'accuracy': 0.9662, 'precision': 0.42857, 'recall': 0.20769, 'f1': 0.27979, 'auc': 0.73564}
2025-08-16 06:24:51,629 - INFO - > Epoch 43: took 71.5s (avg 75.1s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:25:55,425 - INFO - train: {'epoch': 44, 'time_epoch': 63.69408, 'eta': 3652.12511, 'eta_hours': 1.01448, 'loss': 0.08833022, 'lr': 6.387e-05, 'params': 514193, 'time_iter': 0.0619, 'accuracy': 0.97386, 'precision': 0.77434, 'recall': 0.42614, 'f1': 0.54974, 'auc': 0.92344}
2025-08-16 06:25:59,435 - INFO - val: {'epoch': 44, 'time_epoch': 3.98872, 'loss': 0.08856164, 'lr': 0, 'params': 514193, 'time_iter': 0.03092, 'accuracy': 0.97933, 'precision': 0.46154, 'recall': 0.2963, 'f1': 0.3609, 'auc': 0.77474}
2025-08-16 06:26:03,452 - INFO - test: {'epoch': 44, 'time_epoch': 3.99796, 'loss': 0.14274648, 'lr': 0, 'params': 514193, 'time_iter': 0.03099, 'accuracy': 0.96572, 'precision': 0.42254, 'recall': 0.23077, 'f1': 0.29851, 'auc': 0.72341}
2025-08-16 06:26:03,454 - INFO - > Epoch 44: took 71.8s (avg 75.0s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:27:08,795 - INFO - train: {'epoch': 45, 'time_epoch': 65.23731, 'eta': 3584.35527, 'eta_hours': 0.99565, 'loss': 0.08984886, 'lr': 6.227e-05, 'params': 514193, 'time_iter': 0.0634, 'accuracy': 0.9735, 'precision': 0.76316, 'recall': 0.4237, 'f1': 0.54489, 'auc': 0.91691}
2025-08-16 06:27:12,858 - INFO - val: {'epoch': 45, 'time_epoch': 4.04153, 'loss': 0.08941014, 'lr': 0, 'params': 514193, 'time_iter': 0.03133, 'accuracy': 0.97471, 'precision': 0.34667, 'recall': 0.32099, 'f1': 0.33333, 'auc': 0.78493}
2025-08-16 06:27:16,831 - INFO - test: {'epoch': 45, 'time_epoch': 3.95735, 'loss': 0.14116242, 'lr': 0, 'params': 514193, 'time_iter': 0.03068, 'accuracy': 0.9628, 'precision': 0.37634, 'recall': 0.26923, 'f1': 0.3139, 'auc': 0.74949}
2025-08-16 06:27:16,834 - INFO - > Epoch 45: took 73.4s (avg 75.0s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:28:20,293 - INFO - train: {'epoch': 46, 'time_epoch': 63.35861, 'eta': 3514.57466, 'eta_hours': 0.97627, 'loss': 0.08783407, 'lr': 6.066e-05, 'params': 514193, 'time_iter': 0.06157, 'accuracy': 0.97301, 'precision': 0.74784, 'recall': 0.42127, 'f1': 0.53894, 'auc': 0.92973}
2025-08-16 06:28:24,264 - INFO - val: {'epoch': 46, 'time_epoch': 3.95128, 'loss': 0.0846943, 'lr': 0, 'params': 514193, 'time_iter': 0.03063, 'accuracy': 0.98006, 'precision': 0.4898, 'recall': 0.2963, 'f1': 0.36923, 'auc': 0.78405}
2025-08-16 06:28:28,177 - INFO - test: {'epoch': 46, 'time_epoch': 3.89771, 'loss': 0.14583398, 'lr': 0, 'params': 514193, 'time_iter': 0.03021, 'accuracy': 0.96329, 'precision': 0.32203, 'recall': 0.14615, 'f1': 0.20106, 'auc': 0.71727}
2025-08-16 06:28:28,179 - INFO - > Epoch 46: took 71.3s (avg 74.9s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:29:31,262 - INFO - train: {'epoch': 47, 'time_epoch': 62.97821, 'eta': 3444.64953, 'eta_hours': 0.95685, 'loss': 0.08649414, 'lr': 5.904e-05, 'params': 514193, 'time_iter': 0.0612, 'accuracy': 0.97462, 'precision': 0.78726, 'recall': 0.44156, 'f1': 0.56578, 'auc': 0.92715}
2025-08-16 06:29:35,391 - INFO - val: {'epoch': 47, 'time_epoch': 4.10839, 'loss': 0.09407576, 'lr': 0, 'params': 514193, 'time_iter': 0.03185, 'accuracy': 0.97617, 'precision': 0.38028, 'recall': 0.33333, 'f1': 0.35526, 'auc': 0.77818}
2025-08-16 06:29:39,396 - INFO - test: {'epoch': 47, 'time_epoch': 3.98952, 'loss': 0.14865121, 'lr': 0, 'params': 514193, 'time_iter': 0.03093, 'accuracy': 0.96231, 'precision': 0.36559, 'recall': 0.26154, 'f1': 0.30493, 'auc': 0.72901}
2025-08-16 06:29:39,400 - INFO - > Epoch 47: took 71.2s (avg 74.8s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:30:42,488 - INFO - train: {'epoch': 48, 'time_epoch': 62.9828, 'eta': 3375.01273, 'eta_hours': 0.9375, 'loss': 0.08562184, 'lr': 5.741e-05, 'params': 514193, 'time_iter': 0.06121, 'accuracy': 0.97432, 'precision': 0.77922, 'recall': 0.43831, 'f1': 0.56104, 'auc': 0.93215}
2025-08-16 06:30:46,550 - INFO - val: {'epoch': 48, 'time_epoch': 4.04098, 'loss': 0.0876611, 'lr': 0, 'params': 514193, 'time_iter': 0.03133, 'accuracy': 0.98006, 'precision': 0.48649, 'recall': 0.22222, 'f1': 0.30508, 'auc': 0.76454}
2025-08-16 06:30:50,568 - INFO - test: {'epoch': 48, 'time_epoch': 4.00098, 'loss': 0.14750723, 'lr': 0, 'params': 514193, 'time_iter': 0.03102, 'accuracy': 0.9662, 'precision': 0.36364, 'recall': 0.09231, 'f1': 0.14724, 'auc': 0.71663}
2025-08-16 06:30:50,570 - INFO - > Epoch 48: took 71.2s (avg 74.8s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:31:53,835 - INFO - train: {'epoch': 49, 'time_epoch': 63.16185, 'eta': 3305.82114, 'eta_hours': 0.91828, 'loss': 0.08663317, 'lr': 5.577e-05, 'params': 514193, 'time_iter': 0.06138, 'accuracy': 0.97423, 'precision': 0.77195, 'recall': 0.44237, 'f1': 0.56244, 'auc': 0.92594}
2025-08-16 06:31:57,963 - INFO - val: {'epoch': 49, 'time_epoch': 4.10768, 'loss': 0.09414291, 'lr': 0, 'params': 514193, 'time_iter': 0.03184, 'accuracy': 0.97569, 'precision': 0.37662, 'recall': 0.35802, 'f1': 0.36709, 'auc': 0.78586}
2025-08-16 06:32:01,995 - INFO - test: {'epoch': 49, 'time_epoch': 4.01523, 'loss': 0.15007943, 'lr': 0, 'params': 514193, 'time_iter': 0.03113, 'accuracy': 0.9645, 'precision': 0.42, 'recall': 0.32308, 'f1': 0.36522, 'auc': 0.7292}
2025-08-16 06:32:01,997 - INFO - > Epoch 49: took 71.4s (avg 74.7s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:33:05,537 - INFO - train: {'epoch': 50, 'time_epoch': 63.43797, 'eta': 3237.1313, 'eta_hours': 0.8992, 'loss': 0.08468012, 'lr': 5.413e-05, 'params': 514193, 'time_iter': 0.06165, 'accuracy': 0.97465, 'precision': 0.7741, 'recall': 0.45617, 'f1': 0.57406, 'auc': 0.93263}
2025-08-16 06:33:09,581 - INFO - val: {'epoch': 50, 'time_epoch': 4.02391, 'loss': 0.09163293, 'lr': 0, 'params': 514193, 'time_iter': 0.03119, 'accuracy': 0.97739, 'precision': 0.4, 'recall': 0.2963, 'f1': 0.34043, 'auc': 0.7793}
2025-08-16 06:33:13,605 - INFO - test: {'epoch': 50, 'time_epoch': 4.00831, 'loss': 0.14492271, 'lr': 0, 'params': 514193, 'time_iter': 0.03107, 'accuracy': 0.96548, 'precision': 0.42683, 'recall': 0.26923, 'f1': 0.33019, 'auc': 0.74816}
2025-08-16 06:33:13,607 - INFO - > Epoch 50: took 71.6s (avg 74.6s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:34:16,929 - INFO - train: {'epoch': 51, 'time_epoch': 63.22068, 'eta': 3168.44288, 'eta_hours': 0.88012, 'loss': 0.08303835, 'lr': 5.248e-05, 'params': 514193, 'time_iter': 0.06144, 'accuracy': 0.97477, 'precision': 0.7831, 'recall': 0.4513, 'f1': 0.57261, 'auc': 0.93765}
2025-08-16 06:34:20,912 - INFO - val: {'epoch': 51, 'time_epoch': 3.96144, 'loss': 0.0887298, 'lr': 0, 'params': 514193, 'time_iter': 0.03071, 'accuracy': 0.97909, 'precision': 0.44681, 'recall': 0.25926, 'f1': 0.32812, 'auc': 0.75592}
2025-08-16 06:34:24,892 - INFO - test: {'epoch': 51, 'time_epoch': 3.96425, 'loss': 0.14798893, 'lr': 0, 'params': 514193, 'time_iter': 0.03073, 'accuracy': 0.96548, 'precision': 0.42857, 'recall': 0.27692, 'f1': 0.33645, 'auc': 0.71581}
2025-08-16 06:34:24,894 - INFO - > Epoch 51: took 71.3s (avg 74.6s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:35:28,147 - INFO - train: {'epoch': 52, 'time_epoch': 63.14982, 'eta': 3099.89795, 'eta_hours': 0.86108, 'loss': 0.08230164, 'lr': 5.083e-05, 'params': 514193, 'time_iter': 0.06137, 'accuracy': 0.97526, 'precision': 0.7863, 'recall': 0.46591, 'f1': 0.58512, 'auc': 0.94018}
2025-08-16 06:35:32,146 - INFO - val: {'epoch': 52, 'time_epoch': 3.97871, 'loss': 0.08745165, 'lr': 0, 'params': 514193, 'time_iter': 0.03084, 'accuracy': 0.97958, 'precision': 0.46512, 'recall': 0.24691, 'f1': 0.32258, 'auc': 0.7846}
2025-08-16 06:35:36,034 - INFO - test: {'epoch': 52, 'time_epoch': 3.87161, 'loss': 0.1519144, 'lr': 0, 'params': 514193, 'time_iter': 0.03001, 'accuracy': 0.96815, 'precision': 0.49153, 'recall': 0.22308, 'f1': 0.30688, 'auc': 0.71201}
2025-08-16 06:35:36,036 - INFO - > Epoch 52: took 71.1s (avg 74.5s) | Best so far: epoch 27	train_loss: 0.1054 train_auc: 0.8752	val_loss: 0.0797 val_auc: 0.7905	test_loss: 0.1197 test_auc: 0.7770
2025-08-16 06:36:39,259 - INFO - train: {'epoch': 53, 'time_epoch': 63.12101, 'eta': 3031.5283, 'eta_hours': 0.84209, 'loss': 0.08323946, 'lr': 4.917e-05, 'params': 514193, 'time_iter': 0.06134, 'accuracy': 0.97471, 'precision': 0.77855, 'recall': 0.45373, 'f1': 0.57333, 'auc': 0.93763}
2025-08-16 06:36:43,362 - INFO - val: {'epoch': 53, 'time_epoch': 4.08297, 'loss': 0.08769473, 'lr': 0, 'params': 514193, 'time_iter': 0.03165, 'accuracy': 0.97763, 'precision': 0.41538, 'recall': 0.33333, 'f1': 0.36986, 'auc': 0.80063}
2025-08-16 06:36:47,355 - INFO - test: {'epoch': 53, 'time_epoch': 3.97673, 'loss': 0.15080479, 'lr': 0, 'params': 514193, 'time_iter': 0.03083, 'accuracy': 0.96402, 'precision': 0.39773, 'recall': 0.26923, 'f1': 0.3211, 'auc': 0.73369}
2025-08-16 06:36:47,357 - INFO - > Epoch 53: took 71.3s (avg 74.4s) | Best so far: epoch 53	train_loss: 0.0832 train_auc: 0.9376	val_loss: 0.0877 val_auc: 0.8006	test_loss: 0.1508 test_auc: 0.7337
2025-08-16 06:37:51,492 - INFO - train: {'epoch': 54, 'time_epoch': 64.0245, 'eta': 2964.08873, 'eta_hours': 0.82336, 'loss': 0.08260024, 'lr': 4.752e-05, 'params': 514193, 'time_iter': 0.06222, 'accuracy': 0.97505, 'precision': 0.77437, 'recall': 0.47078, 'f1': 0.58556, 'auc': 0.9383}
2025-08-16 06:37:55,450 - INFO - val: {'epoch': 54, 'time_epoch': 3.93879, 'loss': 0.08575222, 'lr': 0, 'params': 514193, 'time_iter': 0.03053, 'accuracy': 0.97836, 'precision': 0.4375, 'recall': 0.34568, 'f1': 0.38621, 'auc': 0.80159}
2025-08-16 06:37:59,309 - INFO - test: {'epoch': 54, 'time_epoch': 3.84323, 'loss': 0.14896572, 'lr': 0, 'params': 514193, 'time_iter': 0.02979, 'accuracy': 0.96329, 'precision': 0.37931, 'recall': 0.25385, 'f1': 0.30415, 'auc': 0.72976}
2025-08-16 06:37:59,312 - INFO - > Epoch 54: took 72.0s (avg 74.4s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:39:02,719 - INFO - train: {'epoch': 55, 'time_epoch': 63.30514, 'eta': 2896.20591, 'eta_hours': 0.8045, 'loss': 0.08040771, 'lr': 4.587e-05, 'params': 514193, 'time_iter': 0.06152, 'accuracy': 0.97553, 'precision': 0.78735, 'recall': 0.47484, 'f1': 0.59241, 'auc': 0.94129}
2025-08-16 06:39:06,770 - INFO - val: {'epoch': 55, 'time_epoch': 4.03102, 'loss': 0.08482244, 'lr': 0, 'params': 514193, 'time_iter': 0.03125, 'accuracy': 0.98055, 'precision': 0.5098, 'recall': 0.32099, 'f1': 0.39394, 'auc': 0.77752}
2025-08-16 06:39:10,735 - INFO - test: {'epoch': 55, 'time_epoch': 3.94835, 'loss': 0.14860585, 'lr': 0, 'params': 514193, 'time_iter': 0.03061, 'accuracy': 0.96377, 'precision': 0.36986, 'recall': 0.20769, 'f1': 0.26601, 'auc': 0.72785}
2025-08-16 06:39:10,737 - INFO - > Epoch 55: took 71.4s (avg 74.3s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:40:13,874 - INFO - train: {'epoch': 56, 'time_epoch': 63.0336, 'eta': 2828.27887, 'eta_hours': 0.78563, 'loss': 0.08113946, 'lr': 4.423e-05, 'params': 514193, 'time_iter': 0.06126, 'accuracy': 0.97483, 'precision': 0.78612, 'recall': 0.45049, 'f1': 0.57276, 'auc': 0.94543}
2025-08-16 06:40:17,956 - INFO - val: {'epoch': 56, 'time_epoch': 4.0612, 'loss': 0.09412252, 'lr': 0, 'params': 514193, 'time_iter': 0.03148, 'accuracy': 0.97496, 'precision': 0.33824, 'recall': 0.28395, 'f1': 0.30872, 'auc': 0.7833}
2025-08-16 06:40:21,950 - INFO - test: {'epoch': 56, 'time_epoch': 3.97752, 'loss': 0.15269788, 'lr': 0, 'params': 514193, 'time_iter': 0.03083, 'accuracy': 0.9594, 'precision': 0.33333, 'recall': 0.28462, 'f1': 0.30705, 'auc': 0.74462}
2025-08-16 06:40:21,952 - INFO - > Epoch 56: took 71.2s (avg 74.3s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:41:24,853 - INFO - train: {'epoch': 57, 'time_epoch': 62.79693, 'eta': 2760.34919, 'eta_hours': 0.76676, 'loss': 0.07889727, 'lr': 4.259e-05, 'params': 514193, 'time_iter': 0.06103, 'accuracy': 0.97587, 'precision': 0.80249, 'recall': 0.47159, 'f1': 0.59407, 'auc': 0.94528}
2025-08-16 06:41:28,928 - INFO - val: {'epoch': 57, 'time_epoch': 4.05531, 'loss': 0.10862431, 'lr': 0, 'params': 514193, 'time_iter': 0.03144, 'accuracy': 0.97082, 'precision': 0.29474, 'recall': 0.34568, 'f1': 0.31818, 'auc': 0.77986}
2025-08-16 06:41:32,972 - INFO - test: {'epoch': 57, 'time_epoch': 4.02746, 'loss': 0.16898813, 'lr': 0, 'params': 514193, 'time_iter': 0.03122, 'accuracy': 0.95332, 'precision': 0.27536, 'recall': 0.29231, 'f1': 0.28358, 'auc': 0.7415}
2025-08-16 06:41:32,974 - INFO - > Epoch 57: took 71.0s (avg 74.2s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:42:36,982 - INFO - train: {'epoch': 58, 'time_epoch': 63.90068, 'eta': 2693.36051, 'eta_hours': 0.74816, 'loss': 0.0785822, 'lr': 4.096e-05, 'params': 514193, 'time_iter': 0.0621, 'accuracy': 0.97632, 'precision': 0.80567, 'recall': 0.48458, 'f1': 0.60517, 'auc': 0.94498}
2025-08-16 06:42:40,896 - INFO - val: {'epoch': 58, 'time_epoch': 3.89446, 'loss': 0.08768928, 'lr': 0, 'params': 514193, 'time_iter': 0.03019, 'accuracy': 0.97958, 'precision': 0.47059, 'recall': 0.2963, 'f1': 0.36364, 'auc': 0.78633}
2025-08-16 06:42:44,766 - INFO - test: {'epoch': 58, 'time_epoch': 3.85507, 'loss': 0.15425315, 'lr': 0, 'params': 514193, 'time_iter': 0.02988, 'accuracy': 0.9662, 'precision': 0.41176, 'recall': 0.16154, 'f1': 0.23204, 'auc': 0.72208}
2025-08-16 06:42:44,769 - INFO - > Epoch 58: took 71.8s (avg 74.2s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:43:47,467 - INFO - train: {'epoch': 59, 'time_epoch': 62.59352, 'eta': 2625.60332, 'eta_hours': 0.72933, 'loss': 0.07932788, 'lr': 3.934e-05, 'params': 514193, 'time_iter': 0.06083, 'accuracy': 0.97529, 'precision': 0.77896, 'recall': 0.47484, 'f1': 0.59002, 'auc': 0.94519}
2025-08-16 06:43:51,511 - INFO - val: {'epoch': 59, 'time_epoch': 4.0228, 'loss': 0.09482674, 'lr': 0, 'params': 514193, 'time_iter': 0.03118, 'accuracy': 0.97715, 'precision': 0.4, 'recall': 0.32099, 'f1': 0.35616, 'auc': 0.77823}
2025-08-16 06:43:55,496 - INFO - test: {'epoch': 59, 'time_epoch': 3.96957, 'loss': 0.16318998, 'lr': 0, 'params': 514193, 'time_iter': 0.03077, 'accuracy': 0.96377, 'precision': 0.38272, 'recall': 0.23846, 'f1': 0.29384, 'auc': 0.72385}
2025-08-16 06:43:55,499 - INFO - > Epoch 59: took 70.7s (avg 74.1s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:45:00,239 - INFO - train: {'epoch': 60, 'time_epoch': 64.63164, 'eta': 2559.3185, 'eta_hours': 0.71092, 'loss': 0.07685869, 'lr': 3.773e-05, 'params': 514193, 'time_iter': 0.06281, 'accuracy': 0.97635, 'precision': 0.79634, 'recall': 0.49513, 'f1': 0.61061, 'auc': 0.94987}
2025-08-16 06:45:04,315 - INFO - val: {'epoch': 60, 'time_epoch': 4.05569, 'loss': 0.09765115, 'lr': 0, 'params': 514193, 'time_iter': 0.03144, 'accuracy': 0.97715, 'precision': 0.40299, 'recall': 0.33333, 'f1': 0.36486, 'auc': 0.7785}
2025-08-16 06:45:08,340 - INFO - test: {'epoch': 60, 'time_epoch': 4.00713, 'loss': 0.16622732, 'lr': 0, 'params': 514193, 'time_iter': 0.03106, 'accuracy': 0.9628, 'precision': 0.37363, 'recall': 0.26154, 'f1': 0.30769, 'auc': 0.72717}
2025-08-16 06:45:08,342 - INFO - > Epoch 60: took 72.8s (avg 74.1s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:46:12,319 - INFO - train: {'epoch': 61, 'time_epoch': 63.8722, 'eta': 2492.62154, 'eta_hours': 0.69239, 'loss': 0.07848433, 'lr': 3.613e-05, 'params': 514193, 'time_iter': 0.06207, 'accuracy': 0.9766, 'precision': 0.80315, 'recall': 0.49675, 'f1': 0.61384, 'auc': 0.94683}
2025-08-16 06:46:16,188 - INFO - val: {'epoch': 61, 'time_epoch': 3.84856, 'loss': 0.09745341, 'lr': 0, 'params': 514193, 'time_iter': 0.02983, 'accuracy': 0.97398, 'precision': 0.3375, 'recall': 0.33333, 'f1': 0.3354, 'auc': 0.79123}
2025-08-16 06:46:20,118 - INFO - test: {'epoch': 61, 'time_epoch': 3.912, 'loss': 0.16648517, 'lr': 0, 'params': 514193, 'time_iter': 0.03033, 'accuracy': 0.95867, 'precision': 0.29592, 'recall': 0.22308, 'f1': 0.25439, 'auc': 0.73072}
2025-08-16 06:46:20,121 - INFO - > Epoch 61: took 71.8s (avg 74.1s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:47:21,806 - INFO - train: {'epoch': 62, 'time_epoch': 61.58147, 'eta': 2424.6689, 'eta_hours': 0.67352, 'loss': 0.07410923, 'lr': 3.455e-05, 'params': 514193, 'time_iter': 0.05985, 'accuracy': 0.97766, 'precision': 0.81496, 'recall': 0.52192, 'f1': 0.63632, 'auc': 0.95188}
2025-08-16 06:47:25,882 - INFO - val: {'epoch': 62, 'time_epoch': 4.05559, 'loss': 0.09618785, 'lr': 0, 'params': 514193, 'time_iter': 0.03144, 'accuracy': 0.97982, 'precision': 0.48148, 'recall': 0.32099, 'f1': 0.38519, 'auc': 0.76714}
2025-08-16 06:47:29,907 - INFO - test: {'epoch': 62, 'time_epoch': 4.00846, 'loss': 0.16916467, 'lr': 0, 'params': 514193, 'time_iter': 0.03107, 'accuracy': 0.96207, 'precision': 0.33333, 'recall': 0.2, 'f1': 0.25, 'auc': 0.71559}
2025-08-16 06:47:29,909 - INFO - > Epoch 62: took 69.8s (avg 74.0s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:48:32,618 - INFO - train: {'epoch': 63, 'time_epoch': 62.60547, 'eta': 2357.49137, 'eta_hours': 0.65486, 'loss': 0.07539032, 'lr': 3.299e-05, 'params': 514193, 'time_iter': 0.06084, 'accuracy': 0.97699, 'precision': 0.7995, 'recall': 0.51461, 'f1': 0.62617, 'auc': 0.94971}
2025-08-16 06:48:36,663 - INFO - val: {'epoch': 63, 'time_epoch': 4.02414, 'loss': 0.0894955, 'lr': 0, 'params': 514193, 'time_iter': 0.03119, 'accuracy': 0.98128, 'precision': 0.55, 'recall': 0.2716, 'f1': 0.36364, 'auc': 0.77503}
2025-08-16 06:48:40,660 - INFO - test: {'epoch': 63, 'time_epoch': 3.98011, 'loss': 0.15288169, 'lr': 0, 'params': 514193, 'time_iter': 0.03085, 'accuracy': 0.96864, 'precision': 0.50909, 'recall': 0.21538, 'f1': 0.3027, 'auc': 0.73893}
2025-08-16 06:48:40,662 - INFO - > Epoch 63: took 70.8s (avg 74.0s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:49:44,383 - INFO - train: {'epoch': 64, 'time_epoch': 63.61811, 'eta': 2290.99978, 'eta_hours': 0.63639, 'loss': 0.07542929, 'lr': 3.144e-05, 'params': 514193, 'time_iter': 0.06183, 'accuracy': 0.97723, 'precision': 0.80608, 'recall': 0.51623, 'f1': 0.62939, 'auc': 0.95102}
2025-08-16 06:49:48,438 - INFO - val: {'epoch': 64, 'time_epoch': 4.03493, 'loss': 0.09690459, 'lr': 0, 'params': 514193, 'time_iter': 0.03128, 'accuracy': 0.97642, 'precision': 0.37879, 'recall': 0.30864, 'f1': 0.34014, 'auc': 0.7806}
2025-08-16 06:49:52,504 - INFO - test: {'epoch': 64, 'time_epoch': 4.04979, 'loss': 0.16283414, 'lr': 0, 'params': 514193, 'time_iter': 0.03139, 'accuracy': 0.96159, 'precision': 0.35106, 'recall': 0.25385, 'f1': 0.29464, 'auc': 0.73478}
2025-08-16 06:49:52,507 - INFO - > Epoch 64: took 71.8s (avg 73.9s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:50:55,904 - INFO - train: {'epoch': 65, 'time_epoch': 63.29382, 'eta': 2224.4282, 'eta_hours': 0.6179, 'loss': 0.07415997, 'lr': 2.992e-05, 'params': 514193, 'time_iter': 0.06151, 'accuracy': 0.97754, 'precision': 0.81725, 'recall': 0.51542, 'f1': 0.63216, 'auc': 0.95282}
2025-08-16 06:50:59,957 - INFO - val: {'epoch': 65, 'time_epoch': 4.03325, 'loss': 0.09622846, 'lr': 0, 'params': 514193, 'time_iter': 0.03127, 'accuracy': 0.9769, 'precision': 0.3871, 'recall': 0.2963, 'f1': 0.33566, 'auc': 0.77729}
2025-08-16 06:51:03,978 - INFO - test: {'epoch': 65, 'time_epoch': 4.00315, 'loss': 0.16296818, 'lr': 0, 'params': 514193, 'time_iter': 0.03103, 'accuracy': 0.96377, 'precision': 0.36986, 'recall': 0.20769, 'f1': 0.26601, 'auc': 0.72634}
2025-08-16 06:51:03,981 - INFO - > Epoch 65: took 71.5s (avg 73.9s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:52:07,302 - INFO - train: {'epoch': 66, 'time_epoch': 63.21279, 'eta': 2157.91456, 'eta_hours': 0.59942, 'loss': 0.0757039, 'lr': 2.841e-05, 'params': 514193, 'time_iter': 0.06143, 'accuracy': 0.97663, 'precision': 0.79641, 'recall': 0.50487, 'f1': 0.61798, 'auc': 0.95172}
2025-08-16 06:52:11,416 - INFO - val: {'epoch': 66, 'time_epoch': 4.08903, 'loss': 0.09759436, 'lr': 0, 'params': 514193, 'time_iter': 0.0317, 'accuracy': 0.97642, 'precision': 0.37879, 'recall': 0.30864, 'f1': 0.34014, 'auc': 0.7779}
2025-08-16 06:52:15,432 - INFO - test: {'epoch': 66, 'time_epoch': 3.99744, 'loss': 0.16213399, 'lr': 0, 'params': 514193, 'time_iter': 0.03099, 'accuracy': 0.96329, 'precision': 0.37931, 'recall': 0.25385, 'f1': 0.30415, 'auc': 0.727}
2025-08-16 06:52:15,435 - INFO - > Epoch 66: took 71.5s (avg 73.9s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:53:19,775 - INFO - train: {'epoch': 67, 'time_epoch': 64.23869, 'eta': 2091.98079, 'eta_hours': 0.58111, 'loss': 0.07262447, 'lr': 2.693e-05, 'params': 514193, 'time_iter': 0.06243, 'accuracy': 0.97684, 'precision': 0.80051, 'recall': 0.50812, 'f1': 0.62165, 'auc': 0.95899}
2025-08-16 06:53:23,670 - INFO - val: {'epoch': 67, 'time_epoch': 3.87497, 'loss': 0.09594827, 'lr': 0, 'params': 514193, 'time_iter': 0.03004, 'accuracy': 0.97885, 'precision': 0.45714, 'recall': 0.39506, 'f1': 0.42384, 'auc': 0.7912}
2025-08-16 06:53:27,578 - INFO - test: {'epoch': 67, 'time_epoch': 3.89065, 'loss': 0.17174409, 'lr': 0, 'params': 514193, 'time_iter': 0.03016, 'accuracy': 0.96159, 'precision': 0.34444, 'recall': 0.23846, 'f1': 0.28182, 'auc': 0.72076}
2025-08-16 06:53:27,580 - INFO - > Epoch 67: took 72.1s (avg 73.8s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:54:30,843 - INFO - train: {'epoch': 68, 'time_epoch': 63.15867, 'eta': 2025.61092, 'eta_hours': 0.56267, 'loss': 0.07293773, 'lr': 2.548e-05, 'params': 514193, 'time_iter': 0.06138, 'accuracy': 0.97775, 'precision': 0.82134, 'recall': 0.51867, 'f1': 0.63582, 'auc': 0.95581}
2025-08-16 06:54:34,915 - INFO - val: {'epoch': 68, 'time_epoch': 4.04531, 'loss': 0.08959557, 'lr': 0, 'params': 514193, 'time_iter': 0.03136, 'accuracy': 0.98177, 'precision': 0.57143, 'recall': 0.2963, 'f1': 0.39024, 'auc': 0.76985}
2025-08-16 06:54:38,950 - INFO - test: {'epoch': 68, 'time_epoch': 4.01761, 'loss': 0.15868107, 'lr': 0, 'params': 514193, 'time_iter': 0.03114, 'accuracy': 0.96693, 'precision': 0.43182, 'recall': 0.14615, 'f1': 0.21839, 'auc': 0.73302}
2025-08-16 06:54:38,952 - INFO - > Epoch 68: took 71.4s (avg 73.8s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:55:41,775 - INFO - train: {'epoch': 69, 'time_epoch': 62.72005, 'eta': 1959.14481, 'eta_hours': 0.54421, 'loss': 0.0719451, 'lr': 2.405e-05, 'params': 514193, 'time_iter': 0.06095, 'accuracy': 0.97714, 'precision': 0.80075, 'recall': 0.51867, 'f1': 0.62956, 'auc': 0.96103}
2025-08-16 06:55:45,813 - INFO - val: {'epoch': 69, 'time_epoch': 4.0166, 'loss': 0.09700352, 'lr': 0, 'params': 514193, 'time_iter': 0.03114, 'accuracy': 0.97885, 'precision': 0.45, 'recall': 0.33333, 'f1': 0.38298, 'auc': 0.78507}
2025-08-16 06:55:49,704 - INFO - test: {'epoch': 69, 'time_epoch': 3.87498, 'loss': 0.17082483, 'lr': 0, 'params': 514193, 'time_iter': 0.03004, 'accuracy': 0.96572, 'precision': 0.40351, 'recall': 0.17692, 'f1': 0.24599, 'auc': 0.73157}
2025-08-16 06:55:49,706 - INFO - > Epoch 69: took 70.8s (avg 73.7s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:56:52,063 - INFO - train: {'epoch': 70, 'time_epoch': 62.25219, 'eta': 1892.59313, 'eta_hours': 0.52572, 'loss': 0.0719857, 'lr': 2.265e-05, 'params': 514193, 'time_iter': 0.0605, 'accuracy': 0.97739, 'precision': 0.80198, 'recall': 0.52597, 'f1': 0.63529, 'auc': 0.95772}
2025-08-16 06:56:56,071 - INFO - val: {'epoch': 70, 'time_epoch': 3.98807, 'loss': 0.09479648, 'lr': 0, 'params': 514193, 'time_iter': 0.03092, 'accuracy': 0.97812, 'precision': 0.43077, 'recall': 0.34568, 'f1': 0.38356, 'auc': 0.77584}
2025-08-16 06:56:59,884 - INFO - test: {'epoch': 70, 'time_epoch': 3.79739, 'loss': 0.16439768, 'lr': 0, 'params': 514193, 'time_iter': 0.02944, 'accuracy': 0.96402, 'precision': 0.38158, 'recall': 0.22308, 'f1': 0.28155, 'auc': 0.73759}
2025-08-16 06:56:59,886 - INFO - > Epoch 70: took 70.2s (avg 73.7s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:58:02,442 - INFO - train: {'epoch': 71, 'time_epoch': 62.45138, 'eta': 1826.23834, 'eta_hours': 0.50729, 'loss': 0.07140686, 'lr': 2.128e-05, 'params': 514193, 'time_iter': 0.06069, 'accuracy': 0.97842, 'precision': 0.82544, 'recall': 0.53734, 'f1': 0.65093, 'auc': 0.95855}
2025-08-16 06:58:06,529 - INFO - val: {'epoch': 71, 'time_epoch': 4.06643, 'loss': 0.09998562, 'lr': 0, 'params': 514193, 'time_iter': 0.03152, 'accuracy': 0.97569, 'precision': 0.3662, 'recall': 0.32099, 'f1': 0.34211, 'auc': 0.77941}
2025-08-16 06:58:10,524 - INFO - test: {'epoch': 71, 'time_epoch': 3.97919, 'loss': 0.16858791, 'lr': 0, 'params': 514193, 'time_iter': 0.03085, 'accuracy': 0.96207, 'precision': 0.36458, 'recall': 0.26923, 'f1': 0.30973, 'auc': 0.73348}
2025-08-16 06:58:10,526 - INFO - > Epoch 71: took 70.6s (avg 73.7s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 06:59:13,701 - INFO - train: {'epoch': 72, 'time_epoch': 63.06541, 'eta': 1760.21761, 'eta_hours': 0.48895, 'loss': 0.06809758, 'lr': 1.995e-05, 'params': 514193, 'time_iter': 0.06129, 'accuracy': 0.97827, 'precision': 0.82032, 'recall': 0.53734, 'f1': 0.64934, 'auc': 0.96368}
2025-08-16 06:59:17,853 - INFO - val: {'epoch': 72, 'time_epoch': 4.12915, 'loss': 0.10064068, 'lr': 0, 'params': 514193, 'time_iter': 0.03201, 'accuracy': 0.9769, 'precision': 0.4, 'recall': 0.34568, 'f1': 0.37086, 'auc': 0.78114}
2025-08-16 06:59:21,864 - INFO - test: {'epoch': 72, 'time_epoch': 3.99527, 'loss': 0.16769849, 'lr': 0, 'params': 514193, 'time_iter': 0.03097, 'accuracy': 0.96475, 'precision': 0.40741, 'recall': 0.25385, 'f1': 0.3128, 'auc': 0.7332}
2025-08-16 06:59:21,866 - INFO - > Epoch 72: took 71.3s (avg 73.6s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:00:25,376 - INFO - train: {'epoch': 73, 'time_epoch': 63.40322, 'eta': 1694.39544, 'eta_hours': 0.47067, 'loss': 0.07167627, 'lr': 1.864e-05, 'params': 514193, 'time_iter': 0.06162, 'accuracy': 0.97799, 'precision': 0.81592, 'recall': 0.53247, 'f1': 0.6444, 'auc': 0.96093}
2025-08-16 07:00:29,508 - INFO - val: {'epoch': 73, 'time_epoch': 4.1111, 'loss': 0.09960299, 'lr': 0, 'params': 514193, 'time_iter': 0.03187, 'accuracy': 0.97666, 'precision': 0.4026, 'recall': 0.38272, 'f1': 0.39241, 'auc': 0.78521}
2025-08-16 07:00:33,567 - INFO - test: {'epoch': 73, 'time_epoch': 4.0428, 'loss': 0.16674323, 'lr': 0, 'params': 514193, 'time_iter': 0.03134, 'accuracy': 0.96353, 'precision': 0.38889, 'recall': 0.26923, 'f1': 0.31818, 'auc': 0.73895}
2025-08-16 07:00:33,569 - INFO - > Epoch 73: took 71.7s (avg 73.6s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:01:36,723 - INFO - train: {'epoch': 74, 'time_epoch': 63.05133, 'eta': 1628.52047, 'eta_hours': 0.45237, 'loss': 0.06952769, 'lr': 1.737e-05, 'params': 514193, 'time_iter': 0.06127, 'accuracy': 0.9779, 'precision': 0.80458, 'recall': 0.5414, 'f1': 0.64726, 'auc': 0.96201}
2025-08-16 07:01:40,786 - INFO - val: {'epoch': 74, 'time_epoch': 4.04212, 'loss': 0.09731909, 'lr': 0, 'params': 514193, 'time_iter': 0.03133, 'accuracy': 0.97836, 'precision': 0.43548, 'recall': 0.33333, 'f1': 0.37762, 'auc': 0.7834}
2025-08-16 07:01:44,743 - INFO - test: {'epoch': 74, 'time_epoch': 3.94095, 'loss': 0.17229341, 'lr': 0, 'params': 514193, 'time_iter': 0.03055, 'accuracy': 0.96329, 'precision': 0.32787, 'recall': 0.15385, 'f1': 0.20942, 'auc': 0.73046}
2025-08-16 07:01:44,745 - INFO - > Epoch 74: took 71.2s (avg 73.6s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:02:47,590 - INFO - train: {'epoch': 75, 'time_epoch': 62.74129, 'eta': 1562.62191, 'eta_hours': 0.43406, 'loss': 0.06918852, 'lr': 1.614e-05, 'params': 514193, 'time_iter': 0.06097, 'accuracy': 0.97863, 'precision': 0.82139, 'recall': 0.5487, 'f1': 0.65791, 'auc': 0.96444}
2025-08-16 07:02:51,741 - INFO - val: {'epoch': 75, 'time_epoch': 4.13151, 'loss': 0.10174576, 'lr': 0, 'params': 514193, 'time_iter': 0.03203, 'accuracy': 0.97666, 'precision': 0.39437, 'recall': 0.34568, 'f1': 0.36842, 'auc': 0.78278}
2025-08-16 07:02:55,741 - INFO - test: {'epoch': 75, 'time_epoch': 3.98355, 'loss': 0.17543339, 'lr': 0, 'params': 514193, 'time_iter': 0.03088, 'accuracy': 0.96231, 'precision': 0.35294, 'recall': 0.23077, 'f1': 0.27907, 'auc': 0.73187}
2025-08-16 07:02:55,744 - INFO - > Epoch 75: took 71.0s (avg 73.5s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:03:59,332 - INFO - train: {'epoch': 76, 'time_epoch': 63.48513, 'eta': 1497.02754, 'eta_hours': 0.41584, 'loss': 0.06786017, 'lr': 1.494e-05, 'params': 514193, 'time_iter': 0.0617, 'accuracy': 0.97882, 'precision': 0.81582, 'recall': 0.56088, 'f1': 0.66474, 'auc': 0.96554}
2025-08-16 07:04:03,476 - INFO - val: {'epoch': 76, 'time_epoch': 4.12283, 'loss': 0.10862537, 'lr': 0, 'params': 514193, 'time_iter': 0.03196, 'accuracy': 0.97253, 'precision': 0.31818, 'recall': 0.34568, 'f1': 0.33136, 'auc': 0.78202}
2025-08-16 07:04:07,453 - INFO - test: {'epoch': 76, 'time_epoch': 3.9607, 'loss': 0.18004649, 'lr': 0, 'params': 514193, 'time_iter': 0.0307, 'accuracy': 0.96061, 'precision': 0.32979, 'recall': 0.23846, 'f1': 0.27679, 'auc': 0.73127}
2025-08-16 07:04:07,455 - INFO - > Epoch 76: took 71.7s (avg 73.5s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:05:10,879 - INFO - train: {'epoch': 77, 'time_epoch': 63.31869, 'eta': 1431.44031, 'eta_hours': 0.39762, 'loss': 0.06876291, 'lr': 1.378e-05, 'params': 514193, 'time_iter': 0.06153, 'accuracy': 0.97851, 'precision': 0.81065, 'recall': 0.55601, 'f1': 0.65961, 'auc': 0.96095}
2025-08-16 07:05:15,026 - INFO - val: {'epoch': 77, 'time_epoch': 4.11414, 'loss': 0.10465042, 'lr': 0, 'params': 514193, 'time_iter': 0.03189, 'accuracy': 0.97544, 'precision': 0.36486, 'recall': 0.33333, 'f1': 0.34839, 'auc': 0.78188}
2025-08-16 07:05:19,019 - INFO - test: {'epoch': 77, 'time_epoch': 3.97314, 'loss': 0.18007727, 'lr': 0, 'params': 514193, 'time_iter': 0.0308, 'accuracy': 0.9611, 'precision': 0.34375, 'recall': 0.25385, 'f1': 0.29204, 'auc': 0.72363}
2025-08-16 07:05:19,022 - INFO - > Epoch 77: took 71.6s (avg 73.5s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:06:22,871 - INFO - train: {'epoch': 78, 'time_epoch': 63.74458, 'eta': 1366.02372, 'eta_hours': 0.37945, 'loss': 0.06876156, 'lr': 1.266e-05, 'params': 514193, 'time_iter': 0.06195, 'accuracy': 0.97842, 'precision': 0.80562, 'recall': 0.55844, 'f1': 0.65964, 'auc': 0.96415}
2025-08-16 07:06:27,024 - INFO - val: {'epoch': 78, 'time_epoch': 4.12798, 'loss': 0.10373444, 'lr': 0, 'params': 514193, 'time_iter': 0.032, 'accuracy': 0.97423, 'precision': 0.34568, 'recall': 0.34568, 'f1': 0.34568, 'auc': 0.78388}
2025-08-16 07:06:31,086 - INFO - test: {'epoch': 78, 'time_epoch': 4.04618, 'loss': 0.17239116, 'lr': 0, 'params': 514193, 'time_iter': 0.03137, 'accuracy': 0.96013, 'precision': 0.33654, 'recall': 0.26923, 'f1': 0.29915, 'auc': 0.73208}
2025-08-16 07:06:31,089 - INFO - > Epoch 78: took 72.1s (avg 73.5s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:07:37,201 - INFO - train: {'epoch': 79, 'time_epoch': 66.00364, 'eta': 1301.21369, 'eta_hours': 0.36145, 'loss': 0.06874823, 'lr': 1.158e-05, 'params': 514193, 'time_iter': 0.06414, 'accuracy': 0.97888, 'precision': 0.82233, 'recall': 0.55601, 'f1': 0.66344, 'auc': 0.96355}
2025-08-16 07:07:41,582 - INFO - val: {'epoch': 79, 'time_epoch': 4.3566, 'loss': 0.10705627, 'lr': 0, 'params': 514193, 'time_iter': 0.03377, 'accuracy': 0.97544, 'precision': 0.36111, 'recall': 0.32099, 'f1': 0.33987, 'auc': 0.78658}
2025-08-16 07:07:45,962 - INFO - test: {'epoch': 79, 'time_epoch': 4.36037, 'loss': 0.1798177, 'lr': 0, 'params': 514193, 'time_iter': 0.0338, 'accuracy': 0.9611, 'precision': 0.32955, 'recall': 0.22308, 'f1': 0.26606, 'auc': 0.72678}
2025-08-16 07:07:45,964 - INFO - > Epoch 79: took 74.9s (avg 73.5s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:08:52,036 - INFO - train: {'epoch': 80, 'time_epoch': 65.96477, 'eta': 1236.36508, 'eta_hours': 0.34343, 'loss': 0.06723762, 'lr': 1.054e-05, 'params': 514193, 'time_iter': 0.06411, 'accuracy': 0.97961, 'precision': 0.83117, 'recall': 0.57143, 'f1': 0.67725, 'auc': 0.96568}
2025-08-16 07:08:56,148 - INFO - val: {'epoch': 80, 'time_epoch': 4.09006, 'loss': 0.1083374, 'lr': 0, 'params': 514193, 'time_iter': 0.03171, 'accuracy': 0.9752, 'precision': 0.36709, 'recall': 0.35802, 'f1': 0.3625, 'auc': 0.79328}
2025-08-16 07:09:00,133 - INFO - test: {'epoch': 80, 'time_epoch': 3.96963, 'loss': 0.17737163, 'lr': 0, 'params': 514193, 'time_iter': 0.03077, 'accuracy': 0.96061, 'precision': 0.33333, 'recall': 0.24615, 'f1': 0.28319, 'auc': 0.73621}
2025-08-16 07:09:00,136 - INFO - > Epoch 80: took 74.2s (avg 73.5s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:10:03,789 - INFO - train: {'epoch': 81, 'time_epoch': 63.54984, 'eta': 1170.95913, 'eta_hours': 0.32527, 'loss': 0.06920262, 'lr': 9.55e-06, 'params': 514193, 'time_iter': 0.06176, 'accuracy': 0.97909, 'precision': 0.82458, 'recall': 0.56088, 'f1': 0.66763, 'auc': 0.96142}
2025-08-16 07:10:08,079 - INFO - val: {'epoch': 81, 'time_epoch': 4.10628, 'loss': 0.09903639, 'lr': 0, 'params': 514193, 'time_iter': 0.03183, 'accuracy': 0.97739, 'precision': 0.41176, 'recall': 0.34568, 'f1': 0.37584, 'auc': 0.78561}
2025-08-16 07:10:12,092 - INFO - test: {'epoch': 81, 'time_epoch': 3.99604, 'loss': 0.17389581, 'lr': 0, 'params': 514193, 'time_iter': 0.03098, 'accuracy': 0.96183, 'precision': 0.32911, 'recall': 0.2, 'f1': 0.2488, 'auc': 0.72774}
2025-08-16 07:10:12,095 - INFO - > Epoch 81: took 72.0s (avg 73.5s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:11:15,376 - INFO - train: {'epoch': 82, 'time_epoch': 63.17804, 'eta': 1105.52176, 'eta_hours': 0.30709, 'loss': 0.06933807, 'lr': 8.6e-06, 'params': 514193, 'time_iter': 0.0614, 'accuracy': 0.97882, 'precision': 0.82113, 'recall': 0.55519, 'f1': 0.66247, 'auc': 0.96313}
2025-08-16 07:11:19,729 - INFO - val: {'epoch': 82, 'time_epoch': 4.06815, 'loss': 0.10030924, 'lr': 0, 'params': 514193, 'time_iter': 0.03154, 'accuracy': 0.97642, 'precision': 0.38889, 'recall': 0.34568, 'f1': 0.36601, 'auc': 0.78805}
2025-08-16 07:11:23,727 - INFO - test: {'epoch': 82, 'time_epoch': 3.9816, 'loss': 0.17301729, 'lr': 0, 'params': 514193, 'time_iter': 0.03087, 'accuracy': 0.96304, 'precision': 0.36905, 'recall': 0.23846, 'f1': 0.28972, 'auc': 0.73269}
2025-08-16 07:11:23,729 - INFO - > Epoch 82: took 71.6s (avg 73.4s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:12:27,114 - INFO - train: {'epoch': 83, 'time_epoch': 63.28242, 'eta': 1040.15806, 'eta_hours': 0.28893, 'loss': 0.0669944, 'lr': 7.7e-06, 'params': 514193, 'time_iter': 0.0615, 'accuracy': 0.97872, 'precision': 0.81221, 'recall': 0.56169, 'f1': 0.66411, 'auc': 0.96542}
2025-08-16 07:12:31,118 - INFO - val: {'epoch': 83, 'time_epoch': 3.98208, 'loss': 0.10551959, 'lr': 0, 'params': 514193, 'time_iter': 0.03087, 'accuracy': 0.97544, 'precision': 0.37179, 'recall': 0.35802, 'f1': 0.36478, 'auc': 0.78922}
2025-08-16 07:12:35,143 - INFO - test: {'epoch': 83, 'time_epoch': 4.00832, 'loss': 0.17269263, 'lr': 0, 'params': 514193, 'time_iter': 0.03107, 'accuracy': 0.9628, 'precision': 0.36782, 'recall': 0.24615, 'f1': 0.29493, 'auc': 0.73634}
2025-08-16 07:12:35,146 - INFO - > Epoch 83: took 71.4s (avg 73.4s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:13:38,499 - INFO - train: {'epoch': 84, 'time_epoch': 63.24998, 'eta': 974.83761, 'eta_hours': 0.27079, 'loss': 0.06579904, 'lr': 6.84e-06, 'params': 514193, 'time_iter': 0.06147, 'accuracy': 0.97982, 'precision': 0.84383, 'recall': 0.56575, 'f1': 0.67736, 'auc': 0.96671}
2025-08-16 07:13:42,549 - INFO - val: {'epoch': 84, 'time_epoch': 4.02955, 'loss': 0.10653054, 'lr': 0, 'params': 514193, 'time_iter': 0.03124, 'accuracy': 0.97544, 'precision': 0.38095, 'recall': 0.39506, 'f1': 0.38788, 'auc': 0.78226}
2025-08-16 07:13:46,446 - INFO - test: {'epoch': 84, 'time_epoch': 3.88179, 'loss': 0.17667106, 'lr': 0, 'params': 514193, 'time_iter': 0.03009, 'accuracy': 0.95842, 'precision': 0.30476, 'recall': 0.24615, 'f1': 0.27234, 'auc': 0.73619}
2025-08-16 07:13:46,448 - INFO - > Epoch 84: took 71.3s (avg 73.4s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:14:48,231 - INFO - train: {'epoch': 85, 'time_epoch': 61.68008, 'eta': 909.30975, 'eta_hours': 0.25259, 'loss': 0.06714702, 'lr': 6.03e-06, 'params': 514193, 'time_iter': 0.05994, 'accuracy': 0.9783, 'precision': 0.80471, 'recall': 0.55519, 'f1': 0.65706, 'auc': 0.96717}
2025-08-16 07:14:52,324 - INFO - val: {'epoch': 85, 'time_epoch': 4.07073, 'loss': 0.09908594, 'lr': 0, 'params': 514193, 'time_iter': 0.03156, 'accuracy': 0.97788, 'precision': 0.42424, 'recall': 0.34568, 'f1': 0.38095, 'auc': 0.79279}
2025-08-16 07:14:56,314 - INFO - test: {'epoch': 85, 'time_epoch': 3.97413, 'loss': 0.17481369, 'lr': 0, 'params': 514193, 'time_iter': 0.03081, 'accuracy': 0.96183, 'precision': 0.34118, 'recall': 0.22308, 'f1': 0.26977, 'auc': 0.72939}
2025-08-16 07:14:56,316 - INFO - > Epoch 85: took 69.9s (avg 73.4s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:15:58,916 - INFO - train: {'epoch': 86, 'time_epoch': 62.49637, 'eta': 843.99232, 'eta_hours': 0.23444, 'loss': 0.06756715, 'lr': 5.26e-06, 'params': 514193, 'time_iter': 0.06074, 'accuracy': 0.97912, 'precision': 0.81797, 'recall': 0.56899, 'f1': 0.67113, 'auc': 0.96555}
2025-08-16 07:16:02,938 - INFO - val: {'epoch': 86, 'time_epoch': 4.00131, 'loss': 0.10187722, 'lr': 0, 'params': 514193, 'time_iter': 0.03102, 'accuracy': 0.97593, 'precision': 0.37838, 'recall': 0.34568, 'f1': 0.36129, 'auc': 0.78924}
2025-08-16 07:16:06,841 - INFO - test: {'epoch': 86, 'time_epoch': 3.88787, 'loss': 0.17199122, 'lr': 0, 'params': 514193, 'time_iter': 0.03014, 'accuracy': 0.96159, 'precision': 0.35106, 'recall': 0.25385, 'f1': 0.29464, 'auc': 0.73971}
2025-08-16 07:16:06,844 - INFO - > Epoch 86: took 70.5s (avg 73.3s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:17:10,840 - INFO - train: {'epoch': 87, 'time_epoch': 63.88367, 'eta': 778.92817, 'eta_hours': 0.21637, 'loss': 0.06684616, 'lr': 4.55e-06, 'params': 514193, 'time_iter': 0.06208, 'accuracy': 0.97888, 'precision': 0.82467, 'recall': 0.55357, 'f1': 0.66246, 'auc': 0.96646}
2025-08-16 07:17:15,035 - INFO - val: {'epoch': 87, 'time_epoch': 4.17183, 'loss': 0.10498747, 'lr': 0, 'params': 514193, 'time_iter': 0.03234, 'accuracy': 0.97642, 'precision': 0.38571, 'recall': 0.33333, 'f1': 0.35762, 'auc': 0.78862}
2025-08-16 07:17:19,091 - INFO - test: {'epoch': 87, 'time_epoch': 4.04064, 'loss': 0.17570446, 'lr': 0, 'params': 514193, 'time_iter': 0.03132, 'accuracy': 0.96207, 'precision': 0.3587, 'recall': 0.25385, 'f1': 0.2973, 'auc': 0.73239}
2025-08-16 07:17:19,121 - INFO - > Epoch 87: took 72.3s (avg 73.3s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:18:24,956 - INFO - train: {'epoch': 88, 'time_epoch': 65.7297, 'eta': 714.11872, 'eta_hours': 0.19837, 'loss': 0.06468039, 'lr': 3.89e-06, 'params': 514193, 'time_iter': 0.06388, 'accuracy': 0.97921, 'precision': 0.82933, 'recall': 0.56006, 'f1': 0.6686, 'auc': 0.97023}
2025-08-16 07:18:29,095 - INFO - val: {'epoch': 88, 'time_epoch': 4.11705, 'loss': 0.10068248, 'lr': 0, 'params': 514193, 'time_iter': 0.03192, 'accuracy': 0.97593, 'precision': 0.38158, 'recall': 0.35802, 'f1': 0.36943, 'auc': 0.79023}
2025-08-16 07:18:33,113 - INFO - test: {'epoch': 88, 'time_epoch': 4.00195, 'loss': 0.17217701, 'lr': 0, 'params': 514193, 'time_iter': 0.03102, 'accuracy': 0.96061, 'precision': 0.32979, 'recall': 0.23846, 'f1': 0.27679, 'auc': 0.73462}
2025-08-16 07:18:33,115 - INFO - > Epoch 88: took 74.0s (avg 73.3s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:19:38,013 - INFO - train: {'epoch': 89, 'time_epoch': 64.79208, 'eta': 649.18463, 'eta_hours': 0.18033, 'loss': 0.06629856, 'lr': 3.27e-06, 'params': 514193, 'time_iter': 0.06297, 'accuracy': 0.97875, 'precision': 0.80388, 'recall': 0.57224, 'f1': 0.66856, 'auc': 0.96771}
2025-08-16 07:19:42,067 - INFO - val: {'epoch': 89, 'time_epoch': 4.03244, 'loss': 0.09851087, 'lr': 0, 'params': 514193, 'time_iter': 0.03126, 'accuracy': 0.97763, 'precision': 0.42029, 'recall': 0.35802, 'f1': 0.38667, 'auc': 0.78681}
2025-08-16 07:19:45,986 - INFO - test: {'epoch': 89, 'time_epoch': 3.90396, 'loss': 0.1735065, 'lr': 0, 'params': 514193, 'time_iter': 0.03026, 'accuracy': 0.96183, 'precision': 0.34483, 'recall': 0.23077, 'f1': 0.2765, 'auc': 0.73154}
2025-08-16 07:19:45,989 - INFO - > Epoch 89: took 72.9s (avg 73.3s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:20:50,120 - INFO - train: {'epoch': 90, 'time_epoch': 64.0198, 'eta': 584.17729, 'eta_hours': 0.16227, 'loss': 0.06588005, 'lr': 2.71e-06, 'params': 514193, 'time_iter': 0.06222, 'accuracy': 0.97942, 'precision': 0.8238, 'recall': 0.57305, 'f1': 0.67592, 'auc': 0.96934}
2025-08-16 07:20:54,060 - INFO - val: {'epoch': 90, 'time_epoch': 3.92043, 'loss': 0.10182458, 'lr': 0, 'params': 514193, 'time_iter': 0.03039, 'accuracy': 0.97544, 'precision': 0.36486, 'recall': 0.33333, 'f1': 0.34839, 'auc': 0.78604}
2025-08-16 07:20:57,847 - INFO - test: {'epoch': 90, 'time_epoch': 3.77134, 'loss': 0.17308365, 'lr': 0, 'params': 514193, 'time_iter': 0.02924, 'accuracy': 0.96134, 'precision': 0.35052, 'recall': 0.26154, 'f1': 0.29956, 'auc': 0.73972}
2025-08-16 07:20:57,849 - INFO - > Epoch 90: took 71.9s (avg 73.3s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:22:01,415 - INFO - train: {'epoch': 91, 'time_epoch': 63.46055, 'eta': 519.14279, 'eta_hours': 0.14421, 'loss': 0.06385267, 'lr': 2.2e-06, 'params': 514193, 'time_iter': 0.06167, 'accuracy': 0.98012, 'precision': 0.82841, 'recall': 0.59172, 'f1': 0.69034, 'auc': 0.96976}
2025-08-16 07:22:05,418 - INFO - val: {'epoch': 91, 'time_epoch': 3.98266, 'loss': 0.103343, 'lr': 0, 'params': 514193, 'time_iter': 0.03087, 'accuracy': 0.97617, 'precision': 0.38667, 'recall': 0.35802, 'f1': 0.37179, 'auc': 0.78591}
2025-08-16 07:22:09,419 - INFO - test: {'epoch': 91, 'time_epoch': 3.9855, 'loss': 0.17658514, 'lr': 0, 'params': 514193, 'time_iter': 0.0309, 'accuracy': 0.96159, 'precision': 0.34444, 'recall': 0.23846, 'f1': 0.28182, 'auc': 0.73813}
2025-08-16 07:22:09,422 - INFO - > Epoch 91: took 71.6s (avg 73.3s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:23:13,496 - INFO - train: {'epoch': 92, 'time_epoch': 63.96815, 'eta': 454.18034, 'eta_hours': 0.12616, 'loss': 0.06602591, 'lr': 1.74e-06, 'params': 514193, 'time_iter': 0.06217, 'accuracy': 0.97912, 'precision': 0.82249, 'recall': 0.56412, 'f1': 0.66923, 'auc': 0.96969}
2025-08-16 07:23:17,618 - INFO - val: {'epoch': 92, 'time_epoch': 4.10057, 'loss': 0.10816244, 'lr': 0, 'params': 514193, 'time_iter': 0.03179, 'accuracy': 0.97374, 'precision': 0.34483, 'recall': 0.37037, 'f1': 0.35714, 'auc': 0.79288}
2025-08-16 07:23:21,646 - INFO - test: {'epoch': 92, 'time_epoch': 4.01189, 'loss': 0.17630652, 'lr': 0, 'params': 514193, 'time_iter': 0.0311, 'accuracy': 0.9611, 'precision': 0.34694, 'recall': 0.26154, 'f1': 0.29825, 'auc': 0.73825}
2025-08-16 07:23:21,649 - INFO - > Epoch 92: took 72.2s (avg 73.3s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:24:27,853 - INFO - train: {'epoch': 93, 'time_epoch': 66.1001, 'eta': 389.37513, 'eta_hours': 0.10816, 'loss': 0.06400856, 'lr': 1.33e-06, 'params': 514193, 'time_iter': 0.06424, 'accuracy': 0.97967, 'precision': 0.83472, 'recall': 0.56981, 'f1': 0.67728, 'auc': 0.9697}
2025-08-16 07:24:31,707 - INFO - val: {'epoch': 93, 'time_epoch': 3.83419, 'loss': 0.10677614, 'lr': 0, 'params': 514193, 'time_iter': 0.02972, 'accuracy': 0.97277, 'precision': 0.32584, 'recall': 0.35802, 'f1': 0.34118, 'auc': 0.78865}
2025-08-16 07:24:35,462 - INFO - test: {'epoch': 93, 'time_epoch': 3.73995, 'loss': 0.17749958, 'lr': 0, 'params': 514193, 'time_iter': 0.02899, 'accuracy': 0.95915, 'precision': 0.31731, 'recall': 0.25385, 'f1': 0.28205, 'auc': 0.73779}
2025-08-16 07:24:35,464 - INFO - > Epoch 93: took 73.8s (avg 73.3s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:25:37,578 - INFO - train: {'epoch': 94, 'time_epoch': 62.00907, 'eta': 324.32734, 'eta_hours': 0.09009, 'loss': 0.06627034, 'lr': 9.8e-07, 'params': 514193, 'time_iter': 0.06026, 'accuracy': 0.979, 'precision': 0.81272, 'recall': 0.57062, 'f1': 0.67048, 'auc': 0.96876}
2025-08-16 07:25:41,561 - INFO - val: {'epoch': 94, 'time_epoch': 3.96203, 'loss': 0.10909305, 'lr': 0, 'params': 514193, 'time_iter': 0.03071, 'accuracy': 0.97496, 'precision': 0.36585, 'recall': 0.37037, 'f1': 0.3681, 'auc': 0.78649}
2025-08-16 07:25:45,421 - INFO - test: {'epoch': 94, 'time_epoch': 3.84538, 'loss': 0.17959498, 'lr': 0, 'params': 514193, 'time_iter': 0.02981, 'accuracy': 0.96061, 'precision': 0.32979, 'recall': 0.23846, 'f1': 0.27679, 'auc': 0.72943}
2025-08-16 07:25:45,424 - INFO - > Epoch 94: took 70.0s (avg 73.2s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:26:47,584 - INFO - train: {'epoch': 95, 'time_epoch': 62.05384, 'eta': 259.34472, 'eta_hours': 0.07204, 'loss': 0.06507082, 'lr': 6.8e-07, 'params': 514193, 'time_iter': 0.0603, 'accuracy': 0.98003, 'precision': 0.83784, 'recall': 0.57873, 'f1': 0.68459, 'auc': 0.96671}
2025-08-16 07:26:51,565 - INFO - val: {'epoch': 95, 'time_epoch': 3.9597, 'loss': 0.10780324, 'lr': 0, 'params': 514193, 'time_iter': 0.0307, 'accuracy': 0.97569, 'precision': 0.38554, 'recall': 0.39506, 'f1': 0.39024, 'auc': 0.79075}
2025-08-16 07:26:55,588 - INFO - test: {'epoch': 95, 'time_epoch': 4.00664, 'loss': 0.18235477, 'lr': 0, 'params': 514193, 'time_iter': 0.03106, 'accuracy': 0.96304, 'precision': 0.37209, 'recall': 0.24615, 'f1': 0.2963, 'auc': 0.73447}
2025-08-16 07:26:55,591 - INFO - > Epoch 95: took 70.2s (avg 73.2s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:28:01,222 - INFO - train: {'epoch': 96, 'time_epoch': 65.52558, 'eta': 194.52986, 'eta_hours': 0.05404, 'loss': 0.06479612, 'lr': 4.4e-07, 'params': 514193, 'time_iter': 0.06368, 'accuracy': 0.97933, 'precision': 0.81507, 'recall': 0.57955, 'f1': 0.67742, 'auc': 0.96794}
2025-08-16 07:28:05,471 - INFO - val: {'epoch': 96, 'time_epoch': 4.22918, 'loss': 0.10036122, 'lr': 0, 'params': 514193, 'time_iter': 0.03278, 'accuracy': 0.97642, 'precision': 0.39189, 'recall': 0.35802, 'f1': 0.37419, 'auc': 0.78833}
2025-08-16 07:28:09,638 - INFO - test: {'epoch': 96, 'time_epoch': 4.15044, 'loss': 0.17478546, 'lr': 0, 'params': 514193, 'time_iter': 0.03217, 'accuracy': 0.96329, 'precision': 0.37647, 'recall': 0.24615, 'f1': 0.29767, 'auc': 0.7329}
2025-08-16 07:28:09,646 - INFO - > Epoch 96: took 74.1s (avg 73.2s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:29:12,553 - INFO - train: {'epoch': 97, 'time_epoch': 62.80008, 'eta': 129.64488, 'eta_hours': 0.03601, 'loss': 0.0636352, 'lr': 2.5e-07, 'params': 514193, 'time_iter': 0.06103, 'accuracy': 0.98064, 'precision': 0.83922, 'recall': 0.5974, 'f1': 0.69796, 'auc': 0.96809}
2025-08-16 07:29:16,541 - INFO - val: {'epoch': 97, 'time_epoch': 3.9684, 'loss': 0.10462295, 'lr': 0, 'params': 514193, 'time_iter': 0.03076, 'accuracy': 0.97398, 'precision': 0.34146, 'recall': 0.34568, 'f1': 0.34356, 'auc': 0.78236}
2025-08-16 07:29:20,370 - INFO - test: {'epoch': 97, 'time_epoch': 3.81358, 'loss': 0.1794191, 'lr': 0, 'params': 514193, 'time_iter': 0.02956, 'accuracy': 0.95575, 'precision': 0.26364, 'recall': 0.22308, 'f1': 0.24167, 'auc': 0.72772}
2025-08-16 07:29:20,373 - INFO - > Epoch 97: took 70.7s (avg 73.2s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:30:26,509 - INFO - train: {'epoch': 98, 'time_epoch': 66.03084, 'eta': 64.83464, 'eta_hours': 0.01801, 'loss': 0.06431848, 'lr': 1.1e-07, 'params': 514193, 'time_iter': 0.06417, 'accuracy': 0.97921, 'precision': 0.82009, 'recall': 0.56981, 'f1': 0.67241, 'auc': 0.96973}
2025-08-16 07:30:30,630 - INFO - val: {'epoch': 98, 'time_epoch': 4.10045, 'loss': 0.10513456, 'lr': 0, 'params': 514193, 'time_iter': 0.03179, 'accuracy': 0.97496, 'precision': 0.3625, 'recall': 0.35802, 'f1': 0.36025, 'auc': 0.7875}
2025-08-16 07:30:34,594 - INFO - test: {'epoch': 98, 'time_epoch': 3.94818, 'loss': 0.17863723, 'lr': 0, 'params': 514193, 'time_iter': 0.03061, 'accuracy': 0.96183, 'precision': 0.35165, 'recall': 0.24615, 'f1': 0.28959, 'auc': 0.7297}
2025-08-16 07:30:34,597 - INFO - > Epoch 98: took 74.2s (avg 73.2s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:31:38,726 - INFO - train: {'epoch': 99, 'time_epoch': 64.01979, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.06577075, 'lr': 3e-08, 'params': 514193, 'time_iter': 0.06222, 'accuracy': 0.97973, 'precision': 0.82811, 'recall': 0.57873, 'f1': 0.68132, 'auc': 0.96762}
2025-08-16 07:31:42,668 - INFO - val: {'epoch': 99, 'time_epoch': 3.92143, 'loss': 0.10222081, 'lr': 0, 'params': 514193, 'time_iter': 0.0304, 'accuracy': 0.9769, 'precision': 0.41026, 'recall': 0.39506, 'f1': 0.40252, 'auc': 0.7955}
2025-08-16 07:31:46,467 - INFO - test: {'epoch': 99, 'time_epoch': 3.78426, 'loss': 0.17537527, 'lr': 0, 'params': 514193, 'time_iter': 0.02934, 'accuracy': 0.96329, 'precision': 0.37931, 'recall': 0.25385, 'f1': 0.30415, 'auc': 0.73748}
2025-08-16 07:31:46,807 - INFO - > Epoch 99: took 71.9s (avg 73.2s) | Best so far: epoch 54	train_loss: 0.0826 train_auc: 0.9383	val_loss: 0.0858 val_auc: 0.8016	test_loss: 0.1490 test_auc: 0.7298
2025-08-16 07:31:46,808 - INFO - Avg time per epoch: 73.19s
2025-08-16 07:31:46,808 - INFO - Total train loop time: 2.03h
2025-08-16 07:31:46,908 - INFO - ============================================================
2025-08-16 07:31:46,908 - INFO - Starting PK-Explainer Analysis (Enhanced Version)
2025-08-16 07:31:46,908 - INFO - ============================================================
2025-08-16 07:31:46,908 - INFO - Dataset: ogbg-molhiv
2025-08-16 07:31:46,908 - INFO - Model type: VanillaModel
2025-08-16 07:31:46,908 - INFO - GNN types available: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 07:31:46,950 - INFO - Saved model state to results/molhiv/molhiv-Vanilla-45/model_for_ablation.pt
2025-08-16 07:31:46,950 - INFO - 
Performing ablation study...
2025-08-16 07:31:47,244 - INFO - Getting baseline performance...
2025-08-16 07:31:47,274 - WARNING - Could not extract GNN mapping from optimal weights, attempting to infer from layers...
2025-08-16 07:31:47,274 - INFO - Final GNN mapping: {}
2025-08-16 07:31:51,135 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.84696, 'loss': 0.17537527, 'lr': 0, 'params': 514193, 'time_iter': 0.02982, 'accuracy': 0.96329, 'precision': 0.37931, 'recall': 0.25385, 'f1': 0.30415, 'auc': 0.73748}
2025-08-16 07:31:51,172 - INFO - ...computing epoch stats took: 0.05s
2025-08-16 07:31:51,172 - INFO - Baseline auc: 0.7375
2025-08-16 07:31:55,089 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.87265, 'loss': 0.18573227, 'lr': 0, 'params': 514193, 'time_iter': 0.03002, 'accuracy': 0.95818, 'precision': 0.31579, 'recall': 0.27692, 'f1': 0.29508, 'auc': 0.72749}
2025-08-16 07:31:55,091 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:31:55,091 - INFO - Layer 0 (Layer_0), Head 0: drop=0.0135
2025-08-16 07:31:59,065 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.91221, 'loss': 0.17348806, 'lr': 0, 'params': 514193, 'time_iter': 0.03033, 'accuracy': 0.96353, 'precision': 0.375, 'recall': 0.23077, 'f1': 0.28571, 'auc': 0.73466}
2025-08-16 07:31:59,067 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:31:59,067 - INFO - Layer 0 (Layer_0), Head 1: drop=0.0038
2025-08-16 07:32:02,938 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.82673, 'loss': 0.18011777, 'lr': 0, 'params': 514193, 'time_iter': 0.02966, 'accuracy': 0.96159, 'precision': 0.35106, 'recall': 0.25385, 'f1': 0.29464, 'auc': 0.73679}
2025-08-16 07:32:02,939 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:02,940 - INFO - Layer 0 (Layer_0), Head 2: drop=0.0009
2025-08-16 07:32:06,920 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.93396, 'loss': 0.177797, 'lr': 0, 'params': 514193, 'time_iter': 0.0305, 'accuracy': 0.96159, 'precision': 0.34091, 'recall': 0.23077, 'f1': 0.27523, 'auc': 0.73753}
2025-08-16 07:32:06,921 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:06,922 - INFO - Layer 0 (Layer_0), Head 3: drop=-0.0001
2025-08-16 07:32:10,951 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.98495, 'loss': 0.17510969, 'lr': 0, 'params': 514193, 'time_iter': 0.03089, 'accuracy': 0.95964, 'precision': 0.32692, 'recall': 0.26154, 'f1': 0.2906, 'auc': 0.74443}
2025-08-16 07:32:10,953 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:10,953 - INFO - Layer 1 (Layer_1), Head 0: drop=-0.0094
2025-08-16 07:32:14,975 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.97585, 'loss': 0.18160065, 'lr': 0, 'params': 514193, 'time_iter': 0.03082, 'accuracy': 0.95599, 'precision': 0.28571, 'recall': 0.26154, 'f1': 0.27309, 'auc': 0.73295}
2025-08-16 07:32:14,977 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:14,977 - INFO - Layer 1 (Layer_1), Head 1: drop=0.0061
2025-08-16 07:32:19,038 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.0152, 'loss': 0.17516921, 'lr': 0, 'params': 514193, 'time_iter': 0.03113, 'accuracy': 0.96061, 'precision': 0.32222, 'recall': 0.22308, 'f1': 0.26364, 'auc': 0.73616}
2025-08-16 07:32:19,039 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:19,040 - INFO - Layer 1 (Layer_1), Head 2: drop=0.0018
2025-08-16 07:32:23,509 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.02079, 'loss': 0.17172881, 'lr': 0, 'params': 514193, 'time_iter': 0.03117, 'accuracy': 0.96086, 'precision': 0.34343, 'recall': 0.26154, 'f1': 0.29694, 'auc': 0.73443}
2025-08-16 07:32:23,513 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:32:23,513 - INFO - Layer 1 (Layer_1), Head 3: drop=0.0041
2025-08-16 07:32:27,485 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.92433, 'loss': 0.17063536, 'lr': 0, 'params': 514193, 'time_iter': 0.03042, 'accuracy': 0.9594, 'precision': 0.30526, 'recall': 0.22308, 'f1': 0.25778, 'auc': 0.75458}
2025-08-16 07:32:27,486 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:27,487 - INFO - Layer 2 (Layer_2), Head 0: drop=-0.0232
2025-08-16 07:32:31,484 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.94958, 'loss': 0.17406007, 'lr': 0, 'params': 514193, 'time_iter': 0.03062, 'accuracy': 0.95721, 'precision': 0.30172, 'recall': 0.26923, 'f1': 0.28455, 'auc': 0.73741}
2025-08-16 07:32:31,485 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:31,485 - INFO - Layer 2 (Layer_2), Head 1: drop=0.0001
2025-08-16 07:32:35,447 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.9136, 'loss': 0.17237668, 'lr': 0, 'params': 514193, 'time_iter': 0.03034, 'accuracy': 0.96304, 'precision': 0.36585, 'recall': 0.23077, 'f1': 0.28302, 'auc': 0.7339}
2025-08-16 07:32:35,449 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:35,449 - INFO - Layer 2 (Layer_2), Head 2: drop=0.0049
2025-08-16 07:32:39,528 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.03146, 'loss': 0.18041212, 'lr': 0, 'params': 514193, 'time_iter': 0.03125, 'accuracy': 0.95526, 'precision': 0.24528, 'recall': 0.2, 'f1': 0.22034, 'auc': 0.73399}
2025-08-16 07:32:39,530 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:39,530 - INFO - Layer 2 (Layer_2), Head 3: drop=0.0047
2025-08-16 07:32:43,585 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.00993, 'loss': 0.17690865, 'lr': 0, 'params': 514193, 'time_iter': 0.03108, 'accuracy': 0.96037, 'precision': 0.33663, 'recall': 0.26154, 'f1': 0.29437, 'auc': 0.73351}
2025-08-16 07:32:43,587 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:43,587 - INFO - Layer 3 (Layer_3), Head 0: drop=0.0054
2025-08-16 07:32:47,631 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.99795, 'loss': 0.18495568, 'lr': 0, 'params': 514193, 'time_iter': 0.03099, 'accuracy': 0.95624, 'precision': 0.32143, 'recall': 0.34615, 'f1': 0.33333, 'auc': 0.72762}
2025-08-16 07:32:47,633 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:47,633 - INFO - Layer 3 (Layer_3), Head 1: drop=0.0134
2025-08-16 07:32:51,700 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.02013, 'loss': 0.1804564, 'lr': 0, 'params': 514193, 'time_iter': 0.03116, 'accuracy': 0.95842, 'precision': 0.31532, 'recall': 0.26923, 'f1': 0.29046, 'auc': 0.7339}
2025-08-16 07:32:51,702 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:51,702 - INFO - Layer 3 (Layer_3), Head 2: drop=0.0049
2025-08-16 07:32:55,732 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.9851, 'loss': 0.17725098, 'lr': 0, 'params': 514193, 'time_iter': 0.03089, 'accuracy': 0.95988, 'precision': 0.32323, 'recall': 0.24615, 'f1': 0.27948, 'auc': 0.74149}
2025-08-16 07:32:55,734 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:55,734 - INFO - Layer 3 (Layer_3), Head 3: drop=-0.0054
2025-08-16 07:32:59,696 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.91556, 'loss': 0.17448904, 'lr': 0, 'params': 514193, 'time_iter': 0.03035, 'accuracy': 0.96159, 'precision': 0.33721, 'recall': 0.22308, 'f1': 0.26852, 'auc': 0.7372}
2025-08-16 07:32:59,698 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:59,698 - INFO - Layer 4 (Layer_4), Head 0: drop=0.0004
2025-08-16 07:33:03,760 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.01468, 'loss': 0.17386381, 'lr': 0, 'params': 514193, 'time_iter': 0.03112, 'accuracy': 0.9628, 'precision': 0.36145, 'recall': 0.23077, 'f1': 0.28169, 'auc': 0.73358}
2025-08-16 07:33:03,762 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:03,762 - INFO - Layer 4 (Layer_4), Head 1: drop=0.0053
2025-08-16 07:33:07,850 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.04219, 'loss': 0.17790586, 'lr': 0, 'params': 514193, 'time_iter': 0.03133, 'accuracy': 0.96061, 'precision': 0.33333, 'recall': 0.24615, 'f1': 0.28319, 'auc': 0.73734}
2025-08-16 07:33:07,852 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:07,853 - INFO - Layer 4 (Layer_4), Head 2: drop=0.0002
2025-08-16 07:33:11,863 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.96495, 'loss': 0.18226626, 'lr': 0, 'params': 514193, 'time_iter': 0.03074, 'accuracy': 0.95964, 'precision': 0.33019, 'recall': 0.26923, 'f1': 0.29661, 'auc': 0.73412}
2025-08-16 07:33:11,865 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:11,865 - INFO - Layer 4 (Layer_4), Head 3: drop=0.0046
2025-08-16 07:33:15,822 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.90898, 'loss': 0.17315118, 'lr': 0, 'params': 514193, 'time_iter': 0.0303, 'accuracy': 0.96353, 'precision': 0.38372, 'recall': 0.25385, 'f1': 0.30556, 'auc': 0.74001}
2025-08-16 07:33:15,824 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:15,824 - INFO - Layer 5 (Layer_5), Head 0: drop=-0.0034
2025-08-16 07:33:19,865 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.99298, 'loss': 0.19829274, 'lr': 0, 'params': 514193, 'time_iter': 0.03095, 'accuracy': 0.94311, 'precision': 0.20787, 'recall': 0.28462, 'f1': 0.24026, 'auc': 0.73465}
2025-08-16 07:33:19,867 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:19,867 - INFO - Layer 5 (Layer_5), Head 1: drop=0.0038
2025-08-16 07:33:23,836 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.92162, 'loss': 0.18134, 'lr': 0, 'params': 514193, 'time_iter': 0.0304, 'accuracy': 0.9577, 'precision': 0.2963, 'recall': 0.24615, 'f1': 0.26891, 'auc': 0.73701}
2025-08-16 07:33:23,838 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:23,838 - INFO - Layer 5 (Layer_5), Head 2: drop=0.0006
2025-08-16 07:33:27,889 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.00428, 'loss': 0.17357045, 'lr': 0, 'params': 514193, 'time_iter': 0.03104, 'accuracy': 0.96377, 'precision': 0.38824, 'recall': 0.25385, 'f1': 0.30698, 'auc': 0.74033}
2025-08-16 07:33:27,891 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:27,891 - INFO - Layer 5 (Layer_5), Head 3: drop=-0.0039
2025-08-16 07:33:31,819 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.88276, 'loss': 0.17586274, 'lr': 0, 'params': 514193, 'time_iter': 0.0301, 'accuracy': 0.95867, 'precision': 0.29592, 'recall': 0.22308, 'f1': 0.25439, 'auc': 0.74493}
2025-08-16 07:33:31,821 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:31,821 - INFO - Layer 6 (Layer_6), Head 0: drop=-0.0101
2025-08-16 07:33:35,823 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.95534, 'loss': 0.17240158, 'lr': 0, 'params': 514193, 'time_iter': 0.03066, 'accuracy': 0.96183, 'precision': 0.34831, 'recall': 0.23846, 'f1': 0.28311, 'auc': 0.72991}
2025-08-16 07:33:35,825 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:35,825 - INFO - Layer 6 (Layer_6), Head 1: drop=0.0103
2025-08-16 07:33:39,820 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.94879, 'loss': 0.17058195, 'lr': 0, 'params': 514193, 'time_iter': 0.03061, 'accuracy': 0.96256, 'precision': 0.36667, 'recall': 0.25385, 'f1': 0.3, 'auc': 0.73674}
2025-08-16 07:33:39,822 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:39,822 - INFO - Layer 6 (Layer_6), Head 2: drop=0.0010
2025-08-16 07:33:43,735 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.86861, 'loss': 0.16552606, 'lr': 0, 'params': 514193, 'time_iter': 0.02999, 'accuracy': 0.96134, 'precision': 0.34066, 'recall': 0.23846, 'f1': 0.28054, 'auc': 0.7384}
2025-08-16 07:33:43,737 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:43,737 - INFO - Layer 6 (Layer_6), Head 3: drop=-0.0012
2025-08-16 07:33:47,631 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.84736, 'loss': 0.16822198, 'lr': 0, 'params': 514193, 'time_iter': 0.02982, 'accuracy': 0.96499, 'precision': 0.40278, 'recall': 0.22308, 'f1': 0.28713, 'auc': 0.74656}
2025-08-16 07:33:47,633 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:47,633 - INFO - Layer 7 (Layer_7), Head 0: drop=-0.0123
2025-08-16 07:33:51,770 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.09104, 'loss': 0.17085025, 'lr': 0, 'params': 514193, 'time_iter': 0.03171, 'accuracy': 0.96159, 'precision': 0.33721, 'recall': 0.22308, 'f1': 0.26852, 'auc': 0.74365}
2025-08-16 07:33:51,773 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:51,773 - INFO - Layer 7 (Layer_7), Head 1: drop=-0.0084
2025-08-16 07:33:55,838 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.0182, 'loss': 0.16901787, 'lr': 0, 'params': 514193, 'time_iter': 0.03115, 'accuracy': 0.96353, 'precision': 0.38095, 'recall': 0.24615, 'f1': 0.29907, 'auc': 0.73479}
2025-08-16 07:33:55,840 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:55,840 - INFO - Layer 7 (Layer_7), Head 2: drop=0.0036
2025-08-16 07:33:59,887 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.99883, 'loss': 0.17007049, 'lr': 0, 'params': 514193, 'time_iter': 0.031, 'accuracy': 0.96353, 'precision': 0.37805, 'recall': 0.23846, 'f1': 0.29245, 'auc': 0.74095}
2025-08-16 07:33:59,889 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:59,889 - INFO - Layer 7 (Layer_7), Head 3: drop=-0.0047
2025-08-16 07:34:03,922 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.9841, 'loss': 0.17265802, 'lr': 0, 'params': 514193, 'time_iter': 0.03088, 'accuracy': 0.96183, 'precision': 0.35165, 'recall': 0.24615, 'f1': 0.28959, 'auc': 0.74026}
2025-08-16 07:34:03,923 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:03,924 - INFO - Layer 8 (Layer_8), Head 0: drop=-0.0038
2025-08-16 07:34:08,006 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.03432, 'loss': 0.17288046, 'lr': 0, 'params': 514193, 'time_iter': 0.03127, 'accuracy': 0.96377, 'precision': 0.37662, 'recall': 0.22308, 'f1': 0.28019, 'auc': 0.73805}
2025-08-16 07:34:08,008 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:08,008 - INFO - Layer 8 (Layer_8), Head 1: drop=-0.0008
2025-08-16 07:34:12,071 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.01607, 'loss': 0.16773269, 'lr': 0, 'params': 514193, 'time_iter': 0.03113, 'accuracy': 0.96426, 'precision': 0.38961, 'recall': 0.23077, 'f1': 0.28986, 'auc': 0.73721}
2025-08-16 07:34:12,073 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:12,073 - INFO - Layer 8 (Layer_8), Head 2: drop=0.0004
2025-08-16 07:34:16,178 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.05897, 'loss': 0.17257038, 'lr': 0, 'params': 514193, 'time_iter': 0.03146, 'accuracy': 0.96329, 'precision': 0.38202, 'recall': 0.26154, 'f1': 0.3105, 'auc': 0.7406}
2025-08-16 07:34:16,180 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:16,180 - INFO - Layer 8 (Layer_8), Head 3: drop=-0.0042
2025-08-16 07:34:20,236 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.00922, 'loss': 0.16615033, 'lr': 0, 'params': 514193, 'time_iter': 0.03108, 'accuracy': 0.96231, 'precision': 0.35955, 'recall': 0.24615, 'f1': 0.29224, 'auc': 0.74131}
2025-08-16 07:34:20,238 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:20,238 - INFO - Layer 9 (Layer_9), Head 0: drop=-0.0052
2025-08-16 07:34:24,320 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.03368, 'loss': 0.17321007, 'lr': 0, 'params': 514193, 'time_iter': 0.03127, 'accuracy': 0.96207, 'precision': 0.35227, 'recall': 0.23846, 'f1': 0.2844, 'auc': 0.73477}
2025-08-16 07:34:24,322 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:24,322 - INFO - Layer 9 (Layer_9), Head 1: drop=0.0037
2025-08-16 07:34:28,291 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.92381, 'loss': 0.17077091, 'lr': 0, 'params': 514193, 'time_iter': 0.03042, 'accuracy': 0.96231, 'precision': 0.36264, 'recall': 0.25385, 'f1': 0.29864, 'auc': 0.73432}
2025-08-16 07:34:28,293 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:28,293 - INFO - Layer 9 (Layer_9), Head 2: drop=0.0043
2025-08-16 07:34:32,366 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.02528, 'loss': 0.1708176, 'lr': 0, 'params': 514193, 'time_iter': 0.0312, 'accuracy': 0.96426, 'precision': 0.39241, 'recall': 0.23846, 'f1': 0.29665, 'auc': 0.73534}
2025-08-16 07:34:32,368 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:32,368 - INFO - Layer 9 (Layer_9), Head 3: drop=0.0029
2025-08-16 07:34:36,472 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.05686, 'loss': 0.17115796, 'lr': 0, 'params': 514193, 'time_iter': 0.03145, 'accuracy': 0.96304, 'precision': 0.37209, 'recall': 0.24615, 'f1': 0.2963, 'auc': 0.73725}
2025-08-16 07:34:36,474 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:36,474 - INFO - Layer 10 (Layer_10), Head 0: drop=0.0003
2025-08-16 07:34:40,646 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.12421, 'loss': 0.17223295, 'lr': 0, 'params': 514193, 'time_iter': 0.03197, 'accuracy': 0.96086, 'precision': 0.34021, 'recall': 0.25385, 'f1': 0.29075, 'auc': 0.73922}
2025-08-16 07:34:40,648 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:40,648 - INFO - Layer 10 (Layer_10), Head 1: drop=-0.0024
2025-08-16 07:34:44,817 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.12227, 'loss': 0.17216636, 'lr': 0, 'params': 514193, 'time_iter': 0.03196, 'accuracy': 0.96426, 'precision': 0.38667, 'recall': 0.22308, 'f1': 0.28293, 'auc': 0.73785}
2025-08-16 07:34:44,819 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:44,819 - INFO - Layer 10 (Layer_10), Head 2: drop=-0.0005
2025-08-16 07:34:49,161 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29431, 'loss': 0.16790967, 'lr': 0, 'params': 514193, 'time_iter': 0.03329, 'accuracy': 0.96231, 'precision': 0.35955, 'recall': 0.24615, 'f1': 0.29224, 'auc': 0.73754}
2025-08-16 07:34:49,163 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:49,163 - INFO - Layer 10 (Layer_10), Head 3: drop=-0.0001
2025-08-16 07:34:53,399 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.18742, 'loss': 0.17305418, 'lr': 0, 'params': 514193, 'time_iter': 0.03246, 'accuracy': 0.96231, 'precision': 0.35955, 'recall': 0.24615, 'f1': 0.29224, 'auc': 0.7351}
2025-08-16 07:34:53,400 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:53,400 - INFO - Layer 11 (Layer_11), Head 0: drop=0.0032
2025-08-16 07:34:57,715 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26435, 'loss': 0.17506753, 'lr': 0, 'params': 514193, 'time_iter': 0.03306, 'accuracy': 0.9611, 'precision': 0.34043, 'recall': 0.24615, 'f1': 0.28571, 'auc': 0.735}
2025-08-16 07:34:57,716 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:57,716 - INFO - Layer 11 (Layer_11), Head 1: drop=0.0034
2025-08-16 07:35:01,862 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.09887, 'loss': 0.17278926, 'lr': 0, 'params': 514193, 'time_iter': 0.03177, 'accuracy': 0.96353, 'precision': 0.37805, 'recall': 0.23846, 'f1': 0.29245, 'auc': 0.73917}
2025-08-16 07:35:01,864 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:01,864 - INFO - Layer 11 (Layer_11), Head 2: drop=-0.0023
2025-08-16 07:35:06,078 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.16517, 'loss': 0.17496037, 'lr': 0, 'params': 514193, 'time_iter': 0.03229, 'accuracy': 0.96402, 'precision': 0.39024, 'recall': 0.24615, 'f1': 0.30189, 'auc': 0.73596}
2025-08-16 07:35:06,079 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:06,079 - INFO - Layer 11 (Layer_11), Head 3: drop=0.0021
2025-08-16 07:35:10,403 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27444, 'loss': 0.1755422, 'lr': 0, 'params': 514193, 'time_iter': 0.03314, 'accuracy': 0.96377, 'precision': 0.38824, 'recall': 0.25385, 'f1': 0.30698, 'auc': 0.73494}
2025-08-16 07:35:10,405 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:10,405 - INFO - Layer 12 (Layer_12), Head 0: drop=0.0034
2025-08-16 07:35:14,409 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.95616, 'loss': 0.16372401, 'lr': 0, 'params': 514193, 'time_iter': 0.03067, 'accuracy': 0.96523, 'precision': 0.39344, 'recall': 0.18462, 'f1': 0.25131, 'auc': 0.73625}
2025-08-16 07:35:14,410 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:14,410 - INFO - Layer 12 (Layer_12), Head 1: drop=0.0017
2025-08-16 07:35:18,365 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.90949, 'loss': 0.17337264, 'lr': 0, 'params': 514193, 'time_iter': 0.03031, 'accuracy': 0.96377, 'precision': 0.38272, 'recall': 0.23846, 'f1': 0.29384, 'auc': 0.73637}
2025-08-16 07:35:18,366 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:18,367 - INFO - Layer 12 (Layer_12), Head 2: drop=0.0015
2025-08-16 07:35:22,445 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.03136, 'loss': 0.17432191, 'lr': 0, 'params': 514193, 'time_iter': 0.03125, 'accuracy': 0.96329, 'precision': 0.37349, 'recall': 0.23846, 'f1': 0.29108, 'auc': 0.73477}
2025-08-16 07:35:22,447 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:22,447 - INFO - Layer 12 (Layer_12), Head 3: drop=0.0037
2025-08-16 07:35:26,453 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.95718, 'loss': 0.1742127, 'lr': 0, 'params': 514193, 'time_iter': 0.03068, 'accuracy': 0.96377, 'precision': 0.38554, 'recall': 0.24615, 'f1': 0.30047, 'auc': 0.73593}
2025-08-16 07:35:26,455 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:26,455 - INFO - Layer 13 (Layer_13), Head 0: drop=0.0021
2025-08-16 07:35:30,475 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.97299, 'loss': 0.17112853, 'lr': 0, 'params': 514193, 'time_iter': 0.0308, 'accuracy': 0.96548, 'precision': 0.41892, 'recall': 0.23846, 'f1': 0.30392, 'auc': 0.73587}
2025-08-16 07:35:30,477 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:30,477 - INFO - Layer 13 (Layer_13), Head 1: drop=0.0022
2025-08-16 07:35:34,458 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.93366, 'loss': 0.16989597, 'lr': 0, 'params': 514193, 'time_iter': 0.03049, 'accuracy': 0.96402, 'precision': 0.39024, 'recall': 0.24615, 'f1': 0.30189, 'auc': 0.73679}
2025-08-16 07:35:34,460 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:34,460 - INFO - Layer 13 (Layer_13), Head 2: drop=0.0009
2025-08-16 07:35:38,573 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.06625, 'loss': 0.1714051, 'lr': 0, 'params': 514193, 'time_iter': 0.03152, 'accuracy': 0.96548, 'precision': 0.41892, 'recall': 0.23846, 'f1': 0.30392, 'auc': 0.73608}
2025-08-16 07:35:38,575 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:38,575 - INFO - Layer 13 (Layer_13), Head 3: drop=0.0019
2025-08-16 07:35:42,619 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.99611, 'loss': 0.17341745, 'lr': 0, 'params': 514193, 'time_iter': 0.03098, 'accuracy': 0.96159, 'precision': 0.35106, 'recall': 0.25385, 'f1': 0.29464, 'auc': 0.73802}
2025-08-16 07:35:42,621 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:42,621 - INFO - Layer 14 (Layer_14), Head 0: drop=-0.0007
2025-08-16 07:35:46,704 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.03544, 'loss': 0.16902652, 'lr': 0, 'params': 514193, 'time_iter': 0.03128, 'accuracy': 0.96304, 'precision': 0.37209, 'recall': 0.24615, 'f1': 0.2963, 'auc': 0.73687}
2025-08-16 07:35:46,706 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:46,706 - INFO - Layer 14 (Layer_14), Head 1: drop=0.0008
2025-08-16 07:35:50,623 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.87, 'loss': 0.17079854, 'lr': 0, 'params': 514193, 'time_iter': 0.03, 'accuracy': 0.96426, 'precision': 0.39241, 'recall': 0.23846, 'f1': 0.29665, 'auc': 0.73658}
2025-08-16 07:35:50,625 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:50,625 - INFO - Layer 14 (Layer_14), Head 2: drop=0.0012
2025-08-16 07:35:54,652 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.98005, 'loss': 0.16858291, 'lr': 0, 'params': 514193, 'time_iter': 0.03085, 'accuracy': 0.9645, 'precision': 0.39744, 'recall': 0.23846, 'f1': 0.29808, 'auc': 0.73811}
2025-08-16 07:35:54,653 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:54,654 - INFO - Layer 14 (Layer_14), Head 3: drop=-0.0009
2025-08-16 07:35:54,657 - INFO - 
FIDELITY METRICS:
2025-08-16 07:35:54,657 - INFO - Fidelity (top 30 heads): 0.0043
2025-08-16 07:35:54,657 - INFO - Fidelity- (bottom 30 heads): -0.0033
2025-08-16 07:35:54,657 - INFO - 
GNN distribution in important heads:
2025-08-16 07:35:54,657 - INFO -   Layer_12: 4 heads
2025-08-16 07:35:54,657 - INFO -   Layer_3: 3 heads
2025-08-16 07:35:54,657 - INFO -   Layer_1: 3 heads
2025-08-16 07:35:54,658 - INFO -   Layer_9: 3 heads
2025-08-16 07:35:54,658 - INFO -   Layer_11: 3 heads
2025-08-16 07:35:54,658 - INFO -   Layer_13: 3 heads
2025-08-16 07:35:54,658 - INFO -   Layer_0: 2 heads
2025-08-16 07:35:54,658 - INFO -   Layer_6: 2 heads
2025-08-16 07:35:54,658 - INFO -   Layer_4: 2 heads
2025-08-16 07:35:54,658 - INFO -   Layer_2: 2 heads
2025-08-16 07:35:54,658 - INFO -   Layer_5: 1 heads
2025-08-16 07:35:54,658 - INFO -   Layer_7: 1 heads
2025-08-16 07:35:54,658 - INFO -   Layer_14: 1 heads
2025-08-16 07:35:54,658 - INFO - 
Interpretability Analysis:
2025-08-16 07:35:54,658 - INFO -   Fidelity: 0.0043
2025-08-16 07:35:54,658 - INFO -   Fidelity-: -0.0033
2025-08-16 07:35:54,658 - INFO -   Total heads tested: 60
2025-08-16 07:35:54,881 - INFO - Excel results saved to results/molhiv/molhiv-Vanilla-45/pk_explainer_results.xlsx
2025-08-16 07:35:56,320 - INFO - Saved visualizations to results/molhiv/molhiv-Vanilla-45/pk_explainer_results
2025-08-16 07:35:56,322 - INFO - 
PK-Explainer results saved to:
2025-08-16 07:35:56,323 - INFO -   - Excel: results/molhiv/molhiv-Vanilla-45/pk_explainer_results.xlsx
2025-08-16 07:35:56,323 - INFO -   - JSON: results/molhiv/molhiv-Vanilla-45/pk_explainer_results.json
2025-08-16 07:35:56,323 - INFO -   - Visualizations: results/molhiv/molhiv-Vanilla-45/pk_explainer_results
2025-08-16 07:35:56,368 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-45
2025-08-16 07:35:56,369 - INFO - Total time: 7916.01s (2.20h)
2025-08-16 07:35:56,427 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-45/agg
2025-08-16 07:35:56,427 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-16 07:35:56,427 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-45
2025-08-16 07:35:56,427 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-45/test_results/
Completed seed 45. Results saved in results/molhiv/molhiv-Vanilla-45
----------------------------------------
Running experiment with seed: 47
Starting training for seed 47...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/TRANS
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/TRANS/confignas.yaml
Using device: cuda
2025-08-16 07:36:05,304 - INFO - GPU Mem: 34.1GB
2025-08-16 07:36:05,304 - INFO - Run directory: results/molhiv/molhiv-Vanilla-47
2025-08-16 07:36:05,305 - INFO - Seed: 47
2025-08-16 07:36:05,305 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-16 07:36:05,305 - INFO - Routing mode: none
2025-08-16 07:36:05,305 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 07:36:05,305 - INFO - Number of layers: 15
2025-08-16 07:36:05,305 - INFO - Uncertainty enabled: False
2025-08-16 07:36:05,305 - INFO - Training mode: custom
2025-08-16 07:36:05,305 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-16 07:36:05,305 - INFO - Additional features: Router weights logging + JSON export
2025-08-16 07:36:12,096 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 07:36:12,099 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 07:36:12,100 - INFO -   undirected: True
2025-08-16 07:36:12,101 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 07:36:12,101 - INFO -   avg num_nodes/graph: 25
2025-08-16 07:36:12,101 - INFO -   num node features: 9
2025-08-16 07:36:12,101 - INFO -   num edge features: 3
2025-08-16 07:36:12,101 - INFO -   num tasks: 1
2025-08-16 07:36:12,102 - INFO -   num classes: 2
2025-08-16 07:36:12,102 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 07:36:12,102 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 07:36:12,105 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  6%|▌         | 2543/41127 [00:10<02:31, 254.27it/s] 12%|█▏        | 5034/41127 [00:20<02:26, 246.37it/s] 12%|█▏        | 5034/41127 [00:33<02:26, 246.37it/s] 15%|█▍        | 6028/41127 [00:33<03:44, 156.23it/s] 16%|█▌        | 6562/41127 [00:43<04:51, 118.70it/s] 20%|█▉        | 8207/41127 [00:53<04:06, 133.60it/s] 25%|██▌       | 10297/41127 [01:04<03:17, 156.47it/s] 29%|██▉       | 12062/41127 [01:14<02:58, 162.77it/s] 34%|███▎      | 13836/41127 [01:24<02:43, 167.03it/s] 36%|███▌      | 14754/41127 [01:34<03:04, 142.70it/s] 38%|███▊      | 15605/41127 [01:44<03:23, 125.14it/s] 40%|████      | 16468/41127 [01:54<03:37, 113.36it/s] 44%|████▍     | 18107/41127 [02:04<02:59, 128.26it/s] 48%|████▊     | 19554/41127 [02:14<02:41, 133.17it/s] 51%|█████▏    | 21129/41127 [02:24<02:22, 140.39it/s] 56%|█████▋    | 23176/41127 [02:34<01:52, 159.68it/s] 62%|██████▏   | 25455/41127 [02:44<01:27, 180.14it/s] 69%|██████▊   | 28205/41127 [02:54<01:01, 208.59it/s] 71%|███████   | 29277/41127 [03:05<01:07, 176.12it/s] 76%|███████▌  | 31059/41127 [03:15<00:57, 175.01it/s] 77%|███████▋  | 31587/41127 [03:25<01:08, 138.46it/s] 82%|████████▏ | 33725/41127 [03:35<00:46, 160.82it/s] 86%|████████▌ | 35435/41127 [03:45<00:35, 162.45it/s] 91%|█████████▏| 37604/41127 [03:55<00:19, 178.60it/s] 95%|█████████▍| 38925/41127 [04:05<00:13, 164.75it/s] 97%|█████████▋| 40068/41127 [04:16<00:07, 148.98it/s] 99%|█████████▉| 40744/41127 [04:26<00:03, 123.61it/s]100%|█████████▉| 41030/41127 [04:36<00:01, 94.44it/s] 100%|██████████| 41127/41127 [04:38<00:00, 147.46it/s]
2025-08-16 07:40:52,196 - INFO - Done! Took 00:04:40.09
2025-08-16 07:40:52,329 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 07:40:52,457 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-16 07:40:52,457 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-08-16 07:40:52,457 - INFO - Inner model has get_darts_model: False
2025-08-16 07:40:52,459 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-08-16 07:40:52,462 - INFO - Number of parameters: 514,193
2025-08-16 07:40:52,462 - INFO - Starting optimized training: 2025-08-16 07:40:52.462258
2025-08-16 07:40:58,322 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 07:40:58,323 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 07:40:58,324 - INFO -   undirected: True
2025-08-16 07:40:58,324 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 07:40:58,324 - INFO -   avg num_nodes/graph: 25
2025-08-16 07:40:58,325 - INFO -   num node features: 9
2025-08-16 07:40:58,325 - INFO -   num edge features: 3
2025-08-16 07:40:58,325 - INFO -   num tasks: 1
2025-08-16 07:40:58,325 - INFO -   num classes: 2
2025-08-16 07:40:58,325 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 07:40:58,325 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 07:40:58,328 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  6%|▋         | 2615/41127 [00:10<02:27, 261.49it/s] 12%|█▏        | 5047/41127 [00:20<02:26, 246.25it/s] 12%|█▏        | 5047/41127 [00:37<02:26, 246.25it/s] 15%|█▌        | 6357/41127 [00:37<03:55, 147.96it/s] 17%|█▋        | 6842/41127 [00:47<04:59, 114.42it/s] 22%|██▏       | 9100/41127 [00:57<03:33, 149.94it/s] 26%|██▌       | 10684/41127 [01:07<03:19, 152.59it/s] 31%|███       | 12800/41127 [01:17<02:47, 169.04it/s] 35%|███▍      | 14339/41127 [01:28<02:45, 162.34it/s] 36%|███▋      | 14927/41127 [01:38<03:20, 130.91it/s] 38%|███▊      | 15606/41127 [01:48<03:48, 111.91it/s] 40%|████      | 16466/41127 [01:58<03:58, 103.44it/s] 44%|████▍     | 18047/41127 [02:08<03:12, 119.73it/s] 48%|████▊     | 19616/41127 [02:18<02:44, 130.45it/s] 53%|█████▎    | 21803/41127 [02:28<02:03, 155.96it/s] 57%|█████▋    | 23588/41127 [02:39<01:48, 161.17it/s] 63%|██████▎   | 26084/41127 [02:49<01:20, 186.96it/s] 67%|██████▋   | 27712/41127 [02:59<01:14, 179.78it/s] 71%|███████   | 29277/41127 [03:09<01:09, 171.31it/s] 75%|███████▍  | 30807/41127 [03:19<01:02, 165.87it/s] 77%|███████▋  | 31588/41127 [03:29<01:08, 139.30it/s] 81%|████████  | 33163/41127 [03:39<00:55, 144.71it/s] 84%|████████▍ | 34580/41127 [03:49<00:45, 142.97it/s] 86%|████████▋ | 35474/41127 [04:00<00:44, 125.67it/s] 91%|█████████ | 37405/41127 [04:10<00:25, 145.64it/s] 94%|█████████▍| 38776/41127 [04:20<00:16, 142.16it/s] 97%|█████████▋| 40062/41127 [04:30<00:07, 138.14it/s] 99%|█████████▉| 40712/41127 [04:40<00:03, 116.26it/s]100%|██████████| 41127/41127 [04:50<00:00, 141.74it/s]
2025-08-16 07:45:49,714 - INFO - Done! Took 00:04:51.39
2025-08-16 07:45:49,852 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 07:45:50,049 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-16 07:45:50,049 - INFO - Start from epoch 0
2025-08-16 07:47:01,353 - INFO - train: {'epoch': 0, 'time_epoch': 71.16234, 'eta': 7045.0721, 'eta_hours': 1.95696, 'loss': 0.88264406, 'lr': 0.0, 'params': 514193, 'time_iter': 0.06916, 'accuracy': 0.03745, 'precision': 0.03745, 'recall': 1.0, 'f1': 0.07219, 'auc': 0.46134}
2025-08-16 07:47:01,408 - INFO - ...computing epoch stats took: 0.17s
2025-08-16 07:47:06,319 - INFO - val: {'epoch': 0, 'time_epoch': 4.89746, 'loss': 0.8974235, 'lr': 0, 'params': 514193, 'time_iter': 0.03796, 'accuracy': 0.01969, 'precision': 0.01969, 'recall': 1.0, 'f1': 0.03863, 'auc': 0.42212}
2025-08-16 07:47:06,390 - INFO - ...computing epoch stats took: 0.08s
2025-08-16 07:47:10,769 - INFO - test: {'epoch': 0, 'time_epoch': 4.36548, 'loss': 0.90642851, 'lr': 0, 'params': 514193, 'time_iter': 0.03384, 'accuracy': 0.03161, 'precision': 0.03161, 'recall': 1.0, 'f1': 0.06128, 'auc': 0.3871}
2025-08-16 07:47:10,820 - INFO - ...computing epoch stats took: 0.06s
2025-08-16 07:47:10,821 - INFO - > Epoch 0: took 80.8s (avg 80.8s) | Best so far: epoch 0	train_loss: 0.8826 train_auc: 0.4613	val_loss: 0.8974 val_auc: 0.4221	test_loss: 0.9064 test_auc: 0.3871
2025-08-16 07:48:16,635 - INFO - train: {'epoch': 1, 'time_epoch': 65.71732, 'eta': 6707.10338, 'eta_hours': 1.86308, 'loss': 0.72046633, 'lr': 2e-05, 'params': 514193, 'time_iter': 0.06387, 'accuracy': 0.30197, 'precision': 0.03895, 'recall': 0.74513, 'f1': 0.07403, 'auc': 0.50943}
2025-08-16 07:48:16,644 - INFO - ...computing epoch stats took: 0.09s
2025-08-16 07:48:20,919 - INFO - val: {'epoch': 1, 'time_epoch': 4.25858, 'loss': 0.57075074, 'lr': 0, 'params': 514193, 'time_iter': 0.03301, 'accuracy': 0.56917, 'precision': 0.02151, 'recall': 0.46914, 'f1': 0.04113, 'auc': 0.51079}
2025-08-16 07:48:20,922 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:48:25,278 - INFO - test: {'epoch': 1, 'time_epoch': 4.33892, 'loss': 0.54257876, 'lr': 0, 'params': 514193, 'time_iter': 0.03364, 'accuracy': 0.60588, 'precision': 0.04067, 'recall': 0.50769, 'f1': 0.0753, 'auc': 0.53988}
2025-08-16 07:48:25,280 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:48:25,281 - INFO - > Epoch 1: took 74.5s (avg 77.6s) | Best so far: epoch 1	train_loss: 0.7205 train_auc: 0.5094	val_loss: 0.5708 val_auc: 0.5108	test_loss: 0.5426 test_auc: 0.5399
2025-08-16 07:49:33,799 - INFO - train: {'epoch': 2, 'time_epoch': 68.40739, 'eta': 6637.61476, 'eta_hours': 1.84378, 'loss': 0.32587403, 'lr': 4e-05, 'params': 514193, 'time_iter': 0.06648, 'accuracy': 0.8631, 'precision': 0.04454, 'recall': 0.12987, 'f1': 0.06633, 'auc': 0.56876}
2025-08-16 07:49:33,807 - INFO - ...computing epoch stats took: 0.10s
2025-08-16 07:49:38,042 - INFO - val: {'epoch': 2, 'time_epoch': 4.21995, 'loss': 0.16184443, 'lr': 0, 'params': 514193, 'time_iter': 0.03271, 'accuracy': 0.97666, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.61655}
2025-08-16 07:49:38,046 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:49:42,165 - INFO - test: {'epoch': 2, 'time_epoch': 4.10265, 'loss': 0.17892667, 'lr': 0, 'params': 514193, 'time_iter': 0.0318, 'accuracy': 0.9645, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66597}
2025-08-16 07:49:42,168 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:49:42,168 - INFO - > Epoch 2: took 76.9s (avg 77.4s) | Best so far: epoch 2	train_loss: 0.3259 train_auc: 0.5688	val_loss: 0.1618 val_auc: 0.6166	test_loss: 0.1789 test_auc: 0.6660
2025-08-16 07:50:48,134 - INFO - train: {'epoch': 3, 'time_epoch': 65.86027, 'eta': 6507.53574, 'eta_hours': 1.80765, 'loss': 0.17107485, 'lr': 6e-05, 'params': 514193, 'time_iter': 0.064, 'accuracy': 0.96155, 'precision': 0.09756, 'recall': 0.00325, 'f1': 0.00628, 'auc': 0.62189}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:50:52,239 - INFO - val: {'epoch': 3, 'time_epoch': 4.06977, 'loss': 0.11889358, 'lr': 0, 'params': 514193, 'time_iter': 0.03155, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.56968}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:50:56,156 - INFO - test: {'epoch': 3, 'time_epoch': 3.9004, 'loss': 0.15115066, 'lr': 0, 'params': 514193, 'time_iter': 0.03024, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.62989}
2025-08-16 07:50:56,159 - INFO - > Epoch 3: took 74.0s (avg 76.5s) | Best so far: epoch 2	train_loss: 0.3259 train_auc: 0.5688	val_loss: 0.1618 val_auc: 0.6166	test_loss: 0.1789 test_auc: 0.6660
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:52:02,615 - INFO - train: {'epoch': 4, 'time_epoch': 66.35367, 'eta': 6412.51877, 'eta_hours': 1.78126, 'loss': 0.16076817, 'lr': 8e-05, 'params': 514193, 'time_iter': 0.06448, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.62947}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:52:07,003 - INFO - val: {'epoch': 4, 'time_epoch': 4.36473, 'loss': 0.09731456, 'lr': 0, 'params': 514193, 'time_iter': 0.03384, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69838}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:52:11,183 - INFO - test: {'epoch': 4, 'time_epoch': 4.16365, 'loss': 0.14066921, 'lr': 0, 'params': 514193, 'time_iter': 0.03228, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68569}
2025-08-16 07:52:11,331 - INFO - > Epoch 4: took 75.2s (avg 76.3s) | Best so far: epoch 4	train_loss: 0.1608 train_auc: 0.6295	val_loss: 0.0973 val_auc: 0.6984	test_loss: 0.1407 test_auc: 0.6857
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:53:22,312 - INFO - train: {'epoch': 5, 'time_epoch': 70.87629, 'eta': 6397.91064, 'eta_hours': 1.7772, 'loss': 0.1549354, 'lr': 0.0001, 'params': 514193, 'time_iter': 0.06888, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66916}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:53:26,549 - INFO - val: {'epoch': 5, 'time_epoch': 4.20949, 'loss': 0.10035689, 'lr': 0, 'params': 514193, 'time_iter': 0.03263, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70929}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:53:30,609 - INFO - test: {'epoch': 5, 'time_epoch': 4.04426, 'loss': 0.13088544, 'lr': 0, 'params': 514193, 'time_iter': 0.03135, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71915}
2025-08-16 07:53:30,611 - INFO - > Epoch 5: took 79.3s (avg 76.8s) | Best so far: epoch 5	train_loss: 0.1549 train_auc: 0.6692	val_loss: 0.1004 val_auc: 0.7093	test_loss: 0.1309 test_auc: 0.7191
2025-08-16 07:54:36,684 - INFO - train: {'epoch': 6, 'time_epoch': 65.96496, 'eta': 6301.97535, 'eta_hours': 1.75055, 'loss': 0.14678163, 'lr': 9.997e-05, 'params': 514193, 'time_iter': 0.06411, 'accuracy': 0.96265, 'precision': 0.8, 'recall': 0.00325, 'f1': 0.00647, 'auc': 0.70001}
2025-08-16 07:54:40,727 - INFO - val: {'epoch': 6, 'time_epoch': 4.02123, 'loss': 0.09103851, 'lr': 0, 'params': 514193, 'time_iter': 0.03117, 'accuracy': 0.98104, 'precision': 0.58824, 'recall': 0.12346, 'f1': 0.20408, 'auc': 0.69892}
2025-08-16 07:54:44,656 - INFO - test: {'epoch': 6, 'time_epoch': 3.91144, 'loss': 0.12266029, 'lr': 0, 'params': 514193, 'time_iter': 0.03032, 'accuracy': 0.96961, 'precision': 0.64706, 'recall': 0.08462, 'f1': 0.14966, 'auc': 0.71377}
2025-08-16 07:54:44,658 - INFO - > Epoch 6: took 74.0s (avg 76.4s) | Best so far: epoch 5	train_loss: 0.1549 train_auc: 0.6692	val_loss: 0.1004 val_auc: 0.7093	test_loss: 0.1309 test_auc: 0.7191
2025-08-16 07:55:50,919 - INFO - train: {'epoch': 7, 'time_epoch': 66.17175, 'eta': 6215.91083, 'eta_hours': 1.72664, 'loss': 0.14117627, 'lr': 9.989e-05, 'params': 514193, 'time_iter': 0.06431, 'accuracy': 0.96298, 'precision': 0.58537, 'recall': 0.03896, 'f1': 0.07306, 'auc': 0.72452}
2025-08-16 07:55:55,276 - INFO - val: {'epoch': 7, 'time_epoch': 4.33424, 'loss': 0.0901743, 'lr': 0, 'params': 514193, 'time_iter': 0.0336, 'accuracy': 0.97933, 'precision': 0.42857, 'recall': 0.14815, 'f1': 0.22018, 'auc': 0.75931}
2025-08-16 07:55:59,469 - INFO - test: {'epoch': 7, 'time_epoch': 4.17633, 'loss': 0.12509335, 'lr': 0, 'params': 514193, 'time_iter': 0.03237, 'accuracy': 0.96718, 'precision': 0.43243, 'recall': 0.12308, 'f1': 0.19162, 'auc': 0.73804}
2025-08-16 07:55:59,471 - INFO - > Epoch 7: took 74.8s (avg 76.2s) | Best so far: epoch 7	train_loss: 0.1412 train_auc: 0.7245	val_loss: 0.0902 val_auc: 0.7593	test_loss: 0.1251 test_auc: 0.7380
2025-08-16 07:57:06,904 - INFO - train: {'epoch': 8, 'time_epoch': 67.32163, 'eta': 6145.89343, 'eta_hours': 1.70719, 'loss': 0.13711717, 'lr': 9.975e-05, 'params': 514193, 'time_iter': 0.06542, 'accuracy': 0.96353, 'precision': 0.57921, 'recall': 0.09497, 'f1': 0.16318, 'auc': 0.73658}
2025-08-16 07:57:11,113 - INFO - val: {'epoch': 8, 'time_epoch': 4.1846, 'loss': 0.08775578, 'lr': 0, 'params': 514193, 'time_iter': 0.03244, 'accuracy': 0.97982, 'precision': 0.45833, 'recall': 0.1358, 'f1': 0.20952, 'auc': 0.73455}
2025-08-16 07:57:15,218 - INFO - test: {'epoch': 8, 'time_epoch': 4.08775, 'loss': 0.12138689, 'lr': 0, 'params': 514193, 'time_iter': 0.03169, 'accuracy': 0.96961, 'precision': 0.55319, 'recall': 0.2, 'f1': 0.29379, 'auc': 0.73935}
2025-08-16 07:57:15,221 - INFO - > Epoch 8: took 75.7s (avg 76.1s) | Best so far: epoch 7	train_loss: 0.1412 train_auc: 0.7245	val_loss: 0.0902 val_auc: 0.7593	test_loss: 0.1251 test_auc: 0.7380
2025-08-16 07:58:21,694 - INFO - train: {'epoch': 9, 'time_epoch': 66.36383, 'eta': 6067.79503, 'eta_hours': 1.6855, 'loss': 0.1350548, 'lr': 9.956e-05, 'params': 514193, 'time_iter': 0.06449, 'accuracy': 0.96356, 'precision': 0.56735, 'recall': 0.11282, 'f1': 0.18822, 'auc': 0.74655}
2025-08-16 07:58:25,861 - INFO - val: {'epoch': 9, 'time_epoch': 4.14364, 'loss': 0.08953045, 'lr': 0, 'params': 514193, 'time_iter': 0.03212, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.17284, 'f1': 0.25688, 'auc': 0.71602}
2025-08-16 07:58:29,990 - INFO - test: {'epoch': 9, 'time_epoch': 4.11118, 'loss': 0.12554214, 'lr': 0, 'params': 514193, 'time_iter': 0.03187, 'accuracy': 0.97058, 'precision': 0.64516, 'recall': 0.15385, 'f1': 0.24845, 'auc': 0.70947}
2025-08-16 07:58:29,992 - INFO - > Epoch 9: took 74.8s (avg 76.0s) | Best so far: epoch 7	train_loss: 0.1412 train_auc: 0.7245	val_loss: 0.0902 val_auc: 0.7593	test_loss: 0.1251 test_auc: 0.7380
2025-08-16 07:59:37,943 - INFO - train: {'epoch': 10, 'time_epoch': 67.83887, 'eta': 6003.76455, 'eta_hours': 1.66771, 'loss': 0.13208381, 'lr': 9.932e-05, 'params': 514193, 'time_iter': 0.06593, 'accuracy': 0.96426, 'precision': 0.58917, 'recall': 0.15016, 'f1': 0.23933, 'auc': 0.76241}
2025-08-16 07:59:42,271 - INFO - val: {'epoch': 10, 'time_epoch': 4.30499, 'loss': 0.08674722, 'lr': 0, 'params': 514193, 'time_iter': 0.03337, 'accuracy': 0.97982, 'precision': 0.45455, 'recall': 0.12346, 'f1': 0.19417, 'auc': 0.73111}
2025-08-16 07:59:46,527 - INFO - test: {'epoch': 10, 'time_epoch': 4.23903, 'loss': 0.1187993, 'lr': 0, 'params': 514193, 'time_iter': 0.03286, 'accuracy': 0.97155, 'precision': 0.64444, 'recall': 0.22308, 'f1': 0.33143, 'auc': 0.73557}
2025-08-16 07:59:46,529 - INFO - > Epoch 10: took 76.5s (avg 76.0s) | Best so far: epoch 7	train_loss: 0.1412 train_auc: 0.7245	val_loss: 0.0902 val_auc: 0.7593	test_loss: 0.1251 test_auc: 0.7380
2025-08-16 08:00:54,571 - INFO - train: {'epoch': 11, 'time_epoch': 67.93188, 'eta': 5939.78141, 'eta_hours': 1.64994, 'loss': 0.12933415, 'lr': 9.902e-05, 'params': 514193, 'time_iter': 0.06602, 'accuracy': 0.96496, 'precision': 0.63036, 'recall': 0.15503, 'f1': 0.24886, 'auc': 0.77851}
2025-08-16 08:00:58,659 - INFO - val: {'epoch': 11, 'time_epoch': 4.06582, 'loss': 0.08850404, 'lr': 0, 'params': 514193, 'time_iter': 0.03152, 'accuracy': 0.97788, 'precision': 0.375, 'recall': 0.18519, 'f1': 0.24793, 'auc': 0.76993}
2025-08-16 08:01:02,672 - INFO - test: {'epoch': 11, 'time_epoch': 3.99511, 'loss': 0.12985016, 'lr': 0, 'params': 514193, 'time_iter': 0.03097, 'accuracy': 0.96791, 'precision': 0.48333, 'recall': 0.22308, 'f1': 0.30526, 'auc': 0.73454}
2025-08-16 08:01:02,674 - INFO - > Epoch 11: took 76.1s (avg 76.1s) | Best so far: epoch 11	train_loss: 0.1293 train_auc: 0.7785	val_loss: 0.0885 val_auc: 0.7699	test_loss: 0.1299 test_auc: 0.7345
2025-08-16 08:02:10,108 - INFO - train: {'epoch': 12, 'time_epoch': 67.32223, 'eta': 5871.11081, 'eta_hours': 1.63086, 'loss': 0.12578712, 'lr': 9.867e-05, 'params': 514193, 'time_iter': 0.06542, 'accuracy': 0.96593, 'precision': 0.65205, 'recall': 0.19318, 'f1': 0.29806, 'auc': 0.78816}
2025-08-16 08:02:14,233 - INFO - val: {'epoch': 12, 'time_epoch': 4.10258, 'loss': 0.08588094, 'lr': 0, 'params': 514193, 'time_iter': 0.0318, 'accuracy': 0.97812, 'precision': 0.39535, 'recall': 0.20988, 'f1': 0.27419, 'auc': 0.78636}
2025-08-16 08:02:18,271 - INFO - test: {'epoch': 12, 'time_epoch': 4.02011, 'loss': 0.12219196, 'lr': 0, 'params': 514193, 'time_iter': 0.03116, 'accuracy': 0.96937, 'precision': 0.54, 'recall': 0.20769, 'f1': 0.3, 'auc': 0.7372}
2025-08-16 08:02:18,273 - INFO - > Epoch 12: took 75.6s (avg 76.0s) | Best so far: epoch 12	train_loss: 0.1258 train_auc: 0.7882	val_loss: 0.0859 val_auc: 0.7864	test_loss: 0.1222 test_auc: 0.7372
2025-08-16 08:03:25,980 - INFO - train: {'epoch': 13, 'time_epoch': 67.59371, 'eta': 5804.30049, 'eta_hours': 1.61231, 'loss': 0.12642344, 'lr': 9.826e-05, 'params': 514193, 'time_iter': 0.06569, 'accuracy': 0.96626, 'precision': 0.65722, 'recall': 0.20698, 'f1': 0.31481, 'auc': 0.78475}
2025-08-16 08:03:30,142 - INFO - val: {'epoch': 13, 'time_epoch': 4.13949, 'loss': 0.08581607, 'lr': 0, 'params': 514193, 'time_iter': 0.03209, 'accuracy': 0.98225, 'precision': 0.75, 'recall': 0.14815, 'f1': 0.24742, 'auc': 0.72147}
2025-08-16 08:03:34,209 - INFO - test: {'epoch': 13, 'time_epoch': 4.05069, 'loss': 0.12175437, 'lr': 0, 'params': 514193, 'time_iter': 0.0314, 'accuracy': 0.97082, 'precision': 0.69231, 'recall': 0.13846, 'f1': 0.23077, 'auc': 0.71497}
2025-08-16 08:03:34,212 - INFO - > Epoch 13: took 75.9s (avg 76.0s) | Best so far: epoch 12	train_loss: 0.1258 train_auc: 0.7882	val_loss: 0.0859 val_auc: 0.7864	test_loss: 0.1222 test_auc: 0.7372
2025-08-16 08:04:40,918 - INFO - train: {'epoch': 14, 'time_epoch': 66.59725, 'eta': 5731.73912, 'eta_hours': 1.59215, 'loss': 0.12414086, 'lr': 9.78e-05, 'params': 514193, 'time_iter': 0.06472, 'accuracy': 0.96648, 'precision': 0.65176, 'recall': 0.22484, 'f1': 0.33434, 'auc': 0.79466}
2025-08-16 08:04:45,109 - INFO - val: {'epoch': 14, 'time_epoch': 4.16864, 'loss': 0.09092403, 'lr': 0, 'params': 514193, 'time_iter': 0.03232, 'accuracy': 0.98006, 'precision': 0.48718, 'recall': 0.23457, 'f1': 0.31667, 'auc': 0.72514}
2025-08-16 08:04:49,133 - INFO - test: {'epoch': 14, 'time_epoch': 4.00646, 'loss': 0.12566399, 'lr': 0, 'params': 514193, 'time_iter': 0.03106, 'accuracy': 0.96353, 'precision': 0.38095, 'recall': 0.24615, 'f1': 0.29907, 'auc': 0.75027}
2025-08-16 08:04:49,135 - INFO - > Epoch 14: took 74.9s (avg 75.9s) | Best so far: epoch 12	train_loss: 0.1258 train_auc: 0.7882	val_loss: 0.0859 val_auc: 0.7864	test_loss: 0.1222 test_auc: 0.7372
2025-08-16 08:05:55,985 - INFO - train: {'epoch': 15, 'time_epoch': 66.74886, 'eta': 5660.71922, 'eta_hours': 1.57242, 'loss': 0.12229336, 'lr': 9.729e-05, 'params': 514193, 'time_iter': 0.06487, 'accuracy': 0.96675, 'precision': 0.67164, 'recall': 0.21916, 'f1': 0.33048, 'auc': 0.80493}
2025-08-16 08:06:00,405 - INFO - val: {'epoch': 15, 'time_epoch': 4.3971, 'loss': 0.08585095, 'lr': 0, 'params': 514193, 'time_iter': 0.03409, 'accuracy': 0.98128, 'precision': 0.58333, 'recall': 0.17284, 'f1': 0.26667, 'auc': 0.70687}
2025-08-16 08:06:04,652 - INFO - test: {'epoch': 15, 'time_epoch': 4.22956, 'loss': 0.11789512, 'lr': 0, 'params': 514193, 'time_iter': 0.03279, 'accuracy': 0.96985, 'precision': 0.58333, 'recall': 0.16154, 'f1': 0.25301, 'auc': 0.73516}
2025-08-16 08:06:04,654 - INFO - > Epoch 15: took 75.5s (avg 75.9s) | Best so far: epoch 12	train_loss: 0.1258 train_auc: 0.7882	val_loss: 0.0859 val_auc: 0.7864	test_loss: 0.1222 test_auc: 0.7372
2025-08-16 08:07:14,584 - INFO - train: {'epoch': 16, 'time_epoch': 69.81816, 'eta': 5605.1872, 'eta_hours': 1.557, 'loss': 0.12183373, 'lr': 9.673e-05, 'params': 514193, 'time_iter': 0.06785, 'accuracy': 0.96648, 'precision': 0.65693, 'recall': 0.21916, 'f1': 0.32867, 'auc': 0.80171}
2025-08-16 08:07:18,962 - INFO - val: {'epoch': 16, 'time_epoch': 4.29279, 'loss': 0.08285779, 'lr': 0, 'params': 514193, 'time_iter': 0.03328, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.22222, 'f1': 0.30769, 'auc': 0.76825}
2025-08-16 08:07:23,229 - INFO - test: {'epoch': 16, 'time_epoch': 4.24939, 'loss': 0.12626995, 'lr': 0, 'params': 514193, 'time_iter': 0.03294, 'accuracy': 0.97058, 'precision': 0.62857, 'recall': 0.16923, 'f1': 0.26667, 'auc': 0.71414}
2025-08-16 08:07:23,232 - INFO - > Epoch 16: took 78.6s (avg 76.1s) | Best so far: epoch 12	train_loss: 0.1258 train_auc: 0.7882	val_loss: 0.0859 val_auc: 0.7864	test_loss: 0.1222 test_auc: 0.7372
2025-08-16 08:08:31,692 - INFO - train: {'epoch': 17, 'time_epoch': 68.34538, 'eta': 5541.35851, 'eta_hours': 1.53927, 'loss': 0.11836862, 'lr': 9.611e-05, 'params': 514193, 'time_iter': 0.06642, 'accuracy': 0.9673, 'precision': 0.67489, 'recall': 0.24432, 'f1': 0.35876, 'auc': 0.81666}
2025-08-16 08:08:35,687 - INFO - val: {'epoch': 17, 'time_epoch': 3.97341, 'loss': 0.11753298, 'lr': 0, 'params': 514193, 'time_iter': 0.0308, 'accuracy': 0.96766, 'precision': 0.19767, 'recall': 0.20988, 'f1': 0.20359, 'auc': 0.66116}
2025-08-16 08:08:39,598 - INFO - test: {'epoch': 17, 'time_epoch': 3.89497, 'loss': 0.15801817, 'lr': 0, 'params': 514193, 'time_iter': 0.03019, 'accuracy': 0.95113, 'precision': 0.216, 'recall': 0.20769, 'f1': 0.21176, 'auc': 0.69549}
2025-08-16 08:08:39,601 - INFO - > Epoch 17: took 76.4s (avg 76.1s) | Best so far: epoch 12	train_loss: 0.1258 train_auc: 0.7882	val_loss: 0.0859 val_auc: 0.7864	test_loss: 0.1222 test_auc: 0.7372
2025-08-16 08:09:46,217 - INFO - train: {'epoch': 18, 'time_epoch': 66.50528, 'eta': 5469.20974, 'eta_hours': 1.51922, 'loss': 0.11813132, 'lr': 9.545e-05, 'params': 514193, 'time_iter': 0.06463, 'accuracy': 0.96742, 'precision': 0.66598, 'recall': 0.26055, 'f1': 0.37456, 'auc': 0.82135}
2025-08-16 08:09:50,650 - INFO - val: {'epoch': 18, 'time_epoch': 4.41, 'loss': 0.08634528, 'lr': 0, 'params': 514193, 'time_iter': 0.03419, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.24691, 'f1': 0.33058, 'auc': 0.74048}
2025-08-16 08:09:54,925 - INFO - test: {'epoch': 18, 'time_epoch': 4.25644, 'loss': 0.12470166, 'lr': 0, 'params': 514193, 'time_iter': 0.033, 'accuracy': 0.96912, 'precision': 0.53333, 'recall': 0.18462, 'f1': 0.27429, 'auc': 0.72076}
2025-08-16 08:09:54,928 - INFO - > Epoch 18: took 75.3s (avg 76.0s) | Best so far: epoch 12	train_loss: 0.1258 train_auc: 0.7882	val_loss: 0.0859 val_auc: 0.7864	test_loss: 0.1222 test_auc: 0.7372
2025-08-16 08:11:01,786 - INFO - train: {'epoch': 19, 'time_epoch': 66.75211, 'eta': 5398.61264, 'eta_hours': 1.49961, 'loss': 0.11880521, 'lr': 9.474e-05, 'params': 514193, 'time_iter': 0.06487, 'accuracy': 0.96717, 'precision': 0.67117, 'recall': 0.24188, 'f1': 0.35561, 'auc': 0.81653}
2025-08-16 08:11:06,116 - INFO - val: {'epoch': 19, 'time_epoch': 4.30626, 'loss': 0.09043542, 'lr': 0, 'params': 514193, 'time_iter': 0.03338, 'accuracy': 0.97617, 'precision': 0.33333, 'recall': 0.20988, 'f1': 0.25758, 'auc': 0.75953}
2025-08-16 08:11:10,401 - INFO - test: {'epoch': 19, 'time_epoch': 4.26757, 'loss': 0.12238206, 'lr': 0, 'params': 514193, 'time_iter': 0.03308, 'accuracy': 0.96912, 'precision': 0.53061, 'recall': 0.2, 'f1': 0.2905, 'auc': 0.74727}
2025-08-16 08:11:10,403 - INFO - > Epoch 19: took 75.5s (avg 76.0s) | Best so far: epoch 12	train_loss: 0.1258 train_auc: 0.7882	val_loss: 0.0859 val_auc: 0.7864	test_loss: 0.1222 test_auc: 0.7372
2025-08-16 08:12:18,695 - INFO - train: {'epoch': 20, 'time_epoch': 68.14691, 'eta': 5333.62884, 'eta_hours': 1.48156, 'loss': 0.11621318, 'lr': 9.397e-05, 'params': 514193, 'time_iter': 0.06623, 'accuracy': 0.96854, 'precision': 0.69819, 'recall': 0.28166, 'f1': 0.40139, 'auc': 0.82154}
2025-08-16 08:12:22,850 - INFO - val: {'epoch': 20, 'time_epoch': 4.13293, 'loss': 0.08866209, 'lr': 0, 'params': 514193, 'time_iter': 0.03204, 'accuracy': 0.97763, 'precision': 0.39623, 'recall': 0.25926, 'f1': 0.31343, 'auc': 0.76309}
2025-08-16 08:12:26,900 - INFO - test: {'epoch': 20, 'time_epoch': 4.03315, 'loss': 0.13097783, 'lr': 0, 'params': 514193, 'time_iter': 0.03126, 'accuracy': 0.96742, 'precision': 0.46429, 'recall': 0.2, 'f1': 0.27957, 'auc': 0.73412}
2025-08-16 08:12:26,903 - INFO - > Epoch 20: took 76.5s (avg 76.0s) | Best so far: epoch 12	train_loss: 0.1258 train_auc: 0.7882	val_loss: 0.0859 val_auc: 0.7864	test_loss: 0.1222 test_auc: 0.7372
2025-08-16 08:13:37,765 - INFO - train: {'epoch': 21, 'time_epoch': 70.74829, 'eta': 5277.58057, 'eta_hours': 1.46599, 'loss': 0.11506888, 'lr': 9.316e-05, 'params': 514193, 'time_iter': 0.06875, 'accuracy': 0.96824, 'precision': 0.69358, 'recall': 0.27192, 'f1': 0.39067, 'auc': 0.83471}
2025-08-16 08:13:42,189 - INFO - val: {'epoch': 21, 'time_epoch': 4.40184, 'loss': 0.08636059, 'lr': 0, 'params': 514193, 'time_iter': 0.03412, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.23457, 'f1': 0.31933, 'auc': 0.75904}
2025-08-16 08:13:46,459 - INFO - test: {'epoch': 21, 'time_epoch': 4.25341, 'loss': 0.12683935, 'lr': 0, 'params': 514193, 'time_iter': 0.03297, 'accuracy': 0.96961, 'precision': 0.56098, 'recall': 0.17692, 'f1': 0.26901, 'auc': 0.7324}
2025-08-16 08:13:46,462 - INFO - > Epoch 21: took 79.6s (avg 76.2s) | Best so far: epoch 12	train_loss: 0.1258 train_auc: 0.7882	val_loss: 0.0859 val_auc: 0.7864	test_loss: 0.1222 test_auc: 0.7372
2025-08-16 08:14:56,102 - INFO - train: {'epoch': 22, 'time_epoch': 69.53054, 'eta': 5216.1772, 'eta_hours': 1.44894, 'loss': 0.11285702, 'lr': 9.23e-05, 'params': 514193, 'time_iter': 0.06757, 'accuracy': 0.96918, 'precision': 0.70566, 'recall': 0.30357, 'f1': 0.42452, 'auc': 0.84281}
2025-08-16 08:15:00,281 - INFO - val: {'epoch': 22, 'time_epoch': 4.15628, 'loss': 0.08467851, 'lr': 0, 'params': 514193, 'time_iter': 0.03222, 'accuracy': 0.98249, 'precision': 0.69565, 'recall': 0.19753, 'f1': 0.30769, 'auc': 0.73821}
2025-08-16 08:15:04,469 - INFO - test: {'epoch': 22, 'time_epoch': 4.17086, 'loss': 0.12222237, 'lr': 0, 'params': 514193, 'time_iter': 0.03233, 'accuracy': 0.97155, 'precision': 0.93333, 'recall': 0.10769, 'f1': 0.1931, 'auc': 0.74347}
2025-08-16 08:15:04,471 - INFO - > Epoch 22: took 78.0s (avg 76.3s) | Best so far: epoch 12	train_loss: 0.1258 train_auc: 0.7882	val_loss: 0.0859 val_auc: 0.7864	test_loss: 0.1222 test_auc: 0.7372
2025-08-16 08:16:12,183 - INFO - train: {'epoch': 23, 'time_epoch': 67.5994, 'eta': 5147.98129, 'eta_hours': 1.42999, 'loss': 0.11197825, 'lr': 9.14e-05, 'params': 514193, 'time_iter': 0.06569, 'accuracy': 0.96854, 'precision': 0.6862, 'recall': 0.29464, 'f1': 0.41227, 'auc': 0.84429}
2025-08-16 08:16:16,416 - INFO - val: {'epoch': 23, 'time_epoch': 4.20854, 'loss': 0.08359583, 'lr': 0, 'params': 514193, 'time_iter': 0.03262, 'accuracy': 0.98177, 'precision': 0.58824, 'recall': 0.24691, 'f1': 0.34783, 'auc': 0.73061}
2025-08-16 08:16:20,529 - INFO - test: {'epoch': 23, 'time_epoch': 4.09318, 'loss': 0.12503442, 'lr': 0, 'params': 514193, 'time_iter': 0.03173, 'accuracy': 0.96961, 'precision': 0.56098, 'recall': 0.17692, 'f1': 0.26901, 'auc': 0.7433}
2025-08-16 08:16:20,532 - INFO - > Epoch 23: took 76.1s (avg 76.3s) | Best so far: epoch 12	train_loss: 0.1258 train_auc: 0.7882	val_loss: 0.0859 val_auc: 0.7864	test_loss: 0.1222 test_auc: 0.7372
2025-08-16 08:17:30,237 - INFO - train: {'epoch': 24, 'time_epoch': 69.58299, 'eta': 5085.78388, 'eta_hours': 1.41272, 'loss': 0.10861908, 'lr': 9.045e-05, 'params': 514193, 'time_iter': 0.06762, 'accuracy': 0.97018, 'precision': 0.72451, 'recall': 0.32873, 'f1': 0.45226, 'auc': 0.85285}
2025-08-16 08:17:34,593 - INFO - val: {'epoch': 24, 'time_epoch': 4.3321, 'loss': 0.08861964, 'lr': 0, 'params': 514193, 'time_iter': 0.03358, 'accuracy': 0.97715, 'precision': 0.3617, 'recall': 0.20988, 'f1': 0.26562, 'auc': 0.74837}
2025-08-16 08:17:38,714 - INFO - test: {'epoch': 24, 'time_epoch': 4.07663, 'loss': 0.12686878, 'lr': 0, 'params': 514193, 'time_iter': 0.0316, 'accuracy': 0.96742, 'precision': 0.46875, 'recall': 0.23077, 'f1': 0.30928, 'auc': 0.71442}
2025-08-16 08:17:38,739 - INFO - > Epoch 24: took 78.2s (avg 76.3s) | Best so far: epoch 12	train_loss: 0.1258 train_auc: 0.7882	val_loss: 0.0859 val_auc: 0.7864	test_loss: 0.1222 test_auc: 0.7372
2025-08-16 08:18:49,949 - INFO - train: {'epoch': 25, 'time_epoch': 71.09089, 'eta': 5027.31007, 'eta_hours': 1.39648, 'loss': 0.11043895, 'lr': 8.946e-05, 'params': 514193, 'time_iter': 0.06909, 'accuracy': 0.96954, 'precision': 0.70683, 'recall': 0.31899, 'f1': 0.4396, 'auc': 0.84886}
2025-08-16 08:18:54,259 - INFO - val: {'epoch': 25, 'time_epoch': 4.28362, 'loss': 0.07930668, 'lr': 0, 'params': 514193, 'time_iter': 0.03321, 'accuracy': 0.98225, 'precision': 0.625, 'recall': 0.24691, 'f1': 0.35398, 'auc': 0.79687}
2025-08-16 08:18:58,267 - INFO - test: {'epoch': 25, 'time_epoch': 3.98759, 'loss': 0.12220019, 'lr': 0, 'params': 514193, 'time_iter': 0.03091, 'accuracy': 0.97058, 'precision': 0.62162, 'recall': 0.17692, 'f1': 0.27545, 'auc': 0.74422}
2025-08-16 08:18:58,271 - INFO - > Epoch 25: took 79.5s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:20:08,842 - INFO - train: {'epoch': 26, 'time_epoch': 70.47573, 'eta': 4966.23843, 'eta_hours': 1.37951, 'loss': 0.10943746, 'lr': 8.842e-05, 'params': 514193, 'time_iter': 0.06849, 'accuracy': 0.96945, 'precision': 0.71058, 'recall': 0.31088, 'f1': 0.43252, 'auc': 0.85612}
2025-08-16 08:20:13,390 - INFO - val: {'epoch': 26, 'time_epoch': 4.52347, 'loss': 0.08434647, 'lr': 0, 'params': 514193, 'time_iter': 0.03507, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.2963, 'f1': 0.37209, 'auc': 0.76297}
2025-08-16 08:20:17,665 - INFO - test: {'epoch': 26, 'time_epoch': 4.25655, 'loss': 0.12252698, 'lr': 0, 'params': 514193, 'time_iter': 0.033, 'accuracy': 0.96791, 'precision': 0.48684, 'recall': 0.28462, 'f1': 0.35922, 'auc': 0.74378}
2025-08-16 08:20:17,668 - INFO - > Epoch 26: took 79.4s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:21:27,135 - INFO - train: {'epoch': 27, 'time_epoch': 69.3528, 'eta': 4901.60756, 'eta_hours': 1.36156, 'loss': 0.10614305, 'lr': 8.734e-05, 'params': 514193, 'time_iter': 0.0674, 'accuracy': 0.97079, 'precision': 0.73083, 'recall': 0.34821, 'f1': 0.47169, 'auc': 0.85962}
2025-08-16 08:21:31,208 - INFO - val: {'epoch': 27, 'time_epoch': 4.05077, 'loss': 0.08388537, 'lr': 0, 'params': 514193, 'time_iter': 0.0314, 'accuracy': 0.98128, 'precision': 0.55, 'recall': 0.2716, 'f1': 0.36364, 'auc': 0.74895}
2025-08-16 08:21:35,221 - INFO - test: {'epoch': 27, 'time_epoch': 3.99659, 'loss': 0.1222119, 'lr': 0, 'params': 514193, 'time_iter': 0.03098, 'accuracy': 0.96864, 'precision': 0.50909, 'recall': 0.21538, 'f1': 0.3027, 'auc': 0.74803}
2025-08-16 08:21:35,224 - INFO - > Epoch 27: took 77.6s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:22:42,637 - INFO - train: {'epoch': 28, 'time_epoch': 67.30239, 'eta': 4831.63106, 'eta_hours': 1.34212, 'loss': 0.10454994, 'lr': 8.622e-05, 'params': 514193, 'time_iter': 0.06541, 'accuracy': 0.97021, 'precision': 0.71724, 'recall': 0.33766, 'f1': 0.45916, 'auc': 0.87232}
2025-08-16 08:22:46,788 - INFO - val: {'epoch': 28, 'time_epoch': 4.13032, 'loss': 0.09702878, 'lr': 0, 'params': 514193, 'time_iter': 0.03202, 'accuracy': 0.97544, 'precision': 0.34375, 'recall': 0.2716, 'f1': 0.30345, 'auc': 0.75488}
2025-08-16 08:22:50,808 - INFO - test: {'epoch': 28, 'time_epoch': 4.00119, 'loss': 0.13151313, 'lr': 0, 'params': 514193, 'time_iter': 0.03102, 'accuracy': 0.96402, 'precision': 0.3875, 'recall': 0.23846, 'f1': 0.29524, 'auc': 0.7221}
2025-08-16 08:22:50,810 - INFO - > Epoch 28: took 75.6s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:23:59,047 - INFO - train: {'epoch': 29, 'time_epoch': 68.12009, 'eta': 4763.74079, 'eta_hours': 1.32326, 'loss': 0.10541931, 'lr': 8.506e-05, 'params': 514193, 'time_iter': 0.0662, 'accuracy': 0.97094, 'precision': 0.7363, 'recall': 0.34903, 'f1': 0.47357, 'auc': 0.86465}
2025-08-16 08:24:03,531 - INFO - val: {'epoch': 29, 'time_epoch': 4.4603, 'loss': 0.08561957, 'lr': 0, 'params': 514193, 'time_iter': 0.03458, 'accuracy': 0.97982, 'precision': 0.47368, 'recall': 0.22222, 'f1': 0.30252, 'auc': 0.74159}
2025-08-16 08:24:07,876 - INFO - test: {'epoch': 29, 'time_epoch': 4.32683, 'loss': 0.12341068, 'lr': 0, 'params': 514193, 'time_iter': 0.03354, 'accuracy': 0.96912, 'precision': 0.53659, 'recall': 0.16923, 'f1': 0.25731, 'auc': 0.74395}
2025-08-16 08:24:07,877 - INFO - > Epoch 29: took 77.1s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:25:16,567 - INFO - train: {'epoch': 30, 'time_epoch': 68.57802, 'eta': 4696.85496, 'eta_hours': 1.30468, 'loss': 0.1031648, 'lr': 8.386e-05, 'params': 514193, 'time_iter': 0.06665, 'accuracy': 0.97067, 'precision': 0.72978, 'recall': 0.34416, 'f1': 0.46773, 'auc': 0.8777}
2025-08-16 08:25:20,865 - INFO - val: {'epoch': 30, 'time_epoch': 4.27608, 'loss': 0.08401264, 'lr': 0, 'params': 514193, 'time_iter': 0.03315, 'accuracy': 0.98104, 'precision': 0.54839, 'recall': 0.20988, 'f1': 0.30357, 'auc': 0.77745}
2025-08-16 08:25:25,059 - INFO - test: {'epoch': 30, 'time_epoch': 4.17614, 'loss': 0.1249798, 'lr': 0, 'params': 514193, 'time_iter': 0.03237, 'accuracy': 0.96912, 'precision': 0.54545, 'recall': 0.13846, 'f1': 0.22086, 'auc': 0.75953}
2025-08-16 08:25:25,061 - INFO - > Epoch 30: took 77.2s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:26:32,568 - INFO - train: {'epoch': 31, 'time_epoch': 67.39584, 'eta': 4627.35123, 'eta_hours': 1.28538, 'loss': 0.10209536, 'lr': 8.263e-05, 'params': 514193, 'time_iter': 0.0655, 'accuracy': 0.97122, 'precision': 0.73869, 'recall': 0.35795, 'f1': 0.48223, 'auc': 0.87501}
2025-08-16 08:26:36,616 - INFO - val: {'epoch': 31, 'time_epoch': 4.02634, 'loss': 0.08717681, 'lr': 0, 'params': 514193, 'time_iter': 0.03121, 'accuracy': 0.97958, 'precision': 0.4717, 'recall': 0.30864, 'f1': 0.37313, 'auc': 0.74058}
2025-08-16 08:26:40,725 - INFO - test: {'epoch': 31, 'time_epoch': 4.08997, 'loss': 0.12280702, 'lr': 0, 'params': 514193, 'time_iter': 0.03171, 'accuracy': 0.96669, 'precision': 0.45882, 'recall': 0.3, 'f1': 0.36279, 'auc': 0.75171}
2025-08-16 08:26:40,728 - INFO - > Epoch 31: took 75.7s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:27:49,539 - INFO - train: {'epoch': 32, 'time_epoch': 68.69894, 'eta': 4560.62096, 'eta_hours': 1.26684, 'loss': 0.1027797, 'lr': 8.136e-05, 'params': 514193, 'time_iter': 0.06676, 'accuracy': 0.97122, 'precision': 0.74112, 'recall': 0.35552, 'f1': 0.48053, 'auc': 0.87861}
2025-08-16 08:27:53,969 - INFO - val: {'epoch': 32, 'time_epoch': 4.39449, 'loss': 0.08296358, 'lr': 0, 'params': 514193, 'time_iter': 0.03407, 'accuracy': 0.98152, 'precision': 0.5641, 'recall': 0.2716, 'f1': 0.36667, 'auc': 0.74599}
2025-08-16 08:27:58,346 - INFO - test: {'epoch': 32, 'time_epoch': 4.35897, 'loss': 0.12246752, 'lr': 0, 'params': 514193, 'time_iter': 0.03379, 'accuracy': 0.96985, 'precision': 0.5625, 'recall': 0.20769, 'f1': 0.30337, 'auc': 0.73338}
2025-08-16 08:27:58,348 - INFO - > Epoch 32: took 77.6s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:29:05,982 - INFO - train: {'epoch': 33, 'time_epoch': 67.52111, 'eta': 4491.48851, 'eta_hours': 1.24764, 'loss': 0.10071733, 'lr': 8.005e-05, 'params': 514193, 'time_iter': 0.06562, 'accuracy': 0.97179, 'precision': 0.74595, 'recall': 0.37419, 'f1': 0.49838, 'auc': 0.88379}
2025-08-16 08:29:10,313 - INFO - val: {'epoch': 33, 'time_epoch': 4.30311, 'loss': 0.09258155, 'lr': 0, 'params': 514193, 'time_iter': 0.03336, 'accuracy': 0.9769, 'precision': 0.39394, 'recall': 0.32099, 'f1': 0.35374, 'auc': 0.77123}
2025-08-16 08:29:14,454 - INFO - test: {'epoch': 33, 'time_epoch': 4.1217, 'loss': 0.12735655, 'lr': 0, 'params': 514193, 'time_iter': 0.03195, 'accuracy': 0.96402, 'precision': 0.40625, 'recall': 0.3, 'f1': 0.34513, 'auc': 0.76606}
2025-08-16 08:29:14,457 - INFO - > Epoch 33: took 76.1s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:30:24,002 - INFO - train: {'epoch': 34, 'time_epoch': 69.42987, 'eta': 4425.99296, 'eta_hours': 1.22944, 'loss': 0.10085585, 'lr': 7.872e-05, 'params': 514193, 'time_iter': 0.06747, 'accuracy': 0.9714, 'precision': 0.72913, 'recall': 0.37581, 'f1': 0.49598, 'auc': 0.88173}
2025-08-16 08:30:28,247 - INFO - val: {'epoch': 34, 'time_epoch': 4.2206, 'loss': 0.08130112, 'lr': 0, 'params': 514193, 'time_iter': 0.03272, 'accuracy': 0.98104, 'precision': 0.53488, 'recall': 0.28395, 'f1': 0.37097, 'auc': 0.78862}
2025-08-16 08:30:32,341 - INFO - test: {'epoch': 34, 'time_epoch': 4.07634, 'loss': 0.12767627, 'lr': 0, 'params': 514193, 'time_iter': 0.0316, 'accuracy': 0.96791, 'precision': 0.47368, 'recall': 0.13846, 'f1': 0.21429, 'auc': 0.76239}
2025-08-16 08:30:32,343 - INFO - > Epoch 34: took 77.9s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:31:39,716 - INFO - train: {'epoch': 35, 'time_epoch': 67.26404, 'eta': 4356.42847, 'eta_hours': 1.21012, 'loss': 0.10068687, 'lr': 7.735e-05, 'params': 514193, 'time_iter': 0.06537, 'accuracy': 0.97152, 'precision': 0.74062, 'recall': 0.36851, 'f1': 0.49214, 'auc': 0.88537}
2025-08-16 08:31:44,050 - INFO - val: {'epoch': 35, 'time_epoch': 4.31026, 'loss': 0.08617151, 'lr': 0, 'params': 514193, 'time_iter': 0.03341, 'accuracy': 0.97642, 'precision': 0.37097, 'recall': 0.28395, 'f1': 0.32168, 'auc': 0.79369}
2025-08-16 08:31:48,223 - INFO - test: {'epoch': 35, 'time_epoch': 4.15507, 'loss': 0.127088, 'lr': 0, 'params': 514193, 'time_iter': 0.03221, 'accuracy': 0.96718, 'precision': 0.45763, 'recall': 0.20769, 'f1': 0.28571, 'auc': 0.75442}
2025-08-16 08:31:48,226 - INFO - > Epoch 35: took 75.9s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:32:56,693 - INFO - train: {'epoch': 36, 'time_epoch': 68.35663, 'eta': 4288.84868, 'eta_hours': 1.19135, 'loss': 0.09793902, 'lr': 7.595e-05, 'params': 514193, 'time_iter': 0.06643, 'accuracy': 0.97167, 'precision': 0.72388, 'recall': 0.39367, 'f1': 0.50999, 'auc': 0.89667}
2025-08-16 08:33:00,916 - INFO - val: {'epoch': 36, 'time_epoch': 4.2009, 'loss': 0.07926303, 'lr': 0, 'params': 514193, 'time_iter': 0.03257, 'accuracy': 0.98006, 'precision': 0.4898, 'recall': 0.2963, 'f1': 0.36923, 'auc': 0.79235}
2025-08-16 08:33:05,078 - INFO - test: {'epoch': 36, 'time_epoch': 4.14419, 'loss': 0.13101865, 'lr': 0, 'params': 514193, 'time_iter': 0.03213, 'accuracy': 0.96645, 'precision': 0.43103, 'recall': 0.19231, 'f1': 0.26596, 'auc': 0.74372}
2025-08-16 08:33:05,080 - INFO - > Epoch 36: took 76.9s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:34:13,312 - INFO - train: {'epoch': 37, 'time_epoch': 68.12145, 'eta': 4220.84431, 'eta_hours': 1.17246, 'loss': 0.09703861, 'lr': 7.452e-05, 'params': 514193, 'time_iter': 0.0662, 'accuracy': 0.97234, 'precision': 0.75394, 'recall': 0.38799, 'f1': 0.51233, 'auc': 0.89722}
2025-08-16 08:34:17,577 - INFO - val: {'epoch': 37, 'time_epoch': 4.24369, 'loss': 0.08760654, 'lr': 0, 'params': 514193, 'time_iter': 0.0329, 'accuracy': 0.97763, 'precision': 0.40984, 'recall': 0.30864, 'f1': 0.35211, 'auc': 0.78057}
2025-08-16 08:34:21,748 - INFO - test: {'epoch': 37, 'time_epoch': 4.15354, 'loss': 0.12963716, 'lr': 0, 'params': 514193, 'time_iter': 0.0322, 'accuracy': 0.96766, 'precision': 0.47887, 'recall': 0.26154, 'f1': 0.33831, 'auc': 0.7482}
2025-08-16 08:34:21,750 - INFO - > Epoch 37: took 76.7s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:35:31,312 - INFO - train: {'epoch': 38, 'time_epoch': 69.45124, 'eta': 4154.91385, 'eta_hours': 1.15414, 'loss': 0.09591488, 'lr': 7.307e-05, 'params': 514193, 'time_iter': 0.06749, 'accuracy': 0.97301, 'precision': 0.76543, 'recall': 0.4026, 'f1': 0.52766, 'auc': 0.90389}
2025-08-16 08:35:35,511 - INFO - val: {'epoch': 38, 'time_epoch': 4.17431, 'loss': 0.09128054, 'lr': 0, 'params': 514193, 'time_iter': 0.03236, 'accuracy': 0.97982, 'precision': 0.48, 'recall': 0.2963, 'f1': 0.36641, 'auc': 0.75038}
2025-08-16 08:35:39,659 - INFO - test: {'epoch': 38, 'time_epoch': 4.13028, 'loss': 0.13638835, 'lr': 0, 'params': 514193, 'time_iter': 0.03202, 'accuracy': 0.96329, 'precision': 0.37647, 'recall': 0.24615, 'f1': 0.29767, 'auc': 0.72617}
2025-08-16 08:35:39,662 - INFO - > Epoch 38: took 77.9s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:36:46,773 - INFO - train: {'epoch': 39, 'time_epoch': 67.00195, 'eta': 4085.13342, 'eta_hours': 1.13476, 'loss': 0.09501676, 'lr': 7.159e-05, 'params': 514193, 'time_iter': 0.06511, 'accuracy': 0.97277, 'precision': 0.7561, 'recall': 0.4026, 'f1': 0.52542, 'auc': 0.90228}
2025-08-16 08:36:51,017 - INFO - val: {'epoch': 39, 'time_epoch': 4.22031, 'loss': 0.08068233, 'lr': 0, 'params': 514193, 'time_iter': 0.03272, 'accuracy': 0.98201, 'precision': 0.6, 'recall': 0.25926, 'f1': 0.36207, 'auc': 0.78023}
2025-08-16 08:36:55,195 - INFO - test: {'epoch': 39, 'time_epoch': 4.15766, 'loss': 0.13349715, 'lr': 0, 'params': 514193, 'time_iter': 0.03223, 'accuracy': 0.96766, 'precision': 0.46154, 'recall': 0.13846, 'f1': 0.21302, 'auc': 0.73237}
2025-08-16 08:36:55,198 - INFO - > Epoch 39: took 75.5s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:38:04,653 - INFO - train: {'epoch': 40, 'time_epoch': 69.33959, 'eta': 4018.85244, 'eta_hours': 1.11635, 'loss': 0.09479822, 'lr': 7.008e-05, 'params': 514193, 'time_iter': 0.06739, 'accuracy': 0.97255, 'precision': 0.75906, 'recall': 0.39123, 'f1': 0.51634, 'auc': 0.90678}
2025-08-16 08:38:09,185 - INFO - val: {'epoch': 40, 'time_epoch': 4.50731, 'loss': 0.09642565, 'lr': 0, 'params': 514193, 'time_iter': 0.03494, 'accuracy': 0.9752, 'precision': 0.36709, 'recall': 0.35802, 'f1': 0.3625, 'auc': 0.76806}
2025-08-16 08:38:13,571 - INFO - test: {'epoch': 40, 'time_epoch': 4.36789, 'loss': 0.14387693, 'lr': 0, 'params': 514193, 'time_iter': 0.03386, 'accuracy': 0.95891, 'precision': 0.31776, 'recall': 0.26154, 'f1': 0.28692, 'auc': 0.75041}
2025-08-16 08:38:13,574 - INFO - > Epoch 40: took 78.4s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:39:21,574 - INFO - train: {'epoch': 41, 'time_epoch': 67.88047, 'eta': 3950.41084, 'eta_hours': 1.09734, 'loss': 0.09473435, 'lr': 6.856e-05, 'params': 514193, 'time_iter': 0.06597, 'accuracy': 0.97271, 'precision': 0.75932, 'recall': 0.39692, 'f1': 0.52132, 'auc': 0.90865}
2025-08-16 08:39:25,915 - INFO - val: {'epoch': 41, 'time_epoch': 4.31649, 'loss': 0.08194149, 'lr': 0, 'params': 514193, 'time_iter': 0.03346, 'accuracy': 0.98128, 'precision': 0.54545, 'recall': 0.2963, 'f1': 0.384, 'auc': 0.79526}
2025-08-16 08:39:30,132 - INFO - test: {'epoch': 41, 'time_epoch': 4.19997, 'loss': 0.13624458, 'lr': 0, 'params': 514193, 'time_iter': 0.03256, 'accuracy': 0.96718, 'precision': 0.44444, 'recall': 0.15385, 'f1': 0.22857, 'auc': 0.73279}
2025-08-16 08:39:30,134 - INFO - > Epoch 41: took 76.6s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:40:38,736 - INFO - train: {'epoch': 42, 'time_epoch': 68.48815, 'eta': 3882.80088, 'eta_hours': 1.07856, 'loss': 0.09203352, 'lr': 6.701e-05, 'params': 514193, 'time_iter': 0.06656, 'accuracy': 0.97292, 'precision': 0.76271, 'recall': 0.40179, 'f1': 0.52632, 'auc': 0.91644}
2025-08-16 08:40:43,123 - INFO - val: {'epoch': 42, 'time_epoch': 4.36443, 'loss': 0.0835877, 'lr': 0, 'params': 514193, 'time_iter': 0.03383, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.2716, 'f1': 0.352, 'auc': 0.7723}
2025-08-16 08:40:47,357 - INFO - test: {'epoch': 42, 'time_epoch': 4.21503, 'loss': 0.13956678, 'lr': 0, 'params': 514193, 'time_iter': 0.03267, 'accuracy': 0.96718, 'precision': 0.4359, 'recall': 0.13077, 'f1': 0.20118, 'auc': 0.72829}
2025-08-16 08:40:47,359 - INFO - > Epoch 42: took 77.2s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:41:55,054 - INFO - train: {'epoch': 43, 'time_epoch': 67.58734, 'eta': 3814.00451, 'eta_hours': 1.05945, 'loss': 0.09212941, 'lr': 6.545e-05, 'params': 514193, 'time_iter': 0.06568, 'accuracy': 0.97344, 'precision': 0.76958, 'recall': 0.41477, 'f1': 0.53903, 'auc': 0.91051}
2025-08-16 08:41:59,170 - INFO - val: {'epoch': 43, 'time_epoch': 4.09331, 'loss': 0.1033563, 'lr': 0, 'params': 514193, 'time_iter': 0.03173, 'accuracy': 0.96985, 'precision': 0.28713, 'recall': 0.35802, 'f1': 0.31868, 'auc': 0.75933}
2025-08-16 08:42:03,229 - INFO - test: {'epoch': 43, 'time_epoch': 4.04148, 'loss': 0.14779697, 'lr': 0, 'params': 514193, 'time_iter': 0.03133, 'accuracy': 0.96061, 'precision': 0.35455, 'recall': 0.3, 'f1': 0.325, 'auc': 0.74385}
2025-08-16 08:42:03,232 - INFO - > Epoch 43: took 75.9s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:43:10,343 - INFO - train: {'epoch': 44, 'time_epoch': 66.99602, 'eta': 3744.53915, 'eta_hours': 1.04015, 'loss': 0.09081913, 'lr': 6.387e-05, 'params': 514193, 'time_iter': 0.06511, 'accuracy': 0.97341, 'precision': 0.76762, 'recall': 0.41558, 'f1': 0.53923, 'auc': 0.91498}
2025-08-16 08:43:14,647 - INFO - val: {'epoch': 44, 'time_epoch': 4.28112, 'loss': 0.10653817, 'lr': 0, 'params': 514193, 'time_iter': 0.03319, 'accuracy': 0.97034, 'precision': 0.30841, 'recall': 0.40741, 'f1': 0.35106, 'auc': 0.77921}
2025-08-16 08:43:18,902 - INFO - test: {'epoch': 44, 'time_epoch': 4.23714, 'loss': 0.15223369, 'lr': 0, 'params': 514193, 'time_iter': 0.03285, 'accuracy': 0.95794, 'precision': 0.33071, 'recall': 0.32308, 'f1': 0.32685, 'auc': 0.74176}
2025-08-16 08:43:18,906 - INFO - > Epoch 44: took 75.7s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:44:29,031 - INFO - train: {'epoch': 45, 'time_epoch': 70.01082, 'eta': 3678.72026, 'eta_hours': 1.02187, 'loss': 0.08970575, 'lr': 6.227e-05, 'params': 514193, 'time_iter': 0.06804, 'accuracy': 0.97386, 'precision': 0.77353, 'recall': 0.42695, 'f1': 0.55021, 'auc': 0.92026}
2025-08-16 08:44:33,469 - INFO - val: {'epoch': 45, 'time_epoch': 4.41434, 'loss': 0.09199951, 'lr': 0, 'params': 514193, 'time_iter': 0.03422, 'accuracy': 0.97739, 'precision': 0.40909, 'recall': 0.33333, 'f1': 0.36735, 'auc': 0.77201}
2025-08-16 08:44:37,839 - INFO - test: {'epoch': 45, 'time_epoch': 4.35137, 'loss': 0.15007874, 'lr': 0, 'params': 514193, 'time_iter': 0.03373, 'accuracy': 0.96548, 'precision': 0.38462, 'recall': 0.15385, 'f1': 0.21978, 'auc': 0.71658}
2025-08-16 08:44:37,842 - INFO - > Epoch 45: took 78.9s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:45:46,962 - INFO - train: {'epoch': 46, 'time_epoch': 69.01278, 'eta': 3611.59755, 'eta_hours': 1.00322, 'loss': 0.08981267, 'lr': 6.066e-05, 'params': 514193, 'time_iter': 0.06707, 'accuracy': 0.97407, 'precision': 0.77033, 'recall': 0.43831, 'f1': 0.55872, 'auc': 0.92224}
2025-08-16 08:45:51,125 - INFO - val: {'epoch': 46, 'time_epoch': 4.14095, 'loss': 0.09264587, 'lr': 0, 'params': 514193, 'time_iter': 0.0321, 'accuracy': 0.97763, 'precision': 0.4127, 'recall': 0.32099, 'f1': 0.36111, 'auc': 0.77815}
2025-08-16 08:45:55,167 - INFO - test: {'epoch': 46, 'time_epoch': 4.02419, 'loss': 0.14526932, 'lr': 0, 'params': 514193, 'time_iter': 0.0312, 'accuracy': 0.96693, 'precision': 0.44444, 'recall': 0.18462, 'f1': 0.26087, 'auc': 0.72886}
2025-08-16 08:45:55,169 - INFO - > Epoch 46: took 77.3s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:47:02,791 - INFO - train: {'epoch': 47, 'time_epoch': 67.50928, 'eta': 3542.76729, 'eta_hours': 0.9841, 'loss': 0.08972625, 'lr': 5.904e-05, 'params': 514193, 'time_iter': 0.06561, 'accuracy': 0.97441, 'precision': 0.78761, 'recall': 0.43344, 'f1': 0.55916, 'auc': 0.92016}
2025-08-16 08:47:07,121 - INFO - val: {'epoch': 47, 'time_epoch': 4.30394, 'loss': 0.10660023, 'lr': 0, 'params': 514193, 'time_iter': 0.03336, 'accuracy': 0.96985, 'precision': 0.27368, 'recall': 0.32099, 'f1': 0.29545, 'auc': 0.75391}
2025-08-16 08:47:11,297 - INFO - test: {'epoch': 47, 'time_epoch': 4.15613, 'loss': 0.14349079, 'lr': 0, 'params': 514193, 'time_iter': 0.03222, 'accuracy': 0.96548, 'precision': 0.43617, 'recall': 0.31538, 'f1': 0.36607, 'auc': 0.72523}
2025-08-16 08:47:11,300 - INFO - > Epoch 47: took 76.1s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:48:18,719 - INFO - train: {'epoch': 48, 'time_epoch': 67.30497, 'eta': 3473.7783, 'eta_hours': 0.96494, 'loss': 0.09008372, 'lr': 5.741e-05, 'params': 514193, 'time_iter': 0.06541, 'accuracy': 0.9742, 'precision': 0.77956, 'recall': 0.43344, 'f1': 0.55712, 'auc': 0.91718}
2025-08-16 08:48:23,085 - INFO - val: {'epoch': 48, 'time_epoch': 4.34206, 'loss': 0.09443125, 'lr': 0, 'params': 514193, 'time_iter': 0.03366, 'accuracy': 0.97642, 'precision': 0.38889, 'recall': 0.34568, 'f1': 0.36601, 'auc': 0.78132}
2025-08-16 08:48:27,276 - INFO - test: {'epoch': 48, 'time_epoch': 4.17507, 'loss': 0.14103942, 'lr': 0, 'params': 514193, 'time_iter': 0.03236, 'accuracy': 0.96548, 'precision': 0.41176, 'recall': 0.21538, 'f1': 0.28283, 'auc': 0.73871}
2025-08-16 08:48:27,279 - INFO - > Epoch 48: took 76.0s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:49:33,373 - INFO - train: {'epoch': 49, 'time_epoch': 65.98378, 'eta': 3403.53548, 'eta_hours': 0.94543, 'loss': 0.08906567, 'lr': 5.577e-05, 'params': 514193, 'time_iter': 0.06412, 'accuracy': 0.97347, 'precision': 0.76672, 'recall': 0.41883, 'f1': 0.54173, 'auc': 0.92467}
2025-08-16 08:49:37,548 - INFO - val: {'epoch': 49, 'time_epoch': 4.15317, 'loss': 0.10035571, 'lr': 0, 'params': 514193, 'time_iter': 0.0322, 'accuracy': 0.9735, 'precision': 0.325, 'recall': 0.32099, 'f1': 0.32298, 'auc': 0.78474}
2025-08-16 08:49:41,696 - INFO - test: {'epoch': 49, 'time_epoch': 4.13068, 'loss': 0.14737212, 'lr': 0, 'params': 514193, 'time_iter': 0.03202, 'accuracy': 0.96329, 'precision': 0.37037, 'recall': 0.23077, 'f1': 0.28436, 'auc': 0.73171}
2025-08-16 08:49:41,698 - INFO - > Epoch 49: took 74.4s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:50:49,949 - INFO - train: {'epoch': 50, 'time_epoch': 68.13618, 'eta': 3335.52768, 'eta_hours': 0.92654, 'loss': 0.0867095, 'lr': 5.413e-05, 'params': 514193, 'time_iter': 0.06622, 'accuracy': 0.9745, 'precision': 0.7894, 'recall': 0.43506, 'f1': 0.56096, 'auc': 0.92619}
2025-08-16 08:50:54,564 - INFO - val: {'epoch': 50, 'time_epoch': 4.59018, 'loss': 0.11035112, 'lr': 0, 'params': 514193, 'time_iter': 0.03558, 'accuracy': 0.96839, 'precision': 0.28696, 'recall': 0.40741, 'f1': 0.33673, 'auc': 0.79059}
2025-08-16 08:50:59,061 - INFO - test: {'epoch': 50, 'time_epoch': 4.47839, 'loss': 0.15471558, 'lr': 0, 'params': 514193, 'time_iter': 0.03472, 'accuracy': 0.95745, 'precision': 0.32824, 'recall': 0.33077, 'f1': 0.3295, 'auc': 0.74612}
2025-08-16 08:50:59,063 - INFO - > Epoch 50: took 77.4s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:52:09,248 - INFO - train: {'epoch': 51, 'time_epoch': 70.06896, 'eta': 3269.29904, 'eta_hours': 0.90814, 'loss': 0.08635664, 'lr': 5.248e-05, 'params': 514193, 'time_iter': 0.06809, 'accuracy': 0.97423, 'precision': 0.77042, 'recall': 0.44399, 'f1': 0.56334, 'auc': 0.93102}
2025-08-16 08:52:13,552 - INFO - val: {'epoch': 51, 'time_epoch': 4.28139, 'loss': 0.09046934, 'lr': 0, 'params': 514193, 'time_iter': 0.03319, 'accuracy': 0.97885, 'precision': 0.44828, 'recall': 0.32099, 'f1': 0.3741, 'auc': 0.77395}
2025-08-16 08:52:17,786 - INFO - test: {'epoch': 51, 'time_epoch': 4.21501, 'loss': 0.14196128, 'lr': 0, 'params': 514193, 'time_iter': 0.03267, 'accuracy': 0.96791, 'precision': 0.48214, 'recall': 0.20769, 'f1': 0.29032, 'auc': 0.72397}
2025-08-16 08:52:17,789 - INFO - > Epoch 51: took 78.7s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:53:26,024 - INFO - train: {'epoch': 52, 'time_epoch': 68.12364, 'eta': 3201.20039, 'eta_hours': 0.88922, 'loss': 0.08526814, 'lr': 5.083e-05, 'params': 514193, 'time_iter': 0.0662, 'accuracy': 0.97459, 'precision': 0.77809, 'recall': 0.44968, 'f1': 0.56996, 'auc': 0.93226}
2025-08-16 08:53:30,262 - INFO - val: {'epoch': 52, 'time_epoch': 4.21366, 'loss': 0.10181755, 'lr': 0, 'params': 514193, 'time_iter': 0.03266, 'accuracy': 0.97228, 'precision': 0.30588, 'recall': 0.32099, 'f1': 0.31325, 'auc': 0.77507}
2025-08-16 08:53:34,502 - INFO - test: {'epoch': 52, 'time_epoch': 4.22192, 'loss': 0.14964862, 'lr': 0, 'params': 514193, 'time_iter': 0.03273, 'accuracy': 0.96523, 'precision': 0.41333, 'recall': 0.23846, 'f1': 0.30244, 'auc': 0.73387}
2025-08-16 08:53:34,504 - INFO - > Epoch 52: took 76.7s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:54:44,405 - INFO - train: {'epoch': 53, 'time_epoch': 69.78554, 'eta': 3134.5165, 'eta_hours': 0.8707, 'loss': 0.0828006, 'lr': 4.917e-05, 'params': 514193, 'time_iter': 0.06782, 'accuracy': 0.97465, 'precision': 0.7726, 'recall': 0.45779, 'f1': 0.57492, 'auc': 0.94022}
2025-08-16 08:54:48,931 - INFO - val: {'epoch': 53, 'time_epoch': 4.50296, 'loss': 0.11704443, 'lr': 0, 'params': 514193, 'time_iter': 0.03491, 'accuracy': 0.96669, 'precision': 0.25439, 'recall': 0.35802, 'f1': 0.29744, 'auc': 0.77025}
2025-08-16 08:54:53,266 - INFO - test: {'epoch': 53, 'time_epoch': 4.31642, 'loss': 0.1662065, 'lr': 0, 'params': 514193, 'time_iter': 0.03346, 'accuracy': 0.95672, 'precision': 0.29661, 'recall': 0.26923, 'f1': 0.28226, 'auc': 0.72256}
2025-08-16 08:54:53,269 - INFO - > Epoch 53: took 78.8s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:56:01,221 - INFO - train: {'epoch': 54, 'time_epoch': 67.84329, 'eta': 3066.13072, 'eta_hours': 0.8517, 'loss': 0.08393077, 'lr': 4.752e-05, 'params': 514193, 'time_iter': 0.06593, 'accuracy': 0.97453, 'precision': 0.7721, 'recall': 0.45373, 'f1': 0.57157, 'auc': 0.93472}
2025-08-16 08:56:05,305 - INFO - val: {'epoch': 54, 'time_epoch': 4.06198, 'loss': 0.0932538, 'lr': 0, 'params': 514193, 'time_iter': 0.03149, 'accuracy': 0.97715, 'precision': 0.4, 'recall': 0.32099, 'f1': 0.35616, 'auc': 0.76341}
2025-08-16 08:56:09,386 - INFO - test: {'epoch': 54, 'time_epoch': 4.06418, 'loss': 0.1449642, 'lr': 0, 'params': 514193, 'time_iter': 0.03151, 'accuracy': 0.96961, 'precision': 0.54717, 'recall': 0.22308, 'f1': 0.31694, 'auc': 0.71808}
2025-08-16 08:56:09,389 - INFO - > Epoch 54: took 76.1s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:57:16,416 - INFO - train: {'epoch': 55, 'time_epoch': 66.91451, 'eta': 2997.03455, 'eta_hours': 0.83251, 'loss': 0.08286752, 'lr': 4.587e-05, 'params': 514193, 'time_iter': 0.06503, 'accuracy': 0.9759, 'precision': 0.80699, 'recall': 0.46834, 'f1': 0.59271, 'auc': 0.93479}
2025-08-16 08:57:20,694 - INFO - val: {'epoch': 55, 'time_epoch': 4.25116, 'loss': 0.09039874, 'lr': 0, 'params': 514193, 'time_iter': 0.03295, 'accuracy': 0.97958, 'precision': 0.47458, 'recall': 0.34568, 'f1': 0.4, 'auc': 0.75664}
2025-08-16 08:57:24,856 - INFO - test: {'epoch': 55, 'time_epoch': 4.13635, 'loss': 0.14652843, 'lr': 0, 'params': 514193, 'time_iter': 0.03206, 'accuracy': 0.96742, 'precision': 0.46429, 'recall': 0.2, 'f1': 0.27957, 'auc': 0.72761}
2025-08-16 08:57:24,860 - INFO - > Epoch 55: took 75.5s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:58:33,790 - INFO - train: {'epoch': 56, 'time_epoch': 68.81654, 'eta': 2929.4498, 'eta_hours': 0.81374, 'loss': 0.08483725, 'lr': 4.423e-05, 'params': 514193, 'time_iter': 0.06688, 'accuracy': 0.97526, 'precision': 0.79772, 'recall': 0.45455, 'f1': 0.57911, 'auc': 0.93063}
2025-08-16 08:58:38,163 - INFO - val: {'epoch': 56, 'time_epoch': 4.34828, 'loss': 0.09385246, 'lr': 0, 'params': 514193, 'time_iter': 0.03371, 'accuracy': 0.97739, 'precision': 0.39655, 'recall': 0.28395, 'f1': 0.33094, 'auc': 0.76341}
2025-08-16 08:58:42,409 - INFO - test: {'epoch': 56, 'time_epoch': 4.22062, 'loss': 0.14935039, 'lr': 0, 'params': 514193, 'time_iter': 0.03272, 'accuracy': 0.96645, 'precision': 0.42593, 'recall': 0.17692, 'f1': 0.25, 'auc': 0.73787}
2025-08-16 08:58:42,414 - INFO - > Epoch 56: took 77.6s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 08:59:49,400 - INFO - train: {'epoch': 57, 'time_epoch': 66.87371, 'eta': 2860.41569, 'eta_hours': 0.79456, 'loss': 0.08183903, 'lr': 4.259e-05, 'params': 514193, 'time_iter': 0.06499, 'accuracy': 0.97547, 'precision': 0.79391, 'recall': 0.46591, 'f1': 0.58721, 'auc': 0.94}
2025-08-16 08:59:53,659 - INFO - val: {'epoch': 57, 'time_epoch': 4.23409, 'loss': 0.09527176, 'lr': 0, 'params': 514193, 'time_iter': 0.03282, 'accuracy': 0.97642, 'precision': 0.39189, 'recall': 0.35802, 'f1': 0.37419, 'auc': 0.78208}
2025-08-16 08:59:57,890 - INFO - test: {'epoch': 57, 'time_epoch': 4.21383, 'loss': 0.15308674, 'lr': 0, 'params': 514193, 'time_iter': 0.03267, 'accuracy': 0.96499, 'precision': 0.39706, 'recall': 0.20769, 'f1': 0.27273, 'auc': 0.73353}
2025-08-16 08:59:57,893 - INFO - > Epoch 57: took 75.5s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:01:06,379 - INFO - train: {'epoch': 58, 'time_epoch': 68.37033, 'eta': 2792.49485, 'eta_hours': 0.77569, 'loss': 0.08047123, 'lr': 4.096e-05, 'params': 514193, 'time_iter': 0.06644, 'accuracy': 0.97635, 'precision': 0.82336, 'recall': 0.46916, 'f1': 0.59772, 'auc': 0.94002}
2025-08-16 09:01:10,724 - INFO - val: {'epoch': 58, 'time_epoch': 4.32123, 'loss': 0.09074576, 'lr': 0, 'params': 514193, 'time_iter': 0.0335, 'accuracy': 0.97958, 'precision': 0.47458, 'recall': 0.34568, 'f1': 0.4, 'auc': 0.78191}
2025-08-16 09:01:14,902 - INFO - test: {'epoch': 58, 'time_epoch': 4.15915, 'loss': 0.15232265, 'lr': 0, 'params': 514193, 'time_iter': 0.03224, 'accuracy': 0.96766, 'precision': 0.47059, 'recall': 0.18462, 'f1': 0.26519, 'auc': 0.72524}
2025-08-16 09:01:14,905 - INFO - > Epoch 58: took 77.0s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:02:22,355 - INFO - train: {'epoch': 59, 'time_epoch': 67.33769, 'eta': 2723.87059, 'eta_hours': 0.75663, 'loss': 0.07967868, 'lr': 3.934e-05, 'params': 514193, 'time_iter': 0.06544, 'accuracy': 0.9755, 'precision': 0.77734, 'recall': 0.48458, 'f1': 0.597, 'auc': 0.94602}
2025-08-16 09:02:26,597 - INFO - val: {'epoch': 59, 'time_epoch': 4.21723, 'loss': 0.09535295, 'lr': 0, 'params': 514193, 'time_iter': 0.03269, 'accuracy': 0.97739, 'precision': 0.40909, 'recall': 0.33333, 'f1': 0.36735, 'auc': 0.78146}
2025-08-16 09:02:30,791 - INFO - test: {'epoch': 59, 'time_epoch': 4.17487, 'loss': 0.15383166, 'lr': 0, 'params': 514193, 'time_iter': 0.03236, 'accuracy': 0.96669, 'precision': 0.44068, 'recall': 0.2, 'f1': 0.27513, 'auc': 0.73102}
2025-08-16 09:02:30,794 - INFO - > Epoch 59: took 75.9s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:03:35,939 - INFO - train: {'epoch': 60, 'time_epoch': 65.02565, 'eta': 2653.81033, 'eta_hours': 0.73717, 'loss': 0.07945737, 'lr': 3.773e-05, 'params': 514193, 'time_iter': 0.06319, 'accuracy': 0.97593, 'precision': 0.7973, 'recall': 0.4789, 'f1': 0.59838, 'auc': 0.94538}
2025-08-16 09:03:40,161 - INFO - val: {'epoch': 60, 'time_epoch': 4.19731, 'loss': 0.09774405, 'lr': 0, 'params': 514193, 'time_iter': 0.03254, 'accuracy': 0.97374, 'precision': 0.33735, 'recall': 0.34568, 'f1': 0.34146, 'auc': 0.79619}
2025-08-16 09:03:44,290 - INFO - test: {'epoch': 60, 'time_epoch': 4.11194, 'loss': 0.15369246, 'lr': 0, 'params': 514193, 'time_iter': 0.03188, 'accuracy': 0.96377, 'precision': 0.3662, 'recall': 0.2, 'f1': 0.25871, 'auc': 0.74378}
2025-08-16 09:03:44,293 - INFO - > Epoch 60: took 73.5s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:04:51,590 - INFO - train: {'epoch': 61, 'time_epoch': 67.18304, 'eta': 2585.23474, 'eta_hours': 0.71812, 'loss': 0.0778809, 'lr': 3.613e-05, 'params': 514193, 'time_iter': 0.06529, 'accuracy': 0.97608, 'precision': 0.79548, 'recall': 0.4862, 'f1': 0.60353, 'auc': 0.94918}
2025-08-16 09:04:56,064 - INFO - val: {'epoch': 61, 'time_epoch': 4.45004, 'loss': 0.10541709, 'lr': 0, 'params': 514193, 'time_iter': 0.0345, 'accuracy': 0.97082, 'precision': 0.29897, 'recall': 0.35802, 'f1': 0.32584, 'auc': 0.78297}
2025-08-16 09:05:00,476 - INFO - test: {'epoch': 61, 'time_epoch': 4.39526, 'loss': 0.16728559, 'lr': 0, 'params': 514193, 'time_iter': 0.03407, 'accuracy': 0.95964, 'precision': 0.29545, 'recall': 0.2, 'f1': 0.23853, 'auc': 0.70453}
2025-08-16 09:05:02,473 - INFO - > Epoch 61: took 78.2s (avg 76.7s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:06:09,727 - INFO - train: {'epoch': 62, 'time_epoch': 67.1432, 'eta': 2516.67997, 'eta_hours': 0.69908, 'loss': 0.07600882, 'lr': 3.455e-05, 'params': 514193, 'time_iter': 0.06525, 'accuracy': 0.97678, 'precision': 0.81452, 'recall': 0.49188, 'f1': 0.61336, 'auc': 0.95196}
2025-08-16 09:06:13,823 - INFO - val: {'epoch': 62, 'time_epoch': 4.07309, 'loss': 0.10227909, 'lr': 0, 'params': 514193, 'time_iter': 0.03157, 'accuracy': 0.97277, 'precision': 0.33333, 'recall': 0.38272, 'f1': 0.35632, 'auc': 0.77807}
2025-08-16 09:06:17,921 - INFO - test: {'epoch': 62, 'time_epoch': 4.08138, 'loss': 0.15770025, 'lr': 0, 'params': 514193, 'time_iter': 0.03164, 'accuracy': 0.96231, 'precision': 0.36264, 'recall': 0.25385, 'f1': 0.29864, 'auc': 0.7236}
2025-08-16 09:06:17,924 - INFO - > Epoch 62: took 75.5s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:07:24,772 - INFO - train: {'epoch': 63, 'time_epoch': 66.7398, 'eta': 2447.94239, 'eta_hours': 0.67998, 'loss': 0.07922349, 'lr': 3.299e-05, 'params': 514193, 'time_iter': 0.06486, 'accuracy': 0.97568, 'precision': 0.78346, 'recall': 0.48458, 'f1': 0.5988, 'auc': 0.94696}
2025-08-16 09:07:28,922 - INFO - val: {'epoch': 63, 'time_epoch': 4.12644, 'loss': 0.10731382, 'lr': 0, 'params': 514193, 'time_iter': 0.03199, 'accuracy': 0.97423, 'precision': 0.33333, 'recall': 0.30864, 'f1': 0.32051, 'auc': 0.76831}
2025-08-16 09:07:32,996 - INFO - test: {'epoch': 63, 'time_epoch': 4.05555, 'loss': 0.16423857, 'lr': 0, 'params': 514193, 'time_iter': 0.03144, 'accuracy': 0.9662, 'precision': 0.44, 'recall': 0.25385, 'f1': 0.32195, 'auc': 0.70238}
2025-08-16 09:07:32,999 - INFO - > Epoch 63: took 75.1s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:08:42,147 - INFO - train: {'epoch': 64, 'time_epoch': 69.05687, 'eta': 2380.51393, 'eta_hours': 0.66125, 'loss': 0.07764568, 'lr': 3.144e-05, 'params': 514193, 'time_iter': 0.06711, 'accuracy': 0.9769, 'precision': 0.80334, 'recall': 0.50731, 'f1': 0.62189, 'auc': 0.94676}
2025-08-16 09:08:46,402 - INFO - val: {'epoch': 64, 'time_epoch': 4.23267, 'loss': 0.10183518, 'lr': 0, 'params': 514193, 'time_iter': 0.03281, 'accuracy': 0.97496, 'precision': 0.36585, 'recall': 0.37037, 'f1': 0.3681, 'auc': 0.77563}
2025-08-16 09:08:50,566 - INFO - test: {'epoch': 64, 'time_epoch': 4.14734, 'loss': 0.16194608, 'lr': 0, 'params': 514193, 'time_iter': 0.03215, 'accuracy': 0.96548, 'precision': 0.42857, 'recall': 0.27692, 'f1': 0.33645, 'auc': 0.71705}
2025-08-16 09:08:50,569 - INFO - > Epoch 64: took 77.6s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:09:57,169 - INFO - train: {'epoch': 65, 'time_epoch': 66.49203, 'eta': 2311.71485, 'eta_hours': 0.64214, 'loss': 0.07646771, 'lr': 2.992e-05, 'params': 514193, 'time_iter': 0.06462, 'accuracy': 0.9769, 'precision': 0.8172, 'recall': 0.49351, 'f1': 0.61538, 'auc': 0.95039}
2025-08-16 09:10:01,238 - INFO - val: {'epoch': 65, 'time_epoch': 4.04681, 'loss': 0.10163751, 'lr': 0, 'params': 514193, 'time_iter': 0.03137, 'accuracy': 0.97447, 'precision': 0.33333, 'recall': 0.2963, 'f1': 0.31373, 'auc': 0.77777}
2025-08-16 09:10:05,222 - INFO - test: {'epoch': 65, 'time_epoch': 3.96813, 'loss': 0.16161688, 'lr': 0, 'params': 514193, 'time_iter': 0.03076, 'accuracy': 0.96718, 'precision': 0.46269, 'recall': 0.23846, 'f1': 0.31472, 'auc': 0.721}
2025-08-16 09:10:05,225 - INFO - > Epoch 65: took 74.7s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:11:10,902 - INFO - train: {'epoch': 66, 'time_epoch': 65.56437, 'eta': 2242.52773, 'eta_hours': 0.62292, 'loss': 0.07664608, 'lr': 2.841e-05, 'params': 514193, 'time_iter': 0.06372, 'accuracy': 0.97666, 'precision': 0.8013, 'recall': 0.50081, 'f1': 0.61638, 'auc': 0.95125}
2025-08-16 09:11:15,218 - INFO - val: {'epoch': 66, 'time_epoch': 4.22208, 'loss': 0.10229335, 'lr': 0, 'params': 514193, 'time_iter': 0.03273, 'accuracy': 0.97228, 'precision': 0.3299, 'recall': 0.39506, 'f1': 0.35955, 'auc': 0.7757}
2025-08-16 09:11:19,362 - INFO - test: {'epoch': 66, 'time_epoch': 4.10235, 'loss': 0.16478607, 'lr': 0, 'params': 514193, 'time_iter': 0.0318, 'accuracy': 0.96183, 'precision': 0.36082, 'recall': 0.26923, 'f1': 0.30837, 'auc': 0.73117}
2025-08-16 09:11:19,386 - INFO - > Epoch 66: took 74.2s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:12:28,402 - INFO - train: {'epoch': 67, 'time_epoch': 68.87378, 'eta': 2175.00453, 'eta_hours': 0.60417, 'loss': 0.07449383, 'lr': 2.693e-05, 'params': 514193, 'time_iter': 0.06693, 'accuracy': 0.97705, 'precision': 0.7985, 'recall': 0.51786, 'f1': 0.62826, 'auc': 0.95365}
2025-08-16 09:12:32,310 - INFO - val: {'epoch': 67, 'time_epoch': 3.88591, 'loss': 0.10965766, 'lr': 0, 'params': 514193, 'time_iter': 0.03012, 'accuracy': 0.97058, 'precision': 0.31132, 'recall': 0.40741, 'f1': 0.35294, 'auc': 0.77297}
2025-08-16 09:12:36,174 - INFO - test: {'epoch': 67, 'time_epoch': 3.84862, 'loss': 0.16459057, 'lr': 0, 'params': 514193, 'time_iter': 0.02983, 'accuracy': 0.96159, 'precision': 0.35714, 'recall': 0.26923, 'f1': 0.30702, 'auc': 0.72465}
2025-08-16 09:12:36,177 - INFO - > Epoch 67: took 76.8s (avg 76.6s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:13:42,214 - INFO - train: {'epoch': 68, 'time_epoch': 65.9284, 'eta': 2106.1189, 'eta_hours': 0.58503, 'loss': 0.07596592, 'lr': 2.548e-05, 'params': 514193, 'time_iter': 0.06407, 'accuracy': 0.97623, 'precision': 0.7945, 'recall': 0.49269, 'f1': 0.60822, 'auc': 0.95458}
2025-08-16 09:13:46,272 - INFO - val: {'epoch': 68, 'time_epoch': 4.03678, 'loss': 0.11719669, 'lr': 0, 'params': 514193, 'time_iter': 0.03129, 'accuracy': 0.96596, 'precision': 0.27481, 'recall': 0.44444, 'f1': 0.33962, 'auc': 0.77571}
2025-08-16 09:13:50,140 - INFO - test: {'epoch': 68, 'time_epoch': 3.85121, 'loss': 0.17261361, 'lr': 0, 'params': 514193, 'time_iter': 0.02985, 'accuracy': 0.95842, 'precision': 0.33058, 'recall': 0.30769, 'f1': 0.31873, 'auc': 0.7203}
2025-08-16 09:13:50,142 - INFO - > Epoch 68: took 74.0s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:14:56,458 - INFO - train: {'epoch': 69, 'time_epoch': 66.20745, 'eta': 2037.43735, 'eta_hours': 0.56595, 'loss': 0.0728261, 'lr': 2.405e-05, 'params': 514193, 'time_iter': 0.06434, 'accuracy': 0.97733, 'precision': 0.80299, 'recall': 0.52273, 'f1': 0.63324, 'auc': 0.95842}
2025-08-16 09:15:00,755 - INFO - val: {'epoch': 69, 'time_epoch': 4.27382, 'loss': 0.10586629, 'lr': 0, 'params': 514193, 'time_iter': 0.03313, 'accuracy': 0.97374, 'precision': 0.34118, 'recall': 0.35802, 'f1': 0.3494, 'auc': 0.77255}
2025-08-16 09:15:04,943 - INFO - test: {'epoch': 69, 'time_epoch': 4.17086, 'loss': 0.16954742, 'lr': 0, 'params': 514193, 'time_iter': 0.03233, 'accuracy': 0.96329, 'precision': 0.38462, 'recall': 0.26923, 'f1': 0.31674, 'auc': 0.71557}
2025-08-16 09:15:04,945 - INFO - > Epoch 69: took 74.8s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:16:11,899 - INFO - train: {'epoch': 70, 'time_epoch': 66.84499, 'eta': 1969.0859, 'eta_hours': 0.54697, 'loss': 0.07484568, 'lr': 2.265e-05, 'params': 514193, 'time_iter': 0.06496, 'accuracy': 0.9776, 'precision': 0.81054, 'recall': 0.52435, 'f1': 0.63677, 'auc': 0.95261}
2025-08-16 09:16:15,921 - INFO - val: {'epoch': 70, 'time_epoch': 3.99691, 'loss': 0.12322808, 'lr': 0, 'params': 514193, 'time_iter': 0.03098, 'accuracy': 0.96475, 'precision': 0.26471, 'recall': 0.44444, 'f1': 0.3318, 'auc': 0.77609}
2025-08-16 09:16:19,821 - INFO - test: {'epoch': 70, 'time_epoch': 3.88332, 'loss': 0.18314964, 'lr': 0, 'params': 514193, 'time_iter': 0.0301, 'accuracy': 0.95648, 'precision': 0.304, 'recall': 0.29231, 'f1': 0.29804, 'auc': 0.71741}
2025-08-16 09:16:19,824 - INFO - > Epoch 70: took 74.9s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:17:25,620 - INFO - train: {'epoch': 71, 'time_epoch': 65.68753, 'eta': 1900.32617, 'eta_hours': 0.52787, 'loss': 0.07420603, 'lr': 2.128e-05, 'params': 514193, 'time_iter': 0.06384, 'accuracy': 0.9766, 'precision': 0.79464, 'recall': 0.50568, 'f1': 0.61806, 'auc': 0.95722}
2025-08-16 09:17:29,553 - INFO - val: {'epoch': 71, 'time_epoch': 3.91209, 'loss': 0.10325854, 'lr': 0, 'params': 514193, 'time_iter': 0.03033, 'accuracy': 0.97301, 'precision': 0.33333, 'recall': 0.37037, 'f1': 0.35088, 'auc': 0.78093}
2025-08-16 09:17:33,434 - INFO - test: {'epoch': 71, 'time_epoch': 3.86441, 'loss': 0.17025177, 'lr': 0, 'params': 514193, 'time_iter': 0.02996, 'accuracy': 0.96329, 'precision': 0.37931, 'recall': 0.25385, 'f1': 0.30415, 'auc': 0.7129}
2025-08-16 09:17:33,437 - INFO - > Epoch 71: took 73.6s (avg 76.4s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:18:41,794 - INFO - train: {'epoch': 72, 'time_epoch': 68.24195, 'eta': 1832.59539, 'eta_hours': 0.50905, 'loss': 0.07393483, 'lr': 1.995e-05, 'params': 514193, 'time_iter': 0.06632, 'accuracy': 0.97745, 'precision': 0.8117, 'recall': 0.51786, 'f1': 0.63231, 'auc': 0.95755}
2025-08-16 09:18:46,095 - INFO - val: {'epoch': 72, 'time_epoch': 4.27759, 'loss': 0.10716138, 'lr': 0, 'params': 514193, 'time_iter': 0.03316, 'accuracy': 0.97301, 'precision': 0.34043, 'recall': 0.39506, 'f1': 0.36571, 'auc': 0.77913}
2025-08-16 09:18:50,284 - INFO - test: {'epoch': 72, 'time_epoch': 4.17245, 'loss': 0.17604374, 'lr': 0, 'params': 514193, 'time_iter': 0.03234, 'accuracy': 0.96353, 'precision': 0.38095, 'recall': 0.24615, 'f1': 0.29907, 'auc': 0.71589}
2025-08-16 09:18:50,286 - INFO - > Epoch 72: took 76.8s (avg 76.4s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:20:00,616 - INFO - train: {'epoch': 73, 'time_epoch': 70.21907, 'eta': 1765.54547, 'eta_hours': 0.49043, 'loss': 0.07165997, 'lr': 1.864e-05, 'params': 514193, 'time_iter': 0.06824, 'accuracy': 0.97754, 'precision': 0.81006, 'recall': 0.52273, 'f1': 0.63542, 'auc': 0.95937}
2025-08-16 09:20:04,922 - INFO - val: {'epoch': 73, 'time_epoch': 4.28077, 'loss': 0.09767301, 'lr': 0, 'params': 514193, 'time_iter': 0.03318, 'accuracy': 0.97544, 'precision': 0.37805, 'recall': 0.38272, 'f1': 0.38037, 'auc': 0.77952}
2025-08-16 09:20:09,014 - INFO - test: {'epoch': 73, 'time_epoch': 4.07529, 'loss': 0.1669985, 'lr': 0, 'params': 514193, 'time_iter': 0.03159, 'accuracy': 0.96329, 'precision': 0.37037, 'recall': 0.23077, 'f1': 0.28436, 'auc': 0.71214}
2025-08-16 09:20:09,017 - INFO - > Epoch 73: took 78.7s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:21:16,805 - INFO - train: {'epoch': 74, 'time_epoch': 67.67857, 'eta': 1697.5642, 'eta_hours': 0.47155, 'loss': 0.07192158, 'lr': 1.737e-05, 'params': 514193, 'time_iter': 0.06577, 'accuracy': 0.97815, 'precision': 0.82346, 'recall': 0.53003, 'f1': 0.64494, 'auc': 0.95778}
2025-08-16 09:21:20,901 - INFO - val: {'epoch': 74, 'time_epoch': 4.07297, 'loss': 0.11224301, 'lr': 0, 'params': 514193, 'time_iter': 0.03157, 'accuracy': 0.96839, 'precision': 0.29752, 'recall': 0.44444, 'f1': 0.35644, 'auc': 0.79353}
2025-08-16 09:21:24,858 - INFO - test: {'epoch': 74, 'time_epoch': 3.9391, 'loss': 0.18195114, 'lr': 0, 'params': 514193, 'time_iter': 0.03054, 'accuracy': 0.95794, 'precision': 0.31624, 'recall': 0.28462, 'f1': 0.2996, 'auc': 0.69825}
2025-08-16 09:21:24,860 - INFO - > Epoch 74: took 75.8s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:22:31,633 - INFO - train: {'epoch': 75, 'time_epoch': 66.66047, 'eta': 1629.26939, 'eta_hours': 0.45257, 'loss': 0.07200232, 'lr': 1.614e-05, 'params': 514193, 'time_iter': 0.06478, 'accuracy': 0.97821, 'precision': 0.81595, 'recall': 0.53977, 'f1': 0.64973, 'auc': 0.95861}
2025-08-16 09:22:35,961 - INFO - val: {'epoch': 75, 'time_epoch': 4.30323, 'loss': 0.10587556, 'lr': 0, 'params': 514193, 'time_iter': 0.03336, 'accuracy': 0.97228, 'precision': 0.33663, 'recall': 0.41975, 'f1': 0.37363, 'auc': 0.7758}
2025-08-16 09:22:40,122 - INFO - test: {'epoch': 75, 'time_epoch': 4.14398, 'loss': 0.17848853, 'lr': 0, 'params': 514193, 'time_iter': 0.03212, 'accuracy': 0.95988, 'precision': 0.33333, 'recall': 0.26923, 'f1': 0.29787, 'auc': 0.70677}
2025-08-16 09:22:40,124 - INFO - > Epoch 75: took 75.3s (avg 76.4s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:23:47,823 - INFO - train: {'epoch': 76, 'time_epoch': 67.58644, 'eta': 1561.29361, 'eta_hours': 0.43369, 'loss': 0.07020956, 'lr': 1.494e-05, 'params': 514193, 'time_iter': 0.06568, 'accuracy': 0.97772, 'precision': 0.80764, 'recall': 0.53166, 'f1': 0.64121, 'auc': 0.96182}
2025-08-16 09:23:52,068 - INFO - val: {'epoch': 76, 'time_epoch': 4.22149, 'loss': 0.10783999, 'lr': 0, 'params': 514193, 'time_iter': 0.03272, 'accuracy': 0.97326, 'precision': 0.35052, 'recall': 0.41975, 'f1': 0.38202, 'auc': 0.78131}
2025-08-16 09:23:56,222 - INFO - test: {'epoch': 76, 'time_epoch': 4.13634, 'loss': 0.18100222, 'lr': 0, 'params': 514193, 'time_iter': 0.03206, 'accuracy': 0.96037, 'precision': 0.33333, 'recall': 0.25385, 'f1': 0.28821, 'auc': 0.70803}
2025-08-16 09:23:56,224 - INFO - > Epoch 76: took 76.1s (avg 76.4s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:25:03,965 - INFO - train: {'epoch': 77, 'time_epoch': 67.62655, 'eta': 1493.33914, 'eta_hours': 0.41482, 'loss': 0.07037718, 'lr': 1.378e-05, 'params': 514193, 'time_iter': 0.06572, 'accuracy': 0.9786, 'precision': 0.82039, 'recall': 0.5487, 'f1': 0.65759, 'auc': 0.96203}
2025-08-16 09:25:08,332 - INFO - val: {'epoch': 77, 'time_epoch': 4.34424, 'loss': 0.11665531, 'lr': 0, 'params': 514193, 'time_iter': 0.03368, 'accuracy': 0.96815, 'precision': 0.28448, 'recall': 0.40741, 'f1': 0.33503, 'auc': 0.77932}
2025-08-16 09:25:12,571 - INFO - test: {'epoch': 77, 'time_epoch': 4.2218, 'loss': 0.18221798, 'lr': 0, 'params': 514193, 'time_iter': 0.03273, 'accuracy': 0.95891, 'precision': 0.33613, 'recall': 0.30769, 'f1': 0.32129, 'auc': 0.7103}
2025-08-16 09:25:12,573 - INFO - > Epoch 77: took 76.3s (avg 76.4s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:26:21,796 - INFO - train: {'epoch': 78, 'time_epoch': 69.1137, 'eta': 1425.78828, 'eta_hours': 0.39605, 'loss': 0.07119129, 'lr': 1.266e-05, 'params': 514193, 'time_iter': 0.06717, 'accuracy': 0.97839, 'precision': 0.80975, 'recall': 0.55276, 'f1': 0.65702, 'auc': 0.95983}
2025-08-16 09:26:25,932 - INFO - val: {'epoch': 78, 'time_epoch': 4.11337, 'loss': 0.10805553, 'lr': 0, 'params': 514193, 'time_iter': 0.03189, 'accuracy': 0.97301, 'precision': 0.34694, 'recall': 0.41975, 'f1': 0.37989, 'auc': 0.7915}
2025-08-16 09:26:30,031 - INFO - test: {'epoch': 78, 'time_epoch': 4.08006, 'loss': 0.17888629, 'lr': 0, 'params': 514193, 'time_iter': 0.03163, 'accuracy': 0.96159, 'precision': 0.36275, 'recall': 0.28462, 'f1': 0.31897, 'auc': 0.71194}
2025-08-16 09:26:30,033 - INFO - > Epoch 78: took 77.5s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:27:38,035 - INFO - train: {'epoch': 79, 'time_epoch': 67.8926, 'eta': 1357.89309, 'eta_hours': 0.37719, 'loss': 0.07071259, 'lr': 1.158e-05, 'params': 514193, 'time_iter': 0.06598, 'accuracy': 0.97806, 'precision': 0.81638, 'recall': 0.53409, 'f1': 0.64573, 'auc': 0.96238}
2025-08-16 09:27:42,292 - INFO - val: {'epoch': 79, 'time_epoch': 4.23476, 'loss': 0.11687109, 'lr': 0, 'params': 514193, 'time_iter': 0.03283, 'accuracy': 0.96985, 'precision': 0.30973, 'recall': 0.4321, 'f1': 0.36082, 'auc': 0.78318}
2025-08-16 09:27:46,356 - INFO - test: {'epoch': 79, 'time_epoch': 4.0476, 'loss': 0.19079224, 'lr': 0, 'params': 514193, 'time_iter': 0.03138, 'accuracy': 0.95624, 'precision': 0.29839, 'recall': 0.28462, 'f1': 0.29134, 'auc': 0.70766}
2025-08-16 09:27:46,359 - INFO - > Epoch 79: took 76.3s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:28:56,408 - INFO - train: {'epoch': 80, 'time_epoch': 69.93645, 'eta': 1290.47737, 'eta_hours': 0.35847, 'loss': 0.07017693, 'lr': 1.054e-05, 'params': 514193, 'time_iter': 0.06797, 'accuracy': 0.979, 'precision': 0.84025, 'recall': 0.54221, 'f1': 0.6591, 'auc': 0.96132}
2025-08-16 09:29:00,817 - INFO - val: {'epoch': 80, 'time_epoch': 4.38404, 'loss': 0.11589289, 'lr': 0, 'params': 514193, 'time_iter': 0.03398, 'accuracy': 0.97009, 'precision': 0.3125, 'recall': 0.4321, 'f1': 0.36269, 'auc': 0.78685}
2025-08-16 09:29:05,038 - INFO - test: {'epoch': 80, 'time_epoch': 4.20203, 'loss': 0.18778603, 'lr': 0, 'params': 514193, 'time_iter': 0.03257, 'accuracy': 0.96037, 'precision': 0.33663, 'recall': 0.26154, 'f1': 0.29437, 'auc': 0.71055}
2025-08-16 09:29:05,041 - INFO - > Epoch 80: took 78.7s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:30:13,247 - INFO - train: {'epoch': 81, 'time_epoch': 68.09658, 'eta': 1222.5963, 'eta_hours': 0.33961, 'loss': 0.06916083, 'lr': 9.55e-06, 'params': 514193, 'time_iter': 0.06618, 'accuracy': 0.97815, 'precision': 0.81319, 'recall': 0.54058, 'f1': 0.64944, 'auc': 0.96284}
2025-08-16 09:30:17,508 - INFO - val: {'epoch': 81, 'time_epoch': 4.23819, 'loss': 0.11406028, 'lr': 0, 'params': 514193, 'time_iter': 0.03285, 'accuracy': 0.96961, 'precision': 0.30357, 'recall': 0.41975, 'f1': 0.35233, 'auc': 0.78064}
2025-08-16 09:30:21,700 - INFO - test: {'epoch': 81, 'time_epoch': 4.17281, 'loss': 0.18412361, 'lr': 0, 'params': 514193, 'time_iter': 0.03235, 'accuracy': 0.95915, 'precision': 0.33036, 'recall': 0.28462, 'f1': 0.30579, 'auc': 0.70833}
2025-08-16 09:30:21,703 - INFO - > Epoch 81: took 76.7s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:31:27,210 - INFO - train: {'epoch': 82, 'time_epoch': 65.35994, 'eta': 1154.14952, 'eta_hours': 0.3206, 'loss': 0.07080384, 'lr': 8.6e-06, 'params': 514193, 'time_iter': 0.06352, 'accuracy': 0.9783, 'precision': 0.8174, 'recall': 0.5414, 'f1': 0.65137, 'auc': 0.96298}
2025-08-16 09:31:31,446 - INFO - val: {'epoch': 82, 'time_epoch': 4.21326, 'loss': 0.12086781, 'lr': 0, 'params': 514193, 'time_iter': 0.03266, 'accuracy': 0.96475, 'precision': 0.26119, 'recall': 0.4321, 'f1': 0.32558, 'auc': 0.7827}
2025-08-16 09:31:35,708 - INFO - test: {'epoch': 82, 'time_epoch': 4.24438, 'loss': 0.18582851, 'lr': 0, 'params': 514193, 'time_iter': 0.0329, 'accuracy': 0.95624, 'precision': 0.30469, 'recall': 0.3, 'f1': 0.30233, 'auc': 0.71017}
2025-08-16 09:31:35,710 - INFO - > Epoch 82: took 74.0s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:32:45,282 - INFO - train: {'epoch': 83, 'time_epoch': 69.45955, 'eta': 1086.55712, 'eta_hours': 0.30182, 'loss': 0.06859084, 'lr': 7.7e-06, 'params': 514193, 'time_iter': 0.0675, 'accuracy': 0.97927, 'precision': 0.83053, 'recall': 0.56088, 'f1': 0.66957, 'auc': 0.9625}
2025-08-16 09:32:49,613 - INFO - val: {'epoch': 83, 'time_epoch': 4.30894, 'loss': 0.11510666, 'lr': 0, 'params': 514193, 'time_iter': 0.0334, 'accuracy': 0.97034, 'precision': 0.31858, 'recall': 0.44444, 'f1': 0.37113, 'auc': 0.78592}
2025-08-16 09:32:53,857 - INFO - test: {'epoch': 83, 'time_epoch': 4.22637, 'loss': 0.18960857, 'lr': 0, 'params': 514193, 'time_iter': 0.03276, 'accuracy': 0.95988, 'precision': 0.33945, 'recall': 0.28462, 'f1': 0.30962, 'auc': 0.70541}
2025-08-16 09:32:53,859 - INFO - > Epoch 83: took 78.1s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:34:01,198 - INFO - train: {'epoch': 84, 'time_epoch': 67.22134, 'eta': 1018.5258, 'eta_hours': 0.28292, 'loss': 0.06782358, 'lr': 6.84e-06, 'params': 514193, 'time_iter': 0.06533, 'accuracy': 0.97927, 'precision': 0.82816, 'recall': 0.56331, 'f1': 0.67053, 'auc': 0.96444}
2025-08-16 09:34:05,372 - INFO - val: {'epoch': 84, 'time_epoch': 4.15138, 'loss': 0.11429775, 'lr': 0, 'params': 514193, 'time_iter': 0.03218, 'accuracy': 0.97155, 'precision': 0.32692, 'recall': 0.41975, 'f1': 0.36757, 'auc': 0.78435}
2025-08-16 09:34:09,324 - INFO - test: {'epoch': 84, 'time_epoch': 3.93606, 'loss': 0.18993387, 'lr': 0, 'params': 514193, 'time_iter': 0.03051, 'accuracy': 0.96304, 'precision': 0.38298, 'recall': 0.27692, 'f1': 0.32143, 'auc': 0.70895}
2025-08-16 09:34:09,327 - INFO - > Epoch 84: took 75.5s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:35:16,768 - INFO - train: {'epoch': 85, 'time_epoch': 67.35727, 'eta': 950.53545, 'eta_hours': 0.26404, 'loss': 0.07066295, 'lr': 6.03e-06, 'params': 514193, 'time_iter': 0.06546, 'accuracy': 0.97915, 'precision': 0.83787, 'recall': 0.54951, 'f1': 0.66373, 'auc': 0.9604}
2025-08-16 09:35:21,019 - INFO - val: {'epoch': 85, 'time_epoch': 4.22648, 'loss': 0.11551623, 'lr': 0, 'params': 514193, 'time_iter': 0.03276, 'accuracy': 0.97009, 'precision': 0.30909, 'recall': 0.41975, 'f1': 0.35602, 'auc': 0.78677}
2025-08-16 09:35:25,285 - INFO - test: {'epoch': 85, 'time_epoch': 4.2477, 'loss': 0.18700599, 'lr': 0, 'params': 514193, 'time_iter': 0.03293, 'accuracy': 0.96134, 'precision': 0.35922, 'recall': 0.28462, 'f1': 0.3176, 'auc': 0.6989}
2025-08-16 09:35:25,288 - INFO - > Epoch 85: took 76.0s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:36:34,472 - INFO - train: {'epoch': 86, 'time_epoch': 69.07182, 'eta': 882.81585, 'eta_hours': 0.24523, 'loss': 0.07063786, 'lr': 5.26e-06, 'params': 514193, 'time_iter': 0.06713, 'accuracy': 0.97781, 'precision': 0.80535, 'recall': 0.53734, 'f1': 0.6446, 'auc': 0.96266}
2025-08-16 09:36:38,601 - INFO - val: {'epoch': 86, 'time_epoch': 4.10601, 'loss': 0.11117022, 'lr': 0, 'params': 514193, 'time_iter': 0.03183, 'accuracy': 0.97155, 'precision': 0.32692, 'recall': 0.41975, 'f1': 0.36757, 'auc': 0.7851}
2025-08-16 09:36:42,690 - INFO - test: {'epoch': 86, 'time_epoch': 4.07017, 'loss': 0.18477703, 'lr': 0, 'params': 514193, 'time_iter': 0.03155, 'accuracy': 0.96231, 'precision': 0.37374, 'recall': 0.28462, 'f1': 0.32314, 'auc': 0.70021}
2025-08-16 09:36:42,693 - INFO - > Epoch 86: took 77.4s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:37:50,213 - INFO - train: {'epoch': 87, 'time_epoch': 67.40831, 'eta': 814.83867, 'eta_hours': 0.22634, 'loss': 0.06886102, 'lr': 4.55e-06, 'params': 514193, 'time_iter': 0.06551, 'accuracy': 0.97866, 'precision': 0.83125, 'recall': 0.53977, 'f1': 0.65453, 'auc': 0.96547}
2025-08-16 09:37:54,405 - INFO - val: {'epoch': 87, 'time_epoch': 4.17049, 'loss': 0.11337258, 'lr': 0, 'params': 514193, 'time_iter': 0.03233, 'accuracy': 0.97204, 'precision': 0.33654, 'recall': 0.4321, 'f1': 0.37838, 'auc': 0.77953}
2025-08-16 09:37:58,509 - INFO - test: {'epoch': 87, 'time_epoch': 4.08588, 'loss': 0.18236125, 'lr': 0, 'params': 514193, 'time_iter': 0.03167, 'accuracy': 0.96061, 'precision': 0.34615, 'recall': 0.27692, 'f1': 0.30769, 'auc': 0.70926}
2025-08-16 09:37:58,525 - INFO - > Epoch 87: took 75.8s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:39:07,038 - INFO - train: {'epoch': 88, 'time_epoch': 68.39862, 'eta': 746.99668, 'eta_hours': 0.2075, 'loss': 0.06839061, 'lr': 3.89e-06, 'params': 514193, 'time_iter': 0.06647, 'accuracy': 0.97872, 'precision': 0.82203, 'recall': 0.55114, 'f1': 0.65986, 'auc': 0.96613}
2025-08-16 09:39:11,405 - INFO - val: {'epoch': 88, 'time_epoch': 4.34206, 'loss': 0.10519271, 'lr': 0, 'params': 514193, 'time_iter': 0.03366, 'accuracy': 0.9752, 'precision': 0.38202, 'recall': 0.41975, 'f1': 0.4, 'auc': 0.78826}
2025-08-16 09:39:15,655 - INFO - test: {'epoch': 88, 'time_epoch': 4.23066, 'loss': 0.18050141, 'lr': 0, 'params': 514193, 'time_iter': 0.0328, 'accuracy': 0.96426, 'precision': 0.4, 'recall': 0.26154, 'f1': 0.31628, 'auc': 0.70525}
2025-08-16 09:39:15,657 - INFO - > Epoch 88: took 77.1s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:40:23,746 - INFO - train: {'epoch': 89, 'time_epoch': 67.98428, 'eta': 679.09628, 'eta_hours': 0.18864, 'loss': 0.06607192, 'lr': 3.27e-06, 'params': 514193, 'time_iter': 0.06607, 'accuracy': 0.97897, 'precision': 0.81915, 'recall': 0.5625, 'f1': 0.66699, 'auc': 0.9679}
2025-08-16 09:40:27,834 - INFO - val: {'epoch': 89, 'time_epoch': 4.0652, 'loss': 0.11503557, 'lr': 0, 'params': 514193, 'time_iter': 0.03151, 'accuracy': 0.96985, 'precision': 0.31304, 'recall': 0.44444, 'f1': 0.36735, 'auc': 0.78865}
2025-08-16 09:40:31,969 - INFO - test: {'epoch': 89, 'time_epoch': 4.11846, 'loss': 0.18703149, 'lr': 0, 'params': 514193, 'time_iter': 0.03193, 'accuracy': 0.95842, 'precision': 0.32174, 'recall': 0.28462, 'f1': 0.30204, 'auc': 0.70608}
2025-08-16 09:40:31,972 - INFO - > Epoch 89: took 76.3s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:41:39,058 - INFO - train: {'epoch': 90, 'time_epoch': 66.97596, 'eta': 611.09431, 'eta_hours': 0.16975, 'loss': 0.06754686, 'lr': 2.71e-06, 'params': 514193, 'time_iter': 0.06509, 'accuracy': 0.9793, 'precision': 0.84054, 'recall': 0.55195, 'f1': 0.66634, 'auc': 0.9649}
2025-08-16 09:41:43,238 - INFO - val: {'epoch': 90, 'time_epoch': 4.1574, 'loss': 0.11154534, 'lr': 0, 'params': 514193, 'time_iter': 0.03223, 'accuracy': 0.97253, 'precision': 0.34, 'recall': 0.41975, 'f1': 0.37569, 'auc': 0.78145}
2025-08-16 09:41:47,362 - INFO - test: {'epoch': 90, 'time_epoch': 4.10595, 'loss': 0.18324425, 'lr': 0, 'params': 514193, 'time_iter': 0.03183, 'accuracy': 0.96159, 'precision': 0.35417, 'recall': 0.26154, 'f1': 0.30088, 'auc': 0.7042}
2025-08-16 09:41:47,364 - INFO - > Epoch 90: took 75.4s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:42:54,991 - INFO - train: {'epoch': 91, 'time_epoch': 67.51568, 'eta': 543.16158, 'eta_hours': 0.15088, 'loss': 0.06821849, 'lr': 2.2e-06, 'params': 514193, 'time_iter': 0.06561, 'accuracy': 0.97894, 'precision': 0.82667, 'recall': 0.55357, 'f1': 0.6631, 'auc': 0.96534}
2025-08-16 09:42:59,262 - INFO - val: {'epoch': 91, 'time_epoch': 4.24537, 'loss': 0.11554342, 'lr': 0, 'params': 514193, 'time_iter': 0.03291, 'accuracy': 0.97107, 'precision': 0.32727, 'recall': 0.44444, 'f1': 0.37696, 'auc': 0.78715}
2025-08-16 09:43:03,567 - INFO - test: {'epoch': 91, 'time_epoch': 4.28641, 'loss': 0.18503483, 'lr': 0, 'params': 514193, 'time_iter': 0.03323, 'accuracy': 0.9611, 'precision': 0.35294, 'recall': 0.27692, 'f1': 0.31034, 'auc': 0.70675}
2025-08-16 09:43:03,569 - INFO - > Epoch 91: took 76.2s (avg 76.5s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:44:10,525 - INFO - train: {'epoch': 92, 'time_epoch': 66.83397, 'eta': 475.1865, 'eta_hours': 0.132, 'loss': 0.06799715, 'lr': 1.74e-06, 'params': 514193, 'time_iter': 0.06495, 'accuracy': 0.97857, 'precision': 0.81557, 'recall': 0.55276, 'f1': 0.65893, 'auc': 0.96469}
2025-08-16 09:44:14,793 - INFO - val: {'epoch': 92, 'time_epoch': 4.24173, 'loss': 0.11713408, 'lr': 0, 'params': 514193, 'time_iter': 0.03288, 'accuracy': 0.96864, 'precision': 0.29661, 'recall': 0.4321, 'f1': 0.35176, 'auc': 0.78092}
2025-08-16 09:44:18,831 - INFO - test: {'epoch': 92, 'time_epoch': 4.01827, 'loss': 0.1889654, 'lr': 0, 'params': 514193, 'time_iter': 0.03115, 'accuracy': 0.95575, 'precision': 0.29365, 'recall': 0.28462, 'f1': 0.28906, 'auc': 0.70549}
2025-08-16 09:44:18,834 - INFO - > Epoch 92: took 75.3s (avg 76.4s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:45:25,857 - INFO - train: {'epoch': 93, 'time_epoch': 66.91559, 'eta': 407.24092, 'eta_hours': 0.11312, 'loss': 0.06923543, 'lr': 1.33e-06, 'params': 514193, 'time_iter': 0.06503, 'accuracy': 0.97885, 'precision': 0.83416, 'recall': 0.54302, 'f1': 0.65782, 'auc': 0.96213}
2025-08-16 09:45:30,054 - INFO - val: {'epoch': 93, 'time_epoch': 4.17078, 'loss': 0.12204236, 'lr': 0, 'params': 514193, 'time_iter': 0.03233, 'accuracy': 0.9662, 'precision': 0.27692, 'recall': 0.44444, 'f1': 0.34123, 'auc': 0.78276}
2025-08-16 09:45:34,489 - INFO - test: {'epoch': 93, 'time_epoch': 4.41706, 'loss': 0.19026232, 'lr': 0, 'params': 514193, 'time_iter': 0.03424, 'accuracy': 0.95478, 'precision': 0.28788, 'recall': 0.29231, 'f1': 0.29008, 'auc': 0.70747}
2025-08-16 09:45:34,491 - INFO - > Epoch 93: took 75.7s (avg 76.4s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:46:44,018 - INFO - train: {'epoch': 94, 'time_epoch': 69.41808, 'eta': 339.44872, 'eta_hours': 0.09429, 'loss': 0.06677394, 'lr': 9.8e-07, 'params': 514193, 'time_iter': 0.06746, 'accuracy': 0.97924, 'precision': 0.82718, 'recall': 0.56331, 'f1': 0.67021, 'auc': 0.96572}
2025-08-16 09:46:48,106 - INFO - val: {'epoch': 94, 'time_epoch': 4.06567, 'loss': 0.11450108, 'lr': 0, 'params': 514193, 'time_iter': 0.03152, 'accuracy': 0.97253, 'precision': 0.34314, 'recall': 0.4321, 'f1': 0.38251, 'auc': 0.78461}
2025-08-16 09:46:52,126 - INFO - test: {'epoch': 94, 'time_epoch': 4.00293, 'loss': 0.19119647, 'lr': 0, 'params': 514193, 'time_iter': 0.03103, 'accuracy': 0.95867, 'precision': 0.31132, 'recall': 0.25385, 'f1': 0.27966, 'auc': 0.70396}
2025-08-16 09:46:52,129 - INFO - > Epoch 94: took 77.6s (avg 76.4s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:47:58,955 - INFO - train: {'epoch': 95, 'time_epoch': 66.71091, 'eta': 271.50986, 'eta_hours': 0.07542, 'loss': 0.06609134, 'lr': 6.8e-07, 'params': 514193, 'time_iter': 0.06483, 'accuracy': 0.97894, 'precision': 0.82045, 'recall': 0.56006, 'f1': 0.6657, 'auc': 0.96822}
2025-08-16 09:48:03,089 - INFO - val: {'epoch': 95, 'time_epoch': 4.10919, 'loss': 0.11628103, 'lr': 0, 'params': 514193, 'time_iter': 0.03185, 'accuracy': 0.96961, 'precision': 0.30702, 'recall': 0.4321, 'f1': 0.35897, 'auc': 0.78208}
2025-08-16 09:48:07,089 - INFO - test: {'epoch': 95, 'time_epoch': 3.98013, 'loss': 0.18589006, 'lr': 0, 'params': 514193, 'time_iter': 0.03085, 'accuracy': 0.95891, 'precision': 0.3211, 'recall': 0.26923, 'f1': 0.29289, 'auc': 0.70829}
2025-08-16 09:48:07,091 - INFO - > Epoch 95: took 75.0s (avg 76.4s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:49:13,131 - INFO - train: {'epoch': 96, 'time_epoch': 65.92865, 'eta': 203.57212, 'eta_hours': 0.05655, 'loss': 0.06752987, 'lr': 4.4e-07, 'params': 514193, 'time_iter': 0.06407, 'accuracy': 0.97869, 'precision': 0.81346, 'recall': 0.55925, 'f1': 0.66282, 'auc': 0.96586}
2025-08-16 09:49:17,380 - INFO - val: {'epoch': 96, 'time_epoch': 4.22597, 'loss': 0.11145154, 'lr': 0, 'params': 514193, 'time_iter': 0.03276, 'accuracy': 0.97204, 'precision': 0.32653, 'recall': 0.39506, 'f1': 0.35754, 'auc': 0.77904}
2025-08-16 09:49:21,575 - INFO - test: {'epoch': 96, 'time_epoch': 4.17779, 'loss': 0.18323802, 'lr': 0, 'params': 514193, 'time_iter': 0.03239, 'accuracy': 0.9611, 'precision': 0.34694, 'recall': 0.26154, 'f1': 0.29825, 'auc': 0.70574}
2025-08-16 09:49:21,577 - INFO - > Epoch 96: took 74.5s (avg 76.4s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:50:29,779 - INFO - train: {'epoch': 97, 'time_epoch': 68.07711, 'eta': 135.71923, 'eta_hours': 0.0377, 'loss': 0.0678961, 'lr': 2.5e-07, 'params': 514193, 'time_iter': 0.06616, 'accuracy': 0.97939, 'precision': 0.83946, 'recall': 0.55601, 'f1': 0.66895, 'auc': 0.96518}
2025-08-16 09:50:34,140 - INFO - val: {'epoch': 97, 'time_epoch': 4.33623, 'loss': 0.11217735, 'lr': 0, 'params': 514193, 'time_iter': 0.03361, 'accuracy': 0.97301, 'precision': 0.34043, 'recall': 0.39506, 'f1': 0.36571, 'auc': 0.77766}
2025-08-16 09:50:38,401 - INFO - test: {'epoch': 97, 'time_epoch': 4.24325, 'loss': 0.18638933, 'lr': 0, 'params': 514193, 'time_iter': 0.03289, 'accuracy': 0.95988, 'precision': 0.32673, 'recall': 0.25385, 'f1': 0.28571, 'auc': 0.70423}
2025-08-16 09:50:38,403 - INFO - > Epoch 97: took 76.8s (avg 76.4s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:51:46,377 - INFO - train: {'epoch': 98, 'time_epoch': 67.86179, 'eta': 67.85964, 'eta_hours': 0.01885, 'loss': 0.06507952, 'lr': 1.1e-07, 'params': 514193, 'time_iter': 0.06595, 'accuracy': 0.97948, 'precision': 0.83194, 'recall': 0.56656, 'f1': 0.67407, 'auc': 0.96772}
2025-08-16 09:51:50,600 - INFO - val: {'epoch': 98, 'time_epoch': 4.20026, 'loss': 0.11842541, 'lr': 0, 'params': 514193, 'time_iter': 0.03256, 'accuracy': 0.96815, 'precision': 0.29167, 'recall': 0.4321, 'f1': 0.34826, 'auc': 0.78048}
2025-08-16 09:51:54,736 - INFO - test: {'epoch': 98, 'time_epoch': 4.11922, 'loss': 0.18846495, 'lr': 0, 'params': 514193, 'time_iter': 0.03193, 'accuracy': 0.95842, 'precision': 0.31858, 'recall': 0.27692, 'f1': 0.2963, 'auc': 0.70621}
2025-08-16 09:51:54,738 - INFO - > Epoch 98: took 76.3s (avg 76.4s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:53:06,067 - INFO - train: {'epoch': 99, 'time_epoch': 71.2159, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.06785285, 'lr': 3e-08, 'params': 514193, 'time_iter': 0.06921, 'accuracy': 0.97897, 'precision': 0.82374, 'recall': 0.55763, 'f1': 0.66505, 'auc': 0.96416}
2025-08-16 09:53:10,416 - INFO - val: {'epoch': 99, 'time_epoch': 4.32607, 'loss': 0.11332175, 'lr': 0, 'params': 514193, 'time_iter': 0.03354, 'accuracy': 0.9718, 'precision': 0.3301, 'recall': 0.41975, 'f1': 0.36957, 'auc': 0.78473}
2025-08-16 09:53:14,653 - INFO - test: {'epoch': 99, 'time_epoch': 4.22007, 'loss': 0.18644223, 'lr': 0, 'params': 514193, 'time_iter': 0.03271, 'accuracy': 0.96037, 'precision': 0.33663, 'recall': 0.26154, 'f1': 0.29437, 'auc': 0.70355}
2025-08-16 09:53:14,891 - INFO - > Epoch 99: took 79.9s (avg 76.4s) | Best so far: epoch 25	train_loss: 0.1104 train_auc: 0.8489	val_loss: 0.0793 val_auc: 0.7969	test_loss: 0.1222 test_auc: 0.7442
2025-08-16 09:53:14,891 - INFO - Avg time per epoch: 76.45s
2025-08-16 09:53:14,891 - INFO - Total train loop time: 2.12h
2025-08-16 09:53:14,973 - INFO - ============================================================
2025-08-16 09:53:14,974 - INFO - Starting PK-Explainer Analysis (Enhanced Version)
2025-08-16 09:53:14,974 - INFO - ============================================================
2025-08-16 09:53:14,974 - INFO - Dataset: ogbg-molhiv
2025-08-16 09:53:14,974 - INFO - Model type: VanillaModel
2025-08-16 09:53:14,974 - INFO - GNN types available: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 09:53:15,016 - INFO - Saved model state to results/molhiv/molhiv-Vanilla-47/model_for_ablation.pt
2025-08-16 09:53:15,016 - INFO - 
Performing ablation study...
2025-08-16 09:53:15,049 - INFO - Getting baseline performance...
2025-08-16 09:53:15,082 - WARNING - Could not extract GNN mapping from optimal weights, attempting to infer from layers...
2025-08-16 09:53:15,082 - INFO - Final GNN mapping: {}
2025-08-16 09:53:19,247 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.14994, 'loss': 0.18644224, 'lr': 0, 'params': 514193, 'time_iter': 0.03217, 'accuracy': 0.96037, 'precision': 0.33663, 'recall': 0.26154, 'f1': 0.29437, 'auc': 0.70355}
2025-08-16 09:53:19,249 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:19,250 - INFO - Baseline auc: 0.7036
2025-08-16 09:53:23,352 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.05595, 'loss': 0.18770214, 'lr': 0, 'params': 514193, 'time_iter': 0.03144, 'accuracy': 0.95915, 'precision': 0.33333, 'recall': 0.29231, 'f1': 0.31148, 'auc': 0.70892}
2025-08-16 09:53:23,354 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:23,354 - INFO - Layer 0 (Layer_0), Head 0: drop=-0.0076
2025-08-16 09:53:27,455 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.03652, 'loss': 0.18742759, 'lr': 0, 'params': 514193, 'time_iter': 0.03129, 'accuracy': 0.96037, 'precision': 0.33333, 'recall': 0.25385, 'f1': 0.28821, 'auc': 0.69597}
2025-08-16 09:53:27,457 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:53:27,458 - INFO - Layer 0 (Layer_0), Head 1: drop=0.0108
2025-08-16 09:53:31,538 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.03115, 'loss': 0.18714258, 'lr': 0, 'params': 514193, 'time_iter': 0.03125, 'accuracy': 0.96013, 'precision': 0.31522, 'recall': 0.22308, 'f1': 0.26126, 'auc': 0.69792}
2025-08-16 09:53:31,540 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:31,540 - INFO - Layer 0 (Layer_0), Head 2: drop=0.0080
2025-08-16 09:53:35,520 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 3.93132, 'loss': 0.18861509, 'lr': 0, 'params': 514193, 'time_iter': 0.03048, 'accuracy': 0.96037, 'precision': 0.34579, 'recall': 0.28462, 'f1': 0.31224, 'auc': 0.6982}
2025-08-16 09:53:35,522 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:35,522 - INFO - Layer 0 (Layer_0), Head 3: drop=0.0076
2025-08-16 09:53:39,603 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.03253, 'loss': 0.18341375, 'lr': 0, 'params': 514193, 'time_iter': 0.03126, 'accuracy': 0.95551, 'precision': 0.28455, 'recall': 0.26923, 'f1': 0.27668, 'auc': 0.69578}
2025-08-16 09:53:39,606 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:53:39,607 - INFO - Layer 1 (Layer_1), Head 0: drop=0.0110
2025-08-16 09:53:43,789 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.12462, 'loss': 0.18934061, 'lr': 0, 'params': 514193, 'time_iter': 0.03197, 'accuracy': 0.95186, 'precision': 0.2875, 'recall': 0.35385, 'f1': 0.31724, 'auc': 0.73007}
2025-08-16 09:53:43,791 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:53:43,791 - INFO - Layer 1 (Layer_1), Head 1: drop=-0.0377
2025-08-16 09:53:47,941 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.09814, 'loss': 0.17867196, 'lr': 0, 'params': 514193, 'time_iter': 0.03177, 'accuracy': 0.96231, 'precision': 0.36842, 'recall': 0.26923, 'f1': 0.31111, 'auc': 0.70929}
2025-08-16 09:53:47,943 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:47,943 - INFO - Layer 1 (Layer_1), Head 2: drop=-0.0082
2025-08-16 09:53:52,708 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.11089, 'loss': 0.18943849, 'lr': 0, 'params': 514193, 'time_iter': 0.03187, 'accuracy': 0.95988, 'precision': 0.33945, 'recall': 0.28462, 'f1': 0.30962, 'auc': 0.68927}
2025-08-16 09:53:52,710 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:52,710 - INFO - Layer 1 (Layer_1), Head 3: drop=0.0203
2025-08-16 09:53:56,829 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.07098, 'loss': 0.18022573, 'lr': 0, 'params': 514193, 'time_iter': 0.03156, 'accuracy': 0.96207, 'precision': 0.36458, 'recall': 0.26923, 'f1': 0.30973, 'auc': 0.70997}
2025-08-16 09:53:56,831 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:56,831 - INFO - Layer 2 (Layer_2), Head 0: drop=-0.0091
2025-08-16 09:54:00,958 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.07888, 'loss': 0.18647005, 'lr': 0, 'params': 514193, 'time_iter': 0.03162, 'accuracy': 0.95867, 'precision': 0.30769, 'recall': 0.24615, 'f1': 0.2735, 'auc': 0.70727}
2025-08-16 09:54:00,960 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:54:00,960 - INFO - Layer 2 (Layer_2), Head 1: drop=-0.0053
2025-08-16 09:54:05,089 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.08003, 'loss': 0.18279281, 'lr': 0, 'params': 514193, 'time_iter': 0.03163, 'accuracy': 0.96086, 'precision': 0.34653, 'recall': 0.26923, 'f1': 0.30303, 'auc': 0.70802}
2025-08-16 09:54:05,091 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:54:05,091 - INFO - Layer 2 (Layer_2), Head 2: drop=-0.0064
2025-08-16 09:54:09,218 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.07755, 'loss': 0.18737788, 'lr': 0, 'params': 514193, 'time_iter': 0.03161, 'accuracy': 0.95672, 'precision': 0.3, 'recall': 0.27692, 'f1': 0.288, 'auc': 0.71864}
2025-08-16 09:54:09,220 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:54:09,221 - INFO - Layer 2 (Layer_2), Head 3: drop=-0.0214
2025-08-16 09:54:13,351 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.08258, 'loss': 0.19022891, 'lr': 0, 'params': 514193, 'time_iter': 0.03165, 'accuracy': 0.95356, 'precision': 0.28058, 'recall': 0.3, 'f1': 0.28996, 'auc': 0.70405}
2025-08-16 09:54:13,353 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:54:13,353 - INFO - Layer 3 (Layer_3), Head 0: drop=-0.0007
2025-08-16 09:54:17,732 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33014, 'loss': 0.18586747, 'lr': 0, 'params': 514193, 'time_iter': 0.03357, 'accuracy': 0.95551, 'precision': 0.27731, 'recall': 0.25385, 'f1': 0.26506, 'auc': 0.70894}
2025-08-16 09:54:17,734 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:54:17,734 - INFO - Layer 3 (Layer_3), Head 1: drop=-0.0077
2025-08-16 09:54:22,071 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27705, 'loss': 0.19063649, 'lr': 0, 'params': 514193, 'time_iter': 0.03316, 'accuracy': 0.95308, 'precision': 0.26316, 'recall': 0.26923, 'f1': 0.26616, 'auc': 0.71206}
2025-08-16 09:54:22,073 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:54:22,073 - INFO - Layer 3 (Layer_3), Head 2: drop=-0.0121
2025-08-16 09:54:26,386 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25834, 'loss': 0.18891074, 'lr': 0, 'params': 514193, 'time_iter': 0.03301, 'accuracy': 0.95721, 'precision': 0.29091, 'recall': 0.24615, 'f1': 0.26667, 'auc': 0.69865}
2025-08-16 09:54:26,390 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:54:26,390 - INFO - Layer 3 (Layer_3), Head 3: drop=0.0070
2025-08-16 09:54:30,679 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23934, 'loss': 0.18657017, 'lr': 0, 'params': 514193, 'time_iter': 0.03286, 'accuracy': 0.95648, 'precision': 0.29412, 'recall': 0.26923, 'f1': 0.28112, 'auc': 0.7117}
2025-08-16 09:54:30,681 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:54:30,681 - INFO - Layer 4 (Layer_4), Head 0: drop=-0.0116
2025-08-16 09:54:34,950 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22137, 'loss': 0.19152646, 'lr': 0, 'params': 514193, 'time_iter': 0.03272, 'accuracy': 0.96013, 'precision': 0.33962, 'recall': 0.27692, 'f1': 0.30508, 'auc': 0.68867}
2025-08-16 09:54:34,952 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:54:34,952 - INFO - Layer 4 (Layer_4), Head 1: drop=0.0211
2025-08-16 09:54:39,231 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23052, 'loss': 0.18295824, 'lr': 0, 'params': 514193, 'time_iter': 0.03279, 'accuracy': 0.96013, 'precision': 0.32292, 'recall': 0.23846, 'f1': 0.27434, 'auc': 0.70597}
2025-08-16 09:54:39,233 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:54:39,233 - INFO - Layer 4 (Layer_4), Head 2: drop=-0.0034
2025-08-16 09:54:43,526 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24358, 'loss': 0.1872022, 'lr': 0, 'params': 514193, 'time_iter': 0.0329, 'accuracy': 0.95478, 'precision': 0.27419, 'recall': 0.26154, 'f1': 0.26772, 'auc': 0.71139}
2025-08-16 09:54:43,528 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:54:43,528 - INFO - Layer 4 (Layer_4), Head 3: drop=-0.0111
2025-08-16 09:54:47,821 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24494, 'loss': 0.1811089, 'lr': 0, 'params': 514193, 'time_iter': 0.03291, 'accuracy': 0.9594, 'precision': 0.30928, 'recall': 0.23077, 'f1': 0.26432, 'auc': 0.69775}
2025-08-16 09:54:47,825 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:54:47,825 - INFO - Layer 5 (Layer_5), Head 0: drop=0.0082
2025-08-16 09:54:52,153 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27613, 'loss': 0.18496816, 'lr': 0, 'params': 514193, 'time_iter': 0.03315, 'accuracy': 0.96086, 'precision': 0.34653, 'recall': 0.26923, 'f1': 0.30303, 'auc': 0.70759}
2025-08-16 09:54:52,155 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:54:52,155 - INFO - Layer 5 (Layer_5), Head 1: drop=-0.0057
2025-08-16 09:54:56,454 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24858, 'loss': 0.18151025, 'lr': 0, 'params': 514193, 'time_iter': 0.03293, 'accuracy': 0.95794, 'precision': 0.31933, 'recall': 0.29231, 'f1': 0.30522, 'auc': 0.71992}
2025-08-16 09:54:56,456 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:54:56,456 - INFO - Layer 5 (Layer_5), Head 2: drop=-0.0233
2025-08-16 09:55:00,747 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24277, 'loss': 0.18515451, 'lr': 0, 'params': 514193, 'time_iter': 0.03289, 'accuracy': 0.95721, 'precision': 0.30508, 'recall': 0.27692, 'f1': 0.29032, 'auc': 0.70557}
2025-08-16 09:55:00,749 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:55:00,749 - INFO - Layer 5 (Layer_5), Head 3: drop=-0.0029
2025-08-16 09:55:05,031 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23209, 'loss': 0.18199577, 'lr': 0, 'params': 514193, 'time_iter': 0.03281, 'accuracy': 0.96037, 'precision': 0.33333, 'recall': 0.25385, 'f1': 0.28821, 'auc': 0.69699}
2025-08-16 09:55:05,033 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:55:05,033 - INFO - Layer 6 (Layer_6), Head 0: drop=0.0093
2025-08-16 09:55:09,319 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23553, 'loss': 0.18187986, 'lr': 0, 'params': 514193, 'time_iter': 0.03283, 'accuracy': 0.95842, 'precision': 0.32773, 'recall': 0.3, 'f1': 0.31325, 'auc': 0.70681}
2025-08-16 09:55:09,321 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:55:09,321 - INFO - Layer 6 (Layer_6), Head 1: drop=-0.0046
2025-08-16 09:55:13,608 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23735, 'loss': 0.18728108, 'lr': 0, 'params': 514193, 'time_iter': 0.03285, 'accuracy': 0.95988, 'precision': 0.33333, 'recall': 0.26923, 'f1': 0.29787, 'auc': 0.70589}
2025-08-16 09:55:13,610 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:55:13,610 - INFO - Layer 6 (Layer_6), Head 2: drop=-0.0033
2025-08-16 09:55:17,904 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24478, 'loss': 0.1909241, 'lr': 0, 'params': 514193, 'time_iter': 0.03291, 'accuracy': 0.95964, 'precision': 0.32353, 'recall': 0.25385, 'f1': 0.28448, 'auc': 0.6992}
2025-08-16 09:55:17,905 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:55:17,906 - INFO - Layer 6 (Layer_6), Head 3: drop=0.0062
2025-08-16 09:55:22,204 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24963, 'loss': 0.17490637, 'lr': 0, 'params': 514193, 'time_iter': 0.03294, 'accuracy': 0.9628, 'precision': 0.37363, 'recall': 0.26154, 'f1': 0.30769, 'auc': 0.70208}
2025-08-16 09:55:22,206 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:55:22,206 - INFO - Layer 7 (Layer_7), Head 0: drop=0.0021
2025-08-16 09:55:26,500 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24556, 'loss': 0.18249825, 'lr': 0, 'params': 514193, 'time_iter': 0.03291, 'accuracy': 0.96207, 'precision': 0.3617, 'recall': 0.26154, 'f1': 0.30357, 'auc': 0.70635}
2025-08-16 09:55:26,502 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:55:26,503 - INFO - Layer 7 (Layer_7), Head 1: drop=-0.0040
2025-08-16 09:55:30,802 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25273, 'loss': 0.19016373, 'lr': 0, 'params': 514193, 'time_iter': 0.03297, 'accuracy': 0.96037, 'precision': 0.33333, 'recall': 0.25385, 'f1': 0.28821, 'auc': 0.70604}
2025-08-16 09:55:30,804 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:55:30,804 - INFO - Layer 7 (Layer_7), Head 2: drop=-0.0035
2025-08-16 09:55:35,099 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24732, 'loss': 0.18412559, 'lr': 0, 'params': 514193, 'time_iter': 0.03292, 'accuracy': 0.95891, 'precision': 0.28571, 'recall': 0.2, 'f1': 0.23529, 'auc': 0.66952}
2025-08-16 09:55:35,101 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:55:35,101 - INFO - Layer 7 (Layer_7), Head 3: drop=0.0484
2025-08-16 09:55:39,399 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24874, 'loss': 0.17628505, 'lr': 0, 'params': 514193, 'time_iter': 0.03294, 'accuracy': 0.9645, 'precision': 0.4, 'recall': 0.24615, 'f1': 0.30476, 'auc': 0.70489}
2025-08-16 09:55:39,401 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:55:39,401 - INFO - Layer 8 (Layer_8), Head 0: drop=-0.0019
2025-08-16 09:55:43,708 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25792, 'loss': 0.1796067, 'lr': 0, 'params': 514193, 'time_iter': 0.03301, 'accuracy': 0.9611, 'precision': 0.34694, 'recall': 0.26154, 'f1': 0.29825, 'auc': 0.7035}
2025-08-16 09:55:43,710 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:55:43,710 - INFO - Layer 8 (Layer_8), Head 1: drop=0.0001
2025-08-16 09:55:47,995 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23546, 'loss': 0.18288003, 'lr': 0, 'params': 514193, 'time_iter': 0.03283, 'accuracy': 0.96086, 'precision': 0.34343, 'recall': 0.26154, 'f1': 0.29694, 'auc': 0.70303}
2025-08-16 09:55:47,997 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:55:47,997 - INFO - Layer 8 (Layer_8), Head 2: drop=0.0007
2025-08-16 09:55:52,278 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23167, 'loss': 0.17935752, 'lr': 0, 'params': 514193, 'time_iter': 0.0328, 'accuracy': 0.96037, 'precision': 0.33981, 'recall': 0.26923, 'f1': 0.30043, 'auc': 0.71238}
2025-08-16 09:55:52,279 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:55:52,280 - INFO - Layer 8 (Layer_8), Head 3: drop=-0.0126
2025-08-16 09:55:56,554 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2257, 'loss': 0.18240868, 'lr': 0, 'params': 514193, 'time_iter': 0.03276, 'accuracy': 0.96159, 'precision': 0.35417, 'recall': 0.26154, 'f1': 0.30088, 'auc': 0.70526}
2025-08-16 09:55:56,556 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:55:56,556 - INFO - Layer 9 (Layer_9), Head 0: drop=-0.0024
2025-08-16 09:56:00,847 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24179, 'loss': 0.183263, 'lr': 0, 'params': 514193, 'time_iter': 0.03288, 'accuracy': 0.96159, 'precision': 0.35417, 'recall': 0.26154, 'f1': 0.30088, 'auc': 0.70797}
2025-08-16 09:56:00,849 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:56:00,849 - INFO - Layer 9 (Layer_9), Head 1: drop=-0.0063
2025-08-16 09:56:05,128 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23012, 'loss': 0.1804347, 'lr': 0, 'params': 514193, 'time_iter': 0.03279, 'accuracy': 0.96475, 'precision': 0.40964, 'recall': 0.26154, 'f1': 0.31925, 'auc': 0.70211}
2025-08-16 09:56:05,130 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:56:05,130 - INFO - Layer 9 (Layer_9), Head 2: drop=0.0020
2025-08-16 09:56:09,406 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22739, 'loss': 0.18167093, 'lr': 0, 'params': 514193, 'time_iter': 0.03277, 'accuracy': 0.9628, 'precision': 0.37363, 'recall': 0.26154, 'f1': 0.30769, 'auc': 0.69743}
2025-08-16 09:56:09,408 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:56:09,409 - INFO - Layer 9 (Layer_9), Head 3: drop=0.0087
2025-08-16 09:56:13,699 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24033, 'loss': 0.18384543, 'lr': 0, 'params': 514193, 'time_iter': 0.03287, 'accuracy': 0.9611, 'precision': 0.34694, 'recall': 0.26154, 'f1': 0.29825, 'auc': 0.7026}
2025-08-16 09:56:13,701 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:56:13,701 - INFO - Layer 10 (Layer_10), Head 0: drop=0.0014
2025-08-16 09:56:17,980 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22978, 'loss': 0.18190195, 'lr': 0, 'params': 514193, 'time_iter': 0.03279, 'accuracy': 0.96183, 'precision': 0.35789, 'recall': 0.26154, 'f1': 0.30222, 'auc': 0.70204}
2025-08-16 09:56:17,982 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:56:17,982 - INFO - Layer 10 (Layer_10), Head 1: drop=0.0021
2025-08-16 09:56:22,271 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24098, 'loss': 0.19171926, 'lr': 0, 'params': 514193, 'time_iter': 0.03288, 'accuracy': 0.9594, 'precision': 0.32381, 'recall': 0.26154, 'f1': 0.28936, 'auc': 0.70398}
2025-08-16 09:56:22,273 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:56:22,273 - INFO - Layer 10 (Layer_10), Head 2: drop=-0.0006
2025-08-16 09:56:26,538 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21792, 'loss': 0.18506203, 'lr': 0, 'params': 514193, 'time_iter': 0.0327, 'accuracy': 0.96086, 'precision': 0.34343, 'recall': 0.26154, 'f1': 0.29694, 'auc': 0.70435}
2025-08-16 09:56:26,540 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:56:26,540 - INFO - Layer 10 (Layer_10), Head 3: drop=-0.0011
2025-08-16 09:56:30,807 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21958, 'loss': 0.18879004, 'lr': 0, 'params': 514193, 'time_iter': 0.03271, 'accuracy': 0.96037, 'precision': 0.33663, 'recall': 0.26154, 'f1': 0.29437, 'auc': 0.70288}
2025-08-16 09:56:30,809 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:56:30,809 - INFO - Layer 11 (Layer_11), Head 0: drop=0.0010
2025-08-16 09:56:34,976 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.1187, 'loss': 0.18269498, 'lr': 0, 'params': 514193, 'time_iter': 0.03193, 'accuracy': 0.96256, 'precision': 0.36957, 'recall': 0.26154, 'f1': 0.30631, 'auc': 0.70358}
2025-08-16 09:56:34,977 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:56:34,978 - INFO - Layer 11 (Layer_11), Head 1: drop=-0.0000
2025-08-16 09:56:39,241 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21715, 'loss': 0.18361067, 'lr': 0, 'params': 514193, 'time_iter': 0.03269, 'accuracy': 0.96231, 'precision': 0.36559, 'recall': 0.26154, 'f1': 0.30493, 'auc': 0.7019}
2025-08-16 09:56:39,243 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:56:39,243 - INFO - Layer 11 (Layer_11), Head 2: drop=0.0023
2025-08-16 09:56:43,529 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23907, 'loss': 0.18674437, 'lr': 0, 'params': 514193, 'time_iter': 0.03286, 'accuracy': 0.9611, 'precision': 0.34694, 'recall': 0.26154, 'f1': 0.29825, 'auc': 0.70313}
2025-08-16 09:56:43,531 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:56:43,532 - INFO - Layer 11 (Layer_11), Head 3: drop=0.0006
2025-08-16 09:56:47,813 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23384, 'loss': 0.18355335, 'lr': 0, 'params': 514193, 'time_iter': 0.03282, 'accuracy': 0.96013, 'precision': 0.33333, 'recall': 0.26154, 'f1': 0.2931, 'auc': 0.69755}
2025-08-16 09:56:47,815 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:56:47,815 - INFO - Layer 12 (Layer_12), Head 0: drop=0.0085
2025-08-16 09:56:52,089 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22576, 'loss': 0.18534769, 'lr': 0, 'params': 514193, 'time_iter': 0.03276, 'accuracy': 0.96086, 'precision': 0.34343, 'recall': 0.26154, 'f1': 0.29694, 'auc': 0.70391}
2025-08-16 09:56:52,091 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:56:52,092 - INFO - Layer 12 (Layer_12), Head 1: drop=-0.0005
2025-08-16 09:56:56,368 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22994, 'loss': 0.18591594, 'lr': 0, 'params': 514193, 'time_iter': 0.03279, 'accuracy': 0.96086, 'precision': 0.34343, 'recall': 0.26154, 'f1': 0.29694, 'auc': 0.70424}
2025-08-16 09:56:56,370 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:56:56,371 - INFO - Layer 12 (Layer_12), Head 2: drop=-0.0010
2025-08-16 09:57:00,482 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.06323, 'loss': 0.18136937, 'lr': 0, 'params': 514193, 'time_iter': 0.0315, 'accuracy': 0.96329, 'precision': 0.38202, 'recall': 0.26154, 'f1': 0.3105, 'auc': 0.70402}
2025-08-16 09:57:00,484 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:57:00,484 - INFO - Layer 12 (Layer_12), Head 3: drop=-0.0007
2025-08-16 09:57:04,601 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.06959, 'loss': 0.18428804, 'lr': 0, 'params': 514193, 'time_iter': 0.03155, 'accuracy': 0.96013, 'precision': 0.33333, 'recall': 0.26154, 'f1': 0.2931, 'auc': 0.70001}
2025-08-16 09:57:04,603 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:57:04,603 - INFO - Layer 13 (Layer_13), Head 0: drop=0.0050
2025-08-16 09:57:08,719 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.06793, 'loss': 0.18113493, 'lr': 0, 'params': 514193, 'time_iter': 0.03153, 'accuracy': 0.96183, 'precision': 0.35789, 'recall': 0.26154, 'f1': 0.30222, 'auc': 0.70313}
2025-08-16 09:57:08,721 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:57:08,721 - INFO - Layer 13 (Layer_13), Head 1: drop=0.0006
2025-08-16 09:57:12,852 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.08271, 'loss': 0.1821438, 'lr': 0, 'params': 514193, 'time_iter': 0.03165, 'accuracy': 0.96207, 'precision': 0.3617, 'recall': 0.26154, 'f1': 0.30357, 'auc': 0.70211}
2025-08-16 09:57:12,854 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:57:12,854 - INFO - Layer 13 (Layer_13), Head 2: drop=0.0020
2025-08-16 09:57:16,963 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.0614, 'loss': 0.1826085, 'lr': 0, 'params': 514193, 'time_iter': 0.03148, 'accuracy': 0.96134, 'precision': 0.35052, 'recall': 0.26154, 'f1': 0.29956, 'auc': 0.70046}
2025-08-16 09:57:16,966 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:57:16,966 - INFO - Layer 13 (Layer_13), Head 3: drop=0.0044
2025-08-16 09:57:21,071 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.05753, 'loss': 0.17595038, 'lr': 0, 'params': 514193, 'time_iter': 0.03145, 'accuracy': 0.96304, 'precision': 0.37778, 'recall': 0.26154, 'f1': 0.30909, 'auc': 0.70415}
2025-08-16 09:57:21,073 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:57:21,073 - INFO - Layer 14 (Layer_14), Head 0: drop=-0.0009
2025-08-16 09:57:25,336 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21512, 'loss': 0.17673959, 'lr': 0, 'params': 514193, 'time_iter': 0.03268, 'accuracy': 0.96256, 'precision': 0.36957, 'recall': 0.26154, 'f1': 0.30631, 'auc': 0.70097}
2025-08-16 09:57:25,338 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:57:25,339 - INFO - Layer 14 (Layer_14), Head 1: drop=0.0037
2025-08-16 09:57:29,600 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21303, 'loss': 0.1809282, 'lr': 0, 'params': 514193, 'time_iter': 0.03266, 'accuracy': 0.96183, 'precision': 0.35789, 'recall': 0.26154, 'f1': 0.30222, 'auc': 0.70233}
2025-08-16 09:57:29,602 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:57:29,602 - INFO - Layer 14 (Layer_14), Head 2: drop=0.0017
2025-08-16 09:57:33,876 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2244, 'loss': 0.17880929, 'lr': 0, 'params': 514193, 'time_iter': 0.03275, 'accuracy': 0.96159, 'precision': 0.35417, 'recall': 0.26154, 'f1': 0.30088, 'auc': 0.70234}
2025-08-16 09:57:33,878 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:57:33,878 - INFO - Layer 14 (Layer_14), Head 3: drop=0.0017
2025-08-16 09:57:33,883 - INFO - 
FIDELITY METRICS:
2025-08-16 09:57:33,884 - INFO - Fidelity (top 30 heads): 0.0069
2025-08-16 09:57:33,884 - INFO - Fidelity- (bottom 30 heads): -0.0073
2025-08-16 09:57:33,884 - INFO - 
GNN distribution in important heads:
2025-08-16 09:57:33,884 - INFO -   Layer_13: 4 heads
2025-08-16 09:57:33,884 - INFO -   Layer_11: 4 heads
2025-08-16 09:57:33,884 - INFO -   Layer_0: 3 heads
2025-08-16 09:57:33,884 - INFO -   Layer_14: 3 heads
2025-08-16 09:57:33,884 - INFO -   Layer_7: 2 heads
2025-08-16 09:57:33,884 - INFO -   Layer_1: 2 heads
2025-08-16 09:57:33,884 - INFO -   Layer_6: 2 heads
2025-08-16 09:57:33,884 - INFO -   Layer_9: 2 heads
2025-08-16 09:57:33,884 - INFO -   Layer_10: 2 heads
2025-08-16 09:57:33,884 - INFO -   Layer_8: 2 heads
2025-08-16 09:57:33,884 - INFO -   Layer_4: 1 heads
2025-08-16 09:57:33,884 - INFO -   Layer_12: 1 heads
2025-08-16 09:57:33,884 - INFO -   Layer_5: 1 heads
2025-08-16 09:57:33,884 - INFO -   Layer_3: 1 heads
2025-08-16 09:57:33,884 - INFO - 
Interpretability Analysis:
2025-08-16 09:57:33,884 - INFO -   Fidelity: 0.0069
2025-08-16 09:57:33,884 - INFO -   Fidelity-: -0.0073
2025-08-16 09:57:33,884 - INFO -   Total heads tested: 60
2025-08-16 09:57:34,146 - INFO - Excel results saved to results/molhiv/molhiv-Vanilla-47/pk_explainer_results.xlsx
2025-08-16 09:57:35,359 - INFO - Saved visualizations to results/molhiv/molhiv-Vanilla-47/pk_explainer_results
2025-08-16 09:57:35,361 - INFO - 
PK-Explainer results saved to:
2025-08-16 09:57:35,362 - INFO -   - Excel: results/molhiv/molhiv-Vanilla-47/pk_explainer_results.xlsx
2025-08-16 09:57:35,362 - INFO -   - JSON: results/molhiv/molhiv-Vanilla-47/pk_explainer_results.json
2025-08-16 09:57:35,362 - INFO -   - Visualizations: results/molhiv/molhiv-Vanilla-47/pk_explainer_results
2025-08-16 09:57:35,381 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-47
2025-08-16 09:57:35,382 - INFO - Total time: 8202.92s (2.28h)
2025-08-16 09:57:35,405 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-47/agg
2025-08-16 09:57:35,406 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-16 09:57:35,406 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-47
2025-08-16 09:57:35,406 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-47/test_results/
Completed seed 47. Results saved in results/molhiv/molhiv-Vanilla-47
----------------------------------------
Running experiment with seed: 49
Starting training for seed 49...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/TRANS
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/TRANS/confignas.yaml
Using device: cuda
2025-08-16 09:57:44,500 - INFO - GPU Mem: 34.1GB
2025-08-16 09:57:44,500 - INFO - Run directory: results/molhiv/molhiv-Vanilla-49
2025-08-16 09:57:44,501 - INFO - Seed: 49
2025-08-16 09:57:44,501 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-16 09:57:44,501 - INFO - Routing mode: none
2025-08-16 09:57:44,501 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 09:57:44,501 - INFO - Number of layers: 15
2025-08-16 09:57:44,501 - INFO - Uncertainty enabled: False
2025-08-16 09:57:44,501 - INFO - Training mode: custom
2025-08-16 09:57:44,501 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-16 09:57:44,501 - INFO - Additional features: Router weights logging + JSON export
2025-08-16 09:57:50,685 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 09:57:50,687 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 09:57:50,688 - INFO -   undirected: True
2025-08-16 09:57:50,689 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 09:57:50,689 - INFO -   avg num_nodes/graph: 25
2025-08-16 09:57:50,689 - INFO -   num node features: 9
2025-08-16 09:57:50,689 - INFO -   num edge features: 3
2025-08-16 09:57:50,689 - INFO -   num tasks: 1
2025-08-16 09:57:50,690 - INFO -   num classes: 2
2025-08-16 09:57:50,690 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 09:57:50,690 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 09:57:50,693 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  8%|▊         | 3361/41127 [00:10<01:52, 334.60it/s] 13%|█▎        | 5417/41127 [00:22<02:37, 227.36it/s] 13%|█▎        | 5417/41127 [00:33<02:37, 227.36it/s] 16%|█▌        | 6448/41127 [00:34<03:35, 161.30it/s] 17%|█▋        | 7019/41127 [00:44<04:35, 123.74it/s] 23%|██▎       | 9298/41127 [00:54<03:20, 158.75it/s] 26%|██▋       | 10867/41127 [01:04<03:13, 156.43it/s] 33%|███▎      | 13615/41127 [01:14<02:22, 193.46it/s] 36%|███▌      | 14745/41127 [01:24<02:36, 168.27it/s] 38%|███▊      | 15606/41127 [01:35<02:59, 142.21it/s] 44%|████▎     | 17961/41127 [01:45<02:15, 170.51it/s] 51%|█████     | 20801/41127 [01:55<01:39, 203.45it/s] 55%|█████▍    | 22486/41127 [02:05<01:37, 191.35it/s] 60%|█████▉    | 24483/41127 [02:15<01:25, 193.70it/s] 65%|██████▌   | 26819/41127 [02:25<01:10, 203.25it/s] 71%|███████   | 29273/41127 [02:36<00:55, 213.31it/s] 78%|███████▊  | 32112/41127 [02:46<00:38, 233.79it/s] 84%|████████▎ | 34388/41127 [02:56<00:29, 231.95it/s] 90%|█████████ | 37186/41127 [03:06<00:16, 246.04it/s] 95%|█████████▌| 39264/41127 [03:16<00:08, 232.19it/s]100%|█████████▉| 40958/41127 [03:27<00:00, 212.30it/s]100%|██████████| 41127/41127 [03:28<00:00, 197.19it/s]
2025-08-16 10:01:20,461 - INFO - Done! Took 00:03:29.77
2025-08-16 10:01:20,608 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 10:01:20,725 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-16 10:01:20,726 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-08-16 10:01:20,726 - INFO - Inner model has get_darts_model: False
2025-08-16 10:01:20,729 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-08-16 10:01:20,731 - INFO - Number of parameters: 514,193
2025-08-16 10:01:20,731 - INFO - Starting optimized training: 2025-08-16 10:01:20.731848
2025-08-16 10:01:26,922 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 10:01:26,922 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 10:01:26,923 - INFO -   undirected: True
2025-08-16 10:01:26,923 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 10:01:26,924 - INFO -   avg num_nodes/graph: 25
2025-08-16 10:01:26,924 - INFO -   num node features: 9
2025-08-16 10:01:26,924 - INFO -   num edge features: 3
2025-08-16 10:01:26,924 - INFO -   num tasks: 1
2025-08-16 10:01:26,924 - INFO -   num classes: 2
2025-08-16 10:01:26,924 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 10:01:26,924 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 10:01:26,927 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  7%|▋         | 2905/41127 [00:10<02:11, 290.50it/s] 12%|█▏        | 5038/41127 [00:20<02:27, 243.94it/s] 12%|█▏        | 5038/41127 [00:37<02:27, 243.94it/s] 16%|█▌        | 6499/41127 [00:37<03:55, 147.01it/s] 18%|█▊        | 7603/41127 [00:48<04:09, 134.38it/s] 24%|██▍       | 9906/41127 [00:58<03:10, 163.72it/s] 28%|██▊       | 11655/41127 [01:08<02:56, 167.18it/s] 34%|███▎      | 13800/41127 [01:18<02:30, 181.44it/s] 36%|███▌      | 14745/41127 [01:28<02:50, 154.59it/s] 38%|███▊      | 15510/41127 [01:38<03:15, 130.95it/s] 40%|███▉      | 16424/41127 [01:48<03:30, 117.51it/s] 44%|████▍     | 18107/41127 [01:59<02:54, 131.62it/s] 48%|████▊     | 19554/41127 [02:09<02:40, 134.74it/s] 52%|█████▏    | 21250/41127 [02:19<02:17, 144.75it/s] 61%|██████    | 24885/41127 [02:29<01:17, 209.78it/s] 74%|███████▎  | 30249/41127 [02:39<00:35, 307.15it/s] 85%|████████▌ | 35156/41127 [02:49<00:16, 359.03it/s] 99%|█████████▉| 40692/41127 [02:59<00:01, 416.88it/s]100%|██████████| 41127/41127 [03:05<00:00, 221.74it/s]
2025-08-16 10:04:33,582 - INFO - Done! Took 00:03:06.66
2025-08-16 10:04:33,729 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 10:04:33,744 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-16 10:04:33,744 - INFO - Start from epoch 0
2025-08-16 10:05:54,590 - INFO - train: {'epoch': 0, 'time_epoch': 80.64969, 'eta': 7984.31935, 'eta_hours': 2.21787, 'loss': 0.73745467, 'lr': 0.0, 'params': 514193, 'time_iter': 0.07838, 'accuracy': 0.04778, 'precision': 0.03761, 'recall': 0.99351, 'f1': 0.07248, 'auc': 0.5461}
2025-08-16 10:05:54,604 - INFO - ...computing epoch stats took: 0.19s
2025-08-16 10:06:00,419 - INFO - val: {'epoch': 0, 'time_epoch': 5.79676, 'loss': 0.73886563, 'lr': 0, 'params': 514193, 'time_iter': 0.04494, 'accuracy': 0.03647, 'precision': 0.02003, 'recall': 1.0, 'f1': 0.03927, 'auc': 0.45448}
2025-08-16 10:06:00,472 - INFO - ...computing epoch stats took: 0.07s
2025-08-16 10:06:05,411 - INFO - test: {'epoch': 0, 'time_epoch': 4.92278, 'loss': 0.73421257, 'lr': 0, 'params': 514193, 'time_iter': 0.03816, 'accuracy': 0.05981, 'precision': 0.03206, 'recall': 0.98462, 'f1': 0.06209, 'auc': 0.51639}
2025-08-16 10:06:05,441 - INFO - ...computing epoch stats took: 0.04s
2025-08-16 10:06:05,441 - INFO - > Epoch 0: took 91.7s (avg 91.7s) | Best so far: epoch 0	train_loss: 0.7375 train_auc: 0.5461	val_loss: 0.7389 val_auc: 0.4545	test_loss: 0.7342 test_auc: 0.5164
2025-08-16 10:07:17,223 - INFO - train: {'epoch': 1, 'time_epoch': 71.66001, 'eta': 7463.17549, 'eta_hours': 2.0731, 'loss': 0.41688263, 'lr': 2e-05, 'params': 514193, 'time_iter': 0.06964, 'accuracy': 0.88435, 'precision': 0.0407, 'recall': 0.09253, 'f1': 0.05653, 'auc': 0.54675}
2025-08-16 10:07:17,233 - INFO - ...computing epoch stats took: 0.11s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:07:21,790 - INFO - val: {'epoch': 1, 'time_epoch': 4.51149, 'loss': 0.18936428, 'lr': 0, 'params': 514193, 'time_iter': 0.03497, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6302}
2025-08-16 10:07:21,793 - INFO - ...computing epoch stats took: 0.05s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:07:26,281 - INFO - test: {'epoch': 1, 'time_epoch': 4.4728, 'loss': 0.20282214, 'lr': 0, 'params': 514193, 'time_iter': 0.03467, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6722}
2025-08-16 10:07:26,284 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 10:07:26,284 - INFO - > Epoch 1: took 80.8s (avg 86.3s) | Best so far: epoch 1	train_loss: 0.4169 train_auc: 0.5467	val_loss: 0.1894 val_auc: 0.6302	test_loss: 0.2028 test_auc: 0.6722
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:08:35,757 - INFO - train: {'epoch': 2, 'time_epoch': 69.37393, 'eta': 7167.77073, 'eta_hours': 1.99105, 'loss': 0.16835699, 'lr': 4e-05, 'params': 514193, 'time_iter': 0.06742, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.62055}
2025-08-16 10:08:35,765 - INFO - ...computing epoch stats took: 0.09s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:08:40,170 - INFO - val: {'epoch': 2, 'time_epoch': 4.39105, 'loss': 0.10130083, 'lr': 0, 'params': 514193, 'time_iter': 0.03404, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.65957}
2025-08-16 10:08:40,172 - INFO - ...computing epoch stats took: 0.01s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:08:44,580 - INFO - test: {'epoch': 2, 'time_epoch': 4.39431, 'loss': 0.13502333, 'lr': 0, 'params': 514193, 'time_iter': 0.03406, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69329}
2025-08-16 10:08:44,582 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 10:08:44,583 - INFO - > Epoch 2: took 78.3s (avg 83.6s) | Best so far: epoch 2	train_loss: 0.1684 train_auc: 0.6206	val_loss: 0.1013 val_auc: 0.6596	test_loss: 0.1350 test_auc: 0.6933
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:09:54,985 - INFO - train: {'epoch': 3, 'time_epoch': 70.30246, 'eta': 7007.66612, 'eta_hours': 1.94657, 'loss': 0.15405471, 'lr': 6e-05, 'params': 514193, 'time_iter': 0.06832, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66698}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:09:59,493 - INFO - val: {'epoch': 3, 'time_epoch': 4.48475, 'loss': 0.09649753, 'lr': 0, 'params': 514193, 'time_iter': 0.03477, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73027}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:10:03,836 - INFO - test: {'epoch': 3, 'time_epoch': 4.32471, 'loss': 0.12800228, 'lr': 0, 'params': 514193, 'time_iter': 0.03352, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74128}
2025-08-16 10:10:03,838 - INFO - > Epoch 3: took 79.3s (avg 82.5s) | Best so far: epoch 3	train_loss: 0.1541 train_auc: 0.6670	val_loss: 0.0965 val_auc: 0.7303	test_loss: 0.1280 test_auc: 0.7413
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:11:13,815 - INFO - train: {'epoch': 4, 'time_epoch': 69.876, 'eta': 6875.37975, 'eta_hours': 1.90983, 'loss': 0.14647841, 'lr': 8e-05, 'params': 514193, 'time_iter': 0.06791, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71281}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:11:18,223 - INFO - val: {'epoch': 4, 'time_epoch': 4.38014, 'loss': 0.0881018, 'lr': 0, 'params': 514193, 'time_iter': 0.03395, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71674}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:11:22,500 - INFO - test: {'epoch': 4, 'time_epoch': 4.25855, 'loss': 0.12877815, 'lr': 0, 'params': 514193, 'time_iter': 0.03301, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69978}
2025-08-16 10:11:22,503 - INFO - > Epoch 4: took 78.7s (avg 81.8s) | Best so far: epoch 3	train_loss: 0.1541 train_auc: 0.6670	val_loss: 0.0965 val_auc: 0.7303	test_loss: 0.1280 test_auc: 0.7413
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:12:30,352 - INFO - train: {'epoch': 5, 'time_epoch': 67.75259, 'eta': 6730.63008, 'eta_hours': 1.86962, 'loss': 0.1424444, 'lr': 0.0001, 'params': 514193, 'time_iter': 0.06584, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72516}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:12:34,790 - INFO - val: {'epoch': 5, 'time_epoch': 4.41541, 'loss': 0.09720514, 'lr': 0, 'params': 514193, 'time_iter': 0.03423, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.65244}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:12:39,170 - INFO - test: {'epoch': 5, 'time_epoch': 4.36353, 'loss': 0.12649232, 'lr': 0, 'params': 514193, 'time_iter': 0.03383, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71421}
2025-08-16 10:12:39,173 - INFO - > Epoch 5: took 76.7s (avg 80.9s) | Best so far: epoch 3	train_loss: 0.1541 train_auc: 0.6670	val_loss: 0.0965 val_auc: 0.7303	test_loss: 0.1280 test_auc: 0.7413
2025-08-16 10:13:47,667 - INFO - train: {'epoch': 6, 'time_epoch': 68.38436, 'eta': 6616.27304, 'eta_hours': 1.83785, 'loss': 0.13755982, 'lr': 9.997e-05, 'params': 514193, 'time_iter': 0.06646, 'accuracy': 0.96249, 'precision': 0.375, 'recall': 0.00244, 'f1': 0.00484, 'auc': 0.74688}
2025-08-16 10:13:51,880 - INFO - val: {'epoch': 6, 'time_epoch': 4.19081, 'loss': 0.10384679, 'lr': 0, 'params': 514193, 'time_iter': 0.03249, 'accuracy': 0.98055, 'precision': 1.0, 'recall': 0.01235, 'f1': 0.02439, 'auc': 0.68392}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:13:55,885 - INFO - test: {'epoch': 6, 'time_epoch': 3.98982, 'loss': 0.13165885, 'lr': 0, 'params': 514193, 'time_iter': 0.03093, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73444}
2025-08-16 10:13:55,888 - INFO - > Epoch 6: took 76.7s (avg 80.3s) | Best so far: epoch 3	train_loss: 0.1541 train_auc: 0.6670	val_loss: 0.0965 val_auc: 0.7303	test_loss: 0.1280 test_auc: 0.7413
2025-08-16 10:15:02,654 - INFO - train: {'epoch': 7, 'time_epoch': 66.65968, 'eta': 6493.57531, 'eta_hours': 1.80377, 'loss': 0.13465009, 'lr': 9.989e-05, 'params': 514193, 'time_iter': 0.06478, 'accuracy': 0.96328, 'precision': 0.625, 'recall': 0.0487, 'f1': 0.09036, 'auc': 0.758}
2025-08-16 10:15:06,916 - INFO - val: {'epoch': 7, 'time_epoch': 4.24035, 'loss': 0.09367914, 'lr': 0, 'params': 514193, 'time_iter': 0.03287, 'accuracy': 0.98177, 'precision': 0.63636, 'recall': 0.17284, 'f1': 0.27184, 'auc': 0.70047}
2025-08-16 10:15:11,109 - INFO - test: {'epoch': 7, 'time_epoch': 4.17607, 'loss': 0.12495444, 'lr': 0, 'params': 514193, 'time_iter': 0.03237, 'accuracy': 0.96888, 'precision': 0.52, 'recall': 0.2, 'f1': 0.28889, 'auc': 0.73426}
2025-08-16 10:15:11,111 - INFO - > Epoch 7: took 75.2s (avg 79.7s) | Best so far: epoch 3	train_loss: 0.1541 train_auc: 0.6670	val_loss: 0.0965 val_auc: 0.7303	test_loss: 0.1280 test_auc: 0.7413
2025-08-16 10:16:19,304 - INFO - train: {'epoch': 8, 'time_epoch': 68.08547, 'eta': 6397.74684, 'eta_hours': 1.77715, 'loss': 0.1321221, 'lr': 9.975e-05, 'params': 514193, 'time_iter': 0.06617, 'accuracy': 0.96395, 'precision': 0.61275, 'recall': 0.10146, 'f1': 0.17409, 'auc': 0.76855}
2025-08-16 10:16:23,714 - INFO - val: {'epoch': 8, 'time_epoch': 4.38756, 'loss': 0.08828557, 'lr': 0, 'params': 514193, 'time_iter': 0.03401, 'accuracy': 0.98225, 'precision': 0.72222, 'recall': 0.16049, 'f1': 0.26263, 'auc': 0.74427}
2025-08-16 10:16:27,957 - INFO - test: {'epoch': 8, 'time_epoch': 4.22649, 'loss': 0.12214515, 'lr': 0, 'params': 514193, 'time_iter': 0.03276, 'accuracy': 0.96815, 'precision': 0.45455, 'recall': 0.03846, 'f1': 0.07092, 'auc': 0.74576}
2025-08-16 10:16:27,960 - INFO - > Epoch 8: took 76.8s (avg 79.4s) | Best so far: epoch 8	train_loss: 0.1321 train_auc: 0.7685	val_loss: 0.0883 val_auc: 0.7443	test_loss: 0.1221 test_auc: 0.7458
2025-08-16 10:17:35,957 - INFO - train: {'epoch': 9, 'time_epoch': 67.88873, 'eta': 6305.69635, 'eta_hours': 1.75158, 'loss': 0.12975904, 'lr': 9.956e-05, 'params': 514193, 'time_iter': 0.06598, 'accuracy': 0.9645, 'precision': 0.60596, 'recall': 0.14854, 'f1': 0.23859, 'auc': 0.7809}
2025-08-16 10:17:40,311 - INFO - val: {'epoch': 9, 'time_epoch': 4.33085, 'loss': 0.08415894, 'lr': 0, 'params': 514193, 'time_iter': 0.03357, 'accuracy': 0.98177, 'precision': 0.625, 'recall': 0.18519, 'f1': 0.28571, 'auc': 0.73889}
2025-08-16 10:17:44,549 - INFO - test: {'epoch': 9, 'time_epoch': 4.22127, 'loss': 0.11752563, 'lr': 0, 'params': 514193, 'time_iter': 0.03272, 'accuracy': 0.96985, 'precision': 0.61538, 'recall': 0.12308, 'f1': 0.20513, 'auc': 0.76626}
2025-08-16 10:17:44,551 - INFO - > Epoch 9: took 76.6s (avg 79.1s) | Best so far: epoch 8	train_loss: 0.1321 train_auc: 0.7685	val_loss: 0.0883 val_auc: 0.7443	test_loss: 0.1221 test_auc: 0.7458
2025-08-16 10:18:52,956 - INFO - train: {'epoch': 10, 'time_epoch': 68.2986, 'eta': 6221.3551, 'eta_hours': 1.72815, 'loss': 0.12629652, 'lr': 9.932e-05, 'params': 514193, 'time_iter': 0.06637, 'accuracy': 0.96562, 'precision': 0.63185, 'recall': 0.19643, 'f1': 0.29969, 'auc': 0.7867}
2025-08-16 10:18:57,128 - INFO - val: {'epoch': 10, 'time_epoch': 4.14983, 'loss': 0.09006693, 'lr': 0, 'params': 514193, 'time_iter': 0.03217, 'accuracy': 0.97933, 'precision': 0.44737, 'recall': 0.20988, 'f1': 0.28571, 'auc': 0.7257}
2025-08-16 10:19:01,269 - INFO - test: {'epoch': 10, 'time_epoch': 4.12413, 'loss': 0.11759373, 'lr': 0, 'params': 514193, 'time_iter': 0.03197, 'accuracy': 0.96572, 'precision': 0.4127, 'recall': 0.2, 'f1': 0.26943, 'auc': 0.77357}
2025-08-16 10:19:01,271 - INFO - > Epoch 10: took 76.7s (avg 78.9s) | Best so far: epoch 8	train_loss: 0.1321 train_auc: 0.7685	val_loss: 0.0883 val_auc: 0.7443	test_loss: 0.1221 test_auc: 0.7458
2025-08-16 10:20:08,100 - INFO - train: {'epoch': 11, 'time_epoch': 66.72225, 'eta': 6128.12775, 'eta_hours': 1.70226, 'loss': 0.12594438, 'lr': 9.902e-05, 'params': 514193, 'time_iter': 0.06484, 'accuracy': 0.96562, 'precision': 0.63325, 'recall': 0.19481, 'f1': 0.29795, 'auc': 0.79421}
2025-08-16 10:20:12,366 - INFO - val: {'epoch': 11, 'time_epoch': 4.24529, 'loss': 0.08662796, 'lr': 0, 'params': 514193, 'time_iter': 0.03291, 'accuracy': 0.98079, 'precision': 0.53333, 'recall': 0.19753, 'f1': 0.28829, 'auc': 0.71808}
2025-08-16 10:20:16,487 - INFO - test: {'epoch': 11, 'time_epoch': 4.10405, 'loss': 0.12102407, 'lr': 0, 'params': 514193, 'time_iter': 0.03181, 'accuracy': 0.96912, 'precision': 0.52632, 'recall': 0.23077, 'f1': 0.32086, 'auc': 0.7514}
2025-08-16 10:20:16,490 - INFO - > Epoch 11: took 75.2s (avg 78.6s) | Best so far: epoch 8	train_loss: 0.1321 train_auc: 0.7685	val_loss: 0.0883 val_auc: 0.7443	test_loss: 0.1221 test_auc: 0.7458
2025-08-16 10:21:24,149 - INFO - train: {'epoch': 12, 'time_epoch': 67.55184, 'eta': 6044.52996, 'eta_hours': 1.67904, 'loss': 0.12308642, 'lr': 9.867e-05, 'params': 514193, 'time_iter': 0.06565, 'accuracy': 0.96629, 'precision': 0.65261, 'recall': 0.21347, 'f1': 0.32171, 'auc': 0.80377}
2025-08-16 10:21:28,573 - INFO - val: {'epoch': 12, 'time_epoch': 4.40079, 'loss': 0.08904794, 'lr': 0, 'params': 514193, 'time_iter': 0.03411, 'accuracy': 0.97544, 'precision': 0.32143, 'recall': 0.22222, 'f1': 0.26277, 'auc': 0.75863}
2025-08-16 10:21:32,922 - INFO - test: {'epoch': 12, 'time_epoch': 4.33243, 'loss': 0.12667586, 'lr': 0, 'params': 514193, 'time_iter': 0.03358, 'accuracy': 0.96377, 'precision': 0.38272, 'recall': 0.23846, 'f1': 0.29384, 'auc': 0.74818}
2025-08-16 10:21:32,924 - INFO - > Epoch 12: took 76.4s (avg 78.4s) | Best so far: epoch 12	train_loss: 0.1231 train_auc: 0.8038	val_loss: 0.0890 val_auc: 0.7586	test_loss: 0.1267 test_auc: 0.7482
2025-08-16 10:22:41,356 - INFO - train: {'epoch': 13, 'time_epoch': 68.33011, 'eta': 5968.00524, 'eta_hours': 1.65778, 'loss': 0.12035757, 'lr': 9.826e-05, 'params': 514193, 'time_iter': 0.0664, 'accuracy': 0.96699, 'precision': 0.66079, 'recall': 0.24351, 'f1': 0.35587, 'auc': 0.81111}
2025-08-16 10:22:45,669 - INFO - val: {'epoch': 13, 'time_epoch': 4.29139, 'loss': 0.08125683, 'lr': 0, 'params': 514193, 'time_iter': 0.03327, 'accuracy': 0.98152, 'precision': 0.6087, 'recall': 0.17284, 'f1': 0.26923, 'auc': 0.73884}
2025-08-16 10:22:49,935 - INFO - test: {'epoch': 13, 'time_epoch': 4.24922, 'loss': 0.11711259, 'lr': 0, 'params': 514193, 'time_iter': 0.03294, 'accuracy': 0.97204, 'precision': 0.74194, 'recall': 0.17692, 'f1': 0.28571, 'auc': 0.73346}
2025-08-16 10:22:49,937 - INFO - > Epoch 13: took 77.0s (avg 78.3s) | Best so far: epoch 12	train_loss: 0.1231 train_auc: 0.8038	val_loss: 0.0890 val_auc: 0.7586	test_loss: 0.1267 test_auc: 0.7482
2025-08-16 10:23:56,647 - INFO - train: {'epoch': 14, 'time_epoch': 66.60159, 'eta': 5882.77821, 'eta_hours': 1.63411, 'loss': 0.11915722, 'lr': 9.78e-05, 'params': 514193, 'time_iter': 0.06472, 'accuracy': 0.9666, 'precision': 0.64877, 'recall': 0.23539, 'f1': 0.34544, 'auc': 0.819}
2025-08-16 10:24:00,952 - INFO - val: {'epoch': 14, 'time_epoch': 4.28311, 'loss': 0.08528102, 'lr': 0, 'params': 514193, 'time_iter': 0.0332, 'accuracy': 0.97885, 'precision': 0.43182, 'recall': 0.23457, 'f1': 0.304, 'auc': 0.73229}
2025-08-16 10:24:05,103 - INFO - test: {'epoch': 14, 'time_epoch': 4.13473, 'loss': 0.1175758, 'lr': 0, 'params': 514193, 'time_iter': 0.03205, 'accuracy': 0.96718, 'precision': 0.46479, 'recall': 0.25385, 'f1': 0.32836, 'auc': 0.7616}
2025-08-16 10:24:05,106 - INFO - > Epoch 14: took 75.2s (avg 78.1s) | Best so far: epoch 12	train_loss: 0.1231 train_auc: 0.8038	val_loss: 0.0890 val_auc: 0.7586	test_loss: 0.1267 test_auc: 0.7482
2025-08-16 10:25:12,942 - INFO - train: {'epoch': 15, 'time_epoch': 67.72906, 'eta': 5805.79855, 'eta_hours': 1.61272, 'loss': 0.11648976, 'lr': 9.729e-05, 'params': 514193, 'time_iter': 0.06582, 'accuracy': 0.9672, 'precision': 0.66381, 'recall': 0.25162, 'f1': 0.36492, 'auc': 0.82356}
2025-08-16 10:25:17,376 - INFO - val: {'epoch': 15, 'time_epoch': 4.4116, 'loss': 0.08756686, 'lr': 0, 'params': 514193, 'time_iter': 0.0342, 'accuracy': 0.97617, 'precision': 0.33333, 'recall': 0.20988, 'f1': 0.25758, 'auc': 0.78494}
2025-08-16 10:25:21,677 - INFO - test: {'epoch': 15, 'time_epoch': 4.28441, 'loss': 0.11955593, 'lr': 0, 'params': 514193, 'time_iter': 0.03321, 'accuracy': 0.96864, 'precision': 0.50526, 'recall': 0.36923, 'f1': 0.42667, 'auc': 0.76097}
2025-08-16 10:25:21,680 - INFO - > Epoch 15: took 76.6s (avg 78.0s) | Best so far: epoch 15	train_loss: 0.1165 train_auc: 0.8236	val_loss: 0.0876 val_auc: 0.7849	test_loss: 0.1196 test_auc: 0.7610
2025-08-16 10:26:28,692 - INFO - train: {'epoch': 16, 'time_epoch': 66.90562, 'eta': 5725.88686, 'eta_hours': 1.59052, 'loss': 0.11593098, 'lr': 9.673e-05, 'params': 514193, 'time_iter': 0.06502, 'accuracy': 0.96693, 'precision': 0.64575, 'recall': 0.25893, 'f1': 0.36964, 'auc': 0.82876}
2025-08-16 10:26:33,158 - INFO - val: {'epoch': 16, 'time_epoch': 4.44365, 'loss': 0.08416681, 'lr': 0, 'params': 514193, 'time_iter': 0.03445, 'accuracy': 0.97958, 'precision': 0.46341, 'recall': 0.23457, 'f1': 0.31148, 'auc': 0.78483}
2025-08-16 10:26:37,381 - INFO - test: {'epoch': 16, 'time_epoch': 4.20477, 'loss': 0.11794566, 'lr': 0, 'params': 514193, 'time_iter': 0.0326, 'accuracy': 0.96718, 'precision': 0.46914, 'recall': 0.29231, 'f1': 0.36019, 'auc': 0.7701}
2025-08-16 10:26:37,383 - INFO - > Epoch 16: took 75.7s (avg 77.9s) | Best so far: epoch 15	train_loss: 0.1165 train_auc: 0.8236	val_loss: 0.0876 val_auc: 0.7849	test_loss: 0.1196 test_auc: 0.7610
2025-08-16 10:27:43,644 - INFO - train: {'epoch': 17, 'time_epoch': 66.15397, 'eta': 5643.99612, 'eta_hours': 1.56778, 'loss': 0.11393416, 'lr': 9.611e-05, 'params': 514193, 'time_iter': 0.06429, 'accuracy': 0.96793, 'precision': 0.67251, 'recall': 0.28003, 'f1': 0.39542, 'auc': 0.83752}
2025-08-16 10:27:47,775 - INFO - val: {'epoch': 17, 'time_epoch': 4.11025, 'loss': 0.0818393, 'lr': 0, 'params': 514193, 'time_iter': 0.03186, 'accuracy': 0.98055, 'precision': 0.51282, 'recall': 0.24691, 'f1': 0.33333, 'auc': 0.78181}
2025-08-16 10:27:51,850 - INFO - test: {'epoch': 17, 'time_epoch': 4.05854, 'loss': 0.12063361, 'lr': 0, 'params': 514193, 'time_iter': 0.03146, 'accuracy': 0.96888, 'precision': 0.51852, 'recall': 0.21538, 'f1': 0.30435, 'auc': 0.74346}
2025-08-16 10:27:51,852 - INFO - > Epoch 17: took 74.5s (avg 77.7s) | Best so far: epoch 15	train_loss: 0.1165 train_auc: 0.8236	val_loss: 0.0876 val_auc: 0.7849	test_loss: 0.1196 test_auc: 0.7610
2025-08-16 10:28:56,845 - INFO - train: {'epoch': 18, 'time_epoch': 64.87775, 'eta': 5558.32115, 'eta_hours': 1.54398, 'loss': 0.11233266, 'lr': 9.545e-05, 'params': 514193, 'time_iter': 0.06305, 'accuracy': 0.96879, 'precision': 0.69524, 'recall': 0.29627, 'f1': 0.41548, 'auc': 0.83854}
2025-08-16 10:29:01,086 - INFO - val: {'epoch': 18, 'time_epoch': 4.21655, 'loss': 0.08556534, 'lr': 0, 'params': 514193, 'time_iter': 0.03269, 'accuracy': 0.97812, 'precision': 0.41176, 'recall': 0.25926, 'f1': 0.31818, 'auc': 0.78163}
2025-08-16 10:29:05,172 - INFO - test: {'epoch': 18, 'time_epoch': 4.06687, 'loss': 0.12384787, 'lr': 0, 'params': 514193, 'time_iter': 0.03153, 'accuracy': 0.96645, 'precision': 0.44118, 'recall': 0.23077, 'f1': 0.30303, 'auc': 0.75465}
2025-08-16 10:29:05,174 - INFO - > Epoch 18: took 73.3s (avg 77.4s) | Best so far: epoch 15	train_loss: 0.1165 train_auc: 0.8236	val_loss: 0.0876 val_auc: 0.7849	test_loss: 0.1196 test_auc: 0.7610
2025-08-16 10:30:10,014 - INFO - train: {'epoch': 19, 'time_epoch': 64.72082, 'eta': 5474.09819, 'eta_hours': 1.52058, 'loss': 0.11212657, 'lr': 9.474e-05, 'params': 514193, 'time_iter': 0.0629, 'accuracy': 0.96936, 'precision': 0.71132, 'recall': 0.30601, 'f1': 0.42792, 'auc': 0.8392}
2025-08-16 10:30:14,461 - INFO - val: {'epoch': 19, 'time_epoch': 4.41901, 'loss': 0.08637943, 'lr': 0, 'params': 514193, 'time_iter': 0.03426, 'accuracy': 0.97812, 'precision': 0.41176, 'recall': 0.25926, 'f1': 0.31818, 'auc': 0.7712}
2025-08-16 10:30:18,653 - INFO - test: {'epoch': 19, 'time_epoch': 4.17478, 'loss': 0.12213379, 'lr': 0, 'params': 514193, 'time_iter': 0.03236, 'accuracy': 0.96815, 'precision': 0.49367, 'recall': 0.3, 'f1': 0.37321, 'auc': 0.75436}
2025-08-16 10:30:18,656 - INFO - > Epoch 19: took 73.5s (avg 77.2s) | Best so far: epoch 15	train_loss: 0.1165 train_auc: 0.8236	val_loss: 0.0876 val_auc: 0.7849	test_loss: 0.1196 test_auc: 0.7610
2025-08-16 10:31:24,148 - INFO - train: {'epoch': 20, 'time_epoch': 65.38442, 'eta': 5394.22898, 'eta_hours': 1.4984, 'loss': 0.11093382, 'lr': 9.397e-05, 'params': 514193, 'time_iter': 0.06354, 'accuracy': 0.96906, 'precision': 0.70898, 'recall': 0.29464, 'f1': 0.41628, 'auc': 0.84888}
2025-08-16 10:31:28,374 - INFO - val: {'epoch': 20, 'time_epoch': 4.20082, 'loss': 0.0924659, 'lr': 0, 'params': 514193, 'time_iter': 0.03256, 'accuracy': 0.97666, 'precision': 0.38095, 'recall': 0.2963, 'f1': 0.33333, 'auc': 0.75313}
2025-08-16 10:31:32,495 - INFO - test: {'epoch': 20, 'time_epoch': 4.10169, 'loss': 0.13147989, 'lr': 0, 'params': 514193, 'time_iter': 0.0318, 'accuracy': 0.96304, 'precision': 0.40517, 'recall': 0.36154, 'f1': 0.38211, 'auc': 0.73943}
2025-08-16 10:31:32,498 - INFO - > Epoch 20: took 73.8s (avg 77.1s) | Best so far: epoch 15	train_loss: 0.1165 train_auc: 0.8236	val_loss: 0.0876 val_auc: 0.7849	test_loss: 0.1196 test_auc: 0.7610
2025-08-16 10:32:37,347 - INFO - train: {'epoch': 21, 'time_epoch': 64.74225, 'eta': 5313.39977, 'eta_hours': 1.47594, 'loss': 0.11032043, 'lr': 9.316e-05, 'params': 514193, 'time_iter': 0.06292, 'accuracy': 0.96954, 'precision': 0.70985, 'recall': 0.31575, 'f1': 0.43708, 'auc': 0.8464}
2025-08-16 10:32:41,496 - INFO - val: {'epoch': 21, 'time_epoch': 4.1274, 'loss': 0.08767009, 'lr': 0, 'params': 514193, 'time_iter': 0.032, 'accuracy': 0.97836, 'precision': 0.42593, 'recall': 0.28395, 'f1': 0.34074, 'auc': 0.74974}
2025-08-16 10:32:45,578 - INFO - test: {'epoch': 21, 'time_epoch': 4.06577, 'loss': 0.13048604, 'lr': 0, 'params': 514193, 'time_iter': 0.03152, 'accuracy': 0.96475, 'precision': 0.41379, 'recall': 0.27692, 'f1': 0.3318, 'auc': 0.73049}
2025-08-16 10:32:45,597 - INFO - > Epoch 21: took 73.1s (avg 76.9s) | Best so far: epoch 15	train_loss: 0.1165 train_auc: 0.8236	val_loss: 0.0876 val_auc: 0.7849	test_loss: 0.1196 test_auc: 0.7610
2025-08-16 10:33:51,011 - INFO - train: {'epoch': 22, 'time_epoch': 65.30534, 'eta': 5235.85457, 'eta_hours': 1.4544, 'loss': 0.10779144, 'lr': 9.23e-05, 'params': 514193, 'time_iter': 0.06346, 'accuracy': 0.96912, 'precision': 0.69926, 'recall': 0.30763, 'f1': 0.42728, 'auc': 0.86313}
2025-08-16 10:33:55,099 - INFO - val: {'epoch': 22, 'time_epoch': 4.06752, 'loss': 0.08705659, 'lr': 0, 'params': 514193, 'time_iter': 0.03153, 'accuracy': 0.97812, 'precision': 0.42373, 'recall': 0.30864, 'f1': 0.35714, 'auc': 0.77227}
2025-08-16 10:33:59,055 - INFO - test: {'epoch': 22, 'time_epoch': 3.93992, 'loss': 0.12850558, 'lr': 0, 'params': 514193, 'time_iter': 0.03054, 'accuracy': 0.96596, 'precision': 0.44792, 'recall': 0.33077, 'f1': 0.38053, 'auc': 0.74968}
2025-08-16 10:33:59,057 - INFO - > Epoch 22: took 73.5s (avg 76.8s) | Best so far: epoch 15	train_loss: 0.1165 train_auc: 0.8236	val_loss: 0.0876 val_auc: 0.7849	test_loss: 0.1196 test_auc: 0.7610
2025-08-16 10:35:02,943 - INFO - train: {'epoch': 23, 'time_epoch': 63.77916, 'eta': 5154.49644, 'eta_hours': 1.4318, 'loss': 0.10604264, 'lr': 9.14e-05, 'params': 514193, 'time_iter': 0.06198, 'accuracy': 0.97085, 'precision': 0.73657, 'recall': 0.34497, 'f1': 0.46987, 'auc': 0.86229}
2025-08-16 10:35:07,030 - INFO - val: {'epoch': 23, 'time_epoch': 4.06708, 'loss': 0.08420214, 'lr': 0, 'params': 514193, 'time_iter': 0.03153, 'accuracy': 0.97812, 'precision': 0.40816, 'recall': 0.24691, 'f1': 0.30769, 'auc': 0.77072}
2025-08-16 10:35:11,026 - INFO - test: {'epoch': 23, 'time_epoch': 3.98, 'loss': 0.12563268, 'lr': 0, 'params': 514193, 'time_iter': 0.03085, 'accuracy': 0.96791, 'precision': 0.4878, 'recall': 0.30769, 'f1': 0.37736, 'auc': 0.74009}
2025-08-16 10:35:11,029 - INFO - > Epoch 23: took 72.0s (avg 76.6s) | Best so far: epoch 15	train_loss: 0.1165 train_auc: 0.8236	val_loss: 0.0876 val_auc: 0.7849	test_loss: 0.1196 test_auc: 0.7610
2025-08-16 10:36:15,555 - INFO - train: {'epoch': 24, 'time_epoch': 64.42164, 'eta': 5076.47206, 'eta_hours': 1.41013, 'loss': 0.1056577, 'lr': 9.045e-05, 'params': 514193, 'time_iter': 0.06261, 'accuracy': 0.97018, 'precision': 0.72056, 'recall': 0.33279, 'f1': 0.4553, 'auc': 0.86749}
2025-08-16 10:36:19,697 - INFO - val: {'epoch': 24, 'time_epoch': 4.12008, 'loss': 0.0788423, 'lr': 0, 'params': 514193, 'time_iter': 0.03194, 'accuracy': 0.98055, 'precision': 0.51613, 'recall': 0.19753, 'f1': 0.28571, 'auc': 0.78023}
2025-08-16 10:36:23,782 - INFO - test: {'epoch': 24, 'time_epoch': 3.97203, 'loss': 0.12022563, 'lr': 0, 'params': 514193, 'time_iter': 0.03079, 'accuracy': 0.96985, 'precision': 0.55769, 'recall': 0.22308, 'f1': 0.31868, 'auc': 0.74557}
2025-08-16 10:36:23,785 - INFO - > Epoch 24: took 72.8s (avg 76.4s) | Best so far: epoch 15	train_loss: 0.1165 train_auc: 0.8236	val_loss: 0.0876 val_auc: 0.7849	test_loss: 0.1196 test_auc: 0.7610
2025-08-16 10:37:27,279 - INFO - train: {'epoch': 25, 'time_epoch': 63.3835, 'eta': 4996.53936, 'eta_hours': 1.38793, 'loss': 0.10459701, 'lr': 8.946e-05, 'params': 514193, 'time_iter': 0.0616, 'accuracy': 0.96951, 'precision': 0.69309, 'recall': 0.3336, 'f1': 0.45041, 'auc': 0.87418}
2025-08-16 10:37:31,320 - INFO - val: {'epoch': 25, 'time_epoch': 4.01938, 'loss': 0.08401571, 'lr': 0, 'params': 514193, 'time_iter': 0.03116, 'accuracy': 0.97909, 'precision': 0.44681, 'recall': 0.25926, 'f1': 0.32812, 'auc': 0.74897}
2025-08-16 10:37:35,268 - INFO - test: {'epoch': 25, 'time_epoch': 3.9324, 'loss': 0.13037886, 'lr': 0, 'params': 514193, 'time_iter': 0.03048, 'accuracy': 0.96766, 'precision': 0.47458, 'recall': 0.21538, 'f1': 0.2963, 'auc': 0.73536}
2025-08-16 10:37:35,271 - INFO - > Epoch 25: took 71.5s (avg 76.2s) | Best so far: epoch 15	train_loss: 0.1165 train_auc: 0.8236	val_loss: 0.0876 val_auc: 0.7849	test_loss: 0.1196 test_auc: 0.7610
2025-08-16 10:38:41,732 - INFO - train: {'epoch': 26, 'time_epoch': 66.3547, 'eta': 4925.86575, 'eta_hours': 1.3683, 'loss': 0.10383321, 'lr': 8.842e-05, 'params': 514193, 'time_iter': 0.06448, 'accuracy': 0.97018, 'precision': 0.70813, 'recall': 0.34659, 'f1': 0.4654, 'auc': 0.87516}
2025-08-16 10:38:45,795 - INFO - val: {'epoch': 26, 'time_epoch': 4.04234, 'loss': 0.08751271, 'lr': 0, 'params': 514193, 'time_iter': 0.03134, 'accuracy': 0.97666, 'precision': 0.38095, 'recall': 0.2963, 'f1': 0.33333, 'auc': 0.77319}
2025-08-16 10:38:49,696 - INFO - test: {'epoch': 26, 'time_epoch': 3.88469, 'loss': 0.13638076, 'lr': 0, 'params': 514193, 'time_iter': 0.03011, 'accuracy': 0.96377, 'precision': 0.41121, 'recall': 0.33846, 'f1': 0.37131, 'auc': 0.74361}
2025-08-16 10:38:49,699 - INFO - > Epoch 26: took 74.4s (avg 76.1s) | Best so far: epoch 15	train_loss: 0.1165 train_auc: 0.8236	val_loss: 0.0876 val_auc: 0.7849	test_loss: 0.1196 test_auc: 0.7610
2025-08-16 10:39:56,017 - INFO - train: {'epoch': 27, 'time_epoch': 66.21306, 'eta': 4855.13643, 'eta_hours': 1.34865, 'loss': 0.10249141, 'lr': 8.734e-05, 'params': 514193, 'time_iter': 0.06435, 'accuracy': 0.97049, 'precision': 0.71151, 'recall': 0.35633, 'f1': 0.47485, 'auc': 0.87812}
2025-08-16 10:40:00,173 - INFO - val: {'epoch': 27, 'time_epoch': 4.1345, 'loss': 0.09218233, 'lr': 0, 'params': 514193, 'time_iter': 0.03205, 'accuracy': 0.97593, 'precision': 0.36364, 'recall': 0.2963, 'f1': 0.32653, 'auc': 0.77261}
2025-08-16 10:40:04,157 - INFO - test: {'epoch': 27, 'time_epoch': 3.96756, 'loss': 0.13196636, 'lr': 0, 'params': 514193, 'time_iter': 0.03076, 'accuracy': 0.9628, 'precision': 0.38614, 'recall': 0.3, 'f1': 0.33766, 'auc': 0.74831}
2025-08-16 10:40:04,159 - INFO - > Epoch 27: took 74.5s (avg 76.1s) | Best so far: epoch 15	train_loss: 0.1165 train_auc: 0.8236	val_loss: 0.0876 val_auc: 0.7849	test_loss: 0.1196 test_auc: 0.7610
2025-08-16 10:41:08,115 - INFO - train: {'epoch': 28, 'time_epoch': 63.84822, 'eta': 4778.92881, 'eta_hours': 1.32748, 'loss': 0.10111448, 'lr': 8.622e-05, 'params': 514193, 'time_iter': 0.06205, 'accuracy': 0.97085, 'precision': 0.72712, 'recall': 0.35471, 'f1': 0.47681, 'auc': 0.88435}
2025-08-16 10:41:12,176 - INFO - val: {'epoch': 28, 'time_epoch': 4.03956, 'loss': 0.08978133, 'lr': 0, 'params': 514193, 'time_iter': 0.03131, 'accuracy': 0.97788, 'precision': 0.41071, 'recall': 0.28395, 'f1': 0.33577, 'auc': 0.77508}
2025-08-16 10:41:16,110 - INFO - test: {'epoch': 28, 'time_epoch': 3.91768, 'loss': 0.14045419, 'lr': 0, 'params': 514193, 'time_iter': 0.03037, 'accuracy': 0.96353, 'precision': 0.38095, 'recall': 0.24615, 'f1': 0.29907, 'auc': 0.71774}
2025-08-16 10:41:16,112 - INFO - > Epoch 28: took 72.0s (avg 75.9s) | Best so far: epoch 15	train_loss: 0.1165 train_auc: 0.8236	val_loss: 0.0876 val_auc: 0.7849	test_loss: 0.1196 test_auc: 0.7610
2025-08-16 10:42:22,038 - INFO - train: {'epoch': 29, 'time_epoch': 65.81749, 'eta': 4708.1401, 'eta_hours': 1.30782, 'loss': 0.10146934, 'lr': 8.506e-05, 'params': 514193, 'time_iter': 0.06396, 'accuracy': 0.97067, 'precision': 0.71849, 'recall': 0.35633, 'f1': 0.4764, 'auc': 0.88225}
2025-08-16 10:42:26,291 - INFO - val: {'epoch': 29, 'time_epoch': 4.23146, 'loss': 0.07951054, 'lr': 0, 'params': 514193, 'time_iter': 0.0328, 'accuracy': 0.97982, 'precision': 0.47917, 'recall': 0.28395, 'f1': 0.35659, 'auc': 0.79137}
2025-08-16 10:42:30,406 - INFO - test: {'epoch': 29, 'time_epoch': 4.09751, 'loss': 0.12826559, 'lr': 0, 'params': 514193, 'time_iter': 0.03176, 'accuracy': 0.96669, 'precision': 0.44444, 'recall': 0.21538, 'f1': 0.29016, 'auc': 0.75585}
2025-08-16 10:42:30,408 - INFO - > Epoch 29: took 74.3s (avg 75.9s) | Best so far: epoch 29	train_loss: 0.1015 train_auc: 0.8822	val_loss: 0.0795 val_auc: 0.7914	test_loss: 0.1283 test_auc: 0.7559
2025-08-16 10:43:35,016 - INFO - train: {'epoch': 30, 'time_epoch': 64.50257, 'eta': 4634.74536, 'eta_hours': 1.28743, 'loss': 0.09925575, 'lr': 8.386e-05, 'params': 514193, 'time_iter': 0.06268, 'accuracy': 0.97204, 'precision': 0.75325, 'recall': 0.37662, 'f1': 0.50216, 'auc': 0.89186}
2025-08-16 10:43:39,152 - INFO - val: {'epoch': 30, 'time_epoch': 4.11403, 'loss': 0.0867618, 'lr': 0, 'params': 514193, 'time_iter': 0.03189, 'accuracy': 0.97958, 'precision': 0.46512, 'recall': 0.24691, 'f1': 0.32258, 'auc': 0.75107}
2025-08-16 10:43:43,133 - INFO - test: {'epoch': 30, 'time_epoch': 3.96495, 'loss': 0.13366169, 'lr': 0, 'params': 514193, 'time_iter': 0.03074, 'accuracy': 0.96766, 'precision': 0.47619, 'recall': 0.23077, 'f1': 0.31088, 'auc': 0.73897}
2025-08-16 10:43:43,135 - INFO - > Epoch 30: took 72.7s (avg 75.8s) | Best so far: epoch 29	train_loss: 0.1015 train_auc: 0.8822	val_loss: 0.0795 val_auc: 0.7914	test_loss: 0.1283 test_auc: 0.7559
2025-08-16 10:44:47,604 - INFO - train: {'epoch': 31, 'time_epoch': 64.36174, 'eta': 4561.60711, 'eta_hours': 1.26711, 'loss': 0.09610696, 'lr': 8.263e-05, 'params': 514193, 'time_iter': 0.06255, 'accuracy': 0.9721, 'precision': 0.7508, 'recall': 0.38149, 'f1': 0.50592, 'auc': 0.89838}
2025-08-16 10:44:51,906 - INFO - val: {'epoch': 31, 'time_epoch': 4.2771, 'loss': 0.08980259, 'lr': 0, 'params': 514193, 'time_iter': 0.03316, 'accuracy': 0.97666, 'precision': 0.36842, 'recall': 0.25926, 'f1': 0.30435, 'auc': 0.77066}
2025-08-16 10:44:56,058 - INFO - test: {'epoch': 31, 'time_epoch': 4.13544, 'loss': 0.14302181, 'lr': 0, 'params': 514193, 'time_iter': 0.03206, 'accuracy': 0.96256, 'precision': 0.36957, 'recall': 0.26154, 'f1': 0.30631, 'auc': 0.73046}
2025-08-16 10:44:56,062 - INFO - > Epoch 31: took 72.9s (avg 75.7s) | Best so far: epoch 29	train_loss: 0.1015 train_auc: 0.8822	val_loss: 0.0795 val_auc: 0.7914	test_loss: 0.1283 test_auc: 0.7559
2025-08-16 10:46:01,296 - INFO - train: {'epoch': 32, 'time_epoch': 65.12448, 'eta': 4490.54937, 'eta_hours': 1.24737, 'loss': 0.0971663, 'lr': 8.136e-05, 'params': 514193, 'time_iter': 0.06329, 'accuracy': 0.97146, 'precision': 0.72643, 'recall': 0.38149, 'f1': 0.50027, 'auc': 0.9011}
2025-08-16 10:46:05,502 - INFO - val: {'epoch': 32, 'time_epoch': 4.18301, 'loss': 0.08646811, 'lr': 0, 'params': 514193, 'time_iter': 0.03243, 'accuracy': 0.97715, 'precision': 0.38983, 'recall': 0.28395, 'f1': 0.32857, 'auc': 0.76412}
2025-08-16 10:46:09,453 - INFO - test: {'epoch': 32, 'time_epoch': 3.93507, 'loss': 0.13252047, 'lr': 0, 'params': 514193, 'time_iter': 0.0305, 'accuracy': 0.96572, 'precision': 0.43373, 'recall': 0.27692, 'f1': 0.33803, 'auc': 0.75688}
2025-08-16 10:46:09,456 - INFO - > Epoch 32: took 73.4s (avg 75.6s) | Best so far: epoch 29	train_loss: 0.1015 train_auc: 0.8822	val_loss: 0.0795 val_auc: 0.7914	test_loss: 0.1283 test_auc: 0.7559
2025-08-16 10:47:14,251 - INFO - train: {'epoch': 33, 'time_epoch': 64.68784, 'eta': 4418.99303, 'eta_hours': 1.2275, 'loss': 0.09700781, 'lr': 8.005e-05, 'params': 514193, 'time_iter': 0.06286, 'accuracy': 0.97222, 'precision': 0.75158, 'recall': 0.38555, 'f1': 0.50966, 'auc': 0.89782}
2025-08-16 10:47:18,360 - INFO - val: {'epoch': 33, 'time_epoch': 4.08815, 'loss': 0.09179183, 'lr': 0, 'params': 514193, 'time_iter': 0.03169, 'accuracy': 0.97763, 'precision': 0.40678, 'recall': 0.2963, 'f1': 0.34286, 'auc': 0.7728}
2025-08-16 10:47:22,354 - INFO - test: {'epoch': 33, 'time_epoch': 3.9781, 'loss': 0.14835747, 'lr': 0, 'params': 514193, 'time_iter': 0.03084, 'accuracy': 0.96134, 'precision': 0.34409, 'recall': 0.24615, 'f1': 0.287, 'auc': 0.7232}
2025-08-16 10:47:22,356 - INFO - > Epoch 33: took 72.9s (avg 75.5s) | Best so far: epoch 29	train_loss: 0.1015 train_auc: 0.8822	val_loss: 0.0795 val_auc: 0.7914	test_loss: 0.1283 test_auc: 0.7559
2025-08-16 10:48:26,400 - INFO - train: {'epoch': 34, 'time_epoch': 63.93599, 'eta': 4346.43291, 'eta_hours': 1.20734, 'loss': 0.09555428, 'lr': 7.872e-05, 'params': 514193, 'time_iter': 0.06213, 'accuracy': 0.97234, 'precision': 0.75078, 'recall': 0.39123, 'f1': 0.51441, 'auc': 0.90422}
2025-08-16 10:48:30,492 - INFO - val: {'epoch': 34, 'time_epoch': 4.07115, 'loss': 0.08471099, 'lr': 0, 'params': 514193, 'time_iter': 0.03156, 'accuracy': 0.97982, 'precision': 0.47727, 'recall': 0.25926, 'f1': 0.336, 'auc': 0.7714}
2025-08-16 10:48:34,413 - INFO - test: {'epoch': 34, 'time_epoch': 3.90499, 'loss': 0.14119147, 'lr': 0, 'params': 514193, 'time_iter': 0.03027, 'accuracy': 0.96693, 'precision': 0.44444, 'recall': 0.18462, 'f1': 0.26087, 'auc': 0.72538}
2025-08-16 10:48:34,415 - INFO - > Epoch 34: took 72.1s (avg 75.4s) | Best so far: epoch 29	train_loss: 0.1015 train_auc: 0.8822	val_loss: 0.0795 val_auc: 0.7914	test_loss: 0.1283 test_auc: 0.7559
2025-08-16 10:49:38,498 - INFO - train: {'epoch': 35, 'time_epoch': 63.97702, 'eta': 4274.42484, 'eta_hours': 1.18734, 'loss': 0.09334951, 'lr': 7.735e-05, 'params': 514193, 'time_iter': 0.06217, 'accuracy': 0.97304, 'precision': 0.76911, 'recall': 0.40016, 'f1': 0.52643, 'auc': 0.90813}
2025-08-16 10:49:42,614 - INFO - val: {'epoch': 35, 'time_epoch': 4.09479, 'loss': 0.08294229, 'lr': 0, 'params': 514193, 'time_iter': 0.03174, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.25926, 'f1': 0.34146, 'auc': 0.78143}
2025-08-16 10:49:46,569 - INFO - test: {'epoch': 35, 'time_epoch': 3.93896, 'loss': 0.13388673, 'lr': 0, 'params': 514193, 'time_iter': 0.03053, 'accuracy': 0.96766, 'precision': 0.47273, 'recall': 0.2, 'f1': 0.28108, 'auc': 0.75816}
2025-08-16 10:49:46,571 - INFO - > Epoch 35: took 72.2s (avg 75.4s) | Best so far: epoch 29	train_loss: 0.1015 train_auc: 0.8822	val_loss: 0.0795 val_auc: 0.7914	test_loss: 0.1283 test_auc: 0.7559
2025-08-16 10:50:53,625 - INFO - train: {'epoch': 36, 'time_epoch': 66.94493, 'eta': 4207.90434, 'eta_hours': 1.16886, 'loss': 0.09275881, 'lr': 7.595e-05, 'params': 514193, 'time_iter': 0.06506, 'accuracy': 0.97328, 'precision': 0.77621, 'recall': 0.4026, 'f1': 0.5302, 'auc': 0.91176}
2025-08-16 10:50:57,921 - INFO - val: {'epoch': 36, 'time_epoch': 4.27259, 'loss': 0.09098717, 'lr': 0, 'params': 514193, 'time_iter': 0.03312, 'accuracy': 0.9769, 'precision': 0.39062, 'recall': 0.30864, 'f1': 0.34483, 'auc': 0.80381}
2025-08-16 10:51:01,895 - INFO - test: {'epoch': 36, 'time_epoch': 3.95673, 'loss': 0.1481983, 'lr': 0, 'params': 514193, 'time_iter': 0.03067, 'accuracy': 0.96402, 'precision': 0.4, 'recall': 0.27692, 'f1': 0.32727, 'auc': 0.75315}
2025-08-16 10:51:01,897 - INFO - > Epoch 36: took 75.3s (avg 75.4s) | Best so far: epoch 36	train_loss: 0.0928 train_auc: 0.9118	val_loss: 0.0910 val_auc: 0.8038	test_loss: 0.1482 test_auc: 0.7531
2025-08-16 10:52:07,527 - INFO - train: {'epoch': 37, 'time_epoch': 65.52219, 'eta': 4139.0402, 'eta_hours': 1.14973, 'loss': 0.09266499, 'lr': 7.452e-05, 'params': 514193, 'time_iter': 0.06368, 'accuracy': 0.97322, 'precision': 0.76959, 'recall': 0.40666, 'f1': 0.53213, 'auc': 0.91172}
2025-08-16 10:52:11,684 - INFO - val: {'epoch': 37, 'time_epoch': 4.1357, 'loss': 0.08281411, 'lr': 0, 'params': 514193, 'time_iter': 0.03206, 'accuracy': 0.97885, 'precision': 0.44, 'recall': 0.2716, 'f1': 0.33588, 'auc': 0.79748}
2025-08-16 10:52:15,704 - INFO - test: {'epoch': 37, 'time_epoch': 4.00448, 'loss': 0.14092981, 'lr': 0, 'params': 514193, 'time_iter': 0.03104, 'accuracy': 0.96377, 'precision': 0.37662, 'recall': 0.22308, 'f1': 0.28019, 'auc': 0.75493}
2025-08-16 10:52:15,707 - INFO - > Epoch 37: took 73.8s (avg 75.3s) | Best so far: epoch 36	train_loss: 0.0928 train_auc: 0.9118	val_loss: 0.0910 val_auc: 0.8038	test_loss: 0.1482 test_auc: 0.7531
2025-08-16 10:53:23,587 - INFO - train: {'epoch': 38, 'time_epoch': 67.76889, 'eta': 4073.86151, 'eta_hours': 1.13163, 'loss': 0.09193338, 'lr': 7.307e-05, 'params': 514193, 'time_iter': 0.06586, 'accuracy': 0.97295, 'precision': 0.75676, 'recall': 0.40909, 'f1': 0.53109, 'auc': 0.91776}
2025-08-16 10:53:27,921 - INFO - val: {'epoch': 38, 'time_epoch': 4.31131, 'loss': 0.09618677, 'lr': 0, 'params': 514193, 'time_iter': 0.03342, 'accuracy': 0.97228, 'precision': 0.31034, 'recall': 0.33333, 'f1': 0.32143, 'auc': 0.79369}
2025-08-16 10:53:32,093 - INFO - test: {'epoch': 38, 'time_epoch': 4.15578, 'loss': 0.14876935, 'lr': 0, 'params': 514193, 'time_iter': 0.03222, 'accuracy': 0.95964, 'precision': 0.30851, 'recall': 0.22308, 'f1': 0.25893, 'auc': 0.75025}
2025-08-16 10:53:32,096 - INFO - > Epoch 38: took 76.4s (avg 75.3s) | Best so far: epoch 36	train_loss: 0.0928 train_auc: 0.9118	val_loss: 0.0910 val_auc: 0.8038	test_loss: 0.1482 test_auc: 0.7531
2025-08-16 10:54:38,449 - INFO - train: {'epoch': 39, 'time_epoch': 66.24304, 'eta': 4006.26453, 'eta_hours': 1.11285, 'loss': 0.09087041, 'lr': 7.159e-05, 'params': 514193, 'time_iter': 0.06438, 'accuracy': 0.97274, 'precision': 0.74032, 'recall': 0.41883, 'f1': 0.53499, 'auc': 0.91634}
2025-08-16 10:54:42,814 - INFO - val: {'epoch': 39, 'time_epoch': 4.34104, 'loss': 0.0855258, 'lr': 0, 'params': 514193, 'time_iter': 0.03365, 'accuracy': 0.97812, 'precision': 0.42105, 'recall': 0.2963, 'f1': 0.34783, 'auc': 0.78383}
2025-08-16 10:54:46,935 - INFO - test: {'epoch': 39, 'time_epoch': 4.10223, 'loss': 0.14664209, 'lr': 0, 'params': 514193, 'time_iter': 0.0318, 'accuracy': 0.96596, 'precision': 0.41935, 'recall': 0.2, 'f1': 0.27083, 'auc': 0.72087}
2025-08-16 10:54:46,937 - INFO - > Epoch 39: took 74.8s (avg 75.3s) | Best so far: epoch 36	train_loss: 0.0928 train_auc: 0.9118	val_loss: 0.0910 val_auc: 0.8038	test_loss: 0.1482 test_auc: 0.7531
2025-08-16 10:55:53,975 - INFO - train: {'epoch': 40, 'time_epoch': 66.92014, 'eta': 3939.70796, 'eta_hours': 1.09436, 'loss': 0.09035913, 'lr': 7.008e-05, 'params': 514193, 'time_iter': 0.06503, 'accuracy': 0.97307, 'precision': 0.75744, 'recall': 0.41315, 'f1': 0.53466, 'auc': 0.925}
2025-08-16 10:55:58,266 - INFO - val: {'epoch': 40, 'time_epoch': 4.26919, 'loss': 0.09008556, 'lr': 0, 'params': 514193, 'time_iter': 0.03309, 'accuracy': 0.9752, 'precision': 0.34328, 'recall': 0.28395, 'f1': 0.31081, 'auc': 0.80125}
2025-08-16 10:56:02,409 - INFO - test: {'epoch': 40, 'time_epoch': 4.12571, 'loss': 0.14994332, 'lr': 0, 'params': 514193, 'time_iter': 0.03198, 'accuracy': 0.96086, 'precision': 0.31325, 'recall': 0.2, 'f1': 0.24413, 'auc': 0.74966}
2025-08-16 10:56:02,412 - INFO - > Epoch 40: took 75.5s (avg 75.3s) | Best so far: epoch 36	train_loss: 0.0928 train_auc: 0.9118	val_loss: 0.0910 val_auc: 0.8038	test_loss: 0.1482 test_auc: 0.7531
2025-08-16 10:57:10,153 - INFO - train: {'epoch': 41, 'time_epoch': 67.62858, 'eta': 3874.1124, 'eta_hours': 1.07614, 'loss': 0.08860638, 'lr': 6.856e-05, 'params': 514193, 'time_iter': 0.06572, 'accuracy': 0.97356, 'precision': 0.77096, 'recall': 0.41802, 'f1': 0.54211, 'auc': 0.9263}
2025-08-16 10:57:14,723 - INFO - val: {'epoch': 41, 'time_epoch': 4.54789, 'loss': 0.09235546, 'lr': 0, 'params': 514193, 'time_iter': 0.03525, 'accuracy': 0.9769, 'precision': 0.37931, 'recall': 0.2716, 'f1': 0.31655, 'auc': 0.7877}
2025-08-16 10:57:19,156 - INFO - test: {'epoch': 41, 'time_epoch': 4.39848, 'loss': 0.15633613, 'lr': 0, 'params': 514193, 'time_iter': 0.0341, 'accuracy': 0.96669, 'precision': 0.43636, 'recall': 0.18462, 'f1': 0.25946, 'auc': 0.73499}
2025-08-16 10:57:19,158 - INFO - > Epoch 41: took 76.7s (avg 75.4s) | Best so far: epoch 36	train_loss: 0.0928 train_auc: 0.9118	val_loss: 0.0910 val_auc: 0.8038	test_loss: 0.1482 test_auc: 0.7531
2025-08-16 10:58:26,979 - INFO - train: {'epoch': 42, 'time_epoch': 67.71223, 'eta': 3808.53316, 'eta_hours': 1.05793, 'loss': 0.08897677, 'lr': 6.701e-05, 'params': 514193, 'time_iter': 0.0658, 'accuracy': 0.97319, 'precision': 0.75585, 'recall': 0.41964, 'f1': 0.53967, 'auc': 0.92632}
2025-08-16 10:58:31,235 - INFO - val: {'epoch': 42, 'time_epoch': 4.23363, 'loss': 0.08584089, 'lr': 0, 'params': 514193, 'time_iter': 0.03282, 'accuracy': 0.97763, 'precision': 0.40351, 'recall': 0.28395, 'f1': 0.33333, 'auc': 0.80249}
2025-08-16 10:58:35,346 - INFO - test: {'epoch': 42, 'time_epoch': 4.09447, 'loss': 0.14155299, 'lr': 0, 'params': 514193, 'time_iter': 0.03174, 'accuracy': 0.96499, 'precision': 0.4125, 'recall': 0.25385, 'f1': 0.31429, 'auc': 0.76302}
2025-08-16 10:58:35,348 - INFO - > Epoch 42: took 76.2s (avg 75.4s) | Best so far: epoch 36	train_loss: 0.0928 train_auc: 0.9118	val_loss: 0.0910 val_auc: 0.8038	test_loss: 0.1482 test_auc: 0.7531
2025-08-16 10:59:42,272 - INFO - train: {'epoch': 43, 'time_epoch': 66.81399, 'eta': 3741.71375, 'eta_hours': 1.03936, 'loss': 0.08684164, 'lr': 6.545e-05, 'params': 514193, 'time_iter': 0.06493, 'accuracy': 0.97313, 'precision': 0.75364, 'recall': 0.41964, 'f1': 0.5391, 'auc': 0.93054}
2025-08-16 10:59:46,539 - INFO - val: {'epoch': 43, 'time_epoch': 4.24532, 'loss': 0.08452609, 'lr': 0, 'params': 514193, 'time_iter': 0.03291, 'accuracy': 0.97812, 'precision': 0.41818, 'recall': 0.28395, 'f1': 0.33824, 'auc': 0.806}
2025-08-16 10:59:50,632 - INFO - test: {'epoch': 43, 'time_epoch': 4.07685, 'loss': 0.14113864, 'lr': 0, 'params': 514193, 'time_iter': 0.0316, 'accuracy': 0.96572, 'precision': 0.43529, 'recall': 0.28462, 'f1': 0.34419, 'auc': 0.75838}
2025-08-16 10:59:50,634 - INFO - > Epoch 43: took 75.3s (avg 75.4s) | Best so far: epoch 43	train_loss: 0.0868 train_auc: 0.9305	val_loss: 0.0845 val_auc: 0.8060	test_loss: 0.1411 test_auc: 0.7584
2025-08-16 11:00:58,609 - INFO - train: {'epoch': 44, 'time_epoch': 67.86545, 'eta': 3676.17971, 'eta_hours': 1.02116, 'loss': 0.08638057, 'lr': 6.387e-05, 'params': 514193, 'time_iter': 0.06595, 'accuracy': 0.97432, 'precision': 0.77369, 'recall': 0.44399, 'f1': 0.56421, 'auc': 0.92966}
2025-08-16 11:01:02,909 - INFO - val: {'epoch': 44, 'time_epoch': 4.27844, 'loss': 0.08254236, 'lr': 0, 'params': 514193, 'time_iter': 0.03317, 'accuracy': 0.98104, 'precision': 0.53191, 'recall': 0.30864, 'f1': 0.39062, 'auc': 0.78216}
2025-08-16 11:01:07,163 - INFO - test: {'epoch': 44, 'time_epoch': 4.23805, 'loss': 0.13808463, 'lr': 0, 'params': 514193, 'time_iter': 0.03285, 'accuracy': 0.96791, 'precision': 0.48276, 'recall': 0.21538, 'f1': 0.29787, 'auc': 0.74658}
2025-08-16 11:01:07,165 - INFO - > Epoch 44: took 76.5s (avg 75.4s) | Best so far: epoch 43	train_loss: 0.0868 train_auc: 0.9305	val_loss: 0.0845 val_auc: 0.8060	test_loss: 0.1411 test_auc: 0.7584
2025-08-16 11:02:12,061 - INFO - train: {'epoch': 45, 'time_epoch': 64.78888, 'eta': 3606.93268, 'eta_hours': 1.00193, 'loss': 0.08601579, 'lr': 6.227e-05, 'params': 514193, 'time_iter': 0.06296, 'accuracy': 0.97462, 'precision': 0.78894, 'recall': 0.43994, 'f1': 0.56488, 'auc': 0.93075}
2025-08-16 11:02:16,139 - INFO - val: {'epoch': 45, 'time_epoch': 4.05694, 'loss': 0.08853556, 'lr': 0, 'params': 514193, 'time_iter': 0.03145, 'accuracy': 0.97909, 'precision': 0.45283, 'recall': 0.2963, 'f1': 0.35821, 'auc': 0.7849}
2025-08-16 11:02:20,069 - INFO - test: {'epoch': 45, 'time_epoch': 3.91451, 'loss': 0.15328512, 'lr': 0, 'params': 514193, 'time_iter': 0.03035, 'accuracy': 0.96523, 'precision': 0.41772, 'recall': 0.25385, 'f1': 0.31579, 'auc': 0.74671}
2025-08-16 11:02:20,072 - INFO - > Epoch 45: took 72.9s (avg 75.4s) | Best so far: epoch 43	train_loss: 0.0868 train_auc: 0.9305	val_loss: 0.0845 val_auc: 0.8060	test_loss: 0.1411 test_auc: 0.7584
2025-08-16 11:03:23,658 - INFO - train: {'epoch': 46, 'time_epoch': 63.48161, 'eta': 3536.40121, 'eta_hours': 0.98233, 'loss': 0.0846912, 'lr': 6.066e-05, 'params': 514193, 'time_iter': 0.06169, 'accuracy': 0.97486, 'precision': 0.78243, 'recall': 0.45536, 'f1': 0.57568, 'auc': 0.93577}
2025-08-16 11:03:27,740 - INFO - val: {'epoch': 46, 'time_epoch': 4.06177, 'loss': 0.09821181, 'lr': 0, 'params': 514193, 'time_iter': 0.03149, 'accuracy': 0.97812, 'precision': 0.42623, 'recall': 0.32099, 'f1': 0.3662, 'auc': 0.76832}
2025-08-16 11:03:31,677 - INFO - test: {'epoch': 46, 'time_epoch': 3.92049, 'loss': 0.16070455, 'lr': 0, 'params': 514193, 'time_iter': 0.03039, 'accuracy': 0.96377, 'precision': 0.38824, 'recall': 0.25385, 'f1': 0.30698, 'auc': 0.73089}
2025-08-16 11:03:31,679 - INFO - > Epoch 46: took 71.6s (avg 75.3s) | Best so far: epoch 43	train_loss: 0.0868 train_auc: 0.9305	val_loss: 0.0845 val_auc: 0.8060	test_loss: 0.1411 test_auc: 0.7584
2025-08-16 11:04:35,347 - INFO - train: {'epoch': 47, 'time_epoch': 63.56261, 'eta': 3466.25122, 'eta_hours': 0.96285, 'loss': 0.08360058, 'lr': 5.904e-05, 'params': 514193, 'time_iter': 0.06177, 'accuracy': 0.97505, 'precision': 0.78423, 'recall': 0.46023, 'f1': 0.58005, 'auc': 0.93695}
2025-08-16 11:04:39,456 - INFO - val: {'epoch': 47, 'time_epoch': 4.08756, 'loss': 0.09064543, 'lr': 0, 'params': 514193, 'time_iter': 0.03169, 'accuracy': 0.97788, 'precision': 0.40385, 'recall': 0.25926, 'f1': 0.31579, 'auc': 0.7832}
2025-08-16 11:04:43,429 - INFO - test: {'epoch': 47, 'time_epoch': 3.95685, 'loss': 0.1546513, 'lr': 0, 'params': 514193, 'time_iter': 0.03067, 'accuracy': 0.96548, 'precision': 0.38, 'recall': 0.14615, 'f1': 0.21111, 'auc': 0.7373}
2025-08-16 11:04:43,431 - INFO - > Epoch 47: took 71.8s (avg 75.2s) | Best so far: epoch 43	train_loss: 0.0868 train_auc: 0.9305	val_loss: 0.0845 val_auc: 0.8060	test_loss: 0.1411 test_auc: 0.7584
2025-08-16 11:05:52,410 - INFO - train: {'epoch': 48, 'time_epoch': 68.86672, 'eta': 3401.89071, 'eta_hours': 0.94497, 'loss': 0.08437208, 'lr': 5.741e-05, 'params': 514193, 'time_iter': 0.06693, 'accuracy': 0.97547, 'precision': 0.80314, 'recall': 0.45698, 'f1': 0.58251, 'auc': 0.93364}
2025-08-16 11:05:56,785 - INFO - val: {'epoch': 48, 'time_epoch': 4.35093, 'loss': 0.08822679, 'lr': 0, 'params': 514193, 'time_iter': 0.03373, 'accuracy': 0.97715, 'precision': 0.39683, 'recall': 0.30864, 'f1': 0.34722, 'auc': 0.81112}
2025-08-16 11:06:01,073 - INFO - test: {'epoch': 48, 'time_epoch': 4.2699, 'loss': 0.14936325, 'lr': 0, 'params': 514193, 'time_iter': 0.0331, 'accuracy': 0.96256, 'precision': 0.36957, 'recall': 0.26154, 'f1': 0.30631, 'auc': 0.75819}
2025-08-16 11:06:01,077 - INFO - > Epoch 48: took 77.6s (avg 75.3s) | Best so far: epoch 48	train_loss: 0.0844 train_auc: 0.9336	val_loss: 0.0882 val_auc: 0.8111	test_loss: 0.1494 test_auc: 0.7582
2025-08-16 11:07:07,451 - INFO - train: {'epoch': 49, 'time_epoch': 66.25868, 'eta': 3334.74192, 'eta_hours': 0.92632, 'loss': 0.0803938, 'lr': 5.577e-05, 'params': 514193, 'time_iter': 0.06439, 'accuracy': 0.97526, 'precision': 0.78788, 'recall': 0.46429, 'f1': 0.58427, 'auc': 0.94563}
2025-08-16 11:07:11,533 - INFO - val: {'epoch': 49, 'time_epoch': 4.06091, 'loss': 0.09893125, 'lr': 0, 'params': 514193, 'time_iter': 0.03148, 'accuracy': 0.97642, 'precision': 0.39189, 'recall': 0.35802, 'f1': 0.37419, 'auc': 0.78161}
2025-08-16 11:07:15,489 - INFO - test: {'epoch': 49, 'time_epoch': 3.92229, 'loss': 0.16513597, 'lr': 0, 'params': 514193, 'time_iter': 0.03041, 'accuracy': 0.96402, 'precision': 0.39773, 'recall': 0.26923, 'f1': 0.3211, 'auc': 0.72228}
2025-08-16 11:07:15,526 - INFO - > Epoch 49: took 74.4s (avg 75.2s) | Best so far: epoch 48	train_loss: 0.0844 train_auc: 0.9336	val_loss: 0.0882 val_auc: 0.8111	test_loss: 0.1494 test_auc: 0.7582
2025-08-16 11:08:22,841 - INFO - train: {'epoch': 50, 'time_epoch': 67.20349, 'eta': 3268.53579, 'eta_hours': 0.90793, 'loss': 0.08373659, 'lr': 5.413e-05, 'params': 514193, 'time_iter': 0.06531, 'accuracy': 0.97441, 'precision': 0.78017, 'recall': 0.44075, 'f1': 0.56328, 'auc': 0.94031}
2025-08-16 11:08:27,419 - INFO - val: {'epoch': 50, 'time_epoch': 4.55151, 'loss': 0.10207438, 'lr': 0, 'params': 514193, 'time_iter': 0.03528, 'accuracy': 0.97326, 'precision': 0.3253, 'recall': 0.33333, 'f1': 0.32927, 'auc': 0.80325}
2025-08-16 11:08:31,661 - INFO - test: {'epoch': 50, 'time_epoch': 4.22237, 'loss': 0.15626353, 'lr': 0, 'params': 514193, 'time_iter': 0.03273, 'accuracy': 0.96304, 'precision': 0.38776, 'recall': 0.29231, 'f1': 0.33333, 'auc': 0.75792}
2025-08-16 11:08:31,664 - INFO - > Epoch 50: took 76.1s (avg 75.3s) | Best so far: epoch 48	train_loss: 0.0844 train_auc: 0.9336	val_loss: 0.0882 val_auc: 0.8111	test_loss: 0.1494 test_auc: 0.7582
2025-08-16 11:09:39,495 - INFO - train: {'epoch': 51, 'time_epoch': 67.72092, 'eta': 3202.76892, 'eta_hours': 0.88966, 'loss': 0.08003647, 'lr': 5.248e-05, 'params': 514193, 'time_iter': 0.06581, 'accuracy': 0.97572, 'precision': 0.80028, 'recall': 0.46834, 'f1': 0.59089, 'auc': 0.94394}
2025-08-16 11:09:43,834 - INFO - val: {'epoch': 51, 'time_epoch': 4.31508, 'loss': 0.10524781, 'lr': 0, 'params': 514193, 'time_iter': 0.03345, 'accuracy': 0.97496, 'precision': 0.3625, 'recall': 0.35802, 'f1': 0.36025, 'auc': 0.79728}
2025-08-16 11:09:47,977 - INFO - test: {'epoch': 51, 'time_epoch': 4.12601, 'loss': 0.17587483, 'lr': 0, 'params': 514193, 'time_iter': 0.03198, 'accuracy': 0.9577, 'precision': 0.3254, 'recall': 0.31538, 'f1': 0.32031, 'auc': 0.73494}
2025-08-16 11:09:47,979 - INFO - > Epoch 51: took 76.3s (avg 75.3s) | Best so far: epoch 48	train_loss: 0.0844 train_auc: 0.9336	val_loss: 0.0882 val_auc: 0.8111	test_loss: 0.1494 test_auc: 0.7582
2025-08-16 11:10:55,758 - INFO - train: {'epoch': 52, 'time_epoch': 67.66561, 'eta': 3136.87927, 'eta_hours': 0.87136, 'loss': 0.07829309, 'lr': 5.083e-05, 'params': 514193, 'time_iter': 0.06576, 'accuracy': 0.9759, 'precision': 0.7892, 'recall': 0.4862, 'f1': 0.60171, 'auc': 0.94852}
2025-08-16 11:11:00,087 - INFO - val: {'epoch': 52, 'time_epoch': 4.30654, 'loss': 0.09661483, 'lr': 0, 'params': 514193, 'time_iter': 0.03338, 'accuracy': 0.97544, 'precision': 0.35714, 'recall': 0.30864, 'f1': 0.33113, 'auc': 0.80319}
2025-08-16 11:11:04,259 - INFO - test: {'epoch': 52, 'time_epoch': 4.15589, 'loss': 0.16974879, 'lr': 0, 'params': 514193, 'time_iter': 0.03222, 'accuracy': 0.96086, 'precision': 0.32967, 'recall': 0.23077, 'f1': 0.27149, 'auc': 0.7485}
2025-08-16 11:11:04,262 - INFO - > Epoch 52: took 76.3s (avg 75.3s) | Best so far: epoch 48	train_loss: 0.0844 train_auc: 0.9336	val_loss: 0.0882 val_auc: 0.8111	test_loss: 0.1494 test_auc: 0.7582
2025-08-16 11:12:12,144 - INFO - train: {'epoch': 53, 'time_epoch': 67.77403, 'eta': 3071.0162, 'eta_hours': 0.85306, 'loss': 0.07920443, 'lr': 4.917e-05, 'params': 514193, 'time_iter': 0.06586, 'accuracy': 0.9755, 'precision': 0.78784, 'recall': 0.47321, 'f1': 0.59128, 'auc': 0.94869}
2025-08-16 11:12:16,476 - INFO - val: {'epoch': 53, 'time_epoch': 4.30983, 'loss': 0.09064434, 'lr': 0, 'params': 514193, 'time_iter': 0.03341, 'accuracy': 0.97715, 'precision': 0.39683, 'recall': 0.30864, 'f1': 0.34722, 'auc': 0.80125}
2025-08-16 11:12:20,627 - INFO - test: {'epoch': 53, 'time_epoch': 4.13448, 'loss': 0.17675073, 'lr': 0, 'params': 514193, 'time_iter': 0.03205, 'accuracy': 0.96256, 'precision': 0.33784, 'recall': 0.19231, 'f1': 0.2451, 'auc': 0.70839}
2025-08-16 11:12:20,630 - INFO - > Epoch 53: took 76.4s (avg 75.3s) | Best so far: epoch 48	train_loss: 0.0844 train_auc: 0.9336	val_loss: 0.0882 val_auc: 0.8111	test_loss: 0.1494 test_auc: 0.7582
2025-08-16 11:13:28,291 - INFO - train: {'epoch': 54, 'time_epoch': 67.55238, 'eta': 3004.90229, 'eta_hours': 0.8347, 'loss': 0.08066586, 'lr': 4.752e-05, 'params': 514193, 'time_iter': 0.06565, 'accuracy': 0.97547, 'precision': 0.78755, 'recall': 0.4724, 'f1': 0.59056, 'auc': 0.94585}
2025-08-16 11:13:32,607 - INFO - val: {'epoch': 54, 'time_epoch': 4.29279, 'loss': 0.09083802, 'lr': 0, 'params': 514193, 'time_iter': 0.03328, 'accuracy': 0.97593, 'precision': 0.36364, 'recall': 0.2963, 'f1': 0.32653, 'auc': 0.79578}
2025-08-16 11:13:36,771 - INFO - test: {'epoch': 54, 'time_epoch': 4.14775, 'loss': 0.15248357, 'lr': 0, 'params': 514193, 'time_iter': 0.03215, 'accuracy': 0.96572, 'precision': 0.4321, 'recall': 0.26923, 'f1': 0.33175, 'auc': 0.75692}
2025-08-16 11:13:36,774 - INFO - > Epoch 54: took 76.1s (avg 75.3s) | Best so far: epoch 48	train_loss: 0.0844 train_auc: 0.9336	val_loss: 0.0882 val_auc: 0.8111	test_loss: 0.1494 test_auc: 0.7582
2025-08-16 11:14:44,229 - INFO - train: {'epoch': 55, 'time_epoch': 67.34633, 'eta': 2938.57511, 'eta_hours': 0.81627, 'loss': 0.07846271, 'lr': 4.587e-05, 'params': 514193, 'time_iter': 0.06545, 'accuracy': 0.97523, 'precision': 0.77987, 'recall': 0.47159, 'f1': 0.58776, 'auc': 0.94998}
2025-08-16 11:14:48,580 - INFO - val: {'epoch': 55, 'time_epoch': 4.32942, 'loss': 0.09881575, 'lr': 0, 'params': 514193, 'time_iter': 0.03356, 'accuracy': 0.97496, 'precision': 0.3625, 'recall': 0.35802, 'f1': 0.36025, 'auc': 0.80315}
2025-08-16 11:14:52,853 - INFO - test: {'epoch': 55, 'time_epoch': 4.25606, 'loss': 0.17332969, 'lr': 0, 'params': 514193, 'time_iter': 0.03299, 'accuracy': 0.95648, 'precision': 0.29412, 'recall': 0.26923, 'f1': 0.28112, 'auc': 0.76734}
2025-08-16 11:14:52,855 - INFO - > Epoch 55: took 76.1s (avg 75.3s) | Best so far: epoch 48	train_loss: 0.0844 train_auc: 0.9336	val_loss: 0.0882 val_auc: 0.8111	test_loss: 0.1494 test_auc: 0.7582
2025-08-16 11:16:00,392 - INFO - train: {'epoch': 56, 'time_epoch': 67.42811, 'eta': 2872.27387, 'eta_hours': 0.79785, 'loss': 0.07726239, 'lr': 4.423e-05, 'params': 514193, 'time_iter': 0.06553, 'accuracy': 0.97641, 'precision': 0.79082, 'recall': 0.50325, 'f1': 0.61508, 'auc': 0.95153}
2025-08-16 11:16:04,747 - INFO - val: {'epoch': 56, 'time_epoch': 4.33224, 'loss': 0.09606465, 'lr': 0, 'params': 514193, 'time_iter': 0.03358, 'accuracy': 0.97593, 'precision': 0.375, 'recall': 0.33333, 'f1': 0.35294, 'auc': 0.8047}
2025-08-16 11:16:08,904 - INFO - test: {'epoch': 56, 'time_epoch': 4.1414, 'loss': 0.16837208, 'lr': 0, 'params': 514193, 'time_iter': 0.0321, 'accuracy': 0.96159, 'precision': 0.34783, 'recall': 0.24615, 'f1': 0.28829, 'auc': 0.74257}
2025-08-16 11:16:08,907 - INFO - > Epoch 56: took 76.1s (avg 75.4s) | Best so far: epoch 48	train_loss: 0.0844 train_auc: 0.9336	val_loss: 0.0882 val_auc: 0.8111	test_loss: 0.1494 test_auc: 0.7582
2025-08-16 11:17:16,442 - INFO - train: {'epoch': 57, 'time_epoch': 67.42049, 'eta': 2805.92825, 'eta_hours': 0.77942, 'loss': 0.07539476, 'lr': 4.259e-05, 'params': 514193, 'time_iter': 0.06552, 'accuracy': 0.97641, 'precision': 0.79457, 'recall': 0.49919, 'f1': 0.61316, 'auc': 0.95483}
2025-08-16 11:17:20,841 - INFO - val: {'epoch': 57, 'time_epoch': 4.37346, 'loss': 0.10756298, 'lr': 0, 'params': 514193, 'time_iter': 0.0339, 'accuracy': 0.97301, 'precision': 0.32955, 'recall': 0.35802, 'f1': 0.3432, 'auc': 0.79999}
2025-08-16 11:17:25,059 - INFO - test: {'epoch': 57, 'time_epoch': 4.20093, 'loss': 0.17909827, 'lr': 0, 'params': 514193, 'time_iter': 0.03257, 'accuracy': 0.96159, 'precision': 0.34783, 'recall': 0.24615, 'f1': 0.28829, 'auc': 0.74311}
2025-08-16 11:17:25,063 - INFO - > Epoch 57: took 76.2s (avg 75.4s) | Best so far: epoch 48	train_loss: 0.0844 train_auc: 0.9336	val_loss: 0.0882 val_auc: 0.8111	test_loss: 0.1494 test_auc: 0.7582
2025-08-16 11:18:32,367 - INFO - train: {'epoch': 58, 'time_epoch': 67.19391, 'eta': 2739.38873, 'eta_hours': 0.76094, 'loss': 0.07470386, 'lr': 4.096e-05, 'params': 514193, 'time_iter': 0.0653, 'accuracy': 0.97657, 'precision': 0.79974, 'recall': 0.49919, 'f1': 0.61469, 'auc': 0.95577}
2025-08-16 11:18:36,697 - INFO - val: {'epoch': 58, 'time_epoch': 4.30809, 'loss': 0.09920738, 'lr': 0, 'params': 514193, 'time_iter': 0.0334, 'accuracy': 0.97715, 'precision': 0.39683, 'recall': 0.30864, 'f1': 0.34722, 'auc': 0.78692}
2025-08-16 11:18:40,871 - INFO - test: {'epoch': 58, 'time_epoch': 4.15813, 'loss': 0.16945167, 'lr': 0, 'params': 514193, 'time_iter': 0.03223, 'accuracy': 0.96645, 'precision': 0.44595, 'recall': 0.25385, 'f1': 0.32353, 'auc': 0.73077}
2025-08-16 11:18:40,873 - INFO - > Epoch 58: took 75.8s (avg 75.4s) | Best so far: epoch 48	train_loss: 0.0844 train_auc: 0.9336	val_loss: 0.0882 val_auc: 0.8111	test_loss: 0.1494 test_auc: 0.7582
2025-08-16 11:19:48,553 - INFO - train: {'epoch': 59, 'time_epoch': 67.57086, 'eta': 2673.07871, 'eta_hours': 0.74252, 'loss': 0.0758153, 'lr': 3.934e-05, 'params': 514193, 'time_iter': 0.06567, 'accuracy': 0.97675, 'precision': 0.80364, 'recall': 0.50162, 'f1': 0.61769, 'auc': 0.95474}
2025-08-16 11:19:52,925 - INFO - val: {'epoch': 59, 'time_epoch': 4.35109, 'loss': 0.09573614, 'lr': 0, 'params': 514193, 'time_iter': 0.03373, 'accuracy': 0.97715, 'precision': 0.39683, 'recall': 0.30864, 'f1': 0.34722, 'auc': 0.79567}
2025-08-16 11:19:57,095 - INFO - test: {'epoch': 59, 'time_epoch': 4.15374, 'loss': 0.16976287, 'lr': 0, 'params': 514193, 'time_iter': 0.0322, 'accuracy': 0.96329, 'precision': 0.35211, 'recall': 0.19231, 'f1': 0.24876, 'auc': 0.7412}
2025-08-16 11:19:57,098 - INFO - > Epoch 59: took 76.2s (avg 75.4s) | Best so far: epoch 48	train_loss: 0.0844 train_auc: 0.9336	val_loss: 0.0882 val_auc: 0.8111	test_loss: 0.1494 test_auc: 0.7582
2025-08-16 11:21:05,559 - INFO - train: {'epoch': 60, 'time_epoch': 68.34793, 'eta': 2607.22416, 'eta_hours': 0.72423, 'loss': 0.07480666, 'lr': 3.773e-05, 'params': 514193, 'time_iter': 0.06642, 'accuracy': 0.97702, 'precision': 0.8028, 'recall': 0.51218, 'f1': 0.62537, 'auc': 0.95704}
2025-08-16 11:21:09,873 - INFO - val: {'epoch': 60, 'time_epoch': 4.2927, 'loss': 0.09600251, 'lr': 0, 'params': 514193, 'time_iter': 0.03328, 'accuracy': 0.9786, 'precision': 0.44262, 'recall': 0.33333, 'f1': 0.38028, 'auc': 0.7733}
2025-08-16 11:21:14,068 - INFO - test: {'epoch': 60, 'time_epoch': 4.17218, 'loss': 0.17205931, 'lr': 0, 'params': 514193, 'time_iter': 0.03234, 'accuracy': 0.96572, 'precision': 0.4127, 'recall': 0.2, 'f1': 0.26943, 'auc': 0.72212}
2025-08-16 11:21:14,070 - INFO - > Epoch 60: took 77.0s (avg 75.4s) | Best so far: epoch 48	train_loss: 0.0844 train_auc: 0.9336	val_loss: 0.0882 val_auc: 0.8111	test_loss: 0.1494 test_auc: 0.7582
2025-08-16 11:22:21,901 - INFO - train: {'epoch': 61, 'time_epoch': 67.71639, 'eta': 2540.9021, 'eta_hours': 0.70581, 'loss': 0.07555751, 'lr': 3.613e-05, 'params': 514193, 'time_iter': 0.06581, 'accuracy': 0.97623, 'precision': 0.7892, 'recall': 0.49838, 'f1': 0.61095, 'auc': 0.95679}
2025-08-16 11:22:26,389 - INFO - val: {'epoch': 61, 'time_epoch': 4.46437, 'loss': 0.10274675, 'lr': 0, 'params': 514193, 'time_iter': 0.03461, 'accuracy': 0.97253, 'precision': 0.30952, 'recall': 0.32099, 'f1': 0.31515, 'auc': 0.81294}
2025-08-16 11:22:30,718 - INFO - test: {'epoch': 61, 'time_epoch': 4.30999, 'loss': 0.17132551, 'lr': 0, 'params': 514193, 'time_iter': 0.03341, 'accuracy': 0.96207, 'precision': 0.3587, 'recall': 0.25385, 'f1': 0.2973, 'auc': 0.75023}
2025-08-16 11:22:30,722 - INFO - > Epoch 61: took 76.7s (avg 75.4s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:23:38,353 - INFO - train: {'epoch': 62, 'time_epoch': 67.51034, 'eta': 2474.41477, 'eta_hours': 0.68734, 'loss': 0.0737749, 'lr': 3.455e-05, 'params': 514193, 'time_iter': 0.06561, 'accuracy': 0.97687, 'precision': 0.79697, 'recall': 0.51299, 'f1': 0.6242, 'auc': 0.95708}
2025-08-16 11:23:42,776 - INFO - val: {'epoch': 62, 'time_epoch': 4.39683, 'loss': 0.10237712, 'lr': 0, 'params': 514193, 'time_iter': 0.03408, 'accuracy': 0.97593, 'precision': 0.3875, 'recall': 0.38272, 'f1': 0.38509, 'auc': 0.79405}
2025-08-16 11:23:47,014 - INFO - test: {'epoch': 62, 'time_epoch': 4.20343, 'loss': 0.17632009, 'lr': 0, 'params': 514193, 'time_iter': 0.03258, 'accuracy': 0.96086, 'precision': 0.35514, 'recall': 0.29231, 'f1': 0.32068, 'auc': 0.74592}
2025-08-16 11:23:47,017 - INFO - > Epoch 62: took 76.3s (avg 75.4s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:24:55,463 - INFO - train: {'epoch': 63, 'time_epoch': 68.32985, 'eta': 2408.35644, 'eta_hours': 0.66899, 'loss': 0.07496982, 'lr': 3.299e-05, 'params': 514193, 'time_iter': 0.0664, 'accuracy': 0.97733, 'precision': 0.80375, 'recall': 0.52192, 'f1': 0.63287, 'auc': 0.954}
2025-08-16 11:24:59,795 - INFO - val: {'epoch': 63, 'time_epoch': 4.30335, 'loss': 0.10794551, 'lr': 0, 'params': 514193, 'time_iter': 0.03336, 'accuracy': 0.97496, 'precision': 0.35526, 'recall': 0.33333, 'f1': 0.34395, 'auc': 0.77771}
2025-08-16 11:25:03,930 - INFO - test: {'epoch': 63, 'time_epoch': 4.11804, 'loss': 0.17610549, 'lr': 0, 'params': 514193, 'time_iter': 0.03192, 'accuracy': 0.9645, 'precision': 0.40476, 'recall': 0.26154, 'f1': 0.31776, 'auc': 0.7459}
2025-08-16 11:25:03,932 - INFO - > Epoch 63: took 76.9s (avg 75.5s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:26:12,253 - INFO - train: {'epoch': 64, 'time_epoch': 68.20302, 'eta': 2342.15993, 'eta_hours': 0.6506, 'loss': 0.07271227, 'lr': 3.144e-05, 'params': 514193, 'time_iter': 0.06628, 'accuracy': 0.97733, 'precision': 0.80916, 'recall': 0.51623, 'f1': 0.63033, 'auc': 0.95983}
2025-08-16 11:26:16,729 - INFO - val: {'epoch': 64, 'time_epoch': 4.44869, 'loss': 0.10781187, 'lr': 0, 'params': 514193, 'time_iter': 0.03449, 'accuracy': 0.97131, 'precision': 0.28736, 'recall': 0.30864, 'f1': 0.29762, 'auc': 0.78537}
2025-08-16 11:26:20,784 - INFO - test: {'epoch': 64, 'time_epoch': 4.03494, 'loss': 0.17305088, 'lr': 0, 'params': 514193, 'time_iter': 0.03128, 'accuracy': 0.9628, 'precision': 0.37895, 'recall': 0.27692, 'f1': 0.32, 'auc': 0.75158}
2025-08-16 11:26:20,787 - INFO - > Epoch 64: took 76.9s (avg 75.5s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:27:26,096 - INFO - train: {'epoch': 65, 'time_epoch': 65.20012, 'eta': 2274.35567, 'eta_hours': 0.63177, 'loss': 0.07372197, 'lr': 2.992e-05, 'params': 514193, 'time_iter': 0.06336, 'accuracy': 0.97696, 'precision': 0.80076, 'recall': 0.51218, 'f1': 0.62475, 'auc': 0.96028}
2025-08-16 11:27:30,446 - INFO - val: {'epoch': 65, 'time_epoch': 4.32715, 'loss': 0.10560684, 'lr': 0, 'params': 514193, 'time_iter': 0.03354, 'accuracy': 0.9735, 'precision': 0.33721, 'recall': 0.35802, 'f1': 0.34731, 'auc': 0.78777}
2025-08-16 11:27:34,688 - INFO - test: {'epoch': 65, 'time_epoch': 4.22469, 'loss': 0.17691033, 'lr': 0, 'params': 514193, 'time_iter': 0.03275, 'accuracy': 0.96183, 'precision': 0.37143, 'recall': 0.3, 'f1': 0.33191, 'auc': 0.74183}
2025-08-16 11:27:34,691 - INFO - > Epoch 65: took 73.9s (avg 75.5s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:28:44,149 - INFO - train: {'epoch': 66, 'time_epoch': 69.34373, 'eta': 2208.67002, 'eta_hours': 0.61352, 'loss': 0.07295523, 'lr': 2.841e-05, 'params': 514193, 'time_iter': 0.06739, 'accuracy': 0.97696, 'precision': 0.79774, 'recall': 0.51542, 'f1': 0.62623, 'auc': 0.96074}
2025-08-16 11:28:48,543 - INFO - val: {'epoch': 66, 'time_epoch': 4.36437, 'loss': 0.10424346, 'lr': 0, 'params': 514193, 'time_iter': 0.03383, 'accuracy': 0.97277, 'precision': 0.31765, 'recall': 0.33333, 'f1': 0.3253, 'auc': 0.80039}
2025-08-16 11:28:52,813 - INFO - test: {'epoch': 66, 'time_epoch': 4.25237, 'loss': 0.17566839, 'lr': 0, 'params': 514193, 'time_iter': 0.03296, 'accuracy': 0.96159, 'precision': 0.36792, 'recall': 0.3, 'f1': 0.33051, 'auc': 0.74995}
2025-08-16 11:28:52,815 - INFO - > Epoch 66: took 78.1s (avg 75.5s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:30:01,860 - INFO - train: {'epoch': 67, 'time_epoch': 68.93228, 'eta': 2142.68316, 'eta_hours': 0.59519, 'loss': 0.06905617, 'lr': 2.693e-05, 'params': 514193, 'time_iter': 0.06699, 'accuracy': 0.9783, 'precision': 0.81897, 'recall': 0.53977, 'f1': 0.65068, 'auc': 0.96402}
2025-08-16 11:30:06,271 - INFO - val: {'epoch': 67, 'time_epoch': 4.38816, 'loss': 0.10714001, 'lr': 0, 'params': 514193, 'time_iter': 0.03402, 'accuracy': 0.9752, 'precision': 0.35211, 'recall': 0.30864, 'f1': 0.32895, 'auc': 0.78577}
2025-08-16 11:30:10,495 - INFO - test: {'epoch': 67, 'time_epoch': 4.2068, 'loss': 0.17889129, 'lr': 0, 'params': 514193, 'time_iter': 0.03261, 'accuracy': 0.96548, 'precision': 0.42105, 'recall': 0.24615, 'f1': 0.31068, 'auc': 0.74711}
2025-08-16 11:30:10,497 - INFO - > Epoch 67: took 77.7s (avg 75.5s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:31:18,958 - INFO - train: {'epoch': 68, 'time_epoch': 68.35056, 'eta': 2076.34958, 'eta_hours': 0.57676, 'loss': 0.07068785, 'lr': 2.548e-05, 'params': 514193, 'time_iter': 0.06642, 'accuracy': 0.97781, 'precision': 0.80685, 'recall': 0.53571, 'f1': 0.6439, 'auc': 0.96245}
2025-08-16 11:31:23,328 - INFO - val: {'epoch': 68, 'time_epoch': 4.34064, 'loss': 0.10451855, 'lr': 0, 'params': 514193, 'time_iter': 0.03365, 'accuracy': 0.97496, 'precision': 0.34286, 'recall': 0.2963, 'f1': 0.31788, 'auc': 0.79589}
2025-08-16 11:31:27,507 - INFO - test: {'epoch': 68, 'time_epoch': 4.1622, 'loss': 0.17904039, 'lr': 0, 'params': 514193, 'time_iter': 0.03227, 'accuracy': 0.9662, 'precision': 0.44304, 'recall': 0.26923, 'f1': 0.33493, 'auc': 0.74015}
2025-08-16 11:31:27,509 - INFO - > Epoch 68: took 77.0s (avg 75.6s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:32:36,183 - INFO - train: {'epoch': 69, 'time_epoch': 68.56308, 'eta': 2010.04944, 'eta_hours': 0.55835, 'loss': 0.06962354, 'lr': 2.405e-05, 'params': 514193, 'time_iter': 0.06663, 'accuracy': 0.97872, 'precision': 0.82759, 'recall': 0.54545, 'f1': 0.65753, 'auc': 0.9645}
2025-08-16 11:32:40,522 - INFO - val: {'epoch': 69, 'time_epoch': 4.31653, 'loss': 0.11161912, 'lr': 0, 'params': 514193, 'time_iter': 0.03346, 'accuracy': 0.97107, 'precision': 0.30208, 'recall': 0.35802, 'f1': 0.32768, 'auc': 0.79632}
2025-08-16 11:32:44,700 - INFO - test: {'epoch': 69, 'time_epoch': 4.16203, 'loss': 0.18813757, 'lr': 0, 'params': 514193, 'time_iter': 0.03226, 'accuracy': 0.95891, 'precision': 0.33043, 'recall': 0.29231, 'f1': 0.3102, 'auc': 0.74927}
2025-08-16 11:32:44,703 - INFO - > Epoch 69: took 77.2s (avg 75.6s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:33:53,076 - INFO - train: {'epoch': 70, 'time_epoch': 68.26399, 'eta': 1943.5634, 'eta_hours': 0.53988, 'loss': 0.06805034, 'lr': 2.265e-05, 'params': 514193, 'time_iter': 0.06634, 'accuracy': 0.97878, 'precision': 0.82561, 'recall': 0.54951, 'f1': 0.65984, 'auc': 0.9655}
2025-08-16 11:33:57,375 - INFO - val: {'epoch': 70, 'time_epoch': 4.27702, 'loss': 0.10532086, 'lr': 0, 'params': 514193, 'time_iter': 0.03316, 'accuracy': 0.97544, 'precision': 0.36111, 'recall': 0.32099, 'f1': 0.33987, 'auc': 0.80117}
2025-08-16 11:34:01,524 - INFO - test: {'epoch': 70, 'time_epoch': 4.1328, 'loss': 0.18618158, 'lr': 0, 'params': 514193, 'time_iter': 0.03204, 'accuracy': 0.96134, 'precision': 0.35644, 'recall': 0.27692, 'f1': 0.31169, 'auc': 0.7419}
2025-08-16 11:34:01,526 - INFO - > Epoch 70: took 76.8s (avg 75.6s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:35:09,492 - INFO - train: {'epoch': 71, 'time_epoch': 67.85529, 'eta': 1876.86903, 'eta_hours': 0.52135, 'loss': 0.06962984, 'lr': 2.128e-05, 'params': 514193, 'time_iter': 0.06594, 'accuracy': 0.97784, 'precision': 0.81165, 'recall': 0.53166, 'f1': 0.64247, 'auc': 0.96517}
2025-08-16 11:35:13,822 - INFO - val: {'epoch': 71, 'time_epoch': 4.30821, 'loss': 0.10700134, 'lr': 0, 'params': 514193, 'time_iter': 0.0334, 'accuracy': 0.97544, 'precision': 0.35714, 'recall': 0.30864, 'f1': 0.33113, 'auc': 0.78779}
2025-08-16 11:35:17,968 - INFO - test: {'epoch': 71, 'time_epoch': 4.12883, 'loss': 0.1831776, 'lr': 0, 'params': 514193, 'time_iter': 0.03201, 'accuracy': 0.9645, 'precision': 0.40698, 'recall': 0.26923, 'f1': 0.32407, 'auc': 0.7484}
2025-08-16 11:35:17,970 - INFO - > Epoch 71: took 76.4s (avg 75.6s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:36:26,164 - INFO - train: {'epoch': 72, 'time_epoch': 68.0809, 'eta': 1810.2263, 'eta_hours': 0.50284, 'loss': 0.06928236, 'lr': 1.995e-05, 'params': 514193, 'time_iter': 0.06616, 'accuracy': 0.9783, 'precision': 0.82375, 'recall': 0.5349, 'f1': 0.64862, 'auc': 0.96573}
2025-08-16 11:36:30,490 - INFO - val: {'epoch': 72, 'time_epoch': 4.30449, 'loss': 0.10512256, 'lr': 0, 'params': 514193, 'time_iter': 0.03337, 'accuracy': 0.97666, 'precision': 0.38462, 'recall': 0.30864, 'f1': 0.34247, 'auc': 0.78689}
2025-08-16 11:36:34,670 - INFO - test: {'epoch': 72, 'time_epoch': 4.16311, 'loss': 0.1840625, 'lr': 0, 'params': 514193, 'time_iter': 0.03227, 'accuracy': 0.9628, 'precision': 0.37079, 'recall': 0.25385, 'f1': 0.30137, 'auc': 0.74612}
2025-08-16 11:36:34,672 - INFO - > Epoch 72: took 76.7s (avg 75.6s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:37:42,568 - INFO - train: {'epoch': 73, 'time_epoch': 67.7877, 'eta': 1743.44168, 'eta_hours': 0.48429, 'loss': 0.06546659, 'lr': 1.864e-05, 'params': 514193, 'time_iter': 0.06588, 'accuracy': 0.97921, 'precision': 0.82697, 'recall': 0.5625, 'f1': 0.66957, 'auc': 0.97124}
2025-08-16 11:37:46,668 - INFO - val: {'epoch': 73, 'time_epoch': 4.07783, 'loss': 0.1111319, 'lr': 0, 'params': 514193, 'time_iter': 0.03161, 'accuracy': 0.97374, 'precision': 0.33333, 'recall': 0.33333, 'f1': 0.33333, 'auc': 0.78784}
2025-08-16 11:37:50,667 - INFO - test: {'epoch': 73, 'time_epoch': 3.98234, 'loss': 0.19512785, 'lr': 0, 'params': 514193, 'time_iter': 0.03087, 'accuracy': 0.96159, 'precision': 0.36792, 'recall': 0.3, 'f1': 0.33051, 'auc': 0.74154}
2025-08-16 11:37:50,669 - INFO - > Epoch 73: took 76.0s (avg 75.6s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:38:58,729 - INFO - train: {'epoch': 74, 'time_epoch': 67.93485, 'eta': 1676.67937, 'eta_hours': 0.46574, 'loss': 0.06727541, 'lr': 1.737e-05, 'params': 514193, 'time_iter': 0.06602, 'accuracy': 0.97857, 'precision': 0.81481, 'recall': 0.55357, 'f1': 0.65926, 'auc': 0.9685}
2025-08-16 11:39:03,049 - INFO - val: {'epoch': 74, 'time_epoch': 4.29504, 'loss': 0.10142583, 'lr': 0, 'params': 514193, 'time_iter': 0.03329, 'accuracy': 0.97447, 'precision': 0.34211, 'recall': 0.32099, 'f1': 0.33121, 'auc': 0.81152}
2025-08-16 11:39:07,177 - INFO - test: {'epoch': 74, 'time_epoch': 4.11006, 'loss': 0.18018651, 'lr': 0, 'params': 514193, 'time_iter': 0.03186, 'accuracy': 0.96304, 'precision': 0.37778, 'recall': 0.26154, 'f1': 0.30909, 'auc': 0.75298}
2025-08-16 11:39:07,179 - INFO - > Epoch 74: took 76.5s (avg 75.6s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:40:15,026 - INFO - train: {'epoch': 75, 'time_epoch': 67.72838, 'eta': 1609.82099, 'eta_hours': 0.44717, 'loss': 0.0672173, 'lr': 1.614e-05, 'params': 514193, 'time_iter': 0.06582, 'accuracy': 0.97857, 'precision': 0.81257, 'recall': 0.55601, 'f1': 0.66024, 'auc': 0.9673}
2025-08-16 11:40:19,330 - INFO - val: {'epoch': 75, 'time_epoch': 4.27993, 'loss': 0.10832248, 'lr': 0, 'params': 514193, 'time_iter': 0.03318, 'accuracy': 0.97374, 'precision': 0.33735, 'recall': 0.34568, 'f1': 0.34146, 'auc': 0.79945}
2025-08-16 11:40:23,552 - INFO - test: {'epoch': 75, 'time_epoch': 4.20384, 'loss': 0.18772877, 'lr': 0, 'params': 514193, 'time_iter': 0.03259, 'accuracy': 0.96159, 'precision': 0.37273, 'recall': 0.31538, 'f1': 0.34167, 'auc': 0.75172}
2025-08-16 11:40:23,554 - INFO - > Epoch 75: took 76.4s (avg 75.7s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:41:31,088 - INFO - train: {'epoch': 76, 'time_epoch': 67.42067, 'eta': 1542.84811, 'eta_hours': 0.42857, 'loss': 0.0656994, 'lr': 1.494e-05, 'params': 514193, 'time_iter': 0.06552, 'accuracy': 0.97906, 'precision': 0.82206, 'recall': 0.5625, 'f1': 0.66795, 'auc': 0.97069}
2025-08-16 11:41:35,344 - INFO - val: {'epoch': 76, 'time_epoch': 4.23463, 'loss': 0.11399864, 'lr': 0, 'params': 514193, 'time_iter': 0.03283, 'accuracy': 0.97082, 'precision': 0.29897, 'recall': 0.35802, 'f1': 0.32584, 'auc': 0.79729}
2025-08-16 11:41:39,474 - INFO - test: {'epoch': 76, 'time_epoch': 4.1142, 'loss': 0.19681264, 'lr': 0, 'params': 514193, 'time_iter': 0.03189, 'accuracy': 0.95794, 'precision': 0.31933, 'recall': 0.29231, 'f1': 0.30522, 'auc': 0.74282}
2025-08-16 11:41:39,477 - INFO - > Epoch 76: took 75.9s (avg 75.7s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:42:46,896 - INFO - train: {'epoch': 77, 'time_epoch': 67.30882, 'eta': 1475.83219, 'eta_hours': 0.40995, 'loss': 0.06784714, 'lr': 1.378e-05, 'params': 514193, 'time_iter': 0.06541, 'accuracy': 0.97812, 'precision': 0.80843, 'recall': 0.54464, 'f1': 0.65082, 'auc': 0.96719}
2025-08-16 11:42:51,153 - INFO - val: {'epoch': 77, 'time_epoch': 4.23556, 'loss': 0.10622489, 'lr': 0, 'params': 514193, 'time_iter': 0.03283, 'accuracy': 0.97398, 'precision': 0.33333, 'recall': 0.32099, 'f1': 0.32704, 'auc': 0.80253}
2025-08-16 11:42:55,328 - INFO - test: {'epoch': 77, 'time_epoch': 4.15792, 'loss': 0.18724039, 'lr': 0, 'params': 514193, 'time_iter': 0.03223, 'accuracy': 0.96304, 'precision': 0.39, 'recall': 0.3, 'f1': 0.33913, 'auc': 0.7484}
2025-08-16 11:42:55,330 - INFO - > Epoch 77: took 75.9s (avg 75.7s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:44:02,966 - INFO - train: {'epoch': 78, 'time_epoch': 67.51961, 'eta': 1408.8649, 'eta_hours': 0.39135, 'loss': 0.06698768, 'lr': 1.266e-05, 'params': 514193, 'time_iter': 0.06562, 'accuracy': 0.979, 'precision': 0.82868, 'recall': 0.55357, 'f1': 0.66375, 'auc': 0.96793}
2025-08-16 11:44:07,426 - INFO - val: {'epoch': 78, 'time_epoch': 4.43338, 'loss': 0.11758237, 'lr': 0, 'params': 514193, 'time_iter': 0.03437, 'accuracy': 0.97253, 'precision': 0.32222, 'recall': 0.35802, 'f1': 0.33918, 'auc': 0.78984}
2025-08-16 11:44:11,736 - INFO - test: {'epoch': 78, 'time_epoch': 4.29226, 'loss': 0.20345732, 'lr': 0, 'params': 514193, 'time_iter': 0.03327, 'accuracy': 0.95745, 'precision': 0.32283, 'recall': 0.31538, 'f1': 0.31907, 'auc': 0.74717}
2025-08-16 11:44:11,738 - INFO - > Epoch 78: took 76.4s (avg 75.7s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:45:19,783 - INFO - train: {'epoch': 79, 'time_epoch': 67.93171, 'eta': 1341.98682, 'eta_hours': 0.37277, 'loss': 0.06448149, 'lr': 1.158e-05, 'params': 514193, 'time_iter': 0.06602, 'accuracy': 0.97979, 'precision': 0.82699, 'recall': 0.58198, 'f1': 0.68318, 'auc': 0.9707}
2025-08-16 11:45:24,107 - INFO - val: {'epoch': 79, 'time_epoch': 4.30135, 'loss': 0.11646329, 'lr': 0, 'params': 514193, 'time_iter': 0.03334, 'accuracy': 0.97301, 'precision': 0.31707, 'recall': 0.32099, 'f1': 0.31902, 'auc': 0.78445}
2025-08-16 11:45:28,265 - INFO - test: {'epoch': 79, 'time_epoch': 4.14092, 'loss': 0.2007328, 'lr': 0, 'params': 514193, 'time_iter': 0.0321, 'accuracy': 0.95915, 'precision': 0.32727, 'recall': 0.27692, 'f1': 0.3, 'auc': 0.73163}
2025-08-16 11:45:28,269 - INFO - > Epoch 79: took 76.5s (avg 75.7s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:46:36,419 - INFO - train: {'epoch': 80, 'time_epoch': 68.03541, 'eta': 1275.10705, 'eta_hours': 0.3542, 'loss': 0.06386132, 'lr': 1.054e-05, 'params': 514193, 'time_iter': 0.06612, 'accuracy': 0.97924, 'precision': 0.83516, 'recall': 0.55519, 'f1': 0.66699, 'auc': 0.97203}
2025-08-16 11:46:41,038 - INFO - val: {'epoch': 80, 'time_epoch': 4.58697, 'loss': 0.11613081, 'lr': 0, 'params': 514193, 'time_iter': 0.03556, 'accuracy': 0.97228, 'precision': 0.31461, 'recall': 0.34568, 'f1': 0.32941, 'auc': 0.79277}
2025-08-16 11:46:45,634 - INFO - test: {'epoch': 80, 'time_epoch': 4.56543, 'loss': 0.20150919, 'lr': 0, 'params': 514193, 'time_iter': 0.03539, 'accuracy': 0.95672, 'precision': 0.28947, 'recall': 0.25385, 'f1': 0.27049, 'auc': 0.73234}
2025-08-16 11:46:45,638 - INFO - > Epoch 80: took 77.4s (avg 75.7s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:47:49,934 - INFO - train: {'epoch': 81, 'time_epoch': 64.19202, 'eta': 1207.35542, 'eta_hours': 0.33538, 'loss': 0.06523912, 'lr': 9.55e-06, 'params': 514193, 'time_iter': 0.06238, 'accuracy': 0.97951, 'precision': 0.81849, 'recall': 0.58198, 'f1': 0.68027, 'auc': 0.97085}
2025-08-16 11:47:54,070 - INFO - val: {'epoch': 81, 'time_epoch': 4.03673, 'loss': 0.11102697, 'lr': 0, 'params': 514193, 'time_iter': 0.03129, 'accuracy': 0.97277, 'precision': 0.31325, 'recall': 0.32099, 'f1': 0.31707, 'auc': 0.79601}
2025-08-16 11:47:57,927 - INFO - test: {'epoch': 81, 'time_epoch': 3.84188, 'loss': 0.19226686, 'lr': 0, 'params': 514193, 'time_iter': 0.02978, 'accuracy': 0.96037, 'precision': 0.34579, 'recall': 0.28462, 'f1': 0.31224, 'auc': 0.73429}
2025-08-16 11:47:58,015 - INFO - > Epoch 81: took 72.4s (avg 75.7s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:49:03,245 - INFO - train: {'epoch': 82, 'time_epoch': 65.11121, 'eta': 1139.87784, 'eta_hours': 0.31663, 'loss': 0.06258702, 'lr': 8.6e-06, 'params': 514193, 'time_iter': 0.06328, 'accuracy': 0.97958, 'precision': 0.82184, 'recall': 0.58036, 'f1': 0.6803, 'auc': 0.97322}
2025-08-16 11:49:07,469 - INFO - val: {'epoch': 82, 'time_epoch': 4.20186, 'loss': 0.11408847, 'lr': 0, 'params': 514193, 'time_iter': 0.03257, 'accuracy': 0.97155, 'precision': 0.3, 'recall': 0.33333, 'f1': 0.31579, 'auc': 0.80807}
2025-08-16 11:49:11,554 - INFO - test: {'epoch': 82, 'time_epoch': 4.0689, 'loss': 0.19851197, 'lr': 0, 'params': 514193, 'time_iter': 0.03154, 'accuracy': 0.9594, 'precision': 0.33028, 'recall': 0.27692, 'f1': 0.30126, 'auc': 0.74479}
2025-08-16 11:49:11,556 - INFO - > Epoch 82: took 73.5s (avg 75.6s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:50:17,601 - INFO - train: {'epoch': 83, 'time_epoch': 65.93643, 'eta': 1072.61378, 'eta_hours': 0.29795, 'loss': 0.06532593, 'lr': 7.7e-06, 'params': 514193, 'time_iter': 0.06408, 'accuracy': 0.97845, 'precision': 0.80231, 'recall': 0.56331, 'f1': 0.6619, 'auc': 0.9717}
2025-08-16 11:50:21,839 - INFO - val: {'epoch': 83, 'time_epoch': 4.21676, 'loss': 0.11246305, 'lr': 0, 'params': 514193, 'time_iter': 0.03269, 'accuracy': 0.97326, 'precision': 0.3253, 'recall': 0.33333, 'f1': 0.32927, 'auc': 0.79286}
2025-08-16 11:50:25,928 - INFO - test: {'epoch': 83, 'time_epoch': 4.07297, 'loss': 0.19564839, 'lr': 0, 'params': 514193, 'time_iter': 0.03157, 'accuracy': 0.96159, 'precision': 0.36, 'recall': 0.27692, 'f1': 0.31304, 'auc': 0.74574}
2025-08-16 11:50:25,938 - INFO - > Epoch 83: took 74.4s (avg 75.6s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:51:34,256 - INFO - train: {'epoch': 84, 'time_epoch': 68.1737, 'eta': 1005.77577, 'eta_hours': 0.27938, 'loss': 0.06512, 'lr': 6.84e-06, 'params': 514193, 'time_iter': 0.06625, 'accuracy': 0.97897, 'precision': 0.82847, 'recall': 0.55276, 'f1': 0.6631, 'auc': 0.97178}
2025-08-16 11:51:39,101 - INFO - val: {'epoch': 84, 'time_epoch': 4.81481, 'loss': 0.11865741, 'lr': 0, 'params': 514193, 'time_iter': 0.03732, 'accuracy': 0.9718, 'precision': 0.31959, 'recall': 0.38272, 'f1': 0.34831, 'auc': 0.79721}
2025-08-16 11:51:43,595 - INFO - test: {'epoch': 84, 'time_epoch': 4.4737, 'loss': 0.20279592, 'lr': 0, 'params': 514193, 'time_iter': 0.03468, 'accuracy': 0.95842, 'precision': 0.32479, 'recall': 0.29231, 'f1': 0.30769, 'auc': 0.74268}
2025-08-16 11:51:43,597 - INFO - > Epoch 84: took 77.7s (avg 75.6s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:52:55,768 - INFO - train: {'epoch': 85, 'time_epoch': 72.04919, 'eta': 939.5376, 'eta_hours': 0.26098, 'loss': 0.06449351, 'lr': 6.03e-06, 'params': 514193, 'time_iter': 0.07002, 'accuracy': 0.97967, 'precision': 0.83957, 'recall': 0.56494, 'f1': 0.6754, 'auc': 0.97034}
2025-08-16 11:53:00,248 - INFO - val: {'epoch': 85, 'time_epoch': 4.4497, 'loss': 0.11654515, 'lr': 0, 'params': 514193, 'time_iter': 0.03449, 'accuracy': 0.97471, 'precision': 0.34667, 'recall': 0.32099, 'f1': 0.33333, 'auc': 0.78909}
2025-08-16 11:53:04,687 - INFO - test: {'epoch': 85, 'time_epoch': 4.41941, 'loss': 0.2071199, 'lr': 0, 'params': 514193, 'time_iter': 0.03426, 'accuracy': 0.96329, 'precision': 0.3871, 'recall': 0.27692, 'f1': 0.32287, 'auc': 0.74171}
2025-08-16 11:53:04,690 - INFO - > Epoch 85: took 81.1s (avg 75.7s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:54:15,978 - INFO - train: {'epoch': 86, 'time_epoch': 71.16922, 'eta': 873.03435, 'eta_hours': 0.24251, 'loss': 0.06135342, 'lr': 5.26e-06, 'params': 514193, 'time_iter': 0.06916, 'accuracy': 0.98015, 'precision': 0.82638, 'recall': 0.59497, 'f1': 0.69184, 'auc': 0.97334}
2025-08-16 11:54:20,219 - INFO - val: {'epoch': 86, 'time_epoch': 4.21899, 'loss': 0.11227204, 'lr': 0, 'params': 514193, 'time_iter': 0.03271, 'accuracy': 0.97374, 'precision': 0.33333, 'recall': 0.33333, 'f1': 0.33333, 'auc': 0.80225}
2025-08-16 11:54:24,320 - INFO - test: {'epoch': 86, 'time_epoch': 4.08544, 'loss': 0.20094564, 'lr': 0, 'params': 514193, 'time_iter': 0.03167, 'accuracy': 0.96207, 'precision': 0.37255, 'recall': 0.29231, 'f1': 0.32759, 'auc': 0.7424}
2025-08-16 11:54:24,323 - INFO - > Epoch 86: took 79.6s (avg 75.8s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:55:35,432 - INFO - train: {'epoch': 87, 'time_epoch': 70.99603, 'eta': 806.40143, 'eta_hours': 0.224, 'loss': 0.06298921, 'lr': 4.55e-06, 'params': 514193, 'time_iter': 0.069, 'accuracy': 0.97958, 'precision': 0.82333, 'recall': 0.57873, 'f1': 0.67969, 'auc': 0.97332}
2025-08-16 11:55:39,713 - INFO - val: {'epoch': 87, 'time_epoch': 4.2577, 'loss': 0.11551777, 'lr': 0, 'params': 514193, 'time_iter': 0.03301, 'accuracy': 0.97107, 'precision': 0.30208, 'recall': 0.35802, 'f1': 0.32768, 'auc': 0.80303}
2025-08-16 11:55:43,863 - INFO - test: {'epoch': 87, 'time_epoch': 4.13338, 'loss': 0.20377234, 'lr': 0, 'params': 514193, 'time_iter': 0.03204, 'accuracy': 0.96013, 'precision': 0.35345, 'recall': 0.31538, 'f1': 0.33333, 'auc': 0.74405}
2025-08-16 11:55:43,865 - INFO - > Epoch 87: took 79.5s (avg 75.8s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:56:53,079 - INFO - train: {'epoch': 88, 'time_epoch': 69.09198, 'eta': 739.43514, 'eta_hours': 0.2054, 'loss': 0.06409872, 'lr': 3.89e-06, 'params': 514193, 'time_iter': 0.06714, 'accuracy': 0.98049, 'precision': 0.83908, 'recall': 0.59253, 'f1': 0.69458, 'auc': 0.97033}
2025-08-16 11:56:57,403 - INFO - val: {'epoch': 88, 'time_epoch': 4.30029, 'loss': 0.11760443, 'lr': 0, 'params': 514193, 'time_iter': 0.03334, 'accuracy': 0.9718, 'precision': 0.31183, 'recall': 0.35802, 'f1': 0.33333, 'auc': 0.79809}
2025-08-16 11:57:01,610 - INFO - test: {'epoch': 88, 'time_epoch': 4.18448, 'loss': 0.20423006, 'lr': 0, 'params': 514193, 'time_iter': 0.03244, 'accuracy': 0.95988, 'precision': 0.34234, 'recall': 0.29231, 'f1': 0.31535, 'auc': 0.74315}
2025-08-16 11:57:01,614 - INFO - > Epoch 88: took 77.7s (avg 75.8s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:58:12,624 - INFO - train: {'epoch': 89, 'time_epoch': 70.89325, 'eta': 672.62175, 'eta_hours': 0.18684, 'loss': 0.06275495, 'lr': 3.27e-06, 'params': 514193, 'time_iter': 0.0689, 'accuracy': 0.97939, 'precision': 0.81335, 'recall': 0.5836, 'f1': 0.67958, 'auc': 0.97491}
2025-08-16 11:58:16,905 - INFO - val: {'epoch': 89, 'time_epoch': 4.25488, 'loss': 0.11930072, 'lr': 0, 'params': 514193, 'time_iter': 0.03298, 'accuracy': 0.97107, 'precision': 0.30612, 'recall': 0.37037, 'f1': 0.3352, 'auc': 0.79851}
2025-08-16 11:58:21,269 - INFO - test: {'epoch': 89, 'time_epoch': 4.3361, 'loss': 0.20285543, 'lr': 0, 'params': 514193, 'time_iter': 0.03361, 'accuracy': 0.9594, 'precision': 0.33913, 'recall': 0.3, 'f1': 0.31837, 'auc': 0.74111}
2025-08-16 11:58:21,273 - INFO - > Epoch 89: took 79.7s (avg 75.9s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 11:59:34,782 - INFO - train: {'epoch': 90, 'time_epoch': 73.38893, 'eta': 605.96552, 'eta_hours': 0.16832, 'loss': 0.06331875, 'lr': 2.71e-06, 'params': 514193, 'time_iter': 0.07132, 'accuracy': 0.97921, 'precision': 0.82697, 'recall': 0.5625, 'f1': 0.66957, 'auc': 0.97316}
2025-08-16 11:59:39,294 - INFO - val: {'epoch': 90, 'time_epoch': 4.48441, 'loss': 0.11667535, 'lr': 0, 'params': 514193, 'time_iter': 0.03476, 'accuracy': 0.97204, 'precision': 0.31111, 'recall': 0.34568, 'f1': 0.32749, 'auc': 0.79939}
2025-08-16 11:59:43,803 - INFO - test: {'epoch': 90, 'time_epoch': 4.47282, 'loss': 0.2042026, 'lr': 0, 'params': 514193, 'time_iter': 0.03467, 'accuracy': 0.95964, 'precision': 0.33929, 'recall': 0.29231, 'f1': 0.31405, 'auc': 0.7445}
2025-08-16 11:59:43,806 - INFO - > Epoch 90: took 82.5s (avg 75.9s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 12:00:56,009 - INFO - train: {'epoch': 91, 'time_epoch': 72.08996, 'eta': 539.04997, 'eta_hours': 0.14974, 'loss': 0.06195386, 'lr': 2.2e-06, 'params': 514193, 'time_iter': 0.07006, 'accuracy': 0.97961, 'precision': 0.81411, 'recall': 0.5901, 'f1': 0.68424, 'auc': 0.97594}
2025-08-16 12:01:00,467 - INFO - val: {'epoch': 91, 'time_epoch': 4.43546, 'loss': 0.11956645, 'lr': 0, 'params': 514193, 'time_iter': 0.03438, 'accuracy': 0.97277, 'precision': 0.34021, 'recall': 0.40741, 'f1': 0.37079, 'auc': 0.79519}
2025-08-16 12:01:04,801 - INFO - test: {'epoch': 91, 'time_epoch': 4.31626, 'loss': 0.20723116, 'lr': 0, 'params': 514193, 'time_iter': 0.03346, 'accuracy': 0.95721, 'precision': 0.31148, 'recall': 0.29231, 'f1': 0.30159, 'auc': 0.74075}
2025-08-16 12:01:04,804 - INFO - > Epoch 91: took 81.0s (avg 76.0s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 12:02:15,068 - INFO - train: {'epoch': 92, 'time_epoch': 70.15112, 'eta': 471.87721, 'eta_hours': 0.13108, 'loss': 0.06416217, 'lr': 1.74e-06, 'params': 514193, 'time_iter': 0.06817, 'accuracy': 0.97924, 'precision': 0.81229, 'recall': 0.57955, 'f1': 0.67646, 'auc': 0.97233}
2025-08-16 12:02:19,553 - INFO - val: {'epoch': 92, 'time_epoch': 4.46264, 'loss': 0.11429916, 'lr': 0, 'params': 514193, 'time_iter': 0.03459, 'accuracy': 0.97253, 'precision': 0.32609, 'recall': 0.37037, 'f1': 0.34682, 'auc': 0.80088}
2025-08-16 12:02:23,947 - INFO - test: {'epoch': 92, 'time_epoch': 4.37658, 'loss': 0.20451088, 'lr': 0, 'params': 514193, 'time_iter': 0.03393, 'accuracy': 0.95818, 'precision': 0.325, 'recall': 0.3, 'f1': 0.312, 'auc': 0.74102}
2025-08-16 12:02:23,950 - INFO - > Epoch 92: took 79.1s (avg 76.0s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 12:03:35,297 - INFO - train: {'epoch': 93, 'time_epoch': 71.2353, 'eta': 404.71028, 'eta_hours': 0.11242, 'loss': 0.06312573, 'lr': 1.33e-06, 'params': 514193, 'time_iter': 0.06923, 'accuracy': 0.97973, 'precision': 0.81494, 'recall': 0.59334, 'f1': 0.68671, 'auc': 0.97194}
2025-08-16 12:03:39,683 - INFO - val: {'epoch': 93, 'time_epoch': 4.36315, 'loss': 0.11486906, 'lr': 0, 'params': 514193, 'time_iter': 0.03382, 'accuracy': 0.9718, 'precision': 0.31579, 'recall': 0.37037, 'f1': 0.34091, 'auc': 0.79994}
2025-08-16 12:03:43,950 - INFO - test: {'epoch': 93, 'time_epoch': 4.24953, 'loss': 0.2038801, 'lr': 0, 'params': 514193, 'time_iter': 0.03294, 'accuracy': 0.9594, 'precision': 0.33628, 'recall': 0.29231, 'f1': 0.31276, 'auc': 0.7343}
2025-08-16 12:03:43,953 - INFO - > Epoch 93: took 80.0s (avg 76.1s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 12:04:53,318 - INFO - train: {'epoch': 94, 'time_epoch': 69.25284, 'eta': 337.35336, 'eta_hours': 0.09371, 'loss': 0.06266167, 'lr': 9.8e-07, 'params': 514193, 'time_iter': 0.0673, 'accuracy': 0.98, 'precision': 0.83924, 'recall': 0.5763, 'f1': 0.68335, 'auc': 0.97293}
2025-08-16 12:04:57,624 - INFO - val: {'epoch': 94, 'time_epoch': 4.28324, 'loss': 0.11339701, 'lr': 0, 'params': 514193, 'time_iter': 0.0332, 'accuracy': 0.97228, 'precision': 0.32258, 'recall': 0.37037, 'f1': 0.34483, 'auc': 0.79897}
2025-08-16 12:05:01,872 - INFO - test: {'epoch': 94, 'time_epoch': 4.23127, 'loss': 0.20271022, 'lr': 0, 'params': 514193, 'time_iter': 0.0328, 'accuracy': 0.95818, 'precision': 0.31579, 'recall': 0.27692, 'f1': 0.29508, 'auc': 0.73398}
2025-08-16 12:05:02,305 - INFO - > Epoch 94: took 78.4s (avg 76.1s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 12:06:11,184 - INFO - train: {'epoch': 95, 'time_epoch': 68.76702, 'eta': 269.9367, 'eta_hours': 0.07498, 'loss': 0.06318703, 'lr': 6.8e-07, 'params': 514193, 'time_iter': 0.06683, 'accuracy': 0.97979, 'precision': 0.82624, 'recall': 0.58279, 'f1': 0.68348, 'auc': 0.9733}
2025-08-16 12:06:15,582 - INFO - val: {'epoch': 95, 'time_epoch': 4.3746, 'loss': 0.11911596, 'lr': 0, 'params': 514193, 'time_iter': 0.03391, 'accuracy': 0.97107, 'precision': 0.30612, 'recall': 0.37037, 'f1': 0.3352, 'auc': 0.79634}
2025-08-16 12:06:19,844 - INFO - test: {'epoch': 95, 'time_epoch': 4.24413, 'loss': 0.20862796, 'lr': 0, 'params': 514193, 'time_iter': 0.0329, 'accuracy': 0.95867, 'precision': 0.33607, 'recall': 0.31538, 'f1': 0.3254, 'auc': 0.74481}
2025-08-16 12:06:19,846 - INFO - > Epoch 95: took 77.5s (avg 76.1s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 12:07:29,703 - INFO - train: {'epoch': 96, 'time_epoch': 69.74254, 'eta': 202.52237, 'eta_hours': 0.05626, 'loss': 0.06067095, 'lr': 4.4e-07, 'params': 514193, 'time_iter': 0.06778, 'accuracy': 0.98027, 'precision': 0.82864, 'recall': 0.59659, 'f1': 0.69372, 'auc': 0.97623}
2025-08-16 12:07:34,149 - INFO - val: {'epoch': 96, 'time_epoch': 4.42007, 'loss': 0.11795276, 'lr': 0, 'params': 514193, 'time_iter': 0.03426, 'accuracy': 0.97131, 'precision': 0.31683, 'recall': 0.39506, 'f1': 0.35165, 'auc': 0.79753}
2025-08-16 12:07:38,516 - INFO - test: {'epoch': 96, 'time_epoch': 4.34674, 'loss': 0.2055512, 'lr': 0, 'params': 514193, 'time_iter': 0.0337, 'accuracy': 0.95794, 'precision': 0.31933, 'recall': 0.29231, 'f1': 0.30522, 'auc': 0.73786}
2025-08-16 12:07:38,519 - INFO - > Epoch 96: took 78.7s (avg 76.1s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 12:08:49,760 - INFO - train: {'epoch': 97, 'time_epoch': 71.12491, 'eta': 135.08874, 'eta_hours': 0.03752, 'loss': 0.06220089, 'lr': 2.5e-07, 'params': 514193, 'time_iter': 0.06912, 'accuracy': 0.97918, 'precision': 0.82063, 'recall': 0.56818, 'f1': 0.67146, 'auc': 0.97536}
2025-08-16 12:08:54,312 - INFO - val: {'epoch': 97, 'time_epoch': 4.52881, 'loss': 0.11534796, 'lr': 0, 'params': 514193, 'time_iter': 0.03511, 'accuracy': 0.97277, 'precision': 0.32967, 'recall': 0.37037, 'f1': 0.34884, 'auc': 0.80154}
2025-08-16 12:08:58,697 - INFO - test: {'epoch': 97, 'time_epoch': 4.36673, 'loss': 0.20819121, 'lr': 0, 'params': 514193, 'time_iter': 0.03385, 'accuracy': 0.95988, 'precision': 0.34783, 'recall': 0.30769, 'f1': 0.32653, 'auc': 0.74258}
2025-08-16 12:08:58,699 - INFO - > Epoch 97: took 80.2s (avg 76.2s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 12:10:09,610 - INFO - train: {'epoch': 98, 'time_epoch': 70.79696, 'eta': 67.57723, 'eta_hours': 0.01877, 'loss': 0.06345665, 'lr': 1.1e-07, 'params': 514193, 'time_iter': 0.0688, 'accuracy': 0.97936, 'precision': 0.82189, 'recall': 0.57305, 'f1': 0.67527, 'auc': 0.97356}
2025-08-16 12:10:14,160 - INFO - val: {'epoch': 98, 'time_epoch': 4.52511, 'loss': 0.11571961, 'lr': 0, 'params': 514193, 'time_iter': 0.03508, 'accuracy': 0.97253, 'precision': 0.30952, 'recall': 0.32099, 'f1': 0.31515, 'auc': 0.79506}
2025-08-16 12:10:18,585 - INFO - test: {'epoch': 98, 'time_epoch': 4.40792, 'loss': 0.20661496, 'lr': 0, 'params': 514193, 'time_iter': 0.03417, 'accuracy': 0.95915, 'precision': 0.32727, 'recall': 0.27692, 'f1': 0.3, 'auc': 0.74203}
2025-08-16 12:10:18,588 - INFO - > Epoch 98: took 79.9s (avg 76.2s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 12:11:29,388 - INFO - train: {'epoch': 99, 'time_epoch': 70.68569, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.06233354, 'lr': 3e-08, 'params': 514193, 'time_iter': 0.06869, 'accuracy': 0.98027, 'precision': 0.83012, 'recall': 0.59497, 'f1': 0.69314, 'auc': 0.97311}
2025-08-16 12:11:33,881 - INFO - val: {'epoch': 99, 'time_epoch': 4.4565, 'loss': 0.11664157, 'lr': 0, 'params': 514193, 'time_iter': 0.03455, 'accuracy': 0.97253, 'precision': 0.32222, 'recall': 0.35802, 'f1': 0.33918, 'auc': 0.7999}
2025-08-16 12:11:38,243 - INFO - test: {'epoch': 99, 'time_epoch': 4.3447, 'loss': 0.20562167, 'lr': 0, 'params': 514193, 'time_iter': 0.03368, 'accuracy': 0.95988, 'precision': 0.34234, 'recall': 0.29231, 'f1': 0.31535, 'auc': 0.7426}
2025-08-16 12:11:38,429 - INFO - > Epoch 99: took 79.7s (avg 76.2s) | Best so far: epoch 61	train_loss: 0.0756 train_auc: 0.9568	val_loss: 0.1027 val_auc: 0.8129	test_loss: 0.1713 test_auc: 0.7502
2025-08-16 12:11:38,429 - INFO - Avg time per epoch: 76.24s
2025-08-16 12:11:38,429 - INFO - Total train loop time: 2.12h
2025-08-16 12:11:38,496 - INFO - ============================================================
2025-08-16 12:11:38,496 - INFO - Starting PK-Explainer Analysis (Enhanced Version)
2025-08-16 12:11:38,496 - INFO - ============================================================
2025-08-16 12:11:38,496 - INFO - Dataset: ogbg-molhiv
2025-08-16 12:11:38,496 - INFO - Model type: VanillaModel
2025-08-16 12:11:38,496 - INFO - GNN types available: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 12:11:38,540 - INFO - Saved model state to results/molhiv/molhiv-Vanilla-49/model_for_ablation.pt
2025-08-16 12:11:38,540 - INFO - 
Performing ablation study...
2025-08-16 12:11:38,595 - INFO - Getting baseline performance...
2025-08-16 12:11:38,629 - WARNING - Could not extract GNN mapping from optimal weights, attempting to infer from layers...
2025-08-16 12:11:38,629 - INFO - Final GNN mapping: {}
2025-08-16 12:11:42,987 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34211, 'loss': 0.20562167, 'lr': 0, 'params': 514193, 'time_iter': 0.03366, 'accuracy': 0.95988, 'precision': 0.34234, 'recall': 0.29231, 'f1': 0.31535, 'auc': 0.7426}
2025-08-16 12:11:42,990 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 12:11:42,990 - INFO - Baseline auc: 0.7426
2025-08-16 12:11:47,368 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32866, 'loss': 0.20978969, 'lr': 0, 'params': 514193, 'time_iter': 0.03356, 'accuracy': 0.95867, 'precision': 0.32456, 'recall': 0.28462, 'f1': 0.30328, 'auc': 0.73122}
2025-08-16 12:11:47,370 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:11:47,370 - INFO - Layer 0 (Layer_0), Head 0: drop=0.0153
2025-08-16 12:11:51,799 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36606, 'loss': 0.21385151, 'lr': 0, 'params': 514193, 'time_iter': 0.03385, 'accuracy': 0.95842, 'precision': 0.32479, 'recall': 0.29231, 'f1': 0.30769, 'auc': 0.74232}
2025-08-16 12:11:51,801 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:11:51,801 - INFO - Layer 0 (Layer_0), Head 1: drop=0.0004
2025-08-16 12:11:56,203 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35295, 'loss': 0.20123254, 'lr': 0, 'params': 514193, 'time_iter': 0.03374, 'accuracy': 0.95891, 'precision': 0.3211, 'recall': 0.26923, 'f1': 0.29289, 'auc': 0.74226}
2025-08-16 12:11:56,205 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:11:56,205 - INFO - Layer 0 (Layer_0), Head 2: drop=0.0005
2025-08-16 12:12:00,592 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33746, 'loss': 0.2086313, 'lr': 0, 'params': 514193, 'time_iter': 0.03362, 'accuracy': 0.9594, 'precision': 0.33028, 'recall': 0.27692, 'f1': 0.30126, 'auc': 0.74277}
2025-08-16 12:12:00,595 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:12:00,595 - INFO - Layer 0 (Layer_0), Head 3: drop=-0.0002
2025-08-16 12:12:05,059 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.41425, 'loss': 0.19951763, 'lr': 0, 'params': 514193, 'time_iter': 0.03422, 'accuracy': 0.95624, 'precision': 0.30469, 'recall': 0.3, 'f1': 0.30233, 'auc': 0.75973}
2025-08-16 12:12:05,062 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:12:05,062 - INFO - Layer 1 (Layer_1), Head 0: drop=-0.0231
2025-08-16 12:12:09,443 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3306, 'loss': 0.20307264, 'lr': 0, 'params': 514193, 'time_iter': 0.03357, 'accuracy': 0.95915, 'precision': 0.33333, 'recall': 0.29231, 'f1': 0.31148, 'auc': 0.7261}
2025-08-16 12:12:09,445 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:12:09,446 - INFO - Layer 1 (Layer_1), Head 1: drop=0.0222
2025-08-16 12:12:13,857 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36286, 'loss': 0.20672729, 'lr': 0, 'params': 514193, 'time_iter': 0.03382, 'accuracy': 0.95964, 'precision': 0.35, 'recall': 0.32308, 'f1': 0.336, 'auc': 0.75104}
2025-08-16 12:12:13,860 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:12:13,860 - INFO - Layer 1 (Layer_1), Head 2: drop=-0.0114
2025-08-16 12:12:18,742 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35211, 'loss': 0.2072932, 'lr': 0, 'params': 514193, 'time_iter': 0.03374, 'accuracy': 0.9577, 'precision': 0.31356, 'recall': 0.28462, 'f1': 0.29839, 'auc': 0.74231}
2025-08-16 12:12:18,744 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:12:18,745 - INFO - Layer 1 (Layer_1), Head 3: drop=0.0004
2025-08-16 12:12:23,191 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.39771, 'loss': 0.20639432, 'lr': 0, 'params': 514193, 'time_iter': 0.03409, 'accuracy': 0.95721, 'precision': 0.30833, 'recall': 0.28462, 'f1': 0.296, 'auc': 0.73146}
2025-08-16 12:12:23,193 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:12:23,194 - INFO - Layer 2 (Layer_2), Head 0: drop=0.0150
2025-08-16 12:12:27,649 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40449, 'loss': 0.20278148, 'lr': 0, 'params': 514193, 'time_iter': 0.03414, 'accuracy': 0.96086, 'precision': 0.35514, 'recall': 0.29231, 'f1': 0.32068, 'auc': 0.74743}
2025-08-16 12:12:27,651 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:12:27,651 - INFO - Layer 2 (Layer_2), Head 1: drop=-0.0065
2025-08-16 12:12:32,034 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33306, 'loss': 0.20185919, 'lr': 0, 'params': 514193, 'time_iter': 0.03359, 'accuracy': 0.96134, 'precision': 0.36449, 'recall': 0.3, 'f1': 0.32911, 'auc': 0.7425}
2025-08-16 12:12:32,047 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 12:12:32,047 - INFO - Layer 2 (Layer_2), Head 2: drop=0.0001
2025-08-16 12:12:36,408 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.31233, 'loss': 0.20439027, 'lr': 0, 'params': 514193, 'time_iter': 0.03343, 'accuracy': 0.95721, 'precision': 0.30508, 'recall': 0.27692, 'f1': 0.29032, 'auc': 0.7374}
2025-08-16 12:12:36,410 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:12:36,410 - INFO - Layer 2 (Layer_2), Head 3: drop=0.0070
2025-08-16 12:12:40,794 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33232, 'loss': 0.20498568, 'lr': 0, 'params': 514193, 'time_iter': 0.03358, 'accuracy': 0.9611, 'precision': 0.35, 'recall': 0.26923, 'f1': 0.30435, 'auc': 0.73674}
2025-08-16 12:12:40,796 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:12:40,796 - INFO - Layer 3 (Layer_3), Head 0: drop=0.0079
2025-08-16 12:12:45,221 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.37636, 'loss': 0.19333745, 'lr': 0, 'params': 514193, 'time_iter': 0.03393, 'accuracy': 0.95697, 'precision': 0.33094, 'recall': 0.35385, 'f1': 0.34201, 'auc': 0.76113}
2025-08-16 12:12:45,223 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:12:45,223 - INFO - Layer 3 (Layer_3), Head 1: drop=-0.0250
2025-08-16 12:12:49,673 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.39971, 'loss': 0.21546238, 'lr': 0, 'params': 514193, 'time_iter': 0.03411, 'accuracy': 0.95599, 'precision': 0.30233, 'recall': 0.3, 'f1': 0.30116, 'auc': 0.7374}
2025-08-16 12:12:49,675 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 12:12:49,675 - INFO - Layer 3 (Layer_3), Head 2: drop=0.0070
2025-08-16 12:12:54,076 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34956, 'loss': 0.20362126, 'lr': 0, 'params': 514193, 'time_iter': 0.03372, 'accuracy': 0.95891, 'precision': 0.33333, 'recall': 0.3, 'f1': 0.31579, 'auc': 0.74207}
2025-08-16 12:12:54,078 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:12:54,078 - INFO - Layer 3 (Layer_3), Head 3: drop=0.0007
2025-08-16 12:12:58,479 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35049, 'loss': 0.20353979, 'lr': 0, 'params': 514193, 'time_iter': 0.03372, 'accuracy': 0.95915, 'precision': 0.33898, 'recall': 0.30769, 'f1': 0.32258, 'auc': 0.7441}
2025-08-16 12:12:58,481 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:12:58,481 - INFO - Layer 4 (Layer_4), Head 0: drop=-0.0020
2025-08-16 12:13:02,917 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.38618, 'loss': 0.20156257, 'lr': 0, 'params': 514193, 'time_iter': 0.034, 'accuracy': 0.95988, 'precision': 0.35043, 'recall': 0.31538, 'f1': 0.33198, 'auc': 0.74321}
2025-08-16 12:13:02,919 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:13:02,919 - INFO - Layer 4 (Layer_4), Head 1: drop=-0.0008
2025-08-16 12:13:07,288 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3202, 'loss': 0.23100486, 'lr': 0, 'params': 514193, 'time_iter': 0.03349, 'accuracy': 0.94189, 'precision': 0.20856, 'recall': 0.3, 'f1': 0.24606, 'auc': 0.72609}
2025-08-16 12:13:07,290 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:13:07,290 - INFO - Layer 4 (Layer_4), Head 2: drop=0.0222
2025-08-16 12:13:11,717 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3772, 'loss': 0.2057935, 'lr': 0, 'params': 514193, 'time_iter': 0.03393, 'accuracy': 0.95648, 'precision': 0.32117, 'recall': 0.33846, 'f1': 0.32959, 'auc': 0.74431}
2025-08-16 12:13:11,719 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:13:11,719 - INFO - Layer 4 (Layer_4), Head 3: drop=-0.0023
2025-08-16 12:13:16,105 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33621, 'loss': 0.20463047, 'lr': 0, 'params': 514193, 'time_iter': 0.03361, 'accuracy': 0.95624, 'precision': 0.30769, 'recall': 0.30769, 'f1': 0.30769, 'auc': 0.73382}
2025-08-16 12:13:16,107 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:13:16,107 - INFO - Layer 5 (Layer_5), Head 0: drop=0.0118
2025-08-16 12:13:20,459 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.303, 'loss': 0.19685893, 'lr': 0, 'params': 514193, 'time_iter': 0.03336, 'accuracy': 0.95818, 'precision': 0.325, 'recall': 0.3, 'f1': 0.312, 'auc': 0.7462}
2025-08-16 12:13:20,461 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:13:20,461 - INFO - Layer 5 (Layer_5), Head 1: drop=-0.0048
2025-08-16 12:13:24,875 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36231, 'loss': 0.20337306, 'lr': 0, 'params': 514193, 'time_iter': 0.03382, 'accuracy': 0.95964, 'precision': 0.33929, 'recall': 0.29231, 'f1': 0.31405, 'auc': 0.74079}
2025-08-16 12:13:24,877 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:13:24,878 - INFO - Layer 5 (Layer_5), Head 2: drop=0.0024
2025-08-16 12:13:29,357 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.42959, 'loss': 0.20642688, 'lr': 0, 'params': 514193, 'time_iter': 0.03434, 'accuracy': 0.95721, 'precision': 0.32576, 'recall': 0.33077, 'f1': 0.32824, 'auc': 0.74552}
2025-08-16 12:13:29,359 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:13:29,359 - INFO - Layer 5 (Layer_5), Head 3: drop=-0.0039
2025-08-16 12:13:33,833 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.42451, 'loss': 0.20387615, 'lr': 0, 'params': 514193, 'time_iter': 0.0343, 'accuracy': 0.95915, 'precision': 0.33333, 'recall': 0.29231, 'f1': 0.31148, 'auc': 0.73}
2025-08-16 12:13:33,835 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:13:33,835 - INFO - Layer 6 (Layer_6), Head 0: drop=0.0170
2025-08-16 12:13:38,301 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.41718, 'loss': 0.19668261, 'lr': 0, 'params': 514193, 'time_iter': 0.03424, 'accuracy': 0.95988, 'precision': 0.34234, 'recall': 0.29231, 'f1': 0.31535, 'auc': 0.7492}
2025-08-16 12:13:38,303 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:13:38,303 - INFO - Layer 6 (Layer_6), Head 1: drop=-0.0089
2025-08-16 12:13:42,833 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.48033, 'loss': 0.20483861, 'lr': 0, 'params': 514193, 'time_iter': 0.03473, 'accuracy': 0.95745, 'precision': 0.32824, 'recall': 0.33077, 'f1': 0.3295, 'auc': 0.74285}
2025-08-16 12:13:42,836 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 12:13:42,836 - INFO - Layer 6 (Layer_6), Head 2: drop=-0.0003
2025-08-16 12:13:47,372 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.4845, 'loss': 0.19225392, 'lr': 0, 'params': 514193, 'time_iter': 0.03476, 'accuracy': 0.9628, 'precision': 0.38144, 'recall': 0.28462, 'f1': 0.32599, 'auc': 0.74219}
2025-08-16 12:13:47,375 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 12:13:47,375 - INFO - Layer 6 (Layer_6), Head 3: drop=0.0006
2025-08-16 12:13:51,848 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.42118, 'loss': 0.20515456, 'lr': 0, 'params': 514193, 'time_iter': 0.03427, 'accuracy': 0.96134, 'precision': 0.36449, 'recall': 0.3, 'f1': 0.32911, 'auc': 0.74113}
2025-08-16 12:13:51,850 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:13:51,850 - INFO - Layer 7 (Layer_7), Head 0: drop=0.0020
2025-08-16 12:13:56,300 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.39933, 'loss': 0.20168312, 'lr': 0, 'params': 514193, 'time_iter': 0.0341, 'accuracy': 0.9611, 'precision': 0.35294, 'recall': 0.27692, 'f1': 0.31034, 'auc': 0.73824}
2025-08-16 12:13:56,302 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:13:56,302 - INFO - Layer 7 (Layer_7), Head 1: drop=0.0059
2025-08-16 12:14:00,814 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.46179, 'loss': 0.20391308, 'lr': 0, 'params': 514193, 'time_iter': 0.03459, 'accuracy': 0.95988, 'precision': 0.34783, 'recall': 0.30769, 'f1': 0.32653, 'auc': 0.74474}
2025-08-16 12:14:00,816 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:14:00,816 - INFO - Layer 7 (Layer_7), Head 2: drop=-0.0029
2025-08-16 12:14:05,266 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40036, 'loss': 0.1985666, 'lr': 0, 'params': 514193, 'time_iter': 0.03411, 'accuracy': 0.96086, 'precision': 0.35514, 'recall': 0.29231, 'f1': 0.32068, 'auc': 0.74364}
2025-08-16 12:14:05,268 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:14:05,268 - INFO - Layer 7 (Layer_7), Head 3: drop=-0.0014
2025-08-16 12:14:09,766 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44561, 'loss': 0.19000652, 'lr': 0, 'params': 514193, 'time_iter': 0.03446, 'accuracy': 0.96256, 'precision': 0.37755, 'recall': 0.28462, 'f1': 0.32456, 'auc': 0.74543}
2025-08-16 12:14:09,767 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:14:09,768 - INFO - Layer 8 (Layer_8), Head 0: drop=-0.0038
2025-08-16 12:14:14,184 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36646, 'loss': 0.1975071, 'lr': 0, 'params': 514193, 'time_iter': 0.03385, 'accuracy': 0.96037, 'precision': 0.35135, 'recall': 0.3, 'f1': 0.32365, 'auc': 0.74014}
2025-08-16 12:14:14,186 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:14:14,187 - INFO - Layer 8 (Layer_8), Head 1: drop=0.0033
2025-08-16 12:14:18,643 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40491, 'loss': 0.20152253, 'lr': 0, 'params': 514193, 'time_iter': 0.03415, 'accuracy': 0.95867, 'precision': 0.32759, 'recall': 0.29231, 'f1': 0.30894, 'auc': 0.74256}
2025-08-16 12:14:18,646 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:14:18,646 - INFO - Layer 8 (Layer_8), Head 2: drop=0.0001
2025-08-16 12:14:23,173 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.47669, 'loss': 0.19730058, 'lr': 0, 'params': 514193, 'time_iter': 0.0347, 'accuracy': 0.96207, 'precision': 0.36735, 'recall': 0.27692, 'f1': 0.31579, 'auc': 0.74654}
2025-08-16 12:14:23,175 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:14:23,175 - INFO - Layer 8 (Layer_8), Head 3: drop=-0.0053
2025-08-16 12:14:27,640 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.41389, 'loss': 0.19007236, 'lr': 0, 'params': 514193, 'time_iter': 0.03422, 'accuracy': 0.9628, 'precision': 0.37895, 'recall': 0.27692, 'f1': 0.32, 'auc': 0.74114}
2025-08-16 12:14:27,642 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:14:27,642 - INFO - Layer 9 (Layer_9), Head 0: drop=0.0020
2025-08-16 12:14:32,106 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.41356, 'loss': 0.20417796, 'lr': 0, 'params': 514193, 'time_iter': 0.03421, 'accuracy': 0.96013, 'precision': 0.34545, 'recall': 0.29231, 'f1': 0.31667, 'auc': 0.74219}
2025-08-16 12:14:32,108 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:14:32,108 - INFO - Layer 9 (Layer_9), Head 1: drop=0.0006
2025-08-16 12:14:36,586 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.42934, 'loss': 0.19746052, 'lr': 0, 'params': 514193, 'time_iter': 0.03434, 'accuracy': 0.96231, 'precision': 0.36559, 'recall': 0.26154, 'f1': 0.30493, 'auc': 0.74196}
2025-08-16 12:14:36,589 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:14:36,589 - INFO - Layer 9 (Layer_9), Head 2: drop=0.0009
2025-08-16 12:14:41,035 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.39461, 'loss': 0.20256067, 'lr': 0, 'params': 514193, 'time_iter': 0.03407, 'accuracy': 0.95988, 'precision': 0.34234, 'recall': 0.29231, 'f1': 0.31535, 'auc': 0.74311}
2025-08-16 12:14:41,037 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:14:41,037 - INFO - Layer 9 (Layer_9), Head 3: drop=-0.0007
2025-08-16 12:14:45,577 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.48896, 'loss': 0.20183182, 'lr': 0, 'params': 514193, 'time_iter': 0.0348, 'accuracy': 0.96037, 'precision': 0.34862, 'recall': 0.29231, 'f1': 0.31799, 'auc': 0.74832}
2025-08-16 12:14:45,579 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 12:14:45,580 - INFO - Layer 10 (Layer_10), Head 0: drop=-0.0077
2025-08-16 12:14:50,068 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43962, 'loss': 0.19763878, 'lr': 0, 'params': 514193, 'time_iter': 0.03442, 'accuracy': 0.96086, 'precision': 0.35514, 'recall': 0.29231, 'f1': 0.32068, 'auc': 0.74526}
2025-08-16 12:14:50,070 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:14:50,070 - INFO - Layer 10 (Layer_10), Head 1: drop=-0.0036
2025-08-16 12:14:54,586 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.46777, 'loss': 0.20364718, 'lr': 0, 'params': 514193, 'time_iter': 0.03463, 'accuracy': 0.96256, 'precision': 0.375, 'recall': 0.27692, 'f1': 0.31858, 'auc': 0.7405}
2025-08-16 12:14:54,588 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:14:54,589 - INFO - Layer 10 (Layer_10), Head 2: drop=0.0028
2025-08-16 12:14:59,070 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43036, 'loss': 0.20068748, 'lr': 0, 'params': 514193, 'time_iter': 0.03434, 'accuracy': 0.9611, 'precision': 0.35849, 'recall': 0.29231, 'f1': 0.32203, 'auc': 0.74107}
2025-08-16 12:14:59,072 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:14:59,072 - INFO - Layer 10 (Layer_10), Head 3: drop=0.0021
2025-08-16 12:15:03,589 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.46611, 'loss': 0.19915485, 'lr': 0, 'params': 514193, 'time_iter': 0.03462, 'accuracy': 0.96086, 'precision': 0.35238, 'recall': 0.28462, 'f1': 0.31489, 'auc': 0.74509}
2025-08-16 12:15:03,591 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:15:03,591 - INFO - Layer 11 (Layer_11), Head 0: drop=-0.0034
2025-08-16 12:15:08,158 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.51413, 'loss': 0.19949064, 'lr': 0, 'params': 514193, 'time_iter': 0.03499, 'accuracy': 0.95988, 'precision': 0.34234, 'recall': 0.29231, 'f1': 0.31535, 'auc': 0.7418}
2025-08-16 12:15:08,161 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 12:15:08,161 - INFO - Layer 11 (Layer_11), Head 1: drop=0.0011
2025-08-16 12:15:12,678 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.466, 'loss': 0.20537806, 'lr': 0, 'params': 514193, 'time_iter': 0.03462, 'accuracy': 0.95988, 'precision': 0.35043, 'recall': 0.31538, 'f1': 0.33198, 'auc': 0.74396}
2025-08-16 12:15:12,680 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:15:12,681 - INFO - Layer 11 (Layer_11), Head 2: drop=-0.0018
2025-08-16 12:15:17,167 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43704, 'loss': 0.19738916, 'lr': 0, 'params': 514193, 'time_iter': 0.0344, 'accuracy': 0.96256, 'precision': 0.37755, 'recall': 0.28462, 'f1': 0.32456, 'auc': 0.74071}
2025-08-16 12:15:17,169 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:15:17,169 - INFO - Layer 11 (Layer_11), Head 3: drop=0.0025
2025-08-16 12:15:21,667 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44786, 'loss': 0.20415719, 'lr': 0, 'params': 514193, 'time_iter': 0.03448, 'accuracy': 0.9594, 'precision': 0.33913, 'recall': 0.3, 'f1': 0.31837, 'auc': 0.74444}
2025-08-16 12:15:21,669 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:15:21,669 - INFO - Layer 12 (Layer_12), Head 0: drop=-0.0025
2025-08-16 12:15:26,118 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.39738, 'loss': 0.20247315, 'lr': 0, 'params': 514193, 'time_iter': 0.03409, 'accuracy': 0.9611, 'precision': 0.35849, 'recall': 0.29231, 'f1': 0.32203, 'auc': 0.74296}
2025-08-16 12:15:26,120 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:15:26,120 - INFO - Layer 12 (Layer_12), Head 1: drop=-0.0005
2025-08-16 12:15:30,581 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.41148, 'loss': 0.20014025, 'lr': 0, 'params': 514193, 'time_iter': 0.0342, 'accuracy': 0.96013, 'precision': 0.34545, 'recall': 0.29231, 'f1': 0.31667, 'auc': 0.74212}
2025-08-16 12:15:30,583 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:15:30,583 - INFO - Layer 12 (Layer_12), Head 2: drop=0.0006
2025-08-16 12:15:35,029 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.39515, 'loss': 0.20176567, 'lr': 0, 'params': 514193, 'time_iter': 0.03407, 'accuracy': 0.96086, 'precision': 0.35514, 'recall': 0.29231, 'f1': 0.32068, 'auc': 0.74367}
2025-08-16 12:15:35,031 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:15:35,032 - INFO - Layer 12 (Layer_12), Head 3: drop=-0.0014
2025-08-16 12:15:39,527 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44589, 'loss': 0.19529079, 'lr': 0, 'params': 514193, 'time_iter': 0.03446, 'accuracy': 0.96061, 'precision': 0.34906, 'recall': 0.28462, 'f1': 0.31356, 'auc': 0.74425}
2025-08-16 12:15:39,531 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 12:15:39,531 - INFO - Layer 13 (Layer_13), Head 0: drop=-0.0022
2025-08-16 12:15:44,022 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44016, 'loss': 0.1971494, 'lr': 0, 'params': 514193, 'time_iter': 0.03442, 'accuracy': 0.96159, 'precision': 0.36275, 'recall': 0.28462, 'f1': 0.31897, 'auc': 0.74239}
2025-08-16 12:15:44,024 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:15:44,025 - INFO - Layer 13 (Layer_13), Head 1: drop=0.0003
2025-08-16 12:15:48,514 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44083, 'loss': 0.20089222, 'lr': 0, 'params': 514193, 'time_iter': 0.03443, 'accuracy': 0.96183, 'precision': 0.36893, 'recall': 0.29231, 'f1': 0.32618, 'auc': 0.73806}
2025-08-16 12:15:48,516 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:15:48,517 - INFO - Layer 13 (Layer_13), Head 2: drop=0.0061
2025-08-16 12:15:53,005 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43909, 'loss': 0.19817461, 'lr': 0, 'params': 514193, 'time_iter': 0.03441, 'accuracy': 0.96207, 'precision': 0.37255, 'recall': 0.29231, 'f1': 0.32759, 'auc': 0.74105}
2025-08-16 12:15:53,007 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:15:53,007 - INFO - Layer 13 (Layer_13), Head 3: drop=0.0021
2025-08-16 12:15:57,456 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.39976, 'loss': 0.19519785, 'lr': 0, 'params': 514193, 'time_iter': 0.03411, 'accuracy': 0.9628, 'precision': 0.38144, 'recall': 0.28462, 'f1': 0.32599, 'auc': 0.73938}
2025-08-16 12:15:57,458 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:15:57,459 - INFO - Layer 14 (Layer_14), Head 0: drop=0.0043
2025-08-16 12:16:01,891 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.38321, 'loss': 0.19648038, 'lr': 0, 'params': 514193, 'time_iter': 0.03398, 'accuracy': 0.96207, 'precision': 0.37255, 'recall': 0.29231, 'f1': 0.32759, 'auc': 0.74471}
2025-08-16 12:16:01,893 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 12:16:01,894 - INFO - Layer 14 (Layer_14), Head 1: drop=-0.0028
2025-08-16 12:16:06,407 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.46423, 'loss': 0.2008993, 'lr': 0, 'params': 514193, 'time_iter': 0.03461, 'accuracy': 0.96159, 'precision': 0.36538, 'recall': 0.29231, 'f1': 0.32479, 'auc': 0.74152}
2025-08-16 12:16:06,409 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:16:06,409 - INFO - Layer 14 (Layer_14), Head 2: drop=0.0015
2025-08-16 12:16:10,850 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.39129, 'loss': 0.19366986, 'lr': 0, 'params': 514193, 'time_iter': 0.03404, 'accuracy': 0.96207, 'precision': 0.37, 'recall': 0.28462, 'f1': 0.32174, 'auc': 0.74573}
2025-08-16 12:16:10,852 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 12:16:10,852 - INFO - Layer 14 (Layer_14), Head 3: drop=-0.0042
2025-08-16 12:16:10,856 - INFO - 
FIDELITY METRICS:
2025-08-16 12:16:10,857 - INFO - Fidelity (top 30 heads): 0.0056
2025-08-16 12:16:10,857 - INFO - Fidelity- (bottom 30 heads): -0.0044
2025-08-16 12:16:10,857 - INFO - 
GNN distribution in important heads:
2025-08-16 12:16:10,857 - INFO -   Layer_0: 3 heads
2025-08-16 12:16:10,857 - INFO -   Layer_3: 3 heads
2025-08-16 12:16:10,857 - INFO -   Layer_9: 3 heads
2025-08-16 12:16:10,857 - INFO -   Layer_1: 2 heads
2025-08-16 12:16:10,857 - INFO -   Layer_6: 2 heads
2025-08-16 12:16:10,857 - INFO -   Layer_2: 2 heads
2025-08-16 12:16:10,857 - INFO -   Layer_5: 2 heads
2025-08-16 12:16:10,857 - INFO -   Layer_13: 2 heads
2025-08-16 12:16:10,857 - INFO -   Layer_7: 2 heads
2025-08-16 12:16:10,857 - INFO -   Layer_14: 2 heads
2025-08-16 12:16:10,857 - INFO -   Layer_10: 2 heads
2025-08-16 12:16:10,857 - INFO -   Layer_11: 2 heads
2025-08-16 12:16:10,857 - INFO -   Layer_4: 1 heads
2025-08-16 12:16:10,857 - INFO -   Layer_8: 1 heads
2025-08-16 12:16:10,857 - INFO -   Layer_12: 1 heads
2025-08-16 12:16:10,857 - INFO - 
Interpretability Analysis:
2025-08-16 12:16:10,857 - INFO -   Fidelity: 0.0056
2025-08-16 12:16:10,858 - INFO -   Fidelity-: -0.0044
2025-08-16 12:16:10,858 - INFO -   Total heads tested: 60
2025-08-16 12:16:11,177 - INFO - Excel results saved to results/molhiv/molhiv-Vanilla-49/pk_explainer_results.xlsx
2025-08-16 12:16:12,597 - INFO - Saved visualizations to results/molhiv/molhiv-Vanilla-49/pk_explainer_results
2025-08-16 12:16:12,636 - INFO - 
PK-Explainer results saved to:
2025-08-16 12:16:12,636 - INFO -   - Excel: results/molhiv/molhiv-Vanilla-49/pk_explainer_results.xlsx
2025-08-16 12:16:12,636 - INFO -   - JSON: results/molhiv/molhiv-Vanilla-49/pk_explainer_results.json
2025-08-16 12:16:12,636 - INFO -   - Visualizations: results/molhiv/molhiv-Vanilla-49/pk_explainer_results
2025-08-16 12:16:12,641 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-49
2025-08-16 12:16:12,641 - INFO - Total time: 8091.91s (2.25h)
2025-08-16 12:16:12,674 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-49/agg
2025-08-16 12:16:12,674 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-16 12:16:12,674 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-49
2025-08-16 12:16:12,674 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-49/test_results/
Completed seed 49. Results saved in results/molhiv/molhiv-Vanilla-49
----------------------------------------
All experiments completed!
