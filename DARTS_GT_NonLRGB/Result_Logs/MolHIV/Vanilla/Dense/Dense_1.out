Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          376Gi        13Gi       339Gi       984Mi        23Gi       359Gi
Swap:         1.9Gi          0B       1.9Gi
Thu Jun 19 23:19:15 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:1C:00.0 Off |                    0 |
| N/A   30C    P0             41W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 41
Starting training for seed 41...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/confignas.yaml
Using device: cuda
2025-06-19 23:20:02,938 - INFO - GPU Mem: 34.1GB
2025-06-19 23:20:02,938 - INFO - Run directory: results/molhiv/molhiv-Vanilla-41
2025-06-19 23:20:02,939 - INFO - Seed: 41
2025-06-19 23:20:02,939 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-06-19 23:20:02,939 - INFO - Routing mode: none
2025-06-19 23:20:02,939 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-06-19 23:20:02,939 - INFO - Number of layers: 15
2025-06-19 23:20:02,939 - INFO - Uncertainty enabled: False
2025-06-19 23:20:02,939 - INFO - Training mode: custom
2025-06-19 23:20:02,939 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-06-19 23:20:02,939 - INFO - Additional features: Router weights logging + JSON export
2025-06-19 23:20:11,364 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-19 23:20:11,367 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-06-19 23:20:11,403 - INFO -   undirected: True
2025-06-19 23:20:11,403 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-19 23:20:11,403 - INFO -   avg num_nodes/graph: 25
2025-06-19 23:20:11,404 - INFO -   num node features: 9
2025-06-19 23:20:11,404 - INFO -   num edge features: 3
2025-06-19 23:20:11,404 - INFO -   num tasks: 1
2025-06-19 23:20:11,404 - INFO -   num classes: 2
2025-06-19 23:20:11,404 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-06-19 23:20:11,404 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-06-19 23:20:11,407 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 16%|█▋        | 6780/41127 [00:10<00:50, 677.96it/s] 33%|███▎      | 13376/41127 [00:20<00:41, 667.11it/s] 50%|████▉     | 20378/41127 [00:30<00:30, 682.22it/s] 68%|██████▊   | 28005/41127 [00:40<00:18, 713.96it/s] 86%|████████▌ | 35315/41127 [00:50<00:08, 720.09it/s]100%|██████████| 41127/41127 [00:57<00:00, 709.24it/s]
2025-06-19 23:21:10,356 - INFO - Done! Took 00:00:58.95
2025-06-19 23:21:10,485 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-06-19 23:21:10,625 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-06-19 23:21:10,625 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-06-19 23:21:10,625 - INFO - Inner model has get_darts_model: False
2025-06-19 23:21:10,629 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-06-19 23:21:10,632 - INFO - Number of parameters: 514,193
2025-06-19 23:21:10,632 - INFO - Starting optimized training: 2025-06-19 23:21:10.632215
2025-06-19 23:21:16,270 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-19 23:21:16,270 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-06-19 23:21:16,271 - INFO -   undirected: True
2025-06-19 23:21:16,271 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-19 23:21:16,271 - INFO -   avg num_nodes/graph: 25
2025-06-19 23:21:16,272 - INFO -   num node features: 9
2025-06-19 23:21:16,272 - INFO -   num edge features: 3
2025-06-19 23:21:16,272 - INFO -   num tasks: 1
2025-06-19 23:21:16,272 - INFO -   num classes: 2
2025-06-19 23:21:16,272 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-06-19 23:21:16,272 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-06-19 23:21:16,275 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 19%|█▊        | 7622/41127 [00:10<00:43, 762.15it/s] 37%|███▋      | 15161/41127 [00:20<00:34, 757.25it/s] 54%|█████▍    | 22356/41127 [00:30<00:25, 740.00it/s] 71%|███████▏  | 29365/41127 [00:40<00:16, 724.54it/s] 89%|████████▉ | 36715/41127 [00:50<00:06, 728.31it/s]100%|██████████| 41127/41127 [00:56<00:00, 730.52it/s]
2025-06-19 23:22:13,581 - INFO - Done! Took 00:00:57.31
2025-06-19 23:22:13,738 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-06-19 23:22:13,867 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-06-19 23:22:13,867 - INFO - Start from epoch 0
2025-06-19 23:23:24,865 - INFO - train: {'epoch': 0, 'time_epoch': 70.47086, 'eta': 6976.61535, 'eta_hours': 1.93795, 'loss': 0.62980532, 'lr': 0.0, 'params': 514193, 'time_iter': 0.06848, 'accuracy': 0.95815, 'precision': 0.01342, 'recall': 0.00162, 'f1': 0.0029, 'auc': 0.5039}
2025-06-19 23:23:24,874 - INFO - ...computing epoch stats took: 0.51s
2025-06-19 23:23:28,755 - INFO - val: {'epoch': 0, 'time_epoch': 3.86288, 'loss': 0.62661056, 'lr': 0, 'params': 514193, 'time_iter': 0.02994, 'accuracy': 0.96937, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.49659}
2025-06-19 23:23:28,758 - INFO - ...computing epoch stats took: 0.02s
2025-06-19 23:23:32,446 - INFO - test: {'epoch': 0, 'time_epoch': 3.67161, 'loss': 0.6255391, 'lr': 0, 'params': 514193, 'time_iter': 0.02846, 'accuracy': 0.95478, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.56562}
2025-06-19 23:23:32,457 - INFO - ...computing epoch stats took: 0.02s
2025-06-19 23:23:32,457 - INFO - > Epoch 0: took 78.6s (avg 78.6s) | Best so far: epoch 0	train_loss: 0.6298 train_auc: 0.5039	val_loss: 0.6266 val_auc: 0.4966	test_loss: 0.6255 test_auc: 0.5656
2025-06-19 23:24:34,273 - INFO - train: {'epoch': 1, 'time_epoch': 61.73558, 'eta': 6478.11554, 'eta_hours': 1.79948, 'loss': 0.35946425, 'lr': 2e-05, 'params': 514193, 'time_iter': 0.06, 'accuracy': 0.9624, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.52729}
2025-06-19 23:24:34,284 - INFO - ...computing epoch stats took: 0.06s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:24:37,518 - INFO - val: {'epoch': 1, 'time_epoch': 3.2119, 'loss': 0.17258644, 'lr': 0, 'params': 514193, 'time_iter': 0.0249, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.58574}
2025-06-19 23:24:37,522 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:24:40,788 - INFO - test: {'epoch': 1, 'time_epoch': 3.2499, 'loss': 0.18741894, 'lr': 0, 'params': 514193, 'time_iter': 0.02519, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.61218}
2025-06-19 23:24:40,791 - INFO - ...computing epoch stats took: 0.02s
2025-06-19 23:24:40,792 - INFO - > Epoch 1: took 68.3s (avg 73.5s) | Best so far: epoch 1	train_loss: 0.3595 train_auc: 0.5273	val_loss: 0.1726 val_auc: 0.5857	test_loss: 0.1874 test_auc: 0.6122
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:25:44,646 - INFO - train: {'epoch': 2, 'time_epoch': 63.78949, 'eta': 6337.20182, 'eta_hours': 1.76033, 'loss': 0.16397615, 'lr': 4e-05, 'params': 514193, 'time_iter': 0.06199, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6411}
2025-06-19 23:25:44,654 - INFO - ...computing epoch stats took: 0.05s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:25:48,069 - INFO - val: {'epoch': 2, 'time_epoch': 3.39823, 'loss': 0.09816459, 'lr': 0, 'params': 514193, 'time_iter': 0.02634, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72408}
2025-06-19 23:25:48,072 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:25:51,416 - INFO - test: {'epoch': 2, 'time_epoch': 3.32719, 'loss': 0.12977038, 'lr': 0, 'params': 514193, 'time_iter': 0.02579, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73086}
2025-06-19 23:25:51,418 - INFO - ...computing epoch stats took: 0.01s
2025-06-19 23:25:51,418 - INFO - > Epoch 2: took 70.6s (avg 72.5s) | Best so far: epoch 2	train_loss: 0.1640 train_auc: 0.6411	val_loss: 0.0982 val_auc: 0.7241	test_loss: 0.1298 test_auc: 0.7309
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:26:55,158 - INFO - train: {'epoch': 3, 'time_epoch': 63.67579, 'eta': 6232.12135, 'eta_hours': 1.73114, 'loss': 0.14773204, 'lr': 6e-05, 'params': 514193, 'time_iter': 0.06188, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70325}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:26:58,646 - INFO - val: {'epoch': 3, 'time_epoch': 3.46197, 'loss': 0.0922388, 'lr': 0, 'params': 514193, 'time_iter': 0.02684, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72474}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:27:02,141 - INFO - test: {'epoch': 3, 'time_epoch': 3.47448, 'loss': 0.12539731, 'lr': 0, 'params': 514193, 'time_iter': 0.02693, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7315}
2025-06-19 23:27:02,143 - INFO - > Epoch 3: took 70.7s (avg 72.1s) | Best so far: epoch 3	train_loss: 0.1477 train_auc: 0.7033	val_loss: 0.0922 val_auc: 0.7247	test_loss: 0.1254 test_auc: 0.7315
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:28:04,747 - INFO - train: {'epoch': 4, 'time_epoch': 62.5422, 'eta': 6122.0645, 'eta_hours': 1.70057, 'loss': 0.14454942, 'lr': 8e-05, 'params': 514193, 'time_iter': 0.06078, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72538}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:28:07,998 - INFO - val: {'epoch': 4, 'time_epoch': 3.22661, 'loss': 0.09090589, 'lr': 0, 'params': 514193, 'time_iter': 0.02501, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70696}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:28:11,516 - INFO - test: {'epoch': 4, 'time_epoch': 3.49723, 'loss': 0.12674765, 'lr': 0, 'params': 514193, 'time_iter': 0.02711, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73247}
2025-06-19 23:28:11,520 - INFO - > Epoch 4: took 69.4s (avg 71.5s) | Best so far: epoch 3	train_loss: 0.1477 train_auc: 0.7033	val_loss: 0.0922 val_auc: 0.7247	test_loss: 0.1254 test_auc: 0.7315
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:29:14,062 - INFO - train: {'epoch': 5, 'time_epoch': 62.48007, 'eta': 6026.87249, 'eta_hours': 1.67413, 'loss': 0.1404606, 'lr': 0.0001, 'params': 514193, 'time_iter': 0.06072, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74378}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:29:17,558 - INFO - val: {'epoch': 5, 'time_epoch': 3.46783, 'loss': 0.09029466, 'lr': 0, 'params': 514193, 'time_iter': 0.02688, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72869}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:29:21,106 - INFO - test: {'epoch': 5, 'time_epoch': 3.51632, 'loss': 0.12669025, 'lr': 0, 'params': 514193, 'time_iter': 0.02726, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71999}
2025-06-19 23:29:21,110 - INFO - > Epoch 5: took 69.6s (avg 71.2s) | Best so far: epoch 5	train_loss: 0.1405 train_auc: 0.7438	val_loss: 0.0903 val_auc: 0.7287	test_loss: 0.1267 test_auc: 0.7200
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:30:25,778 - INFO - train: {'epoch': 6, 'time_epoch': 64.5966, 'eta': 5969.14644, 'eta_hours': 1.6581, 'loss': 0.13557018, 'lr': 9.997e-05, 'params': 514193, 'time_iter': 0.06278, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76435}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:30:29,094 - INFO - val: {'epoch': 6, 'time_epoch': 3.2887, 'loss': 0.0861633, 'lr': 0, 'params': 514193, 'time_iter': 0.02549, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75892}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:30:32,388 - INFO - test: {'epoch': 6, 'time_epoch': 3.27592, 'loss': 0.12708165, 'lr': 0, 'params': 514193, 'time_iter': 0.02539, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72388}
2025-06-19 23:30:32,390 - INFO - > Epoch 6: took 71.3s (avg 71.2s) | Best so far: epoch 6	train_loss: 0.1356 train_auc: 0.7643	val_loss: 0.0862 val_auc: 0.7589	test_loss: 0.1271 test_auc: 0.7239
2025-06-19 23:31:34,190 - INFO - train: {'epoch': 7, 'time_epoch': 61.71234, 'eta': 5876.53374, 'eta_hours': 1.63237, 'loss': 0.13320367, 'lr': 9.989e-05, 'params': 514193, 'time_iter': 0.05997, 'accuracy': 0.96277, 'precision': 0.70588, 'recall': 0.00974, 'f1': 0.01922, 'auc': 0.76995}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:31:37,805 - INFO - val: {'epoch': 7, 'time_epoch': 3.44833, 'loss': 0.08499918, 'lr': 0, 'params': 514193, 'time_iter': 0.02673, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73891}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-19 23:31:41,159 - INFO - test: {'epoch': 7, 'time_epoch': 3.33622, 'loss': 0.12988654, 'lr': 0, 'params': 514193, 'time_iter': 0.02586, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69423}
2025-06-19 23:31:41,162 - INFO - > Epoch 7: took 68.8s (avg 70.9s) | Best so far: epoch 6	train_loss: 0.1356 train_auc: 0.7643	val_loss: 0.0862 val_auc: 0.7589	test_loss: 0.1271 test_auc: 0.7239
2025-06-19 23:32:42,348 - INFO - train: {'epoch': 8, 'time_epoch': 61.10835, 'eta': 5784.68073, 'eta_hours': 1.60686, 'loss': 0.13032115, 'lr': 9.975e-05, 'params': 514193, 'time_iter': 0.05939, 'accuracy': 0.96438, 'precision': 0.69231, 'recall': 0.08766, 'f1': 0.15562, 'auc': 0.78447}
2025-06-19 23:32:45,665 - INFO - val: {'epoch': 8, 'time_epoch': 3.29208, 'loss': 0.08820165, 'lr': 0, 'params': 514193, 'time_iter': 0.02552, 'accuracy': 0.98055, 'precision': 0.52, 'recall': 0.16049, 'f1': 0.24528, 'auc': 0.75301}
2025-06-19 23:32:48,959 - INFO - test: {'epoch': 8, 'time_epoch': 3.27356, 'loss': 0.12956311, 'lr': 0, 'params': 514193, 'time_iter': 0.02538, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.13077, 'f1': 0.20732, 'auc': 0.72363}
2025-06-19 23:32:48,961 - INFO - > Epoch 8: took 67.8s (avg 70.6s) | Best so far: epoch 6	train_loss: 0.1356 train_auc: 0.7643	val_loss: 0.0862 val_auc: 0.7589	test_loss: 0.1271 test_auc: 0.7239
2025-06-19 23:33:50,703 - INFO - train: {'epoch': 9, 'time_epoch': 61.62212, 'eta': 5703.60059, 'eta_hours': 1.58433, 'loss': 0.12736689, 'lr': 9.956e-05, 'params': 514193, 'time_iter': 0.05989, 'accuracy': 0.96514, 'precision': 0.64605, 'recall': 0.1526, 'f1': 0.24688, 'auc': 0.79516}
2025-06-19 23:33:53,946 - INFO - val: {'epoch': 9, 'time_epoch': 3.21741, 'loss': 0.08934498, 'lr': 0, 'params': 514193, 'time_iter': 0.02494, 'accuracy': 0.98006, 'precision': 0.47619, 'recall': 0.12346, 'f1': 0.19608, 'auc': 0.74955}
2025-06-19 23:33:57,223 - INFO - test: {'epoch': 9, 'time_epoch': 3.25723, 'loss': 0.12062217, 'lr': 0, 'params': 514193, 'time_iter': 0.02525, 'accuracy': 0.96888, 'precision': 0.52941, 'recall': 0.13846, 'f1': 0.21951, 'auc': 0.76177}
2025-06-19 23:33:57,225 - INFO - > Epoch 9: took 68.3s (avg 70.3s) | Best so far: epoch 6	train_loss: 0.1356 train_auc: 0.7643	val_loss: 0.0862 val_auc: 0.7589	test_loss: 0.1271 test_auc: 0.7239
2025-06-19 23:34:58,475 - INFO - train: {'epoch': 10, 'time_epoch': 61.17332, 'eta': 5622.42711, 'eta_hours': 1.56179, 'loss': 0.12521866, 'lr': 9.932e-05, 'params': 514193, 'time_iter': 0.05945, 'accuracy': 0.96556, 'precision': 0.64688, 'recall': 0.17695, 'f1': 0.27788, 'auc': 0.80389}
2025-06-19 23:35:01,780 - INFO - val: {'epoch': 10, 'time_epoch': 3.2811, 'loss': 0.08392948, 'lr': 0, 'params': 514193, 'time_iter': 0.02543, 'accuracy': 0.98128, 'precision': 0.57692, 'recall': 0.18519, 'f1': 0.28037, 'auc': 0.74696}
2025-06-19 23:35:05,025 - INFO - test: {'epoch': 10, 'time_epoch': 3.22608, 'loss': 0.1202556, 'lr': 0, 'params': 514193, 'time_iter': 0.02501, 'accuracy': 0.96985, 'precision': 0.6875, 'recall': 0.08462, 'f1': 0.15068, 'auc': 0.74941}
2025-06-19 23:35:05,027 - INFO - > Epoch 10: took 67.8s (avg 70.1s) | Best so far: epoch 6	train_loss: 0.1356 train_auc: 0.7643	val_loss: 0.0862 val_auc: 0.7589	test_loss: 0.1271 test_auc: 0.7239
2025-06-19 23:36:05,888 - INFO - train: {'epoch': 11, 'time_epoch': 60.78054, 'eta': 5541.70656, 'eta_hours': 1.53936, 'loss': 0.12259125, 'lr': 9.902e-05, 'params': 514193, 'time_iter': 0.05907, 'accuracy': 0.96614, 'precision': 0.64532, 'recall': 0.21266, 'f1': 0.3199, 'auc': 0.8097}
2025-06-19 23:36:09,333 - INFO - val: {'epoch': 11, 'time_epoch': 3.41979, 'loss': 0.08936704, 'lr': 0, 'params': 514193, 'time_iter': 0.02651, 'accuracy': 0.97982, 'precision': 0.45455, 'recall': 0.12346, 'f1': 0.19417, 'auc': 0.72024}
2025-06-19 23:36:12,764 - INFO - test: {'epoch': 11, 'time_epoch': 3.40954, 'loss': 0.12148402, 'lr': 0, 'params': 514193, 'time_iter': 0.02643, 'accuracy': 0.96864, 'precision': 0.5122, 'recall': 0.16154, 'f1': 0.24561, 'auc': 0.75777}
2025-06-19 23:36:12,766 - INFO - > Epoch 11: took 67.7s (avg 69.9s) | Best so far: epoch 6	train_loss: 0.1356 train_auc: 0.7643	val_loss: 0.0862 val_auc: 0.7589	test_loss: 0.1271 test_auc: 0.7239
2025-06-19 23:37:21,876 - INFO - train: {'epoch': 12, 'time_epoch': 69.01902, 'eta': 5519.18816, 'eta_hours': 1.53311, 'loss': 0.12062006, 'lr': 9.867e-05, 'params': 514193, 'time_iter': 0.06707, 'accuracy': 0.9669, 'precision': 0.67146, 'recall': 0.22727, 'f1': 0.3396, 'auc': 0.81978}
2025-06-19 23:37:26,034 - INFO - val: {'epoch': 12, 'time_epoch': 4.12901, 'loss': 0.08340561, 'lr': 0, 'params': 514193, 'time_iter': 0.03201, 'accuracy': 0.98055, 'precision': 0.51852, 'recall': 0.17284, 'f1': 0.25926, 'auc': 0.73812}
2025-06-19 23:37:30,189 - INFO - test: {'epoch': 12, 'time_epoch': 4.13041, 'loss': 0.13099613, 'lr': 0, 'params': 514193, 'time_iter': 0.03202, 'accuracy': 0.96961, 'precision': 0.61905, 'recall': 0.1, 'f1': 0.17219, 'auc': 0.7105}
2025-06-19 23:37:30,192 - INFO - > Epoch 12: took 77.4s (avg 70.5s) | Best so far: epoch 6	train_loss: 0.1356 train_auc: 0.7643	val_loss: 0.0862 val_auc: 0.7589	test_loss: 0.1271 test_auc: 0.7239
2025-06-19 23:38:41,636 - INFO - train: {'epoch': 13, 'time_epoch': 71.35098, 'eta': 5504.35172, 'eta_hours': 1.52899, 'loss': 0.11966657, 'lr': 9.826e-05, 'params': 514193, 'time_iter': 0.06934, 'accuracy': 0.96696, 'precision': 0.6808, 'recall': 0.22159, 'f1': 0.33435, 'auc': 0.82148}
2025-06-19 23:38:45,125 - INFO - val: {'epoch': 13, 'time_epoch': 3.46091, 'loss': 0.0801401, 'lr': 0, 'params': 514193, 'time_iter': 0.02683, 'accuracy': 0.98055, 'precision': 0.51613, 'recall': 0.19753, 'f1': 0.28571, 'auc': 0.78657}
2025-06-19 23:38:48,548 - INFO - test: {'epoch': 13, 'time_epoch': 3.40088, 'loss': 0.11620467, 'lr': 0, 'params': 514193, 'time_iter': 0.02636, 'accuracy': 0.97009, 'precision': 0.57447, 'recall': 0.20769, 'f1': 0.30508, 'auc': 0.78147}
2025-06-19 23:38:48,550 - INFO - > Epoch 13: took 78.4s (avg 71.0s) | Best so far: epoch 13	train_loss: 0.1197 train_auc: 0.8215	val_loss: 0.0801 val_auc: 0.7866	test_loss: 0.1162 test_auc: 0.7815
2025-06-19 23:39:57,430 - INFO - train: {'epoch': 14, 'time_epoch': 68.79617, 'eta': 5467.50277, 'eta_hours': 1.51875, 'loss': 0.1188378, 'lr': 9.78e-05, 'params': 514193, 'time_iter': 0.06686, 'accuracy': 0.96699, 'precision': 0.67381, 'recall': 0.22971, 'f1': 0.34262, 'auc': 0.82538}
2025-06-19 23:40:00,720 - INFO - val: {'epoch': 14, 'time_epoch': 3.26424, 'loss': 0.08137615, 'lr': 0, 'params': 514193, 'time_iter': 0.0253, 'accuracy': 0.98152, 'precision': 0.57576, 'recall': 0.23457, 'f1': 0.33333, 'auc': 0.7631}
2025-06-19 23:40:04,062 - INFO - test: {'epoch': 14, 'time_epoch': 3.32265, 'loss': 0.11212864, 'lr': 0, 'params': 514193, 'time_iter': 0.02576, 'accuracy': 0.97107, 'precision': 0.61224, 'recall': 0.23077, 'f1': 0.3352, 'auc': 0.78526}
2025-06-19 23:40:04,065 - INFO - > Epoch 14: took 75.5s (avg 71.3s) | Best so far: epoch 13	train_loss: 0.1197 train_auc: 0.8215	val_loss: 0.0801 val_auc: 0.7866	test_loss: 0.1162 test_auc: 0.7815
2025-06-19 23:41:06,514 - INFO - train: {'epoch': 15, 'time_epoch': 62.36302, 'eta': 5392.88636, 'eta_hours': 1.49802, 'loss': 0.1159527, 'lr': 9.729e-05, 'params': 514193, 'time_iter': 0.06061, 'accuracy': 0.96757, 'precision': 0.68132, 'recall': 0.25162, 'f1': 0.36752, 'auc': 0.83548}
2025-06-19 23:41:10,015 - INFO - val: {'epoch': 15, 'time_epoch': 3.47458, 'loss': 0.08989446, 'lr': 0, 'params': 514193, 'time_iter': 0.02693, 'accuracy': 0.97836, 'precision': 0.42, 'recall': 0.25926, 'f1': 0.32061, 'auc': 0.76424}
2025-06-19 23:41:13,551 - INFO - test: {'epoch': 15, 'time_epoch': 3.51239, 'loss': 0.12223232, 'lr': 0, 'params': 514193, 'time_iter': 0.02723, 'accuracy': 0.96645, 'precision': 0.45745, 'recall': 0.33077, 'f1': 0.38393, 'auc': 0.77049}
2025-06-19 23:41:13,554 - INFO - > Epoch 15: took 69.5s (avg 71.2s) | Best so far: epoch 13	train_loss: 0.1197 train_auc: 0.8215	val_loss: 0.0801 val_auc: 0.7866	test_loss: 0.1162 test_auc: 0.7815
2025-06-19 23:42:16,157 - INFO - train: {'epoch': 16, 'time_epoch': 62.52505, 'eta': 5320.50263, 'eta_hours': 1.47792, 'loss': 0.11532837, 'lr': 9.673e-05, 'params': 514193, 'time_iter': 0.06076, 'accuracy': 0.96784, 'precision': 0.68201, 'recall': 0.26461, 'f1': 0.38129, 'auc': 0.83425}
2025-06-19 23:42:19,428 - INFO - val: {'epoch': 16, 'time_epoch': 3.24729, 'loss': 0.08523572, 'lr': 0, 'params': 514193, 'time_iter': 0.02517, 'accuracy': 0.97982, 'precision': 0.47222, 'recall': 0.20988, 'f1': 0.2906, 'auc': 0.76538}
2025-06-19 23:42:22,947 - INFO - test: {'epoch': 16, 'time_epoch': 3.4983, 'loss': 0.11933525, 'lr': 0, 'params': 514193, 'time_iter': 0.02712, 'accuracy': 0.97034, 'precision': 0.57692, 'recall': 0.23077, 'f1': 0.32967, 'auc': 0.76643}
2025-06-19 23:42:22,950 - INFO - > Epoch 16: took 69.4s (avg 71.1s) | Best so far: epoch 13	train_loss: 0.1197 train_auc: 0.8215	val_loss: 0.0801 val_auc: 0.7866	test_loss: 0.1162 test_auc: 0.7815
2025-06-19 23:43:24,099 - INFO - train: {'epoch': 17, 'time_epoch': 61.07195, 'eta': 5242.59461, 'eta_hours': 1.45628, 'loss': 0.11312323, 'lr': 9.611e-05, 'params': 514193, 'time_iter': 0.05935, 'accuracy': 0.96812, 'precision': 0.68866, 'recall': 0.2711, 'f1': 0.38905, 'auc': 0.84692}
2025-06-19 23:43:27,465 - INFO - val: {'epoch': 17, 'time_epoch': 3.34064, 'loss': 0.07960584, 'lr': 0, 'params': 514193, 'time_iter': 0.0259, 'accuracy': 0.98177, 'precision': 0.61538, 'recall': 0.19753, 'f1': 0.29907, 'auc': 0.76108}
2025-06-19 23:43:30,796 - INFO - test: {'epoch': 17, 'time_epoch': 3.31043, 'loss': 0.11498184, 'lr': 0, 'params': 514193, 'time_iter': 0.02566, 'accuracy': 0.97107, 'precision': 0.61702, 'recall': 0.22308, 'f1': 0.32768, 'auc': 0.76872}
2025-06-19 23:43:30,798 - INFO - > Epoch 17: took 67.8s (avg 70.9s) | Best so far: epoch 13	train_loss: 0.1197 train_auc: 0.8215	val_loss: 0.0801 val_auc: 0.7866	test_loss: 0.1162 test_auc: 0.7815
2025-06-19 23:44:38,071 - INFO - train: {'epoch': 18, 'time_epoch': 67.18469, 'eta': 5192.5184, 'eta_hours': 1.44237, 'loss': 0.11116287, 'lr': 9.545e-05, 'params': 514193, 'time_iter': 0.06529, 'accuracy': 0.96915, 'precision': 0.71919, 'recall': 0.28896, 'f1': 0.41228, 'auc': 0.84848}
2025-06-19 23:44:41,568 - INFO - val: {'epoch': 18, 'time_epoch': 3.46885, 'loss': 0.08549437, 'lr': 0, 'params': 514193, 'time_iter': 0.02689, 'accuracy': 0.97933, 'precision': 0.45455, 'recall': 0.24691, 'f1': 0.32, 'auc': 0.76235}
2025-06-19 23:44:45,063 - INFO - test: {'epoch': 18, 'time_epoch': 3.47216, 'loss': 0.12698669, 'lr': 0, 'params': 514193, 'time_iter': 0.02692, 'accuracy': 0.96766, 'precision': 0.47826, 'recall': 0.25385, 'f1': 0.33166, 'auc': 0.74479}
2025-06-19 23:44:45,065 - INFO - > Epoch 18: took 74.3s (avg 71.1s) | Best so far: epoch 13	train_loss: 0.1197 train_auc: 0.8215	val_loss: 0.0801 val_auc: 0.7866	test_loss: 0.1162 test_auc: 0.7815
2025-06-19 23:45:56,254 - INFO - train: {'epoch': 19, 'time_epoch': 71.08884, 'eta': 5156.34792, 'eta_hours': 1.43232, 'loss': 0.11031104, 'lr': 9.474e-05, 'params': 514193, 'time_iter': 0.06909, 'accuracy': 0.96897, 'precision': 0.71313, 'recall': 0.28653, 'f1': 0.4088, 'auc': 0.85334}
2025-06-19 23:45:59,857 - INFO - val: {'epoch': 19, 'time_epoch': 3.57564, 'loss': 0.08287882, 'lr': 0, 'params': 514193, 'time_iter': 0.02772, 'accuracy': 0.98128, 'precision': 0.55, 'recall': 0.2716, 'f1': 0.36364, 'auc': 0.75807}
2025-06-19 23:46:03,223 - INFO - test: {'epoch': 19, 'time_epoch': 3.3434, 'loss': 0.11959161, 'lr': 0, 'params': 514193, 'time_iter': 0.02592, 'accuracy': 0.96937, 'precision': 0.53704, 'recall': 0.22308, 'f1': 0.31522, 'auc': 0.76481}
2025-06-19 23:46:03,226 - INFO - > Epoch 19: took 78.2s (avg 71.5s) | Best so far: epoch 13	train_loss: 0.1197 train_auc: 0.8215	val_loss: 0.0801 val_auc: 0.7866	test_loss: 0.1162 test_auc: 0.7815
2025-06-19 23:47:14,235 - INFO - train: {'epoch': 20, 'time_epoch': 70.86602, 'eta': 5116.01368, 'eta_hours': 1.42111, 'loss': 0.10903391, 'lr': 9.397e-05, 'params': 514193, 'time_iter': 0.06887, 'accuracy': 0.96961, 'precision': 0.73387, 'recall': 0.29545, 'f1': 0.4213, 'auc': 0.85852}
2025-06-19 23:47:18,285 - INFO - val: {'epoch': 20, 'time_epoch': 4.02142, 'loss': 0.0781651, 'lr': 0, 'params': 514193, 'time_iter': 0.03117, 'accuracy': 0.98298, 'precision': 0.65714, 'recall': 0.28395, 'f1': 0.39655, 'auc': 0.7713}
2025-06-19 23:47:21,687 - INFO - test: {'epoch': 20, 'time_epoch': 3.38166, 'loss': 0.1206484, 'lr': 0, 'params': 514193, 'time_iter': 0.02621, 'accuracy': 0.96888, 'precision': 0.52083, 'recall': 0.19231, 'f1': 0.2809, 'auc': 0.76836}
2025-06-19 23:47:21,689 - INFO - > Epoch 20: took 78.5s (avg 71.8s) | Best so far: epoch 13	train_loss: 0.1197 train_auc: 0.8215	val_loss: 0.0801 val_auc: 0.7866	test_loss: 0.1162 test_auc: 0.7815
2025-06-19 23:48:32,816 - INFO - train: {'epoch': 21, 'time_epoch': 71.03062, 'eta': 5073.4874, 'eta_hours': 1.4093, 'loss': 0.10826647, 'lr': 9.316e-05, 'params': 514193, 'time_iter': 0.06903, 'accuracy': 0.96885, 'precision': 0.70577, 'recall': 0.28815, 'f1': 0.40922, 'auc': 0.86061}
2025-06-19 23:48:36,713 - INFO - val: {'epoch': 21, 'time_epoch': 3.86985, 'loss': 0.08402101, 'lr': 0, 'params': 514193, 'time_iter': 0.03, 'accuracy': 0.97933, 'precision': 0.45833, 'recall': 0.2716, 'f1': 0.34109, 'auc': 0.78557}
2025-06-19 23:48:40,022 - INFO - test: {'epoch': 21, 'time_epoch': 3.28852, 'loss': 0.1300851, 'lr': 0, 'params': 514193, 'time_iter': 0.02549, 'accuracy': 0.96742, 'precision': 0.46154, 'recall': 0.18462, 'f1': 0.26374, 'auc': 0.73421}
2025-06-19 23:48:40,025 - INFO - > Epoch 21: took 78.3s (avg 72.1s) | Best so far: epoch 13	train_loss: 0.1197 train_auc: 0.8215	val_loss: 0.0801 val_auc: 0.7866	test_loss: 0.1162 test_auc: 0.7815
2025-06-19 23:49:48,255 - INFO - train: {'epoch': 22, 'time_epoch': 68.14723, 'eta': 5018.8294, 'eta_hours': 1.39412, 'loss': 0.10695235, 'lr': 9.23e-05, 'params': 514193, 'time_iter': 0.06623, 'accuracy': 0.96991, 'precision': 0.7208, 'recall': 0.32062, 'f1': 0.44382, 'auc': 0.8611}
2025-06-19 23:49:51,645 - INFO - val: {'epoch': 22, 'time_epoch': 3.36532, 'loss': 0.08240527, 'lr': 0, 'params': 514193, 'time_iter': 0.02609, 'accuracy': 0.98201, 'precision': 0.60606, 'recall': 0.24691, 'f1': 0.35088, 'auc': 0.77304}
2025-06-19 23:49:54,988 - INFO - test: {'epoch': 22, 'time_epoch': 3.32326, 'loss': 0.1236665, 'lr': 0, 'params': 514193, 'time_iter': 0.02576, 'accuracy': 0.96985, 'precision': 0.575, 'recall': 0.17692, 'f1': 0.27059, 'auc': 0.77845}
2025-06-19 23:49:54,991 - INFO - > Epoch 22: took 75.0s (avg 72.2s) | Best so far: epoch 13	train_loss: 0.1197 train_auc: 0.8215	val_loss: 0.0801 val_auc: 0.7866	test_loss: 0.1162 test_auc: 0.7815
2025-06-19 23:51:02,379 - INFO - train: {'epoch': 23, 'time_epoch': 67.3003, 'eta': 4960.36534, 'eta_hours': 1.37788, 'loss': 0.10524179, 'lr': 9.14e-05, 'params': 514193, 'time_iter': 0.0654, 'accuracy': 0.97046, 'precision': 0.73723, 'recall': 0.32792, 'f1': 0.45393, 'auc': 0.86723}
2025-06-19 23:51:05,948 - INFO - val: {'epoch': 23, 'time_epoch': 3.53168, 'loss': 0.08192998, 'lr': 0, 'params': 514193, 'time_iter': 0.02738, 'accuracy': 0.98055, 'precision': 0.5122, 'recall': 0.25926, 'f1': 0.34426, 'auc': 0.78688}
2025-06-19 23:51:09,151 - INFO - test: {'epoch': 23, 'time_epoch': 3.18224, 'loss': 0.12784792, 'lr': 0, 'params': 514193, 'time_iter': 0.02467, 'accuracy': 0.96645, 'precision': 0.42857, 'recall': 0.18462, 'f1': 0.25806, 'auc': 0.78}
2025-06-19 23:51:09,153 - INFO - > Epoch 23: took 74.2s (avg 72.3s) | Best so far: epoch 23	train_loss: 0.1052 train_auc: 0.8672	val_loss: 0.0819 val_auc: 0.7869	test_loss: 0.1278 test_auc: 0.7800
2025-06-19 23:52:18,534 - INFO - train: {'epoch': 24, 'time_epoch': 69.28186, 'eta': 4907.13906, 'eta_hours': 1.36309, 'loss': 0.1054539, 'lr': 9.045e-05, 'params': 514193, 'time_iter': 0.06733, 'accuracy': 0.96967, 'precision': 0.71273, 'recall': 0.31818, 'f1': 0.43996, 'auc': 0.86991}
2025-06-19 23:52:22,246 - INFO - val: {'epoch': 24, 'time_epoch': 3.68245, 'loss': 0.08006602, 'lr': 0, 'params': 514193, 'time_iter': 0.02855, 'accuracy': 0.98152, 'precision': 0.56098, 'recall': 0.28395, 'f1': 0.37705, 'auc': 0.79098}
2025-06-19 23:52:25,892 - INFO - test: {'epoch': 24, 'time_epoch': 3.62266, 'loss': 0.12241789, 'lr': 0, 'params': 514193, 'time_iter': 0.02808, 'accuracy': 0.96815, 'precision': 0.49206, 'recall': 0.23846, 'f1': 0.32124, 'auc': 0.77448}
2025-06-19 23:52:25,894 - INFO - > Epoch 24: took 76.7s (avg 72.5s) | Best so far: epoch 24	train_loss: 0.1055 train_auc: 0.8699	val_loss: 0.0801 val_auc: 0.7910	test_loss: 0.1224 test_auc: 0.7745
2025-06-19 23:53:35,960 - INFO - train: {'epoch': 25, 'time_epoch': 69.97352, 'eta': 4854.64631, 'eta_hours': 1.34851, 'loss': 0.10303158, 'lr': 8.946e-05, 'params': 514193, 'time_iter': 0.068, 'accuracy': 0.97006, 'precision': 0.72414, 'recall': 0.32386, 'f1': 0.44756, 'auc': 0.88173}
2025-06-19 23:53:39,284 - INFO - val: {'epoch': 25, 'time_epoch': 3.29513, 'loss': 0.08627582, 'lr': 0, 'params': 514193, 'time_iter': 0.02554, 'accuracy': 0.97812, 'precision': 0.40816, 'recall': 0.24691, 'f1': 0.30769, 'auc': 0.76797}
2025-06-19 23:53:42,618 - INFO - test: {'epoch': 25, 'time_epoch': 3.3076, 'loss': 0.12547111, 'lr': 0, 'params': 514193, 'time_iter': 0.02564, 'accuracy': 0.96645, 'precision': 0.44444, 'recall': 0.24615, 'f1': 0.31683, 'auc': 0.77779}
2025-06-19 23:53:42,620 - INFO - > Epoch 25: took 76.7s (avg 72.6s) | Best so far: epoch 24	train_loss: 0.1055 train_auc: 0.8699	val_loss: 0.0801 val_auc: 0.7910	test_loss: 0.1224 test_auc: 0.7745
2025-06-19 23:54:44,439 - INFO - train: {'epoch': 26, 'time_epoch': 61.73564, 'eta': 4778.58589, 'eta_hours': 1.32738, 'loss': 0.10178527, 'lr': 8.842e-05, 'params': 514193, 'time_iter': 0.06, 'accuracy': 0.97055, 'precision': 0.73192, 'recall': 0.33685, 'f1': 0.46137, 'auc': 0.88587}
2025-06-19 23:54:47,919 - INFO - val: {'epoch': 26, 'time_epoch': 3.45383, 'loss': 0.09560442, 'lr': 0, 'params': 514193, 'time_iter': 0.02677, 'accuracy': 0.97836, 'precision': 0.42593, 'recall': 0.28395, 'f1': 0.34074, 'auc': 0.74815}
2025-06-19 23:54:51,222 - INFO - test: {'epoch': 26, 'time_epoch': 3.28266, 'loss': 0.13278929, 'lr': 0, 'params': 514193, 'time_iter': 0.02545, 'accuracy': 0.96766, 'precision': 0.47692, 'recall': 0.23846, 'f1': 0.31795, 'auc': 0.76102}
2025-06-19 23:54:51,224 - INFO - > Epoch 26: took 68.6s (avg 72.5s) | Best so far: epoch 24	train_loss: 0.1055 train_auc: 0.8699	val_loss: 0.0801 val_auc: 0.7910	test_loss: 0.1224 test_auc: 0.7745
2025-06-19 23:55:53,065 - INFO - train: {'epoch': 27, 'time_epoch': 61.76316, 'eta': 4703.61944, 'eta_hours': 1.30656, 'loss': 0.10087204, 'lr': 8.734e-05, 'params': 514193, 'time_iter': 0.06002, 'accuracy': 0.97061, 'precision': 0.7265, 'recall': 0.34497, 'f1': 0.4678, 'auc': 0.88412}
2025-06-19 23:55:56,713 - INFO - val: {'epoch': 27, 'time_epoch': 3.62254, 'loss': 0.0863126, 'lr': 0, 'params': 514193, 'time_iter': 0.02808, 'accuracy': 0.98055, 'precision': 0.5102, 'recall': 0.30864, 'f1': 0.38462, 'auc': 0.76563}
2025-06-19 23:56:00,352 - INFO - test: {'epoch': 27, 'time_epoch': 3.51415, 'loss': 0.12359416, 'lr': 0, 'params': 514193, 'time_iter': 0.02724, 'accuracy': 0.96742, 'precision': 0.47561, 'recall': 0.3, 'f1': 0.36792, 'auc': 0.77383}
2025-06-19 23:56:00,354 - INFO - > Epoch 27: took 69.1s (avg 72.4s) | Best so far: epoch 24	train_loss: 0.1055 train_auc: 0.8699	val_loss: 0.0801 val_auc: 0.7910	test_loss: 0.1224 test_auc: 0.7745
2025-06-19 23:57:06,498 - INFO - train: {'epoch': 28, 'time_epoch': 66.05753, 'eta': 4640.07736, 'eta_hours': 1.28891, 'loss': 0.09882234, 'lr': 8.622e-05, 'params': 514193, 'time_iter': 0.0642, 'accuracy': 0.97198, 'precision': 0.75578, 'recall': 0.37175, 'f1': 0.49837, 'auc': 0.89289}
2025-06-19 23:57:10,041 - INFO - val: {'epoch': 28, 'time_epoch': 3.51443, 'loss': 0.08489446, 'lr': 0, 'params': 514193, 'time_iter': 0.02724, 'accuracy': 0.98128, 'precision': 0.55, 'recall': 0.2716, 'f1': 0.36364, 'auc': 0.77041}
2025-06-19 23:57:13,691 - INFO - test: {'epoch': 28, 'time_epoch': 3.62483, 'loss': 0.12659587, 'lr': 0, 'params': 514193, 'time_iter': 0.0281, 'accuracy': 0.96742, 'precision': 0.46, 'recall': 0.17692, 'f1': 0.25556, 'auc': 0.76643}
2025-06-19 23:57:13,694 - INFO - > Epoch 28: took 73.3s (avg 72.4s) | Best so far: epoch 24	train_loss: 0.1055 train_auc: 0.8699	val_loss: 0.0801 val_auc: 0.7910	test_loss: 0.1224 test_auc: 0.7745
2025-06-19 23:58:23,647 - INFO - train: {'epoch': 29, 'time_epoch': 69.86175, 'eta': 4585.24411, 'eta_hours': 1.27368, 'loss': 0.09966628, 'lr': 8.506e-05, 'params': 514193, 'time_iter': 0.06789, 'accuracy': 0.97052, 'precision': 0.72743, 'recall': 0.3401, 'f1': 0.4635, 'auc': 0.89498}
2025-06-19 23:58:27,591 - INFO - val: {'epoch': 29, 'time_epoch': 3.91382, 'loss': 0.09058445, 'lr': 0, 'params': 514193, 'time_iter': 0.03034, 'accuracy': 0.9786, 'precision': 0.43396, 'recall': 0.28395, 'f1': 0.34328, 'auc': 0.78271}
2025-06-19 23:58:30,940 - INFO - test: {'epoch': 29, 'time_epoch': 3.32896, 'loss': 0.1302118, 'lr': 0, 'params': 514193, 'time_iter': 0.02581, 'accuracy': 0.9645, 'precision': 0.40244, 'recall': 0.25385, 'f1': 0.31132, 'auc': 0.7737}
2025-06-19 23:58:30,943 - INFO - > Epoch 29: took 77.2s (avg 72.6s) | Best so far: epoch 24	train_loss: 0.1055 train_auc: 0.8699	val_loss: 0.0801 val_auc: 0.7910	test_loss: 0.1224 test_auc: 0.7745
2025-06-19 23:59:37,411 - INFO - train: {'epoch': 30, 'time_epoch': 66.37516, 'eta': 4521.68079, 'eta_hours': 1.25602, 'loss': 0.09863864, 'lr': 8.386e-05, 'params': 514193, 'time_iter': 0.0645, 'accuracy': 0.97146, 'precision': 0.7539, 'recall': 0.35308, 'f1': 0.48093, 'auc': 0.89822}
2025-06-19 23:59:40,982 - INFO - val: {'epoch': 30, 'time_epoch': 3.5438, 'loss': 0.08297877, 'lr': 0, 'params': 514193, 'time_iter': 0.02747, 'accuracy': 0.97958, 'precision': 0.4717, 'recall': 0.30864, 'f1': 0.37313, 'auc': 0.79822}
2025-06-19 23:59:44,331 - INFO - test: {'epoch': 30, 'time_epoch': 3.32858, 'loss': 0.1234101, 'lr': 0, 'params': 514193, 'time_iter': 0.0258, 'accuracy': 0.96645, 'precision': 0.44737, 'recall': 0.26154, 'f1': 0.3301, 'auc': 0.77781}
2025-06-19 23:59:44,334 - INFO - > Epoch 30: took 73.4s (avg 72.6s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:00:57,374 - INFO - train: {'epoch': 31, 'time_epoch': 72.94864, 'eta': 4471.91039, 'eta_hours': 1.2422, 'loss': 0.09777891, 'lr': 8.263e-05, 'params': 514193, 'time_iter': 0.07089, 'accuracy': 0.97213, 'precision': 0.75862, 'recall': 0.375, 'f1': 0.5019, 'auc': 0.89544}
2025-06-20 00:01:00,826 - INFO - val: {'epoch': 31, 'time_epoch': 3.4165, 'loss': 0.08724303, 'lr': 0, 'params': 514193, 'time_iter': 0.02648, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.2963, 'f1': 0.37209, 'auc': 0.75048}
2025-06-20 00:01:04,240 - INFO - test: {'epoch': 31, 'time_epoch': 3.39235, 'loss': 0.12681533, 'lr': 0, 'params': 514193, 'time_iter': 0.0263, 'accuracy': 0.96815, 'precision': 0.49153, 'recall': 0.22308, 'f1': 0.30688, 'auc': 0.76463}
2025-06-20 00:01:04,243 - INFO - > Epoch 31: took 79.9s (avg 72.8s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:02:11,458 - INFO - train: {'epoch': 32, 'time_epoch': 67.13052, 'eta': 4408.92269, 'eta_hours': 1.2247, 'loss': 0.09624888, 'lr': 8.136e-05, 'params': 514193, 'time_iter': 0.06524, 'accuracy': 0.97143, 'precision': 0.73779, 'recall': 0.36769, 'f1': 0.49079, 'auc': 0.90212}
2025-06-20 00:02:14,741 - INFO - val: {'epoch': 32, 'time_epoch': 3.25942, 'loss': 0.08295356, 'lr': 0, 'params': 514193, 'time_iter': 0.02527, 'accuracy': 0.98201, 'precision': 0.60606, 'recall': 0.24691, 'f1': 0.35088, 'auc': 0.77082}
2025-06-20 00:02:18,073 - INFO - test: {'epoch': 32, 'time_epoch': 3.31105, 'loss': 0.12754333, 'lr': 0, 'params': 514193, 'time_iter': 0.02567, 'accuracy': 0.96888, 'precision': 0.52083, 'recall': 0.19231, 'f1': 0.2809, 'auc': 0.77281}
2025-06-20 00:02:18,075 - INFO - > Epoch 32: took 73.8s (avg 72.9s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:03:20,486 - INFO - train: {'epoch': 33, 'time_epoch': 62.32478, 'eta': 4336.36252, 'eta_hours': 1.20455, 'loss': 0.09473607, 'lr': 8.005e-05, 'params': 514193, 'time_iter': 0.06057, 'accuracy': 0.97189, 'precision': 0.74326, 'recall': 0.38068, 'f1': 0.50349, 'auc': 0.90762}
2025-06-20 00:03:23,892 - INFO - val: {'epoch': 33, 'time_epoch': 3.38037, 'loss': 0.08688925, 'lr': 0, 'params': 514193, 'time_iter': 0.0262, 'accuracy': 0.97958, 'precision': 0.4717, 'recall': 0.30864, 'f1': 0.37313, 'auc': 0.78607}
2025-06-20 00:03:27,182 - INFO - test: {'epoch': 33, 'time_epoch': 3.27136, 'loss': 0.12932829, 'lr': 0, 'params': 514193, 'time_iter': 0.02536, 'accuracy': 0.96426, 'precision': 0.39506, 'recall': 0.24615, 'f1': 0.30332, 'auc': 0.7855}
2025-06-20 00:03:27,184 - INFO - > Epoch 33: took 69.1s (avg 72.7s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:04:28,200 - INFO - train: {'epoch': 34, 'time_epoch': 60.93813, 'eta': 4261.81202, 'eta_hours': 1.18384, 'loss': 0.09469026, 'lr': 7.872e-05, 'params': 514193, 'time_iter': 0.05922, 'accuracy': 0.97268, 'precision': 0.77889, 'recall': 0.37744, 'f1': 0.50847, 'auc': 0.90748}
2025-06-20 00:04:31,572 - INFO - val: {'epoch': 34, 'time_epoch': 3.34659, 'loss': 0.09158274, 'lr': 0, 'params': 514193, 'time_iter': 0.02594, 'accuracy': 0.97739, 'precision': 0.40323, 'recall': 0.30864, 'f1': 0.34965, 'auc': 0.75526}
2025-06-20 00:04:34,886 - INFO - test: {'epoch': 34, 'time_epoch': 3.29456, 'loss': 0.14247932, 'lr': 0, 'params': 514193, 'time_iter': 0.02554, 'accuracy': 0.96304, 'precision': 0.36905, 'recall': 0.23846, 'f1': 0.28972, 'auc': 0.74253}
2025-06-20 00:04:34,888 - INFO - > Epoch 34: took 67.7s (avg 72.6s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:05:37,140 - INFO - train: {'epoch': 35, 'time_epoch': 62.17157, 'eta': 4190.21053, 'eta_hours': 1.16395, 'loss': 0.09331496, 'lr': 7.735e-05, 'params': 514193, 'time_iter': 0.06042, 'accuracy': 0.97234, 'precision': 0.77104, 'recall': 0.37175, 'f1': 0.50164, 'auc': 0.9133}
2025-06-20 00:05:40,622 - INFO - val: {'epoch': 35, 'time_epoch': 3.4572, 'loss': 0.08534667, 'lr': 0, 'params': 514193, 'time_iter': 0.0268, 'accuracy': 0.97909, 'precision': 0.44898, 'recall': 0.2716, 'f1': 0.33846, 'auc': 0.78745}
2025-06-20 00:05:44,129 - INFO - test: {'epoch': 35, 'time_epoch': 3.48476, 'loss': 0.13126256, 'lr': 0, 'params': 514193, 'time_iter': 0.02701, 'accuracy': 0.96669, 'precision': 0.44776, 'recall': 0.23077, 'f1': 0.30457, 'auc': 0.77476}
2025-06-20 00:05:44,131 - INFO - > Epoch 35: took 69.2s (avg 72.5s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:06:46,419 - INFO - train: {'epoch': 36, 'time_epoch': 62.20841, 'eta': 4119.18151, 'eta_hours': 1.14422, 'loss': 0.09192824, 'lr': 7.595e-05, 'params': 514193, 'time_iter': 0.06046, 'accuracy': 0.97219, 'precision': 0.74498, 'recall': 0.39123, 'f1': 0.51304, 'auc': 0.91576}
2025-06-20 00:06:49,785 - INFO - val: {'epoch': 36, 'time_epoch': 3.34067, 'loss': 0.09189148, 'lr': 0, 'params': 514193, 'time_iter': 0.0259, 'accuracy': 0.97885, 'precision': 0.44231, 'recall': 0.28395, 'f1': 0.34586, 'auc': 0.76125}
2025-06-20 00:06:53,233 - INFO - test: {'epoch': 36, 'time_epoch': 3.42555, 'loss': 0.1358747, 'lr': 0, 'params': 514193, 'time_iter': 0.02655, 'accuracy': 0.96572, 'precision': 0.43038, 'recall': 0.26154, 'f1': 0.32536, 'auc': 0.75509}
2025-06-20 00:06:53,235 - INFO - > Epoch 36: took 69.1s (avg 72.4s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:07:59,520 - INFO - train: {'epoch': 37, 'time_epoch': 66.19862, 'eta': 4055.12707, 'eta_hours': 1.12642, 'loss': 0.09195403, 'lr': 7.452e-05, 'params': 514193, 'time_iter': 0.06433, 'accuracy': 0.9721, 'precision': 0.74842, 'recall': 0.38393, 'f1': 0.50751, 'auc': 0.91806}
2025-06-20 00:08:02,964 - INFO - val: {'epoch': 37, 'time_epoch': 3.41879, 'loss': 0.08569896, 'lr': 0, 'params': 514193, 'time_iter': 0.0265, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.18519, 'f1': 0.27027, 'auc': 0.75215}
2025-06-20 00:08:06,244 - INFO - test: {'epoch': 37, 'time_epoch': 3.261, 'loss': 0.13389426, 'lr': 0, 'params': 514193, 'time_iter': 0.02528, 'accuracy': 0.96742, 'precision': 0.43333, 'recall': 0.1, 'f1': 0.1625, 'auc': 0.76307}
2025-06-20 00:08:06,247 - INFO - > Epoch 37: took 73.0s (avg 72.4s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:09:09,032 - INFO - train: {'epoch': 38, 'time_epoch': 62.69895, 'eta': 3985.48881, 'eta_hours': 1.10708, 'loss': 0.08959263, 'lr': 7.307e-05, 'params': 514193, 'time_iter': 0.06093, 'accuracy': 0.97337, 'precision': 0.77217, 'recall': 0.4099, 'f1': 0.53552, 'auc': 0.92139}
2025-06-20 00:09:12,535 - INFO - val: {'epoch': 38, 'time_epoch': 3.47637, 'loss': 0.09454719, 'lr': 0, 'params': 514193, 'time_iter': 0.02695, 'accuracy': 0.97982, 'precision': 0.47727, 'recall': 0.25926, 'f1': 0.336, 'auc': 0.73989}
2025-06-20 00:09:16,024 - INFO - test: {'epoch': 38, 'time_epoch': 3.46778, 'loss': 0.14194235, 'lr': 0, 'params': 514193, 'time_iter': 0.02688, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.17692, 'f1': 0.26136, 'auc': 0.76153}
2025-06-20 00:09:16,026 - INFO - > Epoch 38: took 69.8s (avg 72.4s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:10:16,289 - INFO - train: {'epoch': 39, 'time_epoch': 60.14471, 'eta': 3912.36617, 'eta_hours': 1.08677, 'loss': 0.08900218, 'lr': 7.159e-05, 'params': 514193, 'time_iter': 0.05845, 'accuracy': 0.97368, 'precision': 0.77644, 'recall': 0.41721, 'f1': 0.54277, 'auc': 0.92496}
2025-06-20 00:10:19,771 - INFO - val: {'epoch': 39, 'time_epoch': 3.45563, 'loss': 0.08325195, 'lr': 0, 'params': 514193, 'time_iter': 0.02679, 'accuracy': 0.98055, 'precision': 0.51111, 'recall': 0.28395, 'f1': 0.36508, 'auc': 0.78263}
2025-06-20 00:10:23,269 - INFO - test: {'epoch': 39, 'time_epoch': 3.47708, 'loss': 0.13128147, 'lr': 0, 'params': 514193, 'time_iter': 0.02695, 'accuracy': 0.96864, 'precision': 0.50943, 'recall': 0.20769, 'f1': 0.29508, 'auc': 0.77772}
2025-06-20 00:10:23,272 - INFO - > Epoch 39: took 67.2s (avg 72.2s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:11:25,277 - INFO - train: {'epoch': 40, 'time_epoch': 61.9253, 'eta': 3842.43891, 'eta_hours': 1.06734, 'loss': 0.08863272, 'lr': 7.008e-05, 'params': 514193, 'time_iter': 0.06018, 'accuracy': 0.97328, 'precision': 0.76226, 'recall': 0.4164, 'f1': 0.53858, 'auc': 0.92655}
2025-06-20 00:11:28,660 - INFO - val: {'epoch': 40, 'time_epoch': 3.35783, 'loss': 0.08835626, 'lr': 0, 'params': 514193, 'time_iter': 0.02603, 'accuracy': 0.98177, 'precision': 0.58333, 'recall': 0.25926, 'f1': 0.35897, 'auc': 0.74103}
2025-06-20 00:11:32,154 - INFO - test: {'epoch': 40, 'time_epoch': 3.47219, 'loss': 0.13109569, 'lr': 0, 'params': 514193, 'time_iter': 0.02692, 'accuracy': 0.96937, 'precision': 0.54348, 'recall': 0.19231, 'f1': 0.28409, 'auc': 0.77271}
2025-06-20 00:11:32,156 - INFO - > Epoch 40: took 68.9s (avg 72.2s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:12:34,844 - INFO - train: {'epoch': 41, 'time_epoch': 62.60568, 'eta': 3773.83228, 'eta_hours': 1.04829, 'loss': 0.08685274, 'lr': 6.856e-05, 'params': 514193, 'time_iter': 0.06084, 'accuracy': 0.97374, 'precision': 0.78571, 'recall': 0.41071, 'f1': 0.53945, 'auc': 0.93068}
2025-06-20 00:12:38,142 - INFO - val: {'epoch': 41, 'time_epoch': 3.27463, 'loss': 0.09395911, 'lr': 0, 'params': 514193, 'time_iter': 0.02538, 'accuracy': 0.98006, 'precision': 0.49057, 'recall': 0.32099, 'f1': 0.38806, 'auc': 0.77764}
2025-06-20 00:12:41,520 - INFO - test: {'epoch': 41, 'time_epoch': 3.35776, 'loss': 0.15154553, 'lr': 0, 'params': 514193, 'time_iter': 0.02603, 'accuracy': 0.96572, 'precision': 0.42254, 'recall': 0.23077, 'f1': 0.29851, 'auc': 0.75884}
2025-06-20 00:12:41,536 - INFO - > Epoch 41: took 69.4s (avg 72.1s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:13:43,958 - INFO - train: {'epoch': 42, 'time_epoch': 62.33556, 'eta': 3705.14669, 'eta_hours': 1.02921, 'loss': 0.08834543, 'lr': 6.701e-05, 'params': 514193, 'time_iter': 0.06058, 'accuracy': 0.97337, 'precision': 0.76567, 'recall': 0.4164, 'f1': 0.53943, 'auc': 0.92279}
2025-06-20 00:13:47,474 - INFO - val: {'epoch': 42, 'time_epoch': 3.49109, 'loss': 0.08692476, 'lr': 0, 'params': 514193, 'time_iter': 0.02706, 'accuracy': 0.97933, 'precision': 0.46296, 'recall': 0.30864, 'f1': 0.37037, 'auc': 0.78153}
2025-06-20 00:13:51,016 - INFO - test: {'epoch': 42, 'time_epoch': 3.52091, 'loss': 0.13883927, 'lr': 0, 'params': 514193, 'time_iter': 0.02729, 'accuracy': 0.96718, 'precision': 0.45902, 'recall': 0.21538, 'f1': 0.29319, 'auc': 0.76581}
2025-06-20 00:13:51,019 - INFO - > Epoch 42: took 69.5s (avg 72.0s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:14:53,427 - INFO - train: {'epoch': 43, 'time_epoch': 62.32855, 'eta': 3636.7408, 'eta_hours': 1.01021, 'loss': 0.08610846, 'lr': 6.545e-05, 'params': 514193, 'time_iter': 0.06057, 'accuracy': 0.97365, 'precision': 0.7728, 'recall': 0.41964, 'f1': 0.54392, 'auc': 0.93249}
2025-06-20 00:14:56,791 - INFO - val: {'epoch': 43, 'time_epoch': 3.33945, 'loss': 0.10964935, 'lr': 0, 'params': 514193, 'time_iter': 0.02589, 'accuracy': 0.97715, 'precision': 0.40845, 'recall': 0.35802, 'f1': 0.38158, 'auc': 0.75532}
2025-06-20 00:15:00,176 - INFO - test: {'epoch': 43, 'time_epoch': 3.36411, 'loss': 0.16294346, 'lr': 0, 'params': 514193, 'time_iter': 0.02608, 'accuracy': 0.96304, 'precision': 0.38542, 'recall': 0.28462, 'f1': 0.32743, 'auc': 0.7444}
2025-06-20 00:15:00,178 - INFO - > Epoch 43: took 69.2s (avg 72.0s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:16:02,135 - INFO - train: {'epoch': 44, 'time_epoch': 61.87879, 'eta': 3568.05533, 'eta_hours': 0.99113, 'loss': 0.08794903, 'lr': 6.387e-05, 'params': 514193, 'time_iter': 0.06013, 'accuracy': 0.97337, 'precision': 0.76254, 'recall': 0.41964, 'f1': 0.54136, 'auc': 0.92752}
2025-06-20 00:16:05,418 - INFO - val: {'epoch': 44, 'time_epoch': 3.25934, 'loss': 0.09492216, 'lr': 0, 'params': 514193, 'time_iter': 0.02527, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.2963, 'f1': 0.37209, 'auc': 0.74995}
2025-06-20 00:16:08,700 - INFO - test: {'epoch': 44, 'time_epoch': 3.26316, 'loss': 0.14821518, 'lr': 0, 'params': 514193, 'time_iter': 0.0253, 'accuracy': 0.96377, 'precision': 0.35385, 'recall': 0.17692, 'f1': 0.2359, 'auc': 0.76659}
2025-06-20 00:16:08,702 - INFO - > Epoch 44: took 68.5s (avg 71.9s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:17:10,551 - INFO - train: {'epoch': 45, 'time_epoch': 61.76915, 'eta': 3499.53708, 'eta_hours': 0.97209, 'loss': 0.08326445, 'lr': 6.227e-05, 'params': 514193, 'time_iter': 0.06003, 'accuracy': 0.97386, 'precision': 0.77761, 'recall': 0.42289, 'f1': 0.54784, 'auc': 0.93948}
2025-06-20 00:17:14,040 - INFO - val: {'epoch': 45, 'time_epoch': 3.46307, 'loss': 0.09097081, 'lr': 0, 'params': 514193, 'time_iter': 0.02685, 'accuracy': 0.98055, 'precision': 0.51282, 'recall': 0.24691, 'f1': 0.33333, 'auc': 0.76705}
2025-06-20 00:17:17,529 - INFO - test: {'epoch': 45, 'time_epoch': 3.46617, 'loss': 0.14567433, 'lr': 0, 'params': 514193, 'time_iter': 0.02687, 'accuracy': 0.96815, 'precision': 0.4902, 'recall': 0.19231, 'f1': 0.27624, 'auc': 0.78497}
2025-06-20 00:17:17,531 - INFO - > Epoch 45: took 68.8s (avg 71.8s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:18:19,624 - INFO - train: {'epoch': 46, 'time_epoch': 62.01252, 'eta': 3431.58048, 'eta_hours': 0.95322, 'loss': 0.08579499, 'lr': 6.066e-05, 'params': 514193, 'time_iter': 0.06026, 'accuracy': 0.97386, 'precision': 0.78528, 'recall': 0.41558, 'f1': 0.54352, 'auc': 0.93337}
2025-06-20 00:18:23,025 - INFO - val: {'epoch': 46, 'time_epoch': 3.37651, 'loss': 0.09638077, 'lr': 0, 'params': 514193, 'time_iter': 0.02617, 'accuracy': 0.97788, 'precision': 0.40741, 'recall': 0.2716, 'f1': 0.32593, 'auc': 0.75252}
2025-06-20 00:18:26,294 - INFO - test: {'epoch': 46, 'time_epoch': 3.24972, 'loss': 0.14394814, 'lr': 0, 'params': 514193, 'time_iter': 0.02519, 'accuracy': 0.9662, 'precision': 0.43836, 'recall': 0.24615, 'f1': 0.31527, 'auc': 0.76066}
2025-06-20 00:18:26,296 - INFO - > Epoch 46: took 68.8s (avg 71.8s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:19:28,737 - INFO - train: {'epoch': 47, 'time_epoch': 62.36045, 'eta': 3364.24846, 'eta_hours': 0.93451, 'loss': 0.08176242, 'lr': 5.904e-05, 'params': 514193, 'time_iter': 0.0606, 'accuracy': 0.97471, 'precision': 0.78986, 'recall': 0.44237, 'f1': 0.56712, 'auc': 0.94305}
2025-06-20 00:19:32,098 - INFO - val: {'epoch': 47, 'time_epoch': 3.33583, 'loss': 0.09786922, 'lr': 0, 'params': 514193, 'time_iter': 0.02586, 'accuracy': 0.97739, 'precision': 0.40625, 'recall': 0.32099, 'f1': 0.35862, 'auc': 0.77228}
2025-06-20 00:19:35,489 - INFO - test: {'epoch': 47, 'time_epoch': 3.3708, 'loss': 0.15072543, 'lr': 0, 'params': 514193, 'time_iter': 0.02613, 'accuracy': 0.96548, 'precision': 0.41429, 'recall': 0.22308, 'f1': 0.29, 'auc': 0.76352}
2025-06-20 00:19:35,491 - INFO - > Epoch 47: took 69.2s (avg 71.7s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:20:38,251 - INFO - train: {'epoch': 48, 'time_epoch': 62.67994, 'eta': 3297.4519, 'eta_hours': 0.91596, 'loss': 0.08192319, 'lr': 5.741e-05, 'params': 514193, 'time_iter': 0.06091, 'accuracy': 0.97483, 'precision': 0.78612, 'recall': 0.45049, 'f1': 0.57276, 'auc': 0.94277}
2025-06-20 00:20:41,551 - INFO - val: {'epoch': 48, 'time_epoch': 3.27564, 'loss': 0.09729031, 'lr': 0, 'params': 514193, 'time_iter': 0.02539, 'accuracy': 0.9752, 'precision': 0.37931, 'recall': 0.40741, 'f1': 0.39286, 'auc': 0.7915}
2025-06-20 00:20:44,908 - INFO - test: {'epoch': 48, 'time_epoch': 3.33725, 'loss': 0.14347242, 'lr': 0, 'params': 514193, 'time_iter': 0.02587, 'accuracy': 0.96329, 'precision': 0.38202, 'recall': 0.26154, 'f1': 0.3105, 'auc': 0.78777}
2025-06-20 00:20:44,910 - INFO - > Epoch 48: took 69.4s (avg 71.7s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:21:47,762 - INFO - train: {'epoch': 49, 'time_epoch': 62.76151, 'eta': 3230.90157, 'eta_hours': 0.89747, 'loss': 0.0813178, 'lr': 5.577e-05, 'params': 514193, 'time_iter': 0.06099, 'accuracy': 0.97462, 'precision': 0.79148, 'recall': 0.4375, 'f1': 0.56351, 'auc': 0.94368}
2025-06-20 00:21:51,162 - INFO - val: {'epoch': 49, 'time_epoch': 3.37443, 'loss': 0.09736039, 'lr': 0, 'params': 514193, 'time_iter': 0.02616, 'accuracy': 0.97544, 'precision': 0.38636, 'recall': 0.41975, 'f1': 0.40237, 'auc': 0.78931}
2025-06-20 00:21:54,414 - INFO - test: {'epoch': 49, 'time_epoch': 3.2289, 'loss': 0.15110818, 'lr': 0, 'params': 514193, 'time_iter': 0.02503, 'accuracy': 0.96329, 'precision': 0.37647, 'recall': 0.24615, 'f1': 0.29767, 'auc': 0.7785}
2025-06-20 00:21:54,416 - INFO - > Epoch 49: took 69.5s (avg 71.6s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:22:55,233 - INFO - train: {'epoch': 50, 'time_epoch': 60.73742, 'eta': 3162.5551, 'eta_hours': 0.87849, 'loss': 0.08225128, 'lr': 5.413e-05, 'params': 514193, 'time_iter': 0.05903, 'accuracy': 0.97462, 'precision': 0.78561, 'recall': 0.44318, 'f1': 0.56668, 'auc': 0.94336}
2025-06-20 00:22:58,755 - INFO - val: {'epoch': 50, 'time_epoch': 3.49476, 'loss': 0.09825299, 'lr': 0, 'params': 514193, 'time_iter': 0.02709, 'accuracy': 0.97909, 'precision': 0.46575, 'recall': 0.41975, 'f1': 0.44156, 'auc': 0.78044}
2025-06-20 00:23:02,180 - INFO - test: {'epoch': 50, 'time_epoch': 3.40352, 'loss': 0.14905708, 'lr': 0, 'params': 514193, 'time_iter': 0.02638, 'accuracy': 0.96548, 'precision': 0.40909, 'recall': 0.20769, 'f1': 0.27551, 'auc': 0.78826}
2025-06-20 00:23:02,184 - INFO - > Epoch 50: took 67.8s (avg 71.5s) | Best so far: epoch 30	train_loss: 0.0986 train_auc: 0.8982	val_loss: 0.0830 val_auc: 0.7982	test_loss: 0.1234 test_auc: 0.7778
2025-06-20 00:24:04,509 - INFO - train: {'epoch': 51, 'time_epoch': 62.24391, 'eta': 3095.8919, 'eta_hours': 0.85997, 'loss': 0.08074357, 'lr': 5.248e-05, 'params': 514193, 'time_iter': 0.06049, 'accuracy': 0.97535, 'precision': 0.79034, 'recall': 0.4651, 'f1': 0.58559, 'auc': 0.94282}
2025-06-20 00:24:08,039 - INFO - val: {'epoch': 51, 'time_epoch': 3.50351, 'loss': 0.0912183, 'lr': 0, 'params': 514193, 'time_iter': 0.02716, 'accuracy': 0.97885, 'precision': 0.45161, 'recall': 0.34568, 'f1': 0.39161, 'auc': 0.8018}
2025-06-20 00:24:11,593 - INFO - test: {'epoch': 51, 'time_epoch': 3.53446, 'loss': 0.14519568, 'lr': 0, 'params': 514193, 'time_iter': 0.0274, 'accuracy': 0.96718, 'precision': 0.46753, 'recall': 0.27692, 'f1': 0.34783, 'auc': 0.78531}
2025-06-20 00:24:11,596 - INFO - > Epoch 51: took 69.4s (avg 71.5s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:25:13,931 - INFO - train: {'epoch': 52, 'time_epoch': 62.25672, 'eta': 3029.40683, 'eta_hours': 0.8415, 'loss': 0.0799855, 'lr': 5.083e-05, 'params': 514193, 'time_iter': 0.0605, 'accuracy': 0.97532, 'precision': 0.7861, 'recall': 0.46834, 'f1': 0.58698, 'auc': 0.94499}
2025-06-20 00:25:17,318 - INFO - val: {'epoch': 52, 'time_epoch': 3.36173, 'loss': 0.10298255, 'lr': 0, 'params': 514193, 'time_iter': 0.02606, 'accuracy': 0.97739, 'precision': 0.40323, 'recall': 0.30864, 'f1': 0.34965, 'auc': 0.76394}
2025-06-20 00:25:20,670 - INFO - test: {'epoch': 52, 'time_epoch': 3.31531, 'loss': 0.15194152, 'lr': 0, 'params': 514193, 'time_iter': 0.0257, 'accuracy': 0.96572, 'precision': 0.42667, 'recall': 0.24615, 'f1': 0.3122, 'auc': 0.7832}
2025-06-20 00:25:20,672 - INFO - > Epoch 52: took 69.1s (avg 71.4s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:26:23,331 - INFO - train: {'epoch': 53, 'time_epoch': 62.57606, 'eta': 2963.35039, 'eta_hours': 0.82315, 'loss': 0.07824216, 'lr': 4.917e-05, 'params': 514193, 'time_iter': 0.06081, 'accuracy': 0.97511, 'precision': 0.78095, 'recall': 0.46591, 'f1': 0.58363, 'auc': 0.94953}
2025-06-20 00:26:26,844 - INFO - val: {'epoch': 53, 'time_epoch': 3.48666, 'loss': 0.09272434, 'lr': 0, 'params': 514193, 'time_iter': 0.02703, 'accuracy': 0.97836, 'precision': 0.4375, 'recall': 0.34568, 'f1': 0.38621, 'auc': 0.79582}
2025-06-20 00:26:30,224 - INFO - test: {'epoch': 53, 'time_epoch': 3.3598, 'loss': 0.1448958, 'lr': 0, 'params': 514193, 'time_iter': 0.02604, 'accuracy': 0.96718, 'precision': 0.46667, 'recall': 0.26923, 'f1': 0.34146, 'auc': 0.77501}
2025-06-20 00:26:30,226 - INFO - > Epoch 53: took 69.6s (avg 71.4s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:27:32,656 - INFO - train: {'epoch': 54, 'time_epoch': 62.35105, 'eta': 2897.23641, 'eta_hours': 0.80479, 'loss': 0.07791393, 'lr': 4.752e-05, 'params': 514193, 'time_iter': 0.06059, 'accuracy': 0.97581, 'precision': 0.81054, 'recall': 0.46185, 'f1': 0.58842, 'auc': 0.95192}
2025-06-20 00:27:36,032 - INFO - val: {'epoch': 54, 'time_epoch': 3.34974, 'loss': 0.10530898, 'lr': 0, 'params': 514193, 'time_iter': 0.02597, 'accuracy': 0.9752, 'precision': 0.37931, 'recall': 0.40741, 'f1': 0.39286, 'auc': 0.78829}
2025-06-20 00:27:39,540 - INFO - test: {'epoch': 54, 'time_epoch': 3.48626, 'loss': 0.15235101, 'lr': 0, 'params': 514193, 'time_iter': 0.02703, 'accuracy': 0.96426, 'precision': 0.40449, 'recall': 0.27692, 'f1': 0.32877, 'auc': 0.78294}
2025-06-20 00:27:39,543 - INFO - > Epoch 54: took 69.3s (avg 71.4s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:28:41,178 - INFO - train: {'epoch': 55, 'time_epoch': 61.55884, 'eta': 2830.63437, 'eta_hours': 0.78629, 'loss': 0.07608786, 'lr': 4.587e-05, 'params': 514193, 'time_iter': 0.05982, 'accuracy': 0.97632, 'precision': 0.79076, 'recall': 0.5, 'f1': 0.61263, 'auc': 0.95287}
2025-06-20 00:28:44,448 - INFO - val: {'epoch': 55, 'time_epoch': 3.24575, 'loss': 0.09705704, 'lr': 0, 'params': 514193, 'time_iter': 0.02516, 'accuracy': 0.98055, 'precision': 0.5098, 'recall': 0.32099, 'f1': 0.39394, 'auc': 0.76794}
2025-06-20 00:28:47,717 - INFO - test: {'epoch': 55, 'time_epoch': 3.24996, 'loss': 0.16044099, 'lr': 0, 'params': 514193, 'time_iter': 0.02519, 'accuracy': 0.96864, 'precision': 0.50943, 'recall': 0.20769, 'f1': 0.29508, 'auc': 0.75337}
2025-06-20 00:28:47,720 - INFO - > Epoch 55: took 68.2s (avg 71.3s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:29:49,553 - INFO - train: {'epoch': 56, 'time_epoch': 61.74993, 'eta': 2764.35344, 'eta_hours': 0.76788, 'loss': 0.07429282, 'lr': 4.423e-05, 'params': 514193, 'time_iter': 0.06001, 'accuracy': 0.97593, 'precision': 0.7981, 'recall': 0.47808, 'f1': 0.59797, 'auc': 0.95794}
2025-06-20 00:29:53,091 - INFO - val: {'epoch': 56, 'time_epoch': 3.51253, 'loss': 0.10080026, 'lr': 0, 'params': 514193, 'time_iter': 0.02723, 'accuracy': 0.98006, 'precision': 0.49057, 'recall': 0.32099, 'f1': 0.38806, 'auc': 0.76927}
2025-06-20 00:29:56,476 - INFO - test: {'epoch': 56, 'time_epoch': 3.36624, 'loss': 0.15809619, 'lr': 0, 'params': 514193, 'time_iter': 0.02609, 'accuracy': 0.96864, 'precision': 0.50725, 'recall': 0.26923, 'f1': 0.35176, 'auc': 0.76815}
2025-06-20 00:29:56,479 - INFO - > Epoch 56: took 68.8s (avg 71.3s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:30:59,381 - INFO - train: {'epoch': 57, 'time_epoch': 62.82346, 'eta': 2699.00614, 'eta_hours': 0.74972, 'loss': 0.07539002, 'lr': 4.259e-05, 'params': 514193, 'time_iter': 0.06105, 'accuracy': 0.97657, 'precision': 0.81532, 'recall': 0.48377, 'f1': 0.60723, 'auc': 0.95616}
2025-06-20 00:31:02,653 - INFO - val: {'epoch': 57, 'time_epoch': 3.2485, 'loss': 0.10979408, 'lr': 0, 'params': 514193, 'time_iter': 0.02518, 'accuracy': 0.97374, 'precision': 0.33735, 'recall': 0.34568, 'f1': 0.34146, 'auc': 0.76845}
2025-06-20 00:31:05,957 - INFO - test: {'epoch': 57, 'time_epoch': 3.28496, 'loss': 0.15663871, 'lr': 0, 'params': 514193, 'time_iter': 0.02546, 'accuracy': 0.95988, 'precision': 0.34234, 'recall': 0.29231, 'f1': 0.31535, 'auc': 0.78043}
2025-06-20 00:31:05,960 - INFO - > Epoch 57: took 69.5s (avg 71.2s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:32:08,628 - INFO - train: {'epoch': 58, 'time_epoch': 62.58753, 'eta': 2633.58044, 'eta_hours': 0.73155, 'loss': 0.07526444, 'lr': 4.096e-05, 'params': 514193, 'time_iter': 0.06082, 'accuracy': 0.97599, 'precision': 0.79003, 'recall': 0.48864, 'f1': 0.60381, 'auc': 0.95578}
2025-06-20 00:32:11,996 - INFO - val: {'epoch': 58, 'time_epoch': 3.34254, 'loss': 0.11425373, 'lr': 0, 'params': 514193, 'time_iter': 0.02591, 'accuracy': 0.97326, 'precision': 0.34737, 'recall': 0.40741, 'f1': 0.375, 'auc': 0.76546}
2025-06-20 00:32:15,516 - INFO - test: {'epoch': 58, 'time_epoch': 3.49888, 'loss': 0.16676319, 'lr': 0, 'params': 514193, 'time_iter': 0.02712, 'accuracy': 0.96013, 'precision': 0.30233, 'recall': 0.2, 'f1': 0.24074, 'auc': 0.7716}
2025-06-20 00:32:15,519 - INFO - > Epoch 58: took 69.6s (avg 71.2s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:33:18,059 - INFO - train: {'epoch': 59, 'time_epoch': 62.46093, 'eta': 2568.16494, 'eta_hours': 0.71338, 'loss': 0.0765129, 'lr': 3.934e-05, 'params': 514193, 'time_iter': 0.0607, 'accuracy': 0.97556, 'precision': 0.78307, 'recall': 0.48052, 'f1': 0.59557, 'auc': 0.95334}
2025-06-20 00:33:21,376 - INFO - val: {'epoch': 59, 'time_epoch': 3.29282, 'loss': 0.10242644, 'lr': 0, 'params': 514193, 'time_iter': 0.02553, 'accuracy': 0.97666, 'precision': 0.39726, 'recall': 0.35802, 'f1': 0.37662, 'auc': 0.78381}
2025-06-20 00:33:24,738 - INFO - test: {'epoch': 59, 'time_epoch': 3.33964, 'loss': 0.15325621, 'lr': 0, 'params': 514193, 'time_iter': 0.02589, 'accuracy': 0.96669, 'precision': 0.45205, 'recall': 0.25385, 'f1': 0.32512, 'auc': 0.78602}
2025-06-20 00:33:24,745 - INFO - > Epoch 59: took 69.2s (avg 71.2s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:34:27,745 - INFO - train: {'epoch': 60, 'time_epoch': 62.91975, 'eta': 2503.13966, 'eta_hours': 0.69532, 'loss': 0.07418482, 'lr': 3.773e-05, 'params': 514193, 'time_iter': 0.06115, 'accuracy': 0.97572, 'precision': 0.77233, 'recall': 0.49838, 'f1': 0.60582, 'auc': 0.95776}
2025-06-20 00:34:31,085 - INFO - val: {'epoch': 60, 'time_epoch': 3.31666, 'loss': 0.10006673, 'lr': 0, 'params': 514193, 'time_iter': 0.02571, 'accuracy': 0.97933, 'precision': 0.46296, 'recall': 0.30864, 'f1': 0.37037, 'auc': 0.75919}
2025-06-20 00:34:34,419 - INFO - test: {'epoch': 60, 'time_epoch': 3.31456, 'loss': 0.15710635, 'lr': 0, 'params': 514193, 'time_iter': 0.02569, 'accuracy': 0.9645, 'precision': 0.37097, 'recall': 0.17692, 'f1': 0.23958, 'auc': 0.77082}
2025-06-20 00:34:34,422 - INFO - > Epoch 60: took 69.7s (avg 71.2s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:35:35,686 - INFO - train: {'epoch': 61, 'time_epoch': 61.18408, 'eta': 2437.1185, 'eta_hours': 0.67698, 'loss': 0.07254953, 'lr': 3.613e-05, 'params': 514193, 'time_iter': 0.05946, 'accuracy': 0.97675, 'precision': 0.80207, 'recall': 0.50325, 'f1': 0.61845, 'auc': 0.96095}
2025-06-20 00:35:39,187 - INFO - val: {'epoch': 61, 'time_epoch': 3.47561, 'loss': 0.10519566, 'lr': 0, 'params': 514193, 'time_iter': 0.02694, 'accuracy': 0.97812, 'precision': 0.43077, 'recall': 0.34568, 'f1': 0.38356, 'auc': 0.76561}
2025-06-20 00:35:42,539 - INFO - test: {'epoch': 61, 'time_epoch': 3.33193, 'loss': 0.16767134, 'lr': 0, 'params': 514193, 'time_iter': 0.02583, 'accuracy': 0.96645, 'precision': 0.43939, 'recall': 0.22308, 'f1': 0.29592, 'auc': 0.7669}
2025-06-20 00:35:42,542 - INFO - > Epoch 61: took 68.1s (avg 71.1s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:36:44,749 - INFO - train: {'epoch': 62, 'time_epoch': 62.12454, 'eta': 2371.80324, 'eta_hours': 0.65883, 'loss': 0.07296663, 'lr': 3.455e-05, 'params': 514193, 'time_iter': 0.06037, 'accuracy': 0.97733, 'precision': 0.80759, 'recall': 0.51786, 'f1': 0.63106, 'auc': 0.95778}
2025-06-20 00:36:48,250 - INFO - val: {'epoch': 62, 'time_epoch': 3.47627, 'loss': 0.11319696, 'lr': 0, 'params': 514193, 'time_iter': 0.02695, 'accuracy': 0.97788, 'precision': 0.42857, 'recall': 0.37037, 'f1': 0.39735, 'auc': 0.76252}
2025-06-20 00:36:51,502 - INFO - test: {'epoch': 62, 'time_epoch': 3.23368, 'loss': 0.17604232, 'lr': 0, 'params': 514193, 'time_iter': 0.02507, 'accuracy': 0.96499, 'precision': 0.3871, 'recall': 0.18462, 'f1': 0.25, 'auc': 0.7569}
2025-06-20 00:36:51,504 - INFO - > Epoch 62: took 69.0s (avg 71.1s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:37:54,277 - INFO - train: {'epoch': 63, 'time_epoch': 62.69013, 'eta': 2306.90582, 'eta_hours': 0.64081, 'loss': 0.07379363, 'lr': 3.299e-05, 'params': 514193, 'time_iter': 0.06092, 'accuracy': 0.97651, 'precision': 0.78941, 'recall': 0.50812, 'f1': 0.61827, 'auc': 0.95862}
2025-06-20 00:37:57,674 - INFO - val: {'epoch': 63, 'time_epoch': 3.37277, 'loss': 0.10705015, 'lr': 0, 'params': 514193, 'time_iter': 0.02615, 'accuracy': 0.97909, 'precision': 0.45455, 'recall': 0.30864, 'f1': 0.36765, 'auc': 0.74649}
2025-06-20 00:38:01,107 - INFO - test: {'epoch': 63, 'time_epoch': 3.40917, 'loss': 0.16541255, 'lr': 0, 'params': 514193, 'time_iter': 0.02643, 'accuracy': 0.96718, 'precision': 0.46479, 'recall': 0.25385, 'f1': 0.32836, 'auc': 0.76113}
2025-06-20 00:38:01,110 - INFO - > Epoch 63: took 69.6s (avg 71.1s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:39:04,055 - INFO - train: {'epoch': 64, 'time_epoch': 62.86134, 'eta': 2242.16852, 'eta_hours': 0.62282, 'loss': 0.07102854, 'lr': 3.144e-05, 'params': 514193, 'time_iter': 0.06109, 'accuracy': 0.97723, 'precision': 0.81001, 'recall': 0.51218, 'f1': 0.62755, 'auc': 0.96336}
2025-06-20 00:39:07,381 - INFO - val: {'epoch': 64, 'time_epoch': 3.30078, 'loss': 0.10437095, 'lr': 0, 'params': 514193, 'time_iter': 0.02559, 'accuracy': 0.97909, 'precision': 0.45283, 'recall': 0.2963, 'f1': 0.35821, 'auc': 0.76206}
2025-06-20 00:39:10,674 - INFO - test: {'epoch': 64, 'time_epoch': 3.27408, 'loss': 0.16020308, 'lr': 0, 'params': 514193, 'time_iter': 0.02538, 'accuracy': 0.96791, 'precision': 0.48333, 'recall': 0.22308, 'f1': 0.30526, 'auc': 0.77555}
2025-06-20 00:39:10,676 - INFO - > Epoch 64: took 69.6s (avg 71.0s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:40:13,358 - INFO - train: {'epoch': 65, 'time_epoch': 62.59929, 'eta': 2177.35307, 'eta_hours': 0.60482, 'loss': 0.07233584, 'lr': 2.992e-05, 'params': 514193, 'time_iter': 0.06084, 'accuracy': 0.97666, 'precision': 0.80446, 'recall': 0.49756, 'f1': 0.61484, 'auc': 0.96126}
2025-06-20 00:40:16,871 - INFO - val: {'epoch': 65, 'time_epoch': 3.48625, 'loss': 0.09805817, 'lr': 0, 'params': 514193, 'time_iter': 0.02703, 'accuracy': 0.9786, 'precision': 0.44068, 'recall': 0.32099, 'f1': 0.37143, 'auc': 0.76954}
2025-06-20 00:40:20,382 - INFO - test: {'epoch': 65, 'time_epoch': 3.49115, 'loss': 0.15384635, 'lr': 0, 'params': 514193, 'time_iter': 0.02706, 'accuracy': 0.96718, 'precision': 0.46032, 'recall': 0.22308, 'f1': 0.30052, 'auc': 0.77105}
2025-06-20 00:40:20,401 - INFO - > Epoch 65: took 69.7s (avg 71.0s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:41:21,483 - INFO - train: {'epoch': 66, 'time_epoch': 61.00653, 'eta': 2111.81928, 'eta_hours': 0.58662, 'loss': 0.07135378, 'lr': 2.841e-05, 'params': 514193, 'time_iter': 0.05929, 'accuracy': 0.9766, 'precision': 0.79093, 'recall': 0.50974, 'f1': 0.61994, 'auc': 0.96194}
2025-06-20 00:41:24,775 - INFO - val: {'epoch': 66, 'time_epoch': 3.26804, 'loss': 0.10179076, 'lr': 0, 'params': 514193, 'time_iter': 0.02533, 'accuracy': 0.97933, 'precision': 0.46667, 'recall': 0.34568, 'f1': 0.39716, 'auc': 0.77344}
2025-06-20 00:41:28,057 - INFO - test: {'epoch': 66, 'time_epoch': 3.26242, 'loss': 0.16400098, 'lr': 0, 'params': 514193, 'time_iter': 0.02529, 'accuracy': 0.96718, 'precision': 0.45763, 'recall': 0.20769, 'f1': 0.28571, 'auc': 0.769}
2025-06-20 00:41:28,059 - INFO - > Epoch 66: took 67.7s (avg 71.0s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:42:30,310 - INFO - train: {'epoch': 67, 'time_epoch': 62.16979, 'eta': 2046.96606, 'eta_hours': 0.5686, 'loss': 0.0693905, 'lr': 2.693e-05, 'params': 514193, 'time_iter': 0.06042, 'accuracy': 0.97839, 'precision': 0.82522, 'recall': 0.53653, 'f1': 0.65027, 'auc': 0.96521}
2025-06-20 00:42:33,614 - INFO - val: {'epoch': 67, 'time_epoch': 3.27837, 'loss': 0.11713386, 'lr': 0, 'params': 514193, 'time_iter': 0.02541, 'accuracy': 0.97471, 'precision': 0.36471, 'recall': 0.38272, 'f1': 0.37349, 'auc': 0.75784}
2025-06-20 00:42:36,943 - INFO - test: {'epoch': 67, 'time_epoch': 3.30857, 'loss': 0.16959414, 'lr': 0, 'params': 514193, 'time_iter': 0.02565, 'accuracy': 0.96183, 'precision': 0.33333, 'recall': 0.20769, 'f1': 0.25592, 'auc': 0.77676}
2025-06-20 00:42:36,945 - INFO - > Epoch 67: took 68.9s (avg 70.9s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:43:39,182 - INFO - train: {'epoch': 68, 'time_epoch': 62.15778, 'eta': 1982.18522, 'eta_hours': 0.55061, 'loss': 0.07005974, 'lr': 2.548e-05, 'params': 514193, 'time_iter': 0.06041, 'accuracy': 0.9773, 'precision': 0.80657, 'recall': 0.51786, 'f1': 0.63075, 'auc': 0.96319}
2025-06-20 00:43:42,533 - INFO - val: {'epoch': 68, 'time_epoch': 3.32691, 'loss': 0.11260856, 'lr': 0, 'params': 514193, 'time_iter': 0.02579, 'accuracy': 0.97544, 'precision': 0.36486, 'recall': 0.33333, 'f1': 0.34839, 'auc': 0.75106}
2025-06-20 00:43:45,864 - INFO - test: {'epoch': 68, 'time_epoch': 3.31096, 'loss': 0.16158113, 'lr': 0, 'params': 514193, 'time_iter': 0.02567, 'accuracy': 0.96766, 'precision': 0.47887, 'recall': 0.26154, 'f1': 0.33831, 'auc': 0.77917}
2025-06-20 00:43:45,866 - INFO - > Epoch 68: took 68.9s (avg 70.9s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:44:48,343 - INFO - train: {'epoch': 69, 'time_epoch': 62.39847, 'eta': 1917.58248, 'eta_hours': 0.53266, 'loss': 0.06996841, 'lr': 2.405e-05, 'params': 514193, 'time_iter': 0.06064, 'accuracy': 0.97778, 'precision': 0.82406, 'recall': 0.51705, 'f1': 0.63541, 'auc': 0.96434}
2025-06-20 00:44:51,829 - INFO - val: {'epoch': 69, 'time_epoch': 3.46116, 'loss': 0.11471603, 'lr': 0, 'params': 514193, 'time_iter': 0.02683, 'accuracy': 0.97593, 'precision': 0.38158, 'recall': 0.35802, 'f1': 0.36943, 'auc': 0.75323}
2025-06-20 00:44:55,334 - INFO - test: {'epoch': 69, 'time_epoch': 3.48309, 'loss': 0.16527333, 'lr': 0, 'params': 514193, 'time_iter': 0.027, 'accuracy': 0.96499, 'precision': 0.40789, 'recall': 0.23846, 'f1': 0.30097, 'auc': 0.77541}
2025-06-20 00:44:55,336 - INFO - > Epoch 69: took 69.5s (avg 70.9s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:45:57,897 - INFO - train: {'epoch': 70, 'time_epoch': 62.47865, 'eta': 1853.07458, 'eta_hours': 0.51474, 'loss': 0.0700788, 'lr': 2.265e-05, 'params': 514193, 'time_iter': 0.06072, 'accuracy': 0.97763, 'precision': 0.81633, 'recall': 0.51948, 'f1': 0.63492, 'auc': 0.96431}
2025-06-20 00:46:01,236 - INFO - val: {'epoch': 70, 'time_epoch': 3.30682, 'loss': 0.11312176, 'lr': 0, 'params': 514193, 'time_iter': 0.02563, 'accuracy': 0.97715, 'precision': 0.41558, 'recall': 0.39506, 'f1': 0.40506, 'auc': 0.75791}
2025-06-20 00:46:04,577 - INFO - test: {'epoch': 70, 'time_epoch': 3.32143, 'loss': 0.16457825, 'lr': 0, 'params': 514193, 'time_iter': 0.02575, 'accuracy': 0.96426, 'precision': 0.39506, 'recall': 0.24615, 'f1': 0.30332, 'auc': 0.78164}
2025-06-20 00:46:04,579 - INFO - > Epoch 70: took 69.2s (avg 70.9s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:47:07,663 - INFO - train: {'epoch': 71, 'time_epoch': 63.00368, 'eta': 1788.82723, 'eta_hours': 0.4969, 'loss': 0.06848411, 'lr': 2.128e-05, 'params': 514193, 'time_iter': 0.06123, 'accuracy': 0.97818, 'precision': 0.82449, 'recall': 0.53003, 'f1': 0.64526, 'auc': 0.96541}
2025-06-20 00:47:10,944 - INFO - val: {'epoch': 71, 'time_epoch': 3.25768, 'loss': 0.13164184, 'lr': 0, 'params': 514193, 'time_iter': 0.02525, 'accuracy': 0.97082, 'precision': 0.31068, 'recall': 0.39506, 'f1': 0.34783, 'auc': 0.75779}
2025-06-20 00:47:14,229 - INFO - test: {'epoch': 71, 'time_epoch': 3.2657, 'loss': 0.18249539, 'lr': 0, 'params': 514193, 'time_iter': 0.02532, 'accuracy': 0.95915, 'precision': 0.33036, 'recall': 0.28462, 'f1': 0.30579, 'auc': 0.78214}
2025-06-20 00:47:14,232 - INFO - > Epoch 71: took 69.7s (avg 70.8s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:48:15,037 - INFO - train: {'epoch': 72, 'time_epoch': 60.72966, 'eta': 1723.77288, 'eta_hours': 0.47883, 'loss': 0.06837916, 'lr': 1.995e-05, 'params': 514193, 'time_iter': 0.05902, 'accuracy': 0.97793, 'precision': 0.81546, 'recall': 0.53084, 'f1': 0.64307, 'auc': 0.96787}
2025-06-20 00:48:18,533 - INFO - val: {'epoch': 72, 'time_epoch': 3.46992, 'loss': 0.11695896, 'lr': 0, 'params': 514193, 'time_iter': 0.0269, 'accuracy': 0.97642, 'precision': 0.39189, 'recall': 0.35802, 'f1': 0.37419, 'auc': 0.75324}
2025-06-20 00:48:21,798 - INFO - test: {'epoch': 72, 'time_epoch': 3.24571, 'loss': 0.16928413, 'lr': 0, 'params': 514193, 'time_iter': 0.02516, 'accuracy': 0.96572, 'precision': 0.42466, 'recall': 0.23846, 'f1': 0.30542, 'auc': 0.77918}
2025-06-20 00:48:21,801 - INFO - > Epoch 72: took 67.6s (avg 70.8s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:49:23,692 - INFO - train: {'epoch': 73, 'time_epoch': 61.81106, 'eta': 1659.21536, 'eta_hours': 0.46089, 'loss': 0.06877095, 'lr': 1.864e-05, 'params': 514193, 'time_iter': 0.06007, 'accuracy': 0.97742, 'precision': 0.79927, 'recall': 0.53003, 'f1': 0.63738, 'auc': 0.96597}
2025-06-20 00:49:27,194 - INFO - val: {'epoch': 73, 'time_epoch': 3.47665, 'loss': 0.11399735, 'lr': 0, 'params': 514193, 'time_iter': 0.02695, 'accuracy': 0.97569, 'precision': 0.37662, 'recall': 0.35802, 'f1': 0.36709, 'auc': 0.76464}
2025-06-20 00:49:30,551 - INFO - test: {'epoch': 73, 'time_epoch': 3.33677, 'loss': 0.16702227, 'lr': 0, 'params': 514193, 'time_iter': 0.02587, 'accuracy': 0.96523, 'precision': 0.41975, 'recall': 0.26154, 'f1': 0.32227, 'auc': 0.77824}
2025-06-20 00:49:30,553 - INFO - > Epoch 73: took 68.8s (avg 70.8s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:50:32,838 - INFO - train: {'epoch': 74, 'time_epoch': 62.20536, 'eta': 1594.86251, 'eta_hours': 0.44302, 'loss': 0.06633748, 'lr': 1.737e-05, 'params': 514193, 'time_iter': 0.06045, 'accuracy': 0.97793, 'precision': 0.81081, 'recall': 0.53571, 'f1': 0.64516, 'auc': 0.96981}
2025-06-20 00:50:36,181 - INFO - val: {'epoch': 74, 'time_epoch': 3.3187, 'loss': 0.10992034, 'lr': 0, 'params': 514193, 'time_iter': 0.02573, 'accuracy': 0.97812, 'precision': 0.42623, 'recall': 0.32099, 'f1': 0.3662, 'auc': 0.75754}
2025-06-20 00:50:39,529 - INFO - test: {'epoch': 74, 'time_epoch': 3.32787, 'loss': 0.16336181, 'lr': 0, 'params': 514193, 'time_iter': 0.0258, 'accuracy': 0.96596, 'precision': 0.43056, 'recall': 0.23846, 'f1': 0.30693, 'auc': 0.7792}
2025-06-20 00:50:39,531 - INFO - > Epoch 74: took 69.0s (avg 70.7s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:51:42,328 - INFO - train: {'epoch': 75, 'time_epoch': 62.71404, 'eta': 1530.72681, 'eta_hours': 0.4252, 'loss': 0.066575, 'lr': 1.614e-05, 'params': 514193, 'time_iter': 0.06095, 'accuracy': 0.97812, 'precision': 0.81762, 'recall': 0.5349, 'f1': 0.64671, 'auc': 0.96952}
2025-06-20 00:51:45,805 - INFO - val: {'epoch': 75, 'time_epoch': 3.45153, 'loss': 0.12043889, 'lr': 0, 'params': 514193, 'time_iter': 0.02676, 'accuracy': 0.97423, 'precision': 0.35294, 'recall': 0.37037, 'f1': 0.36145, 'auc': 0.76151}
2025-06-20 00:51:49,096 - INFO - test: {'epoch': 75, 'time_epoch': 3.27203, 'loss': 0.17399183, 'lr': 0, 'params': 514193, 'time_iter': 0.02536, 'accuracy': 0.9611, 'precision': 0.33333, 'recall': 0.23077, 'f1': 0.27273, 'auc': 0.78071}
2025-06-20 00:51:49,098 - INFO - > Epoch 75: took 69.6s (avg 70.7s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:52:52,294 - INFO - train: {'epoch': 76, 'time_epoch': 63.11, 'eta': 1466.74632, 'eta_hours': 0.40743, 'loss': 0.06745617, 'lr': 1.494e-05, 'params': 514193, 'time_iter': 0.06133, 'accuracy': 0.97784, 'precision': 0.80338, 'recall': 0.54058, 'f1': 0.64629, 'auc': 0.9697}
2025-06-20 00:52:56,107 - INFO - val: {'epoch': 76, 'time_epoch': 3.78386, 'loss': 0.12050999, 'lr': 0, 'params': 514193, 'time_iter': 0.02933, 'accuracy': 0.97569, 'precision': 0.38554, 'recall': 0.39506, 'f1': 0.39024, 'auc': 0.76265}
2025-06-20 00:53:00,033 - INFO - test: {'epoch': 76, 'time_epoch': 3.90367, 'loss': 0.17141385, 'lr': 0, 'params': 514193, 'time_iter': 0.03026, 'accuracy': 0.96402, 'precision': 0.4, 'recall': 0.27692, 'f1': 0.32727, 'auc': 0.78008}
2025-06-20 00:53:00,036 - INFO - > Epoch 76: took 70.9s (avg 70.7s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:54:04,251 - INFO - train: {'epoch': 77, 'time_epoch': 64.12373, 'eta': 1403.07406, 'eta_hours': 0.38974, 'loss': 0.0682349, 'lr': 1.378e-05, 'params': 514193, 'time_iter': 0.06232, 'accuracy': 0.97875, 'precision': 0.82382, 'recall': 0.55032, 'f1': 0.65985, 'auc': 0.96499}
2025-06-20 00:54:08,240 - INFO - val: {'epoch': 77, 'time_epoch': 3.95821, 'loss': 0.1164945, 'lr': 0, 'params': 514193, 'time_iter': 0.03068, 'accuracy': 0.97569, 'precision': 0.37975, 'recall': 0.37037, 'f1': 0.375, 'auc': 0.77055}
2025-06-20 00:54:11,908 - INFO - test: {'epoch': 77, 'time_epoch': 3.64556, 'loss': 0.17386992, 'lr': 0, 'params': 514193, 'time_iter': 0.02826, 'accuracy': 0.96377, 'precision': 0.3908, 'recall': 0.26154, 'f1': 0.31336, 'auc': 0.78335}
2025-06-20 00:54:11,910 - INFO - > Epoch 77: took 71.9s (avg 70.7s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:55:22,007 - INFO - train: {'epoch': 78, 'time_epoch': 70.00798, 'eta': 1340.95454, 'eta_hours': 0.37249, 'loss': 0.06475627, 'lr': 1.266e-05, 'params': 514193, 'time_iter': 0.06803, 'accuracy': 0.97936, 'precision': 0.82956, 'recall': 0.56494, 'f1': 0.67214, 'auc': 0.97104}
2025-06-20 00:55:25,373 - INFO - val: {'epoch': 78, 'time_epoch': 3.33983, 'loss': 0.12088975, 'lr': 0, 'params': 514193, 'time_iter': 0.02589, 'accuracy': 0.97544, 'precision': 0.37179, 'recall': 0.35802, 'f1': 0.36478, 'auc': 0.75726}
2025-06-20 00:55:28,807 - INFO - test: {'epoch': 78, 'time_epoch': 3.41152, 'loss': 0.17479128, 'lr': 0, 'params': 514193, 'time_iter': 0.02645, 'accuracy': 0.96329, 'precision': 0.37931, 'recall': 0.25385, 'f1': 0.30415, 'auc': 0.77639}
2025-06-20 00:55:28,809 - INFO - > Epoch 78: took 76.9s (avg 70.8s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:56:40,212 - INFO - train: {'epoch': 79, 'time_epoch': 71.30445, 'eta': 1278.96193, 'eta_hours': 0.35527, 'loss': 0.06440483, 'lr': 1.158e-05, 'params': 514193, 'time_iter': 0.06929, 'accuracy': 0.97793, 'precision': 0.80048, 'recall': 0.54708, 'f1': 0.64995, 'auc': 0.97322}
2025-06-20 00:56:44,040 - INFO - val: {'epoch': 79, 'time_epoch': 3.79855, 'loss': 0.11063522, 'lr': 0, 'params': 514193, 'time_iter': 0.02945, 'accuracy': 0.9769, 'precision': 0.40789, 'recall': 0.38272, 'f1': 0.3949, 'auc': 0.76925}
2025-06-20 00:56:47,355 - INFO - test: {'epoch': 79, 'time_epoch': 3.29505, 'loss': 0.1683682, 'lr': 0, 'params': 514193, 'time_iter': 0.02554, 'accuracy': 0.96426, 'precision': 0.39241, 'recall': 0.23846, 'f1': 0.29665, 'auc': 0.77755}
2025-06-20 00:56:47,357 - INFO - > Epoch 79: took 78.5s (avg 70.9s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:57:53,306 - INFO - train: {'epoch': 80, 'time_epoch': 65.86229, 'eta': 1215.46285, 'eta_hours': 0.33763, 'loss': 0.06382095, 'lr': 1.054e-05, 'params': 514193, 'time_iter': 0.06401, 'accuracy': 0.97848, 'precision': 0.81116, 'recall': 0.55438, 'f1': 0.65863, 'auc': 0.97322}
2025-06-20 00:57:56,792 - INFO - val: {'epoch': 80, 'time_epoch': 3.45867, 'loss': 0.12476001, 'lr': 0, 'params': 514193, 'time_iter': 0.02681, 'accuracy': 0.9735, 'precision': 0.35106, 'recall': 0.40741, 'f1': 0.37714, 'auc': 0.77116}
2025-06-20 00:58:00,257 - INFO - test: {'epoch': 80, 'time_epoch': 3.44359, 'loss': 0.17616864, 'lr': 0, 'params': 514193, 'time_iter': 0.02669, 'accuracy': 0.9628, 'precision': 0.39048, 'recall': 0.31538, 'f1': 0.34894, 'auc': 0.78436}
2025-06-20 00:58:00,260 - INFO - > Epoch 80: took 72.9s (avg 70.9s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 00:59:01,855 - INFO - train: {'epoch': 81, 'time_epoch': 61.50766, 'eta': 1150.95022, 'eta_hours': 0.31971, 'loss': 0.06422075, 'lr': 9.55e-06, 'params': 514193, 'time_iter': 0.05977, 'accuracy': 0.97939, 'precision': 0.82588, 'recall': 0.56981, 'f1': 0.67435, 'auc': 0.97133}
2025-06-20 00:59:05,177 - INFO - val: {'epoch': 81, 'time_epoch': 3.29654, 'loss': 0.11664152, 'lr': 0, 'params': 514193, 'time_iter': 0.02555, 'accuracy': 0.97739, 'precision': 0.41429, 'recall': 0.35802, 'f1': 0.38411, 'auc': 0.76763}
2025-06-20 00:59:08,541 - INFO - test: {'epoch': 81, 'time_epoch': 3.34473, 'loss': 0.17588978, 'lr': 0, 'params': 514193, 'time_iter': 0.02593, 'accuracy': 0.96499, 'precision': 0.4, 'recall': 0.21538, 'f1': 0.28, 'auc': 0.78287}
2025-06-20 00:59:08,544 - INFO - > Epoch 81: took 68.3s (avg 70.9s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:00:08,521 - INFO - train: {'epoch': 82, 'time_epoch': 59.90057, 'eta': 1086.18085, 'eta_hours': 0.30172, 'loss': 0.06203885, 'lr': 8.6e-06, 'params': 514193, 'time_iter': 0.05821, 'accuracy': 0.97951, 'precision': 0.81849, 'recall': 0.58198, 'f1': 0.68027, 'auc': 0.97566}
2025-06-20 01:00:11,846 - INFO - val: {'epoch': 82, 'time_epoch': 3.29984, 'loss': 0.11619122, 'lr': 0, 'params': 514193, 'time_iter': 0.02558, 'accuracy': 0.97617, 'precision': 0.39759, 'recall': 0.40741, 'f1': 0.40244, 'auc': 0.77729}
2025-06-20 01:00:15,126 - INFO - test: {'epoch': 82, 'time_epoch': 3.26076, 'loss': 0.17580668, 'lr': 0, 'params': 514193, 'time_iter': 0.02528, 'accuracy': 0.96353, 'precision': 0.38372, 'recall': 0.25385, 'f1': 0.30556, 'auc': 0.77965}
2025-06-20 01:00:15,128 - INFO - > Epoch 82: took 66.6s (avg 70.9s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:01:16,403 - INFO - train: {'epoch': 83, 'time_epoch': 61.19574, 'eta': 1021.77409, 'eta_hours': 0.28383, 'loss': 0.06441068, 'lr': 7.7e-06, 'params': 514193, 'time_iter': 0.05947, 'accuracy': 0.97906, 'precision': 0.81607, 'recall': 0.56899, 'f1': 0.67049, 'auc': 0.97227}
2025-06-20 01:01:19,701 - INFO - val: {'epoch': 83, 'time_epoch': 3.27267, 'loss': 0.11607658, 'lr': 0, 'params': 514193, 'time_iter': 0.02537, 'accuracy': 0.97544, 'precision': 0.38372, 'recall': 0.40741, 'f1': 0.39521, 'auc': 0.77578}
2025-06-20 01:01:23,000 - INFO - test: {'epoch': 83, 'time_epoch': 3.27823, 'loss': 0.17098642, 'lr': 0, 'params': 514193, 'time_iter': 0.02541, 'accuracy': 0.96231, 'precision': 0.37374, 'recall': 0.28462, 'f1': 0.32314, 'auc': 0.78595}
2025-06-20 01:01:23,003 - INFO - > Epoch 83: took 67.9s (avg 70.8s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:02:24,455 - INFO - train: {'epoch': 84, 'time_epoch': 61.37272, 'eta': 957.47413, 'eta_hours': 0.26597, 'loss': 0.06414945, 'lr': 6.84e-06, 'params': 514193, 'time_iter': 0.05964, 'accuracy': 0.97815, 'precision': 0.80355, 'recall': 0.55114, 'f1': 0.65383, 'auc': 0.9731}
2025-06-20 01:02:27,883 - INFO - val: {'epoch': 84, 'time_epoch': 3.40178, 'loss': 0.11442366, 'lr': 0, 'params': 514193, 'time_iter': 0.02637, 'accuracy': 0.97788, 'precision': 0.42647, 'recall': 0.35802, 'f1': 0.38926, 'auc': 0.77001}
2025-06-20 01:02:31,319 - INFO - test: {'epoch': 84, 'time_epoch': 3.41432, 'loss': 0.17573698, 'lr': 0, 'params': 514193, 'time_iter': 0.02647, 'accuracy': 0.96499, 'precision': 0.40789, 'recall': 0.23846, 'f1': 0.30097, 'auc': 0.78222}
2025-06-20 01:02:31,321 - INFO - > Epoch 84: took 68.3s (avg 70.8s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:03:32,687 - INFO - train: {'epoch': 85, 'time_epoch': 61.28784, 'eta': 893.22842, 'eta_hours': 0.24812, 'loss': 0.06089054, 'lr': 6.03e-06, 'params': 514193, 'time_iter': 0.05956, 'accuracy': 0.98015, 'precision': 0.83391, 'recall': 0.58685, 'f1': 0.6889, 'auc': 0.97521}
2025-06-20 01:03:35,999 - INFO - val: {'epoch': 85, 'time_epoch': 3.28612, 'loss': 0.12131223, 'lr': 0, 'params': 514193, 'time_iter': 0.02547, 'accuracy': 0.97204, 'precision': 0.32653, 'recall': 0.39506, 'f1': 0.35754, 'auc': 0.76972}
2025-06-20 01:03:39,307 - INFO - test: {'epoch': 85, 'time_epoch': 3.28813, 'loss': 0.17413308, 'lr': 0, 'params': 514193, 'time_iter': 0.02549, 'accuracy': 0.9611, 'precision': 0.36364, 'recall': 0.30769, 'f1': 0.33333, 'auc': 0.7846}
2025-06-20 01:03:39,310 - INFO - > Epoch 85: took 68.0s (avg 70.8s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:04:41,219 - INFO - train: {'epoch': 86, 'time_epoch': 61.82901, 'eta': 829.13157, 'eta_hours': 0.23031, 'loss': 0.06211601, 'lr': 5.26e-06, 'params': 514193, 'time_iter': 0.06009, 'accuracy': 0.97988, 'precision': 0.83929, 'recall': 0.57224, 'f1': 0.6805, 'auc': 0.97383}
2025-06-20 01:04:44,544 - INFO - val: {'epoch': 86, 'time_epoch': 3.3002, 'loss': 0.11454222, 'lr': 0, 'params': 514193, 'time_iter': 0.02558, 'accuracy': 0.97715, 'precision': 0.40845, 'recall': 0.35802, 'f1': 0.38158, 'auc': 0.77168}
2025-06-20 01:04:47,839 - INFO - test: {'epoch': 86, 'time_epoch': 3.27528, 'loss': 0.17870438, 'lr': 0, 'params': 514193, 'time_iter': 0.02539, 'accuracy': 0.96548, 'precision': 0.41667, 'recall': 0.23077, 'f1': 0.29703, 'auc': 0.7744}
2025-06-20 01:04:47,841 - INFO - > Epoch 86: took 68.5s (avg 70.7s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:05:49,180 - INFO - train: {'epoch': 87, 'time_epoch': 61.26291, 'eta': 765.00906, 'eta_hours': 0.2125, 'loss': 0.06501744, 'lr': 4.55e-06, 'params': 514193, 'time_iter': 0.05954, 'accuracy': 0.97854, 'precision': 0.80023, 'recall': 0.56899, 'f1': 0.66509, 'auc': 0.97168}
2025-06-20 01:05:52,447 - INFO - val: {'epoch': 87, 'time_epoch': 3.24329, 'loss': 0.11759627, 'lr': 0, 'params': 514193, 'time_iter': 0.02514, 'accuracy': 0.97593, 'precision': 0.38462, 'recall': 0.37037, 'f1': 0.37736, 'auc': 0.76748}
2025-06-20 01:05:55,708 - INFO - test: {'epoch': 87, 'time_epoch': 3.24213, 'loss': 0.17691771, 'lr': 0, 'params': 514193, 'time_iter': 0.02513, 'accuracy': 0.9645, 'precision': 0.40244, 'recall': 0.25385, 'f1': 0.31132, 'auc': 0.77976}
2025-06-20 01:05:55,711 - INFO - > Epoch 87: took 67.9s (avg 70.7s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:06:57,913 - INFO - train: {'epoch': 88, 'time_epoch': 62.12453, 'eta': 701.05732, 'eta_hours': 0.19474, 'loss': 0.0633123, 'lr': 3.89e-06, 'params': 514193, 'time_iter': 0.06037, 'accuracy': 0.97973, 'precision': 0.84326, 'recall': 0.56331, 'f1': 0.67543, 'auc': 0.97197}
2025-06-20 01:07:01,237 - INFO - val: {'epoch': 88, 'time_epoch': 3.29908, 'loss': 0.12338262, 'lr': 0, 'params': 514193, 'time_iter': 0.02557, 'accuracy': 0.97836, 'precision': 0.44118, 'recall': 0.37037, 'f1': 0.40268, 'auc': 0.76242}
2025-06-20 01:07:04,528 - INFO - test: {'epoch': 88, 'time_epoch': 3.27167, 'loss': 0.1832534, 'lr': 0, 'params': 514193, 'time_iter': 0.02536, 'accuracy': 0.9645, 'precision': 0.39744, 'recall': 0.23846, 'f1': 0.29808, 'auc': 0.77776}
2025-06-20 01:07:04,531 - INFO - > Epoch 88: took 68.8s (avg 70.7s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:08:08,769 - INFO - train: {'epoch': 89, 'time_epoch': 64.1507, 'eta': 637.3713, 'eta_hours': 0.17705, 'loss': 0.06216857, 'lr': 3.27e-06, 'params': 514193, 'time_iter': 0.06234, 'accuracy': 0.97954, 'precision': 0.82767, 'recall': 0.57305, 'f1': 0.67722, 'auc': 0.97518}
2025-06-20 01:08:12,143 - INFO - val: {'epoch': 89, 'time_epoch': 3.3494, 'loss': 0.12574461, 'lr': 0, 'params': 514193, 'time_iter': 0.02596, 'accuracy': 0.9752, 'precision': 0.37931, 'recall': 0.40741, 'f1': 0.39286, 'auc': 0.76363}
2025-06-20 01:08:15,463 - INFO - test: {'epoch': 89, 'time_epoch': 3.29988, 'loss': 0.18232868, 'lr': 0, 'params': 514193, 'time_iter': 0.02558, 'accuracy': 0.96256, 'precision': 0.36957, 'recall': 0.26154, 'f1': 0.30631, 'auc': 0.77993}
2025-06-20 01:08:15,465 - INFO - > Epoch 89: took 70.9s (avg 70.7s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:09:17,956 - INFO - train: {'epoch': 90, 'time_epoch': 62.40994, 'eta': 573.50291, 'eta_hours': 0.15931, 'loss': 0.06153824, 'lr': 2.71e-06, 'params': 514193, 'time_iter': 0.06065, 'accuracy': 0.97964, 'precision': 0.83294, 'recall': 0.57062, 'f1': 0.67726, 'auc': 0.97621}
2025-06-20 01:09:21,208 - INFO - val: {'epoch': 90, 'time_epoch': 3.22612, 'loss': 0.12824248, 'lr': 0, 'params': 514193, 'time_iter': 0.02501, 'accuracy': 0.97496, 'precision': 0.37209, 'recall': 0.39506, 'f1': 0.38323, 'auc': 0.76436}
2025-06-20 01:09:24,483 - INFO - test: {'epoch': 90, 'time_epoch': 3.25471, 'loss': 0.18295516, 'lr': 0, 'params': 514193, 'time_iter': 0.02523, 'accuracy': 0.96329, 'precision': 0.38947, 'recall': 0.28462, 'f1': 0.32889, 'auc': 0.78043}
2025-06-20 01:09:24,485 - INFO - > Epoch 90: took 69.0s (avg 70.7s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:10:26,911 - INFO - train: {'epoch': 91, 'time_epoch': 62.3472, 'eta': 509.66077, 'eta_hours': 0.14157, 'loss': 0.05942573, 'lr': 2.2e-06, 'params': 514193, 'time_iter': 0.06059, 'accuracy': 0.98009, 'precision': 0.82747, 'recall': 0.59172, 'f1': 0.69001, 'auc': 0.97709}
2025-06-20 01:10:30,350 - INFO - val: {'epoch': 91, 'time_epoch': 3.41304, 'loss': 0.11331969, 'lr': 0, 'params': 514193, 'time_iter': 0.02646, 'accuracy': 0.97812, 'precision': 0.43836, 'recall': 0.39506, 'f1': 0.41558, 'auc': 0.77264}
2025-06-20 01:10:33,771 - INFO - test: {'epoch': 91, 'time_epoch': 3.40012, 'loss': 0.17547882, 'lr': 0, 'params': 514193, 'time_iter': 0.02636, 'accuracy': 0.96596, 'precision': 0.4359, 'recall': 0.26154, 'f1': 0.32692, 'auc': 0.78018}
2025-06-20 01:10:33,773 - INFO - > Epoch 91: took 69.3s (avg 70.7s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:11:35,209 - INFO - train: {'epoch': 92, 'time_epoch': 61.35815, 'eta': 445.77633, 'eta_hours': 0.12383, 'loss': 0.06191261, 'lr': 1.74e-06, 'params': 514193, 'time_iter': 0.05963, 'accuracy': 0.97979, 'precision': 0.83158, 'recall': 0.57711, 'f1': 0.68136, 'auc': 0.97592}
2025-06-20 01:11:38,489 - INFO - val: {'epoch': 92, 'time_epoch': 3.25556, 'loss': 0.1159985, 'lr': 0, 'params': 514193, 'time_iter': 0.02524, 'accuracy': 0.97617, 'precision': 0.39241, 'recall': 0.38272, 'f1': 0.3875, 'auc': 0.77631}
2025-06-20 01:11:41,760 - INFO - test: {'epoch': 92, 'time_epoch': 3.25182, 'loss': 0.17707914, 'lr': 0, 'params': 514193, 'time_iter': 0.02521, 'accuracy': 0.96475, 'precision': 0.40506, 'recall': 0.24615, 'f1': 0.30622, 'auc': 0.77876}
2025-06-20 01:11:41,762 - INFO - > Epoch 92: took 68.0s (avg 70.6s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:12:43,913 - INFO - train: {'epoch': 93, 'time_epoch': 62.06887, 'eta': 381.99101, 'eta_hours': 0.10611, 'loss': 0.06133914, 'lr': 1.33e-06, 'params': 514193, 'time_iter': 0.06032, 'accuracy': 0.97961, 'precision': 0.82884, 'recall': 0.57386, 'f1': 0.67818, 'auc': 0.97471}
2025-06-20 01:12:47,449 - INFO - val: {'epoch': 93, 'time_epoch': 3.5091, 'loss': 0.11650541, 'lr': 0, 'params': 514193, 'time_iter': 0.0272, 'accuracy': 0.97617, 'precision': 0.38961, 'recall': 0.37037, 'f1': 0.37975, 'auc': 0.76868}
2025-06-20 01:12:50,751 - INFO - test: {'epoch': 93, 'time_epoch': 3.28173, 'loss': 0.17555696, 'lr': 0, 'params': 514193, 'time_iter': 0.02544, 'accuracy': 0.9645, 'precision': 0.40476, 'recall': 0.26154, 'f1': 0.31776, 'auc': 0.78271}
2025-06-20 01:12:50,753 - INFO - > Epoch 93: took 69.0s (avg 70.6s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:13:53,126 - INFO - train: {'epoch': 94, 'time_epoch': 62.29393, 'eta': 318.25367, 'eta_hours': 0.0884, 'loss': 0.06137383, 'lr': 9.8e-07, 'params': 514193, 'time_iter': 0.06054, 'accuracy': 0.98024, 'precision': 0.83995, 'recall': 0.5836, 'f1': 0.6887, 'auc': 0.97399}
2025-06-20 01:13:56,401 - INFO - val: {'epoch': 94, 'time_epoch': 3.24876, 'loss': 0.12457106, 'lr': 0, 'params': 514193, 'time_iter': 0.02518, 'accuracy': 0.97398, 'precision': 0.35227, 'recall': 0.38272, 'f1': 0.36686, 'auc': 0.76639}
2025-06-20 01:13:59,711 - INFO - test: {'epoch': 94, 'time_epoch': 3.29003, 'loss': 0.18128455, 'lr': 0, 'params': 514193, 'time_iter': 0.0255, 'accuracy': 0.96256, 'precision': 0.38, 'recall': 0.29231, 'f1': 0.33043, 'auc': 0.77938}
2025-06-20 01:13:59,713 - INFO - > Epoch 94: took 69.0s (avg 70.6s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:15:02,527 - INFO - train: {'epoch': 95, 'time_epoch': 62.73478, 'eta': 254.56477, 'eta_hours': 0.07071, 'loss': 0.06171463, 'lr': 6.8e-07, 'params': 514193, 'time_iter': 0.06097, 'accuracy': 0.9797, 'precision': 0.82791, 'recall': 0.57792, 'f1': 0.68069, 'auc': 0.9721}
2025-06-20 01:15:06,107 - INFO - val: {'epoch': 95, 'time_epoch': 3.55227, 'loss': 0.12525062, 'lr': 0, 'params': 514193, 'time_iter': 0.02754, 'accuracy': 0.97617, 'precision': 0.39241, 'recall': 0.38272, 'f1': 0.3875, 'auc': 0.76836}
2025-06-20 01:15:09,731 - INFO - test: {'epoch': 95, 'time_epoch': 3.60105, 'loss': 0.18532568, 'lr': 0, 'params': 514193, 'time_iter': 0.02792, 'accuracy': 0.9645, 'precision': 0.40476, 'recall': 0.26154, 'f1': 0.31776, 'auc': 0.77732}
2025-06-20 01:15:09,733 - INFO - > Epoch 95: took 70.0s (avg 70.6s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:16:12,157 - INFO - train: {'epoch': 96, 'time_epoch': 62.34235, 'eta': 190.88341, 'eta_hours': 0.05302, 'loss': 0.06072412, 'lr': 4.4e-07, 'params': 514193, 'time_iter': 0.06059, 'accuracy': 0.98003, 'precision': 0.8234, 'recall': 0.59416, 'f1': 0.69024, 'auc': 0.97521}
2025-06-20 01:16:15,550 - INFO - val: {'epoch': 96, 'time_epoch': 3.36859, 'loss': 0.11910176, 'lr': 0, 'params': 514193, 'time_iter': 0.02611, 'accuracy': 0.97228, 'precision': 0.33663, 'recall': 0.41975, 'f1': 0.37363, 'auc': 0.76731}
2025-06-20 01:16:18,912 - INFO - test: {'epoch': 96, 'time_epoch': 3.34034, 'loss': 0.1728984, 'lr': 0, 'params': 514193, 'time_iter': 0.02589, 'accuracy': 0.96207, 'precision': 0.37, 'recall': 0.28462, 'f1': 0.32174, 'auc': 0.77944}
2025-06-20 01:16:18,915 - INFO - > Epoch 96: took 69.2s (avg 70.6s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:17:21,663 - INFO - train: {'epoch': 97, 'time_epoch': 62.66933, 'eta': 127.23605, 'eta_hours': 0.03534, 'loss': 0.06018222, 'lr': 2.5e-07, 'params': 514193, 'time_iter': 0.0609, 'accuracy': 0.97985, 'precision': 0.83197, 'recall': 0.57873, 'f1': 0.68262, 'auc': 0.97866}
2025-06-20 01:17:25,008 - INFO - val: {'epoch': 97, 'time_epoch': 3.31746, 'loss': 0.12463962, 'lr': 0, 'params': 514193, 'time_iter': 0.02572, 'accuracy': 0.97544, 'precision': 0.38372, 'recall': 0.40741, 'f1': 0.39521, 'auc': 0.76988}
2025-06-20 01:17:28,301 - INFO - test: {'epoch': 97, 'time_epoch': 3.27209, 'loss': 0.18111163, 'lr': 0, 'params': 514193, 'time_iter': 0.02537, 'accuracy': 0.96256, 'precision': 0.36364, 'recall': 0.24615, 'f1': 0.29358, 'auc': 0.77807}
2025-06-20 01:17:28,304 - INFO - > Epoch 97: took 69.4s (avg 70.6s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:18:29,874 - INFO - train: {'epoch': 98, 'time_epoch': 61.49118, 'eta': 63.59654, 'eta_hours': 0.01767, 'loss': 0.06140062, 'lr': 1.1e-07, 'params': 514193, 'time_iter': 0.05976, 'accuracy': 0.97973, 'precision': 0.83591, 'recall': 0.57062, 'f1': 0.67824, 'auc': 0.97517}
2025-06-20 01:18:33,279 - INFO - val: {'epoch': 98, 'time_epoch': 3.38054, 'loss': 0.11641406, 'lr': 0, 'params': 514193, 'time_iter': 0.02621, 'accuracy': 0.97569, 'precision': 0.38554, 'recall': 0.39506, 'f1': 0.39024, 'auc': 0.76837}
2025-06-20 01:18:36,715 - INFO - test: {'epoch': 98, 'time_epoch': 3.4148, 'loss': 0.17190032, 'lr': 0, 'params': 514193, 'time_iter': 0.02647, 'accuracy': 0.96353, 'precision': 0.38636, 'recall': 0.26154, 'f1': 0.31193, 'auc': 0.78135}
2025-06-20 01:18:36,722 - INFO - > Epoch 98: took 68.4s (avg 70.5s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:19:38,500 - INFO - train: {'epoch': 99, 'time_epoch': 61.69752, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.06203917, 'lr': 3e-08, 'params': 514193, 'time_iter': 0.05996, 'accuracy': 0.98009, 'precision': 0.83822, 'recall': 0.58036, 'f1': 0.68585, 'auc': 0.97349}
2025-06-20 01:19:41,965 - INFO - val: {'epoch': 99, 'time_epoch': 3.4391, 'loss': 0.1188827, 'lr': 0, 'params': 514193, 'time_iter': 0.02666, 'accuracy': 0.97763, 'precision': 0.42254, 'recall': 0.37037, 'f1': 0.39474, 'auc': 0.76669}
2025-06-20 01:19:45,312 - INFO - test: {'epoch': 99, 'time_epoch': 3.3264, 'loss': 0.17946173, 'lr': 0, 'params': 514193, 'time_iter': 0.02579, 'accuracy': 0.96645, 'precision': 0.44286, 'recall': 0.23846, 'f1': 0.31, 'auc': 0.78019}
2025-06-20 01:19:45,458 - INFO - > Epoch 99: took 68.6s (avg 70.5s) | Best so far: epoch 51	train_loss: 0.0807 train_auc: 0.9428	val_loss: 0.0912 val_auc: 0.8018	test_loss: 0.1452 test_auc: 0.7853
2025-06-20 01:19:45,458 - INFO - Avg time per epoch: 70.51s
2025-06-20 01:19:45,459 - INFO - Total train loop time: 1.96h
2025-06-20 01:19:45,461 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-41
2025-06-20 01:19:45,462 - INFO - Total time: 7114.83s (1.98h)
2025-06-20 01:19:45,475 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-41/agg
2025-06-20 01:19:45,475 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-06-20 01:19:45,475 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-41
2025-06-20 01:19:45,475 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-41/test_results/
Completed seed 41. Results saved in results/molhiv/molhiv-Vanilla-41
----------------------------------------
Running experiment with seed: 45
Starting training for seed 45...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/confignas.yaml
Using device: cuda
2025-06-20 01:19:57,107 - INFO - GPU Mem: 34.1GB
2025-06-20 01:19:57,108 - INFO - Run directory: results/molhiv/molhiv-Vanilla-45
2025-06-20 01:19:57,108 - INFO - Seed: 45
2025-06-20 01:19:57,108 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-06-20 01:19:57,108 - INFO - Routing mode: none
2025-06-20 01:19:57,108 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-06-20 01:19:57,108 - INFO - Number of layers: 15
2025-06-20 01:19:57,108 - INFO - Uncertainty enabled: False
2025-06-20 01:19:57,108 - INFO - Training mode: custom
2025-06-20 01:19:57,108 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-06-20 01:19:57,108 - INFO - Additional features: Router weights logging + JSON export
2025-06-20 01:20:04,000 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-20 01:20:04,002 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-06-20 01:20:04,003 - INFO -   undirected: True
2025-06-20 01:20:04,003 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-20 01:20:04,003 - INFO -   avg num_nodes/graph: 25
2025-06-20 01:20:04,003 - INFO -   num node features: 9
2025-06-20 01:20:04,004 - INFO -   num edge features: 3
2025-06-20 01:20:04,004 - INFO -   num tasks: 1
2025-06-20 01:20:04,004 - INFO -   num classes: 2
2025-06-20 01:20:04,004 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-06-20 01:20:04,004 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-06-20 01:20:04,007 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  0%|          | 0/41127 [00:13<?, ?it/s]  5%|▍         | 2016/41127 [00:13<04:19, 150.88it/s] 10%|▉         | 3939/41127 [00:23<03:35, 172.28it/s] 12%|█▏        | 5034/41127 [00:33<04:08, 145.31it/s] 14%|█▎        | 5595/41127 [00:43<05:20, 110.82it/s] 15%|█▍        | 6008/41127 [00:54<06:54, 84.83it/s]  16%|█▌        | 6447/41127 [01:04<08:17, 69.69it/s] 16%|█▌        | 6562/41127 [01:15<11:22, 50.65it/s] 18%|█▊        | 7399/41127 [01:25<09:21, 60.01it/s] 22%|██▏       | 8879/41127 [01:36<06:16, 85.62it/s] 25%|██▍       | 10201/41127 [01:46<05:12, 98.82it/s] 26%|██▋       | 10867/41127 [01:57<05:44, 87.72it/s] 30%|███       | 12453/41127 [02:07<04:25, 108.16it/s] 34%|███▎      | 13800/41127 [02:17<03:59, 114.11it/s] 35%|███▍      | 14349/41127 [02:27<04:36, 96.74it/s]  36%|███▌      | 14750/41127 [02:38<05:34, 78.94it/s] 37%|███▋      | 15306/41127 [02:48<06:02, 71.16it/s] 38%|███▊      | 15517/41127 [02:59<07:38, 55.92it/s] 40%|███▉      | 16306/41127 [03:09<06:44, 61.37it/s] 40%|████      | 16467/41127 [03:20<08:38, 47.55it/s] 41%|████      | 16848/41127 [03:30<09:01, 44.81it/s] 45%|████▍     | 18469/41127 [03:40<04:46, 79.17it/s] 47%|████▋     | 19278/41127 [03:50<04:35, 79.44it/s] 50%|█████     | 20613/41127 [04:00<03:37, 94.17it/s] 51%|█████▏    | 21130/41127 [04:11<04:07, 80.66it/s] 54%|█████▍    | 22243/41127 [04:22<03:35, 87.47it/s] 57%|█████▋    | 23575/41127 [04:32<02:57, 99.15it/s] 60%|█████▉    | 24481/41127 [04:43<02:54, 95.52it/s] 62%|██████▏   | 25591/41127 [04:53<02:36, 99.14it/s] 65%|██████▍   | 26608/41127 [05:03<02:26, 98.87it/s] 69%|██████▉   | 28311/41127 [05:13<01:47, 119.71it/s] 71%|███████   | 29264/41127 [05:24<01:46, 111.13it/s] 71%|███████▏  | 29332/41127 [05:34<02:27, 79.77it/s]  73%|███████▎  | 29868/41127 [05:44<02:36, 72.09it/s] 76%|███████▌  | 31065/41127 [05:55<01:59, 84.44it/s] 76%|███████▌  | 31119/41127 [06:05<02:45, 60.32it/s] 77%|███████▋  | 31733/41127 [06:15<02:34, 60.64it/s] 79%|███████▉  | 32570/41127 [06:26<02:08, 66.35it/s] 82%|████████▏ | 33653/41127 [06:36<01:36, 77.29it/s] 84%|████████▍ | 34500/41127 [06:47<01:24, 78.10it/s] 85%|████████▍ | 34891/41127 [06:58<01:35, 65.22it/s] 86%|████████▌ | 35434/41127 [07:09<01:33, 60.71it/s] 86%|████████▋ | 35509/41127 [07:19<02:03, 45.34it/s] 90%|████████▉ | 36855/41127 [07:29<01:00, 70.95it/s] 93%|█████████▎| 38269/41127 [07:39<00:31, 90.56it/s] 94%|█████████▍| 38725/41127 [07:50<00:31, 75.67it/s] 95%|█████████▍| 39003/41127 [08:00<00:34, 61.10it/s] 96%|█████████▋| 39619/41127 [08:10<00:24, 60.93it/s] 97%|█████████▋| 40067/41127 [08:21<00:19, 55.74it/s] 98%|█████████▊| 40348/41127 [08:31<00:16, 47.33it/s] 99%|█████████▉| 40746/41127 [08:41<00:08, 44.70it/s]100%|█████████▉| 40986/41127 [08:52<00:03, 38.15it/s]100%|█████████▉| 41117/41127 [09:02<00:00, 30.28it/s]100%|██████████| 41127/41127 [09:02<00:00, 75.76it/s]
2025-06-20 01:29:08,110 - INFO - Done! Took 00:09:04.11
2025-06-20 01:29:08,266 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-06-20 01:29:08,384 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-06-20 01:29:08,384 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-06-20 01:29:08,384 - INFO - Inner model has get_darts_model: False
2025-06-20 01:29:08,386 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-06-20 01:29:08,389 - INFO - Number of parameters: 514,193
2025-06-20 01:29:08,389 - INFO - Starting optimized training: 2025-06-20 01:29:08.389711
2025-06-20 01:29:14,723 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-20 01:29:14,724 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-06-20 01:29:14,724 - INFO -   undirected: True
2025-06-20 01:29:14,724 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-20 01:29:14,725 - INFO -   avg num_nodes/graph: 25
2025-06-20 01:29:14,725 - INFO -   num node features: 9
2025-06-20 01:29:14,725 - INFO -   num edge features: 3
2025-06-20 01:29:14,725 - INFO -   num tasks: 1
2025-06-20 01:29:14,725 - INFO -   num classes: 2
2025-06-20 01:29:14,726 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-06-20 01:29:14,726 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-06-20 01:29:14,729 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  0%|          | 0/41127 [00:12<?, ?it/s]  5%|▍         | 2016/41127 [00:13<04:18, 151.09it/s]  9%|▊         | 3504/41127 [00:23<04:13, 148.36it/s] 12%|█▏        | 5034/41127 [00:34<04:06, 146.47it/s] 14%|█▎        | 5634/41127 [00:44<05:17, 111.81it/s] 15%|█▍        | 6026/41127 [00:54<06:45, 86.55it/s]  16%|█▌        | 6448/41127 [01:05<08:02, 71.85it/s] 16%|█▌        | 6561/41127 [01:15<11:00, 52.34it/s] 18%|█▊        | 7476/41127 [01:25<08:41, 64.50it/s] 21%|██▏       | 8832/41127 [01:35<06:21, 84.72it/s] 24%|██▍       | 9973/41127 [01:46<05:36, 92.66it/s] 26%|██▌       | 10710/41127 [01:56<05:53, 86.16it/s] 29%|██▉       | 11993/41127 [02:06<04:56, 98.33it/s] 33%|███▎      | 13494/41127 [02:17<04:07, 111.46it/s] 34%|███▍      | 13986/41127 [02:27<04:51, 93.16it/s]  36%|███▌      | 14739/41127 [02:37<05:02, 87.32it/s] 36%|███▌      | 14759/41127 [02:47<07:06, 61.75it/s] 38%|███▊      | 15507/41127 [02:57<06:30, 65.55it/s] 38%|███▊      | 15606/41127 [03:08<08:45, 48.52it/s] 40%|███▉      | 16309/41127 [03:18<07:36, 54.40it/s] 40%|████      | 16470/41127 [03:29<09:41, 42.38it/s] 42%|████▏     | 17132/41127 [03:39<08:06, 49.35it/s] 45%|████▍     | 18469/41127 [03:49<05:05, 74.11it/s] 47%|████▋     | 19278/41127 [03:59<04:48, 75.72it/s] 50%|█████     | 20570/41127 [04:09<03:44, 91.56it/s] 51%|█████▏    | 21125/41127 [04:19<04:09, 80.25it/s] 53%|█████▎    | 21985/41127 [04:29<03:56, 81.06it/s] 56%|█████▌    | 23109/41127 [04:39<03:19, 90.29it/s] 58%|█████▊    | 23731/41127 [04:50<03:32, 81.78it/s] 61%|██████    | 24916/41127 [05:00<02:58, 90.83it/s] 64%|██████▍   | 26387/41127 [05:10<02:18, 106.63it/s] 67%|██████▋   | 27537/41127 [05:21<02:05, 108.07it/s] 71%|███████   | 29260/41127 [05:31<01:34, 126.08it/s] 71%|███████▏  | 29330/41127 [05:42<02:12, 89.28it/s]  72%|███████▏  | 29613/41127 [05:52<02:41, 71.47it/s] 75%|███████▌  | 30975/41127 [06:02<01:52, 90.52it/s] 76%|███████▌  | 31117/41127 [06:12<02:28, 67.22it/s] 77%|███████▋  | 31587/41127 [06:22<02:37, 60.63it/s] 79%|███████▉  | 32536/41127 [06:33<02:03, 69.29it/s] 82%|████████▏ | 33702/41127 [06:43<01:30, 82.29it/s] 84%|████████▍ | 34509/41127 [06:54<01:22, 80.01it/s] 85%|████████▍ | 34912/41127 [07:05<01:32, 67.38it/s] 86%|████████▌ | 35436/41127 [07:15<01:30, 62.93it/s] 87%|████████▋ | 35695/41127 [07:25<01:44, 52.11it/s] 90%|█████████ | 37187/41127 [07:36<00:49, 79.03it/s] 93%|█████████▎| 38402/41127 [07:46<00:30, 89.60it/s] 94%|█████████▍| 38774/41127 [07:57<00:32, 73.09it/s] 96%|█████████▌| 39405/41127 [08:08<00:25, 68.34it/s] 96%|█████████▋| 39622/41127 [08:18<00:27, 54.90it/s] 97%|█████████▋| 40070/41127 [08:29<00:20, 50.83it/s] 98%|█████████▊| 40352/41127 [08:39<00:17, 43.75it/s] 99%|█████████▉| 40748/41127 [08:49<00:08, 42.20it/s]100%|█████████▉| 40987/41127 [08:59<00:03, 36.80it/s]100%|█████████▉| 41120/41127 [09:09<00:00, 29.91it/s]100%|██████████| 41127/41127 [09:09<00:00, 74.79it/s]
2025-06-20 01:38:25,857 - INFO - Done! Took 00:09:11.13
2025-06-20 01:38:26,031 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-06-20 01:38:26,043 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-06-20 01:38:26,043 - INFO - Start from epoch 0
2025-06-20 01:39:43,546 - INFO - train: {'epoch': 0, 'time_epoch': 77.29612, 'eta': 7652.31597, 'eta_hours': 2.12564, 'loss': 0.76725595, 'lr': 0.0, 'params': 514193, 'time_iter': 0.07512, 'accuracy': 0.05243, 'precision': 0.03762, 'recall': 0.98864, 'f1': 0.07247, 'auc': 0.47983}
2025-06-20 01:39:43,561 - INFO - ...computing epoch stats took: 0.19s
2025-06-20 01:39:48,368 - INFO - val: {'epoch': 0, 'time_epoch': 4.78586, 'loss': 0.75796515, 'lr': 0, 'params': 514193, 'time_iter': 0.0371, 'accuracy': 0.04182, 'precision': 0.02014, 'recall': 1.0, 'f1': 0.03948, 'auc': 0.54757}
2025-06-20 01:39:48,371 - INFO - ...computing epoch stats took: 0.02s
2025-06-20 01:39:53,142 - INFO - test: {'epoch': 0, 'time_epoch': 4.75293, 'loss': 0.75497651, 'lr': 0, 'params': 514193, 'time_iter': 0.03684, 'accuracy': 0.07294, 'precision': 0.03226, 'recall': 0.97692, 'f1': 0.06245, 'auc': 0.5241}
2025-06-20 01:39:53,146 - INFO - ...computing epoch stats took: 0.02s
2025-06-20 01:39:53,147 - INFO - > Epoch 0: took 87.1s (avg 87.1s) | Best so far: epoch 0	train_loss: 0.7673 train_auc: 0.4798	val_loss: 0.7580 val_auc: 0.5476	test_loss: 0.7550 test_auc: 0.5241
2025-06-20 01:40:58,856 - INFO - train: {'epoch': 1, 'time_epoch': 65.48751, 'eta': 6996.39804, 'eta_hours': 1.94344, 'loss': 0.4767034, 'lr': 2e-05, 'params': 514193, 'time_iter': 0.06364, 'accuracy': 0.80833, 'precision': 0.03398, 'recall': 0.15016, 'f1': 0.05542, 'auc': 0.5032}
2025-06-20 01:40:58,865 - INFO - ...computing epoch stats took: 0.21s
2025-06-20 01:41:02,258 - INFO - val: {'epoch': 1, 'time_epoch': 3.37247, 'loss': 0.2396672, 'lr': 0, 'params': 514193, 'time_iter': 0.02614, 'accuracy': 0.97982, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.60625}
2025-06-20 01:41:02,261 - INFO - ...computing epoch stats took: 0.02s
2025-06-20 01:41:05,638 - INFO - test: {'epoch': 1, 'time_epoch': 3.35912, 'loss': 0.24419897, 'lr': 0, 'params': 514193, 'time_iter': 0.02604, 'accuracy': 0.96815, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.59304}
2025-06-20 01:41:05,640 - INFO - ...computing epoch stats took: 0.02s
2025-06-20 01:41:05,640 - INFO - > Epoch 1: took 72.5s (avg 79.8s) | Best so far: epoch 1	train_loss: 0.4767 train_auc: 0.5032	val_loss: 0.2397 val_auc: 0.6062	test_loss: 0.2442 test_auc: 0.5930
2025-06-20 01:42:11,421 - INFO - train: {'epoch': 2, 'time_epoch': 65.54226, 'eta': 6735.87054, 'eta_hours': 1.87108, 'loss': 0.18564251, 'lr': 4e-05, 'params': 514193, 'time_iter': 0.0637, 'accuracy': 0.96252, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.59803}
2025-06-20 01:42:11,430 - INFO - ...computing epoch stats took: 0.22s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-20 01:42:14,824 - INFO - val: {'epoch': 2, 'time_epoch': 3.3757, 'loss': 0.10087299, 'lr': 0, 'params': 514193, 'time_iter': 0.02617, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67404}
2025-06-20 01:42:14,827 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-20 01:42:18,230 - INFO - test: {'epoch': 2, 'time_epoch': 3.38679, 'loss': 0.13643341, 'lr': 0, 'params': 514193, 'time_iter': 0.02625, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66006}
2025-06-20 01:42:18,233 - INFO - ...computing epoch stats took: 0.02s
2025-06-20 01:42:18,233 - INFO - > Epoch 2: took 72.6s (avg 77.4s) | Best so far: epoch 2	train_loss: 0.1856 train_auc: 0.5980	val_loss: 0.1009 val_auc: 0.6740	test_loss: 0.1364 test_auc: 0.6601
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-20 01:43:24,392 - INFO - train: {'epoch': 3, 'time_epoch': 65.95609, 'eta': 6582.76752, 'eta_hours': 1.82855, 'loss': 0.15423246, 'lr': 6e-05, 'params': 514193, 'time_iter': 0.0641, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66595}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-20 01:43:28,013 - INFO - val: {'epoch': 3, 'time_epoch': 3.59403, 'loss': 0.0961035, 'lr': 0, 'params': 514193, 'time_iter': 0.02786, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71233}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-20 01:43:31,609 - INFO - test: {'epoch': 3, 'time_epoch': 3.57573, 'loss': 0.1308731, 'lr': 0, 'params': 514193, 'time_iter': 0.02772, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72124}
2025-06-20 01:43:31,611 - INFO - > Epoch 3: took 73.4s (avg 76.4s) | Best so far: epoch 3	train_loss: 0.1542 train_auc: 0.6660	val_loss: 0.0961 val_auc: 0.7123	test_loss: 0.1309 test_auc: 0.7212
2025-06-20 01:44:37,579 - INFO - train: {'epoch': 4, 'time_epoch': 65.79235, 'eta': 6461.41231, 'eta_hours': 1.79484, 'loss': 0.1467007, 'lr': 8e-05, 'params': 514193, 'time_iter': 0.06394, 'accuracy': 0.96255, 'precision': 0.5, 'recall': 0.00162, 'f1': 0.00324, 'auc': 0.70938}
2025-06-20 01:44:41,018 - INFO - val: {'epoch': 4, 'time_epoch': 3.41004, 'loss': 0.09631332, 'lr': 0, 'params': 514193, 'time_iter': 0.02643, 'accuracy': 0.98079, 'precision': 0.75, 'recall': 0.03704, 'f1': 0.07059, 'auc': 0.6964}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-20 01:44:44,486 - INFO - test: {'epoch': 4, 'time_epoch': 3.44816, 'loss': 0.12663237, 'lr': 0, 'params': 514193, 'time_iter': 0.02673, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73687}
2025-06-20 01:44:44,488 - INFO - > Epoch 4: took 72.9s (avg 75.7s) | Best so far: epoch 3	train_loss: 0.1542 train_auc: 0.6660	val_loss: 0.0961 val_auc: 0.7123	test_loss: 0.1309 test_auc: 0.7212
2025-06-20 01:45:51,000 - INFO - train: {'epoch': 5, 'time_epoch': 66.32126, 'eta': 6366.86425, 'eta_hours': 1.76857, 'loss': 0.14124126, 'lr': 0.0001, 'params': 514193, 'time_iter': 0.06445, 'accuracy': 0.96286, 'precision': 0.58621, 'recall': 0.0276, 'f1': 0.05271, 'auc': 0.73326}
2025-06-20 01:45:54,355 - INFO - val: {'epoch': 5, 'time_epoch': 3.32939, 'loss': 0.09053872, 'lr': 0, 'params': 514193, 'time_iter': 0.02581, 'accuracy': 0.98055, 'precision': 0.57143, 'recall': 0.04938, 'f1': 0.09091, 'auc': 0.68862}
2025-06-20 01:45:57,942 - INFO - test: {'epoch': 5, 'time_epoch': 3.56489, 'loss': 0.12270861, 'lr': 0, 'params': 514193, 'time_iter': 0.02763, 'accuracy': 0.96912, 'precision': 1.0, 'recall': 0.02308, 'f1': 0.04511, 'auc': 0.74013}
2025-06-20 01:45:57,944 - INFO - > Epoch 5: took 73.5s (avg 75.3s) | Best so far: epoch 3	train_loss: 0.1542 train_auc: 0.6660	val_loss: 0.0961 val_auc: 0.7123	test_loss: 0.1309 test_auc: 0.7212
2025-06-20 01:47:02,659 - INFO - train: {'epoch': 6, 'time_epoch': 64.50073, 'eta': 6256.19398, 'eta_hours': 1.73783, 'loss': 0.13770638, 'lr': 9.997e-05, 'params': 514193, 'time_iter': 0.06268, 'accuracy': 0.96304, 'precision': 0.55714, 'recall': 0.06331, 'f1': 0.1137, 'auc': 0.74575}
2025-06-20 01:47:06,019 - INFO - val: {'epoch': 6, 'time_epoch': 3.33511, 'loss': 0.10439914, 'lr': 0, 'params': 514193, 'time_iter': 0.02585, 'accuracy': 0.97836, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68239}
2025-06-20 01:47:09,424 - INFO - test: {'epoch': 6, 'time_epoch': 3.38371, 'loss': 0.13293162, 'lr': 0, 'params': 514193, 'time_iter': 0.02623, 'accuracy': 0.96377, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73425}
2025-06-20 01:47:09,428 - INFO - > Epoch 6: took 71.5s (avg 74.8s) | Best so far: epoch 3	train_loss: 0.1542 train_auc: 0.6660	val_loss: 0.0961 val_auc: 0.7123	test_loss: 0.1309 test_auc: 0.7212
2025-06-20 01:48:15,519 - INFO - train: {'epoch': 7, 'time_epoch': 65.90661, 'eta': 6173.23365, 'eta_hours': 1.71479, 'loss': 0.13453221, 'lr': 9.989e-05, 'params': 514193, 'time_iter': 0.06405, 'accuracy': 0.96347, 'precision': 0.58152, 'recall': 0.08685, 'f1': 0.15113, 'auc': 0.76002}
2025-06-20 01:48:18,983 - INFO - val: {'epoch': 7, 'time_epoch': 3.43577, 'loss': 0.11109252, 'lr': 0, 'params': 514193, 'time_iter': 0.02663, 'accuracy': 0.97812, 'precision': 0.4, 'recall': 0.22222, 'f1': 0.28571, 'auc': 0.72588}
2025-06-20 01:48:22,440 - INFO - test: {'epoch': 7, 'time_epoch': 3.43651, 'loss': 0.13843565, 'lr': 0, 'params': 514193, 'time_iter': 0.02664, 'accuracy': 0.96475, 'precision': 0.28571, 'recall': 0.07692, 'f1': 0.12121, 'auc': 0.74638}
2025-06-20 01:48:22,443 - INFO - > Epoch 7: took 73.0s (avg 74.5s) | Best so far: epoch 7	train_loss: 0.1345 train_auc: 0.7600	val_loss: 0.1111 val_auc: 0.7259	test_loss: 0.1384 test_auc: 0.7464
2025-06-20 01:49:29,379 - INFO - train: {'epoch': 8, 'time_epoch': 66.72415, 'eta': 6102.32929, 'eta_hours': 1.69509, 'loss': 0.13182736, 'lr': 9.975e-05, 'params': 514193, 'time_iter': 0.06484, 'accuracy': 0.96374, 'precision': 0.58369, 'recall': 0.11039, 'f1': 0.18567, 'auc': 0.77863}
2025-06-20 01:49:32,754 - INFO - val: {'epoch': 8, 'time_epoch': 3.34959, 'loss': 0.08901771, 'lr': 0, 'params': 514193, 'time_iter': 0.02597, 'accuracy': 0.98177, 'precision': 0.65, 'recall': 0.16049, 'f1': 0.25743, 'auc': 0.73005}
2025-06-20 01:49:36,160 - INFO - test: {'epoch': 8, 'time_epoch': 3.38517, 'loss': 0.12574035, 'lr': 0, 'params': 514193, 'time_iter': 0.02624, 'accuracy': 0.97034, 'precision': 0.65385, 'recall': 0.13077, 'f1': 0.21795, 'auc': 0.73147}
2025-06-20 01:49:36,162 - INFO - > Epoch 8: took 73.7s (avg 74.5s) | Best so far: epoch 8	train_loss: 0.1318 train_auc: 0.7786	val_loss: 0.0890 val_auc: 0.7300	test_loss: 0.1257 test_auc: 0.7315
2025-06-20 01:50:42,712 - INFO - train: {'epoch': 9, 'time_epoch': 66.35043, 'eta': 6028.89754, 'eta_hours': 1.67469, 'loss': 0.12903496, 'lr': 9.956e-05, 'params': 514193, 'time_iter': 0.06448, 'accuracy': 0.96547, 'precision': 0.68321, 'recall': 0.14529, 'f1': 0.23963, 'auc': 0.78333}
2025-06-20 01:50:46,264 - INFO - val: {'epoch': 9, 'time_epoch': 3.52329, 'loss': 0.08347453, 'lr': 0, 'params': 514193, 'time_iter': 0.02731, 'accuracy': 0.98128, 'precision': 0.83333, 'recall': 0.06173, 'f1': 0.11494, 'auc': 0.75811}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-20 01:50:49,600 - INFO - test: {'epoch': 9, 'time_epoch': 3.31764, 'loss': 0.12289592, 'lr': 0, 'params': 514193, 'time_iter': 0.02572, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73341}
2025-06-20 01:50:49,603 - INFO - > Epoch 9: took 73.4s (avg 74.4s) | Best so far: epoch 9	train_loss: 0.1290 train_auc: 0.7833	val_loss: 0.0835 val_auc: 0.7581	test_loss: 0.1229 test_auc: 0.7334
2025-06-20 01:51:54,771 - INFO - train: {'epoch': 10, 'time_epoch': 64.94843, 'eta': 5945.40987, 'eta_hours': 1.6515, 'loss': 0.12768088, 'lr': 9.932e-05, 'params': 514193, 'time_iter': 0.06312, 'accuracy': 0.96468, 'precision': 0.61146, 'recall': 0.15584, 'f1': 0.24838, 'auc': 0.78677}
2025-06-20 01:51:58,186 - INFO - val: {'epoch': 10, 'time_epoch': 3.38891, 'loss': 0.08952387, 'lr': 0, 'params': 514193, 'time_iter': 0.02627, 'accuracy': 0.97836, 'precision': 0.40476, 'recall': 0.20988, 'f1': 0.27642, 'auc': 0.72179}
2025-06-20 01:52:01,594 - INFO - test: {'epoch': 10, 'time_epoch': 3.38737, 'loss': 0.12414038, 'lr': 0, 'params': 514193, 'time_iter': 0.02626, 'accuracy': 0.96693, 'precision': 0.45455, 'recall': 0.23077, 'f1': 0.30612, 'auc': 0.74781}
2025-06-20 01:52:01,596 - INFO - > Epoch 10: took 72.0s (avg 74.1s) | Best so far: epoch 9	train_loss: 0.1290 train_auc: 0.7833	val_loss: 0.0835 val_auc: 0.7581	test_loss: 0.1229 test_auc: 0.7334
2025-06-20 01:53:07,938 - INFO - train: {'epoch': 11, 'time_epoch': 66.14078, 'eta': 5873.75597, 'eta_hours': 1.6316, 'loss': 0.12626682, 'lr': 9.902e-05, 'params': 514193, 'time_iter': 0.06428, 'accuracy': 0.96596, 'precision': 0.66374, 'recall': 0.18425, 'f1': 0.28844, 'auc': 0.79501}
2025-06-20 01:53:11,444 - INFO - val: {'epoch': 11, 'time_epoch': 3.41796, 'loss': 0.08408509, 'lr': 0, 'params': 514193, 'time_iter': 0.0265, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.14815, 'f1': 0.22857, 'auc': 0.73771}
2025-06-20 01:53:14,913 - INFO - test: {'epoch': 11, 'time_epoch': 3.44854, 'loss': 0.12588484, 'lr': 0, 'params': 514193, 'time_iter': 0.02673, 'accuracy': 0.96766, 'precision': 0.28571, 'recall': 0.01538, 'f1': 0.0292, 'auc': 0.74186}
2025-06-20 01:53:14,931 - INFO - > Epoch 11: took 73.3s (avg 74.1s) | Best so far: epoch 9	train_loss: 0.1290 train_auc: 0.7833	val_loss: 0.0835 val_auc: 0.7581	test_loss: 0.1229 test_auc: 0.7334
2025-06-20 01:54:21,241 - INFO - train: {'epoch': 12, 'time_epoch': 66.09718, 'eta': 5802.65841, 'eta_hours': 1.61185, 'loss': 0.12362253, 'lr': 9.867e-05, 'params': 514193, 'time_iter': 0.06423, 'accuracy': 0.96562, 'precision': 0.61995, 'recall': 0.21185, 'f1': 0.31579, 'auc': 0.80467}
2025-06-20 01:54:24,854 - INFO - val: {'epoch': 12, 'time_epoch': 3.58094, 'loss': 0.08332528, 'lr': 0, 'params': 514193, 'time_iter': 0.02776, 'accuracy': 0.98055, 'precision': 0.51515, 'recall': 0.20988, 'f1': 0.29825, 'auc': 0.73644}
2025-06-20 01:54:28,472 - INFO - test: {'epoch': 12, 'time_epoch': 3.59581, 'loss': 0.12268187, 'lr': 0, 'params': 514193, 'time_iter': 0.02787, 'accuracy': 0.96864, 'precision': 0.5098, 'recall': 0.2, 'f1': 0.28729, 'auc': 0.75367}
2025-06-20 01:54:28,474 - INFO - > Epoch 12: took 73.5s (avg 74.0s) | Best so far: epoch 9	train_loss: 0.1290 train_auc: 0.7833	val_loss: 0.0835 val_auc: 0.7581	test_loss: 0.1229 test_auc: 0.7334
2025-06-20 01:55:34,310 - INFO - train: {'epoch': 13, 'time_epoch': 65.62923, 'eta': 5729.40068, 'eta_hours': 1.5915, 'loss': 0.12098072, 'lr': 9.826e-05, 'params': 514193, 'time_iter': 0.06378, 'accuracy': 0.96675, 'precision': 0.66667, 'recall': 0.22403, 'f1': 0.33536, 'auc': 0.8116}
2025-06-20 01:55:37,725 - INFO - val: {'epoch': 13, 'time_epoch': 3.38921, 'loss': 0.08724751, 'lr': 0, 'params': 514193, 'time_iter': 0.02627, 'accuracy': 0.97836, 'precision': 0.42308, 'recall': 0.2716, 'f1': 0.33083, 'auc': 0.74526}
2025-06-20 01:55:41,270 - INFO - test: {'epoch': 13, 'time_epoch': 3.52355, 'loss': 0.1267449, 'lr': 0, 'params': 514193, 'time_iter': 0.02731, 'accuracy': 0.96475, 'precision': 0.39437, 'recall': 0.21538, 'f1': 0.27861, 'auc': 0.75534}
2025-06-20 01:55:41,273 - INFO - > Epoch 13: took 72.8s (avg 73.9s) | Best so far: epoch 9	train_loss: 0.1290 train_auc: 0.7833	val_loss: 0.0835 val_auc: 0.7581	test_loss: 0.1229 test_auc: 0.7334
2025-06-20 01:56:47,132 - INFO - train: {'epoch': 14, 'time_epoch': 65.65861, 'eta': 5657.32654, 'eta_hours': 1.57148, 'loss': 0.11918209, 'lr': 9.78e-05, 'params': 514193, 'time_iter': 0.06381, 'accuracy': 0.96657, 'precision': 0.64103, 'recall': 0.24351, 'f1': 0.35294, 'auc': 0.82363}
2025-06-20 01:56:50,483 - INFO - val: {'epoch': 14, 'time_epoch': 3.32247, 'loss': 0.08543703, 'lr': 0, 'params': 514193, 'time_iter': 0.02576, 'accuracy': 0.98079, 'precision': 0.55, 'recall': 0.1358, 'f1': 0.21782, 'auc': 0.75104}
2025-06-20 01:56:54,231 - INFO - test: {'epoch': 14, 'time_epoch': 3.72779, 'loss': 0.12027219, 'lr': 0, 'params': 514193, 'time_iter': 0.0289, 'accuracy': 0.96791, 'precision': 0.47368, 'recall': 0.13846, 'f1': 0.21429, 'auc': 0.77137}
2025-06-20 01:56:54,233 - INFO - > Epoch 14: took 73.0s (avg 73.9s) | Best so far: epoch 9	train_loss: 0.1290 train_auc: 0.7833	val_loss: 0.0835 val_auc: 0.7581	test_loss: 0.1229 test_auc: 0.7334
2025-06-20 01:57:59,050 - INFO - train: {'epoch': 15, 'time_epoch': 64.59816, 'eta': 5580.48701, 'eta_hours': 1.55014, 'loss': 0.11843828, 'lr': 9.729e-05, 'params': 514193, 'time_iter': 0.06278, 'accuracy': 0.96644, 'precision': 0.64414, 'recall': 0.23214, 'f1': 0.34129, 'auc': 0.82703}
2025-06-20 01:58:02,444 - INFO - val: {'epoch': 15, 'time_epoch': 3.36733, 'loss': 0.08583384, 'lr': 0, 'params': 514193, 'time_iter': 0.0261, 'accuracy': 0.98006, 'precision': 0.4878, 'recall': 0.24691, 'f1': 0.32787, 'auc': 0.75363}
2025-06-20 01:58:05,848 - INFO - test: {'epoch': 15, 'time_epoch': 3.38363, 'loss': 0.12002755, 'lr': 0, 'params': 514193, 'time_iter': 0.02623, 'accuracy': 0.96766, 'precision': 0.47541, 'recall': 0.22308, 'f1': 0.30366, 'auc': 0.76608}
2025-06-20 01:58:05,850 - INFO - > Epoch 15: took 71.6s (avg 73.7s) | Best so far: epoch 9	train_loss: 0.1290 train_auc: 0.7833	val_loss: 0.0835 val_auc: 0.7581	test_loss: 0.1229 test_auc: 0.7334
2025-06-20 01:59:11,546 - INFO - train: {'epoch': 16, 'time_epoch': 65.48403, 'eta': 5509.41275, 'eta_hours': 1.53039, 'loss': 0.11818493, 'lr': 9.673e-05, 'params': 514193, 'time_iter': 0.06364, 'accuracy': 0.96757, 'precision': 0.68539, 'recall': 0.24756, 'f1': 0.36374, 'auc': 0.82198}
2025-06-20 01:59:14,953 - INFO - val: {'epoch': 16, 'time_epoch': 3.38013, 'loss': 0.08927604, 'lr': 0, 'params': 514193, 'time_iter': 0.0262, 'accuracy': 0.97739, 'precision': 0.39286, 'recall': 0.2716, 'f1': 0.32117, 'auc': 0.75106}
2025-06-20 01:59:18,412 - INFO - test: {'epoch': 16, 'time_epoch': 3.36229, 'loss': 0.12638945, 'lr': 0, 'params': 514193, 'time_iter': 0.02606, 'accuracy': 0.96523, 'precision': 0.43011, 'recall': 0.30769, 'f1': 0.35874, 'auc': 0.76724}
2025-06-20 01:59:18,414 - INFO - > Epoch 16: took 72.6s (avg 73.7s) | Best so far: epoch 9	train_loss: 0.1290 train_auc: 0.7833	val_loss: 0.0835 val_auc: 0.7581	test_loss: 0.1229 test_auc: 0.7334
2025-06-20 02:00:25,295 - INFO - train: {'epoch': 17, 'time_epoch': 66.66456, 'eta': 5444.33761, 'eta_hours': 1.51232, 'loss': 0.11556891, 'lr': 9.611e-05, 'params': 514193, 'time_iter': 0.06479, 'accuracy': 0.96848, 'precision': 0.70021, 'recall': 0.27679, 'f1': 0.39674, 'auc': 0.83216}
2025-06-20 02:00:28,690 - INFO - val: {'epoch': 17, 'time_epoch': 3.36937, 'loss': 0.08185744, 'lr': 0, 'params': 514193, 'time_iter': 0.02612, 'accuracy': 0.98006, 'precision': 0.48571, 'recall': 0.20988, 'f1': 0.2931, 'auc': 0.77756}
2025-06-20 02:00:32,259 - INFO - test: {'epoch': 17, 'time_epoch': 3.46127, 'loss': 0.12484894, 'lr': 0, 'params': 514193, 'time_iter': 0.02683, 'accuracy': 0.96791, 'precision': 0.47917, 'recall': 0.17692, 'f1': 0.25843, 'auc': 0.76046}
2025-06-20 02:00:32,261 - INFO - > Epoch 17: took 73.8s (avg 73.7s) | Best so far: epoch 17	train_loss: 0.1156 train_auc: 0.8322	val_loss: 0.0819 val_auc: 0.7776	test_loss: 0.1248 test_auc: 0.7605
2025-06-20 02:01:38,482 - INFO - train: {'epoch': 18, 'time_epoch': 65.99965, 'eta': 5376.26055, 'eta_hours': 1.49341, 'loss': 0.11350964, 'lr': 9.545e-05, 'params': 514193, 'time_iter': 0.06414, 'accuracy': 0.96812, 'precision': 0.67976, 'recall': 0.28084, 'f1': 0.39747, 'auc': 0.84584}
2025-06-20 02:01:42,053 - INFO - val: {'epoch': 18, 'time_epoch': 3.5394, 'loss': 0.08422639, 'lr': 0, 'params': 514193, 'time_iter': 0.02744, 'accuracy': 0.98104, 'precision': 0.53488, 'recall': 0.28395, 'f1': 0.37097, 'auc': 0.74691}
2025-06-20 02:01:45,396 - INFO - test: {'epoch': 18, 'time_epoch': 3.31384, 'loss': 0.12219407, 'lr': 0, 'params': 514193, 'time_iter': 0.02569, 'accuracy': 0.96864, 'precision': 0.50909, 'recall': 0.21538, 'f1': 0.3027, 'auc': 0.77057}
2025-06-20 02:01:45,398 - INFO - > Epoch 18: took 73.1s (avg 73.6s) | Best so far: epoch 17	train_loss: 0.1156 train_auc: 0.8322	val_loss: 0.0819 val_auc: 0.7776	test_loss: 0.1248 test_auc: 0.7605
2025-06-20 02:02:51,444 - INFO - train: {'epoch': 19, 'time_epoch': 65.80691, 'eta': 5307.62025, 'eta_hours': 1.47434, 'loss': 0.1134566, 'lr': 9.474e-05, 'params': 514193, 'time_iter': 0.06395, 'accuracy': 0.96827, 'precision': 0.69421, 'recall': 0.27273, 'f1': 0.39161, 'auc': 0.84717}
2025-06-20 02:02:54,898 - INFO - val: {'epoch': 19, 'time_epoch': 3.42705, 'loss': 0.10004978, 'lr': 0, 'params': 514193, 'time_iter': 0.02657, 'accuracy': 0.97471, 'precision': 0.37363, 'recall': 0.41975, 'f1': 0.39535, 'auc': 0.76481}
2025-06-20 02:02:58,278 - INFO - test: {'epoch': 19, 'time_epoch': 3.35995, 'loss': 0.14072225, 'lr': 0, 'params': 514193, 'time_iter': 0.02605, 'accuracy': 0.95648, 'precision': 0.31579, 'recall': 0.32308, 'f1': 0.31939, 'auc': 0.77312}
2025-06-20 02:02:58,280 - INFO - > Epoch 19: took 72.9s (avg 73.6s) | Best so far: epoch 17	train_loss: 0.1156 train_auc: 0.8322	val_loss: 0.0819 val_auc: 0.7776	test_loss: 0.1248 test_auc: 0.7605
2025-06-20 02:04:03,038 - INFO - train: {'epoch': 20, 'time_epoch': 64.56796, 'eta': 5234.58898, 'eta_hours': 1.45405, 'loss': 0.11032614, 'lr': 9.397e-05, 'params': 514193, 'time_iter': 0.06275, 'accuracy': 0.96915, 'precision': 0.7013, 'recall': 0.30682, 'f1': 0.42688, 'auc': 0.85163}
2025-06-20 02:04:06,470 - INFO - val: {'epoch': 20, 'time_epoch': 3.3969, 'loss': 0.08021372, 'lr': 0, 'params': 514193, 'time_iter': 0.02633, 'accuracy': 0.98104, 'precision': 0.53488, 'recall': 0.28395, 'f1': 0.37097, 'auc': 0.78379}
2025-06-20 02:04:09,861 - INFO - test: {'epoch': 20, 'time_epoch': 3.37042, 'loss': 0.12182648, 'lr': 0, 'params': 514193, 'time_iter': 0.02613, 'accuracy': 0.96791, 'precision': 0.48571, 'recall': 0.26154, 'f1': 0.34, 'auc': 0.77634}
2025-06-20 02:04:09,863 - INFO - > Epoch 20: took 71.6s (avg 73.5s) | Best so far: epoch 20	train_loss: 0.1103 train_auc: 0.8516	val_loss: 0.0802 val_auc: 0.7838	test_loss: 0.1218 test_auc: 0.7763
2025-06-20 02:05:16,017 - INFO - train: {'epoch': 21, 'time_epoch': 65.9197, 'eta': 5167.11963, 'eta_hours': 1.43531, 'loss': 0.11164352, 'lr': 9.316e-05, 'params': 514193, 'time_iter': 0.06406, 'accuracy': 0.96857, 'precision': 0.6996, 'recall': 0.28166, 'f1': 0.40162, 'auc': 0.8543}
2025-06-20 02:05:19,626 - INFO - val: {'epoch': 21, 'time_epoch': 3.58111, 'loss': 0.07637663, 'lr': 0, 'params': 514193, 'time_iter': 0.02776, 'accuracy': 0.98274, 'precision': 0.69231, 'recall': 0.22222, 'f1': 0.33645, 'auc': 0.79468}
2025-06-20 02:05:23,004 - INFO - test: {'epoch': 21, 'time_epoch': 3.3581, 'loss': 0.11638309, 'lr': 0, 'params': 514193, 'time_iter': 0.02603, 'accuracy': 0.96937, 'precision': 0.57692, 'recall': 0.11538, 'f1': 0.19231, 'auc': 0.7683}
2025-06-20 02:05:23,007 - INFO - > Epoch 21: took 73.1s (avg 73.5s) | Best so far: epoch 21	train_loss: 0.1116 train_auc: 0.8543	val_loss: 0.0764 val_auc: 0.7947	test_loss: 0.1164 test_auc: 0.7683
2025-06-20 02:06:29,065 - INFO - train: {'epoch': 22, 'time_epoch': 65.82971, 'eta': 5099.48378, 'eta_hours': 1.41652, 'loss': 0.10918635, 'lr': 9.23e-05, 'params': 514193, 'time_iter': 0.06397, 'accuracy': 0.96836, 'precision': 0.6819, 'recall': 0.29058, 'f1': 0.40751, 'auc': 0.86293}
2025-06-20 02:06:32,634 - INFO - val: {'epoch': 22, 'time_epoch': 3.54241, 'loss': 0.07969329, 'lr': 0, 'params': 514193, 'time_iter': 0.02746, 'accuracy': 0.97836, 'precision': 0.44118, 'recall': 0.37037, 'f1': 0.40268, 'auc': 0.7905}
2025-06-20 02:06:36,251 - INFO - test: {'epoch': 22, 'time_epoch': 3.59508, 'loss': 0.1242224, 'lr': 0, 'params': 514193, 'time_iter': 0.02787, 'accuracy': 0.96596, 'precision': 0.44318, 'recall': 0.3, 'f1': 0.3578, 'auc': 0.77468}
2025-06-20 02:06:36,253 - INFO - > Epoch 22: took 73.2s (avg 73.5s) | Best so far: epoch 21	train_loss: 0.1116 train_auc: 0.8543	val_loss: 0.0764 val_auc: 0.7947	test_loss: 0.1164 test_auc: 0.7683
2025-06-20 02:07:42,184 - INFO - train: {'epoch': 23, 'time_epoch': 65.67261, 'eta': 5031.50094, 'eta_hours': 1.39764, 'loss': 0.10683045, 'lr': 9.14e-05, 'params': 514193, 'time_iter': 0.06382, 'accuracy': 0.96988, 'precision': 0.72439, 'recall': 0.31575, 'f1': 0.4398, 'auc': 0.86764}
2025-06-20 02:07:45,943 - INFO - val: {'epoch': 23, 'time_epoch': 3.73022, 'loss': 0.08723133, 'lr': 0, 'params': 514193, 'time_iter': 0.02892, 'accuracy': 0.97933, 'precision': 0.46875, 'recall': 0.37037, 'f1': 0.41379, 'auc': 0.76441}
2025-06-20 02:07:49,403 - INFO - test: {'epoch': 23, 'time_epoch': 3.43914, 'loss': 0.13235405, 'lr': 0, 'params': 514193, 'time_iter': 0.02666, 'accuracy': 0.96304, 'precision': 0.37778, 'recall': 0.26154, 'f1': 0.30909, 'auc': 0.75706}
2025-06-20 02:07:49,405 - INFO - > Epoch 23: took 73.2s (avg 73.5s) | Best so far: epoch 21	train_loss: 0.1116 train_auc: 0.8543	val_loss: 0.0764 val_auc: 0.7947	test_loss: 0.1164 test_auc: 0.7683
2025-06-20 02:08:54,732 - INFO - train: {'epoch': 24, 'time_epoch': 65.14347, 'eta': 4962.11552, 'eta_hours': 1.37837, 'loss': 0.1070465, 'lr': 9.045e-05, 'params': 514193, 'time_iter': 0.06331, 'accuracy': 0.96976, 'precision': 0.71429, 'recall': 0.32062, 'f1': 0.44258, 'auc': 0.86932}
2025-06-20 02:08:58,153 - INFO - val: {'epoch': 24, 'time_epoch': 3.39341, 'loss': 0.07985263, 'lr': 0, 'params': 514193, 'time_iter': 0.02631, 'accuracy': 0.98177, 'precision': 0.58333, 'recall': 0.25926, 'f1': 0.35897, 'auc': 0.78274}
2025-06-20 02:09:01,559 - INFO - test: {'epoch': 24, 'time_epoch': 3.38593, 'loss': 0.12680142, 'lr': 0, 'params': 514193, 'time_iter': 0.02625, 'accuracy': 0.96742, 'precision': 0.46429, 'recall': 0.2, 'f1': 0.27957, 'auc': 0.74828}
2025-06-20 02:09:01,562 - INFO - > Epoch 24: took 72.2s (avg 73.4s) | Best so far: epoch 21	train_loss: 0.1116 train_auc: 0.8543	val_loss: 0.0764 val_auc: 0.7947	test_loss: 0.1164 test_auc: 0.7683
2025-06-20 02:10:07,586 - INFO - train: {'epoch': 25, 'time_epoch': 65.82197, 'eta': 4894.9875, 'eta_hours': 1.35972, 'loss': 0.10624762, 'lr': 8.946e-05, 'params': 514193, 'time_iter': 0.06397, 'accuracy': 0.96982, 'precision': 0.72253, 'recall': 0.31494, 'f1': 0.43867, 'auc': 0.86862}
2025-06-20 02:10:11,134 - INFO - val: {'epoch': 25, 'time_epoch': 3.51898, 'loss': 0.0814813, 'lr': 0, 'params': 514193, 'time_iter': 0.02728, 'accuracy': 0.98177, 'precision': 0.56, 'recall': 0.34568, 'f1': 0.42748, 'auc': 0.79125}
2025-06-20 02:10:14,719 - INFO - test: {'epoch': 25, 'time_epoch': 3.56344, 'loss': 0.12002611, 'lr': 0, 'params': 514193, 'time_iter': 0.02762, 'accuracy': 0.96888, 'precision': 0.51429, 'recall': 0.27692, 'f1': 0.36, 'auc': 0.77747}
2025-06-20 02:10:14,722 - INFO - > Epoch 25: took 73.2s (avg 73.4s) | Best so far: epoch 21	train_loss: 0.1116 train_auc: 0.8543	val_loss: 0.0764 val_auc: 0.7947	test_loss: 0.1164 test_auc: 0.7683
2025-06-20 02:11:20,751 - INFO - train: {'epoch': 26, 'time_epoch': 65.84868, 'eta': 4828.02845, 'eta_hours': 1.34112, 'loss': 0.10518152, 'lr': 8.842e-05, 'params': 514193, 'time_iter': 0.06399, 'accuracy': 0.96951, 'precision': 0.69506, 'recall': 0.33117, 'f1': 0.4486, 'auc': 0.87317}
2025-06-20 02:11:24,177 - INFO - val: {'epoch': 26, 'time_epoch': 3.39854, 'loss': 0.07393625, 'lr': 0, 'params': 514193, 'time_iter': 0.02635, 'accuracy': 0.98298, 'precision': 0.65714, 'recall': 0.28395, 'f1': 0.39655, 'auc': 0.79733}
2025-06-20 02:11:27,584 - INFO - test: {'epoch': 26, 'time_epoch': 3.38563, 'loss': 0.1248128, 'lr': 0, 'params': 514193, 'time_iter': 0.02625, 'accuracy': 0.96912, 'precision': 0.53061, 'recall': 0.2, 'f1': 0.2905, 'auc': 0.76047}
2025-06-20 02:11:27,586 - INFO - > Epoch 26: took 72.9s (avg 73.4s) | Best so far: epoch 26	train_loss: 0.1052 train_auc: 0.8732	val_loss: 0.0739 val_auc: 0.7973	test_loss: 0.1248 test_auc: 0.7605
2025-06-20 02:12:33,967 - INFO - train: {'epoch': 27, 'time_epoch': 66.20314, 'eta': 4762.06019, 'eta_hours': 1.32279, 'loss': 0.10429465, 'lr': 8.734e-05, 'params': 514193, 'time_iter': 0.06434, 'accuracy': 0.97015, 'precision': 0.71552, 'recall': 0.33685, 'f1': 0.45806, 'auc': 0.87732}
2025-06-20 02:12:37,314 - INFO - val: {'epoch': 27, 'time_epoch': 3.32179, 'loss': 0.07361932, 'lr': 0, 'params': 514193, 'time_iter': 0.02575, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.78935}
2025-06-20 02:12:40,647 - INFO - test: {'epoch': 27, 'time_epoch': 3.31303, 'loss': 0.11817329, 'lr': 0, 'params': 514193, 'time_iter': 0.02568, 'accuracy': 0.97107, 'precision': 0.64865, 'recall': 0.18462, 'f1': 0.28743, 'auc': 0.75917}
2025-06-20 02:12:40,650 - INFO - > Epoch 27: took 73.1s (avg 73.4s) | Best so far: epoch 26	train_loss: 0.1052 train_auc: 0.8732	val_loss: 0.0739 val_auc: 0.7973	test_loss: 0.1248 test_auc: 0.7605
2025-06-20 02:13:45,545 - INFO - train: {'epoch': 28, 'time_epoch': 64.71894, 'eta': 4692.44198, 'eta_hours': 1.30346, 'loss': 0.10360307, 'lr': 8.622e-05, 'params': 514193, 'time_iter': 0.06289, 'accuracy': 0.96976, 'precision': 0.70899, 'recall': 0.3263, 'f1': 0.44691, 'auc': 0.88334}
2025-06-20 02:13:48,953 - INFO - val: {'epoch': 28, 'time_epoch': 3.38117, 'loss': 0.07993672, 'lr': 0, 'params': 514193, 'time_iter': 0.02621, 'accuracy': 0.98274, 'precision': 0.61364, 'recall': 0.33333, 'f1': 0.432, 'auc': 0.79432}
2025-06-20 02:13:52,341 - INFO - test: {'epoch': 28, 'time_epoch': 3.36805, 'loss': 0.12737453, 'lr': 0, 'params': 514193, 'time_iter': 0.02611, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.15385, 'f1': 0.23529, 'auc': 0.74754}
2025-06-20 02:13:52,344 - INFO - > Epoch 28: took 71.7s (avg 73.3s) | Best so far: epoch 26	train_loss: 0.1052 train_auc: 0.8732	val_loss: 0.0739 val_auc: 0.7973	test_loss: 0.1248 test_auc: 0.7605
2025-06-20 02:14:59,733 - INFO - train: {'epoch': 29, 'time_epoch': 67.18155, 'eta': 4628.89649, 'eta_hours': 1.2858, 'loss': 0.10233587, 'lr': 8.506e-05, 'params': 514193, 'time_iter': 0.06529, 'accuracy': 0.97064, 'precision': 0.73333, 'recall': 0.33929, 'f1': 0.46393, 'auc': 0.88391}
2025-06-20 02:15:03,405 - INFO - val: {'epoch': 29, 'time_epoch': 3.64025, 'loss': 0.08694227, 'lr': 0, 'params': 514193, 'time_iter': 0.02822, 'accuracy': 0.97909, 'precision': 0.46269, 'recall': 0.38272, 'f1': 0.41892, 'auc': 0.78226}
2025-06-20 02:15:07,098 - INFO - test: {'epoch': 29, 'time_epoch': 3.67052, 'loss': 0.13424426, 'lr': 0, 'params': 514193, 'time_iter': 0.02845, 'accuracy': 0.9628, 'precision': 0.39252, 'recall': 0.32308, 'f1': 0.35443, 'auc': 0.75032}
2025-06-20 02:15:07,100 - INFO - > Epoch 29: took 74.8s (avg 73.4s) | Best so far: epoch 26	train_loss: 0.1052 train_auc: 0.8732	val_loss: 0.0739 val_auc: 0.7973	test_loss: 0.1248 test_auc: 0.7605
2025-06-20 02:16:13,837 - INFO - train: {'epoch': 30, 'time_epoch': 66.54983, 'eta': 4563.71033, 'eta_hours': 1.2677, 'loss': 0.10025545, 'lr': 8.386e-05, 'params': 514193, 'time_iter': 0.06467, 'accuracy': 0.97073, 'precision': 0.71589, 'recall': 0.36201, 'f1': 0.48086, 'auc': 0.89171}
2025-06-20 02:16:17,272 - INFO - val: {'epoch': 30, 'time_epoch': 3.40874, 'loss': 0.07751925, 'lr': 0, 'params': 514193, 'time_iter': 0.02642, 'accuracy': 0.98152, 'precision': 0.55102, 'recall': 0.33333, 'f1': 0.41538, 'auc': 0.80942}
2025-06-20 02:16:20,826 - INFO - test: {'epoch': 30, 'time_epoch': 3.53133, 'loss': 0.13376513, 'lr': 0, 'params': 514193, 'time_iter': 0.02737, 'accuracy': 0.96548, 'precision': 0.41892, 'recall': 0.23846, 'f1': 0.30392, 'auc': 0.76045}
2025-06-20 02:16:20,828 - INFO - > Epoch 30: took 73.7s (avg 73.4s) | Best so far: epoch 30	train_loss: 0.1003 train_auc: 0.8917	val_loss: 0.0775 val_auc: 0.8094	test_loss: 0.1338 test_auc: 0.7604
2025-06-20 02:17:26,799 - INFO - train: {'epoch': 31, 'time_epoch': 65.8017, 'eta': 4496.84917, 'eta_hours': 1.24912, 'loss': 0.09992069, 'lr': 8.263e-05, 'params': 514193, 'time_iter': 0.06395, 'accuracy': 0.97103, 'precision': 0.73524, 'recall': 0.3539, 'f1': 0.47781, 'auc': 0.89412}
2025-06-20 02:17:30,179 - INFO - val: {'epoch': 31, 'time_epoch': 3.35334, 'loss': 0.09971559, 'lr': 0, 'params': 514193, 'time_iter': 0.02599, 'accuracy': 0.97131, 'precision': 0.30108, 'recall': 0.34568, 'f1': 0.32184, 'auc': 0.78939}
2025-06-20 02:17:33,547 - INFO - test: {'epoch': 31, 'time_epoch': 3.34668, 'loss': 0.13727597, 'lr': 0, 'params': 514193, 'time_iter': 0.02594, 'accuracy': 0.95818, 'precision': 0.32203, 'recall': 0.29231, 'f1': 0.30645, 'auc': 0.77682}
2025-06-20 02:17:33,549 - INFO - > Epoch 31: took 72.7s (avg 73.4s) | Best so far: epoch 30	train_loss: 0.1003 train_auc: 0.8917	val_loss: 0.0775 val_auc: 0.8094	test_loss: 0.1338 test_auc: 0.7604
2025-06-20 02:18:42,231 - INFO - train: {'epoch': 32, 'time_epoch': 68.48856, 'eta': 4435.50736, 'eta_hours': 1.23209, 'loss': 0.0984618, 'lr': 8.136e-05, 'params': 514193, 'time_iter': 0.06656, 'accuracy': 0.97043, 'precision': 0.71334, 'recall': 0.35146, 'f1': 0.47091, 'auc': 0.9016}
2025-06-20 02:18:45,581 - INFO - val: {'epoch': 32, 'time_epoch': 3.3225, 'loss': 0.07825407, 'lr': 0, 'params': 514193, 'time_iter': 0.02576, 'accuracy': 0.98249, 'precision': 0.60976, 'recall': 0.30864, 'f1': 0.40984, 'auc': 0.78918}
2025-06-20 02:18:49,108 - INFO - test: {'epoch': 32, 'time_epoch': 3.50529, 'loss': 0.12769729, 'lr': 0, 'params': 514193, 'time_iter': 0.02717, 'accuracy': 0.96937, 'precision': 0.53448, 'recall': 0.23846, 'f1': 0.32979, 'auc': 0.76144}
2025-06-20 02:18:49,111 - INFO - > Epoch 32: took 75.6s (avg 73.4s) | Best so far: epoch 30	train_loss: 0.1003 train_auc: 0.8917	val_loss: 0.0775 val_auc: 0.8094	test_loss: 0.1338 test_auc: 0.7604
2025-06-20 02:19:58,074 - INFO - train: {'epoch': 33, 'time_epoch': 68.75553, 'eta': 4374.26338, 'eta_hours': 1.21507, 'loss': 0.09663737, 'lr': 8.005e-05, 'params': 514193, 'time_iter': 0.06682, 'accuracy': 0.97179, 'precision': 0.75083, 'recall': 0.36932, 'f1': 0.4951, 'auc': 0.90274}
2025-06-20 02:20:01,685 - INFO - val: {'epoch': 33, 'time_epoch': 3.57937, 'loss': 0.0921169, 'lr': 0, 'params': 514193, 'time_iter': 0.02775, 'accuracy': 0.97763, 'precision': 0.41791, 'recall': 0.34568, 'f1': 0.37838, 'auc': 0.78715}
2025-06-20 02:20:05,049 - INFO - test: {'epoch': 33, 'time_epoch': 3.34074, 'loss': 0.13157274, 'lr': 0, 'params': 514193, 'time_iter': 0.0259, 'accuracy': 0.96353, 'precision': 0.40741, 'recall': 0.33846, 'f1': 0.36975, 'auc': 0.77359}
2025-06-20 02:20:05,052 - INFO - > Epoch 33: took 75.9s (avg 73.5s) | Best so far: epoch 30	train_loss: 0.1003 train_auc: 0.8917	val_loss: 0.0775 val_auc: 0.8094	test_loss: 0.1338 test_auc: 0.7604
2025-06-20 02:21:12,721 - INFO - train: {'epoch': 34, 'time_epoch': 67.50149, 'eta': 4310.26124, 'eta_hours': 1.19729, 'loss': 0.0974949, 'lr': 7.872e-05, 'params': 514193, 'time_iter': 0.0656, 'accuracy': 0.97192, 'precision': 0.75081, 'recall': 0.37419, 'f1': 0.49946, 'auc': 0.89901}
2025-06-20 02:21:16,331 - INFO - val: {'epoch': 34, 'time_epoch': 3.58062, 'loss': 0.0795143, 'lr': 0, 'params': 514193, 'time_iter': 0.02776, 'accuracy': 0.98079, 'precision': 0.52273, 'recall': 0.28395, 'f1': 0.368, 'auc': 0.80281}
2025-06-20 02:21:19,674 - INFO - test: {'epoch': 34, 'time_epoch': 3.32355, 'loss': 0.12846772, 'lr': 0, 'params': 514193, 'time_iter': 0.02576, 'accuracy': 0.96718, 'precision': 0.45763, 'recall': 0.20769, 'f1': 0.28571, 'auc': 0.75472}
2025-06-20 02:21:19,676 - INFO - > Epoch 34: took 74.6s (avg 73.5s) | Best so far: epoch 30	train_loss: 0.1003 train_auc: 0.8917	val_loss: 0.0775 val_auc: 0.8094	test_loss: 0.1338 test_auc: 0.7604
2025-06-20 02:22:24,968 - INFO - train: {'epoch': 35, 'time_epoch': 65.09136, 'eta': 4241.78001, 'eta_hours': 1.17827, 'loss': 0.09546194, 'lr': 7.735e-05, 'params': 514193, 'time_iter': 0.06326, 'accuracy': 0.97195, 'precision': 0.74563, 'recall': 0.38068, 'f1': 0.50403, 'auc': 0.90468}
2025-06-20 02:22:28,415 - INFO - val: {'epoch': 35, 'time_epoch': 3.41271, 'loss': 0.08437058, 'lr': 0, 'params': 514193, 'time_iter': 0.02646, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.32099, 'f1': 0.39098, 'auc': 0.78081}
2025-06-20 02:22:31,834 - INFO - test: {'epoch': 35, 'time_epoch': 3.39675, 'loss': 0.13751894, 'lr': 0, 'params': 514193, 'time_iter': 0.02633, 'accuracy': 0.96645, 'precision': 0.43333, 'recall': 0.2, 'f1': 0.27368, 'auc': 0.73057}
2025-06-20 02:22:31,836 - INFO - > Epoch 35: took 72.2s (avg 73.5s) | Best so far: epoch 30	train_loss: 0.1003 train_auc: 0.8917	val_loss: 0.0775 val_auc: 0.8094	test_loss: 0.1338 test_auc: 0.7604
2025-06-20 02:23:40,766 - INFO - train: {'epoch': 36, 'time_epoch': 68.72221, 'eta': 4179.66428, 'eta_hours': 1.16102, 'loss': 0.09413647, 'lr': 7.595e-05, 'params': 514193, 'time_iter': 0.06679, 'accuracy': 0.97265, 'precision': 0.7546, 'recall': 0.39935, 'f1': 0.52229, 'auc': 0.90829}
2025-06-20 02:23:44,183 - INFO - val: {'epoch': 36, 'time_epoch': 3.39044, 'loss': 0.08758993, 'lr': 0, 'params': 514193, 'time_iter': 0.02628, 'accuracy': 0.97739, 'precision': 0.40625, 'recall': 0.32099, 'f1': 0.35862, 'auc': 0.79968}
2025-06-20 02:23:47,571 - INFO - test: {'epoch': 36, 'time_epoch': 3.36713, 'loss': 0.13792627, 'lr': 0, 'params': 514193, 'time_iter': 0.0261, 'accuracy': 0.96475, 'precision': 0.41176, 'recall': 0.26923, 'f1': 0.32558, 'auc': 0.73888}
2025-06-20 02:23:47,573 - INFO - > Epoch 36: took 75.7s (avg 73.6s) | Best so far: epoch 30	train_loss: 0.1003 train_auc: 0.8917	val_loss: 0.0775 val_auc: 0.8094	test_loss: 0.1338 test_auc: 0.7604
2025-06-20 02:24:55,525 - INFO - train: {'epoch': 37, 'time_epoch': 67.75838, 'eta': 4115.62827, 'eta_hours': 1.14323, 'loss': 0.09434427, 'lr': 7.452e-05, 'params': 514193, 'time_iter': 0.06585, 'accuracy': 0.97152, 'precision': 0.73376, 'recall': 0.37581, 'f1': 0.49705, 'auc': 0.91116}
2025-06-20 02:24:58,904 - INFO - val: {'epoch': 37, 'time_epoch': 3.3517, 'loss': 0.08214883, 'lr': 0, 'params': 514193, 'time_iter': 0.02598, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.32099, 'f1': 0.39098, 'auc': 0.80647}
2025-06-20 02:25:02,274 - INFO - test: {'epoch': 37, 'time_epoch': 3.34994, 'loss': 0.14220256, 'lr': 0, 'params': 514193, 'time_iter': 0.02597, 'accuracy': 0.96426, 'precision': 0.38356, 'recall': 0.21538, 'f1': 0.27586, 'auc': 0.74184}
2025-06-20 02:25:02,277 - INFO - > Epoch 37: took 74.7s (avg 73.6s) | Best so far: epoch 30	train_loss: 0.1003 train_auc: 0.8917	val_loss: 0.0775 val_auc: 0.8094	test_loss: 0.1338 test_auc: 0.7604
2025-06-20 02:26:08,794 - INFO - train: {'epoch': 38, 'time_epoch': 66.30933, 'eta': 4049.13491, 'eta_hours': 1.12476, 'loss': 0.09355632, 'lr': 7.307e-05, 'params': 514193, 'time_iter': 0.06444, 'accuracy': 0.97277, 'precision': 0.76498, 'recall': 0.39367, 'f1': 0.51983, 'auc': 0.90962}
2025-06-20 02:26:12,123 - INFO - val: {'epoch': 38, 'time_epoch': 3.30061, 'loss': 0.07578753, 'lr': 0, 'params': 514193, 'time_iter': 0.02559, 'accuracy': 0.98177, 'precision': 0.58824, 'recall': 0.24691, 'f1': 0.34783, 'auc': 0.81013}
2025-06-20 02:26:15,435 - INFO - test: {'epoch': 38, 'time_epoch': 3.28922, 'loss': 0.13149206, 'lr': 0, 'params': 514193, 'time_iter': 0.0255, 'accuracy': 0.96815, 'precision': 0.48276, 'recall': 0.10769, 'f1': 0.1761, 'auc': 0.73777}
2025-06-20 02:26:15,438 - INFO - > Epoch 38: took 73.2s (avg 73.6s) | Best so far: epoch 38	train_loss: 0.0936 train_auc: 0.9096	val_loss: 0.0758 val_auc: 0.8101	test_loss: 0.1315 test_auc: 0.7378
2025-06-20 02:27:19,581 - INFO - train: {'epoch': 39, 'time_epoch': 64.0234, 'eta': 3979.22186, 'eta_hours': 1.10534, 'loss': 0.09255768, 'lr': 7.159e-05, 'params': 514193, 'time_iter': 0.06222, 'accuracy': 0.97246, 'precision': 0.75873, 'recall': 0.38799, 'f1': 0.51343, 'auc': 0.91605}
2025-06-20 02:27:22,855 - INFO - val: {'epoch': 39, 'time_epoch': 3.24667, 'loss': 0.08474635, 'lr': 0, 'params': 514193, 'time_iter': 0.02517, 'accuracy': 0.97836, 'precision': 0.43333, 'recall': 0.32099, 'f1': 0.36879, 'auc': 0.80688}
2025-06-20 02:27:26,256 - INFO - test: {'epoch': 39, 'time_epoch': 3.37967, 'loss': 0.14003093, 'lr': 0, 'params': 514193, 'time_iter': 0.0262, 'accuracy': 0.96548, 'precision': 0.42683, 'recall': 0.26923, 'f1': 0.33019, 'auc': 0.75295}
2025-06-20 02:27:26,260 - INFO - > Epoch 39: took 70.8s (avg 73.5s) | Best so far: epoch 38	train_loss: 0.0936 train_auc: 0.9096	val_loss: 0.0758 val_auc: 0.8101	test_loss: 0.1315 test_auc: 0.7378
2025-06-20 02:28:32,148 - INFO - train: {'epoch': 40, 'time_epoch': 65.70121, 'eta': 3912.01051, 'eta_hours': 1.08667, 'loss': 0.08936176, 'lr': 7.008e-05, 'params': 514193, 'time_iter': 0.06385, 'accuracy': 0.97328, 'precision': 0.77196, 'recall': 0.40666, 'f1': 0.5327, 'auc': 0.92274}
2025-06-20 02:28:35,537 - INFO - val: {'epoch': 40, 'time_epoch': 3.36068, 'loss': 0.0920558, 'lr': 0, 'params': 514193, 'time_iter': 0.02605, 'accuracy': 0.9752, 'precision': 0.37037, 'recall': 0.37037, 'f1': 0.37037, 'auc': 0.81023}
2025-06-20 02:28:38,937 - INFO - test: {'epoch': 40, 'time_epoch': 3.37999, 'loss': 0.14876932, 'lr': 0, 'params': 514193, 'time_iter': 0.0262, 'accuracy': 0.95988, 'precision': 0.34513, 'recall': 0.3, 'f1': 0.32099, 'auc': 0.75137}
2025-06-20 02:28:38,940 - INFO - > Epoch 40: took 72.7s (avg 73.5s) | Best so far: epoch 40	train_loss: 0.0894 train_auc: 0.9227	val_loss: 0.0921 val_auc: 0.8102	test_loss: 0.1488 test_auc: 0.7514
2025-06-20 02:29:44,848 - INFO - train: {'epoch': 41, 'time_epoch': 65.74035, 'eta': 3844.92514, 'eta_hours': 1.06803, 'loss': 0.09019039, 'lr': 6.856e-05, 'params': 514193, 'time_iter': 0.06389, 'accuracy': 0.97301, 'precision': 0.76791, 'recall': 0.40016, 'f1': 0.52615, 'auc': 0.92118}
2025-06-20 02:29:48,253 - INFO - val: {'epoch': 41, 'time_epoch': 3.37691, 'loss': 0.09051422, 'lr': 0, 'params': 514193, 'time_iter': 0.02618, 'accuracy': 0.97763, 'precision': 0.4127, 'recall': 0.32099, 'f1': 0.36111, 'auc': 0.78719}
2025-06-20 02:29:51,638 - INFO - test: {'epoch': 41, 'time_epoch': 3.36504, 'loss': 0.13527386, 'lr': 0, 'params': 514193, 'time_iter': 0.02609, 'accuracy': 0.96572, 'precision': 0.4321, 'recall': 0.26923, 'f1': 0.33175, 'auc': 0.75388}
2025-06-20 02:29:51,642 - INFO - > Epoch 41: took 72.7s (avg 73.5s) | Best so far: epoch 40	train_loss: 0.0894 train_auc: 0.9227	val_loss: 0.0921 val_auc: 0.8102	test_loss: 0.1488 test_auc: 0.7514
2025-06-20 02:30:58,986 - INFO - train: {'epoch': 42, 'time_epoch': 67.17032, 'eta': 3779.79786, 'eta_hours': 1.04994, 'loss': 0.09043771, 'lr': 6.701e-05, 'params': 514193, 'time_iter': 0.06528, 'accuracy': 0.97395, 'precision': 0.78027, 'recall': 0.4237, 'f1': 0.54918, 'auc': 0.92238}
2025-06-20 02:31:02,377 - INFO - val: {'epoch': 42, 'time_epoch': 3.36351, 'loss': 0.08458152, 'lr': 0, 'params': 514193, 'time_iter': 0.02607, 'accuracy': 0.97788, 'precision': 0.41379, 'recall': 0.2963, 'f1': 0.34532, 'auc': 0.81035}
2025-06-20 02:31:05,753 - INFO - test: {'epoch': 42, 'time_epoch': 3.35604, 'loss': 0.13189354, 'lr': 0, 'params': 514193, 'time_iter': 0.02602, 'accuracy': 0.96669, 'precision': 0.45333, 'recall': 0.26154, 'f1': 0.33171, 'auc': 0.76627}
2025-06-20 02:31:05,755 - INFO - > Epoch 42: took 74.1s (avg 73.5s) | Best so far: epoch 42	train_loss: 0.0904 train_auc: 0.9224	val_loss: 0.0846 val_auc: 0.8104	test_loss: 0.1319 test_auc: 0.7663
2025-06-20 02:32:13,676 - INFO - train: {'epoch': 43, 'time_epoch': 67.72776, 'eta': 3715.28718, 'eta_hours': 1.03202, 'loss': 0.09018385, 'lr': 6.545e-05, 'params': 514193, 'time_iter': 0.06582, 'accuracy': 0.97265, 'precision': 0.75305, 'recall': 0.40097, 'f1': 0.52331, 'auc': 0.92416}
2025-06-20 02:32:17,196 - INFO - val: {'epoch': 43, 'time_epoch': 3.48282, 'loss': 0.08718721, 'lr': 0, 'params': 514193, 'time_iter': 0.027, 'accuracy': 0.97715, 'precision': 0.41096, 'recall': 0.37037, 'f1': 0.38961, 'auc': 0.81314}
2025-06-20 02:32:20,664 - INFO - test: {'epoch': 43, 'time_epoch': 3.44413, 'loss': 0.1440318, 'lr': 0, 'params': 514193, 'time_iter': 0.0267, 'accuracy': 0.96329, 'precision': 0.3871, 'recall': 0.27692, 'f1': 0.32287, 'auc': 0.75053}
2025-06-20 02:32:20,668 - INFO - > Epoch 43: took 74.9s (avg 73.5s) | Best so far: epoch 43	train_loss: 0.0902 train_auc: 0.9242	val_loss: 0.0872 val_auc: 0.8131	test_loss: 0.1440 test_auc: 0.7505
2025-06-20 02:33:29,638 - INFO - train: {'epoch': 44, 'time_epoch': 68.78233, 'eta': 3651.92244, 'eta_hours': 1.01442, 'loss': 0.08827362, 'lr': 6.387e-05, 'params': 514193, 'time_iter': 0.06684, 'accuracy': 0.97386, 'precision': 0.77353, 'recall': 0.42695, 'f1': 0.55021, 'auc': 0.92406}
2025-06-20 02:33:33,355 - INFO - val: {'epoch': 44, 'time_epoch': 3.68717, 'loss': 0.07770631, 'lr': 0, 'params': 514193, 'time_iter': 0.02858, 'accuracy': 0.98249, 'precision': 0.6, 'recall': 0.33333, 'f1': 0.42857, 'auc': 0.81141}
2025-06-20 02:33:36,778 - INFO - test: {'epoch': 44, 'time_epoch': 3.40388, 'loss': 0.13755588, 'lr': 0, 'params': 514193, 'time_iter': 0.02639, 'accuracy': 0.96742, 'precision': 0.45833, 'recall': 0.16923, 'f1': 0.24719, 'auc': 0.74998}
2025-06-20 02:33:36,781 - INFO - > Epoch 44: took 76.1s (avg 73.6s) | Best so far: epoch 43	train_loss: 0.0902 train_auc: 0.9242	val_loss: 0.0872 val_auc: 0.8131	test_loss: 0.1440 test_auc: 0.7505
2025-06-20 02:34:44,829 - INFO - train: {'epoch': 45, 'time_epoch': 67.82087, 'eta': 3587.19348, 'eta_hours': 0.99644, 'loss': 0.08665879, 'lr': 6.227e-05, 'params': 514193, 'time_iter': 0.06591, 'accuracy': 0.9742, 'precision': 0.78539, 'recall': 0.42776, 'f1': 0.55386, 'auc': 0.92763}
2025-06-20 02:34:48,424 - INFO - val: {'epoch': 45, 'time_epoch': 3.56157, 'loss': 0.08356351, 'lr': 0, 'params': 514193, 'time_iter': 0.02761, 'accuracy': 0.98055, 'precision': 0.50877, 'recall': 0.35802, 'f1': 0.42029, 'auc': 0.81487}
2025-06-20 02:34:51,831 - INFO - test: {'epoch': 45, 'time_epoch': 3.38612, 'loss': 0.15149751, 'lr': 0, 'params': 514193, 'time_iter': 0.02625, 'accuracy': 0.96669, 'precision': 0.4507, 'recall': 0.24615, 'f1': 0.31841, 'auc': 0.7371}
2025-06-20 02:34:51,835 - INFO - > Epoch 45: took 75.1s (avg 73.6s) | Best so far: epoch 45	train_loss: 0.0867 train_auc: 0.9276	val_loss: 0.0836 val_auc: 0.8149	test_loss: 0.1515 test_auc: 0.7371
2025-06-20 02:36:00,078 - INFO - train: {'epoch': 46, 'time_epoch': 68.02536, 'eta': 3522.56354, 'eta_hours': 0.97849, 'loss': 0.08634024, 'lr': 6.066e-05, 'params': 514193, 'time_iter': 0.06611, 'accuracy': 0.97486, 'precision': 0.78401, 'recall': 0.45373, 'f1': 0.57481, 'auc': 0.92865}
2025-06-20 02:36:03,625 - INFO - val: {'epoch': 46, 'time_epoch': 3.51427, 'loss': 0.07688185, 'lr': 0, 'params': 514193, 'time_iter': 0.02724, 'accuracy': 0.98249, 'precision': 0.6, 'recall': 0.33333, 'f1': 0.42857, 'auc': 0.80338}
2025-06-20 02:36:07,138 - INFO - test: {'epoch': 46, 'time_epoch': 3.49027, 'loss': 0.13556391, 'lr': 0, 'params': 514193, 'time_iter': 0.02706, 'accuracy': 0.96912, 'precision': 0.53191, 'recall': 0.19231, 'f1': 0.28249, 'auc': 0.73216}
2025-06-20 02:36:07,141 - INFO - > Epoch 46: took 75.3s (avg 73.6s) | Best so far: epoch 45	train_loss: 0.0867 train_auc: 0.9276	val_loss: 0.0836 val_auc: 0.8149	test_loss: 0.1515 test_auc: 0.7371
2025-06-20 02:37:12,619 - INFO - train: {'epoch': 47, 'time_epoch': 65.2977, 'eta': 3454.83716, 'eta_hours': 0.95968, 'loss': 0.08517562, 'lr': 5.904e-05, 'params': 514193, 'time_iter': 0.06346, 'accuracy': 0.97502, 'precision': 0.78955, 'recall': 0.45373, 'f1': 0.57629, 'auc': 0.93362}
2025-06-20 02:37:16,108 - INFO - val: {'epoch': 47, 'time_epoch': 3.45632, 'loss': 0.08054501, 'lr': 0, 'params': 514193, 'time_iter': 0.02679, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.34568, 'f1': 0.40876, 'auc': 0.80442}
2025-06-20 02:37:19,595 - INFO - test: {'epoch': 47, 'time_epoch': 3.45916, 'loss': 0.13843293, 'lr': 0, 'params': 514193, 'time_iter': 0.02682, 'accuracy': 0.96645, 'precision': 0.44872, 'recall': 0.26923, 'f1': 0.33654, 'auc': 0.75383}
2025-06-20 02:37:19,601 - INFO - > Epoch 47: took 72.5s (avg 73.6s) | Best so far: epoch 45	train_loss: 0.0867 train_auc: 0.9276	val_loss: 0.0836 val_auc: 0.8149	test_loss: 0.1515 test_auc: 0.7371
2025-06-20 02:38:26,107 - INFO - train: {'epoch': 48, 'time_epoch': 66.291, 'eta': 3388.24377, 'eta_hours': 0.94118, 'loss': 0.08346957, 'lr': 5.741e-05, 'params': 514193, 'time_iter': 0.06442, 'accuracy': 0.97465, 'precision': 0.77716, 'recall': 0.45292, 'f1': 0.57231, 'auc': 0.93609}
2025-06-20 02:38:29,560 - INFO - val: {'epoch': 48, 'time_epoch': 3.42479, 'loss': 0.08205889, 'lr': 0, 'params': 514193, 'time_iter': 0.02655, 'accuracy': 0.98079, 'precision': 0.52381, 'recall': 0.2716, 'f1': 0.35772, 'auc': 0.80031}
2025-06-20 02:38:33,075 - INFO - test: {'epoch': 48, 'time_epoch': 3.49201, 'loss': 0.15167022, 'lr': 0, 'params': 514193, 'time_iter': 0.02707, 'accuracy': 0.9662, 'precision': 0.36364, 'recall': 0.09231, 'f1': 0.14724, 'auc': 0.72418}
2025-06-20 02:38:33,078 - INFO - > Epoch 48: took 73.5s (avg 73.6s) | Best so far: epoch 45	train_loss: 0.0867 train_auc: 0.9276	val_loss: 0.0836 val_auc: 0.8149	test_loss: 0.1515 test_auc: 0.7371
2025-06-20 02:39:41,531 - INFO - train: {'epoch': 49, 'time_epoch': 68.26694, 'eta': 3323.6384, 'eta_hours': 0.92323, 'loss': 0.0844656, 'lr': 5.577e-05, 'params': 514193, 'time_iter': 0.06634, 'accuracy': 0.97483, 'precision': 0.7752, 'recall': 0.46185, 'f1': 0.57884, 'auc': 0.93309}
2025-06-20 02:39:45,115 - INFO - val: {'epoch': 49, 'time_epoch': 3.55453, 'loss': 0.08896619, 'lr': 0, 'params': 514193, 'time_iter': 0.02755, 'accuracy': 0.97836, 'precision': 0.44595, 'recall': 0.40741, 'f1': 0.42581, 'auc': 0.80034}
2025-06-20 02:39:48,632 - INFO - test: {'epoch': 49, 'time_epoch': 3.49603, 'loss': 0.15205451, 'lr': 0, 'params': 514193, 'time_iter': 0.0271, 'accuracy': 0.9645, 'precision': 0.40698, 'recall': 0.26923, 'f1': 0.32407, 'auc': 0.73101}
2025-06-20 02:39:48,635 - INFO - > Epoch 49: took 75.6s (avg 73.7s) | Best so far: epoch 45	train_loss: 0.0867 train_auc: 0.9276	val_loss: 0.0836 val_auc: 0.8149	test_loss: 0.1515 test_auc: 0.7371
2025-06-20 02:40:57,440 - INFO - train: {'epoch': 50, 'time_epoch': 68.62245, 'eta': 3259.23102, 'eta_hours': 0.90534, 'loss': 0.08258678, 'lr': 5.413e-05, 'params': 514193, 'time_iter': 0.06669, 'accuracy': 0.97492, 'precision': 0.78541, 'recall': 0.45455, 'f1': 0.57584, 'auc': 0.941}
2025-06-20 02:41:00,938 - INFO - val: {'epoch': 50, 'time_epoch': 3.46945, 'loss': 0.08930347, 'lr': 0, 'params': 514193, 'time_iter': 0.02689, 'accuracy': 0.97715, 'precision': 0.40845, 'recall': 0.35802, 'f1': 0.38158, 'auc': 0.80646}
2025-06-20 02:41:04,379 - INFO - test: {'epoch': 50, 'time_epoch': 3.42074, 'loss': 0.15073735, 'lr': 0, 'params': 514193, 'time_iter': 0.02652, 'accuracy': 0.96353, 'precision': 0.37805, 'recall': 0.23846, 'f1': 0.29245, 'auc': 0.75899}
2025-06-20 02:41:04,382 - INFO - > Epoch 50: took 75.7s (avg 73.7s) | Best so far: epoch 45	train_loss: 0.0867 train_auc: 0.9276	val_loss: 0.0836 val_auc: 0.8149	test_loss: 0.1515 test_auc: 0.7371
2025-06-20 02:42:14,114 - INFO - train: {'epoch': 51, 'time_epoch': 69.53347, 'eta': 3195.50245, 'eta_hours': 0.88764, 'loss': 0.08244201, 'lr': 5.248e-05, 'params': 514193, 'time_iter': 0.06757, 'accuracy': 0.9752, 'precision': 0.78261, 'recall': 0.46753, 'f1': 0.58537, 'auc': 0.93792}
2025-06-20 02:42:17,672 - INFO - val: {'epoch': 51, 'time_epoch': 3.52846, 'loss': 0.08193504, 'lr': 0, 'params': 514193, 'time_iter': 0.02735, 'accuracy': 0.98128, 'precision': 0.54348, 'recall': 0.30864, 'f1': 0.3937, 'auc': 0.80102}
2025-06-20 02:42:21,185 - INFO - test: {'epoch': 51, 'time_epoch': 3.49215, 'loss': 0.14399286, 'lr': 0, 'params': 514193, 'time_iter': 0.02707, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.20769, 'f1': 0.29348, 'auc': 0.73557}
2025-06-20 02:42:21,187 - INFO - > Epoch 51: took 76.8s (avg 73.8s) | Best so far: epoch 45	train_loss: 0.0867 train_auc: 0.9276	val_loss: 0.0836 val_auc: 0.8149	test_loss: 0.1515 test_auc: 0.7371
2025-06-20 02:43:30,062 - INFO - train: {'epoch': 52, 'time_epoch': 68.69464, 'eta': 3130.81097, 'eta_hours': 0.86967, 'loss': 0.07944393, 'lr': 5.083e-05, 'params': 514193, 'time_iter': 0.06676, 'accuracy': 0.97477, 'precision': 0.7731, 'recall': 0.46185, 'f1': 0.57825, 'auc': 0.9493}
2025-06-20 02:43:33,548 - INFO - val: {'epoch': 52, 'time_epoch': 3.45992, 'loss': 0.08333147, 'lr': 0, 'params': 514193, 'time_iter': 0.02682, 'accuracy': 0.98104, 'precision': 0.52941, 'recall': 0.33333, 'f1': 0.40909, 'auc': 0.80937}
2025-06-20 02:43:37,035 - INFO - test: {'epoch': 52, 'time_epoch': 3.46582, 'loss': 0.15121739, 'lr': 0, 'params': 514193, 'time_iter': 0.02687, 'accuracy': 0.96815, 'precision': 0.4902, 'recall': 0.19231, 'f1': 0.27624, 'auc': 0.73522}
2025-06-20 02:43:37,039 - INFO - > Epoch 52: took 75.9s (avg 73.8s) | Best so far: epoch 45	train_loss: 0.0867 train_auc: 0.9276	val_loss: 0.0836 val_auc: 0.8149	test_loss: 0.1515 test_auc: 0.7371
2025-06-20 02:44:45,345 - INFO - train: {'epoch': 53, 'time_epoch': 68.10677, 'eta': 3065.47044, 'eta_hours': 0.85152, 'loss': 0.08333411, 'lr': 4.917e-05, 'params': 514193, 'time_iter': 0.06619, 'accuracy': 0.97416, 'precision': 0.76751, 'recall': 0.44481, 'f1': 0.56321, 'auc': 0.94051}
2025-06-20 02:44:48,884 - INFO - val: {'epoch': 53, 'time_epoch': 3.51171, 'loss': 0.08211663, 'lr': 0, 'params': 514193, 'time_iter': 0.02722, 'accuracy': 0.97982, 'precision': 0.48333, 'recall': 0.35802, 'f1': 0.41135, 'auc': 0.80959}
2025-06-20 02:44:52,393 - INFO - test: {'epoch': 53, 'time_epoch': 3.48668, 'loss': 0.1478429, 'lr': 0, 'params': 514193, 'time_iter': 0.02703, 'accuracy': 0.9645, 'precision': 0.39474, 'recall': 0.23077, 'f1': 0.29126, 'auc': 0.75076}
2025-06-20 02:44:52,396 - INFO - > Epoch 53: took 75.4s (avg 73.8s) | Best so far: epoch 45	train_loss: 0.0867 train_auc: 0.9276	val_loss: 0.0836 val_auc: 0.8149	test_loss: 0.1515 test_auc: 0.7371
2025-06-20 02:46:00,944 - INFO - train: {'epoch': 54, 'time_epoch': 68.36931, 'eta': 3000.24413, 'eta_hours': 0.8334, 'loss': 0.08143715, 'lr': 4.752e-05, 'params': 514193, 'time_iter': 0.06644, 'accuracy': 0.9755, 'precision': 0.7894, 'recall': 0.47159, 'f1': 0.59045, 'auc': 0.94284}
2025-06-20 02:46:04,511 - INFO - val: {'epoch': 54, 'time_epoch': 3.53623, 'loss': 0.08251067, 'lr': 0, 'params': 514193, 'time_iter': 0.02741, 'accuracy': 0.98152, 'precision': 0.54545, 'recall': 0.37037, 'f1': 0.44118, 'auc': 0.80526}
2025-06-20 02:46:08,052 - INFO - test: {'epoch': 54, 'time_epoch': 3.51977, 'loss': 0.14229121, 'lr': 0, 'params': 514193, 'time_iter': 0.02729, 'accuracy': 0.9662, 'precision': 0.42623, 'recall': 0.2, 'f1': 0.27225, 'auc': 0.75492}
2025-06-20 02:46:08,055 - INFO - > Epoch 54: took 75.7s (avg 73.9s) | Best so far: epoch 45	train_loss: 0.0867 train_auc: 0.9276	val_loss: 0.0836 val_auc: 0.8149	test_loss: 0.1515 test_auc: 0.7371
2025-06-20 02:47:16,836 - INFO - train: {'epoch': 55, 'time_epoch': 68.61029, 'eta': 2935.09491, 'eta_hours': 0.8153, 'loss': 0.07873556, 'lr': 4.587e-05, 'params': 514193, 'time_iter': 0.06668, 'accuracy': 0.97614, 'precision': 0.78913, 'recall': 0.49513, 'f1': 0.60848, 'auc': 0.94748}
2025-06-20 02:47:20,447 - INFO - val: {'epoch': 55, 'time_epoch': 3.58325, 'loss': 0.08954702, 'lr': 0, 'params': 514193, 'time_iter': 0.02778, 'accuracy': 0.97982, 'precision': 0.48214, 'recall': 0.33333, 'f1': 0.39416, 'auc': 0.78699}
2025-06-20 02:47:23,931 - INFO - test: {'epoch': 55, 'time_epoch': 3.46222, 'loss': 0.14805927, 'lr': 0, 'params': 514193, 'time_iter': 0.02684, 'accuracy': 0.9662, 'precision': 0.43836, 'recall': 0.24615, 'f1': 0.31527, 'auc': 0.75361}
2025-06-20 02:47:23,933 - INFO - > Epoch 55: took 75.9s (avg 73.9s) | Best so far: epoch 45	train_loss: 0.0867 train_auc: 0.9276	val_loss: 0.0836 val_auc: 0.8149	test_loss: 0.1515 test_auc: 0.7371
2025-06-20 02:48:32,314 - INFO - train: {'epoch': 56, 'time_epoch': 68.20567, 'eta': 2869.519, 'eta_hours': 0.79709, 'loss': 0.0784545, 'lr': 4.423e-05, 'params': 514193, 'time_iter': 0.06628, 'accuracy': 0.97587, 'precision': 0.8, 'recall': 0.47403, 'f1': 0.59531, 'auc': 0.95097}
2025-06-20 02:48:35,804 - INFO - val: {'epoch': 56, 'time_epoch': 3.4627, 'loss': 0.08866808, 'lr': 0, 'params': 514193, 'time_iter': 0.02684, 'accuracy': 0.97812, 'precision': 0.43836, 'recall': 0.39506, 'f1': 0.41558, 'auc': 0.81771}
2025-06-20 02:48:39,321 - INFO - test: {'epoch': 56, 'time_epoch': 3.49464, 'loss': 0.15154119, 'lr': 0, 'params': 514193, 'time_iter': 0.02709, 'accuracy': 0.96231, 'precision': 0.38095, 'recall': 0.30769, 'f1': 0.34043, 'auc': 0.75331}
2025-06-20 02:48:39,323 - INFO - > Epoch 56: took 75.4s (avg 73.9s) | Best so far: epoch 56	train_loss: 0.0785 train_auc: 0.9510	val_loss: 0.0887 val_auc: 0.8177	test_loss: 0.1515 test_auc: 0.7533
2025-06-20 02:49:47,550 - INFO - train: {'epoch': 57, 'time_epoch': 68.03431, 'eta': 2803.72833, 'eta_hours': 0.77881, 'loss': 0.07929453, 'lr': 4.259e-05, 'params': 514193, 'time_iter': 0.06612, 'accuracy': 0.97559, 'precision': 0.79916, 'recall': 0.4651, 'f1': 0.58799, 'auc': 0.9477}
2025-06-20 02:49:51,279 - INFO - val: {'epoch': 57, 'time_epoch': 3.70155, 'loss': 0.09358465, 'lr': 0, 'params': 514193, 'time_iter': 0.02869, 'accuracy': 0.97715, 'precision': 0.4058, 'recall': 0.34568, 'f1': 0.37333, 'auc': 0.81442}
2025-06-20 02:49:54,833 - INFO - test: {'epoch': 57, 'time_epoch': 3.53321, 'loss': 0.15944678, 'lr': 0, 'params': 514193, 'time_iter': 0.02739, 'accuracy': 0.96256, 'precision': 0.37755, 'recall': 0.28462, 'f1': 0.32456, 'auc': 0.74702}
2025-06-20 02:49:54,836 - INFO - > Epoch 57: took 75.5s (avg 73.9s) | Best so far: epoch 56	train_loss: 0.0785 train_auc: 0.9510	val_loss: 0.0887 val_auc: 0.8177	test_loss: 0.1515 test_auc: 0.7533
2025-06-20 02:51:04,043 - INFO - train: {'epoch': 58, 'time_epoch': 69.01157, 'eta': 2738.54072, 'eta_hours': 0.76071, 'loss': 0.07678948, 'lr': 4.096e-05, 'params': 514193, 'time_iter': 0.06707, 'accuracy': 0.97657, 'precision': 0.80131, 'recall': 0.49756, 'f1': 0.61392, 'auc': 0.95017}
2025-06-20 02:51:07,630 - INFO - val: {'epoch': 58, 'time_epoch': 3.55585, 'loss': 0.0898827, 'lr': 0, 'params': 514193, 'time_iter': 0.02756, 'accuracy': 0.97982, 'precision': 0.48387, 'recall': 0.37037, 'f1': 0.41958, 'auc': 0.82161}
2025-06-20 02:51:11,214 - INFO - test: {'epoch': 58, 'time_epoch': 3.5597, 'loss': 0.15916951, 'lr': 0, 'params': 514193, 'time_iter': 0.02759, 'accuracy': 0.96548, 'precision': 0.42105, 'recall': 0.24615, 'f1': 0.31068, 'auc': 0.74154}
2025-06-20 02:51:11,217 - INFO - > Epoch 58: took 76.4s (avg 74.0s) | Best so far: epoch 58	train_loss: 0.0768 train_auc: 0.9502	val_loss: 0.0899 val_auc: 0.8216	test_loss: 0.1592 test_auc: 0.7415
2025-06-20 02:52:19,582 - INFO - train: {'epoch': 59, 'time_epoch': 68.18255, 'eta': 2672.67295, 'eta_hours': 0.74241, 'loss': 0.07719267, 'lr': 3.934e-05, 'params': 514193, 'time_iter': 0.06626, 'accuracy': 0.97644, 'precision': 0.79791, 'recall': 0.49675, 'f1': 0.61231, 'auc': 0.9504}
2025-06-20 02:52:23,108 - INFO - val: {'epoch': 59, 'time_epoch': 3.49553, 'loss': 0.0890888, 'lr': 0, 'params': 514193, 'time_iter': 0.0271, 'accuracy': 0.97958, 'precision': 0.47273, 'recall': 0.32099, 'f1': 0.38235, 'auc': 0.80029}
2025-06-20 02:52:26,611 - INFO - test: {'epoch': 59, 'time_epoch': 3.4809, 'loss': 0.15999239, 'lr': 0, 'params': 514193, 'time_iter': 0.02698, 'accuracy': 0.96426, 'precision': 0.37313, 'recall': 0.19231, 'f1': 0.25381, 'auc': 0.73689}
2025-06-20 02:52:26,614 - INFO - > Epoch 59: took 75.4s (avg 74.0s) | Best so far: epoch 58	train_loss: 0.0768 train_auc: 0.9502	val_loss: 0.0899 val_auc: 0.8216	test_loss: 0.1592 test_auc: 0.7415
2025-06-20 02:53:34,332 - INFO - train: {'epoch': 60, 'time_epoch': 67.48944, 'eta': 2606.28616, 'eta_hours': 0.72397, 'loss': 0.07515168, 'lr': 3.773e-05, 'params': 514193, 'time_iter': 0.06559, 'accuracy': 0.97733, 'precision': 0.80838, 'recall': 0.51705, 'f1': 0.63069, 'auc': 0.95337}
2025-06-20 02:53:37,823 - INFO - val: {'epoch': 60, 'time_epoch': 3.46286, 'loss': 0.09323159, 'lr': 0, 'params': 514193, 'time_iter': 0.02684, 'accuracy': 0.97982, 'precision': 0.48333, 'recall': 0.35802, 'f1': 0.41135, 'auc': 0.80179}
2025-06-20 02:53:41,329 - INFO - test: {'epoch': 60, 'time_epoch': 3.48443, 'loss': 0.16044073, 'lr': 0, 'params': 514193, 'time_iter': 0.02701, 'accuracy': 0.96742, 'precision': 0.47619, 'recall': 0.30769, 'f1': 0.37383, 'auc': 0.73843}
2025-06-20 02:53:41,331 - INFO - > Epoch 60: took 74.7s (avg 74.0s) | Best so far: epoch 58	train_loss: 0.0768 train_auc: 0.9502	val_loss: 0.0899 val_auc: 0.8216	test_loss: 0.1592 test_auc: 0.7415
2025-06-20 02:54:50,419 - INFO - train: {'epoch': 61, 'time_epoch': 68.86114, 'eta': 2540.70452, 'eta_hours': 0.70575, 'loss': 0.07568466, 'lr': 3.613e-05, 'params': 514193, 'time_iter': 0.06692, 'accuracy': 0.97663, 'precision': 0.79641, 'recall': 0.50487, 'f1': 0.61798, 'auc': 0.95335}
2025-06-20 02:54:53,964 - INFO - val: {'epoch': 61, 'time_epoch': 3.5169, 'loss': 0.08790349, 'lr': 0, 'params': 514193, 'time_iter': 0.02726, 'accuracy': 0.97836, 'precision': 0.44286, 'recall': 0.38272, 'f1': 0.4106, 'auc': 0.82024}
2025-06-20 02:54:57,472 - INFO - test: {'epoch': 61, 'time_epoch': 3.48437, 'loss': 0.15642901, 'lr': 0, 'params': 514193, 'time_iter': 0.02701, 'accuracy': 0.96645, 'precision': 0.44444, 'recall': 0.24615, 'f1': 0.31683, 'auc': 0.74515}
2025-06-20 02:54:57,476 - INFO - > Epoch 61: took 76.1s (avg 74.1s) | Best so far: epoch 58	train_loss: 0.0768 train_auc: 0.9502	val_loss: 0.0899 val_auc: 0.8216	test_loss: 0.1592 test_auc: 0.7415
2025-06-20 02:56:03,009 - INFO - train: {'epoch': 62, 'time_epoch': 65.35748, 'eta': 2472.96106, 'eta_hours': 0.68693, 'loss': 0.07507402, 'lr': 3.455e-05, 'params': 514193, 'time_iter': 0.06352, 'accuracy': 0.97699, 'precision': 0.79799, 'recall': 0.51623, 'f1': 0.62691, 'auc': 0.95524}
2025-06-20 02:56:06,530 - INFO - val: {'epoch': 62, 'time_epoch': 3.49272, 'loss': 0.08740742, 'lr': 0, 'params': 514193, 'time_iter': 0.02708, 'accuracy': 0.98055, 'precision': 0.50943, 'recall': 0.33333, 'f1': 0.40299, 'auc': 0.80376}
2025-06-20 02:56:10,033 - INFO - test: {'epoch': 62, 'time_epoch': 3.4805, 'loss': 0.15921875, 'lr': 0, 'params': 514193, 'time_iter': 0.02698, 'accuracy': 0.96596, 'precision': 0.41935, 'recall': 0.2, 'f1': 0.27083, 'auc': 0.73229}
2025-06-20 02:56:10,037 - INFO - > Epoch 62: took 72.6s (avg 74.0s) | Best so far: epoch 58	train_loss: 0.0768 train_auc: 0.9502	val_loss: 0.0899 val_auc: 0.8216	test_loss: 0.1592 test_auc: 0.7415
2025-06-20 02:57:21,761 - INFO - train: {'epoch': 63, 'time_epoch': 71.49705, 'eta': 2408.74568, 'eta_hours': 0.6691, 'loss': 0.07392527, 'lr': 3.299e-05, 'params': 514193, 'time_iter': 0.06948, 'accuracy': 0.97702, 'precision': 0.8099, 'recall': 0.50487, 'f1': 0.622, 'auc': 0.95676}
2025-06-20 02:57:25,470 - INFO - val: {'epoch': 63, 'time_epoch': 3.64454, 'loss': 0.08567236, 'lr': 0, 'params': 514193, 'time_iter': 0.02825, 'accuracy': 0.98104, 'precision': 0.53191, 'recall': 0.30864, 'f1': 0.39062, 'auc': 0.81449}
2025-06-20 02:57:29,107 - INFO - test: {'epoch': 63, 'time_epoch': 3.61606, 'loss': 0.1591584, 'lr': 0, 'params': 514193, 'time_iter': 0.02803, 'accuracy': 0.96669, 'precision': 0.4386, 'recall': 0.19231, 'f1': 0.26738, 'auc': 0.74451}
2025-06-20 02:57:29,110 - INFO - > Epoch 63: took 79.1s (avg 74.1s) | Best so far: epoch 58	train_loss: 0.0768 train_auc: 0.9502	val_loss: 0.0899 val_auc: 0.8216	test_loss: 0.1592 test_auc: 0.7415
2025-06-20 02:58:43,025 - INFO - train: {'epoch': 64, 'time_epoch': 73.73793, 'eta': 2345.51287, 'eta_hours': 0.65153, 'loss': 0.07312422, 'lr': 3.144e-05, 'params': 514193, 'time_iter': 0.07166, 'accuracy': 0.97727, 'precision': 0.80633, 'recall': 0.51705, 'f1': 0.63007, 'auc': 0.95772}
2025-06-20 02:58:46,731 - INFO - val: {'epoch': 64, 'time_epoch': 3.67505, 'loss': 0.08899347, 'lr': 0, 'params': 514193, 'time_iter': 0.02849, 'accuracy': 0.97933, 'precision': 0.46875, 'recall': 0.37037, 'f1': 0.41379, 'auc': 0.79949}
2025-06-20 02:58:50,347 - INFO - test: {'epoch': 64, 'time_epoch': 3.5951, 'loss': 0.15659431, 'lr': 0, 'params': 514193, 'time_iter': 0.02787, 'accuracy': 0.96693, 'precision': 0.44643, 'recall': 0.19231, 'f1': 0.26882, 'auc': 0.74944}
2025-06-20 02:58:50,350 - INFO - > Epoch 64: took 81.2s (avg 74.2s) | Best so far: epoch 58	train_loss: 0.0768 train_auc: 0.9502	val_loss: 0.0899 val_auc: 0.8216	test_loss: 0.1592 test_auc: 0.7415
2025-06-20 03:00:00,315 - INFO - train: {'epoch': 65, 'time_epoch': 69.78547, 'eta': 2279.9256, 'eta_hours': 0.63331, 'loss': 0.07286838, 'lr': 2.992e-05, 'params': 514193, 'time_iter': 0.06782, 'accuracy': 0.97757, 'precision': 0.80419, 'recall': 0.53003, 'f1': 0.63894, 'auc': 0.95705}
2025-06-20 03:00:04,013 - INFO - val: {'epoch': 65, 'time_epoch': 3.66542, 'loss': 0.08412321, 'lr': 0, 'params': 514193, 'time_iter': 0.02841, 'accuracy': 0.98104, 'precision': 0.52941, 'recall': 0.33333, 'f1': 0.40909, 'auc': 0.81481}
2025-06-20 03:00:07,684 - INFO - test: {'epoch': 65, 'time_epoch': 3.52221, 'loss': 0.15801214, 'lr': 0, 'params': 514193, 'time_iter': 0.0273, 'accuracy': 0.96669, 'precision': 0.43396, 'recall': 0.17692, 'f1': 0.25137, 'auc': 0.74655}
2025-06-20 03:00:07,686 - INFO - > Epoch 65: took 77.3s (avg 74.3s) | Best so far: epoch 58	train_loss: 0.0768 train_auc: 0.9502	val_loss: 0.0899 val_auc: 0.8216	test_loss: 0.1592 test_auc: 0.7415
2025-06-20 03:01:18,578 - INFO - train: {'epoch': 66, 'time_epoch': 70.68231, 'eta': 2214.65475, 'eta_hours': 0.61518, 'loss': 0.07509116, 'lr': 2.841e-05, 'params': 514193, 'time_iter': 0.06869, 'accuracy': 0.97705, 'precision': 0.79408, 'recall': 0.52273, 'f1': 0.63045, 'auc': 0.95532}
2025-06-20 03:01:22,401 - INFO - val: {'epoch': 66, 'time_epoch': 3.78937, 'loss': 0.08728562, 'lr': 0, 'params': 514193, 'time_iter': 0.02937, 'accuracy': 0.97933, 'precision': 0.46875, 'recall': 0.37037, 'f1': 0.41379, 'auc': 0.81748}
2025-06-20 03:01:26,165 - INFO - test: {'epoch': 66, 'time_epoch': 3.74039, 'loss': 0.16225303, 'lr': 0, 'params': 514193, 'time_iter': 0.029, 'accuracy': 0.96499, 'precision': 0.41026, 'recall': 0.24615, 'f1': 0.30769, 'auc': 0.74453}
2025-06-20 03:01:26,168 - INFO - > Epoch 66: took 78.5s (avg 74.3s) | Best so far: epoch 58	train_loss: 0.0768 train_auc: 0.9502	val_loss: 0.0899 val_auc: 0.8216	test_loss: 0.1592 test_auc: 0.7415
2025-06-20 03:02:40,109 - INFO - train: {'epoch': 67, 'time_epoch': 73.75153, 'eta': 2150.66907, 'eta_hours': 0.59741, 'loss': 0.07241482, 'lr': 2.693e-05, 'params': 514193, 'time_iter': 0.07167, 'accuracy': 0.97736, 'precision': 0.80552, 'recall': 0.5211, 'f1': 0.63282, 'auc': 0.95782}
2025-06-20 03:02:43,894 - INFO - val: {'epoch': 67, 'time_epoch': 3.75717, 'loss': 0.08777529, 'lr': 0, 'params': 514193, 'time_iter': 0.02913, 'accuracy': 0.98006, 'precision': 0.49153, 'recall': 0.35802, 'f1': 0.41429, 'auc': 0.82258}
2025-06-20 03:02:47,575 - INFO - test: {'epoch': 67, 'time_epoch': 3.66046, 'loss': 0.16097381, 'lr': 0, 'params': 514193, 'time_iter': 0.02838, 'accuracy': 0.9628, 'precision': 0.37634, 'recall': 0.26923, 'f1': 0.3139, 'auc': 0.74857}
2025-06-20 03:02:47,578 - INFO - > Epoch 67: took 81.4s (avg 74.4s) | Best so far: epoch 67	train_loss: 0.0724 train_auc: 0.9578	val_loss: 0.0878 val_auc: 0.8226	test_loss: 0.1610 test_auc: 0.7486
2025-06-20 03:03:56,326 - INFO - train: {'epoch': 68, 'time_epoch': 68.55375, 'eta': 2084.06509, 'eta_hours': 0.57891, 'loss': 0.07132334, 'lr': 2.548e-05, 'params': 514193, 'time_iter': 0.06662, 'accuracy': 0.97754, 'precision': 0.81084, 'recall': 0.52192, 'f1': 0.63506, 'auc': 0.9606}
2025-06-20 03:03:59,835 - INFO - val: {'epoch': 68, 'time_epoch': 3.48222, 'loss': 0.08555796, 'lr': 0, 'params': 514193, 'time_iter': 0.02699, 'accuracy': 0.98055, 'precision': 0.51111, 'recall': 0.28395, 'f1': 0.36508, 'auc': 0.81479}
2025-06-20 03:04:03,388 - INFO - test: {'epoch': 68, 'time_epoch': 3.53217, 'loss': 0.15326129, 'lr': 0, 'params': 514193, 'time_iter': 0.02738, 'accuracy': 0.96791, 'precision': 0.47727, 'recall': 0.16154, 'f1': 0.24138, 'auc': 0.75865}
2025-06-20 03:04:03,390 - INFO - > Epoch 68: took 75.8s (avg 74.5s) | Best so far: epoch 67	train_loss: 0.0724 train_auc: 0.9578	val_loss: 0.0878 val_auc: 0.8226	test_loss: 0.1610 test_auc: 0.7486
2025-06-20 03:05:15,572 - INFO - train: {'epoch': 69, 'time_epoch': 72.00675, 'eta': 2018.88526, 'eta_hours': 0.5608, 'loss': 0.06972697, 'lr': 2.405e-05, 'params': 514193, 'time_iter': 0.06998, 'accuracy': 0.97772, 'precision': 0.81305, 'recall': 0.52597, 'f1': 0.63874, 'auc': 0.96313}
2025-06-20 03:05:19,233 - INFO - val: {'epoch': 69, 'time_epoch': 3.63151, 'loss': 0.08659728, 'lr': 0, 'params': 514193, 'time_iter': 0.02815, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.30864, 'f1': 0.38168, 'auc': 0.82548}
2025-06-20 03:05:23,122 - INFO - test: {'epoch': 69, 'time_epoch': 3.75151, 'loss': 0.16651499, 'lr': 0, 'params': 514193, 'time_iter': 0.02908, 'accuracy': 0.96669, 'precision': 0.43396, 'recall': 0.17692, 'f1': 0.25137, 'auc': 0.74825}
2025-06-20 03:05:23,125 - INFO - > Epoch 69: took 79.7s (avg 74.5s) | Best so far: epoch 69	train_loss: 0.0697 train_auc: 0.9631	val_loss: 0.0866 val_auc: 0.8255	test_loss: 0.1665 test_auc: 0.7482
2025-06-20 03:06:35,903 - INFO - train: {'epoch': 70, 'time_epoch': 72.6141, 'eta': 1953.76119, 'eta_hours': 0.54271, 'loss': 0.07218897, 'lr': 2.265e-05, 'params': 514193, 'time_iter': 0.07057, 'accuracy': 0.97748, 'precision': 0.81194, 'recall': 0.51867, 'f1': 0.63299, 'auc': 0.95943}
2025-06-20 03:06:39,541 - INFO - val: {'epoch': 70, 'time_epoch': 3.61027, 'loss': 0.0909459, 'lr': 0, 'params': 514193, 'time_iter': 0.02799, 'accuracy': 0.97763, 'precision': 0.41791, 'recall': 0.34568, 'f1': 0.37838, 'auc': 0.82361}
2025-06-20 03:06:43,094 - INFO - test: {'epoch': 70, 'time_epoch': 3.53222, 'loss': 0.16627545, 'lr': 0, 'params': 514193, 'time_iter': 0.02738, 'accuracy': 0.96402, 'precision': 0.37838, 'recall': 0.21538, 'f1': 0.27451, 'auc': 0.74645}
2025-06-20 03:06:43,097 - INFO - > Epoch 70: took 80.0s (avg 74.6s) | Best so far: epoch 69	train_loss: 0.0697 train_auc: 0.9631	val_loss: 0.0866 val_auc: 0.8255	test_loss: 0.1665 test_auc: 0.7482
2025-06-20 03:07:50,793 - INFO - train: {'epoch': 71, 'time_epoch': 67.51718, 'eta': 1886.44694, 'eta_hours': 0.52401, 'loss': 0.07075829, 'lr': 2.128e-05, 'params': 514193, 'time_iter': 0.06561, 'accuracy': 0.97775, 'precision': 0.81726, 'recall': 0.52273, 'f1': 0.63762, 'auc': 0.96259}
2025-06-20 03:07:54,347 - INFO - val: {'epoch': 71, 'time_epoch': 3.52691, 'loss': 0.09091309, 'lr': 0, 'params': 514193, 'time_iter': 0.02734, 'accuracy': 0.97715, 'precision': 0.40845, 'recall': 0.35802, 'f1': 0.38158, 'auc': 0.82196}
2025-06-20 03:07:57,725 - INFO - test: {'epoch': 71, 'time_epoch': 3.35775, 'loss': 0.16560334, 'lr': 0, 'params': 514193, 'time_iter': 0.02603, 'accuracy': 0.96548, 'precision': 0.43023, 'recall': 0.28462, 'f1': 0.34259, 'auc': 0.75034}
2025-06-20 03:07:57,727 - INFO - > Epoch 71: took 74.6s (avg 74.6s) | Best so far: epoch 69	train_loss: 0.0697 train_auc: 0.9631	val_loss: 0.0866 val_auc: 0.8255	test_loss: 0.1665 test_auc: 0.7482
2025-06-20 03:09:06,775 - INFO - train: {'epoch': 72, 'time_epoch': 68.83646, 'eta': 1819.61507, 'eta_hours': 0.50545, 'loss': 0.07051829, 'lr': 1.995e-05, 'params': 514193, 'time_iter': 0.0669, 'accuracy': 0.97784, 'precision': 0.8132, 'recall': 0.53003, 'f1': 0.64177, 'auc': 0.96281}
2025-06-20 03:09:10,471 - INFO - val: {'epoch': 72, 'time_epoch': 3.66452, 'loss': 0.09223272, 'lr': 0, 'params': 514193, 'time_iter': 0.02841, 'accuracy': 0.97885, 'precision': 0.45714, 'recall': 0.39506, 'f1': 0.42384, 'auc': 0.82344}
2025-06-20 03:09:14,063 - INFO - test: {'epoch': 72, 'time_epoch': 3.56764, 'loss': 0.16835873, 'lr': 0, 'params': 514193, 'time_iter': 0.02766, 'accuracy': 0.9628, 'precision': 0.38384, 'recall': 0.29231, 'f1': 0.33188, 'auc': 0.75432}
2025-06-20 03:09:14,067 - INFO - > Epoch 72: took 76.3s (avg 74.6s) | Best so far: epoch 69	train_loss: 0.0697 train_auc: 0.9631	val_loss: 0.0866 val_auc: 0.8255	test_loss: 0.1665 test_auc: 0.7482
2025-06-20 03:10:28,977 - INFO - train: {'epoch': 73, 'time_epoch': 74.70861, 'eta': 1754.79222, 'eta_hours': 0.48744, 'loss': 0.0672478, 'lr': 1.864e-05, 'params': 514193, 'time_iter': 0.0726, 'accuracy': 0.97872, 'precision': 0.81742, 'recall': 0.55601, 'f1': 0.66184, 'auc': 0.96642}
2025-06-20 03:10:32,881 - INFO - val: {'epoch': 73, 'time_epoch': 3.87364, 'loss': 0.0957915, 'lr': 0, 'params': 514193, 'time_iter': 0.03003, 'accuracy': 0.97763, 'precision': 0.4321, 'recall': 0.4321, 'f1': 0.4321, 'auc': 0.82694}
2025-06-20 03:10:36,552 - INFO - test: {'epoch': 73, 'time_epoch': 3.6501, 'loss': 0.17434626, 'lr': 0, 'params': 514193, 'time_iter': 0.0283, 'accuracy': 0.9611, 'precision': 0.35294, 'recall': 0.27692, 'f1': 0.31034, 'auc': 0.75352}
2025-06-20 03:10:36,554 - INFO - > Epoch 73: took 82.5s (avg 74.7s) | Best so far: epoch 73	train_loss: 0.0672 train_auc: 0.9664	val_loss: 0.0958 val_auc: 0.8269	test_loss: 0.1743 test_auc: 0.7535
2025-06-20 03:11:49,438 - INFO - train: {'epoch': 74, 'time_epoch': 72.70374, 'eta': 1689.03745, 'eta_hours': 0.46918, 'loss': 0.07041977, 'lr': 1.737e-05, 'params': 514193, 'time_iter': 0.07065, 'accuracy': 0.97812, 'precision': 0.8192, 'recall': 0.53328, 'f1': 0.64602, 'auc': 0.96146}
2025-06-20 03:11:53,167 - INFO - val: {'epoch': 74, 'time_epoch': 3.69725, 'loss': 0.08772101, 'lr': 0, 'params': 514193, 'time_iter': 0.02866, 'accuracy': 0.97958, 'precision': 0.47541, 'recall': 0.35802, 'f1': 0.40845, 'auc': 0.8312}
2025-06-20 03:11:56,786 - INFO - test: {'epoch': 74, 'time_epoch': 3.59389, 'loss': 0.17202978, 'lr': 0, 'params': 514193, 'time_iter': 0.02786, 'accuracy': 0.96669, 'precision': 0.44262, 'recall': 0.20769, 'f1': 0.28272, 'auc': 0.74124}
2025-06-20 03:11:56,788 - INFO - > Epoch 74: took 80.2s (avg 74.8s) | Best so far: epoch 74	train_loss: 0.0704 train_auc: 0.9615	val_loss: 0.0877 val_auc: 0.8312	test_loss: 0.1720 test_auc: 0.7412
2025-06-20 03:13:04,474 - INFO - train: {'epoch': 75, 'time_epoch': 67.49545, 'eta': 1621.4551, 'eta_hours': 0.4504, 'loss': 0.06882736, 'lr': 1.614e-05, 'params': 514193, 'time_iter': 0.06559, 'accuracy': 0.97763, 'precision': 0.7988, 'recall': 0.53815, 'f1': 0.64306, 'auc': 0.96357}
2025-06-20 03:13:08,320 - INFO - val: {'epoch': 75, 'time_epoch': 3.81807, 'loss': 0.09437635, 'lr': 0, 'params': 514193, 'time_iter': 0.0296, 'accuracy': 0.97933, 'precision': 0.47059, 'recall': 0.39506, 'f1': 0.42953, 'auc': 0.8184}
2025-06-20 03:13:12,097 - INFO - test: {'epoch': 75, 'time_epoch': 3.75212, 'loss': 0.18089164, 'lr': 0, 'params': 514193, 'time_iter': 0.02909, 'accuracy': 0.96183, 'precision': 0.35165, 'recall': 0.24615, 'f1': 0.28959, 'auc': 0.74533}
2025-06-20 03:13:12,101 - INFO - > Epoch 75: took 75.3s (avg 74.8s) | Best so far: epoch 74	train_loss: 0.0704 train_auc: 0.9615	val_loss: 0.0877 val_auc: 0.8312	test_loss: 0.1720 test_auc: 0.7412
2025-06-20 03:14:24,507 - INFO - train: {'epoch': 76, 'time_epoch': 72.18646, 'eta': 1555.27621, 'eta_hours': 0.43202, 'loss': 0.06827395, 'lr': 1.494e-05, 'params': 514193, 'time_iter': 0.07015, 'accuracy': 0.9783, 'precision': 0.79432, 'recall': 0.56737, 'f1': 0.66193, 'auc': 0.96579}
2025-06-20 03:14:28,336 - INFO - val: {'epoch': 76, 'time_epoch': 3.7988, 'loss': 0.0956982, 'lr': 0, 'params': 514193, 'time_iter': 0.02945, 'accuracy': 0.97642, 'precision': 0.4, 'recall': 0.39506, 'f1': 0.39752, 'auc': 0.81846}
2025-06-20 03:14:32,170 - INFO - test: {'epoch': 76, 'time_epoch': 3.8121, 'loss': 0.18107487, 'lr': 0, 'params': 514193, 'time_iter': 0.02955, 'accuracy': 0.96159, 'precision': 0.35106, 'recall': 0.25385, 'f1': 0.29464, 'auc': 0.74516}
2025-06-20 03:14:32,173 - INFO - > Epoch 76: took 80.1s (avg 74.9s) | Best so far: epoch 74	train_loss: 0.0704 train_auc: 0.9615	val_loss: 0.0877 val_auc: 0.8312	test_loss: 0.1720 test_auc: 0.7412
2025-06-20 03:15:45,563 - INFO - train: {'epoch': 77, 'time_epoch': 73.18899, 'eta': 1489.22605, 'eta_hours': 0.41367, 'loss': 0.06673909, 'lr': 1.378e-05, 'params': 514193, 'time_iter': 0.07113, 'accuracy': 0.97933, 'precision': 0.82243, 'recall': 0.57143, 'f1': 0.67433, 'auc': 0.96699}
2025-06-20 03:15:49,165 - INFO - val: {'epoch': 77, 'time_epoch': 3.57332, 'loss': 0.09660397, 'lr': 0, 'params': 514193, 'time_iter': 0.0277, 'accuracy': 0.97642, 'precision': 0.40244, 'recall': 0.40741, 'f1': 0.40491, 'auc': 0.82131}
2025-06-20 03:15:52,747 - INFO - test: {'epoch': 77, 'time_epoch': 3.56084, 'loss': 0.18426335, 'lr': 0, 'params': 514193, 'time_iter': 0.0276, 'accuracy': 0.96086, 'precision': 0.34343, 'recall': 0.26154, 'f1': 0.29694, 'auc': 0.73525}
2025-06-20 03:15:52,750 - INFO - > Epoch 77: took 80.6s (avg 75.0s) | Best so far: epoch 74	train_loss: 0.0704 train_auc: 0.9615	val_loss: 0.0877 val_auc: 0.8312	test_loss: 0.1720 test_auc: 0.7412
2025-06-20 03:17:00,157 - INFO - train: {'epoch': 78, 'time_epoch': 67.20131, 'eta': 1421.40349, 'eta_hours': 0.39483, 'loss': 0.06650956, 'lr': 1.266e-05, 'params': 514193, 'time_iter': 0.06531, 'accuracy': 0.97882, 'precision': 0.8136, 'recall': 0.56331, 'f1': 0.66571, 'auc': 0.96831}
2025-06-20 03:17:03,731 - INFO - val: {'epoch': 78, 'time_epoch': 3.54449, 'loss': 0.09311948, 'lr': 0, 'params': 514193, 'time_iter': 0.02748, 'accuracy': 0.97788, 'precision': 0.43421, 'recall': 0.40741, 'f1': 0.42038, 'auc': 0.82626}
2025-06-20 03:17:07,271 - INFO - test: {'epoch': 78, 'time_epoch': 3.51754, 'loss': 0.17440316, 'lr': 0, 'params': 514193, 'time_iter': 0.02727, 'accuracy': 0.96596, 'precision': 0.44048, 'recall': 0.28462, 'f1': 0.34579, 'auc': 0.74883}
2025-06-20 03:17:07,275 - INFO - > Epoch 78: took 74.5s (avg 75.0s) | Best so far: epoch 74	train_loss: 0.0704 train_auc: 0.9615	val_loss: 0.0877 val_auc: 0.8312	test_loss: 0.1720 test_auc: 0.7412
2025-06-20 03:18:16,899 - INFO - train: {'epoch': 79, 'time_epoch': 69.41925, 'eta': 1354.15095, 'eta_hours': 0.37615, 'loss': 0.06611178, 'lr': 1.158e-05, 'params': 514193, 'time_iter': 0.06746, 'accuracy': 0.97851, 'precision': 0.80846, 'recall': 0.55844, 'f1': 0.66059, 'auc': 0.96902}
2025-06-20 03:18:20,510 - INFO - val: {'epoch': 79, 'time_epoch': 3.58343, 'loss': 0.09779457, 'lr': 0, 'params': 514193, 'time_iter': 0.02778, 'accuracy': 0.97569, 'precision': 0.3908, 'recall': 0.41975, 'f1': 0.40476, 'auc': 0.8267}
2025-06-20 03:18:24,100 - INFO - test: {'epoch': 79, 'time_epoch': 3.56903, 'loss': 0.1760554, 'lr': 0, 'params': 514193, 'time_iter': 0.02767, 'accuracy': 0.96183, 'precision': 0.35165, 'recall': 0.24615, 'f1': 0.28959, 'auc': 0.75264}
2025-06-20 03:18:24,102 - INFO - > Epoch 79: took 76.8s (avg 75.0s) | Best so far: epoch 74	train_loss: 0.0704 train_auc: 0.9615	val_loss: 0.0877 val_auc: 0.8312	test_loss: 0.1720 test_auc: 0.7412
2025-06-20 03:19:35,379 - INFO - train: {'epoch': 80, 'time_epoch': 71.10214, 'eta': 1287.23967, 'eta_hours': 0.35757, 'loss': 0.06471408, 'lr': 1.054e-05, 'params': 514193, 'time_iter': 0.0691, 'accuracy': 0.97839, 'precision': 0.80975, 'recall': 0.55276, 'f1': 0.65702, 'auc': 0.97225}
2025-06-20 03:19:38,976 - INFO - val: {'epoch': 80, 'time_epoch': 3.56747, 'loss': 0.10277869, 'lr': 0, 'params': 514193, 'time_iter': 0.02765, 'accuracy': 0.97496, 'precision': 0.37778, 'recall': 0.41975, 'f1': 0.39766, 'auc': 0.82643}
2025-06-20 03:19:42,400 - INFO - test: {'epoch': 80, 'time_epoch': 3.40426, 'loss': 0.17763917, 'lr': 0, 'params': 514193, 'time_iter': 0.02639, 'accuracy': 0.96037, 'precision': 0.33981, 'recall': 0.26923, 'f1': 0.30043, 'auc': 0.76183}
2025-06-20 03:19:42,402 - INFO - > Epoch 80: took 78.3s (avg 75.0s) | Best so far: epoch 74	train_loss: 0.0704 train_auc: 0.9615	val_loss: 0.0877 val_auc: 0.8312	test_loss: 0.1720 test_auc: 0.7412
2025-06-20 03:20:47,920 - INFO - train: {'epoch': 81, 'time_epoch': 65.33808, 'eta': 1218.96089, 'eta_hours': 0.3386, 'loss': 0.06709609, 'lr': 9.55e-06, 'params': 514193, 'time_iter': 0.0635, 'accuracy': 0.97863, 'precision': 0.81228, 'recall': 0.55844, 'f1': 0.66186, 'auc': 0.96814}
2025-06-20 03:20:51,263 - INFO - val: {'epoch': 81, 'time_epoch': 3.31725, 'loss': 0.09338537, 'lr': 0, 'params': 514193, 'time_iter': 0.02572, 'accuracy': 0.9769, 'precision': 0.41026, 'recall': 0.39506, 'f1': 0.40252, 'auc': 0.83218}
2025-06-20 03:20:54,710 - INFO - test: {'epoch': 81, 'time_epoch': 3.42605, 'loss': 0.1736385, 'lr': 0, 'params': 514193, 'time_iter': 0.02656, 'accuracy': 0.96377, 'precision': 0.39326, 'recall': 0.26923, 'f1': 0.31963, 'auc': 0.75119}
2025-06-20 03:20:54,712 - INFO - > Epoch 81: took 72.3s (avg 75.0s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:22:05,415 - INFO - train: {'epoch': 82, 'time_epoch': 70.48954, 'eta': 1151.80808, 'eta_hours': 0.31995, 'loss': 0.06694489, 'lr': 8.6e-06, 'params': 514193, 'time_iter': 0.0685, 'accuracy': 0.97948, 'precision': 0.8384, 'recall': 0.56006, 'f1': 0.67153, 'auc': 0.96744}
2025-06-20 03:22:09,292 - INFO - val: {'epoch': 82, 'time_epoch': 3.83103, 'loss': 0.09492004, 'lr': 0, 'params': 514193, 'time_iter': 0.0297, 'accuracy': 0.97788, 'precision': 0.43243, 'recall': 0.39506, 'f1': 0.4129, 'auc': 0.82925}
2025-06-20 03:22:13,029 - INFO - test: {'epoch': 82, 'time_epoch': 3.7157, 'loss': 0.1790827, 'lr': 0, 'params': 514193, 'time_iter': 0.0288, 'accuracy': 0.96402, 'precision': 0.39024, 'recall': 0.24615, 'f1': 0.30189, 'auc': 0.7473}
2025-06-20 03:22:13,031 - INFO - > Epoch 82: took 78.3s (avg 75.0s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:23:26,221 - INFO - train: {'epoch': 83, 'time_epoch': 73.00308, 'eta': 1085.0546, 'eta_hours': 0.3014, 'loss': 0.06672711, 'lr': 7.7e-06, 'params': 514193, 'time_iter': 0.07095, 'accuracy': 0.97912, 'precision': 0.82557, 'recall': 0.56088, 'f1': 0.66796, 'auc': 0.96868}
2025-06-20 03:23:29,862 - INFO - val: {'epoch': 83, 'time_epoch': 3.61344, 'loss': 0.09908563, 'lr': 0, 'params': 514193, 'time_iter': 0.02801, 'accuracy': 0.97788, 'precision': 0.4359, 'recall': 0.41975, 'f1': 0.42767, 'auc': 0.8281}
2025-06-20 03:23:33,473 - INFO - test: {'epoch': 83, 'time_epoch': 3.58949, 'loss': 0.17972873, 'lr': 0, 'params': 514193, 'time_iter': 0.02783, 'accuracy': 0.96548, 'precision': 0.42308, 'recall': 0.25385, 'f1': 0.31731, 'auc': 0.74569}
2025-06-20 03:23:33,476 - INFO - > Epoch 83: took 80.4s (avg 75.1s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:24:42,624 - INFO - train: {'epoch': 84, 'time_epoch': 68.93068, 'eta': 1017.43541, 'eta_hours': 0.28262, 'loss': 0.06588961, 'lr': 6.84e-06, 'params': 514193, 'time_iter': 0.06699, 'accuracy': 0.97939, 'precision': 0.82512, 'recall': 0.57062, 'f1': 0.67466, 'auc': 0.96845}
2025-06-20 03:24:46,112 - INFO - val: {'epoch': 84, 'time_epoch': 3.44577, 'loss': 0.09883801, 'lr': 0, 'params': 514193, 'time_iter': 0.02671, 'accuracy': 0.97569, 'precision': 0.39326, 'recall': 0.4321, 'f1': 0.41176, 'auc': 0.83136}
2025-06-20 03:24:49,544 - INFO - test: {'epoch': 84, 'time_epoch': 3.41067, 'loss': 0.17912922, 'lr': 0, 'params': 514193, 'time_iter': 0.02644, 'accuracy': 0.9594, 'precision': 0.3271, 'recall': 0.26923, 'f1': 0.29536, 'auc': 0.75501}
2025-06-20 03:24:49,546 - INFO - > Epoch 84: took 76.1s (avg 75.1s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:26:00,762 - INFO - train: {'epoch': 85, 'time_epoch': 71.02556, 'eta': 950.12675, 'eta_hours': 0.26392, 'loss': 0.06425761, 'lr': 6.03e-06, 'params': 514193, 'time_iter': 0.06902, 'accuracy': 0.97967, 'precision': 0.82847, 'recall': 0.5763, 'f1': 0.67975, 'auc': 0.97005}
2025-06-20 03:26:04,435 - INFO - val: {'epoch': 85, 'time_epoch': 3.64537, 'loss': 0.09833291, 'lr': 0, 'params': 514193, 'time_iter': 0.02826, 'accuracy': 0.97398, 'precision': 0.36458, 'recall': 0.4321, 'f1': 0.39548, 'auc': 0.82891}
2025-06-20 03:26:08,064 - INFO - test: {'epoch': 85, 'time_epoch': 3.60808, 'loss': 0.1724254, 'lr': 0, 'params': 514193, 'time_iter': 0.02797, 'accuracy': 0.95988, 'precision': 0.3301, 'recall': 0.26154, 'f1': 0.29185, 'auc': 0.75609}
2025-06-20 03:26:08,066 - INFO - > Epoch 85: took 78.5s (avg 75.1s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:27:21,922 - INFO - train: {'epoch': 86, 'time_epoch': 73.66282, 'eta': 883.12672, 'eta_hours': 0.24531, 'loss': 0.06598339, 'lr': 5.26e-06, 'params': 514193, 'time_iter': 0.07159, 'accuracy': 0.98009, 'precision': 0.8497, 'recall': 0.56899, 'f1': 0.68158, 'auc': 0.96824}
2025-06-20 03:27:25,632 - INFO - val: {'epoch': 86, 'time_epoch': 3.67887, 'loss': 0.09838904, 'lr': 0, 'params': 514193, 'time_iter': 0.02852, 'accuracy': 0.97642, 'precision': 0.40476, 'recall': 0.41975, 'f1': 0.41212, 'auc': 0.82515}
2025-06-20 03:27:29,257 - INFO - test: {'epoch': 86, 'time_epoch': 3.601, 'loss': 0.18087371, 'lr': 0, 'params': 514193, 'time_iter': 0.02791, 'accuracy': 0.96159, 'precision': 0.34783, 'recall': 0.24615, 'f1': 0.28829, 'auc': 0.75034}
2025-06-20 03:27:29,261 - INFO - > Epoch 86: took 81.2s (avg 75.2s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:28:38,532 - INFO - train: {'epoch': 87, 'time_epoch': 69.05015, 'eta': 815.34625, 'eta_hours': 0.22649, 'loss': 0.06445812, 'lr': 4.55e-06, 'params': 514193, 'time_iter': 0.0671, 'accuracy': 0.97994, 'precision': 0.83333, 'recall': 0.58036, 'f1': 0.68421, 'auc': 0.96967}
2025-06-20 03:28:42,011 - INFO - val: {'epoch': 87, 'time_epoch': 3.45027, 'loss': 0.09517187, 'lr': 0, 'params': 514193, 'time_iter': 0.02675, 'accuracy': 0.97763, 'precision': 0.42667, 'recall': 0.39506, 'f1': 0.41026, 'auc': 0.82121}
2025-06-20 03:28:45,366 - INFO - test: {'epoch': 87, 'time_epoch': 3.3335, 'loss': 0.17563917, 'lr': 0, 'params': 514193, 'time_iter': 0.02584, 'accuracy': 0.96377, 'precision': 0.37662, 'recall': 0.22308, 'f1': 0.28019, 'auc': 0.75687}
2025-06-20 03:28:45,369 - INFO - > Epoch 87: took 76.1s (avg 75.2s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:29:50,829 - INFO - train: {'epoch': 88, 'time_epoch': 65.28126, 'eta': 747.07144, 'eta_hours': 0.20752, 'loss': 0.06534438, 'lr': 3.89e-06, 'params': 514193, 'time_iter': 0.06344, 'accuracy': 0.97988, 'precision': 0.8314, 'recall': 0.58036, 'f1': 0.68356, 'auc': 0.96861}
2025-06-20 03:29:54,341 - INFO - val: {'epoch': 88, 'time_epoch': 3.48443, 'loss': 0.09604374, 'lr': 0, 'params': 514193, 'time_iter': 0.02701, 'accuracy': 0.97666, 'precision': 0.40506, 'recall': 0.39506, 'f1': 0.4, 'auc': 0.82609}
2025-06-20 03:29:57,865 - INFO - test: {'epoch': 88, 'time_epoch': 3.50316, 'loss': 0.17674525, 'lr': 0, 'params': 514193, 'time_iter': 0.02716, 'accuracy': 0.96426, 'precision': 0.39759, 'recall': 0.25385, 'f1': 0.30986, 'auc': 0.75261}
2025-06-20 03:29:57,867 - INFO - > Epoch 88: took 72.5s (avg 75.2s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:31:04,991 - INFO - train: {'epoch': 89, 'time_epoch': 66.92835, 'eta': 679.04616, 'eta_hours': 0.18862, 'loss': 0.06492396, 'lr': 3.27e-06, 'params': 514193, 'time_iter': 0.06504, 'accuracy': 0.97924, 'precision': 0.81734, 'recall': 0.57386, 'f1': 0.6743, 'auc': 0.97192}
2025-06-20 03:31:08,624 - INFO - val: {'epoch': 89, 'time_epoch': 3.59992, 'loss': 0.09443121, 'lr': 0, 'params': 514193, 'time_iter': 0.02791, 'accuracy': 0.97763, 'precision': 0.42667, 'recall': 0.39506, 'f1': 0.41026, 'auc': 0.82075}
2025-06-20 03:31:12,228 - INFO - test: {'epoch': 89, 'time_epoch': 3.58236, 'loss': 0.1754498, 'lr': 0, 'params': 514193, 'time_iter': 0.02777, 'accuracy': 0.96207, 'precision': 0.34884, 'recall': 0.23077, 'f1': 0.27778, 'auc': 0.75151}
2025-06-20 03:31:12,231 - INFO - > Epoch 89: took 74.4s (avg 75.2s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:32:16,573 - INFO - train: {'epoch': 90, 'time_epoch': 64.01783, 'eta': 610.75714, 'eta_hours': 0.16965, 'loss': 0.06459131, 'lr': 2.71e-06, 'params': 514193, 'time_iter': 0.06221, 'accuracy': 0.97948, 'precision': 0.81975, 'recall': 0.57955, 'f1': 0.67903, 'auc': 0.97009}
2025-06-20 03:32:19,940 - INFO - val: {'epoch': 90, 'time_epoch': 3.34036, 'loss': 0.09359244, 'lr': 0, 'params': 514193, 'time_iter': 0.02589, 'accuracy': 0.97715, 'precision': 0.41333, 'recall': 0.38272, 'f1': 0.39744, 'auc': 0.8225}
2025-06-20 03:32:23,294 - INFO - test: {'epoch': 90, 'time_epoch': 3.3264, 'loss': 0.17310121, 'lr': 0, 'params': 514193, 'time_iter': 0.02579, 'accuracy': 0.96207, 'precision': 0.35227, 'recall': 0.23846, 'f1': 0.2844, 'auc': 0.75801}
2025-06-20 03:32:23,301 - INFO - > Epoch 90: took 71.1s (avg 75.1s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:33:28,982 - INFO - train: {'epoch': 91, 'time_epoch': 65.4493, 'eta': 542.68544, 'eta_hours': 0.15075, 'loss': 0.06293224, 'lr': 2.2e-06, 'params': 514193, 'time_iter': 0.0636, 'accuracy': 0.97994, 'precision': 0.82949, 'recall': 0.58442, 'f1': 0.68571, 'auc': 0.97299}
2025-06-20 03:33:32,625 - INFO - val: {'epoch': 91, 'time_epoch': 3.53112, 'loss': 0.09419441, 'lr': 0, 'params': 514193, 'time_iter': 0.02737, 'accuracy': 0.9769, 'precision': 0.4125, 'recall': 0.40741, 'f1': 0.40994, 'auc': 0.8268}
2025-06-20 03:33:36,039 - INFO - test: {'epoch': 91, 'time_epoch': 3.38799, 'loss': 0.17514312, 'lr': 0, 'params': 514193, 'time_iter': 0.02626, 'accuracy': 0.96353, 'precision': 0.38636, 'recall': 0.26154, 'f1': 0.31193, 'auc': 0.75835}
2025-06-20 03:33:36,041 - INFO - > Epoch 91: took 72.7s (avg 75.1s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:34:42,787 - INFO - train: {'epoch': 92, 'time_epoch': 66.48431, 'eta': 474.74805, 'eta_hours': 0.13187, 'loss': 0.06357667, 'lr': 1.74e-06, 'params': 514193, 'time_iter': 0.06461, 'accuracy': 0.97933, 'precision': 0.81364, 'recall': 0.58117, 'f1': 0.67803, 'auc': 0.97393}
2025-06-20 03:34:46,269 - INFO - val: {'epoch': 92, 'time_epoch': 3.42382, 'loss': 0.10043479, 'lr': 0, 'params': 514193, 'time_iter': 0.02654, 'accuracy': 0.9752, 'precision': 0.38202, 'recall': 0.41975, 'f1': 0.4, 'auc': 0.81823}
2025-06-20 03:34:49,725 - INFO - test: {'epoch': 92, 'time_epoch': 3.43454, 'loss': 0.17933181, 'lr': 0, 'params': 514193, 'time_iter': 0.02662, 'accuracy': 0.95915, 'precision': 0.32407, 'recall': 0.26923, 'f1': 0.29412, 'auc': 0.76003}
2025-06-20 03:34:49,727 - INFO - > Epoch 92: took 73.7s (avg 75.1s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:35:57,003 - INFO - train: {'epoch': 93, 'time_epoch': 67.00595, 'eta': 406.87486, 'eta_hours': 0.11302, 'loss': 0.06438778, 'lr': 1.33e-06, 'params': 514193, 'time_iter': 0.06512, 'accuracy': 0.97878, 'precision': 0.80831, 'recall': 0.56818, 'f1': 0.6673, 'auc': 0.97246}
2025-06-20 03:36:00,914 - INFO - val: {'epoch': 93, 'time_epoch': 3.6762, 'loss': 0.09754252, 'lr': 0, 'params': 514193, 'time_iter': 0.0285, 'accuracy': 0.97471, 'precision': 0.37634, 'recall': 0.4321, 'f1': 0.4023, 'auc': 0.82706}
2025-06-20 03:36:04,359 - INFO - test: {'epoch': 93, 'time_epoch': 3.41704, 'loss': 0.17489302, 'lr': 0, 'params': 514193, 'time_iter': 0.02649, 'accuracy': 0.96037, 'precision': 0.34862, 'recall': 0.29231, 'f1': 0.31799, 'auc': 0.75554}
2025-06-20 03:36:04,367 - INFO - > Epoch 93: took 74.6s (avg 75.1s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:37:09,598 - INFO - train: {'epoch': 94, 'time_epoch': 64.98832, 'eta': 338.91375, 'eta_hours': 0.09414, 'loss': 0.06259998, 'lr': 9.8e-07, 'params': 514193, 'time_iter': 0.06316, 'accuracy': 0.97991, 'precision': 0.83628, 'recall': 0.5763, 'f1': 0.68236, 'auc': 0.97061}
2025-06-20 03:37:13,000 - INFO - val: {'epoch': 94, 'time_epoch': 3.35525, 'loss': 0.09733669, 'lr': 0, 'params': 514193, 'time_iter': 0.02601, 'accuracy': 0.97812, 'precision': 0.44304, 'recall': 0.4321, 'f1': 0.4375, 'auc': 0.82657}
2025-06-20 03:37:16,343 - INFO - test: {'epoch': 94, 'time_epoch': 3.31779, 'loss': 0.1784315, 'lr': 0, 'params': 514193, 'time_iter': 0.02572, 'accuracy': 0.96183, 'precision': 0.35789, 'recall': 0.26154, 'f1': 0.30222, 'auc': 0.75348}
2025-06-20 03:37:16,349 - INFO - > Epoch 94: took 72.0s (avg 75.1s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:38:24,445 - INFO - train: {'epoch': 95, 'time_epoch': 67.68411, 'eta': 271.12689, 'eta_hours': 0.07531, 'loss': 0.06369979, 'lr': 6.8e-07, 'params': 514193, 'time_iter': 0.06578, 'accuracy': 0.97945, 'precision': 0.82176, 'recall': 0.5763, 'f1': 0.67748, 'auc': 0.97112}
2025-06-20 03:38:27,916 - INFO - val: {'epoch': 95, 'time_epoch': 3.43569, 'loss': 0.09650502, 'lr': 0, 'params': 514193, 'time_iter': 0.02663, 'accuracy': 0.9786, 'precision': 0.45333, 'recall': 0.41975, 'f1': 0.4359, 'auc': 0.82139}
2025-06-20 03:38:31,266 - INFO - test: {'epoch': 95, 'time_epoch': 3.32133, 'loss': 0.1803698, 'lr': 0, 'params': 514193, 'time_iter': 0.02575, 'accuracy': 0.96499, 'precision': 0.40541, 'recall': 0.23077, 'f1': 0.29412, 'auc': 0.75323}
2025-06-20 03:38:31,269 - INFO - > Epoch 95: took 74.9s (avg 75.1s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:39:37,261 - INFO - train: {'epoch': 96, 'time_epoch': 65.66709, 'eta': 203.27976, 'eta_hours': 0.05647, 'loss': 0.06171187, 'lr': 4.4e-07, 'params': 514193, 'time_iter': 0.06382, 'accuracy': 0.98006, 'precision': 0.82877, 'recall': 0.58929, 'f1': 0.6888, 'auc': 0.9728}
2025-06-20 03:39:40,834 - INFO - val: {'epoch': 96, 'time_epoch': 3.53311, 'loss': 0.09135241, 'lr': 0, 'params': 514193, 'time_iter': 0.02739, 'accuracy': 0.97788, 'precision': 0.43421, 'recall': 0.40741, 'f1': 0.42038, 'auc': 0.83186}
2025-06-20 03:39:44,288 - INFO - test: {'epoch': 96, 'time_epoch': 3.43043, 'loss': 0.17569933, 'lr': 0, 'params': 514193, 'time_iter': 0.02659, 'accuracy': 0.96426, 'precision': 0.38356, 'recall': 0.21538, 'f1': 0.27586, 'auc': 0.75389}
2025-06-20 03:39:44,296 - INFO - > Epoch 96: took 73.0s (avg 75.0s) | Best so far: epoch 81	train_loss: 0.0671 train_auc: 0.9681	val_loss: 0.0934 val_auc: 0.8322	test_loss: 0.1736 test_auc: 0.7512
2025-06-20 03:40:48,426 - INFO - train: {'epoch': 97, 'time_epoch': 63.96197, 'eta': 135.44233, 'eta_hours': 0.03762, 'loss': 0.06394241, 'lr': 2.5e-07, 'params': 514193, 'time_iter': 0.06216, 'accuracy': 0.97915, 'precision': 0.81597, 'recall': 0.57224, 'f1': 0.67271, 'auc': 0.97217}
2025-06-20 03:40:51,956 - INFO - val: {'epoch': 97, 'time_epoch': 3.46464, 'loss': 0.09293335, 'lr': 0, 'params': 514193, 'time_iter': 0.02686, 'accuracy': 0.97496, 'precision': 0.37778, 'recall': 0.41975, 'f1': 0.39766, 'auc': 0.8338}
2025-06-20 03:40:55,330 - INFO - test: {'epoch': 97, 'time_epoch': 3.35246, 'loss': 0.17109718, 'lr': 0, 'params': 514193, 'time_iter': 0.02599, 'accuracy': 0.96013, 'precision': 0.32292, 'recall': 0.23846, 'f1': 0.27434, 'auc': 0.74829}
2025-06-20 03:40:55,342 - INFO - > Epoch 97: took 71.0s (avg 75.0s) | Best so far: epoch 97	train_loss: 0.0639 train_auc: 0.9722	val_loss: 0.0929 val_auc: 0.8338	test_loss: 0.1711 test_auc: 0.7483
2025-06-20 03:42:00,035 - INFO - train: {'epoch': 98, 'time_epoch': 64.33893, 'eta': 67.687, 'eta_hours': 0.0188, 'loss': 0.06306286, 'lr': 1.1e-07, 'params': 514193, 'time_iter': 0.06253, 'accuracy': 0.98, 'precision': 0.8345, 'recall': 0.58117, 'f1': 0.68517, 'auc': 0.97264}
2025-06-20 03:42:03,847 - INFO - val: {'epoch': 98, 'time_epoch': 3.78217, 'loss': 0.09651748, 'lr': 0, 'params': 514193, 'time_iter': 0.02932, 'accuracy': 0.97836, 'precision': 0.44444, 'recall': 0.39506, 'f1': 0.4183, 'auc': 0.82546}
2025-06-20 03:42:07,238 - INFO - test: {'epoch': 98, 'time_epoch': 3.36701, 'loss': 0.18327024, 'lr': 0, 'params': 514193, 'time_iter': 0.0261, 'accuracy': 0.96475, 'precision': 0.4026, 'recall': 0.23846, 'f1': 0.29952, 'auc': 0.74806}
2025-06-20 03:42:07,240 - INFO - > Epoch 98: took 71.9s (avg 75.0s) | Best so far: epoch 97	train_loss: 0.0639 train_auc: 0.9722	val_loss: 0.0929 val_auc: 0.8338	test_loss: 0.1711 test_auc: 0.7483
2025-06-20 03:43:13,196 - INFO - train: {'epoch': 99, 'time_epoch': 65.72119, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.06275611, 'lr': 3e-08, 'params': 514193, 'time_iter': 0.06387, 'accuracy': 0.97991, 'precision': 0.83948, 'recall': 0.57305, 'f1': 0.68114, 'auc': 0.97115}
2025-06-20 03:43:16,670 - INFO - val: {'epoch': 99, 'time_epoch': 3.42983, 'loss': 0.09446104, 'lr': 0, 'params': 514193, 'time_iter': 0.02659, 'accuracy': 0.97763, 'precision': 0.42667, 'recall': 0.39506, 'f1': 0.41026, 'auc': 0.82932}
2025-06-20 03:43:20,110 - INFO - test: {'epoch': 99, 'time_epoch': 3.38965, 'loss': 0.17924066, 'lr': 0, 'params': 514193, 'time_iter': 0.02628, 'accuracy': 0.96329, 'precision': 0.37931, 'recall': 0.25385, 'f1': 0.30415, 'auc': 0.74987}
2025-06-20 03:43:20,279 - INFO - > Epoch 99: took 72.9s (avg 74.9s) | Best so far: epoch 97	train_loss: 0.0639 train_auc: 0.9722	val_loss: 0.0929 val_auc: 0.8338	test_loss: 0.1711 test_auc: 0.7483
2025-06-20 03:43:20,280 - INFO - Avg time per epoch: 74.94s
2025-06-20 03:43:20,280 - INFO - Total train loop time: 2.08h
2025-06-20 03:43:20,291 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-45
2025-06-20 03:43:20,292 - INFO - Total time: 8051.90s (2.24h)
2025-06-20 03:43:20,304 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-45/agg
2025-06-20 03:43:20,304 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-06-20 03:43:20,304 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-45
2025-06-20 03:43:20,304 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-45/test_results/
Completed seed 45. Results saved in results/molhiv/molhiv-Vanilla-45
----------------------------------------
Running experiment with seed: 47
Starting training for seed 47...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/confignas.yaml
Using device: cuda
2025-06-20 03:43:50,436 - INFO - GPU Mem: 34.1GB
2025-06-20 03:43:50,437 - INFO - Run directory: results/molhiv/molhiv-Vanilla-47
2025-06-20 03:43:50,437 - INFO - Seed: 47
2025-06-20 03:43:50,437 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-06-20 03:43:50,437 - INFO - Routing mode: none
2025-06-20 03:43:50,437 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-06-20 03:43:50,437 - INFO - Number of layers: 15
2025-06-20 03:43:50,437 - INFO - Uncertainty enabled: False
2025-06-20 03:43:50,437 - INFO - Training mode: custom
2025-06-20 03:43:50,437 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-06-20 03:43:50,437 - INFO - Additional features: Router weights logging + JSON export
2025-06-20 03:43:57,500 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-20 03:43:57,505 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-06-20 03:43:57,506 - INFO -   undirected: True
2025-06-20 03:43:57,506 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-20 03:43:57,506 - INFO -   avg num_nodes/graph: 25
2025-06-20 03:43:57,507 - INFO -   num node features: 9
2025-06-20 03:43:57,507 - INFO -   num edge features: 3
2025-06-20 03:43:57,507 - INFO -   num tasks: 1
2025-06-20 03:43:57,507 - INFO -   num classes: 2
2025-06-20 03:43:57,507 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-06-20 03:43:57,508 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-06-20 03:43:57,511 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  0%|          | 0/41127 [00:13<?, ?it/s]  4%|▍         | 1562/41127 [00:13<05:32, 119.07it/s]  8%|▊         | 3282/41127 [00:23<04:18, 146.65it/s] 10%|▉         | 4003/41127 [00:34<05:39, 109.43it/s] 12%|█▏        | 5030/41127 [00:45<05:51, 102.74it/s] 12%|█▏        | 5137/41127 [00:56<08:38, 69.44it/s]  14%|█▎        | 5634/41127 [01:06<09:21, 63.19it/s] 15%|█▍        | 5988/41127 [01:16<10:48, 54.22it/s] 15%|█▌        | 6204/41127 [01:27<13:33, 42.93it/s] 16%|█▌        | 6449/41127 [01:37<15:33, 37.15it/s] 16%|█▌        | 6534/41127 [01:48<20:14, 28.49it/s] 16%|█▋        | 6773/41127 [01:58<21:06, 27.12it/s] 18%|█▊        | 7603/41127 [02:08<12:58, 43.09it/s] 20%|██        | 8355/41127 [02:18<10:29, 52.05it/s] 23%|██▎       | 9299/41127 [02:29<08:25, 62.96it/s] 25%|██▍       | 10201/41127 [02:39<07:19, 70.40it/s] 26%|██▌       | 10636/41127 [02:50<08:10, 62.19it/s] 26%|██▋       | 10884/41127 [03:00<09:53, 51.00it/s] 30%|███       | 12374/41127 [03:10<06:00, 79.65it/s] 33%|███▎      | 13492/41127 [03:20<05:11, 88.78it/s] 34%|███▎      | 13834/41127 [03:30<06:16, 72.50it/s] 35%|███▍      | 14339/41127 [03:41<06:58, 63.95it/s] 36%|███▌      | 14744/41127 [03:52<07:49, 56.16it/s] 36%|███▌      | 14756/41127 [04:02<10:59, 40.00it/s] 37%|███▋      | 15311/41127 [04:13<09:53, 43.53it/s] 38%|███▊      | 15510/41127 [04:23<11:40, 36.56it/s] 38%|███▊      | 15605/41127 [04:34<15:10, 28.04it/s] 40%|███▉      | 16305/41127 [04:44<10:24, 39.78it/s] 40%|███▉      | 16410/41127 [04:54<13:14, 31.11it/s] 40%|████      | 16469/41127 [05:05<17:34, 23.38it/s] 40%|████      | 16538/41127 [05:15<22:29, 18.22it/s] 44%|████▍     | 18107/41127 [05:26<06:40, 57.53it/s] 45%|████▌     | 18652/41127 [05:37<06:46, 55.22it/s] 47%|████▋     | 19277/41127 [05:47<06:21, 57.26it/s] 48%|████▊     | 19702/41127 [05:57<06:50, 52.18it/s] 51%|█████     | 20801/41127 [06:07<04:55, 68.80it/s] 51%|█████▏    | 21126/41127 [06:18<05:47, 57.47it/s] 52%|█████▏    | 21529/41127 [06:29<06:21, 51.37it/s] 54%|█████▍    | 22243/41127 [06:39<05:35, 56.25it/s] 56%|█████▋    | 23184/41127 [06:49<04:29, 66.54it/s] 58%|█████▊    | 23687/41127 [07:00<04:46, 60.78it/s] 60%|█████▉    | 24481/41127 [07:11<04:17, 64.68it/s] 62%|██████▏   | 25486/41127 [07:21<03:28, 75.00it/s] 64%|██████▍   | 26386/41127 [07:31<03:06, 79.01it/s] 65%|██████▍   | 26664/41127 [07:42<03:51, 62.53it/s] 67%|██████▋   | 27631/41127 [07:53<03:11, 70.66it/s] 71%|███████   | 29257/41127 [08:04<02:06, 93.94it/s] 71%|███████   | 29266/41127 [08:14<02:58, 66.61it/s] 71%|███████▏  | 29331/41127 [08:25<04:03, 48.46it/s] 72%|███████▏  | 29419/41127 [08:35<05:18, 36.72it/s] 74%|███████▎  | 30328/41127 [08:46<03:27, 52.00it/s] 76%|███████▌  | 31085/41127 [08:56<02:51, 58.55it/s] 76%|███████▌  | 31115/41127 [09:06<03:58, 42.01it/s] 76%|███████▌  | 31129/41127 [09:17<05:38, 29.57it/s] 78%|███████▊  | 31986/41127 [09:27<03:19, 45.91it/s] 79%|███████▉  | 32529/41127 [09:37<02:59, 47.87it/s] 80%|████████  | 32906/41127 [09:48<03:07, 43.82it/s] 83%|████████▎ | 34005/41127 [09:59<01:56, 61.09it/s] 84%|████████▍ | 34478/41127 [10:10<02:00, 55.39it/s] 84%|████████▍ | 34581/41127 [10:21<02:37, 41.51it/s] 85%|████████▍ | 34913/41127 [10:32<02:43, 38.00it/s] 86%|████████▌ | 35433/41127 [10:42<02:16, 41.71it/s] 86%|████████▋ | 35477/41127 [10:52<03:02, 31.03it/s] 87%|████████▋ | 35616/41127 [11:03<03:35, 25.58it/s] 90%|████████▉ | 36856/41127 [11:14<01:21, 52.32it/s] 92%|█████████▏| 37957/41127 [11:25<00:47, 66.96it/s] 93%|█████████▎| 38403/41127 [11:35<00:45, 59.73it/s] 94%|█████████▍| 38732/41127 [11:47<00:47, 50.44it/s] 95%|█████████▍| 39003/41127 [11:58<00:49, 42.69it/s] 96%|█████████▌| 39528/41127 [12:08<00:35, 45.46it/s] 97%|█████████▋| 39748/41127 [12:18<00:36, 37.86it/s] 97%|█████████▋| 40066/41127 [12:29<00:29, 35.88it/s] 98%|█████████▊| 40159/41127 [12:40<00:35, 27.43it/s] 98%|█████████▊| 40356/41127 [12:50<00:30, 25.12it/s] 99%|█████████▉| 40745/41127 [13:00<00:13, 28.44it/s]100%|█████████▉| 40958/41127 [13:11<00:06, 26.12it/s]100%|█████████▉| 41001/41127 [13:21<00:06, 19.52it/s]100%|█████████▉| 41037/41127 [13:31<00:06, 14.89it/s]100%|██████████| 41127/41127 [13:34<00:00, 50.50it/s]
2025-06-20 03:57:33,318 - INFO - Done! Took 00:13:35.81
2025-06-20 03:57:33,478 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-06-20 03:57:33,609 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-06-20 03:57:33,609 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-06-20 03:57:33,609 - INFO - Inner model has get_darts_model: False
2025-06-20 03:57:33,615 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=Transformer, heads=4
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-06-20 03:57:33,618 - INFO - Number of parameters: 514,193
2025-06-20 03:57:33,618 - INFO - Starting optimized training: 2025-06-20 03:57:33.618555
2025-06-20 03:57:40,494 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-20 03:57:40,495 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-06-20 03:57:40,496 - INFO -   undirected: True
2025-06-20 03:57:40,496 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-06-20 03:57:40,496 - INFO -   avg num_nodes/graph: 25
2025-06-20 03:57:40,496 - INFO -   num node features: 9
2025-06-20 03:57:40,497 - INFO -   num edge features: 3
2025-06-20 03:57:40,497 - INFO -   num tasks: 1
2025-06-20 03:57:40,497 - INFO -   num classes: 2
2025-06-20 03:57:40,497 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-06-20 03:57:40,497 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-06-20 03:57:40,500 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  0%|          | 0/41127 [00:10<?, ?it/s]  3%|▎         | 1372/41127 [00:10<05:02, 131.49it/s]  5%|▌         | 2188/41127 [00:21<06:37, 98.02it/s]   8%|▊         | 3476/41127 [00:31<05:37, 111.58it/s] 11%|█         | 4418/41127 [00:42<06:03, 101.05it/s] 12%|█▏        | 5047/41127 [00:52<06:53, 87.26it/s]  13%|█▎        | 5275/41127 [01:03<09:22, 63.79it/s] 14%|█▍        | 5858/41127 [01:14<09:49, 59.82it/s] 15%|█▍        | 6025/41127 [01:25<12:51, 45.49it/s] 15%|█▌        | 6319/41127 [01:36<14:43, 39.40it/s] 16%|█▌        | 6500/41127 [01:46<17:22, 33.21it/s] 16%|█▌        | 6563/41127 [01:57<22:55, 25.12it/s] 17%|█▋        | 7019/41127 [02:07<18:30, 30.73it/s] 19%|█▉        | 7889/41127 [02:17<11:50, 46.78it/s] 21%|██▏       | 8832/41127 [02:28<09:00, 59.76it/s] 24%|██▍       | 9888/41127 [02:38<07:07, 73.13it/s] 26%|██▌       | 10631/41127 [02:49<07:08, 71.17it/s] 26%|██▋       | 10834/41127 [02:59<08:58, 56.28it/s] 29%|██▊       | 11806/41127 [03:10<07:17, 67.08it/s] 31%|███       | 12800/41127 [03:21<06:20, 74.48it/s] 34%|███▎      | 13800/41127 [03:31<05:42, 79.88it/s] 34%|███▍      | 14107/41127 [03:42<07:01, 64.04it/s] 36%|███▌      | 14738/41127 [03:53<07:05, 62.07it/s] 36%|███▌      | 14753/41127 [04:04<10:01, 43.84it/s] 37%|███▋      | 15029/41127 [04:14<11:07, 39.11it/s] 38%|███▊      | 15508/41127 [04:26<10:38, 40.09it/s] 38%|███▊      | 15519/41127 [04:36<15:02, 28.39it/s] 39%|███▊      | 15900/41127 [04:46<13:30, 31.14it/s] 40%|███▉      | 16402/41127 [04:57<11:32, 35.73it/s] 40%|████      | 16468/41127 [05:07<15:02, 27.32it/s] 40%|████      | 16525/41127 [05:17<19:28, 21.05it/s] 42%|████▏     | 17342/41127 [05:27<10:13, 38.79it/s] 45%|████▍     | 18487/41127 [05:37<06:10, 61.12it/s] 46%|████▋     | 19038/41127 [05:48<06:20, 58.09it/s] 48%|████▊     | 19617/41127 [05:59<06:19, 56.70it/s] 50%|█████     | 20614/41127 [06:09<04:56, 69.11it/s] 51%|█████▏    | 21125/41127 [06:20<05:22, 62.11it/s] 52%|█████▏    | 21251/41127 [06:30<07:00, 47.29it/s] 54%|█████▍    | 22242/41127 [06:41<05:07, 61.47it/s] 56%|█████▌    | 23109/41127 [06:51<04:23, 68.42it/s] 58%|█████▊    | 23686/41127 [07:02<04:31, 64.25it/s] 60%|█████▉    | 24481/41127 [07:12<04:05, 67.86it/s] 62%|██████▏   | 25493/41127 [07:23<03:28, 75.03it/s] 64%|██████▍   | 26387/41127 [07:34<03:08, 78.27it/s] 65%|██████▍   | 26728/41127 [07:44<03:44, 64.12it/s] 69%|██████▉   | 28294/41127 [07:55<02:25, 88.02it/s] 71%|███████   | 29259/41127 [08:06<02:13, 89.04it/s] 71%|███████   | 29269/41127 [08:17<03:10, 62.32it/s] 71%|███████▏  | 29346/41127 [08:27<04:15, 46.03it/s] 72%|███████▏  | 29441/41127 [08:38<05:32, 35.13it/s] 74%|███████▍  | 30351/41127 [08:49<03:37, 49.58it/s] 76%|███████▌  | 31087/41127 [08:59<03:00, 55.63it/s] 76%|███████▌  | 31118/41127 [09:10<04:09, 40.07it/s] 76%|███████▋  | 31442/41127 [09:21<04:20, 37.11it/s] 79%|███████▉  | 32424/41127 [09:31<02:39, 54.65it/s] 79%|███████▉  | 32571/41127 [09:42<03:26, 41.40it/s] 80%|████████  | 33067/41127 [09:52<03:07, 42.98it/s] 83%|████████▎ | 34218/41127 [10:03<01:49, 63.32it/s] 84%|████████▍ | 34508/41127 [10:13<02:04, 53.37it/s] 84%|████████▍ | 34583/41127 [10:23<02:46, 39.26it/s] 85%|████████▍ | 34946/41127 [10:33<02:41, 38.26it/s] 86%|████████▌ | 35434/41127 [10:44<02:21, 40.11it/s] 86%|████████▋ | 35505/41127 [10:56<03:09, 29.64it/s] 87%|████████▋ | 35921/41127 [11:06<02:37, 33.05it/s] 90%|████████▉ | 36857/41127 [11:16<01:25, 50.22it/s] 93%|█████████▎| 38151/41127 [11:26<00:41, 72.12it/s] 93%|█████████▎| 38403/41127 [11:37<00:47, 57.73it/s] 94%|█████████▍| 38732/41127 [11:47<00:47, 49.91it/s] 95%|█████████▍| 39003/41127 [11:58<00:49, 42.92it/s] 96%|█████████▌| 39548/41127 [12:08<00:34, 45.26it/s] 97%|█████████▋| 40017/41127 [12:19<00:24, 45.03it/s] 97%|█████████▋| 40069/41127 [12:30<00:32, 32.69it/s] 98%|█████████▊| 40346/41127 [12:41<00:25, 30.33it/s] 98%|█████████▊| 40481/41127 [12:51<00:25, 25.20it/s] 99%|█████████▉| 40749/41127 [13:02<00:15, 25.12it/s]100%|█████████▉| 40976/41127 [13:13<00:06, 23.88it/s]100%|█████████▉| 41030/41127 [13:24<00:05, 18.16it/s]100%|██████████| 41127/41127 [13:30<00:00, 50.72it/s]
2025-06-20 04:11:12,720 - INFO - Done! Took 00:13:32.22
2025-06-20 04:11:12,885 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-06-20 04:11:12,904 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-06-20 04:11:12,904 - INFO - Start from epoch 0
2025-06-20 04:12:27,067 - INFO - train: {'epoch': 0, 'time_epoch': 73.76192, 'eta': 7302.42975, 'eta_hours': 2.02845, 'loss': 0.88283524, 'lr': 0.0, 'params': 514193, 'time_iter': 0.07168, 'accuracy': 0.03745, 'precision': 0.03745, 'recall': 1.0, 'f1': 0.07219, 'auc': 0.45857}
2025-06-20 04:12:27,080 - INFO - ...computing epoch stats took: 0.38s
2025-06-20 04:12:31,647 - INFO - val: {'epoch': 0, 'time_epoch': 4.54629, 'loss': 0.89694621, 'lr': 0, 'params': 514193, 'time_iter': 0.03524, 'accuracy': 0.01969, 'precision': 0.01969, 'recall': 1.0, 'f1': 0.03863, 'auc': 0.42113}
2025-06-20 04:12:31,657 - INFO - ...computing epoch stats took: 0.03s
2025-06-20 04:12:35,640 - INFO - test: {'epoch': 0, 'time_epoch': 3.96335, 'loss': 0.90524137, 'lr': 0, 'params': 514193, 'time_iter': 0.03072, 'accuracy': 0.03161, 'precision': 0.03161, 'recall': 1.0, 'f1': 0.06128, 'auc': 0.39071}
2025-06-20 04:12:35,649 - INFO - ...computing epoch stats took: 0.03s
2025-06-20 04:12:35,650 - INFO - > Epoch 0: took 82.7s (avg 82.7s) | Best so far: epoch 0	train_loss: 0.8828 train_auc: 0.4586	val_loss: 0.8969 val_auc: 0.4211	test_loss: 0.9052 test_auc: 0.3907
2025-06-20 04:13:45,789 - INFO - train: {'epoch': 1, 'time_epoch': 69.95108, 'eta': 7041.93686, 'eta_hours': 1.95609, 'loss': 0.71920364, 'lr': 2e-05, 'params': 514193, 'time_iter': 0.06798, 'accuracy': 0.30321, 'precision': 0.03874, 'recall': 0.73945, 'f1': 0.07363, 'auc': 0.5116}
2025-06-20 04:13:45,811 - INFO - ...computing epoch stats took: 0.18s
2025-06-20 04:13:49,490 - INFO - val: {'epoch': 1, 'time_epoch': 3.66153, 'loss': 0.56826612, 'lr': 0, 'params': 514193, 'time_iter': 0.02838, 'accuracy': 0.57744, 'precision': 0.02193, 'recall': 0.46914, 'f1': 0.0419, 'auc': 0.51442}
2025-06-20 04:13:49,499 - INFO - ...computing epoch stats took: 0.02s
2025-06-20 04:13:53,033 - INFO - test: {'epoch': 1, 'time_epoch': 3.51668, 'loss': 0.54096597, 'lr': 0, 'params': 514193, 'time_iter': 0.02726, 'accuracy': 0.60977, 'precision': 0.03877, 'recall': 0.47692, 'f1': 0.07172, 'auc': 0.53518}
2025-06-20 04:13:53,039 - INFO - ...computing epoch stats took: 0.02s
2025-06-20 04:13:53,039 - INFO - > Epoch 1: took 77.4s (avg 80.1s) | Best so far: epoch 1	train_loss: 0.7192 train_auc: 0.5116	val_loss: 0.5683 val_auc: 0.5144	test_loss: 0.5410 test_auc: 0.5352
2025-06-20 04:15:01,939 - INFO - train: {'epoch': 2, 'time_epoch': 68.63803, 'eta': 6866.01665, 'eta_hours': 1.90723, 'loss': 0.3261406, 'lr': 4e-05, 'params': 514193, 'time_iter': 0.0667, 'accuracy': 0.8649, 'precision': 0.04836, 'recall': 0.13961, 'f1': 0.07183, 'auc': 0.55691}
2025-06-20 04:15:01,970 - INFO - ...computing epoch stats took: 0.27s
2025-06-20 04:15:05,605 - INFO - val: {'epoch': 2, 'time_epoch': 3.61666, 'loss': 0.15950416, 'lr': 0, 'params': 514193, 'time_iter': 0.02804, 'accuracy': 0.97666, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.5504}
2025-06-20 04:15:05,615 - INFO - ...computing epoch stats took: 0.02s
2025-06-20 04:15:09,113 - INFO - test: {'epoch': 2, 'time_epoch': 3.4798, 'loss': 0.18868982, 'lr': 0, 'params': 514193, 'time_iter': 0.02698, 'accuracy': 0.96475, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.55056}
2025-06-20 04:15:09,125 - INFO - ...computing epoch stats took: 0.03s
2025-06-20 04:15:09,126 - INFO - > Epoch 2: took 76.1s (avg 78.7s) | Best so far: epoch 2	train_loss: 0.3261 train_auc: 0.5569	val_loss: 0.1595 val_auc: 0.5504	test_loss: 0.1887 test_auc: 0.5506
2025-06-20 04:16:17,150 - INFO - train: {'epoch': 3, 'time_epoch': 67.78095, 'eta': 6723.16742, 'eta_hours': 1.86755, 'loss': 0.17305661, 'lr': 6e-05, 'params': 514193, 'time_iter': 0.06587, 'accuracy': 0.96167, 'precision': 0.03226, 'recall': 0.00081, 'f1': 0.00158, 'auc': 0.59081}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-20 04:16:20,674 - INFO - val: {'epoch': 3, 'time_epoch': 3.48027, 'loss': 0.10437261, 'lr': 0, 'params': 514193, 'time_iter': 0.02698, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67426}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-20 04:16:24,175 - INFO - test: {'epoch': 3, 'time_epoch': 3.47627, 'loss': 0.14136467, 'lr': 0, 'params': 514193, 'time_iter': 0.02695, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6336}
2025-06-20 04:16:24,180 - INFO - > Epoch 3: took 75.1s (avg 77.8s) | Best so far: epoch 3	train_loss: 0.1731 train_auc: 0.5908	val_loss: 0.1044 val_auc: 0.6743	test_loss: 0.1414 test_auc: 0.6336
2025-06-20 04:17:31,758 - INFO - train: {'epoch': 4, 'time_epoch': 67.29148, 'eta': 6601.04557, 'eta_hours': 1.83362, 'loss': 0.15354961, 'lr': 8e-05, 'params': 514193, 'time_iter': 0.0654, 'accuracy': 0.96252, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6696}
2025-06-20 04:17:35,416 - INFO - val: {'epoch': 4, 'time_epoch': 3.62671, 'loss': 0.09876218, 'lr': 0, 'params': 514193, 'time_iter': 0.02811, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.01235, 'f1': 0.0241, 'auc': 0.70204}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-20 04:17:39,000 - INFO - test: {'epoch': 4, 'time_epoch': 3.55348, 'loss': 0.13066289, 'lr': 0, 'params': 514193, 'time_iter': 0.02755, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69314}
2025-06-20 04:17:39,008 - INFO - > Epoch 4: took 74.8s (avg 77.2s) | Best so far: epoch 4	train_loss: 0.1535 train_auc: 0.6696	val_loss: 0.0988 val_auc: 0.7020	test_loss: 0.1307 test_auc: 0.6931
2025-06-20 04:18:50,230 - INFO - train: {'epoch': 5, 'time_epoch': 70.91797, 'eta': 6554.01559, 'eta_hours': 1.82056, 'loss': 0.14922091, 'lr': 0.0001, 'params': 514193, 'time_iter': 0.06892, 'accuracy': 0.96255, 'precision': 0.5, 'recall': 0.00081, 'f1': 0.00162, 'auc': 0.70183}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-20 04:18:54,004 - INFO - val: {'epoch': 5, 'time_epoch': 3.72185, 'loss': 0.09172953, 'lr': 0, 'params': 514193, 'time_iter': 0.02885, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69255}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-20 04:18:57,700 - INFO - test: {'epoch': 5, 'time_epoch': 3.67222, 'loss': 0.12447922, 'lr': 0, 'params': 514193, 'time_iter': 0.02847, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73625}
2025-06-20 04:18:57,707 - INFO - > Epoch 5: took 78.7s (avg 77.5s) | Best so far: epoch 4	train_loss: 0.1535 train_auc: 0.6696	val_loss: 0.0988 val_auc: 0.7020	test_loss: 0.1307 test_auc: 0.6931
2025-06-20 04:20:09,974 - INFO - train: {'epoch': 6, 'time_epoch': 72.03202, 'eta': 6514.9614, 'eta_hours': 1.80971, 'loss': 0.1432534, 'lr': 9.997e-05, 'params': 514193, 'time_iter': 0.07, 'accuracy': 0.96255, 'precision': 0.5, 'recall': 0.00974, 'f1': 0.01911, 'auc': 0.71942}
2025-06-20 04:20:13,644 - INFO - val: {'epoch': 6, 'time_epoch': 3.61379, 'loss': 0.09323231, 'lr': 0, 'params': 514193, 'time_iter': 0.02801, 'accuracy': 0.98006, 'precision': 0.33333, 'recall': 0.01235, 'f1': 0.02381, 'auc': 0.71203}
2025-06-20 04:20:17,325 - INFO - test: {'epoch': 6, 'time_epoch': 3.64741, 'loss': 0.12313584, 'lr': 0, 'params': 514193, 'time_iter': 0.02827, 'accuracy': 0.96815, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72373}
2025-06-20 04:20:17,337 - INFO - > Epoch 6: took 79.6s (avg 77.8s) | Best so far: epoch 6	train_loss: 0.1433 train_auc: 0.7194	val_loss: 0.0932 val_auc: 0.7120	test_loss: 0.1231 test_auc: 0.7237
2025-06-20 04:21:26,031 - INFO - train: {'epoch': 7, 'time_epoch': 68.40935, 'eta': 6426.00207, 'eta_hours': 1.785, 'loss': 0.14003113, 'lr': 9.989e-05, 'params': 514193, 'time_iter': 0.06648, 'accuracy': 0.96307, 'precision': 0.63077, 'recall': 0.03328, 'f1': 0.06322, 'auc': 0.73324}
2025-06-20 04:21:29,663 - INFO - val: {'epoch': 7, 'time_epoch': 3.5982, 'loss': 0.10165549, 'lr': 0, 'params': 514193, 'time_iter': 0.02789, 'accuracy': 0.97228, 'precision': 0.21053, 'recall': 0.14815, 'f1': 0.17391, 'auc': 0.71501}
2025-06-20 04:21:33,125 - INFO - test: {'epoch': 7, 'time_epoch': 3.43946, 'loss': 0.13654849, 'lr': 0, 'params': 514193, 'time_iter': 0.02666, 'accuracy': 0.96256, 'precision': 0.33784, 'recall': 0.19231, 'f1': 0.2451, 'auc': 0.74331}
2025-06-20 04:21:33,136 - INFO - > Epoch 7: took 75.8s (avg 77.5s) | Best so far: epoch 7	train_loss: 0.1400 train_auc: 0.7332	val_loss: 0.1017 val_auc: 0.7150	test_loss: 0.1365 test_auc: 0.7433
2025-06-20 04:22:39,284 - INFO - train: {'epoch': 8, 'time_epoch': 65.84949, 'eta': 6315.72634, 'eta_hours': 1.75437, 'loss': 0.1373528, 'lr': 9.975e-05, 'params': 514193, 'time_iter': 0.06399, 'accuracy': 0.96277, 'precision': 0.528, 'recall': 0.05357, 'f1': 0.09727, 'auc': 0.74695}
2025-06-20 04:22:42,851 - INFO - val: {'epoch': 8, 'time_epoch': 3.53328, 'loss': 0.08559865, 'lr': 0, 'params': 514193, 'time_iter': 0.02739, 'accuracy': 0.98055, 'precision': 0.52174, 'recall': 0.14815, 'f1': 0.23077, 'auc': 0.74436}
2025-06-20 04:22:46,293 - INFO - test: {'epoch': 8, 'time_epoch': 3.41287, 'loss': 0.11680279, 'lr': 0, 'params': 514193, 'time_iter': 0.02646, 'accuracy': 0.97107, 'precision': 0.63415, 'recall': 0.2, 'f1': 0.30409, 'auc': 0.74714}
2025-06-20 04:22:46,305 - INFO - > Epoch 8: took 73.2s (avg 77.0s) | Best so far: epoch 8	train_loss: 0.1374 train_auc: 0.7470	val_loss: 0.0856 val_auc: 0.7444	test_loss: 0.1168 test_auc: 0.7471
2025-06-20 04:23:54,421 - INFO - train: {'epoch': 9, 'time_epoch': 67.83338, 'eta': 6232.19087, 'eta_hours': 1.73116, 'loss': 0.13428218, 'lr': 9.956e-05, 'params': 514193, 'time_iter': 0.06592, 'accuracy': 0.96356, 'precision': 0.58049, 'recall': 0.09659, 'f1': 0.16562, 'auc': 0.75893}
2025-06-20 04:23:57,977 - INFO - val: {'epoch': 9, 'time_epoch': 3.5292, 'loss': 0.08764732, 'lr': 0, 'params': 514193, 'time_iter': 0.02736, 'accuracy': 0.98079, 'precision': 0.53846, 'recall': 0.17284, 'f1': 0.26168, 'auc': 0.75186}
2025-06-20 04:24:01,396 - INFO - test: {'epoch': 9, 'time_epoch': 3.39908, 'loss': 0.12282712, 'lr': 0, 'params': 514193, 'time_iter': 0.02635, 'accuracy': 0.97155, 'precision': 0.67568, 'recall': 0.19231, 'f1': 0.2994, 'auc': 0.73218}
2025-06-20 04:24:01,398 - INFO - > Epoch 9: took 75.1s (avg 76.8s) | Best so far: epoch 9	train_loss: 0.1343 train_auc: 0.7589	val_loss: 0.0876 val_auc: 0.7519	test_loss: 0.1228 test_auc: 0.7322
2025-06-20 04:25:11,489 - INFO - train: {'epoch': 10, 'time_epoch': 69.75738, 'eta': 6167.07727, 'eta_hours': 1.71308, 'loss': 0.12955605, 'lr': 9.932e-05, 'params': 514193, 'time_iter': 0.06779, 'accuracy': 0.96423, 'precision': 0.603, 'recall': 0.13068, 'f1': 0.21481, 'auc': 0.78205}
2025-06-20 04:25:15,065 - INFO - val: {'epoch': 10, 'time_epoch': 3.52646, 'loss': 0.08509093, 'lr': 0, 'params': 514193, 'time_iter': 0.02734, 'accuracy': 0.98055, 'precision': 0.51724, 'recall': 0.18519, 'f1': 0.27273, 'auc': 0.77119}
2025-06-20 04:25:18,533 - INFO - test: {'epoch': 10, 'time_epoch': 3.44383, 'loss': 0.11843731, 'lr': 0, 'params': 514193, 'time_iter': 0.0267, 'accuracy': 0.97058, 'precision': 0.57627, 'recall': 0.26154, 'f1': 0.35979, 'auc': 0.75701}
2025-06-20 04:25:18,543 - INFO - > Epoch 10: took 77.1s (avg 76.9s) | Best so far: epoch 10	train_loss: 0.1296 train_auc: 0.7821	val_loss: 0.0851 val_auc: 0.7712	test_loss: 0.1184 test_auc: 0.7570
2025-06-20 04:26:25,416 - INFO - train: {'epoch': 11, 'time_epoch': 66.45939, 'eta': 6077.0044, 'eta_hours': 1.68806, 'loss': 0.12810723, 'lr': 9.902e-05, 'params': 514193, 'time_iter': 0.06459, 'accuracy': 0.96447, 'precision': 0.60129, 'recall': 0.15179, 'f1': 0.24238, 'auc': 0.78604}
2025-06-20 04:26:28,917 - INFO - val: {'epoch': 11, 'time_epoch': 3.44764, 'loss': 0.08997778, 'lr': 0, 'params': 514193, 'time_iter': 0.02673, 'accuracy': 0.97739, 'precision': 0.35714, 'recall': 0.18519, 'f1': 0.2439, 'auc': 0.75878}
2025-06-20 04:26:32,385 - INFO - test: {'epoch': 11, 'time_epoch': 3.44663, 'loss': 0.12714237, 'lr': 0, 'params': 514193, 'time_iter': 0.02672, 'accuracy': 0.96718, 'precision': 0.46154, 'recall': 0.23077, 'f1': 0.30769, 'auc': 0.74594}
2025-06-20 04:26:32,391 - INFO - > Epoch 11: took 73.8s (avg 76.6s) | Best so far: epoch 10	train_loss: 0.1296 train_auc: 0.7821	val_loss: 0.0851 val_auc: 0.7712	test_loss: 0.1184 test_auc: 0.7570
2025-06-20 04:27:39,669 - INFO - train: {'epoch': 12, 'time_epoch': 67.05339, 'eta': 5994.53967, 'eta_hours': 1.66515, 'loss': 0.12508426, 'lr': 9.867e-05, 'params': 514193, 'time_iter': 0.06516, 'accuracy': 0.96541, 'precision': 0.62772, 'recall': 0.1875, 'f1': 0.28875, 'auc': 0.79487}
2025-06-20 04:27:43,273 - INFO - val: {'epoch': 12, 'time_epoch': 3.52268, 'loss': 0.08765992, 'lr': 0, 'params': 514193, 'time_iter': 0.02731, 'accuracy': 0.9786, 'precision': 0.42857, 'recall': 0.25926, 'f1': 0.32308, 'auc': 0.75656}
2025-06-20 04:27:46,717 - INFO - test: {'epoch': 12, 'time_epoch': 3.42347, 'loss': 0.12372216, 'lr': 0, 'params': 514193, 'time_iter': 0.02654, 'accuracy': 0.96693, 'precision': 0.45946, 'recall': 0.26154, 'f1': 0.33333, 'auc': 0.74458}
2025-06-20 04:27:46,727 - INFO - > Epoch 12: took 74.3s (avg 76.4s) | Best so far: epoch 10	train_loss: 0.1296 train_auc: 0.7821	val_loss: 0.0851 val_auc: 0.7712	test_loss: 0.1184 test_auc: 0.7570
2025-06-20 04:28:54,650 - INFO - train: {'epoch': 13, 'time_epoch': 67.64578, 'eta': 5917.91548, 'eta_hours': 1.64387, 'loss': 0.1241149, 'lr': 9.826e-05, 'params': 514193, 'time_iter': 0.06574, 'accuracy': 0.96617, 'precision': 0.64764, 'recall': 0.21185, 'f1': 0.31927, 'auc': 0.79662}
2025-06-20 04:28:58,220 - INFO - val: {'epoch': 13, 'time_epoch': 3.53513, 'loss': 0.08021657, 'lr': 0, 'params': 514193, 'time_iter': 0.0274, 'accuracy': 0.98152, 'precision': 0.6087, 'recall': 0.17284, 'f1': 0.26923, 'auc': 0.75102}
2025-06-20 04:29:01,668 - INFO - test: {'epoch': 13, 'time_epoch': 3.4234, 'loss': 0.11736097, 'lr': 0, 'params': 514193, 'time_iter': 0.02654, 'accuracy': 0.97082, 'precision': 0.77778, 'recall': 0.10769, 'f1': 0.18919, 'auc': 0.7662}
2025-06-20 04:29:01,673 - INFO - > Epoch 13: took 74.9s (avg 76.3s) | Best so far: epoch 10	train_loss: 0.1296 train_auc: 0.7821	val_loss: 0.0851 val_auc: 0.7712	test_loss: 0.1184 test_auc: 0.7570
2025-06-20 04:30:10,308 - INFO - train: {'epoch': 14, 'time_epoch': 68.36302, 'eta': 5846.55277, 'eta_hours': 1.62404, 'loss': 0.12163111, 'lr': 9.78e-05, 'params': 514193, 'time_iter': 0.06644, 'accuracy': 0.96657, 'precision': 0.65, 'recall': 0.23214, 'f1': 0.34211, 'auc': 0.80713}
2025-06-20 04:30:13,820 - INFO - val: {'epoch': 14, 'time_epoch': 3.48392, 'loss': 0.098609, 'lr': 0, 'params': 514193, 'time_iter': 0.02701, 'accuracy': 0.9735, 'precision': 0.3, 'recall': 0.25926, 'f1': 0.27815, 'auc': 0.75433}
2025-06-20 04:30:17,299 - INFO - test: {'epoch': 14, 'time_epoch': 3.45673, 'loss': 0.13119489, 'lr': 0, 'params': 514193, 'time_iter': 0.0268, 'accuracy': 0.96061, 'precision': 0.37097, 'recall': 0.35385, 'f1': 0.3622, 'auc': 0.75275}
2025-06-20 04:30:17,301 - INFO - > Epoch 14: took 75.6s (avg 76.3s) | Best so far: epoch 10	train_loss: 0.1296 train_auc: 0.7821	val_loss: 0.0851 val_auc: 0.7712	test_loss: 0.1184 test_auc: 0.7570
2025-06-20 04:31:24,676 - INFO - train: {'epoch': 15, 'time_epoch': 66.99088, 'eta': 5768.36128, 'eta_hours': 1.60232, 'loss': 0.11890586, 'lr': 9.729e-05, 'params': 514193, 'time_iter': 0.0651, 'accuracy': 0.96714, 'precision': 0.66966, 'recall': 0.24188, 'f1': 0.3554, 'auc': 0.81613}
2025-06-20 04:31:28,168 - INFO - val: {'epoch': 15, 'time_epoch': 3.46188, 'loss': 0.08230622, 'lr': 0, 'params': 514193, 'time_iter': 0.02684, 'accuracy': 0.98225, 'precision': 0.61111, 'recall': 0.2716, 'f1': 0.37607, 'auc': 0.71288}
2025-06-20 04:31:31,643 - INFO - test: {'epoch': 15, 'time_epoch': 3.44986, 'loss': 0.11989485, 'lr': 0, 'params': 514193, 'time_iter': 0.02674, 'accuracy': 0.96937, 'precision': 0.54545, 'recall': 0.18462, 'f1': 0.27586, 'auc': 0.72436}
2025-06-20 04:31:31,654 - INFO - > Epoch 15: took 74.4s (avg 76.2s) | Best so far: epoch 10	train_loss: 0.1296 train_auc: 0.7821	val_loss: 0.0851 val_auc: 0.7712	test_loss: 0.1184 test_auc: 0.7570
2025-06-20 04:32:38,867 - INFO - train: {'epoch': 16, 'time_epoch': 66.89246, 'eta': 5691.00701, 'eta_hours': 1.58084, 'loss': 0.11862212, 'lr': 9.673e-05, 'params': 514193, 'time_iter': 0.06501, 'accuracy': 0.96702, 'precision': 0.65806, 'recall': 0.24838, 'f1': 0.36064, 'auc': 0.81589}
2025-06-20 04:32:42,366 - INFO - val: {'epoch': 16, 'time_epoch': 3.46681, 'loss': 0.08198351, 'lr': 0, 'params': 514193, 'time_iter': 0.02687, 'accuracy': 0.97909, 'precision': 0.45455, 'recall': 0.30864, 'f1': 0.36765, 'auc': 0.77724}
2025-06-20 04:32:45,842 - INFO - test: {'epoch': 16, 'time_epoch': 3.45145, 'loss': 0.12375083, 'lr': 0, 'params': 514193, 'time_iter': 0.02676, 'accuracy': 0.96596, 'precision': 0.42857, 'recall': 0.23077, 'f1': 0.3, 'auc': 0.7432}
2025-06-20 04:32:45,852 - INFO - > Epoch 16: took 74.2s (avg 76.1s) | Best so far: epoch 16	train_loss: 0.1186 train_auc: 0.8159	val_loss: 0.0820 val_auc: 0.7772	test_loss: 0.1238 test_auc: 0.7432
2025-06-20 04:33:53,141 - INFO - train: {'epoch': 17, 'time_epoch': 67.07087, 'eta': 5615.62791, 'eta_hours': 1.5599, 'loss': 0.11515159, 'lr': 9.611e-05, 'params': 514193, 'time_iter': 0.06518, 'accuracy': 0.9679, 'precision': 0.66794, 'recall': 0.28409, 'f1': 0.39863, 'auc': 0.82921}
2025-06-20 04:33:56,687 - INFO - val: {'epoch': 17, 'time_epoch': 3.51859, 'loss': 0.09206989, 'lr': 0, 'params': 514193, 'time_iter': 0.02728, 'accuracy': 0.97836, 'precision': 0.43333, 'recall': 0.32099, 'f1': 0.36879, 'auc': 0.67133}
2025-06-20 04:34:00,161 - INFO - test: {'epoch': 17, 'time_epoch': 3.44882, 'loss': 0.1269528, 'lr': 0, 'params': 514193, 'time_iter': 0.02674, 'accuracy': 0.9645, 'precision': 0.40909, 'recall': 0.27692, 'f1': 0.33028, 'auc': 0.74167}
2025-06-20 04:34:00,167 - INFO - > Epoch 17: took 74.3s (avg 76.0s) | Best so far: epoch 16	train_loss: 0.1186 train_auc: 0.8159	val_loss: 0.0820 val_auc: 0.7772	test_loss: 0.1238 test_auc: 0.7432
2025-06-20 04:35:08,092 - INFO - train: {'epoch': 18, 'time_epoch': 67.7102, 'eta': 5543.84894, 'eta_hours': 1.53996, 'loss': 0.11447523, 'lr': 9.545e-05, 'params': 514193, 'time_iter': 0.0658, 'accuracy': 0.96821, 'precision': 0.68023, 'recall': 0.2849, 'f1': 0.4016, 'auc': 0.83766}
2025-06-20 04:35:11,556 - INFO - val: {'epoch': 18, 'time_epoch': 3.43613, 'loss': 0.08303862, 'lr': 0, 'params': 514193, 'time_iter': 0.02664, 'accuracy': 0.98225, 'precision': 0.6, 'recall': 0.2963, 'f1': 0.39669, 'auc': 0.73309}
2025-06-20 04:35:15,053 - INFO - test: {'epoch': 18, 'time_epoch': 3.46657, 'loss': 0.12722615, 'lr': 0, 'params': 514193, 'time_iter': 0.02687, 'accuracy': 0.96791, 'precision': 0.47727, 'recall': 0.16154, 'f1': 0.24138, 'auc': 0.72974}
2025-06-20 04:35:15,063 - INFO - > Epoch 18: took 74.9s (avg 75.9s) | Best so far: epoch 16	train_loss: 0.1186 train_auc: 0.8159	val_loss: 0.0820 val_auc: 0.7772	test_loss: 0.1238 test_auc: 0.7432
2025-06-20 04:36:24,352 - INFO - train: {'epoch': 19, 'time_epoch': 68.99887, 'eta': 5477.63151, 'eta_hours': 1.52156, 'loss': 0.11501242, 'lr': 9.474e-05, 'params': 514193, 'time_iter': 0.06705, 'accuracy': 0.96806, 'precision': 0.68209, 'recall': 0.27516, 'f1': 0.39213, 'auc': 0.83371}
2025-06-20 04:36:27,920 - INFO - val: {'epoch': 19, 'time_epoch': 3.54031, 'loss': 0.08032404, 'lr': 0, 'params': 514193, 'time_iter': 0.02744, 'accuracy': 0.98079, 'precision': 0.52632, 'recall': 0.24691, 'f1': 0.33613, 'auc': 0.78785}
2025-06-20 04:36:31,317 - INFO - test: {'epoch': 19, 'time_epoch': 3.37575, 'loss': 0.11722126, 'lr': 0, 'params': 514193, 'time_iter': 0.02617, 'accuracy': 0.96864, 'precision': 0.50909, 'recall': 0.21538, 'f1': 0.3027, 'auc': 0.7596}
2025-06-20 04:36:31,329 - INFO - > Epoch 19: took 76.3s (avg 75.9s) | Best so far: epoch 19	train_loss: 0.1150 train_auc: 0.8337	val_loss: 0.0803 val_auc: 0.7879	test_loss: 0.1172 test_auc: 0.7596
2025-06-20 04:37:36,820 - INFO - train: {'epoch': 20, 'time_epoch': 65.34627, 'eta': 5397.40847, 'eta_hours': 1.49928, 'loss': 0.11144772, 'lr': 9.397e-05, 'params': 514193, 'time_iter': 0.0635, 'accuracy': 0.96906, 'precision': 0.69815, 'recall': 0.30601, 'f1': 0.42551, 'auc': 0.84306}
2025-06-20 04:37:40,390 - INFO - val: {'epoch': 20, 'time_epoch': 3.40358, 'loss': 0.08152455, 'lr': 0, 'params': 514193, 'time_iter': 0.02638, 'accuracy': 0.98177, 'precision': 0.57895, 'recall': 0.2716, 'f1': 0.36975, 'auc': 0.77568}
2025-06-20 04:37:43,748 - INFO - test: {'epoch': 20, 'time_epoch': 3.3367, 'loss': 0.12038122, 'lr': 0, 'params': 514193, 'time_iter': 0.02587, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.21538, 'f1': 0.30108, 'auc': 0.75124}
2025-06-20 04:37:43,751 - INFO - > Epoch 20: took 72.4s (avg 75.8s) | Best so far: epoch 19	train_loss: 0.1150 train_auc: 0.8337	val_loss: 0.0803 val_auc: 0.7879	test_loss: 0.1172 test_auc: 0.7596
2025-06-20 04:38:50,685 - INFO - train: {'epoch': 21, 'time_epoch': 66.54852, 'eta': 5322.80039, 'eta_hours': 1.47856, 'loss': 0.1100116, 'lr': 9.316e-05, 'params': 514193, 'time_iter': 0.06467, 'accuracy': 0.96879, 'precision': 0.68402, 'recall': 0.30925, 'f1': 0.42594, 'auc': 0.85649}
2025-06-20 04:38:54,129 - INFO - val: {'epoch': 21, 'time_epoch': 3.40518, 'loss': 0.08445042, 'lr': 0, 'params': 514193, 'time_iter': 0.0264, 'accuracy': 0.9786, 'precision': 0.44262, 'recall': 0.33333, 'f1': 0.38028, 'auc': 0.7691}
2025-06-20 04:38:57,568 - INFO - test: {'epoch': 21, 'time_epoch': 3.41231, 'loss': 0.12417657, 'lr': 0, 'params': 514193, 'time_iter': 0.02645, 'accuracy': 0.96572, 'precision': 0.42667, 'recall': 0.24615, 'f1': 0.3122, 'auc': 0.76612}
2025-06-20 04:38:57,579 - INFO - > Epoch 21: took 73.8s (avg 75.7s) | Best so far: epoch 19	train_loss: 0.1150 train_auc: 0.8337	val_loss: 0.0803 val_auc: 0.7879	test_loss: 0.1172 test_auc: 0.7596
2025-06-20 04:40:04,045 - INFO - train: {'epoch': 22, 'time_epoch': 66.2051, 'eta': 5247.74343, 'eta_hours': 1.45771, 'loss': 0.11044805, 'lr': 9.23e-05, 'params': 514193, 'time_iter': 0.06434, 'accuracy': 0.96851, 'precision': 0.66838, 'recall': 0.31575, 'f1': 0.42889, 'auc': 0.85643}
2025-06-20 04:40:07,611 - INFO - val: {'epoch': 22, 'time_epoch': 3.53622, 'loss': 0.08599523, 'lr': 0, 'params': 514193, 'time_iter': 0.02741, 'accuracy': 0.97958, 'precision': 0.4717, 'recall': 0.30864, 'f1': 0.37313, 'auc': 0.76702}
2025-06-20 04:40:11,109 - INFO - test: {'epoch': 22, 'time_epoch': 3.47127, 'loss': 0.12032206, 'lr': 0, 'params': 514193, 'time_iter': 0.02691, 'accuracy': 0.96693, 'precision': 0.45714, 'recall': 0.24615, 'f1': 0.32, 'auc': 0.76331}
2025-06-20 04:40:11,119 - INFO - > Epoch 22: took 73.5s (avg 75.6s) | Best so far: epoch 19	train_loss: 0.1150 train_auc: 0.8337	val_loss: 0.0803 val_auc: 0.7879	test_loss: 0.1172 test_auc: 0.7596
2025-06-20 04:41:18,432 - INFO - train: {'epoch': 23, 'time_epoch': 67.06753, 'eta': 5176.15515, 'eta_hours': 1.43782, 'loss': 0.1068262, 'lr': 9.14e-05, 'params': 514193, 'time_iter': 0.06518, 'accuracy': 0.97009, 'precision': 0.72143, 'recall': 0.32792, 'f1': 0.45089, 'auc': 0.86716}
2025-06-20 04:41:21,951 - INFO - val: {'epoch': 23, 'time_epoch': 3.45602, 'loss': 0.08446008, 'lr': 0, 'params': 514193, 'time_iter': 0.02679, 'accuracy': 0.97933, 'precision': 0.46429, 'recall': 0.32099, 'f1': 0.37956, 'auc': 0.77752}
2025-06-20 04:41:25,374 - INFO - test: {'epoch': 23, 'time_epoch': 3.39418, 'loss': 0.12480318, 'lr': 0, 'params': 514193, 'time_iter': 0.02631, 'accuracy': 0.96645, 'precision': 0.45652, 'recall': 0.32308, 'f1': 0.37838, 'auc': 0.77087}
2025-06-20 04:41:25,383 - INFO - > Epoch 23: took 74.3s (avg 75.5s) | Best so far: epoch 19	train_loss: 0.1150 train_auc: 0.8337	val_loss: 0.0803 val_auc: 0.7879	test_loss: 0.1172 test_auc: 0.7596
2025-06-20 04:42:33,530 - INFO - train: {'epoch': 24, 'time_epoch': 67.92519, 'eta': 5107.50151, 'eta_hours': 1.41875, 'loss': 0.10733702, 'lr': 9.045e-05, 'params': 514193, 'time_iter': 0.06601, 'accuracy': 0.96985, 'precision': 0.70408, 'recall': 0.33604, 'f1': 0.45495, 'auc': 0.86188}
2025-06-20 04:42:37,106 - INFO - val: {'epoch': 24, 'time_epoch': 3.5447, 'loss': 0.08676903, 'lr': 0, 'params': 514193, 'time_iter': 0.02748, 'accuracy': 0.97958, 'precision': 0.47273, 'recall': 0.32099, 'f1': 0.38235, 'auc': 0.75766}
2025-06-20 04:42:40,671 - INFO - test: {'epoch': 24, 'time_epoch': 3.53351, 'loss': 0.12397447, 'lr': 0, 'params': 514193, 'time_iter': 0.02739, 'accuracy': 0.96766, 'precision': 0.48148, 'recall': 0.3, 'f1': 0.36967, 'auc': 0.75857}
2025-06-20 04:42:40,679 - INFO - > Epoch 24: took 75.3s (avg 75.5s) | Best so far: epoch 19	train_loss: 0.1150 train_auc: 0.8337	val_loss: 0.0803 val_auc: 0.7879	test_loss: 0.1172 test_auc: 0.7596
2025-06-20 04:43:47,500 - INFO - train: {'epoch': 25, 'time_epoch': 66.52429, 'eta': 5034.91671, 'eta_hours': 1.39859, 'loss': 0.10583418, 'lr': 8.946e-05, 'params': 514193, 'time_iter': 0.06465, 'accuracy': 0.97018, 'precision': 0.71826, 'recall': 0.33523, 'f1': 0.45711, 'auc': 0.86586}
2025-06-20 04:43:50,960 - INFO - val: {'epoch': 25, 'time_epoch': 3.43143, 'loss': 0.07697713, 'lr': 0, 'params': 514193, 'time_iter': 0.0266, 'accuracy': 0.98201, 'precision': 0.6, 'recall': 0.25926, 'f1': 0.36207, 'auc': 0.76619}
2025-06-20 04:43:54,395 - INFO - test: {'epoch': 25, 'time_epoch': 3.41349, 'loss': 0.11574077, 'lr': 0, 'params': 514193, 'time_iter': 0.02646, 'accuracy': 0.97107, 'precision': 0.64865, 'recall': 0.18462, 'f1': 0.28743, 'auc': 0.77189}
2025-06-20 04:43:54,500 - INFO - > Epoch 25: took 73.8s (avg 75.4s) | Best so far: epoch 19	train_loss: 0.1150 train_auc: 0.8337	val_loss: 0.0803 val_auc: 0.7879	test_loss: 0.1172 test_auc: 0.7596
2025-06-20 04:45:01,833 - INFO - train: {'epoch': 26, 'time_epoch': 67.0984, 'eta': 4964.33308, 'eta_hours': 1.37898, 'loss': 0.10467159, 'lr': 8.842e-05, 'params': 514193, 'time_iter': 0.06521, 'accuracy': 0.97012, 'precision': 0.70924, 'recall': 0.34253, 'f1': 0.46196, 'auc': 0.8724}
2025-06-20 04:45:05,309 - INFO - val: {'epoch': 26, 'time_epoch': 3.41497, 'loss': 0.08268611, 'lr': 0, 'params': 514193, 'time_iter': 0.02647, 'accuracy': 0.98055, 'precision': 0.5102, 'recall': 0.30864, 'f1': 0.38462, 'auc': 0.72511}
2025-06-20 04:45:08,756 - INFO - test: {'epoch': 26, 'time_epoch': 3.41691, 'loss': 0.12522807, 'lr': 0, 'params': 514193, 'time_iter': 0.02649, 'accuracy': 0.96645, 'precision': 0.44872, 'recall': 0.26923, 'f1': 0.33654, 'auc': 0.73276}
2025-06-20 04:45:08,770 - INFO - > Epoch 26: took 74.3s (avg 75.4s) | Best so far: epoch 19	train_loss: 0.1150 train_auc: 0.8337	val_loss: 0.0803 val_auc: 0.7879	test_loss: 0.1172 test_auc: 0.7596
2025-06-20 04:46:15,694 - INFO - train: {'epoch': 27, 'time_epoch': 66.59173, 'eta': 4892.69553, 'eta_hours': 1.35908, 'loss': 0.1036251, 'lr': 8.734e-05, 'params': 514193, 'time_iter': 0.06471, 'accuracy': 0.9714, 'precision': 0.7421, 'recall': 0.36201, 'f1': 0.48663, 'auc': 0.87528}
2025-06-20 04:46:19,138 - INFO - val: {'epoch': 27, 'time_epoch': 3.4155, 'loss': 0.09133321, 'lr': 0, 'params': 514193, 'time_iter': 0.02648, 'accuracy': 0.97909, 'precision': 0.45763, 'recall': 0.33333, 'f1': 0.38571, 'auc': 0.68712}
2025-06-20 04:46:22,585 - INFO - test: {'epoch': 27, 'time_epoch': 3.42139, 'loss': 0.13283743, 'lr': 0, 'params': 514193, 'time_iter': 0.02652, 'accuracy': 0.96523, 'precision': 0.42353, 'recall': 0.27692, 'f1': 0.33488, 'auc': 0.72501}
2025-06-20 04:46:22,593 - INFO - > Epoch 27: took 73.8s (avg 75.3s) | Best so far: epoch 19	train_loss: 0.1150 train_auc: 0.8337	val_loss: 0.0803 val_auc: 0.7879	test_loss: 0.1172 test_auc: 0.7596
2025-06-20 04:47:30,400 - INFO - train: {'epoch': 28, 'time_epoch': 67.45966, 'eta': 4823.53088, 'eta_hours': 1.33987, 'loss': 0.10225499, 'lr': 8.622e-05, 'params': 514193, 'time_iter': 0.06556, 'accuracy': 0.97094, 'precision': 0.72623, 'recall': 0.35958, 'f1': 0.481, 'auc': 0.87969}
2025-06-20 04:47:33,878 - INFO - val: {'epoch': 28, 'time_epoch': 3.4478, 'loss': 0.09831697, 'lr': 0, 'params': 514193, 'time_iter': 0.02673, 'accuracy': 0.97398, 'precision': 0.3375, 'recall': 0.33333, 'f1': 0.3354, 'auc': 0.74081}
2025-06-20 04:47:37,317 - INFO - test: {'epoch': 28, 'time_epoch': 3.41222, 'loss': 0.1383598, 'lr': 0, 'params': 514193, 'time_iter': 0.02645, 'accuracy': 0.95988, 'precision': 0.33645, 'recall': 0.27692, 'f1': 0.3038, 'auc': 0.74666}
2025-06-20 04:47:37,328 - INFO - > Epoch 28: took 74.7s (avg 75.3s) | Best so far: epoch 19	train_loss: 0.1150 train_auc: 0.8337	val_loss: 0.0803 val_auc: 0.7879	test_loss: 0.1172 test_auc: 0.7596
2025-06-20 04:48:45,481 - INFO - train: {'epoch': 29, 'time_epoch': 67.90865, 'eta': 4755.52755, 'eta_hours': 1.32098, 'loss': 0.10232841, 'lr': 8.506e-05, 'params': 514193, 'time_iter': 0.06599, 'accuracy': 0.97143, 'precision': 0.74252, 'recall': 0.36282, 'f1': 0.48746, 'auc': 0.88184}
2025-06-20 04:48:49,491 - INFO - val: {'epoch': 29, 'time_epoch': 3.93342, 'loss': 0.08608703, 'lr': 0, 'params': 514193, 'time_iter': 0.03049, 'accuracy': 0.98152, 'precision': 0.56098, 'recall': 0.28395, 'f1': 0.37705, 'auc': 0.70529}
2025-06-20 04:48:52,997 - INFO - test: {'epoch': 29, 'time_epoch': 3.48139, 'loss': 0.12488078, 'lr': 0, 'params': 514193, 'time_iter': 0.02699, 'accuracy': 0.96718, 'precision': 0.45098, 'recall': 0.17692, 'f1': 0.25414, 'auc': 0.75233}
2025-06-20 04:48:53,004 - INFO - > Epoch 29: took 75.7s (avg 75.3s) | Best so far: epoch 19	train_loss: 0.1150 train_auc: 0.8337	val_loss: 0.0803 val_auc: 0.7879	test_loss: 0.1172 test_auc: 0.7596
2025-06-20 04:50:01,632 - INFO - train: {'epoch': 30, 'time_epoch': 68.41321, 'eta': 4688.65339, 'eta_hours': 1.3024, 'loss': 0.10014335, 'lr': 8.386e-05, 'params': 514193, 'time_iter': 0.06649, 'accuracy': 0.97122, 'precision': 0.73399, 'recall': 0.36282, 'f1': 0.48561, 'auc': 0.88869}
2025-06-20 04:50:05,174 - INFO - val: {'epoch': 30, 'time_epoch': 3.47759, 'loss': 0.08252441, 'lr': 0, 'params': 514193, 'time_iter': 0.02696, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.32099, 'f1': 0.39098, 'auc': 0.76643}
2025-06-20 04:50:08,701 - INFO - test: {'epoch': 30, 'time_epoch': 3.50237, 'loss': 0.13144313, 'lr': 0, 'params': 514193, 'time_iter': 0.02715, 'accuracy': 0.9662, 'precision': 0.39024, 'recall': 0.12308, 'f1': 0.18713, 'auc': 0.746}
2025-06-20 04:50:08,706 - INFO - > Epoch 30: took 75.7s (avg 75.3s) | Best so far: epoch 19	train_loss: 0.1150 train_auc: 0.8337	val_loss: 0.0803 val_auc: 0.7879	test_loss: 0.1172 test_auc: 0.7596
2025-06-20 04:51:15,900 - INFO - train: {'epoch': 31, 'time_epoch': 66.99921, 'eta': 4618.67828, 'eta_hours': 1.28297, 'loss': 0.09928767, 'lr': 8.263e-05, 'params': 514193, 'time_iter': 0.06511, 'accuracy': 0.97143, 'precision': 0.73323, 'recall': 0.37256, 'f1': 0.49408, 'auc': 0.89132}
2025-06-20 04:51:19,490 - INFO - val: {'epoch': 31, 'time_epoch': 3.55286, 'loss': 0.08558437, 'lr': 0, 'params': 514193, 'time_iter': 0.02754, 'accuracy': 0.97933, 'precision': 0.46429, 'recall': 0.32099, 'f1': 0.37956, 'auc': 0.75194}
2025-06-20 04:51:22,897 - INFO - test: {'epoch': 31, 'time_epoch': 3.38722, 'loss': 0.13045681, 'lr': 0, 'params': 514193, 'time_iter': 0.02626, 'accuracy': 0.96304, 'precision': 0.37209, 'recall': 0.24615, 'f1': 0.2963, 'auc': 0.75355}
2025-06-20 04:51:22,900 - INFO - > Epoch 31: took 74.2s (avg 75.3s) | Best so far: epoch 19	train_loss: 0.1150 train_auc: 0.8337	val_loss: 0.0803 val_auc: 0.7879	test_loss: 0.1172 test_auc: 0.7596
2025-06-20 04:52:29,519 - INFO - train: {'epoch': 32, 'time_epoch': 66.34047, 'eta': 4547.54608, 'eta_hours': 1.26321, 'loss': 0.09943226, 'lr': 8.136e-05, 'params': 514193, 'time_iter': 0.06447, 'accuracy': 0.97152, 'precision': 0.73228, 'recall': 0.37744, 'f1': 0.49813, 'auc': 0.89204}
2025-06-20 04:52:33,045 - INFO - val: {'epoch': 32, 'time_epoch': 3.46626, 'loss': 0.08524894, 'lr': 0, 'params': 514193, 'time_iter': 0.02687, 'accuracy': 0.98152, 'precision': 0.55556, 'recall': 0.30864, 'f1': 0.39683, 'auc': 0.74494}
2025-06-20 04:52:36,486 - INFO - test: {'epoch': 32, 'time_epoch': 3.42098, 'loss': 0.13120718, 'lr': 0, 'params': 514193, 'time_iter': 0.02652, 'accuracy': 0.96669, 'precision': 0.42222, 'recall': 0.14615, 'f1': 0.21714, 'auc': 0.73824}
2025-06-20 04:52:36,491 - INFO - > Epoch 32: took 73.6s (avg 75.3s) | Best so far: epoch 19	train_loss: 0.1150 train_auc: 0.8337	val_loss: 0.0803 val_auc: 0.7879	test_loss: 0.1172 test_auc: 0.7596
2025-06-20 04:53:43,179 - INFO - train: {'epoch': 33, 'time_epoch': 66.45018, 'eta': 4476.90873, 'eta_hours': 1.24359, 'loss': 0.09757692, 'lr': 8.005e-05, 'params': 514193, 'time_iter': 0.06458, 'accuracy': 0.97161, 'precision': 0.72923, 'recall': 0.38474, 'f1': 0.50372, 'auc': 0.89802}
2025-06-20 04:53:47,150 - INFO - val: {'epoch': 33, 'time_epoch': 3.93179, 'loss': 0.0875154, 'lr': 0, 'params': 514193, 'time_iter': 0.03048, 'accuracy': 0.97885, 'precision': 0.44643, 'recall': 0.30864, 'f1': 0.36496, 'auc': 0.76123}
2025-06-20 04:53:50,629 - INFO - test: {'epoch': 33, 'time_epoch': 3.45646, 'loss': 0.13013009, 'lr': 0, 'params': 514193, 'time_iter': 0.02679, 'accuracy': 0.96353, 'precision': 0.39362, 'recall': 0.28462, 'f1': 0.33036, 'auc': 0.76609}
2025-06-20 04:53:50,637 - INFO - > Epoch 33: took 74.1s (avg 75.2s) | Best so far: epoch 19	train_loss: 0.1150 train_auc: 0.8337	val_loss: 0.0803 val_auc: 0.7879	test_loss: 0.1172 test_auc: 0.7596
2025-06-20 04:54:57,103 - INFO - train: {'epoch': 34, 'time_epoch': 66.15306, 'eta': 4405.95884, 'eta_hours': 1.22388, 'loss': 0.09599588, 'lr': 7.872e-05, 'params': 514193, 'time_iter': 0.06429, 'accuracy': 0.97252, 'precision': 0.75705, 'recall': 0.39205, 'f1': 0.51658, 'auc': 0.90257}
2025-06-20 04:55:00,648 - INFO - val: {'epoch': 34, 'time_epoch': 3.479, 'loss': 0.08028737, 'lr': 0, 'params': 514193, 'time_iter': 0.02697, 'accuracy': 0.98055, 'precision': 0.5122, 'recall': 0.25926, 'f1': 0.34426, 'auc': 0.78921}
2025-06-20 04:55:04,199 - INFO - test: {'epoch': 34, 'time_epoch': 3.5225, 'loss': 0.12420868, 'lr': 0, 'params': 514193, 'time_iter': 0.02731, 'accuracy': 0.96864, 'precision': 0.50943, 'recall': 0.20769, 'f1': 0.29508, 'auc': 0.75549}
2025-06-20 04:55:04,205 - INFO - > Epoch 34: took 73.6s (avg 75.2s) | Best so far: epoch 34	train_loss: 0.0960 train_auc: 0.9026	val_loss: 0.0803 val_auc: 0.7892	test_loss: 0.1242 test_auc: 0.7555
2025-06-20 04:56:12,046 - INFO - train: {'epoch': 35, 'time_epoch': 67.60019, 'eta': 4337.84812, 'eta_hours': 1.20496, 'loss': 0.09629314, 'lr': 7.735e-05, 'params': 514193, 'time_iter': 0.0657, 'accuracy': 0.97207, 'precision': 0.7504, 'recall': 0.38068, 'f1': 0.50512, 'auc': 0.90068}
2025-06-20 04:56:15,489 - INFO - val: {'epoch': 35, 'time_epoch': 3.38563, 'loss': 0.08361854, 'lr': 0, 'params': 514193, 'time_iter': 0.02625, 'accuracy': 0.9786, 'precision': 0.44262, 'recall': 0.33333, 'f1': 0.38028, 'auc': 0.80647}
2025-06-20 04:56:18,868 - INFO - test: {'epoch': 35, 'time_epoch': 3.35621, 'loss': 0.13205468, 'lr': 0, 'params': 514193, 'time_iter': 0.02602, 'accuracy': 0.96231, 'precision': 0.33333, 'recall': 0.19231, 'f1': 0.2439, 'auc': 0.76438}
2025-06-20 04:56:18,875 - INFO - > Epoch 35: took 74.7s (avg 75.2s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 04:57:24,895 - INFO - train: {'epoch': 36, 'time_epoch': 65.76361, 'eta': 4266.63784, 'eta_hours': 1.18518, 'loss': 0.09614432, 'lr': 7.595e-05, 'params': 514193, 'time_iter': 0.06391, 'accuracy': 0.97204, 'precision': 0.7378, 'recall': 0.39286, 'f1': 0.51271, 'auc': 0.90298}
2025-06-20 04:57:28,319 - INFO - val: {'epoch': 36, 'time_epoch': 3.38961, 'loss': 0.08424661, 'lr': 0, 'params': 514193, 'time_iter': 0.02628, 'accuracy': 0.98128, 'precision': 0.54, 'recall': 0.33333, 'f1': 0.41221, 'auc': 0.75413}
2025-06-20 04:57:31,769 - INFO - test: {'epoch': 36, 'time_epoch': 3.41685, 'loss': 0.13046866, 'lr': 0, 'params': 514193, 'time_iter': 0.02649, 'accuracy': 0.96596, 'precision': 0.42647, 'recall': 0.22308, 'f1': 0.29293, 'auc': 0.75651}
2025-06-20 04:57:31,771 - INFO - > Epoch 36: took 72.9s (avg 75.1s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 04:58:38,507 - INFO - train: {'epoch': 37, 'time_epoch': 66.50222, 'eta': 4196.91932, 'eta_hours': 1.16581, 'loss': 0.09381609, 'lr': 7.452e-05, 'params': 514193, 'time_iter': 0.06463, 'accuracy': 0.97216, 'precision': 0.74085, 'recall': 0.39448, 'f1': 0.51483, 'auc': 0.91032}
2025-06-20 04:58:41,970 - INFO - val: {'epoch': 37, 'time_epoch': 3.42973, 'loss': 0.08549434, 'lr': 0, 'params': 514193, 'time_iter': 0.02659, 'accuracy': 0.97982, 'precision': 0.48148, 'recall': 0.32099, 'f1': 0.38519, 'auc': 0.75927}
2025-06-20 04:58:45,386 - INFO - test: {'epoch': 37, 'time_epoch': 3.39469, 'loss': 0.13277758, 'lr': 0, 'params': 514193, 'time_iter': 0.02632, 'accuracy': 0.96596, 'precision': 0.43902, 'recall': 0.27692, 'f1': 0.33962, 'auc': 0.74747}
2025-06-20 04:58:45,399 - INFO - > Epoch 37: took 73.6s (avg 75.1s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 04:59:50,753 - INFO - train: {'epoch': 38, 'time_epoch': 65.13281, 'eta': 4125.22386, 'eta_hours': 1.1459, 'loss': 0.09219789, 'lr': 7.307e-05, 'params': 514193, 'time_iter': 0.0633, 'accuracy': 0.97289, 'precision': 0.74927, 'recall': 0.41477, 'f1': 0.53396, 'auc': 0.91191}
2025-06-20 04:59:54,173 - INFO - val: {'epoch': 38, 'time_epoch': 3.39305, 'loss': 0.09369302, 'lr': 0, 'params': 514193, 'time_iter': 0.0263, 'accuracy': 0.97788, 'precision': 0.42424, 'recall': 0.34568, 'f1': 0.38095, 'auc': 0.72989}
2025-06-20 04:59:57,615 - INFO - test: {'epoch': 38, 'time_epoch': 3.40793, 'loss': 0.1349357, 'lr': 0, 'params': 514193, 'time_iter': 0.02642, 'accuracy': 0.96377, 'precision': 0.39785, 'recall': 0.28462, 'f1': 0.33184, 'auc': 0.74385}
2025-06-20 04:59:57,626 - INFO - > Epoch 38: took 72.2s (avg 75.0s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:01:00,980 - INFO - train: {'epoch': 39, 'time_epoch': 63.10451, 'eta': 4050.81407, 'eta_hours': 1.12523, 'loss': 0.09155254, 'lr': 7.159e-05, 'params': 514193, 'time_iter': 0.06133, 'accuracy': 0.97316, 'precision': 0.75108, 'recall': 0.4237, 'f1': 0.54177, 'auc': 0.91069}
2025-06-20 05:01:04,475 - INFO - val: {'epoch': 39, 'time_epoch': 3.35278, 'loss': 0.09272353, 'lr': 0, 'params': 514193, 'time_iter': 0.02599, 'accuracy': 0.9786, 'precision': 0.4386, 'recall': 0.30864, 'f1': 0.36232, 'auc': 0.71913}
2025-06-20 05:01:07,815 - INFO - test: {'epoch': 39, 'time_epoch': 3.31928, 'loss': 0.1313441, 'lr': 0, 'params': 514193, 'time_iter': 0.02573, 'accuracy': 0.96791, 'precision': 0.48333, 'recall': 0.22308, 'f1': 0.30526, 'auc': 0.74615}
2025-06-20 05:01:07,823 - INFO - > Epoch 39: took 70.2s (avg 74.9s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:02:11,727 - INFO - train: {'epoch': 40, 'time_epoch': 63.70968, 'eta': 3977.82662, 'eta_hours': 1.10495, 'loss': 0.09212509, 'lr': 7.008e-05, 'params': 514193, 'time_iter': 0.06191, 'accuracy': 0.97265, 'precision': 0.73988, 'recall': 0.41558, 'f1': 0.53222, 'auc': 0.91387}
2025-06-20 05:02:15,067 - INFO - val: {'epoch': 40, 'time_epoch': 3.30872, 'loss': 0.09368143, 'lr': 0, 'params': 514193, 'time_iter': 0.02565, 'accuracy': 0.97544, 'precision': 0.36486, 'recall': 0.33333, 'f1': 0.34839, 'auc': 0.73893}
2025-06-20 05:02:18,408 - INFO - test: {'epoch': 40, 'time_epoch': 3.32071, 'loss': 0.13532233, 'lr': 0, 'params': 514193, 'time_iter': 0.02574, 'accuracy': 0.9628, 'precision': 0.39048, 'recall': 0.31538, 'f1': 0.34894, 'auc': 0.76802}
2025-06-20 05:02:18,416 - INFO - > Epoch 40: took 70.6s (avg 74.8s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:03:23,181 - INFO - train: {'epoch': 41, 'time_epoch': 64.52853, 'eta': 3906.41175, 'eta_hours': 1.08511, 'loss': 0.08882286, 'lr': 6.856e-05, 'params': 514193, 'time_iter': 0.06271, 'accuracy': 0.97404, 'precision': 0.76695, 'recall': 0.44075, 'f1': 0.55979, 'auc': 0.92177}
2025-06-20 05:03:26,862 - INFO - val: {'epoch': 41, 'time_epoch': 3.64605, 'loss': 0.08869471, 'lr': 0, 'params': 514193, 'time_iter': 0.02826, 'accuracy': 0.97812, 'precision': 0.43284, 'recall': 0.35802, 'f1': 0.39189, 'auc': 0.763}
2025-06-20 05:03:30,204 - INFO - test: {'epoch': 41, 'time_epoch': 3.31654, 'loss': 0.13334126, 'lr': 0, 'params': 514193, 'time_iter': 0.02571, 'accuracy': 0.9645, 'precision': 0.39189, 'recall': 0.22308, 'f1': 0.28431, 'auc': 0.76067}
2025-06-20 05:03:30,230 - INFO - > Epoch 41: took 71.8s (avg 74.7s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:04:34,562 - INFO - train: {'epoch': 42, 'time_epoch': 64.15103, 'eta': 3834.81677, 'eta_hours': 1.06523, 'loss': 0.08788359, 'lr': 6.701e-05, 'params': 514193, 'time_iter': 0.06234, 'accuracy': 0.97404, 'precision': 0.77, 'recall': 0.4375, 'f1': 0.55797, 'auc': 0.92411}
2025-06-20 05:04:38,077 - INFO - val: {'epoch': 42, 'time_epoch': 3.46086, 'loss': 0.08635711, 'lr': 0, 'params': 514193, 'time_iter': 0.02683, 'accuracy': 0.97982, 'precision': 0.48, 'recall': 0.2963, 'f1': 0.36641, 'auc': 0.74246}
2025-06-20 05:04:41,517 - INFO - test: {'epoch': 42, 'time_epoch': 3.41454, 'loss': 0.13510318, 'lr': 0, 'params': 514193, 'time_iter': 0.02647, 'accuracy': 0.96669, 'precision': 0.41026, 'recall': 0.12308, 'f1': 0.18935, 'auc': 0.74151}
2025-06-20 05:04:41,524 - INFO - > Epoch 42: took 71.3s (avg 74.6s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:05:45,659 - INFO - train: {'epoch': 43, 'time_epoch': 63.88755, 'eta': 3763.22483, 'eta_hours': 1.04534, 'loss': 0.08857528, 'lr': 6.545e-05, 'params': 514193, 'time_iter': 0.06209, 'accuracy': 0.97337, 'precision': 0.75141, 'recall': 0.43182, 'f1': 0.54845, 'auc': 0.92425}
2025-06-20 05:05:49,213 - INFO - val: {'epoch': 43, 'time_epoch': 3.44161, 'loss': 0.10198218, 'lr': 0, 'params': 514193, 'time_iter': 0.02668, 'accuracy': 0.97277, 'precision': 0.32184, 'recall': 0.34568, 'f1': 0.33333, 'auc': 0.73661}
2025-06-20 05:05:52,557 - INFO - test: {'epoch': 43, 'time_epoch': 3.3159, 'loss': 0.14608514, 'lr': 0, 'params': 514193, 'time_iter': 0.0257, 'accuracy': 0.9611, 'precision': 0.36842, 'recall': 0.32308, 'f1': 0.34426, 'auc': 0.74727}
2025-06-20 05:05:52,563 - INFO - > Epoch 43: took 71.0s (avg 74.5s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:06:54,940 - INFO - train: {'epoch': 44, 'time_epoch': 62.07063, 'eta': 3689.75461, 'eta_hours': 1.02493, 'loss': 0.08746154, 'lr': 6.387e-05, 'params': 514193, 'time_iter': 0.06032, 'accuracy': 0.97432, 'precision': 0.77603, 'recall': 0.44156, 'f1': 0.56286, 'auc': 0.9255}
2025-06-20 05:06:58,400 - INFO - val: {'epoch': 44, 'time_epoch': 3.41765, 'loss': 0.09542135, 'lr': 0, 'params': 514193, 'time_iter': 0.02649, 'accuracy': 0.97447, 'precision': 0.35714, 'recall': 0.37037, 'f1': 0.36364, 'auc': 0.79131}
2025-06-20 05:07:01,843 - INFO - test: {'epoch': 44, 'time_epoch': 3.41899, 'loss': 0.14330315, 'lr': 0, 'params': 514193, 'time_iter': 0.0265, 'accuracy': 0.95915, 'precision': 0.32407, 'recall': 0.26923, 'f1': 0.29412, 'auc': 0.75842}
2025-06-20 05:07:01,851 - INFO - > Epoch 44: took 69.3s (avg 74.4s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:08:05,521 - INFO - train: {'epoch': 45, 'time_epoch': 63.38481, 'eta': 3618.32277, 'eta_hours': 1.00509, 'loss': 0.0879932, 'lr': 6.227e-05, 'params': 514193, 'time_iter': 0.0616, 'accuracy': 0.97401, 'precision': 0.77279, 'recall': 0.43344, 'f1': 0.55538, 'auc': 0.9245}
2025-06-20 05:08:08,993 - INFO - val: {'epoch': 45, 'time_epoch': 3.44746, 'loss': 0.08566258, 'lr': 0, 'params': 514193, 'time_iter': 0.02672, 'accuracy': 0.97982, 'precision': 0.48214, 'recall': 0.33333, 'f1': 0.39416, 'auc': 0.7824}
2025-06-20 05:08:12,417 - INFO - test: {'epoch': 45, 'time_epoch': 3.39877, 'loss': 0.14787667, 'lr': 0, 'params': 514193, 'time_iter': 0.02635, 'accuracy': 0.96475, 'precision': 0.36842, 'recall': 0.16154, 'f1': 0.2246, 'auc': 0.73066}
2025-06-20 05:08:12,423 - INFO - > Epoch 45: took 70.6s (avg 74.3s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:09:16,296 - INFO - train: {'epoch': 46, 'time_epoch': 63.66572, 'eta': 3547.55012, 'eta_hours': 0.98543, 'loss': 0.08781567, 'lr': 6.066e-05, 'params': 514193, 'time_iter': 0.06187, 'accuracy': 0.97389, 'precision': 0.76454, 'recall': 0.4375, 'f1': 0.55653, 'auc': 0.92601}
2025-06-20 05:09:19,921 - INFO - val: {'epoch': 46, 'time_epoch': 3.56845, 'loss': 0.08792805, 'lr': 0, 'params': 514193, 'time_iter': 0.02766, 'accuracy': 0.97933, 'precision': 0.46552, 'recall': 0.33333, 'f1': 0.38849, 'auc': 0.77253}
2025-06-20 05:09:23,383 - INFO - test: {'epoch': 46, 'time_epoch': 3.44202, 'loss': 0.1411567, 'lr': 0, 'params': 514193, 'time_iter': 0.02668, 'accuracy': 0.96402, 'precision': 0.35938, 'recall': 0.17692, 'f1': 0.23711, 'auc': 0.75266}
2025-06-20 05:09:23,393 - INFO - > Epoch 46: took 71.0s (avg 74.3s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:10:27,451 - INFO - train: {'epoch': 47, 'time_epoch': 63.76641, 'eta': 3477.18267, 'eta_hours': 0.96588, 'loss': 0.08675284, 'lr': 5.904e-05, 'params': 514193, 'time_iter': 0.06197, 'accuracy': 0.97468, 'precision': 0.78955, 'recall': 0.44156, 'f1': 0.56637, 'auc': 0.92858}
2025-06-20 05:10:30,836 - INFO - val: {'epoch': 47, 'time_epoch': 3.35668, 'loss': 0.102292, 'lr': 0, 'params': 514193, 'time_iter': 0.02602, 'accuracy': 0.97204, 'precision': 0.31915, 'recall': 0.37037, 'f1': 0.34286, 'auc': 0.79614}
2025-06-20 05:10:34,172 - INFO - test: {'epoch': 47, 'time_epoch': 3.31231, 'loss': 0.15034307, 'lr': 0, 'params': 514193, 'time_iter': 0.02568, 'accuracy': 0.95915, 'precision': 0.33898, 'recall': 0.30769, 'f1': 0.32258, 'auc': 0.75386}
2025-06-20 05:10:34,179 - INFO - > Epoch 47: took 70.8s (avg 74.2s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:11:38,632 - INFO - train: {'epoch': 48, 'time_epoch': 64.09517, 'eta': 3407.42684, 'eta_hours': 0.94651, 'loss': 0.08410398, 'lr': 5.741e-05, 'params': 514193, 'time_iter': 0.06229, 'accuracy': 0.97511, 'precision': 0.78562, 'recall': 0.46104, 'f1': 0.58107, 'auc': 0.93416}
2025-06-20 05:11:41,996 - INFO - val: {'epoch': 48, 'time_epoch': 3.33668, 'loss': 0.09352708, 'lr': 0, 'params': 514193, 'time_iter': 0.02587, 'accuracy': 0.9769, 'precision': 0.4, 'recall': 0.34568, 'f1': 0.37086, 'auc': 0.76831}
2025-06-20 05:11:45,395 - INFO - test: {'epoch': 48, 'time_epoch': 3.36971, 'loss': 0.14287977, 'lr': 0, 'params': 514193, 'time_iter': 0.02612, 'accuracy': 0.96475, 'precision': 0.38095, 'recall': 0.18462, 'f1': 0.2487, 'auc': 0.73427}
2025-06-20 05:11:45,400 - INFO - > Epoch 48: took 71.2s (avg 74.1s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:12:49,703 - INFO - train: {'epoch': 49, 'time_epoch': 64.00458, 'eta': 3337.80684, 'eta_hours': 0.92717, 'loss': 0.08677962, 'lr': 5.577e-05, 'params': 514193, 'time_iter': 0.0622, 'accuracy': 0.97438, 'precision': 0.77203, 'recall': 0.44805, 'f1': 0.56703, 'auc': 0.92724}
2025-06-20 05:12:53,057 - INFO - val: {'epoch': 49, 'time_epoch': 3.31159, 'loss': 0.09453555, 'lr': 0, 'params': 514193, 'time_iter': 0.02567, 'accuracy': 0.97471, 'precision': 0.36145, 'recall': 0.37037, 'f1': 0.36585, 'auc': 0.78642}
2025-06-20 05:12:56,389 - INFO - test: {'epoch': 49, 'time_epoch': 3.30669, 'loss': 0.15099659, 'lr': 0, 'params': 514193, 'time_iter': 0.02563, 'accuracy': 0.96159, 'precision': 0.32927, 'recall': 0.20769, 'f1': 0.25472, 'auc': 0.73586}
2025-06-20 05:12:56,397 - INFO - > Epoch 49: took 71.0s (avg 74.1s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:14:00,473 - INFO - train: {'epoch': 50, 'time_epoch': 63.85078, 'eta': 3268.25929, 'eta_hours': 0.90785, 'loss': 0.08245404, 'lr': 5.413e-05, 'params': 514193, 'time_iter': 0.06205, 'accuracy': 0.97489, 'precision': 0.77808, 'recall': 0.46104, 'f1': 0.579, 'auc': 0.93942}
2025-06-20 05:14:03,950 - INFO - val: {'epoch': 50, 'time_epoch': 3.44767, 'loss': 0.09525917, 'lr': 0, 'params': 514193, 'time_iter': 0.02673, 'accuracy': 0.97423, 'precision': 0.3494, 'recall': 0.35802, 'f1': 0.35366, 'auc': 0.79526}
2025-06-20 05:14:07,423 - INFO - test: {'epoch': 50, 'time_epoch': 3.41352, 'loss': 0.15207702, 'lr': 0, 'params': 514193, 'time_iter': 0.02646, 'accuracy': 0.96159, 'precision': 0.35714, 'recall': 0.26923, 'f1': 0.30702, 'auc': 0.74762}
2025-06-20 05:14:07,437 - INFO - > Epoch 50: took 71.0s (avg 74.0s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:15:09,657 - INFO - train: {'epoch': 51, 'time_epoch': 61.97403, 'eta': 3197.19845, 'eta_hours': 0.88811, 'loss': 0.08172992, 'lr': 5.248e-05, 'params': 514193, 'time_iter': 0.06023, 'accuracy': 0.97499, 'precision': 0.77598, 'recall': 0.46672, 'f1': 0.58287, 'auc': 0.94036}
2025-06-20 05:15:13,087 - INFO - val: {'epoch': 51, 'time_epoch': 3.39129, 'loss': 0.08757356, 'lr': 0, 'params': 514193, 'time_iter': 0.02629, 'accuracy': 0.97836, 'precision': 0.43548, 'recall': 0.33333, 'f1': 0.37762, 'auc': 0.78868}
2025-06-20 05:15:16,480 - INFO - test: {'epoch': 51, 'time_epoch': 3.36608, 'loss': 0.14563963, 'lr': 0, 'params': 514193, 'time_iter': 0.02609, 'accuracy': 0.96499, 'precision': 0.40541, 'recall': 0.23077, 'f1': 0.29412, 'auc': 0.74679}
2025-06-20 05:15:16,488 - INFO - > Epoch 51: took 69.1s (avg 73.9s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:16:21,372 - INFO - train: {'epoch': 52, 'time_epoch': 64.57827, 'eta': 3128.78994, 'eta_hours': 0.86911, 'loss': 0.08230961, 'lr': 5.083e-05, 'params': 514193, 'time_iter': 0.06276, 'accuracy': 0.97508, 'precision': 0.76823, 'recall': 0.4789, 'f1': 0.59, 'auc': 0.9386}
2025-06-20 05:16:24,835 - INFO - val: {'epoch': 52, 'time_epoch': 3.43321, 'loss': 0.09846543, 'lr': 0, 'params': 514193, 'time_iter': 0.02661, 'accuracy': 0.97398, 'precision': 0.35227, 'recall': 0.38272, 'f1': 0.36686, 'auc': 0.78908}
2025-06-20 05:16:28,213 - INFO - test: {'epoch': 52, 'time_epoch': 3.35071, 'loss': 0.14851673, 'lr': 0, 'params': 514193, 'time_iter': 0.02597, 'accuracy': 0.9628, 'precision': 0.3945, 'recall': 0.33077, 'f1': 0.35983, 'auc': 0.7549}
2025-06-20 05:16:28,218 - INFO - > Epoch 52: took 71.7s (avg 73.9s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:17:33,599 - INFO - train: {'epoch': 53, 'time_epoch': 65.08032, 'eta': 3060.95096, 'eta_hours': 0.85026, 'loss': 0.0812526, 'lr': 4.917e-05, 'params': 514193, 'time_iter': 0.06325, 'accuracy': 0.9755, 'precision': 0.77953, 'recall': 0.48214, 'f1': 0.59579, 'auc': 0.9406}
2025-06-20 05:17:37,011 - INFO - val: {'epoch': 53, 'time_epoch': 3.3685, 'loss': 0.10054479, 'lr': 0, 'params': 514193, 'time_iter': 0.02611, 'accuracy': 0.97058, 'precision': 0.30769, 'recall': 0.39506, 'f1': 0.34595, 'auc': 0.78508}
2025-06-20 05:17:40,443 - INFO - test: {'epoch': 53, 'time_epoch': 3.40659, 'loss': 0.15550145, 'lr': 0, 'params': 514193, 'time_iter': 0.02641, 'accuracy': 0.95964, 'precision': 0.34746, 'recall': 0.31538, 'f1': 0.33065, 'auc': 0.74761}
2025-06-20 05:17:40,453 - INFO - > Epoch 53: took 72.2s (avg 73.8s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:18:45,675 - INFO - train: {'epoch': 54, 'time_epoch': 64.91467, 'eta': 2993.07675, 'eta_hours': 0.83141, 'loss': 0.08137223, 'lr': 4.752e-05, 'params': 514193, 'time_iter': 0.06309, 'accuracy': 0.97553, 'precision': 0.78353, 'recall': 0.4789, 'f1': 0.59446, 'auc': 0.9432}
2025-06-20 05:18:49,036 - INFO - val: {'epoch': 54, 'time_epoch': 3.31136, 'loss': 0.08927156, 'lr': 0, 'params': 514193, 'time_iter': 0.02567, 'accuracy': 0.9786, 'precision': 0.44262, 'recall': 0.33333, 'f1': 0.38028, 'auc': 0.77193}
2025-06-20 05:18:52,380 - INFO - test: {'epoch': 54, 'time_epoch': 3.32107, 'loss': 0.14671176, 'lr': 0, 'params': 514193, 'time_iter': 0.02574, 'accuracy': 0.96499, 'precision': 0.40789, 'recall': 0.23846, 'f1': 0.30097, 'auc': 0.73449}
2025-06-20 05:18:52,389 - INFO - > Epoch 54: took 71.9s (avg 73.8s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:19:57,072 - INFO - train: {'epoch': 55, 'time_epoch': 64.45948, 'eta': 2924.9506, 'eta_hours': 0.81249, 'loss': 0.07955145, 'lr': 4.587e-05, 'params': 514193, 'time_iter': 0.06264, 'accuracy': 0.97568, 'precision': 0.78052, 'recall': 0.48782, 'f1': 0.6004, 'auc': 0.94383}
2025-06-20 05:20:00,443 - INFO - val: {'epoch': 55, 'time_epoch': 3.34443, 'loss': 0.09164713, 'lr': 0, 'params': 514193, 'time_iter': 0.02593, 'accuracy': 0.98006, 'precision': 0.49057, 'recall': 0.32099, 'f1': 0.38806, 'auc': 0.76079}
2025-06-20 05:20:03,851 - INFO - test: {'epoch': 55, 'time_epoch': 3.38629, 'loss': 0.15085565, 'lr': 0, 'params': 514193, 'time_iter': 0.02625, 'accuracy': 0.96718, 'precision': 0.46479, 'recall': 0.25385, 'f1': 0.32836, 'auc': 0.73492}
2025-06-20 05:20:03,859 - INFO - > Epoch 55: took 71.5s (avg 73.8s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:21:08,472 - INFO - train: {'epoch': 56, 'time_epoch': 64.30716, 'eta': 2856.83819, 'eta_hours': 0.79357, 'loss': 0.08143179, 'lr': 4.423e-05, 'params': 514193, 'time_iter': 0.06249, 'accuracy': 0.97526, 'precision': 0.77719, 'recall': 0.47565, 'f1': 0.59013, 'auc': 0.93919}
2025-06-20 05:21:11,837 - INFO - val: {'epoch': 56, 'time_epoch': 3.30866, 'loss': 0.08711144, 'lr': 0, 'params': 514193, 'time_iter': 0.02565, 'accuracy': 0.97885, 'precision': 0.44643, 'recall': 0.30864, 'f1': 0.36496, 'auc': 0.80071}
2025-06-20 05:21:15,149 - INFO - test: {'epoch': 56, 'time_epoch': 3.29099, 'loss': 0.14479175, 'lr': 0, 'params': 514193, 'time_iter': 0.02551, 'accuracy': 0.96815, 'precision': 0.48936, 'recall': 0.17692, 'f1': 0.25989, 'auc': 0.76446}
2025-06-20 05:21:15,157 - INFO - > Epoch 56: took 71.3s (avg 73.7s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:22:18,444 - INFO - train: {'epoch': 57, 'time_epoch': 63.0714, 'eta': 2787.96214, 'eta_hours': 0.77443, 'loss': 0.07734347, 'lr': 4.259e-05, 'params': 514193, 'time_iter': 0.06129, 'accuracy': 0.97647, 'precision': 0.79061, 'recall': 0.50568, 'f1': 0.61683, 'auc': 0.95013}
2025-06-20 05:22:21,765 - INFO - val: {'epoch': 57, 'time_epoch': 3.29739, 'loss': 0.10033555, 'lr': 0, 'params': 514193, 'time_iter': 0.02556, 'accuracy': 0.97423, 'precision': 0.3494, 'recall': 0.35802, 'f1': 0.35366, 'auc': 0.78159}
2025-06-20 05:22:25,074 - INFO - test: {'epoch': 57, 'time_epoch': 3.28898, 'loss': 0.16047269, 'lr': 0, 'params': 514193, 'time_iter': 0.0255, 'accuracy': 0.96061, 'precision': 0.32222, 'recall': 0.22308, 'f1': 0.26364, 'auc': 0.73727}
2025-06-20 05:22:25,080 - INFO - > Epoch 57: took 69.9s (avg 73.7s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:23:27,745 - INFO - train: {'epoch': 58, 'time_epoch': 62.35086, 'eta': 2718.78214, 'eta_hours': 0.75522, 'loss': 0.07672937, 'lr': 4.096e-05, 'params': 514193, 'time_iter': 0.06059, 'accuracy': 0.97593, 'precision': 0.78061, 'recall': 0.49675, 'f1': 0.60714, 'auc': 0.95038}
2025-06-20 05:23:31,134 - INFO - val: {'epoch': 58, 'time_epoch': 3.35931, 'loss': 0.09226197, 'lr': 0, 'params': 514193, 'time_iter': 0.02604, 'accuracy': 0.97836, 'precision': 0.43333, 'recall': 0.32099, 'f1': 0.36879, 'auc': 0.7924}
2025-06-20 05:23:34,491 - INFO - test: {'epoch': 58, 'time_epoch': 3.33616, 'loss': 0.15227785, 'lr': 0, 'params': 514193, 'time_iter': 0.02586, 'accuracy': 0.9645, 'precision': 0.39474, 'recall': 0.23077, 'f1': 0.29126, 'auc': 0.74119}
2025-06-20 05:23:34,494 - INFO - > Epoch 58: took 69.4s (avg 73.6s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:24:39,358 - INFO - train: {'epoch': 59, 'time_epoch': 64.61012, 'eta': 2651.33595, 'eta_hours': 0.73648, 'loss': 0.07797504, 'lr': 3.934e-05, 'params': 514193, 'time_iter': 0.06279, 'accuracy': 0.97593, 'precision': 0.78424, 'recall': 0.49269, 'f1': 0.60518, 'auc': 0.94779}
2025-06-20 05:24:42,847 - INFO - val: {'epoch': 59, 'time_epoch': 3.45602, 'loss': 0.09191682, 'lr': 0, 'params': 514193, 'time_iter': 0.02679, 'accuracy': 0.97666, 'precision': 0.39726, 'recall': 0.35802, 'f1': 0.37662, 'auc': 0.7998}
2025-06-20 05:24:46,271 - INFO - test: {'epoch': 59, 'time_epoch': 3.40014, 'loss': 0.15251463, 'lr': 0, 'params': 514193, 'time_iter': 0.02636, 'accuracy': 0.96329, 'precision': 0.35211, 'recall': 0.19231, 'f1': 0.24876, 'auc': 0.74267}
2025-06-20 05:24:46,277 - INFO - > Epoch 59: took 71.8s (avg 73.6s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:25:51,006 - INFO - train: {'epoch': 60, 'time_epoch': 64.43255, 'eta': 2583.86922, 'eta_hours': 0.71774, 'loss': 0.07709997, 'lr': 3.773e-05, 'params': 514193, 'time_iter': 0.06262, 'accuracy': 0.97663, 'precision': 0.80662, 'recall': 0.49432, 'f1': 0.61298, 'auc': 0.95203}
2025-06-20 05:25:54,388 - INFO - val: {'epoch': 60, 'time_epoch': 3.3488, 'loss': 0.09840943, 'lr': 0, 'params': 514193, 'time_iter': 0.02596, 'accuracy': 0.97642, 'precision': 0.38571, 'recall': 0.33333, 'f1': 0.35762, 'auc': 0.77968}
2025-06-20 05:25:57,786 - INFO - test: {'epoch': 60, 'time_epoch': 3.37833, 'loss': 0.15222949, 'lr': 0, 'params': 514193, 'time_iter': 0.02619, 'accuracy': 0.96523, 'precision': 0.41558, 'recall': 0.24615, 'f1': 0.30918, 'auc': 0.74679}
2025-06-20 05:25:57,792 - INFO - > Epoch 60: took 71.5s (avg 73.5s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:27:03,145 - INFO - train: {'epoch': 61, 'time_epoch': 65.14243, 'eta': 2516.93546, 'eta_hours': 0.69915, 'loss': 0.07641156, 'lr': 3.613e-05, 'params': 514193, 'time_iter': 0.06331, 'accuracy': 0.97705, 'precision': 0.8, 'recall': 0.51623, 'f1': 0.62753, 'auc': 0.95036}
2025-06-20 05:27:06,653 - INFO - val: {'epoch': 61, 'time_epoch': 3.46379, 'loss': 0.10420505, 'lr': 0, 'params': 514193, 'time_iter': 0.02685, 'accuracy': 0.97447, 'precision': 0.35, 'recall': 0.34568, 'f1': 0.34783, 'auc': 0.76739}
2025-06-20 05:27:09,977 - INFO - test: {'epoch': 61, 'time_epoch': 3.29268, 'loss': 0.16546969, 'lr': 0, 'params': 514193, 'time_iter': 0.02552, 'accuracy': 0.9628, 'precision': 0.36782, 'recall': 0.24615, 'f1': 0.29493, 'auc': 0.71915}
2025-06-20 05:27:09,992 - INFO - > Epoch 61: took 72.2s (avg 73.5s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:28:14,678 - INFO - train: {'epoch': 62, 'time_epoch': 64.54219, 'eta': 2449.70604, 'eta_hours': 0.68047, 'loss': 0.07552423, 'lr': 3.455e-05, 'params': 514193, 'time_iter': 0.06272, 'accuracy': 0.97663, 'precision': 0.79566, 'recall': 0.50568, 'f1': 0.61836, 'auc': 0.95101}
2025-06-20 05:28:18,102 - INFO - val: {'epoch': 62, 'time_epoch': 3.38864, 'loss': 0.10048558, 'lr': 0, 'params': 514193, 'time_iter': 0.02627, 'accuracy': 0.97617, 'precision': 0.38356, 'recall': 0.34568, 'f1': 0.36364, 'auc': 0.76649}
2025-06-20 05:28:21,545 - INFO - test: {'epoch': 62, 'time_epoch': 3.41025, 'loss': 0.15559082, 'lr': 0, 'params': 514193, 'time_iter': 0.02644, 'accuracy': 0.96475, 'precision': 0.41379, 'recall': 0.27692, 'f1': 0.3318, 'auc': 0.73547}
2025-06-20 05:28:21,571 - INFO - > Epoch 62: took 71.6s (avg 73.5s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:29:25,157 - INFO - train: {'epoch': 63, 'time_epoch': 63.34873, 'eta': 2381.88928, 'eta_hours': 0.66164, 'loss': 0.07663021, 'lr': 3.299e-05, 'params': 514193, 'time_iter': 0.06156, 'accuracy': 0.9762, 'precision': 0.78599, 'recall': 0.50081, 'f1': 0.6118, 'auc': 0.95208}
2025-06-20 05:29:28,623 - INFO - val: {'epoch': 63, 'time_epoch': 3.43204, 'loss': 0.10547508, 'lr': 0, 'params': 514193, 'time_iter': 0.0266, 'accuracy': 0.97763, 'precision': 0.42254, 'recall': 0.37037, 'f1': 0.39474, 'auc': 0.74469}
2025-06-20 05:29:31,938 - INFO - test: {'epoch': 63, 'time_epoch': 3.28989, 'loss': 0.16216219, 'lr': 0, 'params': 514193, 'time_iter': 0.0255, 'accuracy': 0.9645, 'precision': 0.40476, 'recall': 0.26154, 'f1': 0.31776, 'auc': 0.72945}
2025-06-20 05:29:31,951 - INFO - > Epoch 63: took 70.4s (avg 73.4s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:30:36,633 - INFO - train: {'epoch': 64, 'time_epoch': 64.4727, 'eta': 2314.81521, 'eta_hours': 0.643, 'loss': 0.07512206, 'lr': 3.144e-05, 'params': 514193, 'time_iter': 0.06266, 'accuracy': 0.97663, 'precision': 0.79566, 'recall': 0.50568, 'f1': 0.61836, 'auc': 0.95328}
2025-06-20 05:30:40,133 - INFO - val: {'epoch': 64, 'time_epoch': 3.472, 'loss': 0.10534983, 'lr': 0, 'params': 514193, 'time_iter': 0.02691, 'accuracy': 0.97471, 'precision': 0.35802, 'recall': 0.35802, 'f1': 0.35802, 'auc': 0.77042}
2025-06-20 05:30:43,562 - INFO - test: {'epoch': 64, 'time_epoch': 3.40224, 'loss': 0.15932473, 'lr': 0, 'params': 514193, 'time_iter': 0.02637, 'accuracy': 0.96426, 'precision': 0.41053, 'recall': 0.3, 'f1': 0.34667, 'auc': 0.73918}
2025-06-20 05:30:43,575 - INFO - > Epoch 64: took 71.6s (avg 73.4s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:31:46,854 - INFO - train: {'epoch': 65, 'time_epoch': 62.99479, 'eta': 2247.05862, 'eta_hours': 0.62418, 'loss': 0.07437714, 'lr': 2.992e-05, 'params': 514193, 'time_iter': 0.06122, 'accuracy': 0.97684, 'precision': 0.8044, 'recall': 0.50406, 'f1': 0.61976, 'auc': 0.95638}
2025-06-20 05:31:50,192 - INFO - val: {'epoch': 65, 'time_epoch': 3.3101, 'loss': 0.09351884, 'lr': 0, 'params': 514193, 'time_iter': 0.02566, 'accuracy': 0.97885, 'precision': 0.45, 'recall': 0.33333, 'f1': 0.38298, 'auc': 0.77685}
2025-06-20 05:31:53,542 - INFO - test: {'epoch': 65, 'time_epoch': 3.32351, 'loss': 0.15285204, 'lr': 0, 'params': 514193, 'time_iter': 0.02576, 'accuracy': 0.96693, 'precision': 0.44231, 'recall': 0.17692, 'f1': 0.25275, 'auc': 0.73807}
2025-06-20 05:31:53,549 - INFO - > Epoch 65: took 70.0s (avg 73.3s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:32:58,094 - INFO - train: {'epoch': 66, 'time_epoch': 64.35039, 'eta': 2180.11186, 'eta_hours': 0.60559, 'loss': 0.07442876, 'lr': 2.841e-05, 'params': 514193, 'time_iter': 0.06254, 'accuracy': 0.9769, 'precision': 0.79426, 'recall': 0.51705, 'f1': 0.62635, 'auc': 0.95637}
2025-06-20 05:33:01,720 - INFO - val: {'epoch': 66, 'time_epoch': 3.55939, 'loss': 0.09963097, 'lr': 0, 'params': 514193, 'time_iter': 0.02759, 'accuracy': 0.97666, 'precision': 0.3913, 'recall': 0.33333, 'f1': 0.36, 'auc': 0.76645}
2025-06-20 05:33:05,174 - INFO - test: {'epoch': 66, 'time_epoch': 3.43182, 'loss': 0.15849628, 'lr': 0, 'params': 514193, 'time_iter': 0.0266, 'accuracy': 0.96475, 'precision': 0.40741, 'recall': 0.25385, 'f1': 0.3128, 'auc': 0.74672}
2025-06-20 05:33:05,180 - INFO - > Epoch 66: took 71.6s (avg 73.3s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:34:09,961 - INFO - train: {'epoch': 67, 'time_epoch': 64.55916, 'eta': 2113.3397, 'eta_hours': 0.58704, 'loss': 0.07547157, 'lr': 2.693e-05, 'params': 514193, 'time_iter': 0.06274, 'accuracy': 0.97578, 'precision': 0.77154, 'recall': 0.50162, 'f1': 0.60797, 'auc': 0.95631}
2025-06-20 05:34:13,550 - INFO - val: {'epoch': 67, 'time_epoch': 3.52236, 'loss': 0.10765151, 'lr': 0, 'params': 514193, 'time_iter': 0.02731, 'accuracy': 0.97471, 'precision': 0.36471, 'recall': 0.38272, 'f1': 0.37349, 'auc': 0.77306}
2025-06-20 05:34:16,876 - INFO - test: {'epoch': 67, 'time_epoch': 3.30167, 'loss': 0.1595819, 'lr': 0, 'params': 514193, 'time_iter': 0.02559, 'accuracy': 0.96304, 'precision': 0.37778, 'recall': 0.26154, 'f1': 0.30909, 'auc': 0.75369}
2025-06-20 05:34:16,884 - INFO - > Epoch 67: took 71.7s (avg 73.3s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:35:21,510 - INFO - train: {'epoch': 68, 'time_epoch': 64.39872, 'eta': 2046.55961, 'eta_hours': 0.56849, 'loss': 0.07267529, 'lr': 2.548e-05, 'params': 514193, 'time_iter': 0.06258, 'accuracy': 0.97757, 'precision': 0.80645, 'recall': 0.5276, 'f1': 0.63788, 'auc': 0.95835}
2025-06-20 05:35:25,005 - INFO - val: {'epoch': 68, 'time_epoch': 3.43207, 'loss': 0.10441679, 'lr': 0, 'params': 514193, 'time_iter': 0.02661, 'accuracy': 0.97447, 'precision': 0.35714, 'recall': 0.37037, 'f1': 0.36364, 'auc': 0.79042}
2025-06-20 05:35:28,334 - INFO - test: {'epoch': 68, 'time_epoch': 3.30378, 'loss': 0.15982848, 'lr': 0, 'params': 514193, 'time_iter': 0.02561, 'accuracy': 0.9611, 'precision': 0.36111, 'recall': 0.3, 'f1': 0.32773, 'auc': 0.73953}
2025-06-20 05:35:28,339 - INFO - > Epoch 68: took 71.5s (avg 73.3s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:36:31,533 - INFO - train: {'epoch': 69, 'time_epoch': 62.9361, 'eta': 1979.22072, 'eta_hours': 0.54978, 'loss': 0.07211417, 'lr': 2.405e-05, 'params': 514193, 'time_iter': 0.06116, 'accuracy': 0.9779, 'precision': 0.80095, 'recall': 0.54545, 'f1': 0.64896, 'auc': 0.95845}
2025-06-20 05:36:34,878 - INFO - val: {'epoch': 69, 'time_epoch': 3.28456, 'loss': 0.10518493, 'lr': 0, 'params': 514193, 'time_iter': 0.02546, 'accuracy': 0.97496, 'precision': 0.36905, 'recall': 0.38272, 'f1': 0.37576, 'auc': 0.79003}
2025-06-20 05:36:38,264 - INFO - test: {'epoch': 69, 'time_epoch': 3.36488, 'loss': 0.16421966, 'lr': 0, 'params': 514193, 'time_iter': 0.02608, 'accuracy': 0.96134, 'precision': 0.35354, 'recall': 0.26923, 'f1': 0.30568, 'auc': 0.74806}
2025-06-20 05:36:38,272 - INFO - > Epoch 69: took 69.9s (avg 73.2s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:37:42,809 - INFO - train: {'epoch': 70, 'time_epoch': 64.18885, 'eta': 1912.51754, 'eta_hours': 0.53125, 'loss': 0.07162406, 'lr': 2.265e-05, 'params': 514193, 'time_iter': 0.06238, 'accuracy': 0.97699, 'precision': 0.78999, 'recall': 0.52516, 'f1': 0.63091, 'auc': 0.95952}
2025-06-20 05:37:46,370 - INFO - val: {'epoch': 70, 'time_epoch': 3.52187, 'loss': 0.11955941, 'lr': 0, 'params': 514193, 'time_iter': 0.0273, 'accuracy': 0.97107, 'precision': 0.31373, 'recall': 0.39506, 'f1': 0.34973, 'auc': 0.76456}
2025-06-20 05:37:49,688 - INFO - test: {'epoch': 70, 'time_epoch': 3.29497, 'loss': 0.1769563, 'lr': 0, 'params': 514193, 'time_iter': 0.02554, 'accuracy': 0.95478, 'precision': 0.29104, 'recall': 0.3, 'f1': 0.29545, 'auc': 0.73081}
2025-06-20 05:37:49,690 - INFO - > Epoch 70: took 71.4s (avg 73.2s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:38:53,886 - INFO - train: {'epoch': 71, 'time_epoch': 63.95921, 'eta': 1845.7949, 'eta_hours': 0.51272, 'loss': 0.07209436, 'lr': 2.128e-05, 'params': 514193, 'time_iter': 0.06216, 'accuracy': 0.97757, 'precision': 0.80494, 'recall': 0.52922, 'f1': 0.63859, 'auc': 0.96062}
2025-06-20 05:38:57,284 - INFO - val: {'epoch': 71, 'time_epoch': 3.36714, 'loss': 0.1097929, 'lr': 0, 'params': 514193, 'time_iter': 0.0261, 'accuracy': 0.97496, 'precision': 0.37209, 'recall': 0.39506, 'f1': 0.38323, 'auc': 0.77114}
2025-06-20 05:39:00,657 - INFO - test: {'epoch': 71, 'time_epoch': 3.34614, 'loss': 0.16960178, 'lr': 0, 'params': 514193, 'time_iter': 0.02594, 'accuracy': 0.95867, 'precision': 0.33333, 'recall': 0.30769, 'f1': 0.32, 'auc': 0.74075}
2025-06-20 05:39:00,663 - INFO - > Epoch 71: took 71.0s (avg 73.2s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:40:05,339 - INFO - train: {'epoch': 72, 'time_epoch': 64.44501, 'eta': 1779.32765, 'eta_hours': 0.49426, 'loss': 0.07332936, 'lr': 1.995e-05, 'params': 514193, 'time_iter': 0.06263, 'accuracy': 0.97763, 'precision': 0.80467, 'recall': 0.53166, 'f1': 0.64027, 'auc': 0.95901}
2025-06-20 05:40:08,973 - INFO - val: {'epoch': 72, 'time_epoch': 3.5773, 'loss': 0.10547731, 'lr': 0, 'params': 514193, 'time_iter': 0.02773, 'accuracy': 0.97617, 'precision': 0.39506, 'recall': 0.39506, 'f1': 0.39506, 'auc': 0.76814}
2025-06-20 05:40:12,436 - INFO - test: {'epoch': 72, 'time_epoch': 3.43954, 'loss': 0.16184561, 'lr': 0, 'params': 514193, 'time_iter': 0.02666, 'accuracy': 0.96329, 'precision': 0.37647, 'recall': 0.24615, 'f1': 0.29767, 'auc': 0.73788}
2025-06-20 05:40:12,445 - INFO - > Epoch 72: took 71.8s (avg 73.1s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:41:16,804 - INFO - train: {'epoch': 73, 'time_epoch': 64.09729, 'eta': 1712.79288, 'eta_hours': 0.47578, 'loss': 0.07005334, 'lr': 1.864e-05, 'params': 514193, 'time_iter': 0.06229, 'accuracy': 0.9783, 'precision': 0.80907, 'recall': 0.55032, 'f1': 0.65507, 'auc': 0.96042}
2025-06-20 05:41:20,166 - INFO - val: {'epoch': 73, 'time_epoch': 3.33621, 'loss': 0.09988538, 'lr': 0, 'params': 514193, 'time_iter': 0.02586, 'accuracy': 0.97788, 'precision': 0.42857, 'recall': 0.37037, 'f1': 0.39735, 'auc': 0.76906}
2025-06-20 05:41:23,495 - INFO - test: {'epoch': 73, 'time_epoch': 3.30564, 'loss': 0.15616279, 'lr': 0, 'params': 514193, 'time_iter': 0.02563, 'accuracy': 0.96596, 'precision': 0.4375, 'recall': 0.26923, 'f1': 0.33333, 'auc': 0.73245}
2025-06-20 05:41:23,504 - INFO - > Epoch 73: took 71.1s (avg 73.1s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:42:28,534 - INFO - train: {'epoch': 74, 'time_epoch': 64.78676, 'eta': 1646.55293, 'eta_hours': 0.45738, 'loss': 0.07221099, 'lr': 1.737e-05, 'params': 514193, 'time_iter': 0.06296, 'accuracy': 0.97781, 'precision': 0.81612, 'recall': 0.52597, 'f1': 0.63968, 'auc': 0.96079}
2025-06-20 05:42:32,080 - INFO - val: {'epoch': 74, 'time_epoch': 3.38223, 'loss': 0.10871537, 'lr': 0, 'params': 514193, 'time_iter': 0.02622, 'accuracy': 0.97301, 'precision': 0.33333, 'recall': 0.37037, 'f1': 0.35088, 'auc': 0.79223}
2025-06-20 05:42:35,407 - INFO - test: {'epoch': 74, 'time_epoch': 3.30205, 'loss': 0.17396522, 'lr': 0, 'params': 514193, 'time_iter': 0.0256, 'accuracy': 0.95648, 'precision': 0.30081, 'recall': 0.28462, 'f1': 0.29249, 'auc': 0.73018}
2025-06-20 05:42:35,414 - INFO - > Epoch 74: took 71.9s (avg 73.1s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:43:39,501 - INFO - train: {'epoch': 75, 'time_epoch': 63.83667, 'eta': 1580.0512, 'eta_hours': 0.4389, 'loss': 0.06982319, 'lr': 1.614e-05, 'params': 514193, 'time_iter': 0.06204, 'accuracy': 0.97711, 'precision': 0.78614, 'recall': 0.53409, 'f1': 0.63606, 'auc': 0.96436}
2025-06-20 05:43:43,078 - INFO - val: {'epoch': 75, 'time_epoch': 3.52382, 'loss': 0.10469555, 'lr': 0, 'params': 514193, 'time_iter': 0.02732, 'accuracy': 0.97666, 'precision': 0.4026, 'recall': 0.38272, 'f1': 0.39241, 'auc': 0.78358}
2025-06-20 05:43:46,500 - INFO - test: {'epoch': 75, 'time_epoch': 3.39568, 'loss': 0.16765524, 'lr': 0, 'params': 514193, 'time_iter': 0.02632, 'accuracy': 0.96061, 'precision': 0.32222, 'recall': 0.22308, 'f1': 0.26364, 'auc': 0.72969}
2025-06-20 05:43:46,502 - INFO - > Epoch 75: took 71.1s (avg 73.1s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:44:49,931 - INFO - train: {'epoch': 76, 'time_epoch': 63.17881, 'eta': 1513.42219, 'eta_hours': 0.4204, 'loss': 0.07044186, 'lr': 1.494e-05, 'params': 514193, 'time_iter': 0.0614, 'accuracy': 0.97763, 'precision': 0.79808, 'recall': 0.53896, 'f1': 0.64341, 'auc': 0.96285}
2025-06-20 05:44:53,414 - INFO - val: {'epoch': 76, 'time_epoch': 3.38243, 'loss': 0.11252659, 'lr': 0, 'params': 514193, 'time_iter': 0.02622, 'accuracy': 0.9752, 'precision': 0.37349, 'recall': 0.38272, 'f1': 0.37805, 'auc': 0.77213}
2025-06-20 05:44:56,812 - INFO - test: {'epoch': 76, 'time_epoch': 3.37308, 'loss': 0.177007, 'lr': 0, 'params': 514193, 'time_iter': 0.02615, 'accuracy': 0.9577, 'precision': 0.31034, 'recall': 0.27692, 'f1': 0.29268, 'auc': 0.73035}
2025-06-20 05:44:56,821 - INFO - > Epoch 76: took 70.3s (avg 73.0s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:46:01,728 - INFO - train: {'epoch': 77, 'time_epoch': 64.59658, 'eta': 1447.28152, 'eta_hours': 0.40202, 'loss': 0.06955886, 'lr': 1.378e-05, 'params': 514193, 'time_iter': 0.06278, 'accuracy': 0.97757, 'precision': 0.79903, 'recall': 0.53571, 'f1': 0.6414, 'auc': 0.9657}
2025-06-20 05:46:05,294 - INFO - val: {'epoch': 77, 'time_epoch': 3.5313, 'loss': 0.11092339, 'lr': 0, 'params': 514193, 'time_iter': 0.02737, 'accuracy': 0.97326, 'precision': 0.34066, 'recall': 0.38272, 'f1': 0.36047, 'auc': 0.78468}
2025-06-20 05:46:08,597 - INFO - test: {'epoch': 77, 'time_epoch': 3.28047, 'loss': 0.17611264, 'lr': 0, 'params': 514193, 'time_iter': 0.02543, 'accuracy': 0.95891, 'precision': 0.33043, 'recall': 0.29231, 'f1': 0.3102, 'auc': 0.7352}
2025-06-20 05:46:08,605 - INFO - > Epoch 77: took 71.8s (avg 73.0s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:47:12,044 - INFO - train: {'epoch': 78, 'time_epoch': 63.1971, 'eta': 1380.80794, 'eta_hours': 0.38356, 'loss': 0.06799391, 'lr': 1.266e-05, 'params': 514193, 'time_iter': 0.06142, 'accuracy': 0.97796, 'precision': 0.80143, 'recall': 0.54708, 'f1': 0.65027, 'auc': 0.96581}
2025-06-20 05:47:15,410 - INFO - val: {'epoch': 78, 'time_epoch': 3.33922, 'loss': 0.10723765, 'lr': 0, 'params': 514193, 'time_iter': 0.02589, 'accuracy': 0.97447, 'precision': 0.36047, 'recall': 0.38272, 'f1': 0.37126, 'auc': 0.78301}
2025-06-20 05:47:18,759 - INFO - test: {'epoch': 78, 'time_epoch': 3.32706, 'loss': 0.16959041, 'lr': 0, 'params': 514193, 'time_iter': 0.02579, 'accuracy': 0.96159, 'precision': 0.35106, 'recall': 0.25385, 'f1': 0.29464, 'auc': 0.74039}
2025-06-20 05:47:18,768 - INFO - > Epoch 78: took 70.2s (avg 73.0s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:48:22,922 - INFO - train: {'epoch': 79, 'time_epoch': 63.79542, 'eta': 1314.56584, 'eta_hours': 0.36516, 'loss': 0.06925201, 'lr': 1.158e-05, 'params': 514193, 'time_iter': 0.062, 'accuracy': 0.97875, 'precision': 0.81916, 'recall': 0.55519, 'f1': 0.66183, 'auc': 0.96342}
2025-06-20 05:48:26,584 - INFO - val: {'epoch': 79, 'time_epoch': 3.41696, 'loss': 0.10837672, 'lr': 0, 'params': 514193, 'time_iter': 0.02649, 'accuracy': 0.97763, 'precision': 0.42667, 'recall': 0.39506, 'f1': 0.41026, 'auc': 0.7689}
2025-06-20 05:48:29,927 - INFO - test: {'epoch': 79, 'time_epoch': 3.32257, 'loss': 0.17182077, 'lr': 0, 'params': 514193, 'time_iter': 0.02576, 'accuracy': 0.9645, 'precision': 0.40698, 'recall': 0.26923, 'f1': 0.32407, 'auc': 0.73872}
2025-06-20 05:48:29,931 - INFO - > Epoch 79: took 71.2s (avg 73.0s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:49:34,385 - INFO - train: {'epoch': 80, 'time_epoch': 64.23052, 'eta': 1248.48622, 'eta_hours': 0.3468, 'loss': 0.06771872, 'lr': 1.054e-05, 'params': 514193, 'time_iter': 0.06242, 'accuracy': 0.97921, 'precision': 0.82464, 'recall': 0.56494, 'f1': 0.67052, 'auc': 0.96532}
2025-06-20 05:49:37,941 - INFO - val: {'epoch': 80, 'time_epoch': 3.52809, 'loss': 0.11400015, 'lr': 0, 'params': 514193, 'time_iter': 0.02735, 'accuracy': 0.97447, 'precision': 0.36364, 'recall': 0.39506, 'f1': 0.3787, 'auc': 0.7715}
2025-06-20 05:49:41,324 - INFO - test: {'epoch': 80, 'time_epoch': 3.35778, 'loss': 0.17644373, 'lr': 0, 'params': 514193, 'time_iter': 0.02603, 'accuracy': 0.96086, 'precision': 0.35238, 'recall': 0.28462, 'f1': 0.31489, 'auc': 0.73532}
2025-06-20 05:49:41,331 - INFO - > Epoch 80: took 71.4s (avg 72.9s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:50:45,013 - INFO - train: {'epoch': 81, 'time_epoch': 63.49827, 'eta': 1182.29096, 'eta_hours': 0.32841, 'loss': 0.06957176, 'lr': 9.55e-06, 'params': 514193, 'time_iter': 0.06171, 'accuracy': 0.97851, 'precision': 0.80846, 'recall': 0.55844, 'f1': 0.66059, 'auc': 0.96385}
2025-06-20 05:50:48,329 - INFO - val: {'epoch': 81, 'time_epoch': 3.27612, 'loss': 0.10888405, 'lr': 0, 'params': 514193, 'time_iter': 0.0254, 'accuracy': 0.97666, 'precision': 0.40506, 'recall': 0.39506, 'f1': 0.4, 'auc': 0.7625}
2025-06-20 05:50:51,629 - INFO - test: {'epoch': 81, 'time_epoch': 3.27311, 'loss': 0.17006837, 'lr': 0, 'params': 514193, 'time_iter': 0.02537, 'accuracy': 0.96329, 'precision': 0.3871, 'recall': 0.27692, 'f1': 0.32287, 'auc': 0.73476}
2025-06-20 05:50:51,632 - INFO - > Epoch 81: took 70.3s (avg 72.9s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:51:56,671 - INFO - train: {'epoch': 82, 'time_epoch': 64.70564, 'eta': 1116.40798, 'eta_hours': 0.31011, 'loss': 0.06981554, 'lr': 8.6e-06, 'params': 514193, 'time_iter': 0.06288, 'accuracy': 0.97806, 'precision': 0.81796, 'recall': 0.53247, 'f1': 0.64503, 'auc': 0.96317}
2025-06-20 05:52:00,201 - INFO - val: {'epoch': 82, 'time_epoch': 3.48083, 'loss': 0.11670586, 'lr': 0, 'params': 514193, 'time_iter': 0.02698, 'accuracy': 0.97228, 'precision': 0.33333, 'recall': 0.40741, 'f1': 0.36667, 'auc': 0.77472}
2025-06-20 05:52:03,635 - INFO - test: {'epoch': 82, 'time_epoch': 3.40521, 'loss': 0.18168223, 'lr': 0, 'params': 514193, 'time_iter': 0.0264, 'accuracy': 0.95672, 'precision': 0.30952, 'recall': 0.3, 'f1': 0.30469, 'auc': 0.7327}
2025-06-20 05:52:03,644 - INFO - > Epoch 82: took 72.0s (avg 72.9s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:53:08,369 - INFO - train: {'epoch': 83, 'time_epoch': 64.42334, 'eta': 1050.49927, 'eta_hours': 0.29181, 'loss': 0.06712524, 'lr': 7.7e-06, 'params': 514193, 'time_iter': 0.06261, 'accuracy': 0.97918, 'precision': 0.82992, 'recall': 0.55844, 'f1': 0.66764, 'auc': 0.96533}
2025-06-20 05:53:11,693 - INFO - val: {'epoch': 83, 'time_epoch': 3.29724, 'loss': 0.11192922, 'lr': 0, 'params': 514193, 'time_iter': 0.02556, 'accuracy': 0.97544, 'precision': 0.38372, 'recall': 0.40741, 'f1': 0.39521, 'auc': 0.7713}
2025-06-20 05:53:15,001 - INFO - test: {'epoch': 83, 'time_epoch': 3.28867, 'loss': 0.17336823, 'lr': 0, 'params': 514193, 'time_iter': 0.02549, 'accuracy': 0.95988, 'precision': 0.33945, 'recall': 0.28462, 'f1': 0.30962, 'auc': 0.7354}
2025-06-20 05:53:15,016 - INFO - > Epoch 83: took 71.4s (avg 72.9s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:54:19,539 - INFO - train: {'epoch': 84, 'time_epoch': 64.30527, 'eta': 984.60466, 'eta_hours': 0.2735, 'loss': 0.0674691, 'lr': 6.84e-06, 'params': 514193, 'time_iter': 0.06249, 'accuracy': 0.9786, 'precision': 0.81059, 'recall': 0.55925, 'f1': 0.66186, 'auc': 0.96807}
2025-06-20 05:54:22,979 - INFO - val: {'epoch': 84, 'time_epoch': 3.39985, 'loss': 0.10311318, 'lr': 0, 'params': 514193, 'time_iter': 0.02636, 'accuracy': 0.97739, 'precision': 0.41429, 'recall': 0.35802, 'f1': 0.38411, 'auc': 0.79172}
2025-06-20 05:54:26,351 - INFO - test: {'epoch': 84, 'time_epoch': 3.34582, 'loss': 0.17175888, 'lr': 0, 'params': 514193, 'time_iter': 0.02594, 'accuracy': 0.9645, 'precision': 0.40244, 'recall': 0.25385, 'f1': 0.31132, 'auc': 0.73557}
2025-06-20 05:54:26,359 - INFO - > Epoch 84: took 71.3s (avg 72.9s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:55:31,003 - INFO - train: {'epoch': 85, 'time_epoch': 64.39127, 'eta': 918.76102, 'eta_hours': 0.25521, 'loss': 0.06705428, 'lr': 6.03e-06, 'params': 514193, 'time_iter': 0.06258, 'accuracy': 0.97863, 'precision': 0.81154, 'recall': 0.55925, 'f1': 0.66218, 'auc': 0.96799}
2025-06-20 05:55:34,483 - INFO - val: {'epoch': 85, 'time_epoch': 3.42622, 'loss': 0.10761744, 'lr': 0, 'params': 514193, 'time_iter': 0.02656, 'accuracy': 0.97617, 'precision': 0.39506, 'recall': 0.39506, 'f1': 0.39506, 'auc': 0.79525}
2025-06-20 05:55:37,821 - INFO - test: {'epoch': 85, 'time_epoch': 3.31649, 'loss': 0.17504039, 'lr': 0, 'params': 514193, 'time_iter': 0.02571, 'accuracy': 0.9628, 'precision': 0.37634, 'recall': 0.26923, 'f1': 0.3139, 'auc': 0.73421}
2025-06-20 05:55:37,825 - INFO - > Epoch 85: took 71.5s (avg 72.8s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:56:41,451 - INFO - train: {'epoch': 86, 'time_epoch': 63.43497, 'eta': 852.80787, 'eta_hours': 0.23689, 'loss': 0.06604373, 'lr': 5.26e-06, 'params': 514193, 'time_iter': 0.06165, 'accuracy': 0.97976, 'precision': 0.83531, 'recall': 0.57224, 'f1': 0.67919, 'auc': 0.96615}
2025-06-20 05:56:44,801 - INFO - val: {'epoch': 86, 'time_epoch': 3.29048, 'loss': 0.10921191, 'lr': 0, 'params': 514193, 'time_iter': 0.02551, 'accuracy': 0.97423, 'precision': 0.35632, 'recall': 0.38272, 'f1': 0.36905, 'auc': 0.78868}
2025-06-20 05:56:48,174 - INFO - test: {'epoch': 86, 'time_epoch': 3.35014, 'loss': 0.18140448, 'lr': 0, 'params': 514193, 'time_iter': 0.02597, 'accuracy': 0.9611, 'precision': 0.34694, 'recall': 0.26154, 'f1': 0.29825, 'auc': 0.7238}
2025-06-20 05:56:48,183 - INFO - > Epoch 86: took 70.4s (avg 72.8s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:57:50,882 - INFO - train: {'epoch': 87, 'time_epoch': 62.48361, 'eta': 786.78222, 'eta_hours': 0.21855, 'loss': 0.06710668, 'lr': 4.55e-06, 'params': 514193, 'time_iter': 0.06072, 'accuracy': 0.97885, 'precision': 0.81754, 'recall': 0.56006, 'f1': 0.66474, 'auc': 0.96695}
2025-06-20 05:57:54,273 - INFO - val: {'epoch': 87, 'time_epoch': 3.35738, 'loss': 0.10817851, 'lr': 0, 'params': 514193, 'time_iter': 0.02603, 'accuracy': 0.97715, 'precision': 0.41772, 'recall': 0.40741, 'f1': 0.4125, 'auc': 0.78276}
2025-06-20 05:57:57,585 - INFO - test: {'epoch': 87, 'time_epoch': 3.28745, 'loss': 0.17656639, 'lr': 0, 'params': 514193, 'time_iter': 0.02548, 'accuracy': 0.96256, 'precision': 0.36957, 'recall': 0.26154, 'f1': 0.30631, 'auc': 0.73231}
2025-06-20 05:57:57,593 - INFO - > Epoch 87: took 69.4s (avg 72.8s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 05:59:00,934 - INFO - train: {'epoch': 88, 'time_epoch': 63.00544, 'eta': 720.90066, 'eta_hours': 0.20025, 'loss': 0.06811683, 'lr': 3.89e-06, 'params': 514193, 'time_iter': 0.06123, 'accuracy': 0.97915, 'precision': 0.81967, 'recall': 0.56818, 'f1': 0.67114, 'auc': 0.96487}
2025-06-20 05:59:04,354 - INFO - val: {'epoch': 88, 'time_epoch': 3.37077, 'loss': 0.11039578, 'lr': 0, 'params': 514193, 'time_iter': 0.02613, 'accuracy': 0.97471, 'precision': 0.36782, 'recall': 0.39506, 'f1': 0.38095, 'auc': 0.78106}
2025-06-20 05:59:07,799 - INFO - test: {'epoch': 88, 'time_epoch': 3.41197, 'loss': 0.17482958, 'lr': 0, 'params': 514193, 'time_iter': 0.02645, 'accuracy': 0.96256, 'precision': 0.38462, 'recall': 0.30769, 'f1': 0.34188, 'auc': 0.72891}
2025-06-20 05:59:07,807 - INFO - > Epoch 88: took 70.2s (avg 72.8s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 06:00:12,935 - INFO - train: {'epoch': 89, 'time_epoch': 64.89929, 'eta': 655.29344, 'eta_hours': 0.18203, 'loss': 0.06802014, 'lr': 3.27e-06, 'params': 514193, 'time_iter': 0.06307, 'accuracy': 0.97912, 'precision': 0.82402, 'recall': 0.5625, 'f1': 0.6686, 'auc': 0.965}
2025-06-20 06:00:16,307 - INFO - val: {'epoch': 89, 'time_epoch': 3.33935, 'loss': 0.11039817, 'lr': 0, 'params': 514193, 'time_iter': 0.02589, 'accuracy': 0.97617, 'precision': 0.39506, 'recall': 0.39506, 'f1': 0.39506, 'auc': 0.78158}
2025-06-20 06:00:19,618 - INFO - test: {'epoch': 89, 'time_epoch': 3.28769, 'loss': 0.17803989, 'lr': 0, 'params': 514193, 'time_iter': 0.02549, 'accuracy': 0.96329, 'precision': 0.38202, 'recall': 0.26154, 'f1': 0.3105, 'auc': 0.73404}
2025-06-20 06:00:19,620 - INFO - > Epoch 89: took 71.8s (avg 72.7s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 06:01:23,895 - INFO - train: {'epoch': 90, 'time_epoch': 63.95551, 'eta': 589.60845, 'eta_hours': 0.16378, 'loss': 0.06723449, 'lr': 2.71e-06, 'params': 514193, 'time_iter': 0.06215, 'accuracy': 0.97945, 'precision': 0.81663, 'recall': 0.58198, 'f1': 0.67962, 'auc': 0.96501}
2025-06-20 06:01:27,267 - INFO - val: {'epoch': 90, 'time_epoch': 3.33338, 'loss': 0.10694363, 'lr': 0, 'params': 514193, 'time_iter': 0.02584, 'accuracy': 0.97739, 'precision': 0.42105, 'recall': 0.39506, 'f1': 0.40764, 'auc': 0.77115}
2025-06-20 06:01:30,629 - INFO - test: {'epoch': 90, 'time_epoch': 3.34037, 'loss': 0.17175115, 'lr': 0, 'params': 514193, 'time_iter': 0.02589, 'accuracy': 0.96231, 'precision': 0.35955, 'recall': 0.24615, 'f1': 0.29224, 'auc': 0.73505}
2025-06-20 06:01:30,638 - INFO - > Epoch 90: took 71.0s (avg 72.7s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 06:02:35,505 - INFO - train: {'epoch': 91, 'time_epoch': 64.61138, 'eta': 524.01808, 'eta_hours': 0.14556, 'loss': 0.06700099, 'lr': 2.2e-06, 'params': 514193, 'time_iter': 0.06279, 'accuracy': 0.97875, 'precision': 0.8117, 'recall': 0.56331, 'f1': 0.66507, 'auc': 0.96724}
2025-06-20 06:02:38,866 - INFO - val: {'epoch': 91, 'time_epoch': 3.31119, 'loss': 0.11021962, 'lr': 0, 'params': 514193, 'time_iter': 0.02567, 'accuracy': 0.97496, 'precision': 0.37209, 'recall': 0.39506, 'f1': 0.38323, 'auc': 0.77946}
2025-06-20 06:02:42,186 - INFO - test: {'epoch': 91, 'time_epoch': 3.30055, 'loss': 0.17488386, 'lr': 0, 'params': 514193, 'time_iter': 0.02559, 'accuracy': 0.96256, 'precision': 0.37234, 'recall': 0.26923, 'f1': 0.3125, 'auc': 0.73502}
2025-06-20 06:02:42,193 - INFO - > Epoch 91: took 71.6s (avg 72.7s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 06:03:46,333 - INFO - train: {'epoch': 92, 'time_epoch': 63.899, 'eta': 458.39514, 'eta_hours': 0.12733, 'loss': 0.06723969, 'lr': 1.74e-06, 'params': 514193, 'time_iter': 0.0621, 'accuracy': 0.97903, 'precision': 0.81808, 'recall': 0.56575, 'f1': 0.66891, 'auc': 0.96789}
2025-06-20 06:03:49,762 - INFO - val: {'epoch': 92, 'time_epoch': 3.38871, 'loss': 0.11260649, 'lr': 0, 'params': 514193, 'time_iter': 0.02627, 'accuracy': 0.97301, 'precision': 0.34375, 'recall': 0.40741, 'f1': 0.37288, 'auc': 0.7893}
2025-06-20 06:03:53,095 - INFO - test: {'epoch': 92, 'time_epoch': 3.30639, 'loss': 0.17772786, 'lr': 0, 'params': 514193, 'time_iter': 0.02563, 'accuracy': 0.9577, 'precision': 0.3254, 'recall': 0.31538, 'f1': 0.32031, 'auc': 0.73884}
2025-06-20 06:03:53,106 - INFO - > Epoch 92: took 70.9s (avg 72.7s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 06:04:55,465 - INFO - train: {'epoch': 93, 'time_epoch': 62.16139, 'eta': 392.69797, 'eta_hours': 0.10908, 'loss': 0.06750283, 'lr': 1.33e-06, 'params': 514193, 'time_iter': 0.06041, 'accuracy': 0.97921, 'precision': 0.83092, 'recall': 0.55844, 'f1': 0.66796, 'auc': 0.96702}
2025-06-20 06:04:59,018 - INFO - val: {'epoch': 93, 'time_epoch': 3.33124, 'loss': 0.10879526, 'lr': 0, 'params': 514193, 'time_iter': 0.02582, 'accuracy': 0.97642, 'precision': 0.4, 'recall': 0.39506, 'f1': 0.39752, 'auc': 0.78113}
2025-06-20 06:05:02,323 - INFO - test: {'epoch': 93, 'time_epoch': 3.28351, 'loss': 0.1701505, 'lr': 0, 'params': 514193, 'time_iter': 0.02545, 'accuracy': 0.96256, 'precision': 0.375, 'recall': 0.27692, 'f1': 0.31858, 'auc': 0.73949}
2025-06-20 06:05:02,329 - INFO - > Epoch 93: took 69.2s (avg 72.7s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 06:06:06,799 - INFO - train: {'epoch': 94, 'time_epoch': 64.20917, 'eta': 327.18302, 'eta_hours': 0.09088, 'loss': 0.06460348, 'lr': 9.8e-07, 'params': 514193, 'time_iter': 0.0624, 'accuracy': 0.97903, 'precision': 0.80656, 'recall': 0.57873, 'f1': 0.67391, 'auc': 0.97148}
2025-06-20 06:06:10,144 - INFO - val: {'epoch': 94, 'time_epoch': 3.31847, 'loss': 0.11087783, 'lr': 0, 'params': 514193, 'time_iter': 0.02572, 'accuracy': 0.97617, 'precision': 0.39506, 'recall': 0.39506, 'f1': 0.39506, 'auc': 0.78174}
2025-06-20 06:06:13,553 - INFO - test: {'epoch': 94, 'time_epoch': 3.3864, 'loss': 0.17954179, 'lr': 0, 'params': 514193, 'time_iter': 0.02625, 'accuracy': 0.96231, 'precision': 0.37374, 'recall': 0.28462, 'f1': 0.32314, 'auc': 0.73669}
2025-06-20 06:06:13,557 - INFO - > Epoch 94: took 71.2s (avg 72.6s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 06:07:18,501 - INFO - train: {'epoch': 95, 'time_epoch': 64.69846, 'eta': 261.71566, 'eta_hours': 0.0727, 'loss': 0.06546958, 'lr': 6.8e-07, 'params': 514193, 'time_iter': 0.06288, 'accuracy': 0.97894, 'precision': 0.81594, 'recall': 0.56494, 'f1': 0.66763, 'auc': 0.96983}
2025-06-20 06:07:21,915 - INFO - val: {'epoch': 95, 'time_epoch': 3.38408, 'loss': 0.10819074, 'lr': 0, 'params': 514193, 'time_iter': 0.02623, 'accuracy': 0.97617, 'precision': 0.39241, 'recall': 0.38272, 'f1': 0.3875, 'auc': 0.77178}
2025-06-20 06:07:25,226 - INFO - test: {'epoch': 95, 'time_epoch': 3.28774, 'loss': 0.17156688, 'lr': 0, 'params': 514193, 'time_iter': 0.02549, 'accuracy': 0.96159, 'precision': 0.36275, 'recall': 0.28462, 'f1': 0.31897, 'auc': 0.73197}
2025-06-20 06:07:25,230 - INFO - > Epoch 95: took 71.7s (avg 72.6s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 06:08:29,212 - INFO - train: {'epoch': 96, 'time_epoch': 63.7932, 'eta': 196.23616, 'eta_hours': 0.05451, 'loss': 0.06287384, 'lr': 4.4e-07, 'params': 514193, 'time_iter': 0.062, 'accuracy': 0.9797, 'precision': 0.82488, 'recall': 0.58117, 'f1': 0.6819, 'auc': 0.97159}
2025-06-20 06:08:32,605 - INFO - val: {'epoch': 96, 'time_epoch': 3.35895, 'loss': 0.10926355, 'lr': 0, 'params': 514193, 'time_iter': 0.02604, 'accuracy': 0.9752, 'precision': 0.37349, 'recall': 0.38272, 'f1': 0.37805, 'auc': 0.77075}
2025-06-20 06:08:35,946 - INFO - test: {'epoch': 96, 'time_epoch': 3.32097, 'loss': 0.17629198, 'lr': 0, 'params': 514193, 'time_iter': 0.02574, 'accuracy': 0.96061, 'precision': 0.35185, 'recall': 0.29231, 'f1': 0.31933, 'auc': 0.73052}
2025-06-20 06:08:35,949 - INFO - > Epoch 96: took 70.7s (avg 72.6s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 06:09:39,696 - INFO - train: {'epoch': 97, 'time_epoch': 63.4499, 'eta': 130.78406, 'eta_hours': 0.03633, 'loss': 0.06704186, 'lr': 2.5e-07, 'params': 514193, 'time_iter': 0.06166, 'accuracy': 0.97882, 'precision': 0.80854, 'recall': 0.56899, 'f1': 0.66794, 'auc': 0.96728}
2025-06-20 06:09:43,242 - INFO - val: {'epoch': 97, 'time_epoch': 3.50903, 'loss': 0.10851483, 'lr': 0, 'params': 514193, 'time_iter': 0.0272, 'accuracy': 0.97666, 'precision': 0.40741, 'recall': 0.40741, 'f1': 0.40741, 'auc': 0.77927}
2025-06-20 06:09:46,654 - INFO - test: {'epoch': 97, 'time_epoch': 3.38916, 'loss': 0.17502891, 'lr': 0, 'params': 514193, 'time_iter': 0.02627, 'accuracy': 0.96256, 'precision': 0.37755, 'recall': 0.28462, 'f1': 0.32456, 'auc': 0.73487}
2025-06-20 06:09:46,660 - INFO - > Epoch 97: took 70.7s (avg 72.6s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 06:10:50,697 - INFO - train: {'epoch': 98, 'time_epoch': 63.75712, 'eta': 65.37552, 'eta_hours': 0.01816, 'loss': 0.06720341, 'lr': 1.1e-07, 'params': 514193, 'time_iter': 0.06196, 'accuracy': 0.97909, 'precision': 0.8185, 'recall': 0.56737, 'f1': 0.67018, 'auc': 0.96597}
2025-06-20 06:10:54,120 - INFO - val: {'epoch': 98, 'time_epoch': 3.36195, 'loss': 0.11312458, 'lr': 0, 'params': 514193, 'time_iter': 0.02606, 'accuracy': 0.97374, 'precision': 0.35484, 'recall': 0.40741, 'f1': 0.37931, 'auc': 0.78375}
2025-06-20 06:10:57,433 - INFO - test: {'epoch': 98, 'time_epoch': 3.29294, 'loss': 0.17701219, 'lr': 0, 'params': 514193, 'time_iter': 0.02553, 'accuracy': 0.95697, 'precision': 0.30894, 'recall': 0.29231, 'f1': 0.3004, 'auc': 0.74154}
2025-06-20 06:10:57,439 - INFO - > Epoch 98: took 70.8s (avg 72.6s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 06:12:00,931 - INFO - train: {'epoch': 99, 'time_epoch': 63.17505, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.06484337, 'lr': 3e-08, 'params': 514193, 'time_iter': 0.06139, 'accuracy': 0.97979, 'precision': 0.82927, 'recall': 0.57955, 'f1': 0.68227, 'auc': 0.96847}
2025-06-20 06:12:04,454 - INFO - val: {'epoch': 99, 'time_epoch': 3.35001, 'loss': 0.10743273, 'lr': 0, 'params': 514193, 'time_iter': 0.02597, 'accuracy': 0.97642, 'precision': 0.39744, 'recall': 0.38272, 'f1': 0.38994, 'auc': 0.78334}
2025-06-20 06:12:07,825 - INFO - test: {'epoch': 99, 'time_epoch': 3.34227, 'loss': 0.17232969, 'lr': 0, 'params': 514193, 'time_iter': 0.02591, 'accuracy': 0.96329, 'precision': 0.38462, 'recall': 0.26923, 'f1': 0.31674, 'auc': 0.7378}
2025-06-20 06:12:08,016 - INFO - > Epoch 99: took 70.4s (avg 72.5s) | Best so far: epoch 35	train_loss: 0.0963 train_auc: 0.9007	val_loss: 0.0836 val_auc: 0.8065	test_loss: 0.1321 test_auc: 0.7644
2025-06-20 06:12:08,017 - INFO - Avg time per epoch: 72.55s
2025-06-20 06:12:08,017 - INFO - Total train loop time: 2.02h
2025-06-20 06:12:08,027 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-47
2025-06-20 06:12:08,028 - INFO - Total time: 8074.41s (2.24h)
2025-06-20 06:12:08,038 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-47/agg
2025-06-20 06:12:08,038 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-06-20 06:12:08,038 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-47
2025-06-20 06:12:08,038 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-47/test_results/
Completed seed 47. Results saved in results/molhiv/molhiv-Vanilla-47
----------------------------------------
All experiments completed!
