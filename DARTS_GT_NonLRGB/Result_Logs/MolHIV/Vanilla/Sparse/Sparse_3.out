Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          251Gi       8.7Gi       167Gi       2.3Gi        74Gi       237Gi
Swap:         1.9Gi        21Mi       1.8Gi
Sat Aug 16 03:01:04 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA TITAN RTX               On  |   00000000:1B:00.0 Off |                  N/A |
| 41%   38C    P8             33W /  280W |       1MiB /  24576MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 41
Starting training for seed 41...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/confignas.yaml
Using device: cuda
2025-08-16 03:01:32,252 - INFO - GPU Mem: 25.2GB
2025-08-16 03:01:32,252 - INFO - Run directory: results/molhiv/molhiv-Vanilla-41
2025-08-16 03:01:32,252 - INFO - Seed: 41
2025-08-16 03:01:32,252 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-16 03:01:32,252 - INFO - Routing mode: none
2025-08-16 03:01:32,252 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 03:01:32,252 - INFO - Number of layers: 15
2025-08-16 03:01:32,252 - INFO - Uncertainty enabled: False
2025-08-16 03:01:32,252 - INFO - Training mode: custom
2025-08-16 03:01:32,252 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-16 03:01:32,252 - INFO - Additional features: Router weights logging + JSON export
2025-08-16 03:01:39,914 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 03:01:39,917 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 03:01:39,942 - INFO -   undirected: True
2025-08-16 03:01:39,943 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 03:01:39,943 - INFO -   avg num_nodes/graph: 25
2025-08-16 03:01:39,943 - INFO -   num node features: 9
2025-08-16 03:01:39,944 - INFO -   num edge features: 3
2025-08-16 03:01:39,944 - INFO -   num tasks: 1
2025-08-16 03:01:39,944 - INFO -   num classes: 2
2025-08-16 03:01:39,944 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 03:01:39,944 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 03:01:39,947 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 19%|█▊        | 7708/41127 [00:10<00:43, 770.79it/s] 37%|███▋      | 15216/41127 [00:20<00:34, 758.99it/s] 55%|█████▌    | 22640/41127 [00:30<00:24, 751.41it/s] 72%|███████▏  | 29728/41127 [00:40<00:15, 734.55it/s] 90%|████████▉ | 36867/41127 [00:50<00:05, 727.07it/s]100%|██████████| 41127/41127 [00:56<00:00, 729.93it/s]
2025-08-16 03:02:37,289 - INFO - Done! Took 00:00:57.34
2025-08-16 03:02:37,426 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 03:02:37,749 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-16 03:02:37,750 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-08-16 03:02:37,750 - INFO - Inner model has get_darts_model: False
2025-08-16 03:02:37,754 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-08-16 03:02:37,757 - INFO - Number of parameters: 451,793
2025-08-16 03:02:37,757 - INFO - Starting optimized training: 2025-08-16 03:02:37.757130
2025-08-16 03:02:43,504 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 03:02:43,505 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 03:02:43,505 - INFO -   undirected: True
2025-08-16 03:02:43,506 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 03:02:43,506 - INFO -   avg num_nodes/graph: 25
2025-08-16 03:02:43,506 - INFO -   num node features: 9
2025-08-16 03:02:43,506 - INFO -   num edge features: 3
2025-08-16 03:02:43,506 - INFO -   num tasks: 1
2025-08-16 03:02:43,507 - INFO -   num classes: 2
2025-08-16 03:02:43,507 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 03:02:43,507 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 03:02:43,510 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 17%|█▋        | 7093/41127 [00:10<00:47, 709.29it/s] 35%|███▍      | 14209/41127 [00:20<00:37, 710.65it/s] 52%|█████▏    | 21408/41127 [00:30<00:27, 714.85it/s] 69%|██████▉   | 28451/41127 [00:40<00:17, 710.64it/s] 86%|████████▌ | 35345/41127 [00:50<00:08, 702.98it/s]100%|██████████| 41127/41127 [00:58<00:00, 708.00it/s]
2025-08-16 03:03:42,536 - INFO - Done! Took 00:00:59.03
2025-08-16 03:03:42,673 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 03:03:42,763 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-16 03:03:42,763 - INFO - Start from epoch 0
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:05:03,281 - INFO - train: {'epoch': 0, 'time_epoch': 79.80588, 'eta': 7900.78241, 'eta_hours': 2.19466, 'loss': 0.64553239, 'lr': 0.0, 'params': 451793, 'time_iter': 0.07756, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.54815}
2025-08-16 03:05:03,369 - INFO - ...computing epoch stats took: 0.77s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:05:08,892 - INFO - val: {'epoch': 0, 'time_epoch': 5.5073, 'loss': 0.64428301, 'lr': 0, 'params': 451793, 'time_iter': 0.04269, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.57096}
2025-08-16 03:05:08,908 - INFO - ...computing epoch stats took: 0.03s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:05:13,833 - INFO - test: {'epoch': 0, 'time_epoch': 4.90967, 'loss': 0.64384036, 'lr': 0, 'params': 451793, 'time_iter': 0.03806, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.61957}
2025-08-16 03:05:13,848 - INFO - ...computing epoch stats took: 0.03s
2025-08-16 03:05:13,849 - INFO - > Epoch 0: took 91.1s (avg 91.1s) | Best so far: epoch 0	train_loss: 0.6455 train_auc: 0.5482	val_loss: 0.6443 val_auc: 0.5710	test_loss: 0.6438 test_auc: 0.6196
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:06:26,971 - INFO - train: {'epoch': 1, 'time_epoch': 73.06528, 'eta': 7490.68678, 'eta_hours': 2.08075, 'loss': 0.3821699, 'lr': 2e-05, 'params': 451793, 'time_iter': 0.07101, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.54467}
2025-08-16 03:06:26,980 - INFO - ...computing epoch stats took: 0.04s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:06:31,467 - INFO - val: {'epoch': 1, 'time_epoch': 4.47194, 'loss': 0.20050563, 'lr': 0, 'params': 451793, 'time_iter': 0.03467, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.58384}
2025-08-16 03:06:31,469 - INFO - ...computing epoch stats took: 0.01s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:06:35,969 - INFO - test: {'epoch': 1, 'time_epoch': 4.48391, 'loss': 0.20861545, 'lr': 0, 'params': 451793, 'time_iter': 0.03476, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.5968}
2025-08-16 03:06:35,972 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 03:06:35,972 - INFO - > Epoch 1: took 82.1s (avg 86.6s) | Best so far: epoch 1	train_loss: 0.3822 train_auc: 0.5447	val_loss: 0.2005 val_auc: 0.5838	test_loss: 0.2086 test_auc: 0.5968
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:07:50,148 - INFO - train: {'epoch': 2, 'time_epoch': 74.12118, 'eta': 7339.41893, 'eta_hours': 2.03873, 'loss': 0.18444954, 'lr': 4e-05, 'params': 451793, 'time_iter': 0.07203, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.60474}
2025-08-16 03:07:50,156 - INFO - ...computing epoch stats took: 0.04s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:07:54,660 - INFO - val: {'epoch': 2, 'time_epoch': 4.48759, 'loss': 0.11382988, 'lr': 0, 'params': 451793, 'time_iter': 0.03479, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.46579}
2025-08-16 03:07:54,662 - INFO - ...computing epoch stats took: 0.01s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:07:59,175 - INFO - test: {'epoch': 2, 'time_epoch': 4.49678, 'loss': 0.1455848, 'lr': 0, 'params': 451793, 'time_iter': 0.03486, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.54686}
2025-08-16 03:07:59,178 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 03:07:59,178 - INFO - > Epoch 2: took 83.2s (avg 85.5s) | Best so far: epoch 1	train_loss: 0.3822 train_auc: 0.5447	val_loss: 0.2005 val_auc: 0.5838	test_loss: 0.2086 test_auc: 0.5968
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:09:11,431 - INFO - train: {'epoch': 3, 'time_epoch': 72.19564, 'eta': 7180.51145, 'eta_hours': 1.99459, 'loss': 0.15736938, 'lr': 6e-05, 'params': 451793, 'time_iter': 0.07016, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.63402}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:09:15,936 - INFO - val: {'epoch': 3, 'time_epoch': 4.48166, 'loss': 0.09956219, 'lr': 0, 'params': 451793, 'time_iter': 0.03474, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.61942}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:09:20,390 - INFO - test: {'epoch': 3, 'time_epoch': 4.43616, 'loss': 0.13154004, 'lr': 0, 'params': 451793, 'time_iter': 0.03439, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6903}
2025-08-16 03:09:20,393 - INFO - > Epoch 3: took 81.2s (avg 84.4s) | Best so far: epoch 3	train_loss: 0.1574 train_auc: 0.6340	val_loss: 0.0996 val_auc: 0.6194	test_loss: 0.1315 test_auc: 0.6903
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:10:33,211 - INFO - train: {'epoch': 4, 'time_epoch': 72.76112, 'eta': 7067.03279, 'eta_hours': 1.96306, 'loss': 0.15128936, 'lr': 8e-05, 'params': 451793, 'time_iter': 0.07071, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67382}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:10:37,682 - INFO - val: {'epoch': 4, 'time_epoch': 4.4475, 'loss': 0.10024306, 'lr': 0, 'params': 451793, 'time_iter': 0.03448, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.64238}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:10:42,331 - INFO - test: {'epoch': 4, 'time_epoch': 4.44445, 'loss': 0.13237797, 'lr': 0, 'params': 451793, 'time_iter': 0.03445, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68561}
2025-08-16 03:10:42,445 - INFO - > Epoch 4: took 82.1s (avg 83.9s) | Best so far: epoch 4	train_loss: 0.1513 train_auc: 0.6738	val_loss: 0.1002 val_auc: 0.6424	test_loss: 0.1324 test_auc: 0.6856
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:11:54,208 - INFO - train: {'epoch': 5, 'time_epoch': 71.70767, 'eta': 6950.62258, 'eta_hours': 1.93073, 'loss': 0.14594814, 'lr': 0.0001, 'params': 451793, 'time_iter': 0.06969, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70851}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:11:58,683 - INFO - val: {'epoch': 5, 'time_epoch': 4.45036, 'loss': 0.09661796, 'lr': 0, 'params': 451793, 'time_iter': 0.0345, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.63666}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:12:03,179 - INFO - test: {'epoch': 5, 'time_epoch': 4.47874, 'loss': 0.12739449, 'lr': 0, 'params': 451793, 'time_iter': 0.03472, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69211}
2025-08-16 03:12:03,181 - INFO - > Epoch 5: took 80.7s (avg 83.4s) | Best so far: epoch 4	train_loss: 0.1513 train_auc: 0.6738	val_loss: 0.1002 val_auc: 0.6424	test_loss: 0.1324 test_auc: 0.6856
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:13:14,276 - INFO - train: {'epoch': 6, 'time_epoch': 71.03863, 'eta': 6838.09596, 'eta_hours': 1.89947, 'loss': 0.14238403, 'lr': 9.997e-05, 'params': 451793, 'time_iter': 0.06904, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72993}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:13:18,780 - INFO - val: {'epoch': 6, 'time_epoch': 4.48146, 'loss': 0.09067256, 'lr': 0, 'params': 451793, 'time_iter': 0.03474, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66082}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:13:23,293 - INFO - test: {'epoch': 6, 'time_epoch': 4.49536, 'loss': 0.12330959, 'lr': 0, 'params': 451793, 'time_iter': 0.03485, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74326}
2025-08-16 03:13:23,296 - INFO - > Epoch 6: took 80.1s (avg 82.9s) | Best so far: epoch 6	train_loss: 0.1424 train_auc: 0.7299	val_loss: 0.0907 val_auc: 0.6608	test_loss: 0.1233 test_auc: 0.7433
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:14:34,019 - INFO - train: {'epoch': 7, 'time_epoch': 70.66875, 'eta': 6731.6877, 'eta_hours': 1.86991, 'loss': 0.13919372, 'lr': 9.989e-05, 'params': 451793, 'time_iter': 0.06868, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74893}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:14:38,408 - INFO - val: {'epoch': 7, 'time_epoch': 4.36622, 'loss': 0.0929497, 'lr': 0, 'params': 451793, 'time_iter': 0.03385, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66577}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:14:42,784 - INFO - test: {'epoch': 7, 'time_epoch': 4.3591, 'loss': 0.1239755, 'lr': 0, 'params': 451793, 'time_iter': 0.03379, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73138}
2025-08-16 03:14:42,786 - INFO - > Epoch 7: took 79.5s (avg 82.5s) | Best so far: epoch 7	train_loss: 0.1392 train_auc: 0.7489	val_loss: 0.0929 val_auc: 0.6658	test_loss: 0.1240 test_auc: 0.7314
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:15:54,461 - INFO - train: {'epoch': 8, 'time_epoch': 71.61974, 'eta': 6642.83713, 'eta_hours': 1.84523, 'loss': 0.13803706, 'lr': 9.975e-05, 'params': 451793, 'time_iter': 0.0696, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.749}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:15:58,934 - INFO - val: {'epoch': 8, 'time_epoch': 4.4502, 'loss': 0.08682058, 'lr': 0, 'params': 451793, 'time_iter': 0.0345, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70122}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:16:03,390 - INFO - test: {'epoch': 8, 'time_epoch': 4.43759, 'loss': 0.1152708, 'lr': 0, 'params': 451793, 'time_iter': 0.0344, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75637}
2025-08-16 03:16:03,393 - INFO - > Epoch 8: took 80.6s (avg 82.3s) | Best so far: epoch 8	train_loss: 0.1380 train_auc: 0.7490	val_loss: 0.0868 val_auc: 0.7012	test_loss: 0.1153 test_auc: 0.7564
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:17:14,439 - INFO - train: {'epoch': 9, 'time_epoch': 70.9902, 'eta': 6551.76679, 'eta_hours': 1.81994, 'loss': 0.13524073, 'lr': 9.956e-05, 'params': 451793, 'time_iter': 0.06899, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76337}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:17:18,899 - INFO - val: {'epoch': 9, 'time_epoch': 4.43782, 'loss': 0.08642248, 'lr': 0, 'params': 451793, 'time_iter': 0.0344, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69302}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:17:23,377 - INFO - test: {'epoch': 9, 'time_epoch': 4.46007, 'loss': 0.11929241, 'lr': 0, 'params': 451793, 'time_iter': 0.03457, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75803}
2025-08-16 03:17:23,380 - INFO - > Epoch 9: took 80.0s (avg 82.1s) | Best so far: epoch 8	train_loss: 0.1380 train_auc: 0.7490	val_loss: 0.0868 val_auc: 0.7012	test_loss: 0.1153 test_auc: 0.7564
2025-08-16 03:18:34,614 - INFO - train: {'epoch': 10, 'time_epoch': 71.16283, 'eta': 6465.74419, 'eta_hours': 1.79604, 'loss': 0.13292195, 'lr': 9.932e-05, 'params': 451793, 'time_iter': 0.06916, 'accuracy': 0.96252, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.77312}
2025-08-16 03:18:39,128 - INFO - val: {'epoch': 10, 'time_epoch': 4.48961, 'loss': 0.0852731, 'lr': 0, 'params': 451793, 'time_iter': 0.0348, 'accuracy': 0.98104, 'precision': 1.0, 'recall': 0.03704, 'f1': 0.07143, 'auc': 0.713}
2025-08-16 03:18:43,627 - INFO - test: {'epoch': 10, 'time_epoch': 4.47922, 'loss': 0.11931739, 'lr': 0, 'params': 451793, 'time_iter': 0.03472, 'accuracy': 0.96864, 'precision': 0.66667, 'recall': 0.01538, 'f1': 0.03008, 'auc': 0.75231}
2025-08-16 03:18:43,630 - INFO - > Epoch 10: took 80.2s (avg 81.9s) | Best so far: epoch 10	train_loss: 0.1329 train_auc: 0.7731	val_loss: 0.0853 val_auc: 0.7130	test_loss: 0.1193 test_auc: 0.7523
2025-08-16 03:19:55,371 - INFO - train: {'epoch': 11, 'time_epoch': 71.6716, 'eta': 6385.92916, 'eta_hours': 1.77387, 'loss': 0.13295993, 'lr': 9.902e-05, 'params': 451793, 'time_iter': 0.06965, 'accuracy': 0.96255, 'precision': 0.5, 'recall': 0.00081, 'f1': 0.00162, 'auc': 0.77427}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:19:59,838 - INFO - val: {'epoch': 11, 'time_epoch': 4.44408, 'loss': 0.08975313, 'lr': 0, 'params': 451793, 'time_iter': 0.03445, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67693}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:20:04,299 - INFO - test: {'epoch': 11, 'time_epoch': 4.44312, 'loss': 0.12263582, 'lr': 0, 'params': 451793, 'time_iter': 0.03444, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74253}
2025-08-16 03:20:04,301 - INFO - > Epoch 11: took 80.7s (avg 81.8s) | Best so far: epoch 10	train_loss: 0.1329 train_auc: 0.7731	val_loss: 0.0853 val_auc: 0.7130	test_loss: 0.1193 test_auc: 0.7523
2025-08-16 03:21:15,351 - INFO - train: {'epoch': 12, 'time_epoch': 70.97856, 'eta': 6302.72891, 'eta_hours': 1.75076, 'loss': 0.1310577, 'lr': 9.867e-05, 'params': 451793, 'time_iter': 0.06898, 'accuracy': 0.96255, 'precision': 0.5, 'recall': 0.00406, 'f1': 0.00805, 'auc': 0.78801}
2025-08-16 03:21:19,823 - INFO - val: {'epoch': 12, 'time_epoch': 4.44957, 'loss': 0.083352, 'lr': 0, 'params': 451793, 'time_iter': 0.03449, 'accuracy': 0.98055, 'precision': 0.66667, 'recall': 0.02469, 'f1': 0.04762, 'auc': 0.71962}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 03:21:24,281 - INFO - test: {'epoch': 12, 'time_epoch': 4.44023, 'loss': 0.11815439, 'lr': 0, 'params': 451793, 'time_iter': 0.03442, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75836}
2025-08-16 03:21:24,284 - INFO - > Epoch 12: took 80.0s (avg 81.7s) | Best so far: epoch 12	train_loss: 0.1311 train_auc: 0.7880	val_loss: 0.0834 val_auc: 0.7196	test_loss: 0.1182 test_auc: 0.7584
2025-08-16 03:22:35,242 - INFO - train: {'epoch': 13, 'time_epoch': 70.88717, 'eta': 6220.71326, 'eta_hours': 1.72798, 'loss': 0.12994158, 'lr': 9.826e-05, 'params': 451793, 'time_iter': 0.06889, 'accuracy': 0.96286, 'precision': 0.64706, 'recall': 0.01786, 'f1': 0.03476, 'auc': 0.78767}
2025-08-16 03:22:39,703 - INFO - val: {'epoch': 13, 'time_epoch': 4.43756, 'loss': 0.08711192, 'lr': 0, 'params': 451793, 'time_iter': 0.0344, 'accuracy': 0.98128, 'precision': 0.75, 'recall': 0.07407, 'f1': 0.13483, 'auc': 0.70939}
2025-08-16 03:22:44,172 - INFO - test: {'epoch': 13, 'time_epoch': 4.44817, 'loss': 0.12123351, 'lr': 0, 'params': 451793, 'time_iter': 0.03448, 'accuracy': 0.96864, 'precision': 0.55556, 'recall': 0.03846, 'f1': 0.07194, 'auc': 0.73911}
2025-08-16 03:22:44,175 - INFO - > Epoch 13: took 79.9s (avg 81.5s) | Best so far: epoch 12	train_loss: 0.1311 train_auc: 0.7880	val_loss: 0.0834 val_auc: 0.7196	test_loss: 0.1182 test_auc: 0.7584
2025-08-16 03:23:56,080 - INFO - train: {'epoch': 14, 'time_epoch': 71.83716, 'eta': 6145.56466, 'eta_hours': 1.7071, 'loss': 0.12910805, 'lr': 9.78e-05, 'params': 451793, 'time_iter': 0.06981, 'accuracy': 0.96292, 'precision': 0.60714, 'recall': 0.0276, 'f1': 0.0528, 'auc': 0.79582}
2025-08-16 03:24:00,543 - INFO - val: {'epoch': 14, 'time_epoch': 4.43925, 'loss': 0.08444091, 'lr': 0, 'params': 451793, 'time_iter': 0.03441, 'accuracy': 0.98128, 'precision': 0.66667, 'recall': 0.09877, 'f1': 0.17204, 'auc': 0.71973}
2025-08-16 03:24:05,005 - INFO - test: {'epoch': 14, 'time_epoch': 4.44279, 'loss': 0.11606609, 'lr': 0, 'params': 451793, 'time_iter': 0.03444, 'accuracy': 0.96961, 'precision': 0.6, 'recall': 0.11538, 'f1': 0.19355, 'auc': 0.77584}
2025-08-16 03:24:05,008 - INFO - > Epoch 14: took 80.8s (avg 81.5s) | Best so far: epoch 14	train_loss: 0.1291 train_auc: 0.7958	val_loss: 0.0844 val_auc: 0.7197	test_loss: 0.1161 test_auc: 0.7758
2025-08-16 03:25:17,672 - INFO - train: {'epoch': 15, 'time_epoch': 72.59127, 'eta': 6074.78909, 'eta_hours': 1.68744, 'loss': 0.12844579, 'lr': 9.729e-05, 'params': 451793, 'time_iter': 0.07055, 'accuracy': 0.96295, 'precision': 0.58228, 'recall': 0.03734, 'f1': 0.07018, 'auc': 0.79337}
2025-08-16 03:25:22,215 - INFO - val: {'epoch': 15, 'time_epoch': 4.51802, 'loss': 0.08188598, 'lr': 0, 'params': 451793, 'time_iter': 0.03502, 'accuracy': 0.98104, 'precision': 0.66667, 'recall': 0.07407, 'f1': 0.13333, 'auc': 0.74196}
2025-08-16 03:25:26,722 - INFO - test: {'epoch': 15, 'time_epoch': 4.48791, 'loss': 0.11507695, 'lr': 0, 'params': 451793, 'time_iter': 0.03479, 'accuracy': 0.97009, 'precision': 0.66667, 'recall': 0.10769, 'f1': 0.18543, 'auc': 0.76631}
2025-08-16 03:25:26,726 - INFO - > Epoch 15: took 81.7s (avg 81.5s) | Best so far: epoch 15	train_loss: 0.1284 train_auc: 0.7934	val_loss: 0.0819 val_auc: 0.7420	test_loss: 0.1151 test_auc: 0.7663
2025-08-16 03:26:38,135 - INFO - train: {'epoch': 16, 'time_epoch': 71.33677, 'eta': 5997.67499, 'eta_hours': 1.66602, 'loss': 0.12713174, 'lr': 9.673e-05, 'params': 451793, 'time_iter': 0.06933, 'accuracy': 0.96325, 'precision': 0.59829, 'recall': 0.05682, 'f1': 0.10378, 'auc': 0.79529}
2025-08-16 03:26:42,613 - INFO - val: {'epoch': 16, 'time_epoch': 4.45362, 'loss': 0.08420952, 'lr': 0, 'params': 451793, 'time_iter': 0.03452, 'accuracy': 0.98249, 'precision': 0.76471, 'recall': 0.16049, 'f1': 0.26531, 'auc': 0.71091}
2025-08-16 03:26:47,078 - INFO - test: {'epoch': 16, 'time_epoch': 4.44481, 'loss': 0.12051067, 'lr': 0, 'params': 451793, 'time_iter': 0.03446, 'accuracy': 0.96791, 'precision': 0.42857, 'recall': 0.04615, 'f1': 0.08333, 'auc': 0.73958}
2025-08-16 03:26:47,081 - INFO - > Epoch 16: took 80.4s (avg 81.4s) | Best so far: epoch 15	train_loss: 0.1284 train_auc: 0.7934	val_loss: 0.0819 val_auc: 0.7420	test_loss: 0.1151 test_auc: 0.7663
2025-08-16 03:27:58,496 - INFO - train: {'epoch': 17, 'time_epoch': 71.34227, 'eta': 5921.22786, 'eta_hours': 1.64479, 'loss': 0.12543044, 'lr': 9.611e-05, 'params': 451793, 'time_iter': 0.06933, 'accuracy': 0.96404, 'precision': 0.64848, 'recall': 0.08685, 'f1': 0.15319, 'auc': 0.8025}
2025-08-16 03:28:02,985 - INFO - val: {'epoch': 17, 'time_epoch': 4.45107, 'loss': 0.08079785, 'lr': 0, 'params': 451793, 'time_iter': 0.0345, 'accuracy': 0.98298, 'precision': 0.7619, 'recall': 0.19753, 'f1': 0.31373, 'auc': 0.71289}
2025-08-16 03:28:07,457 - INFO - test: {'epoch': 17, 'time_epoch': 4.45158, 'loss': 0.11584865, 'lr': 0, 'params': 451793, 'time_iter': 0.03451, 'accuracy': 0.97107, 'precision': 0.65714, 'recall': 0.17692, 'f1': 0.27879, 'auc': 0.75377}
2025-08-16 03:28:07,460 - INFO - > Epoch 17: took 80.4s (avg 81.4s) | Best so far: epoch 15	train_loss: 0.1284 train_auc: 0.7934	val_loss: 0.0819 val_auc: 0.7420	test_loss: 0.1151 test_auc: 0.7663
2025-08-16 03:29:18,394 - INFO - train: {'epoch': 18, 'time_epoch': 70.86355, 'eta': 5843.27721, 'eta_hours': 1.62313, 'loss': 0.12508097, 'lr': 9.545e-05, 'params': 451793, 'time_iter': 0.06887, 'accuracy': 0.96413, 'precision': 0.604, 'recall': 0.12256, 'f1': 0.20378, 'auc': 0.80266}
2025-08-16 03:29:22,858 - INFO - val: {'epoch': 18, 'time_epoch': 4.44055, 'loss': 0.08138944, 'lr': 0, 'params': 451793, 'time_iter': 0.03442, 'accuracy': 0.98274, 'precision': 0.70833, 'recall': 0.20988, 'f1': 0.32381, 'auc': 0.74426}
2025-08-16 03:29:27,326 - INFO - test: {'epoch': 18, 'time_epoch': 4.44839, 'loss': 0.11955495, 'lr': 0, 'params': 451793, 'time_iter': 0.03448, 'accuracy': 0.96985, 'precision': 0.63636, 'recall': 0.10769, 'f1': 0.18421, 'auc': 0.7544}
2025-08-16 03:29:27,329 - INFO - > Epoch 18: took 79.9s (avg 81.3s) | Best so far: epoch 18	train_loss: 0.1251 train_auc: 0.8027	val_loss: 0.0814 val_auc: 0.7443	test_loss: 0.1196 test_auc: 0.7544
2025-08-16 03:30:38,180 - INFO - train: {'epoch': 19, 'time_epoch': 70.7819, 'eta': 5765.7087, 'eta_hours': 1.60159, 'loss': 0.12184853, 'lr': 9.474e-05, 'params': 451793, 'time_iter': 0.06879, 'accuracy': 0.96508, 'precision': 0.6436, 'recall': 0.15097, 'f1': 0.24458, 'auc': 0.81737}
2025-08-16 03:30:42,619 - INFO - val: {'epoch': 19, 'time_epoch': 4.41457, 'loss': 0.07695392, 'lr': 0, 'params': 451793, 'time_iter': 0.03422, 'accuracy': 0.98298, 'precision': 0.7619, 'recall': 0.19753, 'f1': 0.31373, 'auc': 0.75321}
2025-08-16 03:30:47,058 - INFO - test: {'epoch': 19, 'time_epoch': 4.42041, 'loss': 0.11585351, 'lr': 0, 'params': 451793, 'time_iter': 0.03427, 'accuracy': 0.97009, 'precision': 0.65217, 'recall': 0.11538, 'f1': 0.19608, 'auc': 0.75706}
2025-08-16 03:30:47,062 - INFO - > Epoch 19: took 79.7s (avg 81.2s) | Best so far: epoch 19	train_loss: 0.1218 train_auc: 0.8174	val_loss: 0.0770 val_auc: 0.7532	test_loss: 0.1159 test_auc: 0.7571
2025-08-16 03:31:58,465 - INFO - train: {'epoch': 20, 'time_epoch': 71.3331, 'eta': 5690.86008, 'eta_hours': 1.58079, 'loss': 0.12111058, 'lr': 9.397e-05, 'params': 451793, 'time_iter': 0.06932, 'accuracy': 0.96462, 'precision': 0.59392, 'recall': 0.17451, 'f1': 0.26976, 'auc': 0.82023}
2025-08-16 03:32:02,990 - INFO - val: {'epoch': 20, 'time_epoch': 4.50128, 'loss': 0.08129836, 'lr': 0, 'params': 451793, 'time_iter': 0.03489, 'accuracy': 0.98371, 'precision': 0.75, 'recall': 0.25926, 'f1': 0.38532, 'auc': 0.72834}
2025-08-16 03:32:07,491 - INFO - test: {'epoch': 20, 'time_epoch': 4.48153, 'loss': 0.12158471, 'lr': 0, 'params': 451793, 'time_iter': 0.03474, 'accuracy': 0.97155, 'precision': 0.67568, 'recall': 0.19231, 'f1': 0.2994, 'auc': 0.7149}
2025-08-16 03:32:07,494 - INFO - > Epoch 20: took 80.4s (avg 81.2s) | Best so far: epoch 19	train_loss: 0.1218 train_auc: 0.8174	val_loss: 0.0770 val_auc: 0.7532	test_loss: 0.1159 test_auc: 0.7571
2025-08-16 03:33:18,674 - INFO - train: {'epoch': 21, 'time_epoch': 71.10892, 'eta': 5615.53623, 'eta_hours': 1.55987, 'loss': 0.1218185, 'lr': 9.316e-05, 'params': 451793, 'time_iter': 0.0691, 'accuracy': 0.96499, 'precision': 0.62579, 'recall': 0.16153, 'f1': 0.25677, 'auc': 0.81205}
2025-08-16 03:33:23,197 - INFO - val: {'epoch': 21, 'time_epoch': 4.4976, 'loss': 0.07724597, 'lr': 0, 'params': 451793, 'time_iter': 0.03487, 'accuracy': 0.98371, 'precision': 0.9375, 'recall': 0.18519, 'f1': 0.30928, 'auc': 0.73556}
2025-08-16 03:33:27,699 - INFO - test: {'epoch': 21, 'time_epoch': 4.48383, 'loss': 0.12110412, 'lr': 0, 'params': 451793, 'time_iter': 0.03476, 'accuracy': 0.96791, 'precision': 0.25, 'recall': 0.00769, 'f1': 0.01493, 'auc': 0.75402}
2025-08-16 03:33:27,703 - INFO - > Epoch 21: took 80.2s (avg 81.1s) | Best so far: epoch 19	train_loss: 0.1218 train_auc: 0.8174	val_loss: 0.0770 val_auc: 0.7532	test_loss: 0.1159 test_auc: 0.7571
2025-08-16 03:34:39,486 - INFO - train: {'epoch': 22, 'time_epoch': 71.71106, 'eta': 5542.59478, 'eta_hours': 1.53961, 'loss': 0.11959451, 'lr': 9.23e-05, 'params': 451793, 'time_iter': 0.06969, 'accuracy': 0.96459, 'precision': 0.6006, 'recall': 0.16234, 'f1': 0.25559, 'auc': 0.8253}
2025-08-16 03:34:44,007 - INFO - val: {'epoch': 22, 'time_epoch': 4.49571, 'loss': 0.07915884, 'lr': 0, 'params': 451793, 'time_iter': 0.03485, 'accuracy': 0.98298, 'precision': 0.72, 'recall': 0.22222, 'f1': 0.33962, 'auc': 0.73743}
2025-08-16 03:34:48,511 - INFO - test: {'epoch': 22, 'time_epoch': 4.48401, 'loss': 0.1202854, 'lr': 0, 'params': 451793, 'time_iter': 0.03476, 'accuracy': 0.97009, 'precision': 0.73333, 'recall': 0.08462, 'f1': 0.15172, 'auc': 0.74941}
2025-08-16 03:34:48,515 - INFO - > Epoch 22: took 80.8s (avg 81.1s) | Best so far: epoch 19	train_loss: 0.1218 train_auc: 0.8174	val_loss: 0.0770 val_auc: 0.7532	test_loss: 0.1159 test_auc: 0.7571
2025-08-16 03:36:00,077 - INFO - train: {'epoch': 23, 'time_epoch': 71.48932, 'eta': 5469.05367, 'eta_hours': 1.51918, 'loss': 0.11991709, 'lr': 9.14e-05, 'params': 451793, 'time_iter': 0.06947, 'accuracy': 0.96517, 'precision': 0.6075, 'recall': 0.19724, 'f1': 0.29779, 'auc': 0.82492}
2025-08-16 03:36:04,558 - INFO - val: {'epoch': 23, 'time_epoch': 4.45698, 'loss': 0.08202794, 'lr': 0, 'params': 451793, 'time_iter': 0.03455, 'accuracy': 0.98201, 'precision': 0.58974, 'recall': 0.28395, 'f1': 0.38333, 'auc': 0.72878}
2025-08-16 03:36:08,967 - INFO - test: {'epoch': 23, 'time_epoch': 4.38997, 'loss': 0.12058834, 'lr': 0, 'params': 451793, 'time_iter': 0.03403, 'accuracy': 0.96864, 'precision': 0.51111, 'recall': 0.17692, 'f1': 0.26286, 'auc': 0.74601}
2025-08-16 03:36:08,970 - INFO - > Epoch 23: took 80.5s (avg 81.1s) | Best so far: epoch 19	train_loss: 0.1218 train_auc: 0.8174	val_loss: 0.0770 val_auc: 0.7532	test_loss: 0.1159 test_auc: 0.7571
2025-08-16 03:37:20,622 - INFO - train: {'epoch': 24, 'time_epoch': 71.57909, 'eta': 5395.94601, 'eta_hours': 1.49887, 'loss': 0.11954055, 'lr': 9.045e-05, 'params': 451793, 'time_iter': 0.06956, 'accuracy': 0.96535, 'precision': 0.61111, 'recall': 0.20536, 'f1': 0.30741, 'auc': 0.81652}
2025-08-16 03:37:25,090 - INFO - val: {'epoch': 24, 'time_epoch': 4.44385, 'loss': 0.08017966, 'lr': 0, 'params': 451793, 'time_iter': 0.03445, 'accuracy': 0.98249, 'precision': 0.62857, 'recall': 0.2716, 'f1': 0.37931, 'auc': 0.71736}
2025-08-16 03:37:29,550 - INFO - test: {'epoch': 24, 'time_epoch': 4.44125, 'loss': 0.1221209, 'lr': 0, 'params': 451793, 'time_iter': 0.03443, 'accuracy': 0.96961, 'precision': 0.57576, 'recall': 0.14615, 'f1': 0.23313, 'auc': 0.7357}
2025-08-16 03:37:29,553 - INFO - > Epoch 24: took 80.6s (avg 81.1s) | Best so far: epoch 19	train_loss: 0.1218 train_auc: 0.8174	val_loss: 0.0770 val_auc: 0.7532	test_loss: 0.1159 test_auc: 0.7571
2025-08-16 03:38:40,674 - INFO - train: {'epoch': 25, 'time_epoch': 71.04972, 'eta': 5321.44926, 'eta_hours': 1.47818, 'loss': 0.11831575, 'lr': 8.946e-05, 'params': 451793, 'time_iter': 0.06905, 'accuracy': 0.96651, 'precision': 0.66332, 'recall': 0.21429, 'f1': 0.32393, 'auc': 0.82039}
2025-08-16 03:38:45,147 - INFO - val: {'epoch': 25, 'time_epoch': 4.44956, 'loss': 0.07674367, 'lr': 0, 'params': 451793, 'time_iter': 0.03449, 'accuracy': 0.98347, 'precision': 0.74074, 'recall': 0.24691, 'f1': 0.37037, 'auc': 0.74866}
2025-08-16 03:38:49,598 - INFO - test: {'epoch': 25, 'time_epoch': 4.43127, 'loss': 0.1162027, 'lr': 0, 'params': 451793, 'time_iter': 0.03435, 'accuracy': 0.97082, 'precision': 0.72727, 'recall': 0.12308, 'f1': 0.21053, 'auc': 0.7324}
2025-08-16 03:38:49,601 - INFO - > Epoch 25: took 80.0s (avg 81.0s) | Best so far: epoch 19	train_loss: 0.1218 train_auc: 0.8174	val_loss: 0.0770 val_auc: 0.7532	test_loss: 0.1159 test_auc: 0.7571
2025-08-16 03:40:02,148 - INFO - train: {'epoch': 26, 'time_epoch': 72.47325, 'eta': 5251.05666, 'eta_hours': 1.45863, 'loss': 0.11754734, 'lr': 8.842e-05, 'params': 451793, 'time_iter': 0.07043, 'accuracy': 0.96544, 'precision': 0.61787, 'recall': 0.20211, 'f1': 0.30459, 'auc': 0.83431}
2025-08-16 03:40:06,560 - INFO - val: {'epoch': 26, 'time_epoch': 4.38869, 'loss': 0.07635063, 'lr': 0, 'params': 451793, 'time_iter': 0.03402, 'accuracy': 0.98371, 'precision': 0.71875, 'recall': 0.28395, 'f1': 0.40708, 'auc': 0.78344}
2025-08-16 03:40:11,035 - INFO - test: {'epoch': 26, 'time_epoch': 4.4559, 'loss': 0.11797717, 'lr': 0, 'params': 451793, 'time_iter': 0.03454, 'accuracy': 0.97131, 'precision': 0.6875, 'recall': 0.16923, 'f1': 0.2716, 'auc': 0.73855}
2025-08-16 03:40:11,038 - INFO - > Epoch 26: took 81.4s (avg 81.0s) | Best so far: epoch 26	train_loss: 0.1175 train_auc: 0.8343	val_loss: 0.0764 val_auc: 0.7834	test_loss: 0.1180 test_auc: 0.7386
2025-08-16 03:41:22,526 - INFO - train: {'epoch': 27, 'time_epoch': 71.41844, 'eta': 5177.80306, 'eta_hours': 1.43828, 'loss': 0.11698873, 'lr': 8.734e-05, 'params': 451793, 'time_iter': 0.06941, 'accuracy': 0.96654, 'precision': 0.64989, 'recall': 0.23052, 'f1': 0.34032, 'auc': 0.82733}
2025-08-16 03:41:26,959 - INFO - val: {'epoch': 27, 'time_epoch': 4.40933, 'loss': 0.07674051, 'lr': 0, 'params': 451793, 'time_iter': 0.03418, 'accuracy': 0.98347, 'precision': 0.69697, 'recall': 0.28395, 'f1': 0.40351, 'auc': 0.78054}
2025-08-16 03:41:31,400 - INFO - test: {'epoch': 27, 'time_epoch': 4.42148, 'loss': 0.11744207, 'lr': 0, 'params': 451793, 'time_iter': 0.03428, 'accuracy': 0.97204, 'precision': 0.66667, 'recall': 0.23077, 'f1': 0.34286, 'auc': 0.74901}
2025-08-16 03:41:31,403 - INFO - > Epoch 27: took 80.4s (avg 81.0s) | Best so far: epoch 26	train_loss: 0.1175 train_auc: 0.8343	val_loss: 0.0764 val_auc: 0.7834	test_loss: 0.1180 test_auc: 0.7386
2025-08-16 03:42:42,409 - INFO - train: {'epoch': 28, 'time_epoch': 70.93591, 'eta': 5103.49466, 'eta_hours': 1.41764, 'loss': 0.11467371, 'lr': 8.622e-05, 'params': 451793, 'time_iter': 0.06894, 'accuracy': 0.96705, 'precision': 0.66444, 'recall': 0.24269, 'f1': 0.35553, 'auc': 0.83572}
2025-08-16 03:42:46,895 - INFO - val: {'epoch': 28, 'time_epoch': 4.46178, 'loss': 0.07885082, 'lr': 0, 'params': 451793, 'time_iter': 0.03459, 'accuracy': 0.98225, 'precision': 0.59524, 'recall': 0.30864, 'f1': 0.4065, 'auc': 0.77037}
2025-08-16 03:42:51,359 - INFO - test: {'epoch': 28, 'time_epoch': 4.445, 'loss': 0.11757777, 'lr': 0, 'params': 451793, 'time_iter': 0.03446, 'accuracy': 0.97107, 'precision': 0.6, 'recall': 0.25385, 'f1': 0.35676, 'auc': 0.75879}
2025-08-16 03:42:51,361 - INFO - > Epoch 28: took 80.0s (avg 81.0s) | Best so far: epoch 26	train_loss: 0.1175 train_auc: 0.8343	val_loss: 0.0764 val_auc: 0.7834	test_loss: 0.1180 test_auc: 0.7386
2025-08-16 03:44:01,945 - INFO - train: {'epoch': 29, 'time_epoch': 70.51281, 'eta': 5028.42385, 'eta_hours': 1.39678, 'loss': 0.11547081, 'lr': 8.506e-05, 'params': 451793, 'time_iter': 0.06853, 'accuracy': 0.96629, 'precision': 0.63697, 'recall': 0.23214, 'f1': 0.34027, 'auc': 0.83577}
2025-08-16 03:44:06,378 - INFO - val: {'epoch': 29, 'time_epoch': 4.40845, 'loss': 0.07665563, 'lr': 0, 'params': 451793, 'time_iter': 0.03417, 'accuracy': 0.98347, 'precision': 0.68571, 'recall': 0.2963, 'f1': 0.41379, 'auc': 0.75635}
2025-08-16 03:44:10,773 - INFO - test: {'epoch': 29, 'time_epoch': 4.37683, 'loss': 0.11979828, 'lr': 0, 'params': 451793, 'time_iter': 0.03393, 'accuracy': 0.97009, 'precision': 0.5814, 'recall': 0.19231, 'f1': 0.28902, 'auc': 0.74851}
2025-08-16 03:44:10,776 - INFO - > Epoch 29: took 79.4s (avg 80.9s) | Best so far: epoch 26	train_loss: 0.1175 train_auc: 0.8343	val_loss: 0.0764 val_auc: 0.7834	test_loss: 0.1180 test_auc: 0.7386
2025-08-16 03:45:21,553 - INFO - train: {'epoch': 30, 'time_epoch': 70.70622, 'eta': 4954.07761, 'eta_hours': 1.37613, 'loss': 0.11458663, 'lr': 8.386e-05, 'params': 451793, 'time_iter': 0.06871, 'accuracy': 0.96705, 'precision': 0.6588, 'recall': 0.24919, 'f1': 0.3616, 'auc': 0.83393}
2025-08-16 03:45:25,984 - INFO - val: {'epoch': 30, 'time_epoch': 4.40615, 'loss': 0.07404996, 'lr': 0, 'params': 451793, 'time_iter': 0.03416, 'accuracy': 0.98347, 'precision': 0.68571, 'recall': 0.2963, 'f1': 0.41379, 'auc': 0.79337}
2025-08-16 03:45:30,417 - INFO - test: {'epoch': 30, 'time_epoch': 4.41404, 'loss': 0.11704047, 'lr': 0, 'params': 451793, 'time_iter': 0.03422, 'accuracy': 0.97107, 'precision': 0.61224, 'recall': 0.23077, 'f1': 0.3352, 'auc': 0.75198}
2025-08-16 03:45:30,420 - INFO - > Epoch 30: took 79.6s (avg 80.9s) | Best so far: epoch 30	train_loss: 0.1146 train_auc: 0.8339	val_loss: 0.0740 val_auc: 0.7934	test_loss: 0.1170 test_auc: 0.7520
2025-08-16 03:46:40,796 - INFO - train: {'epoch': 31, 'time_epoch': 70.30818, 'eta': 4879.11303, 'eta_hours': 1.35531, 'loss': 0.11423067, 'lr': 8.263e-05, 'params': 451793, 'time_iter': 0.06833, 'accuracy': 0.96696, 'precision': 0.65136, 'recall': 0.25325, 'f1': 0.3647, 'auc': 0.83935}
2025-08-16 03:46:45,140 - INFO - val: {'epoch': 31, 'time_epoch': 4.3199, 'loss': 0.07387536, 'lr': 0, 'params': 451793, 'time_iter': 0.03349, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.80826}
2025-08-16 03:46:49,475 - INFO - test: {'epoch': 31, 'time_epoch': 4.31647, 'loss': 0.1163671, 'lr': 0, 'params': 451793, 'time_iter': 0.03346, 'accuracy': 0.97082, 'precision': 0.59615, 'recall': 0.23846, 'f1': 0.34066, 'auc': 0.7629}
2025-08-16 03:46:49,477 - INFO - > Epoch 31: took 79.1s (avg 80.8s) | Best so far: epoch 31	train_loss: 0.1142 train_auc: 0.8394	val_loss: 0.0739 val_auc: 0.8083	test_loss: 0.1164 test_auc: 0.7629
2025-08-16 03:47:58,708 - INFO - train: {'epoch': 32, 'time_epoch': 69.16148, 'eta': 4802.10251, 'eta_hours': 1.33392, 'loss': 0.11329625, 'lr': 8.136e-05, 'params': 451793, 'time_iter': 0.06721, 'accuracy': 0.96733, 'precision': 0.66119, 'recall': 0.26136, 'f1': 0.37464, 'auc': 0.84063}
2025-08-16 03:48:03,090 - INFO - val: {'epoch': 32, 'time_epoch': 4.3599, 'loss': 0.07437073, 'lr': 0, 'params': 451793, 'time_iter': 0.0338, 'accuracy': 0.98322, 'precision': 0.65789, 'recall': 0.30864, 'f1': 0.42017, 'auc': 0.79239}
2025-08-16 03:48:07,451 - INFO - test: {'epoch': 32, 'time_epoch': 4.34175, 'loss': 0.1181373, 'lr': 0, 'params': 451793, 'time_iter': 0.03366, 'accuracy': 0.97155, 'precision': 0.66667, 'recall': 0.2, 'f1': 0.30769, 'auc': 0.74532}
2025-08-16 03:48:07,453 - INFO - > Epoch 32: took 78.0s (avg 80.7s) | Best so far: epoch 31	train_loss: 0.1142 train_auc: 0.8394	val_loss: 0.0739 val_auc: 0.8083	test_loss: 0.1164 test_auc: 0.7629
2025-08-16 03:49:16,729 - INFO - train: {'epoch': 33, 'time_epoch': 69.20776, 'eta': 4725.64354, 'eta_hours': 1.31268, 'loss': 0.11349107, 'lr': 8.005e-05, 'params': 451793, 'time_iter': 0.06726, 'accuracy': 0.96684, 'precision': 0.63128, 'recall': 0.27516, 'f1': 0.38327, 'auc': 0.84015}
2025-08-16 03:49:21,093 - INFO - val: {'epoch': 33, 'time_epoch': 4.34092, 'loss': 0.07691722, 'lr': 0, 'params': 451793, 'time_iter': 0.03365, 'accuracy': 0.98249, 'precision': 0.62162, 'recall': 0.28395, 'f1': 0.38983, 'auc': 0.77014}
2025-08-16 03:49:25,490 - INFO - test: {'epoch': 33, 'time_epoch': 4.37749, 'loss': 0.11795308, 'lr': 0, 'params': 451793, 'time_iter': 0.03393, 'accuracy': 0.96937, 'precision': 0.53846, 'recall': 0.21538, 'f1': 0.30769, 'auc': 0.74878}
2025-08-16 03:49:25,493 - INFO - > Epoch 33: took 78.0s (avg 80.7s) | Best so far: epoch 31	train_loss: 0.1142 train_auc: 0.8394	val_loss: 0.0739 val_auc: 0.8083	test_loss: 0.1164 test_auc: 0.7629
2025-08-16 03:50:33,943 - INFO - train: {'epoch': 34, 'time_epoch': 68.34271, 'eta': 4647.99241, 'eta_hours': 1.29111, 'loss': 0.11320744, 'lr': 7.872e-05, 'params': 451793, 'time_iter': 0.06642, 'accuracy': 0.96702, 'precision': 0.64554, 'recall': 0.26461, 'f1': 0.37536, 'auc': 0.84338}
2025-08-16 03:50:38,315 - INFO - val: {'epoch': 34, 'time_epoch': 4.34852, 'loss': 0.07589157, 'lr': 0, 'params': 451793, 'time_iter': 0.03371, 'accuracy': 0.98274, 'precision': 0.63158, 'recall': 0.2963, 'f1': 0.40336, 'auc': 0.78007}
2025-08-16 03:50:42,678 - INFO - test: {'epoch': 34, 'time_epoch': 4.34364, 'loss': 0.11658996, 'lr': 0, 'params': 451793, 'time_iter': 0.03367, 'accuracy': 0.96888, 'precision': 0.52, 'recall': 0.2, 'f1': 0.28889, 'auc': 0.77134}
2025-08-16 03:50:42,680 - INFO - > Epoch 34: took 77.2s (avg 80.6s) | Best so far: epoch 31	train_loss: 0.1142 train_auc: 0.8394	val_loss: 0.0739 val_auc: 0.8083	test_loss: 0.1164 test_auc: 0.7629
2025-08-16 03:51:50,058 - INFO - train: {'epoch': 35, 'time_epoch': 67.31271, 'eta': 4569.0273, 'eta_hours': 1.26917, 'loss': 0.11175492, 'lr': 7.735e-05, 'params': 451793, 'time_iter': 0.06542, 'accuracy': 0.96781, 'precision': 0.67835, 'recall': 0.26705, 'f1': 0.38323, 'auc': 0.84648}
2025-08-16 03:51:54,294 - INFO - val: {'epoch': 35, 'time_epoch': 4.21274, 'loss': 0.07254901, 'lr': 0, 'params': 451793, 'time_iter': 0.03266, 'accuracy': 0.98322, 'precision': 0.67647, 'recall': 0.28395, 'f1': 0.4, 'auc': 0.82309}
2025-08-16 03:51:58,529 - INFO - test: {'epoch': 35, 'time_epoch': 4.21698, 'loss': 0.11854188, 'lr': 0, 'params': 451793, 'time_iter': 0.03269, 'accuracy': 0.97107, 'precision': 0.63415, 'recall': 0.2, 'f1': 0.30409, 'auc': 0.75106}
2025-08-16 03:51:58,532 - INFO - > Epoch 35: took 75.9s (avg 80.4s) | Best so far: epoch 35	train_loss: 0.1118 train_auc: 0.8465	val_loss: 0.0725 val_auc: 0.8231	test_loss: 0.1185 test_auc: 0.7511
2025-08-16 03:53:06,594 - INFO - train: {'epoch': 36, 'time_epoch': 67.99348, 'eta': 4491.8512, 'eta_hours': 1.24774, 'loss': 0.11207376, 'lr': 7.595e-05, 'params': 451793, 'time_iter': 0.06608, 'accuracy': 0.96687, 'precision': 0.63922, 'recall': 0.26461, 'f1': 0.37428, 'auc': 0.84572}
2025-08-16 03:53:10,961 - INFO - val: {'epoch': 36, 'time_epoch': 4.34442, 'loss': 0.07572467, 'lr': 0, 'params': 451793, 'time_iter': 0.03368, 'accuracy': 0.98225, 'precision': 0.59091, 'recall': 0.32099, 'f1': 0.416, 'auc': 0.77283}
2025-08-16 03:53:15,337 - INFO - test: {'epoch': 36, 'time_epoch': 4.3568, 'loss': 0.11396175, 'lr': 0, 'params': 451793, 'time_iter': 0.03377, 'accuracy': 0.97058, 'precision': 0.55844, 'recall': 0.33077, 'f1': 0.41546, 'auc': 0.75748}
2025-08-16 03:53:15,340 - INFO - > Epoch 36: took 76.8s (avg 80.3s) | Best so far: epoch 35	train_loss: 0.1118 train_auc: 0.8465	val_loss: 0.0725 val_auc: 0.8231	test_loss: 0.1185 test_auc: 0.7511
2025-08-16 03:54:23,860 - INFO - train: {'epoch': 37, 'time_epoch': 68.45039, 'eta': 4415.90387, 'eta_hours': 1.22664, 'loss': 0.11106578, 'lr': 7.452e-05, 'params': 451793, 'time_iter': 0.06652, 'accuracy': 0.96827, 'precision': 0.67537, 'recall': 0.29383, 'f1': 0.4095, 'auc': 0.84577}
2025-08-16 03:54:28,251 - INFO - val: {'epoch': 37, 'time_epoch': 4.36855, 'loss': 0.07678245, 'lr': 0, 'params': 451793, 'time_iter': 0.03386, 'accuracy': 0.98249, 'precision': 0.62162, 'recall': 0.28395, 'f1': 0.38983, 'auc': 0.7634}
2025-08-16 03:54:32,644 - INFO - test: {'epoch': 37, 'time_epoch': 4.37355, 'loss': 0.11738869, 'lr': 0, 'params': 451793, 'time_iter': 0.0339, 'accuracy': 0.97058, 'precision': 0.59574, 'recall': 0.21538, 'f1': 0.31638, 'auc': 0.76415}
2025-08-16 03:54:32,647 - INFO - > Epoch 37: took 77.3s (avg 80.3s) | Best so far: epoch 35	train_loss: 0.1118 train_auc: 0.8465	val_loss: 0.0725 val_auc: 0.8231	test_loss: 0.1185 test_auc: 0.7511
2025-08-16 03:55:40,811 - INFO - train: {'epoch': 38, 'time_epoch': 68.09566, 'eta': 4339.78617, 'eta_hours': 1.2055, 'loss': 0.1102364, 'lr': 7.307e-05, 'params': 451793, 'time_iter': 0.06618, 'accuracy': 0.96796, 'precision': 0.678, 'recall': 0.27516, 'f1': 0.39145, 'auc': 0.85044}
2025-08-16 03:55:45,132 - INFO - val: {'epoch': 38, 'time_epoch': 4.29814, 'loss': 0.07457762, 'lr': 0, 'params': 451793, 'time_iter': 0.03332, 'accuracy': 0.98322, 'precision': 0.65789, 'recall': 0.30864, 'f1': 0.42017, 'auc': 0.78306}
2025-08-16 03:55:49,451 - INFO - test: {'epoch': 38, 'time_epoch': 4.30028, 'loss': 0.11959089, 'lr': 0, 'params': 451793, 'time_iter': 0.03334, 'accuracy': 0.96937, 'precision': 0.53846, 'recall': 0.21538, 'f1': 0.30769, 'auc': 0.76038}
2025-08-16 03:55:49,453 - INFO - > Epoch 38: took 76.8s (avg 80.2s) | Best so far: epoch 35	train_loss: 0.1118 train_auc: 0.8465	val_loss: 0.0725 val_auc: 0.8231	test_loss: 0.1185 test_auc: 0.7511
2025-08-16 03:56:57,636 - INFO - train: {'epoch': 39, 'time_epoch': 68.11492, 'eta': 4264.09845, 'eta_hours': 1.18447, 'loss': 0.11121886, 'lr': 7.159e-05, 'params': 451793, 'time_iter': 0.0662, 'accuracy': 0.96824, 'precision': 0.67477, 'recall': 0.29302, 'f1': 0.4086, 'auc': 0.84568}
2025-08-16 03:57:01,971 - INFO - val: {'epoch': 39, 'time_epoch': 4.31347, 'loss': 0.07616151, 'lr': 0, 'params': 451793, 'time_iter': 0.03344, 'accuracy': 0.98249, 'precision': 0.60465, 'recall': 0.32099, 'f1': 0.41935, 'auc': 0.77841}
2025-08-16 03:57:06,279 - INFO - test: {'epoch': 39, 'time_epoch': 4.28983, 'loss': 0.11628054, 'lr': 0, 'params': 451793, 'time_iter': 0.03325, 'accuracy': 0.97009, 'precision': 0.55385, 'recall': 0.27692, 'f1': 0.36923, 'auc': 0.76649}
2025-08-16 03:57:06,282 - INFO - > Epoch 39: took 76.8s (avg 80.1s) | Best so far: epoch 35	train_loss: 0.1118 train_auc: 0.8465	val_loss: 0.0725 val_auc: 0.8231	test_loss: 0.1185 test_auc: 0.7511
2025-08-16 03:58:14,152 - INFO - train: {'epoch': 40, 'time_epoch': 67.80359, 'eta': 4188.33213, 'eta_hours': 1.16343, 'loss': 0.10909743, 'lr': 7.008e-05, 'params': 451793, 'time_iter': 0.06589, 'accuracy': 0.96854, 'precision': 0.67558, 'recall': 0.30763, 'f1': 0.42276, 'auc': 0.85918}
2025-08-16 03:58:18,482 - INFO - val: {'epoch': 40, 'time_epoch': 4.30797, 'loss': 0.07636876, 'lr': 0, 'params': 451793, 'time_iter': 0.0334, 'accuracy': 0.98274, 'precision': 0.625, 'recall': 0.30864, 'f1': 0.41322, 'auc': 0.77291}
2025-08-16 03:58:22,798 - INFO - test: {'epoch': 40, 'time_epoch': 4.29749, 'loss': 0.11788697, 'lr': 0, 'params': 451793, 'time_iter': 0.03331, 'accuracy': 0.97009, 'precision': 0.5614, 'recall': 0.24615, 'f1': 0.34225, 'auc': 0.75191}
2025-08-16 03:58:22,801 - INFO - > Epoch 40: took 76.5s (avg 80.0s) | Best so far: epoch 35	train_loss: 0.1118 train_auc: 0.8465	val_loss: 0.0725 val_auc: 0.8231	test_loss: 0.1185 test_auc: 0.7511
2025-08-16 03:59:30,967 - INFO - train: {'epoch': 41, 'time_epoch': 68.09806, 'eta': 4113.35164, 'eta_hours': 1.1426, 'loss': 0.10851438, 'lr': 6.856e-05, 'params': 451793, 'time_iter': 0.06618, 'accuracy': 0.96824, 'precision': 0.67283, 'recall': 0.29545, 'f1': 0.4106, 'auc': 0.86409}
2025-08-16 03:59:35,296 - INFO - val: {'epoch': 41, 'time_epoch': 4.30683, 'loss': 0.07268478, 'lr': 0, 'params': 451793, 'time_iter': 0.03339, 'accuracy': 0.98225, 'precision': 0.6, 'recall': 0.2963, 'f1': 0.39669, 'auc': 0.81652}
2025-08-16 03:59:39,611 - INFO - test: {'epoch': 41, 'time_epoch': 4.29517, 'loss': 0.11719328, 'lr': 0, 'params': 451793, 'time_iter': 0.0333, 'accuracy': 0.97082, 'precision': 0.57576, 'recall': 0.29231, 'f1': 0.38776, 'auc': 0.75832}
2025-08-16 03:59:39,613 - INFO - > Epoch 41: took 76.8s (avg 79.9s) | Best so far: epoch 35	train_loss: 0.1118 train_auc: 0.8465	val_loss: 0.0725 val_auc: 0.8231	test_loss: 0.1185 test_auc: 0.7511
2025-08-16 04:00:48,008 - INFO - train: {'epoch': 42, 'time_epoch': 68.32807, 'eta': 4038.99617, 'eta_hours': 1.12194, 'loss': 0.10880338, 'lr': 6.701e-05, 'params': 451793, 'time_iter': 0.0664, 'accuracy': 0.96894, 'precision': 0.70115, 'recall': 0.29708, 'f1': 0.41733, 'auc': 0.85855}
2025-08-16 04:00:52,345 - INFO - val: {'epoch': 42, 'time_epoch': 4.31364, 'loss': 0.07255654, 'lr': 0, 'params': 451793, 'time_iter': 0.03344, 'accuracy': 0.98371, 'precision': 0.70588, 'recall': 0.2963, 'f1': 0.41739, 'auc': 0.79624}
2025-08-16 04:00:56,669 - INFO - test: {'epoch': 42, 'time_epoch': 4.3059, 'loss': 0.11622591, 'lr': 0, 'params': 451793, 'time_iter': 0.03338, 'accuracy': 0.97058, 'precision': 0.57895, 'recall': 0.25385, 'f1': 0.35294, 'auc': 0.75783}
2025-08-16 04:00:56,671 - INFO - > Epoch 42: took 77.1s (avg 79.9s) | Best so far: epoch 35	train_loss: 0.1118 train_auc: 0.8465	val_loss: 0.0725 val_auc: 0.8231	test_loss: 0.1185 test_auc: 0.7511
2025-08-16 04:02:04,781 - INFO - train: {'epoch': 43, 'time_epoch': 68.04164, 'eta': 3964.55011, 'eta_hours': 1.10126, 'loss': 0.10912277, 'lr': 6.545e-05, 'params': 451793, 'time_iter': 0.06612, 'accuracy': 0.96842, 'precision': 0.68242, 'recall': 0.29302, 'f1': 0.40999, 'auc': 0.85504}
2025-08-16 04:02:09,111 - INFO - val: {'epoch': 43, 'time_epoch': 4.30678, 'loss': 0.07309728, 'lr': 0, 'params': 451793, 'time_iter': 0.03339, 'accuracy': 0.98298, 'precision': 0.66667, 'recall': 0.2716, 'f1': 0.38596, 'auc': 0.78764}
2025-08-16 04:02:13,443 - INFO - test: {'epoch': 43, 'time_epoch': 4.31474, 'loss': 0.11708893, 'lr': 0, 'params': 451793, 'time_iter': 0.03345, 'accuracy': 0.9718, 'precision': 0.64583, 'recall': 0.23846, 'f1': 0.34831, 'auc': 0.74879}
2025-08-16 04:02:13,446 - INFO - > Epoch 43: took 76.8s (avg 79.8s) | Best so far: epoch 35	train_loss: 0.1118 train_auc: 0.8465	val_loss: 0.0725 val_auc: 0.8231	test_loss: 0.1185 test_auc: 0.7511
2025-08-16 04:03:21,520 - INFO - train: {'epoch': 44, 'time_epoch': 68.00605, 'eta': 3890.3452, 'eta_hours': 1.08065, 'loss': 0.10657383, 'lr': 6.387e-05, 'params': 451793, 'time_iter': 0.06609, 'accuracy': 0.96924, 'precision': 0.68644, 'recall': 0.32873, 'f1': 0.44457, 'auc': 0.86677}
2025-08-16 04:03:25,849 - INFO - val: {'epoch': 44, 'time_epoch': 4.30708, 'loss': 0.07408803, 'lr': 0, 'params': 451793, 'time_iter': 0.03339, 'accuracy': 0.98225, 'precision': 0.6, 'recall': 0.2963, 'f1': 0.39669, 'auc': 0.79979}
2025-08-16 04:03:30,204 - INFO - test: {'epoch': 44, 'time_epoch': 4.33678, 'loss': 0.12014604, 'lr': 0, 'params': 451793, 'time_iter': 0.03362, 'accuracy': 0.97034, 'precision': 0.57407, 'recall': 0.23846, 'f1': 0.33696, 'auc': 0.75315}
2025-08-16 04:03:30,206 - INFO - > Epoch 44: took 76.8s (avg 79.7s) | Best so far: epoch 35	train_loss: 0.1118 train_auc: 0.8465	val_loss: 0.0725 val_auc: 0.8231	test_loss: 0.1185 test_auc: 0.7511
2025-08-16 04:04:38,530 - INFO - train: {'epoch': 45, 'time_epoch': 68.25672, 'eta': 3816.70407, 'eta_hours': 1.0602, 'loss': 0.10680522, 'lr': 6.227e-05, 'params': 451793, 'time_iter': 0.06633, 'accuracy': 0.96821, 'precision': 0.6587, 'recall': 0.31331, 'f1': 0.42464, 'auc': 0.86392}
2025-08-16 04:04:42,899 - INFO - val: {'epoch': 45, 'time_epoch': 4.34611, 'loss': 0.0734275, 'lr': 0, 'params': 451793, 'time_iter': 0.03369, 'accuracy': 0.98371, 'precision': 0.70588, 'recall': 0.2963, 'f1': 0.41739, 'auc': 0.78799}
2025-08-16 04:04:47,260 - INFO - test: {'epoch': 45, 'time_epoch': 4.34199, 'loss': 0.11560617, 'lr': 0, 'params': 451793, 'time_iter': 0.03366, 'accuracy': 0.97009, 'precision': 0.56863, 'recall': 0.22308, 'f1': 0.32044, 'auc': 0.76759}
2025-08-16 04:04:47,262 - INFO - > Epoch 45: took 77.1s (avg 79.7s) | Best so far: epoch 35	train_loss: 0.1118 train_auc: 0.8465	val_loss: 0.0725 val_auc: 0.8231	test_loss: 0.1185 test_auc: 0.7511
2025-08-16 04:05:55,019 - INFO - train: {'epoch': 46, 'time_epoch': 67.69063, 'eta': 3742.6537, 'eta_hours': 1.03963, 'loss': 0.10738367, 'lr': 6.066e-05, 'params': 451793, 'time_iter': 0.06578, 'accuracy': 0.96888, 'precision': 0.69403, 'recall': 0.30195, 'f1': 0.42081, 'auc': 0.86327}
2025-08-16 04:05:59,373 - INFO - val: {'epoch': 46, 'time_epoch': 4.32998, 'loss': 0.07495332, 'lr': 0, 'params': 451793, 'time_iter': 0.03357, 'accuracy': 0.98274, 'precision': 0.63158, 'recall': 0.2963, 'f1': 0.40336, 'auc': 0.78452}
2025-08-16 04:06:03,687 - INFO - test: {'epoch': 46, 'time_epoch': 4.29724, 'loss': 0.11988622, 'lr': 0, 'params': 451793, 'time_iter': 0.03331, 'accuracy': 0.96912, 'precision': 0.5283, 'recall': 0.21538, 'f1': 0.30601, 'auc': 0.76192}
2025-08-16 04:06:03,690 - INFO - > Epoch 46: took 76.4s (avg 79.6s) | Best so far: epoch 35	train_loss: 0.1118 train_auc: 0.8465	val_loss: 0.0725 val_auc: 0.8231	test_loss: 0.1185 test_auc: 0.7511
2025-08-16 04:07:11,519 - INFO - train: {'epoch': 47, 'time_epoch': 67.76101, 'eta': 3668.94458, 'eta_hours': 1.01915, 'loss': 0.10448154, 'lr': 5.904e-05, 'params': 451793, 'time_iter': 0.06585, 'accuracy': 0.96985, 'precision': 0.70906, 'recall': 0.33036, 'f1': 0.45072, 'auc': 0.87053}
2025-08-16 04:07:15,844 - INFO - val: {'epoch': 47, 'time_epoch': 4.3031, 'loss': 0.07449037, 'lr': 0, 'params': 451793, 'time_iter': 0.03336, 'accuracy': 0.98201, 'precision': 0.5814, 'recall': 0.30864, 'f1': 0.40323, 'auc': 0.79684}
2025-08-16 04:07:20,153 - INFO - test: {'epoch': 47, 'time_epoch': 4.28892, 'loss': 0.1168391, 'lr': 0, 'params': 451793, 'time_iter': 0.03325, 'accuracy': 0.97058, 'precision': 0.56, 'recall': 0.32308, 'f1': 0.40976, 'auc': 0.76458}
2025-08-16 04:07:20,155 - INFO - > Epoch 47: took 76.5s (avg 79.5s) | Best so far: epoch 35	train_loss: 0.1118 train_auc: 0.8465	val_loss: 0.0725 val_auc: 0.8231	test_loss: 0.1185 test_auc: 0.7511
2025-08-16 04:08:28,534 - INFO - train: {'epoch': 48, 'time_epoch': 68.31158, 'eta': 3596.05128, 'eta_hours': 0.9989, 'loss': 0.10473738, 'lr': 5.741e-05, 'params': 451793, 'time_iter': 0.06639, 'accuracy': 0.96967, 'precision': 0.69966, 'recall': 0.33279, 'f1': 0.45105, 'auc': 0.87239}
2025-08-16 04:08:32,898 - INFO - val: {'epoch': 48, 'time_epoch': 4.33924, 'loss': 0.07207417, 'lr': 0, 'params': 451793, 'time_iter': 0.03364, 'accuracy': 0.98249, 'precision': 0.62162, 'recall': 0.28395, 'f1': 0.38983, 'auc': 0.82551}
2025-08-16 04:08:37,222 - INFO - test: {'epoch': 48, 'time_epoch': 4.30542, 'loss': 0.11940988, 'lr': 0, 'params': 451793, 'time_iter': 0.03338, 'accuracy': 0.96888, 'precision': 0.51852, 'recall': 0.21538, 'f1': 0.30435, 'auc': 0.76852}
2025-08-16 04:08:37,224 - INFO - > Epoch 48: took 77.1s (avg 79.5s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:09:46,122 - INFO - train: {'epoch': 49, 'time_epoch': 68.82966, 'eta': 3523.85932, 'eta_hours': 0.97885, 'loss': 0.1051576, 'lr': 5.577e-05, 'params': 451793, 'time_iter': 0.06689, 'accuracy': 0.96988, 'precision': 0.70957, 'recall': 0.33117, 'f1': 0.45158, 'auc': 0.87091}
2025-08-16 04:09:50,479 - INFO - val: {'epoch': 49, 'time_epoch': 4.33402, 'loss': 0.07612869, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.98249, 'precision': 0.60976, 'recall': 0.30864, 'f1': 0.40984, 'auc': 0.76588}
2025-08-16 04:09:54,832 - INFO - test: {'epoch': 49, 'time_epoch': 4.33539, 'loss': 0.11841413, 'lr': 0, 'params': 451793, 'time_iter': 0.03361, 'accuracy': 0.96864, 'precision': 0.50746, 'recall': 0.26154, 'f1': 0.34518, 'auc': 0.76687}
2025-08-16 04:09:54,835 - INFO - > Epoch 49: took 77.6s (avg 79.4s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:11:02,963 - INFO - train: {'epoch': 50, 'time_epoch': 68.05906, 'eta': 3451.05884, 'eta_hours': 0.95863, 'loss': 0.10435206, 'lr': 5.413e-05, 'params': 451793, 'time_iter': 0.06614, 'accuracy': 0.97006, 'precision': 0.71256, 'recall': 0.33604, 'f1': 0.4567, 'auc': 0.86489}
2025-08-16 04:11:07,317 - INFO - val: {'epoch': 50, 'time_epoch': 4.31869, 'loss': 0.07529673, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.98225, 'precision': 0.58696, 'recall': 0.33333, 'f1': 0.4252, 'auc': 0.79806}
2025-08-16 04:11:11,620 - INFO - test: {'epoch': 50, 'time_epoch': 4.28513, 'loss': 0.11808886, 'lr': 0, 'params': 451793, 'time_iter': 0.03322, 'accuracy': 0.96937, 'precision': 0.5303, 'recall': 0.26923, 'f1': 0.35714, 'auc': 0.77562}
2025-08-16 04:11:11,623 - INFO - > Epoch 50: took 76.8s (avg 79.4s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:12:19,987 - INFO - train: {'epoch': 51, 'time_epoch': 68.29415, 'eta': 3378.65772, 'eta_hours': 0.93852, 'loss': 0.10442759, 'lr': 5.248e-05, 'params': 451793, 'time_iter': 0.06637, 'accuracy': 0.96973, 'precision': 0.69094, 'recall': 0.34659, 'f1': 0.46162, 'auc': 0.86895}
2025-08-16 04:12:24,316 - INFO - val: {'epoch': 51, 'time_epoch': 4.30575, 'loss': 0.07573964, 'lr': 0, 'params': 451793, 'time_iter': 0.03338, 'accuracy': 0.98201, 'precision': 0.58974, 'recall': 0.28395, 'f1': 0.38333, 'auc': 0.7971}
2025-08-16 04:12:28,635 - INFO - test: {'epoch': 51, 'time_epoch': 4.29973, 'loss': 0.11787132, 'lr': 0, 'params': 451793, 'time_iter': 0.03333, 'accuracy': 0.97082, 'precision': 0.57353, 'recall': 0.3, 'f1': 0.39394, 'auc': 0.76516}
2025-08-16 04:12:28,637 - INFO - > Epoch 51: took 77.0s (avg 79.3s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:13:36,492 - INFO - train: {'epoch': 52, 'time_epoch': 67.78665, 'eta': 3305.96154, 'eta_hours': 0.91832, 'loss': 0.10326469, 'lr': 5.083e-05, 'params': 451793, 'time_iter': 0.06588, 'accuracy': 0.96991, 'precision': 0.70033, 'recall': 0.34334, 'f1': 0.46078, 'auc': 0.87677}
2025-08-16 04:13:40,818 - INFO - val: {'epoch': 52, 'time_epoch': 4.30445, 'loss': 0.0728867, 'lr': 0, 'params': 451793, 'time_iter': 0.03337, 'accuracy': 0.98274, 'precision': 0.63889, 'recall': 0.28395, 'f1': 0.39316, 'auc': 0.81699}
2025-08-16 04:13:45,144 - INFO - test: {'epoch': 52, 'time_epoch': 4.30625, 'loss': 0.11501143, 'lr': 0, 'params': 451793, 'time_iter': 0.03338, 'accuracy': 0.97034, 'precision': 0.56452, 'recall': 0.26923, 'f1': 0.36458, 'auc': 0.78139}
2025-08-16 04:13:45,146 - INFO - > Epoch 52: took 76.5s (avg 79.3s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:14:52,959 - INFO - train: {'epoch': 53, 'time_epoch': 67.74461, 'eta': 3233.41137, 'eta_hours': 0.89817, 'loss': 0.10281276, 'lr': 4.917e-05, 'params': 451793, 'time_iter': 0.06584, 'accuracy': 0.97097, 'precision': 0.74513, 'recall': 0.34172, 'f1': 0.46856, 'auc': 0.87855}
2025-08-16 04:14:57,296 - INFO - val: {'epoch': 53, 'time_epoch': 4.31509, 'loss': 0.07262756, 'lr': 0, 'params': 451793, 'time_iter': 0.03345, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.8085}
2025-08-16 04:15:01,630 - INFO - test: {'epoch': 53, 'time_epoch': 4.31117, 'loss': 0.11688694, 'lr': 0, 'params': 451793, 'time_iter': 0.03342, 'accuracy': 0.96985, 'precision': 0.55357, 'recall': 0.23846, 'f1': 0.33333, 'auc': 0.77308}
2025-08-16 04:15:01,632 - INFO - > Epoch 53: took 76.5s (avg 79.2s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:16:10,328 - INFO - train: {'epoch': 54, 'time_epoch': 68.6271, 'eta': 3161.758, 'eta_hours': 0.87827, 'loss': 0.10239647, 'lr': 4.752e-05, 'params': 451793, 'time_iter': 0.06669, 'accuracy': 0.97064, 'precision': 0.71803, 'recall': 0.35552, 'f1': 0.47557, 'auc': 0.87673}
2025-08-16 04:16:14,669 - INFO - val: {'epoch': 54, 'time_epoch': 4.31804, 'loss': 0.07377032, 'lr': 0, 'params': 451793, 'time_iter': 0.03347, 'accuracy': 0.98274, 'precision': 0.63889, 'recall': 0.28395, 'f1': 0.39316, 'auc': 0.81062}
2025-08-16 04:16:18,997 - INFO - test: {'epoch': 54, 'time_epoch': 4.30561, 'loss': 0.12053647, 'lr': 0, 'params': 451793, 'time_iter': 0.03338, 'accuracy': 0.96961, 'precision': 0.55102, 'recall': 0.20769, 'f1': 0.30168, 'auc': 0.75723}
2025-08-16 04:16:18,999 - INFO - > Epoch 54: took 77.4s (avg 79.2s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:17:27,104 - INFO - train: {'epoch': 55, 'time_epoch': 68.03703, 'eta': 3089.74908, 'eta_hours': 0.85826, 'loss': 0.10284245, 'lr': 4.587e-05, 'params': 451793, 'time_iter': 0.06612, 'accuracy': 0.97106, 'precision': 0.73569, 'recall': 0.35471, 'f1': 0.47864, 'auc': 0.8766}
2025-08-16 04:17:31,451 - INFO - val: {'epoch': 55, 'time_epoch': 4.32511, 'loss': 0.07418902, 'lr': 0, 'params': 451793, 'time_iter': 0.03353, 'accuracy': 0.98201, 'precision': 0.57778, 'recall': 0.32099, 'f1': 0.4127, 'auc': 0.80179}
2025-08-16 04:17:35,788 - INFO - test: {'epoch': 55, 'time_epoch': 4.31675, 'loss': 0.12058872, 'lr': 0, 'params': 451793, 'time_iter': 0.03346, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.31538, 'f1': 0.38679, 'auc': 0.77009}
2025-08-16 04:17:35,790 - INFO - > Epoch 55: took 76.8s (avg 79.2s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:18:44,017 - INFO - train: {'epoch': 56, 'time_epoch': 68.15675, 'eta': 3017.96984, 'eta_hours': 0.83832, 'loss': 0.10079717, 'lr': 4.423e-05, 'params': 451793, 'time_iter': 0.06624, 'accuracy': 0.97024, 'precision': 0.70305, 'recall': 0.35552, 'f1': 0.47224, 'auc': 0.88415}
2025-08-16 04:18:48,316 - INFO - val: {'epoch': 56, 'time_epoch': 4.27615, 'loss': 0.07227883, 'lr': 0, 'params': 451793, 'time_iter': 0.03315, 'accuracy': 0.98298, 'precision': 0.63415, 'recall': 0.32099, 'f1': 0.42623, 'auc': 0.80006}
2025-08-16 04:18:52,635 - INFO - test: {'epoch': 56, 'time_epoch': 4.3008, 'loss': 0.11875246, 'lr': 0, 'params': 451793, 'time_iter': 0.03334, 'accuracy': 0.97058, 'precision': 0.56522, 'recall': 0.3, 'f1': 0.39196, 'auc': 0.77541}
2025-08-16 04:18:52,638 - INFO - > Epoch 56: took 76.8s (avg 79.1s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:20:00,955 - INFO - train: {'epoch': 57, 'time_epoch': 68.25053, 'eta': 2946.38342, 'eta_hours': 0.81844, 'loss': 0.10127926, 'lr': 4.259e-05, 'params': 451793, 'time_iter': 0.06633, 'accuracy': 0.97103, 'precision': 0.73134, 'recall': 0.35795, 'f1': 0.48065, 'auc': 0.88001}
2025-08-16 04:20:05,292 - INFO - val: {'epoch': 57, 'time_epoch': 4.31538, 'loss': 0.07353623, 'lr': 0, 'params': 451793, 'time_iter': 0.03345, 'accuracy': 0.98225, 'precision': 0.58696, 'recall': 0.33333, 'f1': 0.4252, 'auc': 0.82235}
2025-08-16 04:20:09,619 - INFO - test: {'epoch': 57, 'time_epoch': 4.30868, 'loss': 0.12066965, 'lr': 0, 'params': 451793, 'time_iter': 0.0334, 'accuracy': 0.96864, 'precision': 0.50588, 'recall': 0.33077, 'f1': 0.4, 'auc': 0.76778}
2025-08-16 04:20:09,622 - INFO - > Epoch 57: took 77.0s (avg 79.1s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:21:17,467 - INFO - train: {'epoch': 58, 'time_epoch': 67.7764, 'eta': 2874.5806, 'eta_hours': 0.79849, 'loss': 0.10082576, 'lr': 4.096e-05, 'params': 451793, 'time_iter': 0.06587, 'accuracy': 0.97058, 'precision': 0.7129, 'recall': 0.35877, 'f1': 0.47732, 'auc': 0.88309}
2025-08-16 04:21:21,788 - INFO - val: {'epoch': 58, 'time_epoch': 4.2986, 'loss': 0.07385077, 'lr': 0, 'params': 451793, 'time_iter': 0.03332, 'accuracy': 0.98274, 'precision': 0.625, 'recall': 0.30864, 'f1': 0.41322, 'auc': 0.79896}
2025-08-16 04:21:26,103 - INFO - test: {'epoch': 58, 'time_epoch': 4.29719, 'loss': 0.1221897, 'lr': 0, 'params': 451793, 'time_iter': 0.03331, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.24615, 'f1': 0.3299, 'auc': 0.75802}
2025-08-16 04:21:26,106 - INFO - > Epoch 58: took 76.5s (avg 79.0s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:22:33,817 - INFO - train: {'epoch': 59, 'time_epoch': 67.6427, 'eta': 2802.82287, 'eta_hours': 0.77856, 'loss': 0.09848754, 'lr': 3.934e-05, 'params': 451793, 'time_iter': 0.06574, 'accuracy': 0.97143, 'precision': 0.72121, 'recall': 0.38636, 'f1': 0.50317, 'auc': 0.88928}
2025-08-16 04:22:38,192 - INFO - val: {'epoch': 59, 'time_epoch': 4.3524, 'loss': 0.07152399, 'lr': 0, 'params': 451793, 'time_iter': 0.03374, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.80242}
2025-08-16 04:22:42,545 - INFO - test: {'epoch': 59, 'time_epoch': 4.33399, 'loss': 0.12149472, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.96912, 'precision': 0.53191, 'recall': 0.19231, 'f1': 0.28249, 'auc': 0.76269}
2025-08-16 04:22:42,548 - INFO - > Epoch 59: took 76.4s (avg 79.0s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:23:50,876 - INFO - train: {'epoch': 60, 'time_epoch': 68.25827, 'eta': 2731.59361, 'eta_hours': 0.75878, 'loss': 0.09927427, 'lr': 3.773e-05, 'params': 451793, 'time_iter': 0.06633, 'accuracy': 0.97128, 'precision': 0.72527, 'recall': 0.375, 'f1': 0.49438, 'auc': 0.88475}
2025-08-16 04:23:55,209 - INFO - val: {'epoch': 60, 'time_epoch': 4.30945, 'loss': 0.07452593, 'lr': 0, 'params': 451793, 'time_iter': 0.03341, 'accuracy': 0.98225, 'precision': 0.59091, 'recall': 0.32099, 'f1': 0.416, 'auc': 0.79528}
2025-08-16 04:23:59,529 - INFO - test: {'epoch': 60, 'time_epoch': 4.30292, 'loss': 0.11998789, 'lr': 0, 'params': 451793, 'time_iter': 0.03336, 'accuracy': 0.96864, 'precision': 0.50725, 'recall': 0.26923, 'f1': 0.35176, 'auc': 0.77024}
2025-08-16 04:23:59,532 - INFO - > Epoch 60: took 77.0s (avg 79.0s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:25:08,201 - INFO - train: {'epoch': 61, 'time_epoch': 68.5986, 'eta': 2660.66878, 'eta_hours': 0.73907, 'loss': 0.10067076, 'lr': 3.613e-05, 'params': 451793, 'time_iter': 0.06667, 'accuracy': 0.97088, 'precision': 0.72459, 'recall': 0.35877, 'f1': 0.47991, 'auc': 0.8869}
2025-08-16 04:25:12,592 - INFO - val: {'epoch': 61, 'time_epoch': 4.3638, 'loss': 0.07297126, 'lr': 0, 'params': 451793, 'time_iter': 0.03383, 'accuracy': 0.98347, 'precision': 0.66667, 'recall': 0.32099, 'f1': 0.43333, 'auc': 0.80823}
2025-08-16 04:25:17,001 - INFO - test: {'epoch': 61, 'time_epoch': 4.38963, 'loss': 0.11916576, 'lr': 0, 'params': 451793, 'time_iter': 0.03403, 'accuracy': 0.97058, 'precision': 0.57377, 'recall': 0.26923, 'f1': 0.36649, 'auc': 0.76904}
2025-08-16 04:25:17,004 - INFO - > Epoch 61: took 77.5s (avg 78.9s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:26:25,260 - INFO - train: {'epoch': 62, 'time_epoch': 68.18496, 'eta': 2589.57487, 'eta_hours': 0.71933, 'loss': 0.10009301, 'lr': 3.455e-05, 'params': 451793, 'time_iter': 0.06626, 'accuracy': 0.97085, 'precision': 0.71564, 'recall': 0.36769, 'f1': 0.48579, 'auc': 0.88943}
2025-08-16 04:26:29,623 - INFO - val: {'epoch': 62, 'time_epoch': 4.33977, 'loss': 0.07286273, 'lr': 0, 'params': 451793, 'time_iter': 0.03364, 'accuracy': 0.98274, 'precision': 0.63889, 'recall': 0.28395, 'f1': 0.39316, 'auc': 0.81782}
2025-08-16 04:26:33,983 - INFO - test: {'epoch': 62, 'time_epoch': 4.34118, 'loss': 0.12099855, 'lr': 0, 'params': 451793, 'time_iter': 0.03365, 'accuracy': 0.97009, 'precision': 0.56364, 'recall': 0.23846, 'f1': 0.33514, 'auc': 0.76678}
2025-08-16 04:26:33,985 - INFO - > Epoch 62: took 77.0s (avg 78.9s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:27:42,485 - INFO - train: {'epoch': 63, 'time_epoch': 68.43037, 'eta': 2518.70991, 'eta_hours': 0.69964, 'loss': 0.09920634, 'lr': 3.299e-05, 'params': 451793, 'time_iter': 0.0665, 'accuracy': 0.97113, 'precision': 0.73579, 'recall': 0.35714, 'f1': 0.48087, 'auc': 0.88887}
2025-08-16 04:27:46,796 - INFO - val: {'epoch': 63, 'time_epoch': 4.28878, 'loss': 0.07353646, 'lr': 0, 'params': 451793, 'time_iter': 0.03325, 'accuracy': 0.98298, 'precision': 0.65714, 'recall': 0.28395, 'f1': 0.39655, 'auc': 0.80306}
2025-08-16 04:27:51,111 - INFO - test: {'epoch': 63, 'time_epoch': 4.29609, 'loss': 0.12135382, 'lr': 0, 'params': 451793, 'time_iter': 0.0333, 'accuracy': 0.96985, 'precision': 0.56, 'recall': 0.21538, 'f1': 0.31111, 'auc': 0.76951}
2025-08-16 04:27:51,114 - INFO - > Epoch 63: took 77.1s (avg 78.9s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:28:58,967 - INFO - train: {'epoch': 64, 'time_epoch': 67.78583, 'eta': 2447.57279, 'eta_hours': 0.67988, 'loss': 0.09862717, 'lr': 3.144e-05, 'params': 451793, 'time_iter': 0.06588, 'accuracy': 0.97085, 'precision': 0.7184, 'recall': 0.36445, 'f1': 0.48358, 'auc': 0.89466}
2025-08-16 04:29:03,327 - INFO - val: {'epoch': 64, 'time_epoch': 4.33781, 'loss': 0.07423147, 'lr': 0, 'params': 451793, 'time_iter': 0.03363, 'accuracy': 0.98322, 'precision': 0.66667, 'recall': 0.2963, 'f1': 0.41026, 'auc': 0.79122}
2025-08-16 04:29:07,675 - INFO - test: {'epoch': 64, 'time_epoch': 4.32941, 'loss': 0.11971949, 'lr': 0, 'params': 451793, 'time_iter': 0.03356, 'accuracy': 0.96937, 'precision': 0.53125, 'recall': 0.26154, 'f1': 0.35052, 'auc': 0.76821}
2025-08-16 04:29:07,678 - INFO - > Epoch 64: took 76.6s (avg 78.8s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:30:16,000 - INFO - train: {'epoch': 65, 'time_epoch': 68.25383, 'eta': 2376.77833, 'eta_hours': 0.66022, 'loss': 0.09901441, 'lr': 2.992e-05, 'params': 451793, 'time_iter': 0.06633, 'accuracy': 0.97128, 'precision': 0.73563, 'recall': 0.36364, 'f1': 0.48669, 'auc': 0.89069}
2025-08-16 04:30:20,328 - INFO - val: {'epoch': 65, 'time_epoch': 4.3052, 'loss': 0.07288283, 'lr': 0, 'params': 451793, 'time_iter': 0.03337, 'accuracy': 0.98298, 'precision': 0.65714, 'recall': 0.28395, 'f1': 0.39655, 'auc': 0.80798}
2025-08-16 04:30:24,640 - INFO - test: {'epoch': 65, 'time_epoch': 4.29347, 'loss': 0.12253934, 'lr': 0, 'params': 451793, 'time_iter': 0.03328, 'accuracy': 0.96888, 'precision': 0.51667, 'recall': 0.23846, 'f1': 0.32632, 'auc': 0.7625}
2025-08-16 04:30:24,643 - INFO - > Epoch 65: took 77.0s (avg 78.8s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:31:32,946 - INFO - train: {'epoch': 66, 'time_epoch': 68.23531, 'eta': 2306.05058, 'eta_hours': 0.64057, 'loss': 0.09736287, 'lr': 2.841e-05, 'params': 451793, 'time_iter': 0.06631, 'accuracy': 0.97176, 'precision': 0.74318, 'recall': 0.37581, 'f1': 0.49919, 'auc': 0.89426}
2025-08-16 04:31:37,274 - INFO - val: {'epoch': 66, 'time_epoch': 4.30436, 'loss': 0.07432589, 'lr': 0, 'params': 451793, 'time_iter': 0.03337, 'accuracy': 0.98177, 'precision': 0.57895, 'recall': 0.2716, 'f1': 0.36975, 'auc': 0.80957}
2025-08-16 04:31:41,592 - INFO - test: {'epoch': 66, 'time_epoch': 4.3011, 'loss': 0.12117601, 'lr': 0, 'params': 451793, 'time_iter': 0.03334, 'accuracy': 0.96791, 'precision': 0.48276, 'recall': 0.21538, 'f1': 0.29787, 'auc': 0.77915}
2025-08-16 04:31:41,595 - INFO - > Epoch 66: took 77.0s (avg 78.8s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:32:49,545 - INFO - train: {'epoch': 67, 'time_epoch': 67.8818, 'eta': 2235.22978, 'eta_hours': 0.6209, 'loss': 0.098183, 'lr': 2.693e-05, 'params': 451793, 'time_iter': 0.06597, 'accuracy': 0.97167, 'precision': 0.74116, 'recall': 0.37419, 'f1': 0.4973, 'auc': 0.89199}
2025-08-16 04:32:53,856 - INFO - val: {'epoch': 67, 'time_epoch': 4.28594, 'loss': 0.07318022, 'lr': 0, 'params': 451793, 'time_iter': 0.03322, 'accuracy': 0.98225, 'precision': 0.6, 'recall': 0.2963, 'f1': 0.39669, 'auc': 0.82518}
2025-08-16 04:32:58,166 - INFO - test: {'epoch': 67, 'time_epoch': 4.27961, 'loss': 0.12434254, 'lr': 0, 'params': 451793, 'time_iter': 0.03318, 'accuracy': 0.96693, 'precision': 0.46053, 'recall': 0.26923, 'f1': 0.33981, 'auc': 0.76587}
2025-08-16 04:32:58,169 - INFO - > Epoch 67: took 76.6s (avg 78.8s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:34:06,101 - INFO - train: {'epoch': 68, 'time_epoch': 67.8635, 'eta': 2164.48595, 'eta_hours': 0.60125, 'loss': 0.09737485, 'lr': 2.548e-05, 'params': 451793, 'time_iter': 0.06595, 'accuracy': 0.97179, 'precision': 0.74595, 'recall': 0.37419, 'f1': 0.49838, 'auc': 0.89575}
2025-08-16 04:34:10,421 - INFO - val: {'epoch': 68, 'time_epoch': 4.29801, 'loss': 0.07306432, 'lr': 0, 'params': 451793, 'time_iter': 0.03332, 'accuracy': 0.98225, 'precision': 0.59091, 'recall': 0.32099, 'f1': 0.416, 'auc': 0.81448}
2025-08-16 04:34:14,749 - INFO - test: {'epoch': 68, 'time_epoch': 4.30951, 'loss': 0.1209725, 'lr': 0, 'params': 451793, 'time_iter': 0.03341, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.29231, 'f1': 0.36893, 'auc': 0.77757}
2025-08-16 04:34:14,752 - INFO - > Epoch 68: took 76.6s (avg 78.7s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:35:22,874 - INFO - train: {'epoch': 69, 'time_epoch': 68.0553, 'eta': 2093.90661, 'eta_hours': 0.58164, 'loss': 0.09591383, 'lr': 2.405e-05, 'params': 451793, 'time_iter': 0.06614, 'accuracy': 0.9721, 'precision': 0.74303, 'recall': 0.38961, 'f1': 0.51118, 'auc': 0.89904}
2025-08-16 04:35:27,143 - INFO - val: {'epoch': 69, 'time_epoch': 4.24617, 'loss': 0.07502482, 'lr': 0, 'params': 451793, 'time_iter': 0.03292, 'accuracy': 0.98201, 'precision': 0.57447, 'recall': 0.33333, 'f1': 0.42188, 'auc': 0.79818}
2025-08-16 04:35:31,399 - INFO - test: {'epoch': 69, 'time_epoch': 4.23836, 'loss': 0.12138146, 'lr': 0, 'params': 451793, 'time_iter': 0.03286, 'accuracy': 0.96961, 'precision': 0.53086, 'recall': 0.33077, 'f1': 0.40758, 'auc': 0.77654}
2025-08-16 04:35:31,401 - INFO - > Epoch 69: took 76.6s (avg 78.7s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:36:38,711 - INFO - train: {'epoch': 70, 'time_epoch': 67.24449, 'eta': 2023.06719, 'eta_hours': 0.56196, 'loss': 0.0964204, 'lr': 2.265e-05, 'params': 451793, 'time_iter': 0.06535, 'accuracy': 0.97195, 'precision': 0.74408, 'recall': 0.38231, 'f1': 0.50509, 'auc': 0.89769}
2025-08-16 04:36:43,000 - INFO - val: {'epoch': 70, 'time_epoch': 4.26552, 'loss': 0.07329985, 'lr': 0, 'params': 451793, 'time_iter': 0.03307, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.81568}
2025-08-16 04:36:47,270 - INFO - test: {'epoch': 70, 'time_epoch': 4.25276, 'loss': 0.12275255, 'lr': 0, 'params': 451793, 'time_iter': 0.03297, 'accuracy': 0.97058, 'precision': 0.56522, 'recall': 0.3, 'f1': 0.39196, 'auc': 0.76747}
2025-08-16 04:36:47,273 - INFO - > Epoch 70: took 75.9s (avg 78.7s) | Best so far: epoch 48	train_loss: 0.1047 train_auc: 0.8724	val_loss: 0.0721 val_auc: 0.8255	test_loss: 0.1194 test_auc: 0.7685
2025-08-16 04:37:54,519 - INFO - train: {'epoch': 71, 'time_epoch': 67.17978, 'eta': 1952.30247, 'eta_hours': 0.54231, 'loss': 0.09756512, 'lr': 2.128e-05, 'params': 451793, 'time_iter': 0.06529, 'accuracy': 0.97179, 'precision': 0.73899, 'recall': 0.38149, 'f1': 0.50321, 'auc': 0.89331}
2025-08-16 04:37:58,790 - INFO - val: {'epoch': 71, 'time_epoch': 4.24828, 'loss': 0.07272549, 'lr': 0, 'params': 451793, 'time_iter': 0.03293, 'accuracy': 0.98201, 'precision': 0.57447, 'recall': 0.33333, 'f1': 0.42188, 'auc': 0.82632}
2025-08-16 04:38:03,066 - INFO - test: {'epoch': 71, 'time_epoch': 4.2588, 'loss': 0.12404184, 'lr': 0, 'params': 451793, 'time_iter': 0.03301, 'accuracy': 0.96791, 'precision': 0.4878, 'recall': 0.30769, 'f1': 0.37736, 'auc': 0.76583}
2025-08-16 04:38:03,069 - INFO - > Epoch 71: took 75.8s (avg 78.6s) | Best so far: epoch 71	train_loss: 0.0976 train_auc: 0.8933	val_loss: 0.0727 val_auc: 0.8263	test_loss: 0.1240 test_auc: 0.7658
2025-08-16 04:39:11,489 - INFO - train: {'epoch': 72, 'time_epoch': 68.3512, 'eta': 1882.06923, 'eta_hours': 0.5228, 'loss': 0.09646052, 'lr': 1.995e-05, 'params': 451793, 'time_iter': 0.06642, 'accuracy': 0.97173, 'precision': 0.7316, 'recall': 0.38718, 'f1': 0.50637, 'auc': 0.90091}
2025-08-16 04:39:15,867 - INFO - val: {'epoch': 72, 'time_epoch': 4.3542, 'loss': 0.07308216, 'lr': 0, 'params': 451793, 'time_iter': 0.03375, 'accuracy': 0.98274, 'precision': 0.63158, 'recall': 0.2963, 'f1': 0.40336, 'auc': 0.81903}
2025-08-16 04:39:20,235 - INFO - test: {'epoch': 72, 'time_epoch': 4.34996, 'loss': 0.12292701, 'lr': 0, 'params': 451793, 'time_iter': 0.03372, 'accuracy': 0.96888, 'precision': 0.51724, 'recall': 0.23077, 'f1': 0.31915, 'auc': 0.76322}
2025-08-16 04:39:20,237 - INFO - > Epoch 72: took 77.2s (avg 78.6s) | Best so far: epoch 71	train_loss: 0.0976 train_auc: 0.8933	val_loss: 0.0727 val_auc: 0.8263	test_loss: 0.1240 test_auc: 0.7658
2025-08-16 04:40:29,361 - INFO - train: {'epoch': 73, 'time_epoch': 69.05488, 'eta': 1812.1341, 'eta_hours': 0.50337, 'loss': 0.09593235, 'lr': 1.864e-05, 'params': 451793, 'time_iter': 0.06711, 'accuracy': 0.97185, 'precision': 0.74363, 'recall': 0.37906, 'f1': 0.50215, 'auc': 0.90002}
2025-08-16 04:40:33,697 - INFO - val: {'epoch': 73, 'time_epoch': 4.31312, 'loss': 0.07373591, 'lr': 0, 'params': 451793, 'time_iter': 0.03344, 'accuracy': 0.98249, 'precision': 0.63636, 'recall': 0.25926, 'f1': 0.36842, 'auc': 0.80956}
2025-08-16 04:40:38,013 - INFO - test: {'epoch': 73, 'time_epoch': 4.29777, 'loss': 0.1247666, 'lr': 0, 'params': 451793, 'time_iter': 0.03332, 'accuracy': 0.96912, 'precision': 0.53191, 'recall': 0.19231, 'f1': 0.28249, 'auc': 0.76507}
2025-08-16 04:40:38,016 - INFO - > Epoch 73: took 77.8s (avg 78.6s) | Best so far: epoch 71	train_loss: 0.0976 train_auc: 0.8933	val_loss: 0.0727 val_auc: 0.8263	test_loss: 0.1240 test_auc: 0.7658
2025-08-16 04:41:45,884 - INFO - train: {'epoch': 74, 'time_epoch': 67.80214, 'eta': 1741.80486, 'eta_hours': 0.48383, 'loss': 0.09595594, 'lr': 1.737e-05, 'params': 451793, 'time_iter': 0.06589, 'accuracy': 0.97176, 'precision': 0.73709, 'recall': 0.38231, 'f1': 0.50347, 'auc': 0.89982}
2025-08-16 04:41:50,180 - INFO - val: {'epoch': 74, 'time_epoch': 4.27398, 'loss': 0.07181255, 'lr': 0, 'params': 451793, 'time_iter': 0.03313, 'accuracy': 0.98225, 'precision': 0.61111, 'recall': 0.2716, 'f1': 0.37607, 'auc': 0.82696}
2025-08-16 04:41:54,470 - INFO - test: {'epoch': 74, 'time_epoch': 4.27196, 'loss': 0.12410553, 'lr': 0, 'params': 451793, 'time_iter': 0.03312, 'accuracy': 0.96791, 'precision': 0.48611, 'recall': 0.26923, 'f1': 0.34653, 'auc': 0.76028}
2025-08-16 04:41:54,473 - INFO - > Epoch 74: took 76.5s (avg 78.6s) | Best so far: epoch 74	train_loss: 0.0960 train_auc: 0.8998	val_loss: 0.0718 val_auc: 0.8270	test_loss: 0.1241 test_auc: 0.7603
2025-08-16 04:43:02,600 - INFO - train: {'epoch': 75, 'time_epoch': 68.06109, 'eta': 1671.6239, 'eta_hours': 0.46434, 'loss': 0.095696, 'lr': 1.614e-05, 'params': 451793, 'time_iter': 0.06614, 'accuracy': 0.97216, 'precision': 0.75159, 'recall': 0.38312, 'f1': 0.50753, 'auc': 0.90118}
2025-08-16 04:43:06,935 - INFO - val: {'epoch': 75, 'time_epoch': 4.31195, 'loss': 0.07345565, 'lr': 0, 'params': 451793, 'time_iter': 0.03343, 'accuracy': 0.98128, 'precision': 0.54348, 'recall': 0.30864, 'f1': 0.3937, 'auc': 0.82064}
2025-08-16 04:43:11,261 - INFO - test: {'epoch': 75, 'time_epoch': 4.30723, 'loss': 0.12406962, 'lr': 0, 'params': 451793, 'time_iter': 0.03339, 'accuracy': 0.96815, 'precision': 0.49438, 'recall': 0.33846, 'f1': 0.40183, 'auc': 0.77573}
2025-08-16 04:43:11,263 - INFO - > Epoch 75: took 76.8s (avg 78.5s) | Best so far: epoch 74	train_loss: 0.0960 train_auc: 0.8998	val_loss: 0.0718 val_auc: 0.8270	test_loss: 0.1241 test_auc: 0.7603
2025-08-16 04:44:19,222 - INFO - train: {'epoch': 76, 'time_epoch': 67.88797, 'eta': 1601.44628, 'eta_hours': 0.44485, 'loss': 0.09510721, 'lr': 1.494e-05, 'params': 451793, 'time_iter': 0.06597, 'accuracy': 0.97277, 'precision': 0.76168, 'recall': 0.39692, 'f1': 0.52188, 'auc': 0.89917}
2025-08-16 04:44:23,583 - INFO - val: {'epoch': 76, 'time_epoch': 4.33852, 'loss': 0.07216105, 'lr': 0, 'params': 451793, 'time_iter': 0.03363, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.82492}
2025-08-16 04:44:27,934 - INFO - test: {'epoch': 76, 'time_epoch': 4.33311, 'loss': 0.12528705, 'lr': 0, 'params': 451793, 'time_iter': 0.03359, 'accuracy': 0.96912, 'precision': 0.52239, 'recall': 0.26923, 'f1': 0.35533, 'auc': 0.76431}
2025-08-16 04:44:27,937 - INFO - > Epoch 76: took 76.7s (avg 78.5s) | Best so far: epoch 74	train_loss: 0.0960 train_auc: 0.8998	val_loss: 0.0718 val_auc: 0.8270	test_loss: 0.1241 test_auc: 0.7603
2025-08-16 04:45:36,111 - INFO - train: {'epoch': 77, 'time_epoch': 68.10819, 'eta': 1531.38949, 'eta_hours': 0.42539, 'loss': 0.0943551, 'lr': 1.378e-05, 'params': 451793, 'time_iter': 0.06619, 'accuracy': 0.97268, 'precision': 0.76056, 'recall': 0.39448, 'f1': 0.51951, 'auc': 0.90922}
2025-08-16 04:45:40,479 - INFO - val: {'epoch': 77, 'time_epoch': 4.34621, 'loss': 0.07249894, 'lr': 0, 'params': 451793, 'time_iter': 0.03369, 'accuracy': 0.98128, 'precision': 0.55556, 'recall': 0.24691, 'f1': 0.34188, 'auc': 0.82619}
2025-08-16 04:45:44,836 - INFO - test: {'epoch': 77, 'time_epoch': 4.33894, 'loss': 0.12682943, 'lr': 0, 'params': 451793, 'time_iter': 0.03364, 'accuracy': 0.96791, 'precision': 0.48571, 'recall': 0.26154, 'f1': 0.34, 'auc': 0.76681}
2025-08-16 04:45:44,839 - INFO - > Epoch 77: took 76.9s (avg 78.5s) | Best so far: epoch 74	train_loss: 0.0960 train_auc: 0.8998	val_loss: 0.0718 val_auc: 0.8270	test_loss: 0.1241 test_auc: 0.7603
2025-08-16 04:46:53,210 - INFO - train: {'epoch': 78, 'time_epoch': 68.30323, 'eta': 1461.43388, 'eta_hours': 0.40595, 'loss': 0.09530904, 'lr': 1.266e-05, 'params': 451793, 'time_iter': 0.06638, 'accuracy': 0.97258, 'precision': 0.76358, 'recall': 0.38799, 'f1': 0.51453, 'auc': 0.90194}
2025-08-16 04:46:57,539 - INFO - val: {'epoch': 78, 'time_epoch': 4.3071, 'loss': 0.07191452, 'lr': 0, 'params': 451793, 'time_iter': 0.03339, 'accuracy': 0.98177, 'precision': 0.57895, 'recall': 0.2716, 'f1': 0.36975, 'auc': 0.82813}
2025-08-16 04:47:01,862 - INFO - test: {'epoch': 78, 'time_epoch': 4.30373, 'loss': 0.12392038, 'lr': 0, 'params': 451793, 'time_iter': 0.03336, 'accuracy': 0.96766, 'precision': 0.47945, 'recall': 0.26923, 'f1': 0.34483, 'auc': 0.76535}
2025-08-16 04:47:01,865 - INFO - > Epoch 78: took 77.0s (avg 78.5s) | Best so far: epoch 78	train_loss: 0.0953 train_auc: 0.9019	val_loss: 0.0719 val_auc: 0.8281	test_loss: 0.1239 test_auc: 0.7653
2025-08-16 04:48:09,940 - INFO - train: {'epoch': 79, 'time_epoch': 68.00675, 'eta': 1391.44545, 'eta_hours': 0.38651, 'loss': 0.09592911, 'lr': 1.158e-05, 'params': 451793, 'time_iter': 0.06609, 'accuracy': 0.97228, 'precision': 0.75, 'recall': 0.38961, 'f1': 0.51282, 'auc': 0.90266}
2025-08-16 04:48:14,307 - INFO - val: {'epoch': 79, 'time_epoch': 4.3447, 'loss': 0.07266905, 'lr': 0, 'params': 451793, 'time_iter': 0.03368, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.81776}
2025-08-16 04:48:18,662 - INFO - test: {'epoch': 79, 'time_epoch': 4.33686, 'loss': 0.12152704, 'lr': 0, 'params': 451793, 'time_iter': 0.03362, 'accuracy': 0.97034, 'precision': 0.56452, 'recall': 0.26923, 'f1': 0.36458, 'auc': 0.76796}
2025-08-16 04:48:18,666 - INFO - > Epoch 79: took 76.8s (avg 78.4s) | Best so far: epoch 78	train_loss: 0.0953 train_auc: 0.9019	val_loss: 0.0719 val_auc: 0.8281	test_loss: 0.1239 test_auc: 0.7653
2025-08-16 04:49:26,568 - INFO - train: {'epoch': 80, 'time_epoch': 67.83813, 'eta': 1321.46641, 'eta_hours': 0.36707, 'loss': 0.0952093, 'lr': 1.054e-05, 'params': 451793, 'time_iter': 0.06593, 'accuracy': 0.97207, 'precision': 0.73966, 'recall': 0.39205, 'f1': 0.51247, 'auc': 0.90162}
2025-08-16 04:49:30,815 - INFO - val: {'epoch': 80, 'time_epoch': 4.22508, 'loss': 0.07087306, 'lr': 0, 'params': 451793, 'time_iter': 0.03275, 'accuracy': 0.98249, 'precision': 0.62857, 'recall': 0.2716, 'f1': 0.37931, 'auc': 0.82784}
2025-08-16 04:49:35,102 - INFO - test: {'epoch': 80, 'time_epoch': 4.26744, 'loss': 0.12308906, 'lr': 0, 'params': 451793, 'time_iter': 0.03308, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.23846, 'f1': 0.32292, 'auc': 0.77264}
2025-08-16 04:49:35,105 - INFO - > Epoch 80: took 76.4s (avg 78.4s) | Best so far: epoch 78	train_loss: 0.0953 train_auc: 0.9019	val_loss: 0.0719 val_auc: 0.8281	test_loss: 0.1239 test_auc: 0.7653
2025-08-16 04:50:43,008 - INFO - train: {'epoch': 81, 'time_epoch': 67.8364, 'eta': 1251.5392, 'eta_hours': 0.34765, 'loss': 0.0947126, 'lr': 9.55e-06, 'params': 451793, 'time_iter': 0.06592, 'accuracy': 0.97261, 'precision': 0.75422, 'recall': 0.39854, 'f1': 0.52151, 'auc': 0.89893}
2025-08-16 04:50:47,327 - INFO - val: {'epoch': 81, 'time_epoch': 4.29547, 'loss': 0.07239244, 'lr': 0, 'params': 451793, 'time_iter': 0.0333, 'accuracy': 0.98249, 'precision': 0.63636, 'recall': 0.25926, 'f1': 0.36842, 'auc': 0.81904}
2025-08-16 04:50:51,649 - INFO - test: {'epoch': 81, 'time_epoch': 4.30331, 'loss': 0.12490242, 'lr': 0, 'params': 451793, 'time_iter': 0.03336, 'accuracy': 0.96912, 'precision': 0.52381, 'recall': 0.25385, 'f1': 0.34197, 'auc': 0.76935}
2025-08-16 04:50:51,651 - INFO - > Epoch 81: took 76.5s (avg 78.4s) | Best so far: epoch 78	train_loss: 0.0953 train_auc: 0.9019	val_loss: 0.0719 val_auc: 0.8281	test_loss: 0.1239 test_auc: 0.7653
2025-08-16 04:51:59,404 - INFO - train: {'epoch': 82, 'time_epoch': 67.68573, 'eta': 1181.63151, 'eta_hours': 0.32823, 'loss': 0.09290748, 'lr': 8.6e-06, 'params': 451793, 'time_iter': 0.06578, 'accuracy': 0.9728, 'precision': 0.75725, 'recall': 0.4026, 'f1': 0.5257, 'auc': 0.90736}
2025-08-16 04:52:03,734 - INFO - val: {'epoch': 82, 'time_epoch': 4.30682, 'loss': 0.07260464, 'lr': 0, 'params': 451793, 'time_iter': 0.03339, 'accuracy': 0.98225, 'precision': 0.61765, 'recall': 0.25926, 'f1': 0.36522, 'auc': 0.81903}
2025-08-16 04:52:08,028 - INFO - test: {'epoch': 82, 'time_epoch': 4.27586, 'loss': 0.12460882, 'lr': 0, 'params': 451793, 'time_iter': 0.03315, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.22308, 'f1': 0.30851, 'auc': 0.7668}
2025-08-16 04:52:08,030 - INFO - > Epoch 82: took 76.4s (avg 78.4s) | Best so far: epoch 78	train_loss: 0.0953 train_auc: 0.9019	val_loss: 0.0719 val_auc: 0.8281	test_loss: 0.1239 test_auc: 0.7653
2025-08-16 04:53:15,484 - INFO - train: {'epoch': 83, 'time_epoch': 67.3858, 'eta': 1111.71959, 'eta_hours': 0.30881, 'loss': 0.09445192, 'lr': 7.7e-06, 'params': 451793, 'time_iter': 0.06549, 'accuracy': 0.97231, 'precision': 0.74807, 'recall': 0.39286, 'f1': 0.51517, 'auc': 0.90238}
2025-08-16 04:53:19,804 - INFO - val: {'epoch': 83, 'time_epoch': 4.29677, 'loss': 0.07190751, 'lr': 0, 'params': 451793, 'time_iter': 0.03331, 'accuracy': 0.98201, 'precision': 0.58537, 'recall': 0.2963, 'f1': 0.39344, 'auc': 0.82602}
2025-08-16 04:53:24,128 - INFO - test: {'epoch': 83, 'time_epoch': 4.30662, 'loss': 0.12365162, 'lr': 0, 'params': 451793, 'time_iter': 0.03338, 'accuracy': 0.96815, 'precision': 0.49351, 'recall': 0.29231, 'f1': 0.36715, 'auc': 0.7695}
2025-08-16 04:53:24,131 - INFO - > Epoch 83: took 76.1s (avg 78.3s) | Best so far: epoch 78	train_loss: 0.0953 train_auc: 0.9019	val_loss: 0.0719 val_auc: 0.8281	test_loss: 0.1239 test_auc: 0.7653
2025-08-16 04:54:32,611 - INFO - train: {'epoch': 84, 'time_epoch': 68.41283, 'eta': 1042.04836, 'eta_hours': 0.28946, 'loss': 0.09357283, 'lr': 6.84e-06, 'params': 451793, 'time_iter': 0.06648, 'accuracy': 0.97249, 'precision': 0.74735, 'recall': 0.40097, 'f1': 0.52192, 'auc': 0.90583}
2025-08-16 04:54:37,010 - INFO - val: {'epoch': 84, 'time_epoch': 4.37597, 'loss': 0.07479544, 'lr': 0, 'params': 451793, 'time_iter': 0.03392, 'accuracy': 0.98104, 'precision': 0.53333, 'recall': 0.2963, 'f1': 0.38095, 'auc': 0.81116}
2025-08-16 04:54:41,435 - INFO - test: {'epoch': 84, 'time_epoch': 4.40502, 'loss': 0.126107, 'lr': 0, 'params': 451793, 'time_iter': 0.03415, 'accuracy': 0.96864, 'precision': 0.50588, 'recall': 0.33077, 'f1': 0.4, 'auc': 0.7636}
2025-08-16 04:54:41,438 - INFO - > Epoch 84: took 77.3s (avg 78.3s) | Best so far: epoch 78	train_loss: 0.0953 train_auc: 0.9019	val_loss: 0.0719 val_auc: 0.8281	test_loss: 0.1239 test_auc: 0.7653
2025-08-16 04:55:52,337 - INFO - train: {'epoch': 85, 'time_epoch': 70.8295, 'eta': 972.7998, 'eta_hours': 0.27022, 'loss': 0.09342991, 'lr': 6.03e-06, 'params': 451793, 'time_iter': 0.06883, 'accuracy': 0.97234, 'precision': 0.75078, 'recall': 0.39123, 'f1': 0.51441, 'auc': 0.90771}
2025-08-16 04:55:56,685 - INFO - val: {'epoch': 85, 'time_epoch': 4.3251, 'loss': 0.073201, 'lr': 0, 'params': 451793, 'time_iter': 0.03353, 'accuracy': 0.98249, 'precision': 0.60976, 'recall': 0.30864, 'f1': 0.40984, 'auc': 0.82031}
2025-08-16 04:56:00,997 - INFO - test: {'epoch': 85, 'time_epoch': 4.29269, 'loss': 0.125374, 'lr': 0, 'params': 451793, 'time_iter': 0.03328, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.3, 'f1': 0.375, 'auc': 0.76992}
2025-08-16 04:56:01,000 - INFO - > Epoch 85: took 79.6s (avg 78.4s) | Best so far: epoch 78	train_loss: 0.0953 train_auc: 0.9019	val_loss: 0.0719 val_auc: 0.8281	test_loss: 0.1239 test_auc: 0.7653
2025-08-16 04:57:09,571 - INFO - train: {'epoch': 86, 'time_epoch': 68.50345, 'eta': 903.16733, 'eta_hours': 0.25088, 'loss': 0.09316633, 'lr': 5.26e-06, 'params': 451793, 'time_iter': 0.06657, 'accuracy': 0.97265, 'precision': 0.75152, 'recall': 0.4026, 'f1': 0.52431, 'auc': 0.90193}
2025-08-16 04:57:13,871 - INFO - val: {'epoch': 86, 'time_epoch': 4.27735, 'loss': 0.07265939, 'lr': 0, 'params': 451793, 'time_iter': 0.03316, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.82125}
2025-08-16 04:57:18,067 - INFO - test: {'epoch': 86, 'time_epoch': 4.17907, 'loss': 0.12390161, 'lr': 0, 'params': 451793, 'time_iter': 0.0324, 'accuracy': 0.96912, 'precision': 0.52239, 'recall': 0.26923, 'f1': 0.35533, 'auc': 0.76882}
2025-08-16 04:57:18,070 - INFO - > Epoch 86: took 77.1s (avg 78.3s) | Best so far: epoch 78	train_loss: 0.0953 train_auc: 0.9019	val_loss: 0.0719 val_auc: 0.8281	test_loss: 0.1239 test_auc: 0.7653
2025-08-16 04:58:25,646 - INFO - train: {'epoch': 87, 'time_epoch': 67.50985, 'eta': 833.42502, 'eta_hours': 0.23151, 'loss': 0.09398063, 'lr': 4.55e-06, 'params': 451793, 'time_iter': 0.06561, 'accuracy': 0.97277, 'precision': 0.75378, 'recall': 0.40503, 'f1': 0.52693, 'auc': 0.90626}
2025-08-16 04:58:29,979 - INFO - val: {'epoch': 87, 'time_epoch': 4.31006, 'loss': 0.07217586, 'lr': 0, 'params': 451793, 'time_iter': 0.03341, 'accuracy': 0.98225, 'precision': 0.61111, 'recall': 0.2716, 'f1': 0.37607, 'auc': 0.82298}
2025-08-16 04:58:34,303 - INFO - test: {'epoch': 87, 'time_epoch': 4.30555, 'loss': 0.1228692, 'lr': 0, 'params': 451793, 'time_iter': 0.03338, 'accuracy': 0.96912, 'precision': 0.52308, 'recall': 0.26154, 'f1': 0.34872, 'auc': 0.77108}
2025-08-16 04:58:34,306 - INFO - > Epoch 87: took 76.2s (avg 78.3s) | Best so far: epoch 78	train_loss: 0.0953 train_auc: 0.9019	val_loss: 0.0719 val_auc: 0.8281	test_loss: 0.1239 test_auc: 0.7653
2025-08-16 04:59:42,091 - INFO - train: {'epoch': 88, 'time_epoch': 67.71849, 'eta': 763.75867, 'eta_hours': 0.21216, 'loss': 0.09487066, 'lr': 3.89e-06, 'params': 451793, 'time_iter': 0.06581, 'accuracy': 0.97258, 'precision': 0.76025, 'recall': 0.39123, 'f1': 0.51661, 'auc': 0.89752}
2025-08-16 04:59:46,392 - INFO - val: {'epoch': 88, 'time_epoch': 4.27787, 'loss': 0.07263465, 'lr': 0, 'params': 451793, 'time_iter': 0.03316, 'accuracy': 0.98177, 'precision': 0.57895, 'recall': 0.2716, 'f1': 0.36975, 'auc': 0.82474}
2025-08-16 04:59:50,709 - INFO - test: {'epoch': 88, 'time_epoch': 4.29951, 'loss': 0.12521955, 'lr': 0, 'params': 451793, 'time_iter': 0.03333, 'accuracy': 0.96815, 'precision': 0.49275, 'recall': 0.26154, 'f1': 0.34171, 'auc': 0.77046}
2025-08-16 04:59:50,712 - INFO - > Epoch 88: took 76.4s (avg 78.3s) | Best so far: epoch 78	train_loss: 0.0953 train_auc: 0.9019	val_loss: 0.0719 val_auc: 0.8281	test_loss: 0.1239 test_auc: 0.7653
2025-08-16 05:00:58,637 - INFO - train: {'epoch': 89, 'time_epoch': 67.85757, 'eta': 694.15106, 'eta_hours': 0.19282, 'loss': 0.09296077, 'lr': 3.27e-06, 'params': 451793, 'time_iter': 0.06595, 'accuracy': 0.97201, 'precision': 0.73454, 'recall': 0.39529, 'f1': 0.51398, 'auc': 0.91201}
2025-08-16 05:01:02,946 - INFO - val: {'epoch': 89, 'time_epoch': 4.28743, 'loss': 0.0722817, 'lr': 0, 'params': 451793, 'time_iter': 0.03324, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.82198}
2025-08-16 05:01:07,252 - INFO - test: {'epoch': 89, 'time_epoch': 4.28873, 'loss': 0.1240486, 'lr': 0, 'params': 451793, 'time_iter': 0.03325, 'accuracy': 0.96815, 'precision': 0.49254, 'recall': 0.25385, 'f1': 0.33503, 'auc': 0.76815}
2025-08-16 05:01:07,255 - INFO - > Epoch 89: took 76.5s (avg 78.3s) | Best so far: epoch 78	train_loss: 0.0953 train_auc: 0.9019	val_loss: 0.0719 val_auc: 0.8281	test_loss: 0.1239 test_auc: 0.7653
2025-08-16 05:02:15,622 - INFO - train: {'epoch': 90, 'time_epoch': 68.29768, 'eta': 624.62544, 'eta_hours': 0.17351, 'loss': 0.09132739, 'lr': 2.71e-06, 'params': 451793, 'time_iter': 0.06637, 'accuracy': 0.9731, 'precision': 0.76248, 'recall': 0.40909, 'f1': 0.53249, 'auc': 0.91357}
2025-08-16 05:02:20,000 - INFO - val: {'epoch': 90, 'time_epoch': 4.35537, 'loss': 0.07395899, 'lr': 0, 'params': 451793, 'time_iter': 0.03376, 'accuracy': 0.98128, 'precision': 0.54545, 'recall': 0.2963, 'f1': 0.384, 'auc': 0.81993}
2025-08-16 05:02:24,367 - INFO - test: {'epoch': 90, 'time_epoch': 4.34963, 'loss': 0.12618213, 'lr': 0, 'params': 451793, 'time_iter': 0.03372, 'accuracy': 0.96791, 'precision': 0.4878, 'recall': 0.30769, 'f1': 0.37736, 'auc': 0.76394}
2025-08-16 05:02:24,369 - INFO - > Epoch 90: took 77.1s (avg 78.3s) | Best so far: epoch 78	train_loss: 0.0953 train_auc: 0.9019	val_loss: 0.0719 val_auc: 0.8281	test_loss: 0.1239 test_auc: 0.7653
2025-08-16 05:03:33,214 - INFO - train: {'epoch': 91, 'time_epoch': 68.73702, 'eta': 555.16472, 'eta_hours': 0.15421, 'loss': 0.09515998, 'lr': 2.2e-06, 'params': 451793, 'time_iter': 0.0668, 'accuracy': 0.97213, 'precision': 0.73543, 'recall': 0.39935, 'f1': 0.51762, 'auc': 0.90081}
2025-08-16 05:03:37,585 - INFO - val: {'epoch': 91, 'time_epoch': 4.3481, 'loss': 0.07268898, 'lr': 0, 'params': 451793, 'time_iter': 0.03371, 'accuracy': 0.98201, 'precision': 0.59459, 'recall': 0.2716, 'f1': 0.37288, 'auc': 0.8253}
2025-08-16 05:03:41,958 - INFO - test: {'epoch': 91, 'time_epoch': 4.3551, 'loss': 0.12446274, 'lr': 0, 'params': 451793, 'time_iter': 0.03376, 'accuracy': 0.96815, 'precision': 0.49206, 'recall': 0.23846, 'f1': 0.32124, 'auc': 0.77296}
2025-08-16 05:03:41,960 - INFO - > Epoch 91: took 77.6s (avg 78.3s) | Best so far: epoch 78	train_loss: 0.0953 train_auc: 0.9019	val_loss: 0.0719 val_auc: 0.8281	test_loss: 0.1239 test_auc: 0.7653
2025-08-16 05:04:50,377 - INFO - train: {'epoch': 92, 'time_epoch': 68.34943, 'eta': 485.69039, 'eta_hours': 0.13491, 'loss': 0.09258364, 'lr': 1.74e-06, 'params': 451793, 'time_iter': 0.06642, 'accuracy': 0.97228, 'precision': 0.73952, 'recall': 0.40097, 'f1': 0.52, 'auc': 0.91027}
2025-08-16 05:04:54,727 - INFO - val: {'epoch': 92, 'time_epoch': 4.3264, 'loss': 0.07168939, 'lr': 0, 'params': 451793, 'time_iter': 0.03354, 'accuracy': 0.98152, 'precision': 0.5641, 'recall': 0.2716, 'f1': 0.36667, 'auc': 0.83111}
2025-08-16 05:04:59,066 - INFO - test: {'epoch': 92, 'time_epoch': 4.32152, 'loss': 0.12492536, 'lr': 0, 'params': 451793, 'time_iter': 0.0335, 'accuracy': 0.96791, 'precision': 0.48438, 'recall': 0.23846, 'f1': 0.31959, 'auc': 0.77122}
2025-08-16 05:04:59,069 - INFO - > Epoch 92: took 77.1s (avg 78.2s) | Best so far: epoch 92	train_loss: 0.0926 train_auc: 0.9103	val_loss: 0.0717 val_auc: 0.8311	test_loss: 0.1249 test_auc: 0.7712
2025-08-16 05:06:07,111 - INFO - train: {'epoch': 93, 'time_epoch': 67.97405, 'eta': 416.21603, 'eta_hours': 0.11562, 'loss': 0.09412, 'lr': 1.33e-06, 'params': 451793, 'time_iter': 0.06606, 'accuracy': 0.97356, 'precision': 0.77676, 'recall': 0.41234, 'f1': 0.53871, 'auc': 0.90328}
2025-08-16 05:06:11,461 - INFO - val: {'epoch': 93, 'time_epoch': 4.32694, 'loss': 0.07244511, 'lr': 0, 'params': 451793, 'time_iter': 0.03354, 'accuracy': 0.98177, 'precision': 0.57895, 'recall': 0.2716, 'f1': 0.36975, 'auc': 0.82548}
2025-08-16 05:06:15,769 - INFO - test: {'epoch': 93, 'time_epoch': 4.28985, 'loss': 0.12508127, 'lr': 0, 'params': 451793, 'time_iter': 0.03325, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.26154, 'f1': 0.34343, 'auc': 0.77052}
2025-08-16 05:06:15,771 - INFO - > Epoch 93: took 76.7s (avg 78.2s) | Best so far: epoch 92	train_loss: 0.0926 train_auc: 0.9103	val_loss: 0.0717 val_auc: 0.8311	test_loss: 0.1249 test_auc: 0.7712
2025-08-16 05:07:24,229 - INFO - train: {'epoch': 94, 'time_epoch': 68.38951, 'eta': 346.79512, 'eta_hours': 0.09633, 'loss': 0.09328058, 'lr': 9.8e-07, 'params': 451793, 'time_iter': 0.06646, 'accuracy': 0.97304, 'precision': 0.7594, 'recall': 0.4099, 'f1': 0.53242, 'auc': 0.90636}
2025-08-16 05:07:28,563 - INFO - val: {'epoch': 94, 'time_epoch': 4.31119, 'loss': 0.07205627, 'lr': 0, 'params': 451793, 'time_iter': 0.03342, 'accuracy': 0.98177, 'precision': 0.575, 'recall': 0.28395, 'f1': 0.38017, 'auc': 0.82692}
2025-08-16 05:07:32,897 - INFO - test: {'epoch': 94, 'time_epoch': 4.31656, 'loss': 0.12413106, 'lr': 0, 'params': 451793, 'time_iter': 0.03346, 'accuracy': 0.96791, 'precision': 0.48611, 'recall': 0.26923, 'f1': 0.34653, 'auc': 0.77329}
2025-08-16 05:07:32,900 - INFO - > Epoch 94: took 77.1s (avg 78.2s) | Best so far: epoch 92	train_loss: 0.0926 train_auc: 0.9103	val_loss: 0.0717 val_auc: 0.8311	test_loss: 0.1249 test_auc: 0.7712
2025-08-16 05:08:41,050 - INFO - train: {'epoch': 95, 'time_epoch': 68.082, 'eta': 277.38289, 'eta_hours': 0.07705, 'loss': 0.09318018, 'lr': 6.8e-07, 'params': 451793, 'time_iter': 0.06616, 'accuracy': 0.97271, 'precision': 0.74559, 'recall': 0.41153, 'f1': 0.53033, 'auc': 0.90665}
2025-08-16 05:08:45,394 - INFO - val: {'epoch': 95, 'time_epoch': 4.31922, 'loss': 0.0714427, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.98201, 'precision': 0.59459, 'recall': 0.2716, 'f1': 0.37288, 'auc': 0.82878}
2025-08-16 05:08:49,717 - INFO - test: {'epoch': 95, 'time_epoch': 4.30475, 'loss': 0.12344464, 'lr': 0, 'params': 451793, 'time_iter': 0.03337, 'accuracy': 0.96815, 'precision': 0.49254, 'recall': 0.25385, 'f1': 0.33503, 'auc': 0.77208}
2025-08-16 05:08:49,720 - INFO - > Epoch 95: took 76.8s (avg 78.2s) | Best so far: epoch 92	train_loss: 0.0926 train_auc: 0.9103	val_loss: 0.0717 val_auc: 0.8311	test_loss: 0.1249 test_auc: 0.7712
2025-08-16 05:09:58,290 - INFO - train: {'epoch': 96, 'time_epoch': 68.50106, 'eta': 208.01104, 'eta_hours': 0.05778, 'loss': 0.09390264, 'lr': 4.4e-07, 'params': 451793, 'time_iter': 0.06657, 'accuracy': 0.97219, 'precision': 0.74347, 'recall': 0.39286, 'f1': 0.51407, 'auc': 0.90757}
2025-08-16 05:10:02,642 - INFO - val: {'epoch': 96, 'time_epoch': 4.32812, 'loss': 0.07276745, 'lr': 0, 'params': 451793, 'time_iter': 0.03355, 'accuracy': 0.98128, 'precision': 0.54762, 'recall': 0.28395, 'f1': 0.37398, 'auc': 0.82508}
2025-08-16 05:10:06,982 - INFO - test: {'epoch': 96, 'time_epoch': 4.32103, 'loss': 0.1257699, 'lr': 0, 'params': 451793, 'time_iter': 0.0335, 'accuracy': 0.96864, 'precision': 0.50667, 'recall': 0.29231, 'f1': 0.37073, 'auc': 0.7668}
2025-08-16 05:10:06,985 - INFO - > Epoch 96: took 77.3s (avg 78.2s) | Best so far: epoch 92	train_loss: 0.0926 train_auc: 0.9103	val_loss: 0.0717 val_auc: 0.8311	test_loss: 0.1249 test_auc: 0.7712
2025-08-16 05:11:14,736 - INFO - train: {'epoch': 97, 'time_epoch': 67.6844, 'eta': 138.6403, 'eta_hours': 0.03851, 'loss': 0.09310548, 'lr': 2.5e-07, 'params': 451793, 'time_iter': 0.06578, 'accuracy': 0.97237, 'precision': 0.74213, 'recall': 0.40179, 'f1': 0.52133, 'auc': 0.90897}
2025-08-16 05:11:19,000 - INFO - val: {'epoch': 97, 'time_epoch': 4.24154, 'loss': 0.07200189, 'lr': 0, 'params': 451793, 'time_iter': 0.03288, 'accuracy': 0.98152, 'precision': 0.56098, 'recall': 0.28395, 'f1': 0.37705, 'auc': 0.82777}
2025-08-16 05:11:23,256 - INFO - test: {'epoch': 97, 'time_epoch': 4.23801, 'loss': 0.12480878, 'lr': 0, 'params': 451793, 'time_iter': 0.03285, 'accuracy': 0.96815, 'precision': 0.49315, 'recall': 0.27692, 'f1': 0.35468, 'auc': 0.76971}
2025-08-16 05:11:23,258 - INFO - > Epoch 97: took 76.3s (avg 78.2s) | Best so far: epoch 92	train_loss: 0.0926 train_auc: 0.9103	val_loss: 0.0717 val_auc: 0.8311	test_loss: 0.1249 test_auc: 0.7712
2025-08-16 05:12:30,947 - INFO - train: {'epoch': 98, 'time_epoch': 67.62271, 'eta': 69.303, 'eta_hours': 0.01925, 'loss': 0.09341409, 'lr': 1.1e-07, 'params': 451793, 'time_iter': 0.06572, 'accuracy': 0.97243, 'precision': 0.74218, 'recall': 0.40422, 'f1': 0.52338, 'auc': 0.90755}
2025-08-16 05:12:35,235 - INFO - val: {'epoch': 98, 'time_epoch': 4.26529, 'loss': 0.07173392, 'lr': 0, 'params': 451793, 'time_iter': 0.03306, 'accuracy': 0.98177, 'precision': 0.575, 'recall': 0.28395, 'f1': 0.38017, 'auc': 0.82726}
2025-08-16 05:12:39,504 - INFO - test: {'epoch': 98, 'time_epoch': 4.25069, 'loss': 0.12327944, 'lr': 0, 'params': 451793, 'time_iter': 0.03295, 'accuracy': 0.96937, 'precision': 0.52703, 'recall': 0.3, 'f1': 0.38235, 'auc': 0.77453}
2025-08-16 05:12:39,506 - INFO - > Epoch 98: took 76.2s (avg 78.1s) | Best so far: epoch 92	train_loss: 0.0926 train_auc: 0.9103	val_loss: 0.0717 val_auc: 0.8311	test_loss: 0.1249 test_auc: 0.7712
2025-08-16 05:13:47,750 - INFO - train: {'epoch': 99, 'time_epoch': 68.17642, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.09229601, 'lr': 3e-08, 'params': 451793, 'time_iter': 0.06626, 'accuracy': 0.97368, 'precision': 0.76599, 'recall': 0.42776, 'f1': 0.54896, 'auc': 0.91055}
2025-08-16 05:13:52,106 - INFO - val: {'epoch': 99, 'time_epoch': 4.33312, 'loss': 0.07214171, 'lr': 0, 'params': 451793, 'time_iter': 0.03359, 'accuracy': 0.98152, 'precision': 0.5641, 'recall': 0.2716, 'f1': 0.36667, 'auc': 0.82756}
2025-08-16 05:13:56,460 - INFO - test: {'epoch': 99, 'time_epoch': 4.33541, 'loss': 0.12421133, 'lr': 0, 'params': 451793, 'time_iter': 0.03361, 'accuracy': 0.96766, 'precision': 0.47945, 'recall': 0.26923, 'f1': 0.34483, 'auc': 0.76944}
2025-08-16 05:13:56,832 - INFO - > Epoch 99: took 77.0s (avg 78.1s) | Best so far: epoch 92	train_loss: 0.0926 train_auc: 0.9103	val_loss: 0.0717 val_auc: 0.8311	test_loss: 0.1249 test_auc: 0.7712
2025-08-16 05:13:56,833 - INFO - Avg time per epoch: 78.14s
2025-08-16 05:13:56,833 - INFO - Total train loop time: 2.17h
2025-08-16 05:13:57,179 - INFO - ============================================================
2025-08-16 05:13:57,180 - INFO - Starting PK-Explainer Analysis (Enhanced Version)
2025-08-16 05:13:57,180 - INFO - ============================================================
2025-08-16 05:13:57,180 - INFO - Dataset: ogbg-molhiv
2025-08-16 05:13:57,180 - INFO - Model type: VanillaModel
2025-08-16 05:13:57,180 - INFO - GNN types available: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 05:13:57,222 - INFO - Saved model state to results/molhiv/molhiv-Vanilla-41/model_for_ablation.pt
2025-08-16 05:13:57,223 - INFO - 
Performing ablation study...
2025-08-16 05:13:57,259 - INFO - Getting baseline performance...
2025-08-16 05:13:57,293 - WARNING - Could not extract GNN mapping from optimal weights, attempting to infer from layers...
2025-08-16 05:13:57,293 - INFO - Final GNN mapping: {}
2025-08-16 05:14:02,068 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.75877, 'loss': 0.12421133, 'lr': 0, 'params': 451793, 'time_iter': 0.03689, 'accuracy': 0.96766, 'precision': 0.47945, 'recall': 0.26923, 'f1': 0.34483, 'auc': 0.76944}
2025-08-16 05:14:02,070 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:14:02,070 - INFO - Baseline auc: 0.7694
2025-08-16 05:14:06,454 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33404, 'loss': 0.12400156, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.96791, 'precision': 0.48529, 'recall': 0.25385, 'f1': 0.33333, 'auc': 0.77026}
2025-08-16 05:14:06,456 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:14:06,457 - INFO - Layer 0 (Layer_0), Head 0: drop=-0.0011
2025-08-16 05:14:10,853 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34384, 'loss': 0.12503711, 'lr': 0, 'params': 451793, 'time_iter': 0.03367, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.26154, 'f1': 0.34343, 'auc': 0.76741}
2025-08-16 05:14:10,855 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:10,855 - INFO - Layer 0 (Layer_0), Head 1: drop=0.0026
2025-08-16 05:14:15,248 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34277, 'loss': 0.12415429, 'lr': 0, 'params': 451793, 'time_iter': 0.03366, 'accuracy': 0.96791, 'precision': 0.48684, 'recall': 0.28462, 'f1': 0.35922, 'auc': 0.77085}
2025-08-16 05:14:15,251 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:14:15,251 - INFO - Layer 0 (Layer_0), Head 2: drop=-0.0018
2025-08-16 05:14:19,651 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34999, 'loss': 0.12345313, 'lr': 0, 'params': 451793, 'time_iter': 0.03372, 'accuracy': 0.96791, 'precision': 0.48611, 'recall': 0.26923, 'f1': 0.34653, 'auc': 0.77151}
2025-08-16 05:14:19,653 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:14:19,653 - INFO - Layer 0 (Layer_0), Head 3: drop=-0.0027
2025-08-16 05:14:24,045 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34219, 'loss': 0.12242267, 'lr': 0, 'params': 451793, 'time_iter': 0.03366, 'accuracy': 0.96912, 'precision': 0.52113, 'recall': 0.28462, 'f1': 0.36816, 'auc': 0.77112}
2025-08-16 05:14:24,047 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:24,047 - INFO - Layer 1 (Layer_1), Head 0: drop=-0.0022
2025-08-16 05:14:28,374 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2774, 'loss': 0.12373918, 'lr': 0, 'params': 451793, 'time_iter': 0.03316, 'accuracy': 0.96791, 'precision': 0.48571, 'recall': 0.26154, 'f1': 0.34, 'auc': 0.76823}
2025-08-16 05:14:28,376 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:28,376 - INFO - Layer 1 (Layer_1), Head 1: drop=0.0016
2025-08-16 05:14:32,695 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27005, 'loss': 0.12337046, 'lr': 0, 'params': 451793, 'time_iter': 0.0331, 'accuracy': 0.96815, 'precision': 0.49351, 'recall': 0.29231, 'f1': 0.36715, 'auc': 0.76973}
2025-08-16 05:14:32,698 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:14:32,698 - INFO - Layer 1 (Layer_1), Head 2: drop=-0.0004
2025-08-16 05:14:37,049 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.30233, 'loss': 0.12118948, 'lr': 0, 'params': 451793, 'time_iter': 0.03335, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.26154, 'f1': 0.34343, 'auc': 0.7769}
2025-08-16 05:14:37,051 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:37,051 - INFO - Layer 1 (Layer_1), Head 3: drop=-0.0097
2025-08-16 05:14:41,387 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.28589, 'loss': 0.12419303, 'lr': 0, 'params': 451793, 'time_iter': 0.03322, 'accuracy': 0.96766, 'precision': 0.47887, 'recall': 0.26154, 'f1': 0.33831, 'auc': 0.76732}
2025-08-16 05:14:41,389 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:41,389 - INFO - Layer 2 (Layer_2), Head 0: drop=0.0028
2025-08-16 05:14:45,728 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.28984, 'loss': 0.12378099, 'lr': 0, 'params': 451793, 'time_iter': 0.03325, 'accuracy': 0.96718, 'precision': 0.46835, 'recall': 0.28462, 'f1': 0.35407, 'auc': 0.77165}
2025-08-16 05:14:45,730 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:14:45,730 - INFO - Layer 2 (Layer_2), Head 1: drop=-0.0029
2025-08-16 05:14:50,056 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27513, 'loss': 0.12239586, 'lr': 0, 'params': 451793, 'time_iter': 0.03314, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.28462, 'f1': 0.36275, 'auc': 0.7736}
2025-08-16 05:14:50,058 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:14:50,058 - INFO - Layer 2 (Layer_2), Head 2: drop=-0.0054
2025-08-16 05:14:54,466 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35641, 'loss': 0.12391279, 'lr': 0, 'params': 451793, 'time_iter': 0.03377, 'accuracy': 0.96815, 'precision': 0.49315, 'recall': 0.27692, 'f1': 0.35468, 'auc': 0.76854}
2025-08-16 05:14:54,468 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:14:54,468 - INFO - Layer 2 (Layer_2), Head 3: drop=0.0012
2025-08-16 05:14:58,867 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34838, 'loss': 0.12371807, 'lr': 0, 'params': 451793, 'time_iter': 0.03371, 'accuracy': 0.96766, 'precision': 0.47945, 'recall': 0.26923, 'f1': 0.34483, 'auc': 0.77013}
2025-08-16 05:14:58,869 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:14:58,869 - INFO - Layer 3 (Layer_3), Head 0: drop=-0.0009
2025-08-16 05:15:03,302 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3822, 'loss': 0.12374039, 'lr': 0, 'params': 451793, 'time_iter': 0.03397, 'accuracy': 0.96791, 'precision': 0.48529, 'recall': 0.25385, 'f1': 0.33333, 'auc': 0.77168}
2025-08-16 05:15:03,304 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:15:03,304 - INFO - Layer 3 (Layer_3), Head 1: drop=-0.0029
2025-08-16 05:15:07,713 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35822, 'loss': 0.12340735, 'lr': 0, 'params': 451793, 'time_iter': 0.03378, 'accuracy': 0.96766, 'precision': 0.47945, 'recall': 0.26923, 'f1': 0.34483, 'auc': 0.77476}
2025-08-16 05:15:07,715 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:15:07,715 - INFO - Layer 3 (Layer_3), Head 2: drop=-0.0069
2025-08-16 05:15:12,084 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.31851, 'loss': 0.12285589, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.96815, 'precision': 0.49275, 'recall': 0.26154, 'f1': 0.34171, 'auc': 0.76783}
2025-08-16 05:15:12,086 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:15:12,086 - INFO - Layer 3 (Layer_3), Head 3: drop=0.0021
2025-08-16 05:15:16,488 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35179, 'loss': 0.12351896, 'lr': 0, 'params': 451793, 'time_iter': 0.03373, 'accuracy': 0.96815, 'precision': 0.49315, 'recall': 0.27692, 'f1': 0.35468, 'auc': 0.77131}
2025-08-16 05:15:16,490 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:15:16,490 - INFO - Layer 4 (Layer_4), Head 0: drop=-0.0024
2025-08-16 05:15:20,880 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3406, 'loss': 0.12266143, 'lr': 0, 'params': 451793, 'time_iter': 0.03365, 'accuracy': 0.96864, 'precision': 0.50725, 'recall': 0.26923, 'f1': 0.35176, 'auc': 0.77079}
2025-08-16 05:15:20,882 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:15:20,882 - INFO - Layer 4 (Layer_4), Head 1: drop=-0.0018
2025-08-16 05:15:25,240 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.30887, 'loss': 0.12215316, 'lr': 0, 'params': 451793, 'time_iter': 0.0334, 'accuracy': 0.96864, 'precision': 0.50769, 'recall': 0.25385, 'f1': 0.33846, 'auc': 0.77326}
2025-08-16 05:15:25,242 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:15:25,243 - INFO - Layer 4 (Layer_4), Head 2: drop=-0.0050
2025-08-16 05:15:29,599 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.30713, 'loss': 0.12377992, 'lr': 0, 'params': 451793, 'time_iter': 0.03339, 'accuracy': 0.96864, 'precision': 0.50649, 'recall': 0.3, 'f1': 0.37681, 'auc': 0.76929}
2025-08-16 05:15:29,602 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:15:29,602 - INFO - Layer 4 (Layer_4), Head 3: drop=0.0002
2025-08-16 05:15:33,987 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33494, 'loss': 0.12218081, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.96864, 'precision': 0.50649, 'recall': 0.3, 'f1': 0.37681, 'auc': 0.7708}
2025-08-16 05:15:33,989 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:15:33,989 - INFO - Layer 5 (Layer_5), Head 0: drop=-0.0018
2025-08-16 05:15:38,359 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32006, 'loss': 0.12322415, 'lr': 0, 'params': 451793, 'time_iter': 0.03349, 'accuracy': 0.96815, 'precision': 0.49275, 'recall': 0.26154, 'f1': 0.34171, 'auc': 0.77075}
2025-08-16 05:15:38,361 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:15:38,361 - INFO - Layer 5 (Layer_5), Head 1: drop=-0.0017
2025-08-16 05:15:42,727 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.31659, 'loss': 0.12209293, 'lr': 0, 'params': 451793, 'time_iter': 0.03346, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.27692, 'f1': 0.35644, 'auc': 0.77087}
2025-08-16 05:15:42,729 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:15:42,730 - INFO - Layer 5 (Layer_5), Head 2: drop=-0.0019
2025-08-16 05:15:47,022 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24223, 'loss': 0.12234963, 'lr': 0, 'params': 451793, 'time_iter': 0.03289, 'accuracy': 0.96791, 'precision': 0.48649, 'recall': 0.27692, 'f1': 0.35294, 'auc': 0.77316}
2025-08-16 05:15:47,024 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:15:47,024 - INFO - Layer 5 (Layer_5), Head 3: drop=-0.0048
2025-08-16 05:15:51,315 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24179, 'loss': 0.12186623, 'lr': 0, 'params': 451793, 'time_iter': 0.03288, 'accuracy': 0.96864, 'precision': 0.50704, 'recall': 0.27692, 'f1': 0.35821, 'auc': 0.77219}
2025-08-16 05:15:51,318 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:15:51,318 - INFO - Layer 6 (Layer_6), Head 0: drop=-0.0036
2025-08-16 05:15:55,599 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23174, 'loss': 0.12386023, 'lr': 0, 'params': 451793, 'time_iter': 0.0328, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.28462, 'f1': 0.36275, 'auc': 0.77017}
2025-08-16 05:15:55,601 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:15:55,601 - INFO - Layer 6 (Layer_6), Head 1: drop=-0.0009
2025-08-16 05:15:59,866 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21644, 'loss': 0.1239122, 'lr': 0, 'params': 451793, 'time_iter': 0.03269, 'accuracy': 0.96766, 'precision': 0.47826, 'recall': 0.25385, 'f1': 0.33166, 'auc': 0.76904}
2025-08-16 05:15:59,868 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:15:59,868 - INFO - Layer 6 (Layer_6), Head 2: drop=0.0005
2025-08-16 05:16:04,183 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26505, 'loss': 0.12288215, 'lr': 0, 'params': 451793, 'time_iter': 0.03306, 'accuracy': 0.96815, 'precision': 0.49275, 'recall': 0.26154, 'f1': 0.34171, 'auc': 0.77398}
2025-08-16 05:16:04,184 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:04,184 - INFO - Layer 6 (Layer_6), Head 3: drop=-0.0059
2025-08-16 05:16:08,460 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22698, 'loss': 0.12291047, 'lr': 0, 'params': 451793, 'time_iter': 0.03277, 'accuracy': 0.96791, 'precision': 0.48571, 'recall': 0.26154, 'f1': 0.34, 'auc': 0.7705}
2025-08-16 05:16:08,462 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:08,462 - INFO - Layer 7 (Layer_7), Head 0: drop=-0.0014
2025-08-16 05:16:12,763 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25202, 'loss': 0.12335661, 'lr': 0, 'params': 451793, 'time_iter': 0.03296, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.26923, 'f1': 0.35, 'auc': 0.77183}
2025-08-16 05:16:12,765 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:12,765 - INFO - Layer 7 (Layer_7), Head 1: drop=-0.0031
2025-08-16 05:16:17,066 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25185, 'loss': 0.12293472, 'lr': 0, 'params': 451793, 'time_iter': 0.03296, 'accuracy': 0.96791, 'precision': 0.48485, 'recall': 0.24615, 'f1': 0.32653, 'auc': 0.76916}
2025-08-16 05:16:17,068 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:17,069 - INFO - Layer 7 (Layer_7), Head 2: drop=0.0004
2025-08-16 05:16:21,331 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21296, 'loss': 0.12313935, 'lr': 0, 'params': 451793, 'time_iter': 0.03266, 'accuracy': 0.96766, 'precision': 0.47887, 'recall': 0.26154, 'f1': 0.33831, 'auc': 0.77228}
2025-08-16 05:16:21,333 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:16:21,333 - INFO - Layer 7 (Layer_7), Head 3: drop=-0.0037
2025-08-16 05:16:25,590 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.20718, 'loss': 0.12299206, 'lr': 0, 'params': 451793, 'time_iter': 0.03261, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.25385, 'f1': 0.33673, 'auc': 0.77149}
2025-08-16 05:16:25,591 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:25,591 - INFO - Layer 8 (Layer_8), Head 0: drop=-0.0027
2025-08-16 05:16:29,830 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.18961, 'loss': 0.12243928, 'lr': 0, 'params': 451793, 'time_iter': 0.03248, 'accuracy': 0.96888, 'precision': 0.51562, 'recall': 0.25385, 'f1': 0.34021, 'auc': 0.77196}
2025-08-16 05:16:29,832 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:29,832 - INFO - Layer 8 (Layer_8), Head 1: drop=-0.0033
2025-08-16 05:16:34,132 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25099, 'loss': 0.12309002, 'lr': 0, 'params': 451793, 'time_iter': 0.03295, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.26154, 'f1': 0.34343, 'auc': 0.77221}
2025-08-16 05:16:34,134 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:34,134 - INFO - Layer 8 (Layer_8), Head 2: drop=-0.0036
2025-08-16 05:16:38,410 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22547, 'loss': 0.12290858, 'lr': 0, 'params': 451793, 'time_iter': 0.03276, 'accuracy': 0.96815, 'precision': 0.49275, 'recall': 0.26154, 'f1': 0.34171, 'auc': 0.77073}
2025-08-16 05:16:38,412 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:16:38,413 - INFO - Layer 8 (Layer_8), Head 3: drop=-0.0017
2025-08-16 05:16:42,704 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2403, 'loss': 0.12360889, 'lr': 0, 'params': 451793, 'time_iter': 0.03287, 'accuracy': 0.96791, 'precision': 0.48571, 'recall': 0.26154, 'f1': 0.34, 'auc': 0.77036}
2025-08-16 05:16:42,705 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:16:42,705 - INFO - Layer 9 (Layer_9), Head 0: drop=-0.0012
2025-08-16 05:16:47,030 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27364, 'loss': 0.12276286, 'lr': 0, 'params': 451793, 'time_iter': 0.03313, 'accuracy': 0.96815, 'precision': 0.49254, 'recall': 0.25385, 'f1': 0.33503, 'auc': 0.77316}
2025-08-16 05:16:47,032 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:47,032 - INFO - Layer 9 (Layer_9), Head 1: drop=-0.0048
2025-08-16 05:16:51,333 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25147, 'loss': 0.12287763, 'lr': 0, 'params': 451793, 'time_iter': 0.03296, 'accuracy': 0.96815, 'precision': 0.49231, 'recall': 0.24615, 'f1': 0.32821, 'auc': 0.77215}
2025-08-16 05:16:51,335 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:16:51,336 - INFO - Layer 9 (Layer_9), Head 2: drop=-0.0035
2025-08-16 05:16:55,640 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2546, 'loss': 0.12296764, 'lr': 0, 'params': 451793, 'time_iter': 0.03298, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.26154, 'f1': 0.34343, 'auc': 0.77307}
2025-08-16 05:16:55,642 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:55,642 - INFO - Layer 9 (Layer_9), Head 3: drop=-0.0047
2025-08-16 05:16:59,946 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25556, 'loss': 0.12308624, 'lr': 0, 'params': 451793, 'time_iter': 0.03299, 'accuracy': 0.96791, 'precision': 0.48485, 'recall': 0.24615, 'f1': 0.32653, 'auc': 0.77098}
2025-08-16 05:16:59,949 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:16:59,949 - INFO - Layer 10 (Layer_10), Head 0: drop=-0.0020
2025-08-16 05:17:04,272 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27444, 'loss': 0.12267841, 'lr': 0, 'params': 451793, 'time_iter': 0.03314, 'accuracy': 0.96718, 'precision': 0.46479, 'recall': 0.25385, 'f1': 0.32836, 'auc': 0.77406}
2025-08-16 05:17:04,274 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:04,274 - INFO - Layer 10 (Layer_10), Head 1: drop=-0.0060
2025-08-16 05:17:08,577 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25345, 'loss': 0.12336026, 'lr': 0, 'params': 451793, 'time_iter': 0.03297, 'accuracy': 0.96815, 'precision': 0.49254, 'recall': 0.25385, 'f1': 0.33503, 'auc': 0.76984}
2025-08-16 05:17:08,579 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:08,579 - INFO - Layer 10 (Layer_10), Head 2: drop=-0.0005
2025-08-16 05:17:12,887 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25828, 'loss': 0.12351307, 'lr': 0, 'params': 451793, 'time_iter': 0.03301, 'accuracy': 0.96815, 'precision': 0.49254, 'recall': 0.25385, 'f1': 0.33503, 'auc': 0.76984}
2025-08-16 05:17:12,888 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:12,888 - INFO - Layer 10 (Layer_10), Head 3: drop=-0.0005
2025-08-16 05:17:17,221 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.28209, 'loss': 0.12334834, 'lr': 0, 'params': 451793, 'time_iter': 0.03319, 'accuracy': 0.96815, 'precision': 0.49254, 'recall': 0.25385, 'f1': 0.33503, 'auc': 0.77099}
2025-08-16 05:17:17,223 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:17,223 - INFO - Layer 11 (Layer_11), Head 0: drop=-0.0020
2025-08-16 05:17:21,546 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2733, 'loss': 0.12348924, 'lr': 0, 'params': 451793, 'time_iter': 0.03313, 'accuracy': 0.96766, 'precision': 0.47887, 'recall': 0.26154, 'f1': 0.33831, 'auc': 0.77177}
2025-08-16 05:17:21,547 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:21,547 - INFO - Layer 11 (Layer_11), Head 1: drop=-0.0030
2025-08-16 05:17:25,847 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25026, 'loss': 0.12247272, 'lr': 0, 'params': 451793, 'time_iter': 0.03295, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.25385, 'f1': 0.33673, 'auc': 0.77182}
2025-08-16 05:17:25,849 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:25,850 - INFO - Layer 11 (Layer_11), Head 2: drop=-0.0031
2025-08-16 05:17:30,156 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25631, 'loss': 0.12324874, 'lr': 0, 'params': 451793, 'time_iter': 0.03299, 'accuracy': 0.96815, 'precision': 0.49275, 'recall': 0.26154, 'f1': 0.34171, 'auc': 0.7719}
2025-08-16 05:17:30,159 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:17:30,159 - INFO - Layer 11 (Layer_11), Head 3: drop=-0.0032
2025-08-16 05:17:34,457 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24847, 'loss': 0.12351301, 'lr': 0, 'params': 451793, 'time_iter': 0.03293, 'accuracy': 0.96815, 'precision': 0.49296, 'recall': 0.26923, 'f1': 0.34826, 'auc': 0.77179}
2025-08-16 05:17:34,459 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:34,460 - INFO - Layer 12 (Layer_12), Head 0: drop=-0.0031
2025-08-16 05:17:38,748 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23901, 'loss': 0.12226852, 'lr': 0, 'params': 451793, 'time_iter': 0.03286, 'accuracy': 0.96791, 'precision': 0.48571, 'recall': 0.26154, 'f1': 0.34, 'auc': 0.77139}
2025-08-16 05:17:38,750 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:38,750 - INFO - Layer 12 (Layer_12), Head 1: drop=-0.0025
2025-08-16 05:17:43,033 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23301, 'loss': 0.12310913, 'lr': 0, 'params': 451793, 'time_iter': 0.03281, 'accuracy': 0.96815, 'precision': 0.49254, 'recall': 0.25385, 'f1': 0.33503, 'auc': 0.77227}
2025-08-16 05:17:43,034 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:43,035 - INFO - Layer 12 (Layer_12), Head 2: drop=-0.0037
2025-08-16 05:17:47,254 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.16999, 'loss': 0.12303028, 'lr': 0, 'params': 451793, 'time_iter': 0.03233, 'accuracy': 0.96718, 'precision': 0.46575, 'recall': 0.26154, 'f1': 0.33498, 'auc': 0.77278}
2025-08-16 05:17:47,256 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:47,256 - INFO - Layer 12 (Layer_12), Head 3: drop=-0.0043
2025-08-16 05:17:51,495 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.19017, 'loss': 0.12384375, 'lr': 0, 'params': 451793, 'time_iter': 0.03248, 'accuracy': 0.96791, 'precision': 0.48485, 'recall': 0.24615, 'f1': 0.32653, 'auc': 0.76975}
2025-08-16 05:17:51,498 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:51,498 - INFO - Layer 13 (Layer_13), Head 0: drop=-0.0004
2025-08-16 05:17:55,730 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.18286, 'loss': 0.12364649, 'lr': 0, 'params': 451793, 'time_iter': 0.03243, 'accuracy': 0.96791, 'precision': 0.48529, 'recall': 0.25385, 'f1': 0.33333, 'auc': 0.76982}
2025-08-16 05:17:55,732 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:17:55,732 - INFO - Layer 13 (Layer_13), Head 1: drop=-0.0005
2025-08-16 05:17:59,932 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.15155, 'loss': 0.12350258, 'lr': 0, 'params': 451793, 'time_iter': 0.03218, 'accuracy': 0.96693, 'precision': 0.46053, 'recall': 0.26923, 'f1': 0.33981, 'auc': 0.76978}
2025-08-16 05:17:59,934 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:17:59,934 - INFO - Layer 13 (Layer_13), Head 2: drop=-0.0004
2025-08-16 05:18:04,206 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22345, 'loss': 0.12341816, 'lr': 0, 'params': 451793, 'time_iter': 0.03274, 'accuracy': 0.96718, 'precision': 0.46575, 'recall': 0.26154, 'f1': 0.33498, 'auc': 0.769}
2025-08-16 05:18:04,208 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:18:04,208 - INFO - Layer 13 (Layer_13), Head 3: drop=0.0006
2025-08-16 05:18:08,498 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2403, 'loss': 0.12248112, 'lr': 0, 'params': 451793, 'time_iter': 0.03287, 'accuracy': 0.96815, 'precision': 0.49231, 'recall': 0.24615, 'f1': 0.32821, 'auc': 0.77139}
2025-08-16 05:18:08,500 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:18:08,500 - INFO - Layer 14 (Layer_14), Head 0: drop=-0.0025
2025-08-16 05:18:12,795 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24505, 'loss': 0.12269538, 'lr': 0, 'params': 451793, 'time_iter': 0.03291, 'accuracy': 0.96791, 'precision': 0.48571, 'recall': 0.26154, 'f1': 0.34, 'auc': 0.76871}
2025-08-16 05:18:12,796 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:18:12,796 - INFO - Layer 14 (Layer_14), Head 1: drop=0.0009
2025-08-16 05:18:17,108 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26207, 'loss': 0.12354043, 'lr': 0, 'params': 451793, 'time_iter': 0.03304, 'accuracy': 0.96742, 'precision': 0.47222, 'recall': 0.26154, 'f1': 0.33663, 'auc': 0.7678}
2025-08-16 05:18:17,110 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:18:17,110 - INFO - Layer 14 (Layer_14), Head 2: drop=0.0021
2025-08-16 05:18:21,422 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26211, 'loss': 0.12316069, 'lr': 0, 'params': 451793, 'time_iter': 0.03304, 'accuracy': 0.96766, 'precision': 0.47826, 'recall': 0.25385, 'f1': 0.33166, 'auc': 0.76975}
2025-08-16 05:18:21,424 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 05:18:21,425 - INFO - Layer 14 (Layer_14), Head 3: drop=-0.0004
2025-08-16 05:18:21,428 - INFO - 
FIDELITY METRICS:
2025-08-16 05:18:21,428 - INFO - Fidelity (top 30 heads): -0.0002
2025-08-16 05:18:21,428 - INFO - Fidelity- (bottom 30 heads): -0.0039
2025-08-16 05:18:21,428 - INFO - 
GNN distribution in important heads:
2025-08-16 05:18:21,428 - INFO -   Layer_13: 4 heads
2025-08-16 05:18:21,428 - INFO -   Layer_0: 3 heads
2025-08-16 05:18:21,428 - INFO -   Layer_14: 3 heads
2025-08-16 05:18:21,428 - INFO -   Layer_10: 3 heads
2025-08-16 05:18:21,428 - INFO -   Layer_5: 3 heads
2025-08-16 05:18:21,428 - INFO -   Layer_2: 2 heads
2025-08-16 05:18:21,428 - INFO -   Layer_3: 2 heads
2025-08-16 05:18:21,429 - INFO -   Layer_1: 2 heads
2025-08-16 05:18:21,429 - INFO -   Layer_6: 2 heads
2025-08-16 05:18:21,429 - INFO -   Layer_7: 2 heads
2025-08-16 05:18:21,429 - INFO -   Layer_4: 2 heads
2025-08-16 05:18:21,429 - INFO -   Layer_9: 1 heads
2025-08-16 05:18:21,429 - INFO -   Layer_8: 1 heads
2025-08-16 05:18:21,429 - INFO - 
Interpretability Analysis:
2025-08-16 05:18:21,429 - INFO -   Fidelity: -0.0002
2025-08-16 05:18:21,429 - INFO -   Fidelity-: -0.0039
2025-08-16 05:18:21,429 - INFO -   Total heads tested: 60
2025-08-16 05:18:21,767 - INFO - Excel results saved to results/molhiv/molhiv-Vanilla-41/pk_explainer_results.xlsx
2025-08-16 05:18:23,038 - INFO - Saved visualizations to results/molhiv/molhiv-Vanilla-41/pk_explainer_results
2025-08-16 05:18:23,041 - INFO - 
PK-Explainer results saved to:
2025-08-16 05:18:23,041 - INFO -   - Excel: results/molhiv/molhiv-Vanilla-41/pk_explainer_results.xlsx
2025-08-16 05:18:23,041 - INFO -   - JSON: results/molhiv/molhiv-Vanilla-41/pk_explainer_results.json
2025-08-16 05:18:23,041 - INFO -   - Visualizations: results/molhiv/molhiv-Vanilla-41/pk_explainer_results
2025-08-16 05:18:23,094 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-41
2025-08-16 05:18:23,094 - INFO - Total time: 8145.34s (2.26h)
2025-08-16 05:18:23,151 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-41/agg
2025-08-16 05:18:23,151 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-16 05:18:23,151 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-41
2025-08-16 05:18:23,151 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-41/test_results/
Completed seed 41. Results saved in results/molhiv/molhiv-Vanilla-41
----------------------------------------
Running experiment with seed: 45
Starting training for seed 45...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/confignas.yaml
Using device: cuda
2025-08-16 05:18:34,082 - INFO - GPU Mem: 25.2GB
2025-08-16 05:18:34,082 - INFO - Run directory: results/molhiv/molhiv-Vanilla-45
2025-08-16 05:18:34,082 - INFO - Seed: 45
2025-08-16 05:18:34,082 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-16 05:18:34,082 - INFO - Routing mode: none
2025-08-16 05:18:34,082 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 05:18:34,082 - INFO - Number of layers: 15
2025-08-16 05:18:34,082 - INFO - Uncertainty enabled: False
2025-08-16 05:18:34,082 - INFO - Training mode: custom
2025-08-16 05:18:34,082 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-16 05:18:34,082 - INFO - Additional features: Router weights logging + JSON export
2025-08-16 05:18:40,847 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 05:18:40,850 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 05:18:40,851 - INFO -   undirected: True
2025-08-16 05:18:40,851 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 05:18:40,851 - INFO -   avg num_nodes/graph: 25
2025-08-16 05:18:40,851 - INFO -   num node features: 9
2025-08-16 05:18:40,852 - INFO -   num edge features: 3
2025-08-16 05:18:40,852 - INFO -   num tasks: 1
2025-08-16 05:18:40,852 - INFO -   num classes: 2
2025-08-16 05:18:40,852 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 05:18:40,852 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 05:18:40,855 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 10%|█         | 4202/41127 [00:10<01:27, 420.18it/s] 15%|█▌        | 6319/41127 [00:20<01:57, 296.97it/s] 23%|██▎       | 9282/41127 [00:30<01:47, 296.65it/s] 31%|███       | 12577/41127 [00:40<01:32, 309.60it/s] 36%|███▋      | 14927/41127 [00:50<01:32, 282.04it/s] 41%|████▏     | 16983/41127 [01:02<01:41, 237.46it/s] 50%|█████     | 20632/41127 [01:12<01:14, 276.12it/s] 58%|█████▊    | 23688/41127 [01:22<01:01, 284.72it/s] 66%|██████▌   | 27168/41127 [01:32<00:45, 303.95it/s] 72%|███████▏  | 29763/41127 [01:42<00:39, 290.48it/s] 79%|███████▉  | 32464/41127 [01:52<00:30, 283.43it/s] 85%|████████▍ | 34896/41127 [02:02<00:22, 271.33it/s] 92%|█████████▏| 37801/41127 [02:12<00:12, 277.08it/s] 97%|█████████▋| 39961/41127 [02:22<00:04, 258.73it/s] 97%|█████████▋| 39961/41127 [02:33<00:04, 258.73it/s]100%|█████████▉| 41117/41127 [02:33<00:00, 211.26it/s]100%|██████████| 41127/41127 [02:33<00:00, 268.10it/s]
2025-08-16 05:21:15,387 - INFO - Done! Took 00:02:34.53
2025-08-16 05:21:15,537 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 05:21:15,730 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-16 05:21:15,730 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-08-16 05:21:15,730 - INFO - Inner model has get_darts_model: False
2025-08-16 05:21:15,733 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-08-16 05:21:15,736 - INFO - Number of parameters: 451,793
2025-08-16 05:21:15,736 - INFO - Starting optimized training: 2025-08-16 05:21:15.736214
2025-08-16 05:21:21,539 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 05:21:21,539 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 05:21:21,540 - INFO -   undirected: True
2025-08-16 05:21:21,540 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 05:21:21,541 - INFO -   avg num_nodes/graph: 25
2025-08-16 05:21:21,541 - INFO -   num node features: 9
2025-08-16 05:21:21,541 - INFO -   num edge features: 3
2025-08-16 05:21:21,541 - INFO -   num tasks: 1
2025-08-16 05:21:21,541 - INFO -   num classes: 2
2025-08-16 05:21:21,542 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 05:21:21,542 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 05:21:21,545 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 10%|█         | 4163/41127 [00:10<01:29, 413.12it/s] 15%|█▌        | 6318/41127 [00:20<01:57, 297.16it/s] 22%|██▏       | 8988/41127 [00:30<01:53, 283.39it/s] 30%|██▉       | 12267/41127 [00:40<01:35, 300.94it/s] 36%|███▌      | 14753/41127 [00:50<01:33, 282.05it/s] 41%|████      | 16809/41127 [01:02<01:43, 236.06it/s] 49%|████▉     | 20265/41127 [01:12<01:17, 269.92it/s] 49%|████▉     | 20265/41127 [01:22<01:17, 269.92it/s] 56%|█████▋    | 23186/41127 [01:22<01:05, 275.27it/s] 64%|██████▍   | 26495/41127 [01:32<00:50, 292.14it/s] 71%|███████▏  | 29348/41127 [01:42<00:40, 288.45it/s] 77%|███████▋  | 31588/41127 [01:53<00:35, 268.50it/s] 84%|████████▍ | 34509/41127 [02:03<00:24, 274.13it/s] 89%|████████▉ | 36700/41127 [02:13<00:17, 257.68it/s] 96%|█████████▌| 39394/41127 [02:23<00:06, 261.18it/s]100%|█████████▉| 40947/41127 [02:33<00:00, 229.48it/s]100%|██████████| 41127/41127 [02:36<00:00, 262.54it/s]
2025-08-16 05:23:59,299 - INFO - Done! Took 00:02:37.76
2025-08-16 05:23:59,441 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 05:23:59,538 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-16 05:23:59,538 - INFO - Start from epoch 0
2025-08-16 05:25:15,503 - INFO - train: {'epoch': 0, 'time_epoch': 75.84272, 'eta': 7508.42905, 'eta_hours': 2.08567, 'loss': 0.62549571, 'lr': 0.0, 'params': 451793, 'time_iter': 0.07371, 'accuracy': 0.96222, 'precision': 0.07692, 'recall': 0.00081, 'f1': 0.00161, 'auc': 0.4713}
2025-08-16 05:25:15,544 - INFO - ...computing epoch stats took: 0.14s
2025-08-16 05:25:20,806 - INFO - val: {'epoch': 0, 'time_epoch': 5.24483, 'loss': 0.62598024, 'lr': 0, 'params': 451793, 'time_iter': 0.04066, 'accuracy': 0.98006, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.43285}
2025-08-16 05:25:20,850 - INFO - ...computing epoch stats took: 0.06s
2025-08-16 05:25:25,732 - INFO - test: {'epoch': 0, 'time_epoch': 4.86396, 'loss': 0.62910126, 'lr': 0, 'params': 451793, 'time_iter': 0.03771, 'accuracy': 0.96815, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.41876}
2025-08-16 05:25:25,752 - INFO - ...computing epoch stats took: 0.03s
2025-08-16 05:25:25,753 - INFO - > Epoch 0: took 86.2s (avg 86.2s) | Best so far: epoch 0	train_loss: 0.6255 train_auc: 0.4713	val_loss: 0.6260 val_auc: 0.4329	test_loss: 0.6291 test_auc: 0.4188
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:26:35,543 - INFO - train: {'epoch': 1, 'time_epoch': 69.70942, 'eta': 7132.05456, 'eta_hours': 1.98113, 'loss': 0.49412674, 'lr': 2e-05, 'params': 451793, 'time_iter': 0.06774, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.51119}
2025-08-16 05:26:35,552 - INFO - ...computing epoch stats took: 0.07s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:26:39,858 - INFO - val: {'epoch': 1, 'time_epoch': 4.28995, 'loss': 0.31098767, 'lr': 0, 'params': 451793, 'time_iter': 0.03326, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.51661}
2025-08-16 05:26:39,861 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:26:44,147 - INFO - test: {'epoch': 1, 'time_epoch': 4.27143, 'loss': 0.31454738, 'lr': 0, 'params': 451793, 'time_iter': 0.03311, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.50504}
2025-08-16 05:26:44,150 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:26:44,150 - INFO - > Epoch 1: took 78.4s (avg 82.3s) | Best so far: epoch 1	train_loss: 0.4941 train_auc: 0.5112	val_loss: 0.3110 val_auc: 0.5166	test_loss: 0.3145 test_auc: 0.5050
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:27:54,530 - INFO - train: {'epoch': 2, 'time_epoch': 70.30618, 'eta': 6979.4188, 'eta_hours': 1.93873, 'loss': 0.21067856, 'lr': 4e-05, 'params': 451793, 'time_iter': 0.06832, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.55243}
2025-08-16 05:27:54,537 - INFO - ...computing epoch stats took: 0.06s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:27:58,624 - INFO - val: {'epoch': 2, 'time_epoch': 4.07219, 'loss': 0.10837078, 'lr': 0, 'params': 451793, 'time_iter': 0.03157, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.62022}
2025-08-16 05:27:58,627 - INFO - ...computing epoch stats took: 0.01s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:28:02,742 - INFO - test: {'epoch': 2, 'time_epoch': 4.10043, 'loss': 0.14763972, 'lr': 0, 'params': 451793, 'time_iter': 0.03179, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6161}
2025-08-16 05:28:02,744 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 05:28:02,745 - INFO - > Epoch 2: took 78.6s (avg 81.1s) | Best so far: epoch 2	train_loss: 0.2107 train_auc: 0.5524	val_loss: 0.1084 val_auc: 0.6202	test_loss: 0.1476 test_auc: 0.6161
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:29:12,608 - INFO - train: {'epoch': 3, 'time_epoch': 69.7908, 'eta': 6855.5788, 'eta_hours': 1.90433, 'loss': 0.15962133, 'lr': 6e-05, 'params': 451793, 'time_iter': 0.06782, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.60866}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:29:17,086 - INFO - val: {'epoch': 3, 'time_epoch': 4.45563, 'loss': 0.10074518, 'lr': 0, 'params': 451793, 'time_iter': 0.03454, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.61518}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:29:21,537 - INFO - test: {'epoch': 3, 'time_epoch': 4.43268, 'loss': 0.13923057, 'lr': 0, 'params': 451793, 'time_iter': 0.03436, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6382}
2025-08-16 05:29:21,539 - INFO - > Epoch 3: took 78.8s (avg 80.5s) | Best so far: epoch 2	train_loss: 0.2107 train_auc: 0.5524	val_loss: 0.1084 val_auc: 0.6202	test_loss: 0.1476 test_auc: 0.6161
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:30:32,624 - INFO - train: {'epoch': 4, 'time_epoch': 71.01412, 'eta': 6776.6015, 'eta_hours': 1.88239, 'loss': 0.1529517, 'lr': 8e-05, 'params': 451793, 'time_iter': 0.06901, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.65149}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:30:36,903 - INFO - val: {'epoch': 4, 'time_epoch': 4.2575, 'loss': 0.09393387, 'lr': 0, 'params': 451793, 'time_iter': 0.033, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67784}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:30:41,274 - INFO - test: {'epoch': 4, 'time_epoch': 4.267, 'loss': 0.13199944, 'lr': 0, 'params': 451793, 'time_iter': 0.03308, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68154}
2025-08-16 05:30:41,347 - INFO - > Epoch 4: took 79.8s (avg 80.4s) | Best so far: epoch 4	train_loss: 0.1530 train_auc: 0.6515	val_loss: 0.0939 val_auc: 0.6778	test_loss: 0.1320 test_auc: 0.6815
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:31:51,703 - INFO - train: {'epoch': 5, 'time_epoch': 70.28321, 'eta': 6688.82766, 'eta_hours': 1.85801, 'loss': 0.14951486, 'lr': 0.0001, 'params': 451793, 'time_iter': 0.0683, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68057}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:31:56,196 - INFO - val: {'epoch': 5, 'time_epoch': 4.468, 'loss': 0.09368554, 'lr': 0, 'params': 451793, 'time_iter': 0.03464, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69188}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:32:00,758 - INFO - test: {'epoch': 5, 'time_epoch': 4.54237, 'loss': 0.13054103, 'lr': 0, 'params': 451793, 'time_iter': 0.03521, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71564}
2025-08-16 05:32:00,762 - INFO - > Epoch 5: took 79.4s (avg 80.2s) | Best so far: epoch 5	train_loss: 0.1495 train_auc: 0.6806	val_loss: 0.0937 val_auc: 0.6919	test_loss: 0.1305 test_auc: 0.7156
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:33:10,753 - INFO - train: {'epoch': 6, 'time_epoch': 69.91715, 'eta': 6601.18781, 'eta_hours': 1.83366, 'loss': 0.14452294, 'lr': 9.997e-05, 'params': 451793, 'time_iter': 0.06795, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71274}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:33:15,269 - INFO - val: {'epoch': 6, 'time_epoch': 4.49116, 'loss': 0.09345897, 'lr': 0, 'params': 451793, 'time_iter': 0.03482, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70134}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:33:19,783 - INFO - test: {'epoch': 6, 'time_epoch': 4.49556, 'loss': 0.12761009, 'lr': 0, 'params': 451793, 'time_iter': 0.03485, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74859}
2025-08-16 05:33:19,785 - INFO - > Epoch 6: took 79.0s (avg 80.0s) | Best so far: epoch 6	train_loss: 0.1445 train_auc: 0.7127	val_loss: 0.0935 val_auc: 0.7013	test_loss: 0.1276 test_auc: 0.7486
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:34:29,816 - INFO - train: {'epoch': 7, 'time_epoch': 69.95738, 'eta': 6518.44125, 'eta_hours': 1.81068, 'loss': 0.14315651, 'lr': 9.989e-05, 'params': 451793, 'time_iter': 0.06799, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72228}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:34:34,150 - INFO - val: {'epoch': 7, 'time_epoch': 4.31293, 'loss': 0.09347329, 'lr': 0, 'params': 451793, 'time_iter': 0.03343, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71503}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:34:38,465 - INFO - test: {'epoch': 7, 'time_epoch': 4.29414, 'loss': 0.13354025, 'lr': 0, 'params': 451793, 'time_iter': 0.03329, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72721}
2025-08-16 05:34:38,467 - INFO - > Epoch 7: took 78.7s (avg 79.9s) | Best so far: epoch 7	train_loss: 0.1432 train_auc: 0.7223	val_loss: 0.0935 val_auc: 0.7150	test_loss: 0.1335 test_auc: 0.7272
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:35:48,262 - INFO - train: {'epoch': 8, 'time_epoch': 69.72291, 'eta': 6436.16601, 'eta_hours': 1.78782, 'loss': 0.14123746, 'lr': 9.975e-05, 'params': 451793, 'time_iter': 0.06776, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73418}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:35:52,516 - INFO - val: {'epoch': 8, 'time_epoch': 4.2313, 'loss': 0.09132923, 'lr': 0, 'params': 451793, 'time_iter': 0.0328, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73089}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:35:56,759 - INFO - test: {'epoch': 8, 'time_epoch': 4.22616, 'loss': 0.1235198, 'lr': 0, 'params': 451793, 'time_iter': 0.03276, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7476}
2025-08-16 05:35:56,761 - INFO - > Epoch 8: took 78.3s (avg 79.7s) | Best so far: epoch 8	train_loss: 0.1412 train_auc: 0.7342	val_loss: 0.0913 val_auc: 0.7309	test_loss: 0.1235 test_auc: 0.7476
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:37:05,167 - INFO - train: {'epoch': 9, 'time_epoch': 68.33033, 'eta': 6343.86797, 'eta_hours': 1.76219, 'loss': 0.13963434, 'lr': 9.956e-05, 'params': 451793, 'time_iter': 0.0664, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74148}
2025-08-16 05:37:09,589 - INFO - val: {'epoch': 9, 'time_epoch': 4.39432, 'loss': 0.08738317, 'lr': 0, 'params': 451793, 'time_iter': 0.03406, 'accuracy': 0.98055, 'precision': 1.0, 'recall': 0.01235, 'f1': 0.02439, 'auc': 0.72693}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:37:14,023 - INFO - test: {'epoch': 9, 'time_epoch': 4.41629, 'loss': 0.12017674, 'lr': 0, 'params': 451793, 'time_iter': 0.03423, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74473}
2025-08-16 05:37:14,025 - INFO - > Epoch 9: took 77.3s (avg 79.4s) | Best so far: epoch 8	train_loss: 0.1412 train_auc: 0.7342	val_loss: 0.0913 val_auc: 0.7309	test_loss: 0.1235 test_auc: 0.7476
2025-08-16 05:38:24,505 - INFO - train: {'epoch': 10, 'time_epoch': 70.38571, 'eta': 6272.55764, 'eta_hours': 1.74238, 'loss': 0.13780239, 'lr': 9.932e-05, 'params': 451793, 'time_iter': 0.0684, 'accuracy': 0.96243, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75155}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:38:28,792 - INFO - val: {'epoch': 10, 'time_epoch': 4.26347, 'loss': 0.08486061, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74981}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 05:38:33,080 - INFO - test: {'epoch': 10, 'time_epoch': 4.27069, 'loss': 0.12578166, 'lr': 0, 'params': 451793, 'time_iter': 0.03311, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74236}
2025-08-16 05:38:33,083 - INFO - > Epoch 10: took 79.1s (avg 79.4s) | Best so far: epoch 10	train_loss: 0.1378 train_auc: 0.7516	val_loss: 0.0849 val_auc: 0.7498	test_loss: 0.1258 test_auc: 0.7424
2025-08-16 05:39:43,996 - INFO - train: {'epoch': 11, 'time_epoch': 70.83242, 'eta': 6204.67722, 'eta_hours': 1.72352, 'loss': 0.13555549, 'lr': 9.902e-05, 'params': 451793, 'time_iter': 0.06884, 'accuracy': 0.96258, 'precision': 0.50943, 'recall': 0.02192, 'f1': 0.04202, 'auc': 0.75794}
2025-08-16 05:39:48,302 - INFO - val: {'epoch': 11, 'time_epoch': 4.28281, 'loss': 0.084529, 'lr': 0, 'params': 451793, 'time_iter': 0.0332, 'accuracy': 0.98079, 'precision': 0.75, 'recall': 0.03704, 'f1': 0.07059, 'auc': 0.74511}
2025-08-16 05:39:52,537 - INFO - test: {'epoch': 11, 'time_epoch': 4.21733, 'loss': 0.11945437, 'lr': 0, 'params': 451793, 'time_iter': 0.03269, 'accuracy': 0.97082, 'precision': 0.85714, 'recall': 0.09231, 'f1': 0.16667, 'auc': 0.75365}
2025-08-16 05:39:52,539 - INFO - > Epoch 11: took 79.5s (avg 79.4s) | Best so far: epoch 10	train_loss: 0.1378 train_auc: 0.7516	val_loss: 0.0849 val_auc: 0.7498	test_loss: 0.1258 test_auc: 0.7424
2025-08-16 05:41:02,267 - INFO - train: {'epoch': 12, 'time_epoch': 69.63498, 'eta': 6128.32903, 'eta_hours': 1.70231, 'loss': 0.13382676, 'lr': 9.867e-05, 'params': 451793, 'time_iter': 0.06767, 'accuracy': 0.96344, 'precision': 0.63551, 'recall': 0.05519, 'f1': 0.10157, 'auc': 0.76706}
2025-08-16 05:41:06,737 - INFO - val: {'epoch': 12, 'time_epoch': 4.44607, 'loss': 0.08293083, 'lr': 0, 'params': 451793, 'time_iter': 0.03447, 'accuracy': 0.98079, 'precision': 0.58333, 'recall': 0.08642, 'f1': 0.15054, 'auc': 0.76057}
2025-08-16 05:41:11,221 - INFO - test: {'epoch': 12, 'time_epoch': 4.46482, 'loss': 0.12176519, 'lr': 0, 'params': 451793, 'time_iter': 0.03461, 'accuracy': 0.97009, 'precision': 0.76923, 'recall': 0.07692, 'f1': 0.13986, 'auc': 0.74017}
2025-08-16 05:41:11,223 - INFO - > Epoch 12: took 78.7s (avg 79.4s) | Best so far: epoch 12	train_loss: 0.1338 train_auc: 0.7671	val_loss: 0.0829 val_auc: 0.7606	test_loss: 0.1218 test_auc: 0.7402
2025-08-16 05:42:21,798 - INFO - train: {'epoch': 13, 'time_epoch': 70.49065, 'eta': 6058.19617, 'eta_hours': 1.68283, 'loss': 0.13108396, 'lr': 9.826e-05, 'params': 451793, 'time_iter': 0.0685, 'accuracy': 0.96413, 'precision': 0.64943, 'recall': 0.09172, 'f1': 0.16074, 'auc': 0.7817}
2025-08-16 05:42:26,086 - INFO - val: {'epoch': 13, 'time_epoch': 4.26404, 'loss': 0.0846452, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.98055, 'precision': 0.52941, 'recall': 0.11111, 'f1': 0.18367, 'auc': 0.763}
2025-08-16 05:42:30,360 - INFO - test: {'epoch': 13, 'time_epoch': 4.25263, 'loss': 0.11800463, 'lr': 0, 'params': 451793, 'time_iter': 0.03297, 'accuracy': 0.97058, 'precision': 0.69565, 'recall': 0.12308, 'f1': 0.20915, 'auc': 0.76084}
2025-08-16 05:42:30,363 - INFO - > Epoch 13: took 79.1s (avg 79.3s) | Best so far: epoch 13	train_loss: 0.1311 train_auc: 0.7817	val_loss: 0.0846 val_auc: 0.7630	test_loss: 0.1180 test_auc: 0.7608
2025-08-16 05:43:39,740 - INFO - train: {'epoch': 14, 'time_epoch': 69.29123, 'eta': 5981.21885, 'eta_hours': 1.66145, 'loss': 0.13143301, 'lr': 9.78e-05, 'params': 451793, 'time_iter': 0.06734, 'accuracy': 0.96395, 'precision': 0.61979, 'recall': 0.09659, 'f1': 0.16713, 'auc': 0.77817}
2025-08-16 05:43:44,175 - INFO - val: {'epoch': 14, 'time_epoch': 4.41139, 'loss': 0.08383841, 'lr': 0, 'params': 451793, 'time_iter': 0.0342, 'accuracy': 0.98128, 'precision': 0.6, 'recall': 0.14815, 'f1': 0.23762, 'auc': 0.77461}
2025-08-16 05:43:48,591 - INFO - test: {'epoch': 14, 'time_epoch': 4.39678, 'loss': 0.11961437, 'lr': 0, 'params': 451793, 'time_iter': 0.03408, 'accuracy': 0.96742, 'precision': 0.38889, 'recall': 0.05385, 'f1': 0.09459, 'auc': 0.76094}
2025-08-16 05:43:48,594 - INFO - > Epoch 14: took 78.2s (avg 79.3s) | Best so far: epoch 14	train_loss: 0.1314 train_auc: 0.7782	val_loss: 0.0838 val_auc: 0.7746	test_loss: 0.1196 test_auc: 0.7609
2025-08-16 05:44:58,490 - INFO - train: {'epoch': 15, 'time_epoch': 69.8103, 'eta': 5907.92739, 'eta_hours': 1.64109, 'loss': 0.1295687, 'lr': 9.729e-05, 'params': 451793, 'time_iter': 0.06784, 'accuracy': 0.9642, 'precision': 0.62617, 'recall': 0.10877, 'f1': 0.18534, 'auc': 0.78833}
2025-08-16 05:45:02,879 - INFO - val: {'epoch': 15, 'time_epoch': 4.36524, 'loss': 0.08306716, 'lr': 0, 'params': 451793, 'time_iter': 0.03384, 'accuracy': 0.97982, 'precision': 0.46429, 'recall': 0.16049, 'f1': 0.23853, 'auc': 0.75124}
2025-08-16 05:45:07,364 - INFO - test: {'epoch': 15, 'time_epoch': 4.46632, 'loss': 0.11819824, 'lr': 0, 'params': 451793, 'time_iter': 0.03462, 'accuracy': 0.96937, 'precision': 0.53846, 'recall': 0.21538, 'f1': 0.30769, 'auc': 0.76887}
2025-08-16 05:45:07,367 - INFO - > Epoch 15: took 78.8s (avg 79.2s) | Best so far: epoch 14	train_loss: 0.1314 train_auc: 0.7782	val_loss: 0.0838 val_auc: 0.7746	test_loss: 0.1196 test_auc: 0.7609
2025-08-16 05:46:17,666 - INFO - train: {'epoch': 16, 'time_epoch': 70.21039, 'eta': 5836.99888, 'eta_hours': 1.62139, 'loss': 0.12721528, 'lr': 9.673e-05, 'params': 451793, 'time_iter': 0.06823, 'accuracy': 0.96389, 'precision': 0.58594, 'recall': 0.12175, 'f1': 0.20161, 'auc': 0.79933}
2025-08-16 05:46:22,290 - INFO - val: {'epoch': 16, 'time_epoch': 4.47868, 'loss': 0.08600406, 'lr': 0, 'params': 451793, 'time_iter': 0.03472, 'accuracy': 0.98006, 'precision': 0.47619, 'recall': 0.12346, 'f1': 0.19608, 'auc': 0.72037}
2025-08-16 05:46:26,788 - INFO - test: {'epoch': 16, 'time_epoch': 4.48003, 'loss': 0.12634075, 'lr': 0, 'params': 451793, 'time_iter': 0.03473, 'accuracy': 0.96985, 'precision': 0.625, 'recall': 0.11538, 'f1': 0.19481, 'auc': 0.72481}
2025-08-16 05:46:26,791 - INFO - > Epoch 16: took 79.4s (avg 79.2s) | Best so far: epoch 14	train_loss: 0.1314 train_auc: 0.7782	val_loss: 0.0838 val_auc: 0.7746	test_loss: 0.1196 test_auc: 0.7609
2025-08-16 05:47:38,640 - INFO - train: {'epoch': 17, 'time_epoch': 71.7652, 'eta': 5773.23319, 'eta_hours': 1.60368, 'loss': 0.12760821, 'lr': 9.611e-05, 'params': 451793, 'time_iter': 0.06974, 'accuracy': 0.96392, 'precision': 0.58491, 'recall': 0.12581, 'f1': 0.20708, 'auc': 0.79434}
2025-08-16 05:47:42,800 - INFO - val: {'epoch': 17, 'time_epoch': 4.13695, 'loss': 0.08468051, 'lr': 0, 'params': 451793, 'time_iter': 0.03207, 'accuracy': 0.98055, 'precision': 0.51852, 'recall': 0.17284, 'f1': 0.25926, 'auc': 0.76188}
2025-08-16 05:47:47,081 - INFO - test: {'epoch': 17, 'time_epoch': 4.26299, 'loss': 0.11794972, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.97058, 'precision': 0.58491, 'recall': 0.23846, 'f1': 0.3388, 'auc': 0.76837}
2025-08-16 05:47:47,083 - INFO - > Epoch 17: took 80.3s (avg 79.3s) | Best so far: epoch 14	train_loss: 0.1314 train_auc: 0.7782	val_loss: 0.0838 val_auc: 0.7746	test_loss: 0.1196 test_auc: 0.7609
2025-08-16 05:48:56,262 - INFO - train: {'epoch': 18, 'time_epoch': 69.08659, 'eta': 5697.20612, 'eta_hours': 1.58256, 'loss': 0.12694743, 'lr': 9.545e-05, 'params': 451793, 'time_iter': 0.06714, 'accuracy': 0.96359, 'precision': 0.56071, 'recall': 0.12744, 'f1': 0.20767, 'auc': 0.79849}
2025-08-16 05:49:00,528 - INFO - val: {'epoch': 18, 'time_epoch': 4.23937, 'loss': 0.07773872, 'lr': 0, 'params': 451793, 'time_iter': 0.03286, 'accuracy': 0.98104, 'precision': 0.56, 'recall': 0.17284, 'f1': 0.26415, 'auc': 0.78823}
2025-08-16 05:49:04,715 - INFO - test: {'epoch': 18, 'time_epoch': 4.16904, 'loss': 0.1141938, 'lr': 0, 'params': 451793, 'time_iter': 0.03232, 'accuracy': 0.97058, 'precision': 0.63636, 'recall': 0.16154, 'f1': 0.25767, 'auc': 0.7744}
2025-08-16 05:49:04,717 - INFO - > Epoch 18: took 77.6s (avg 79.2s) | Best so far: epoch 18	train_loss: 0.1269 train_auc: 0.7985	val_loss: 0.0777 val_auc: 0.7882	test_loss: 0.1142 test_auc: 0.7744
2025-08-16 05:50:11,807 - INFO - train: {'epoch': 19, 'time_epoch': 67.0008, 'eta': 5613.52992, 'eta_hours': 1.55931, 'loss': 0.12654006, 'lr': 9.474e-05, 'params': 451793, 'time_iter': 0.06511, 'accuracy': 0.96459, 'precision': 0.62835, 'recall': 0.13312, 'f1': 0.21969, 'auc': 0.80053}
2025-08-16 05:50:15,964 - INFO - val: {'epoch': 19, 'time_epoch': 4.13453, 'loss': 0.08584779, 'lr': 0, 'params': 451793, 'time_iter': 0.03205, 'accuracy': 0.98177, 'precision': 0.57143, 'recall': 0.2963, 'f1': 0.39024, 'auc': 0.75853}
2025-08-16 05:50:20,085 - INFO - test: {'epoch': 19, 'time_epoch': 4.10289, 'loss': 0.11960742, 'lr': 0, 'params': 451793, 'time_iter': 0.03181, 'accuracy': 0.96864, 'precision': 0.50704, 'recall': 0.27692, 'f1': 0.35821, 'auc': 0.7614}
2025-08-16 05:50:20,087 - INFO - > Epoch 19: took 75.4s (avg 79.0s) | Best so far: epoch 18	train_loss: 0.1269 train_auc: 0.7985	val_loss: 0.0777 val_auc: 0.7882	test_loss: 0.1142 test_auc: 0.7744
2025-08-16 05:51:27,537 - INFO - train: {'epoch': 20, 'time_epoch': 67.36789, 'eta': 5532.82281, 'eta_hours': 1.5369, 'loss': 0.1255593, 'lr': 9.397e-05, 'params': 451793, 'time_iter': 0.06547, 'accuracy': 0.96456, 'precision': 0.61224, 'recall': 0.1461, 'f1': 0.23591, 'auc': 0.80009}
2025-08-16 05:51:31,655 - INFO - val: {'epoch': 20, 'time_epoch': 4.09593, 'loss': 0.07933224, 'lr': 0, 'params': 451793, 'time_iter': 0.03175, 'accuracy': 0.98079, 'precision': 0.55, 'recall': 0.1358, 'f1': 0.21782, 'auc': 0.77491}
2025-08-16 05:51:35,770 - INFO - test: {'epoch': 20, 'time_epoch': 4.09851, 'loss': 0.11847563, 'lr': 0, 'params': 451793, 'time_iter': 0.03177, 'accuracy': 0.96888, 'precision': 0.57143, 'recall': 0.06154, 'f1': 0.11111, 'auc': 0.76085}
2025-08-16 05:51:35,773 - INFO - > Epoch 20: took 75.7s (avg 78.9s) | Best so far: epoch 18	train_loss: 0.1269 train_auc: 0.7985	val_loss: 0.0777 val_auc: 0.7882	test_loss: 0.1142 test_auc: 0.7744
2025-08-16 05:52:44,224 - INFO - train: {'epoch': 21, 'time_epoch': 68.36854, 'eta': 5456.87612, 'eta_hours': 1.5158, 'loss': 0.12422601, 'lr': 9.316e-05, 'params': 451793, 'time_iter': 0.06644, 'accuracy': 0.9645, 'precision': 0.6039, 'recall': 0.15097, 'f1': 0.24156, 'auc': 0.80508}
2025-08-16 05:52:48,450 - INFO - val: {'epoch': 21, 'time_epoch': 4.19839, 'loss': 0.07965216, 'lr': 0, 'params': 451793, 'time_iter': 0.03255, 'accuracy': 0.98177, 'precision': 0.575, 'recall': 0.28395, 'f1': 0.38017, 'auc': 0.77105}
2025-08-16 05:52:52,691 - INFO - test: {'epoch': 21, 'time_epoch': 4.2205, 'loss': 0.11939425, 'lr': 0, 'params': 451793, 'time_iter': 0.03272, 'accuracy': 0.96815, 'precision': 0.49231, 'recall': 0.24615, 'f1': 0.32821, 'auc': 0.76465}
2025-08-16 05:52:52,695 - INFO - > Epoch 21: took 76.9s (avg 78.8s) | Best so far: epoch 18	train_loss: 0.1269 train_auc: 0.7985	val_loss: 0.0777 val_auc: 0.7882	test_loss: 0.1142 test_auc: 0.7744
2025-08-16 05:53:59,752 - INFO - train: {'epoch': 22, 'time_epoch': 66.97057, 'eta': 5376.90826, 'eta_hours': 1.49359, 'loss': 0.12353634, 'lr': 9.23e-05, 'params': 451793, 'time_iter': 0.06508, 'accuracy': 0.96444, 'precision': 0.59627, 'recall': 0.15584, 'f1': 0.2471, 'auc': 0.81104}
2025-08-16 05:54:04,085 - INFO - val: {'epoch': 22, 'time_epoch': 4.30912, 'loss': 0.07657511, 'lr': 0, 'params': 451793, 'time_iter': 0.0334, 'accuracy': 0.98274, 'precision': 0.63889, 'recall': 0.28395, 'f1': 0.39316, 'auc': 0.78607}
2025-08-16 05:54:08,360 - INFO - test: {'epoch': 22, 'time_epoch': 4.25732, 'loss': 0.11676556, 'lr': 0, 'params': 451793, 'time_iter': 0.033, 'accuracy': 0.96766, 'precision': 0.4717, 'recall': 0.19231, 'f1': 0.27322, 'auc': 0.77638}
2025-08-16 05:54:08,363 - INFO - > Epoch 22: took 75.7s (avg 78.6s) | Best so far: epoch 18	train_loss: 0.1269 train_auc: 0.7985	val_loss: 0.0777 val_auc: 0.7882	test_loss: 0.1142 test_auc: 0.7744
2025-08-16 05:55:19,366 - INFO - train: {'epoch': 23, 'time_epoch': 70.91356, 'eta': 5310.50963, 'eta_hours': 1.47514, 'loss': 0.12282246, 'lr': 9.14e-05, 'params': 451793, 'time_iter': 0.06892, 'accuracy': 0.9648, 'precision': 0.61709, 'recall': 0.15828, 'f1': 0.25194, 'auc': 0.80943}
2025-08-16 05:55:23,633 - INFO - val: {'epoch': 23, 'time_epoch': 4.24308, 'loss': 0.073505, 'lr': 0, 'params': 451793, 'time_iter': 0.03289, 'accuracy': 0.98371, 'precision': 0.71875, 'recall': 0.28395, 'f1': 0.40708, 'auc': 0.79613}
2025-08-16 05:55:27,888 - INFO - test: {'epoch': 23, 'time_epoch': 4.23631, 'loss': 0.11327959, 'lr': 0, 'params': 451793, 'time_iter': 0.03284, 'accuracy': 0.97107, 'precision': 0.64103, 'recall': 0.19231, 'f1': 0.29586, 'auc': 0.76625}
2025-08-16 05:55:27,890 - INFO - > Epoch 23: took 79.5s (avg 78.7s) | Best so far: epoch 23	train_loss: 0.1228 train_auc: 0.8094	val_loss: 0.0735 val_auc: 0.7961	test_loss: 0.1133 test_auc: 0.7662
2025-08-16 05:56:38,823 - INFO - train: {'epoch': 24, 'time_epoch': 70.84784, 'eta': 5243.55265, 'eta_hours': 1.45654, 'loss': 0.12093454, 'lr': 9.045e-05, 'params': 451793, 'time_iter': 0.06885, 'accuracy': 0.96526, 'precision': 0.62974, 'recall': 0.17532, 'f1': 0.27429, 'auc': 0.81887}
2025-08-16 05:56:43,244 - INFO - val: {'epoch': 24, 'time_epoch': 4.39832, 'loss': 0.07593901, 'lr': 0, 'params': 451793, 'time_iter': 0.0341, 'accuracy': 0.98152, 'precision': 0.59259, 'recall': 0.19753, 'f1': 0.2963, 'auc': 0.77115}
2025-08-16 05:56:47,516 - INFO - test: {'epoch': 24, 'time_epoch': 4.25499, 'loss': 0.11734433, 'lr': 0, 'params': 451793, 'time_iter': 0.03298, 'accuracy': 0.96937, 'precision': 0.55556, 'recall': 0.15385, 'f1': 0.24096, 'auc': 0.74352}
2025-08-16 05:56:47,519 - INFO - > Epoch 24: took 79.6s (avg 78.7s) | Best so far: epoch 23	train_loss: 0.1228 train_auc: 0.8094	val_loss: 0.0735 val_auc: 0.7961	test_loss: 0.1133 test_auc: 0.7662
2025-08-16 05:57:56,692 - INFO - train: {'epoch': 25, 'time_epoch': 69.088, 'eta': 5171.2876, 'eta_hours': 1.43647, 'loss': 0.12135617, 'lr': 8.946e-05, 'params': 451793, 'time_iter': 0.06714, 'accuracy': 0.96511, 'precision': 0.60769, 'recall': 0.19237, 'f1': 0.29223, 'auc': 0.81253}
2025-08-16 05:58:00,813 - INFO - val: {'epoch': 25, 'time_epoch': 4.09913, 'loss': 0.07370779, 'lr': 0, 'params': 451793, 'time_iter': 0.03178, 'accuracy': 0.98347, 'precision': 0.72414, 'recall': 0.25926, 'f1': 0.38182, 'auc': 0.78838}
2025-08-16 05:58:04,943 - INFO - test: {'epoch': 25, 'time_epoch': 4.11309, 'loss': 0.11473199, 'lr': 0, 'params': 451793, 'time_iter': 0.03188, 'accuracy': 0.97034, 'precision': 0.63333, 'recall': 0.14615, 'f1': 0.2375, 'auc': 0.76702}
2025-08-16 05:58:04,946 - INFO - > Epoch 25: took 77.4s (avg 78.7s) | Best so far: epoch 23	train_loss: 0.1228 train_auc: 0.8094	val_loss: 0.0735 val_auc: 0.7961	test_loss: 0.1133 test_auc: 0.7662
2025-08-16 05:59:13,926 - INFO - train: {'epoch': 26, 'time_epoch': 68.89524, 'eta': 5098.7367, 'eta_hours': 1.41632, 'loss': 0.11993287, 'lr': 8.842e-05, 'params': 451793, 'time_iter': 0.06695, 'accuracy': 0.96514, 'precision': 0.60705, 'recall': 0.19562, 'f1': 0.29589, 'auc': 0.81622}
2025-08-16 05:59:18,079 - INFO - val: {'epoch': 26, 'time_epoch': 4.12971, 'loss': 0.07654715, 'lr': 0, 'params': 451793, 'time_iter': 0.03201, 'accuracy': 0.98225, 'precision': 0.64286, 'recall': 0.22222, 'f1': 0.33028, 'auc': 0.77387}
2025-08-16 05:59:22,247 - INFO - test: {'epoch': 26, 'time_epoch': 4.15135, 'loss': 0.1160965, 'lr': 0, 'params': 451793, 'time_iter': 0.03218, 'accuracy': 0.96985, 'precision': 0.59375, 'recall': 0.14615, 'f1': 0.23457, 'auc': 0.75978}
2025-08-16 05:59:22,250 - INFO - > Epoch 26: took 77.3s (avg 78.6s) | Best so far: epoch 23	train_loss: 0.1228 train_auc: 0.8094	val_loss: 0.0735 val_auc: 0.7961	test_loss: 0.1133 test_auc: 0.7662
2025-08-16 06:00:32,643 - INFO - train: {'epoch': 27, 'time_epoch': 70.31092, 'eta': 5030.08726, 'eta_hours': 1.39725, 'loss': 0.12102368, 'lr': 8.734e-05, 'params': 451793, 'time_iter': 0.06833, 'accuracy': 0.9659, 'precision': 0.63682, 'recall': 0.20779, 'f1': 0.31334, 'auc': 0.81381}
2025-08-16 06:00:36,930 - INFO - val: {'epoch': 27, 'time_epoch': 4.26405, 'loss': 0.07478758, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.76903}
2025-08-16 06:00:41,207 - INFO - test: {'epoch': 27, 'time_epoch': 4.2598, 'loss': 0.11595052, 'lr': 0, 'params': 451793, 'time_iter': 0.03302, 'accuracy': 0.97058, 'precision': 0.61538, 'recall': 0.18462, 'f1': 0.28402, 'auc': 0.76244}
2025-08-16 06:00:41,210 - INFO - > Epoch 27: took 79.0s (avg 78.6s) | Best so far: epoch 23	train_loss: 0.1228 train_auc: 0.8094	val_loss: 0.0735 val_auc: 0.7961	test_loss: 0.1133 test_auc: 0.7662
2025-08-16 06:01:50,341 - INFO - train: {'epoch': 28, 'time_epoch': 69.05273, 'eta': 4958.24284, 'eta_hours': 1.37729, 'loss': 0.11942676, 'lr': 8.622e-05, 'params': 451793, 'time_iter': 0.06711, 'accuracy': 0.9662, 'precision': 0.65228, 'recall': 0.2086, 'f1': 0.31611, 'auc': 0.82347}
2025-08-16 06:01:54,627 - INFO - val: {'epoch': 28, 'time_epoch': 4.26296, 'loss': 0.07530251, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.78677}
2025-08-16 06:01:58,908 - INFO - test: {'epoch': 28, 'time_epoch': 4.26295, 'loss': 0.11506964, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.96888, 'precision': 0.51786, 'recall': 0.22308, 'f1': 0.31183, 'auc': 0.7688}
2025-08-16 06:01:58,911 - INFO - > Epoch 28: took 77.7s (avg 78.6s) | Best so far: epoch 23	train_loss: 0.1228 train_auc: 0.8094	val_loss: 0.0735 val_auc: 0.7961	test_loss: 0.1133 test_auc: 0.7662
2025-08-16 06:03:07,676 - INFO - train: {'epoch': 29, 'time_epoch': 68.68304, 'eta': 4885.72191, 'eta_hours': 1.35714, 'loss': 0.11921439, 'lr': 8.506e-05, 'params': 451793, 'time_iter': 0.06675, 'accuracy': 0.96556, 'precision': 0.61871, 'recall': 0.20942, 'f1': 0.31292, 'auc': 0.82391}
2025-08-16 06:03:11,749 - INFO - val: {'epoch': 29, 'time_epoch': 4.0521, 'loss': 0.07471874, 'lr': 0, 'params': 451793, 'time_iter': 0.03141, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.77867}
2025-08-16 06:03:15,865 - INFO - test: {'epoch': 29, 'time_epoch': 4.09904, 'loss': 0.1142602, 'lr': 0, 'params': 451793, 'time_iter': 0.03178, 'accuracy': 0.97058, 'precision': 0.59574, 'recall': 0.21538, 'f1': 0.31638, 'auc': 0.76632}
2025-08-16 06:03:15,867 - INFO - > Epoch 29: took 77.0s (avg 78.5s) | Best so far: epoch 23	train_loss: 0.1228 train_auc: 0.8094	val_loss: 0.0735 val_auc: 0.7961	test_loss: 0.1133 test_auc: 0.7662
2025-08-16 06:04:23,381 - INFO - train: {'epoch': 30, 'time_epoch': 67.43023, 'eta': 4810.66007, 'eta_hours': 1.33629, 'loss': 0.11870577, 'lr': 8.386e-05, 'params': 451793, 'time_iter': 0.06553, 'accuracy': 0.96523, 'precision': 0.60732, 'recall': 0.20211, 'f1': 0.30329, 'auc': 0.83112}
2025-08-16 06:04:27,557 - INFO - val: {'epoch': 30, 'time_epoch': 4.15285, 'loss': 0.07378919, 'lr': 0, 'params': 451793, 'time_iter': 0.03219, 'accuracy': 0.9842, 'precision': 0.76667, 'recall': 0.28395, 'f1': 0.41441, 'auc': 0.78148}
2025-08-16 06:04:31,684 - INFO - test: {'epoch': 30, 'time_epoch': 4.10897, 'loss': 0.11894963, 'lr': 0, 'params': 451793, 'time_iter': 0.03185, 'accuracy': 0.96766, 'precision': 0.44828, 'recall': 0.1, 'f1': 0.16352, 'auc': 0.76794}
2025-08-16 06:04:31,686 - INFO - > Epoch 30: took 75.8s (avg 78.5s) | Best so far: epoch 23	train_loss: 0.1228 train_auc: 0.8094	val_loss: 0.0735 val_auc: 0.7961	test_loss: 0.1133 test_auc: 0.7662
2025-08-16 06:05:39,363 - INFO - train: {'epoch': 31, 'time_epoch': 67.59441, 'eta': 4736.4241, 'eta_hours': 1.31567, 'loss': 0.11688363, 'lr': 8.263e-05, 'params': 451793, 'time_iter': 0.06569, 'accuracy': 0.96605, 'precision': 0.63218, 'recall': 0.22321, 'f1': 0.32993, 'auc': 0.83383}
2025-08-16 06:05:43,642 - INFO - val: {'epoch': 31, 'time_epoch': 4.25622, 'loss': 0.07538298, 'lr': 0, 'params': 451793, 'time_iter': 0.03299, 'accuracy': 0.98249, 'precision': 0.60465, 'recall': 0.32099, 'f1': 0.41935, 'auc': 0.78847}
2025-08-16 06:05:47,876 - INFO - test: {'epoch': 31, 'time_epoch': 4.21554, 'loss': 0.11855485, 'lr': 0, 'params': 451793, 'time_iter': 0.03268, 'accuracy': 0.96596, 'precision': 0.44318, 'recall': 0.3, 'f1': 0.3578, 'auc': 0.76007}
2025-08-16 06:05:47,878 - INFO - > Epoch 31: took 76.2s (avg 78.4s) | Best so far: epoch 23	train_loss: 0.1228 train_auc: 0.8094	val_loss: 0.0735 val_auc: 0.7961	test_loss: 0.1133 test_auc: 0.7662
2025-08-16 06:06:55,419 - INFO - train: {'epoch': 32, 'time_epoch': 67.45335, 'eta': 4662.30425, 'eta_hours': 1.29508, 'loss': 0.11709793, 'lr': 8.136e-05, 'params': 451793, 'time_iter': 0.06555, 'accuracy': 0.96587, 'precision': 0.62587, 'recall': 0.21997, 'f1': 0.32553, 'auc': 0.82623}
2025-08-16 06:06:59,749 - INFO - val: {'epoch': 32, 'time_epoch': 4.30527, 'loss': 0.07232069, 'lr': 0, 'params': 451793, 'time_iter': 0.03337, 'accuracy': 0.98371, 'precision': 0.68421, 'recall': 0.32099, 'f1': 0.43697, 'auc': 0.7769}
2025-08-16 06:07:04,055 - INFO - test: {'epoch': 32, 'time_epoch': 4.28725, 'loss': 0.11606475, 'lr': 0, 'params': 451793, 'time_iter': 0.03323, 'accuracy': 0.96961, 'precision': 0.54545, 'recall': 0.23077, 'f1': 0.32432, 'auc': 0.74813}
2025-08-16 06:07:04,057 - INFO - > Epoch 32: took 76.2s (avg 78.3s) | Best so far: epoch 23	train_loss: 0.1228 train_auc: 0.8094	val_loss: 0.0735 val_auc: 0.7961	test_loss: 0.1133 test_auc: 0.7662
2025-08-16 06:08:13,794 - INFO - train: {'epoch': 33, 'time_epoch': 69.65285, 'eta': 4592.84616, 'eta_hours': 1.27579, 'loss': 0.11605934, 'lr': 8.005e-05, 'params': 451793, 'time_iter': 0.06769, 'accuracy': 0.96702, 'precision': 0.65672, 'recall': 0.25, 'f1': 0.36214, 'auc': 0.83341}
2025-08-16 06:08:18,003 - INFO - val: {'epoch': 33, 'time_epoch': 4.18502, 'loss': 0.07153605, 'lr': 0, 'params': 451793, 'time_iter': 0.03244, 'accuracy': 0.9842, 'precision': 0.86364, 'recall': 0.23457, 'f1': 0.36893, 'auc': 0.78821}
2025-08-16 06:08:22,213 - INFO - test: {'epoch': 33, 'time_epoch': 4.19081, 'loss': 0.11713638, 'lr': 0, 'params': 451793, 'time_iter': 0.03249, 'accuracy': 0.97009, 'precision': 0.64, 'recall': 0.12308, 'f1': 0.20645, 'auc': 0.76193}
2025-08-16 06:08:22,216 - INFO - > Epoch 33: took 78.2s (avg 78.3s) | Best so far: epoch 23	train_loss: 0.1228 train_auc: 0.8094	val_loss: 0.0735 val_auc: 0.7961	test_loss: 0.1133 test_auc: 0.7662
2025-08-16 06:09:32,733 - INFO - train: {'epoch': 34, 'time_epoch': 70.4123, 'eta': 4524.78736, 'eta_hours': 1.25689, 'loss': 0.1159149, 'lr': 7.872e-05, 'params': 451793, 'time_iter': 0.06843, 'accuracy': 0.96663, 'precision': 0.64823, 'recall': 0.23782, 'f1': 0.34798, 'auc': 0.83362}
2025-08-16 06:09:37,313 - INFO - val: {'epoch': 34, 'time_epoch': 4.55134, 'loss': 0.071973, 'lr': 0, 'params': 451793, 'time_iter': 0.03528, 'accuracy': 0.98371, 'precision': 0.675, 'recall': 0.33333, 'f1': 0.44628, 'auc': 0.79639}
2025-08-16 06:09:41,797 - INFO - test: {'epoch': 34, 'time_epoch': 4.46469, 'loss': 0.11784197, 'lr': 0, 'params': 451793, 'time_iter': 0.03461, 'accuracy': 0.97058, 'precision': 0.57627, 'recall': 0.26154, 'f1': 0.35979, 'auc': 0.75503}
2025-08-16 06:09:41,800 - INFO - > Epoch 34: took 79.6s (avg 78.3s) | Best so far: epoch 34	train_loss: 0.1159 train_auc: 0.8336	val_loss: 0.0720 val_auc: 0.7964	test_loss: 0.1178 test_auc: 0.7550
2025-08-16 06:10:51,229 - INFO - train: {'epoch': 35, 'time_epoch': 69.34411, 'eta': 4454.6988, 'eta_hours': 1.23742, 'loss': 0.11583427, 'lr': 7.735e-05, 'params': 451793, 'time_iter': 0.06739, 'accuracy': 0.96641, 'precision': 0.62475, 'recall': 0.25812, 'f1': 0.36531, 'auc': 0.83056}
2025-08-16 06:10:55,639 - INFO - val: {'epoch': 35, 'time_epoch': 4.38429, 'loss': 0.07323788, 'lr': 0, 'params': 451793, 'time_iter': 0.03399, 'accuracy': 0.98347, 'precision': 0.72414, 'recall': 0.25926, 'f1': 0.38182, 'auc': 0.77574}
2025-08-16 06:10:59,948 - INFO - test: {'epoch': 35, 'time_epoch': 4.29084, 'loss': 0.11538225, 'lr': 0, 'params': 451793, 'time_iter': 0.03326, 'accuracy': 0.97058, 'precision': 0.62162, 'recall': 0.17692, 'f1': 0.27545, 'auc': 0.75878}
2025-08-16 06:10:59,951 - INFO - > Epoch 35: took 78.2s (avg 78.3s) | Best so far: epoch 34	train_loss: 0.1159 train_auc: 0.8336	val_loss: 0.0720 val_auc: 0.7964	test_loss: 0.1178 test_auc: 0.7550
2025-08-16 06:12:08,505 - INFO - train: {'epoch': 36, 'time_epoch': 68.47065, 'eta': 4383.16323, 'eta_hours': 1.21755, 'loss': 0.11333847, 'lr': 7.595e-05, 'params': 451793, 'time_iter': 0.06654, 'accuracy': 0.96678, 'precision': 0.63872, 'recall': 0.25974, 'f1': 0.3693, 'auc': 0.83895}
2025-08-16 06:12:12,678 - INFO - val: {'epoch': 36, 'time_epoch': 4.14647, 'loss': 0.07292493, 'lr': 0, 'params': 451793, 'time_iter': 0.03214, 'accuracy': 0.98371, 'precision': 0.68421, 'recall': 0.32099, 'f1': 0.43697, 'auc': 0.77606}
2025-08-16 06:12:16,852 - INFO - test: {'epoch': 36, 'time_epoch': 4.15768, 'loss': 0.11867403, 'lr': 0, 'params': 451793, 'time_iter': 0.03223, 'accuracy': 0.96985, 'precision': 0.56, 'recall': 0.21538, 'f1': 0.31111, 'auc': 0.75275}
2025-08-16 06:12:16,855 - INFO - > Epoch 36: took 76.9s (avg 78.3s) | Best so far: epoch 34	train_loss: 0.1159 train_auc: 0.8336	val_loss: 0.0720 val_auc: 0.7964	test_loss: 0.1178 test_auc: 0.7550
2025-08-16 06:13:26,553 - INFO - train: {'epoch': 37, 'time_epoch': 69.61347, 'eta': 4313.65358, 'eta_hours': 1.19824, 'loss': 0.1137453, 'lr': 7.452e-05, 'params': 451793, 'time_iter': 0.06765, 'accuracy': 0.96684, 'precision': 0.63689, 'recall': 0.26623, 'f1': 0.3755, 'auc': 0.83775}
2025-08-16 06:13:30,800 - INFO - val: {'epoch': 37, 'time_epoch': 4.22257, 'loss': 0.07157855, 'lr': 0, 'params': 451793, 'time_iter': 0.03273, 'accuracy': 0.98322, 'precision': 0.65, 'recall': 0.32099, 'f1': 0.42975, 'auc': 0.78426}
2025-08-16 06:13:35,038 - INFO - test: {'epoch': 37, 'time_epoch': 4.22115, 'loss': 0.11559538, 'lr': 0, 'params': 451793, 'time_iter': 0.03272, 'accuracy': 0.97131, 'precision': 0.6, 'recall': 0.27692, 'f1': 0.37895, 'auc': 0.76054}
2025-08-16 06:13:35,041 - INFO - > Epoch 37: took 78.2s (avg 78.3s) | Best so far: epoch 34	train_loss: 0.1159 train_auc: 0.8336	val_loss: 0.0720 val_auc: 0.7964	test_loss: 0.1178 test_auc: 0.7550
2025-08-16 06:14:44,201 - INFO - train: {'epoch': 38, 'time_epoch': 69.0685, 'eta': 4243.28622, 'eta_hours': 1.17869, 'loss': 0.1126797, 'lr': 7.307e-05, 'params': 451793, 'time_iter': 0.06712, 'accuracy': 0.9676, 'precision': 0.66148, 'recall': 0.27597, 'f1': 0.38946, 'auc': 0.83853}
2025-08-16 06:14:48,406 - INFO - val: {'epoch': 38, 'time_epoch': 4.18016, 'loss': 0.07326099, 'lr': 0, 'params': 451793, 'time_iter': 0.0324, 'accuracy': 0.98322, 'precision': 0.71429, 'recall': 0.24691, 'f1': 0.36697, 'auc': 0.77819}
2025-08-16 06:14:52,568 - INFO - test: {'epoch': 38, 'time_epoch': 4.14305, 'loss': 0.11651221, 'lr': 0, 'params': 451793, 'time_iter': 0.03212, 'accuracy': 0.96985, 'precision': 0.575, 'recall': 0.17692, 'f1': 0.27059, 'auc': 0.76223}
2025-08-16 06:14:52,571 - INFO - > Epoch 38: took 77.5s (avg 78.3s) | Best so far: epoch 34	train_loss: 0.1159 train_auc: 0.8336	val_loss: 0.0720 val_auc: 0.7964	test_loss: 0.1178 test_auc: 0.7550
2025-08-16 06:16:01,039 - INFO - train: {'epoch': 39, 'time_epoch': 68.38345, 'eta': 4171.95622, 'eta_hours': 1.15888, 'loss': 0.11156347, 'lr': 7.159e-05, 'params': 451793, 'time_iter': 0.06646, 'accuracy': 0.96763, 'precision': 0.66151, 'recall': 0.2776, 'f1': 0.39108, 'auc': 0.84364}
2025-08-16 06:16:05,263 - INFO - val: {'epoch': 39, 'time_epoch': 4.20104, 'loss': 0.07353224, 'lr': 0, 'params': 451793, 'time_iter': 0.03257, 'accuracy': 0.98225, 'precision': 0.60526, 'recall': 0.28395, 'f1': 0.38655, 'auc': 0.78057}
2025-08-16 06:16:09,441 - INFO - test: {'epoch': 39, 'time_epoch': 4.16056, 'loss': 0.11752171, 'lr': 0, 'params': 451793, 'time_iter': 0.03225, 'accuracy': 0.96791, 'precision': 0.48684, 'recall': 0.28462, 'f1': 0.35922, 'auc': 0.75712}
2025-08-16 06:16:09,443 - INFO - > Epoch 39: took 76.9s (avg 78.2s) | Best so far: epoch 34	train_loss: 0.1159 train_auc: 0.8336	val_loss: 0.0720 val_auc: 0.7964	test_loss: 0.1178 test_auc: 0.7550
2025-08-16 06:17:18,185 - INFO - train: {'epoch': 40, 'time_epoch': 68.61383, 'eta': 4101.10148, 'eta_hours': 1.13919, 'loss': 0.11187524, 'lr': 7.008e-05, 'params': 451793, 'time_iter': 0.06668, 'accuracy': 0.96736, 'precision': 0.64906, 'recall': 0.27922, 'f1': 0.39047, 'auc': 0.84659}
2025-08-16 06:17:22,535 - INFO - val: {'epoch': 40, 'time_epoch': 4.32334, 'loss': 0.07289004, 'lr': 0, 'params': 451793, 'time_iter': 0.03351, 'accuracy': 0.98347, 'precision': 0.65854, 'recall': 0.33333, 'f1': 0.44262, 'auc': 0.79731}
2025-08-16 06:17:26,814 - INFO - test: {'epoch': 40, 'time_epoch': 4.26136, 'loss': 0.11471906, 'lr': 0, 'params': 451793, 'time_iter': 0.03303, 'accuracy': 0.96961, 'precision': 0.53968, 'recall': 0.26154, 'f1': 0.35233, 'auc': 0.7527}
2025-08-16 06:17:26,817 - INFO - > Epoch 40: took 77.4s (avg 78.2s) | Best so far: epoch 40	train_loss: 0.1119 train_auc: 0.8466	val_loss: 0.0729 val_auc: 0.7973	test_loss: 0.1147 test_auc: 0.7527
2025-08-16 06:18:34,674 - INFO - train: {'epoch': 41, 'time_epoch': 67.76879, 'eta': 4029.18649, 'eta_hours': 1.11922, 'loss': 0.11147576, 'lr': 6.856e-05, 'params': 451793, 'time_iter': 0.06586, 'accuracy': 0.96766, 'precision': 0.65909, 'recall': 0.28247, 'f1': 0.39545, 'auc': 0.84653}
2025-08-16 06:18:38,869 - INFO - val: {'epoch': 41, 'time_epoch': 4.17029, 'loss': 0.07255782, 'lr': 0, 'params': 451793, 'time_iter': 0.03233, 'accuracy': 0.98274, 'precision': 0.67857, 'recall': 0.23457, 'f1': 0.34862, 'auc': 0.77363}
2025-08-16 06:18:43,076 - INFO - test: {'epoch': 41, 'time_epoch': 4.18942, 'loss': 0.11880325, 'lr': 0, 'params': 451793, 'time_iter': 0.03248, 'accuracy': 0.97058, 'precision': 0.63636, 'recall': 0.16154, 'f1': 0.25767, 'auc': 0.74422}
2025-08-16 06:18:43,079 - INFO - > Epoch 41: took 76.3s (avg 78.2s) | Best so far: epoch 40	train_loss: 0.1119 train_auc: 0.8466	val_loss: 0.0729 val_auc: 0.7973	test_loss: 0.1147 test_auc: 0.7527
2025-08-16 06:19:50,257 - INFO - train: {'epoch': 42, 'time_epoch': 67.08939, 'eta': 3956.56374, 'eta_hours': 1.09905, 'loss': 0.10961792, 'lr': 6.701e-05, 'params': 451793, 'time_iter': 0.0652, 'accuracy': 0.96815, 'precision': 0.67969, 'recall': 0.28247, 'f1': 0.39908, 'auc': 0.85691}
2025-08-16 06:19:54,453 - INFO - val: {'epoch': 42, 'time_epoch': 4.17123, 'loss': 0.07321661, 'lr': 0, 'params': 451793, 'time_iter': 0.03234, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.78238}
2025-08-16 06:19:58,626 - INFO - test: {'epoch': 42, 'time_epoch': 4.15582, 'loss': 0.11777135, 'lr': 0, 'params': 451793, 'time_iter': 0.03222, 'accuracy': 0.96864, 'precision': 0.50704, 'recall': 0.27692, 'f1': 0.35821, 'auc': 0.7644}
2025-08-16 06:19:58,628 - INFO - > Epoch 42: took 75.5s (avg 78.1s) | Best so far: epoch 40	train_loss: 0.1119 train_auc: 0.8466	val_loss: 0.0729 val_auc: 0.7973	test_loss: 0.1147 test_auc: 0.7527
2025-08-16 06:21:06,298 - INFO - train: {'epoch': 43, 'time_epoch': 67.58227, 'eta': 3884.81982, 'eta_hours': 1.07912, 'loss': 0.11175864, 'lr': 6.545e-05, 'params': 451793, 'time_iter': 0.06568, 'accuracy': 0.9672, 'precision': 0.64407, 'recall': 0.2776, 'f1': 0.38798, 'auc': 0.84927}
2025-08-16 06:21:10,346 - INFO - val: {'epoch': 43, 'time_epoch': 4.02343, 'loss': 0.07483857, 'lr': 0, 'params': 451793, 'time_iter': 0.03119, 'accuracy': 0.98249, 'precision': 0.62162, 'recall': 0.28395, 'f1': 0.38983, 'auc': 0.75528}
2025-08-16 06:21:14,424 - INFO - test: {'epoch': 43, 'time_epoch': 4.02131, 'loss': 0.11751955, 'lr': 0, 'params': 451793, 'time_iter': 0.03117, 'accuracy': 0.96961, 'precision': 0.54902, 'recall': 0.21538, 'f1': 0.30939, 'auc': 0.74605}
2025-08-16 06:21:14,427 - INFO - > Epoch 43: took 75.8s (avg 78.1s) | Best so far: epoch 40	train_loss: 0.1119 train_auc: 0.8466	val_loss: 0.0729 val_auc: 0.7973	test_loss: 0.1147 test_auc: 0.7527
2025-08-16 06:22:22,101 - INFO - train: {'epoch': 44, 'time_epoch': 67.58607, 'eta': 3813.26551, 'eta_hours': 1.05924, 'loss': 0.11013641, 'lr': 6.387e-05, 'params': 451793, 'time_iter': 0.06568, 'accuracy': 0.96806, 'precision': 0.66667, 'recall': 0.29383, 'f1': 0.40789, 'auc': 0.84873}
2025-08-16 06:22:26,114 - INFO - val: {'epoch': 44, 'time_epoch': 3.99027, 'loss': 0.07509636, 'lr': 0, 'params': 451793, 'time_iter': 0.03093, 'accuracy': 0.98274, 'precision': 0.61364, 'recall': 0.33333, 'f1': 0.432, 'auc': 0.78763}
2025-08-16 06:22:30,085 - INFO - test: {'epoch': 44, 'time_epoch': 3.9538, 'loss': 0.11816622, 'lr': 0, 'params': 451793, 'time_iter': 0.03065, 'accuracy': 0.96815, 'precision': 0.49425, 'recall': 0.33077, 'f1': 0.39631, 'auc': 0.76518}
2025-08-16 06:22:30,088 - INFO - > Epoch 44: took 75.7s (avg 78.0s) | Best so far: epoch 40	train_loss: 0.1119 train_auc: 0.8466	val_loss: 0.0729 val_auc: 0.7973	test_loss: 0.1147 test_auc: 0.7527
2025-08-16 06:23:37,312 - INFO - train: {'epoch': 45, 'time_epoch': 67.14082, 'eta': 3741.36104, 'eta_hours': 1.03927, 'loss': 0.11067426, 'lr': 6.227e-05, 'params': 451793, 'time_iter': 0.06525, 'accuracy': 0.96796, 'precision': 0.66007, 'recall': 0.29789, 'f1': 0.41051, 'auc': 0.85615}
2025-08-16 06:23:41,436 - INFO - val: {'epoch': 45, 'time_epoch': 4.10252, 'loss': 0.07388194, 'lr': 0, 'params': 451793, 'time_iter': 0.0318, 'accuracy': 0.98298, 'precision': 0.66667, 'recall': 0.2716, 'f1': 0.38596, 'auc': 0.77352}
2025-08-16 06:23:45,574 - INFO - test: {'epoch': 45, 'time_epoch': 4.12034, 'loss': 0.11405539, 'lr': 0, 'params': 451793, 'time_iter': 0.03194, 'accuracy': 0.96985, 'precision': 0.57895, 'recall': 0.16923, 'f1': 0.2619, 'auc': 0.7497}
2025-08-16 06:23:45,576 - INFO - > Epoch 45: took 75.5s (avg 78.0s) | Best so far: epoch 40	train_loss: 0.1119 train_auc: 0.8466	val_loss: 0.0729 val_auc: 0.7973	test_loss: 0.1147 test_auc: 0.7527
2025-08-16 06:24:53,282 - INFO - train: {'epoch': 46, 'time_epoch': 67.6259, 'eta': 3670.20628, 'eta_hours': 1.0195, 'loss': 0.10978687, 'lr': 6.066e-05, 'params': 451793, 'time_iter': 0.06572, 'accuracy': 0.96772, 'precision': 0.65741, 'recall': 0.28815, 'f1': 0.40068, 'auc': 0.85154}
2025-08-16 06:24:57,368 - INFO - val: {'epoch': 46, 'time_epoch': 4.06375, 'loss': 0.0728174, 'lr': 0, 'params': 451793, 'time_iter': 0.0315, 'accuracy': 0.98347, 'precision': 0.74074, 'recall': 0.24691, 'f1': 0.37037, 'auc': 0.75389}
2025-08-16 06:25:01,619 - INFO - test: {'epoch': 46, 'time_epoch': 4.19189, 'loss': 0.1165301, 'lr': 0, 'params': 451793, 'time_iter': 0.0325, 'accuracy': 0.97058, 'precision': 0.60465, 'recall': 0.2, 'f1': 0.30058, 'auc': 0.74969}
2025-08-16 06:25:01,628 - INFO - > Epoch 46: took 76.1s (avg 77.9s) | Best so far: epoch 40	train_loss: 0.1119 train_auc: 0.8466	val_loss: 0.0729 val_auc: 0.7973	test_loss: 0.1147 test_auc: 0.7527
2025-08-16 06:26:07,974 - INFO - train: {'epoch': 47, 'time_epoch': 66.26199, 'eta': 3597.72098, 'eta_hours': 0.99937, 'loss': 0.10955082, 'lr': 5.904e-05, 'params': 451793, 'time_iter': 0.06439, 'accuracy': 0.96787, 'precision': 0.65487, 'recall': 0.30032, 'f1': 0.4118, 'auc': 0.85638}
2025-08-16 06:26:12,230 - INFO - val: {'epoch': 47, 'time_epoch': 4.23135, 'loss': 0.07378762, 'lr': 0, 'params': 451793, 'time_iter': 0.0328, 'accuracy': 0.98274, 'precision': 0.61905, 'recall': 0.32099, 'f1': 0.42276, 'auc': 0.78293}
2025-08-16 06:26:16,492 - INFO - test: {'epoch': 47, 'time_epoch': 4.2432, 'loss': 0.11611728, 'lr': 0, 'params': 451793, 'time_iter': 0.03289, 'accuracy': 0.96791, 'precision': 0.48611, 'recall': 0.26923, 'f1': 0.34653, 'auc': 0.74964}
2025-08-16 06:26:16,494 - INFO - > Epoch 47: took 74.9s (avg 77.9s) | Best so far: epoch 40	train_loss: 0.1119 train_auc: 0.8466	val_loss: 0.0729 val_auc: 0.7973	test_loss: 0.1147 test_auc: 0.7527
2025-08-16 06:27:23,012 - INFO - train: {'epoch': 48, 'time_epoch': 66.4379, 'eta': 3525.6728, 'eta_hours': 0.97935, 'loss': 0.10857576, 'lr': 5.741e-05, 'params': 451793, 'time_iter': 0.06457, 'accuracy': 0.96809, 'precision': 0.67433, 'recall': 0.28571, 'f1': 0.40137, 'auc': 0.85808}
2025-08-16 06:27:27,399 - INFO - val: {'epoch': 48, 'time_epoch': 4.36177, 'loss': 0.07224478, 'lr': 0, 'params': 451793, 'time_iter': 0.03381, 'accuracy': 0.98298, 'precision': 0.63415, 'recall': 0.32099, 'f1': 0.42623, 'auc': 0.79373}
2025-08-16 06:27:31,766 - INFO - test: {'epoch': 48, 'time_epoch': 4.34884, 'loss': 0.11646821, 'lr': 0, 'params': 451793, 'time_iter': 0.03371, 'accuracy': 0.96985, 'precision': 0.54688, 'recall': 0.26923, 'f1': 0.36082, 'auc': 0.74767}
2025-08-16 06:27:31,768 - INFO - > Epoch 48: took 75.3s (avg 77.8s) | Best so far: epoch 40	train_loss: 0.1119 train_auc: 0.8466	val_loss: 0.0729 val_auc: 0.7973	test_loss: 0.1147 test_auc: 0.7527
2025-08-16 06:28:39,079 - INFO - train: {'epoch': 49, 'time_epoch': 67.22441, 'eta': 3454.63553, 'eta_hours': 0.95962, 'loss': 0.10866966, 'lr': 5.577e-05, 'params': 451793, 'time_iter': 0.06533, 'accuracy': 0.96888, 'precision': 0.68773, 'recall': 0.30925, 'f1': 0.42665, 'auc': 0.85412}
2025-08-16 06:28:43,414 - INFO - val: {'epoch': 49, 'time_epoch': 4.31134, 'loss': 0.07088842, 'lr': 0, 'params': 451793, 'time_iter': 0.03342, 'accuracy': 0.98395, 'precision': 0.7027, 'recall': 0.32099, 'f1': 0.44068, 'auc': 0.78827}
2025-08-16 06:28:47,706 - INFO - test: {'epoch': 49, 'time_epoch': 4.27451, 'loss': 0.11510954, 'lr': 0, 'params': 451793, 'time_iter': 0.03314, 'accuracy': 0.97034, 'precision': 0.57143, 'recall': 0.24615, 'f1': 0.34409, 'auc': 0.75847}
2025-08-16 06:28:47,708 - INFO - > Epoch 49: took 75.9s (avg 77.8s) | Best so far: epoch 40	train_loss: 0.1119 train_auc: 0.8466	val_loss: 0.0729 val_auc: 0.7973	test_loss: 0.1147 test_auc: 0.7527
2025-08-16 06:29:55,694 - INFO - train: {'epoch': 50, 'time_epoch': 67.90225, 'eta': 3384.39904, 'eta_hours': 0.94011, 'loss': 0.10708053, 'lr': 5.413e-05, 'params': 451793, 'time_iter': 0.06599, 'accuracy': 0.96839, 'precision': 0.65894, 'recall': 0.32305, 'f1': 0.43355, 'auc': 0.86634}
2025-08-16 06:29:59,863 - INFO - val: {'epoch': 50, 'time_epoch': 4.14667, 'loss': 0.07278687, 'lr': 0, 'params': 451793, 'time_iter': 0.03214, 'accuracy': 0.98347, 'precision': 0.67568, 'recall': 0.30864, 'f1': 0.42373, 'auc': 0.78629}
2025-08-16 06:30:04,164 - INFO - test: {'epoch': 50, 'time_epoch': 4.2831, 'loss': 0.11767672, 'lr': 0, 'params': 451793, 'time_iter': 0.0332, 'accuracy': 0.97082, 'precision': 0.57812, 'recall': 0.28462, 'f1': 0.38144, 'auc': 0.74616}
2025-08-16 06:30:04,165 - INFO - > Epoch 50: took 76.5s (avg 77.7s) | Best so far: epoch 40	train_loss: 0.1119 train_auc: 0.8466	val_loss: 0.0729 val_auc: 0.7973	test_loss: 0.1147 test_auc: 0.7527
2025-08-16 06:31:11,485 - INFO - train: {'epoch': 51, 'time_epoch': 67.23692, 'eta': 3313.63818, 'eta_hours': 0.92046, 'loss': 0.10704946, 'lr': 5.248e-05, 'params': 451793, 'time_iter': 0.06534, 'accuracy': 0.96894, 'precision': 0.67736, 'recall': 0.32549, 'f1': 0.43969, 'auc': 0.86412}
2025-08-16 06:31:15,740 - INFO - val: {'epoch': 51, 'time_epoch': 4.23309, 'loss': 0.07427443, 'lr': 0, 'params': 451793, 'time_iter': 0.03281, 'accuracy': 0.98274, 'precision': 0.6087, 'recall': 0.34568, 'f1': 0.44094, 'auc': 0.78786}
2025-08-16 06:31:19,974 - INFO - test: {'epoch': 51, 'time_epoch': 4.21602, 'loss': 0.11721495, 'lr': 0, 'params': 451793, 'time_iter': 0.03268, 'accuracy': 0.96985, 'precision': 0.54688, 'recall': 0.26923, 'f1': 0.36082, 'auc': 0.76237}
2025-08-16 06:31:19,976 - INFO - > Epoch 51: took 75.8s (avg 77.7s) | Best so far: epoch 40	train_loss: 0.1119 train_auc: 0.8466	val_loss: 0.0729 val_auc: 0.7973	test_loss: 0.1147 test_auc: 0.7527
2025-08-16 06:32:26,290 - INFO - train: {'epoch': 52, 'time_epoch': 66.23306, 'eta': 3242.12009, 'eta_hours': 0.90059, 'loss': 0.10744939, 'lr': 5.083e-05, 'params': 451793, 'time_iter': 0.06437, 'accuracy': 0.96903, 'precision': 0.6778, 'recall': 0.32955, 'f1': 0.44347, 'auc': 0.85996}
2025-08-16 06:32:30,360 - INFO - val: {'epoch': 52, 'time_epoch': 4.04834, 'loss': 0.07171309, 'lr': 0, 'params': 451793, 'time_iter': 0.03138, 'accuracy': 0.9842, 'precision': 0.73529, 'recall': 0.30864, 'f1': 0.43478, 'auc': 0.79079}
2025-08-16 06:32:34,414 - INFO - test: {'epoch': 52, 'time_epoch': 4.03686, 'loss': 0.1156998, 'lr': 0, 'params': 451793, 'time_iter': 0.03129, 'accuracy': 0.97034, 'precision': 0.59524, 'recall': 0.19231, 'f1': 0.2907, 'auc': 0.76301}
2025-08-16 06:32:34,417 - INFO - > Epoch 52: took 74.4s (avg 77.6s) | Best so far: epoch 40	train_loss: 0.1119 train_auc: 0.8466	val_loss: 0.0729 val_auc: 0.7973	test_loss: 0.1147 test_auc: 0.7527
2025-08-16 06:33:41,430 - INFO - train: {'epoch': 53, 'time_epoch': 66.93228, 'eta': 3171.39336, 'eta_hours': 0.88094, 'loss': 0.10633086, 'lr': 4.917e-05, 'params': 451793, 'time_iter': 0.06505, 'accuracy': 0.96936, 'precision': 0.69929, 'recall': 0.31899, 'f1': 0.43813, 'auc': 0.86668}
2025-08-16 06:33:45,585 - INFO - val: {'epoch': 53, 'time_epoch': 4.13364, 'loss': 0.07399705, 'lr': 0, 'params': 451793, 'time_iter': 0.03204, 'accuracy': 0.98201, 'precision': 0.56604, 'recall': 0.37037, 'f1': 0.44776, 'auc': 0.78914}
2025-08-16 06:33:49,720 - INFO - test: {'epoch': 53, 'time_epoch': 4.11803, 'loss': 0.11657699, 'lr': 0, 'params': 451793, 'time_iter': 0.03192, 'accuracy': 0.96985, 'precision': 0.53659, 'recall': 0.33846, 'f1': 0.41509, 'auc': 0.76881}
2025-08-16 06:33:49,722 - INFO - > Epoch 53: took 75.3s (avg 77.6s) | Best so far: epoch 40	train_loss: 0.1119 train_auc: 0.8466	val_loss: 0.0729 val_auc: 0.7973	test_loss: 0.1147 test_auc: 0.7527
2025-08-16 06:34:56,641 - INFO - train: {'epoch': 54, 'time_epoch': 66.83438, 'eta': 3100.72452, 'eta_hours': 0.86131, 'loss': 0.10622986, 'lr': 4.752e-05, 'params': 451793, 'time_iter': 0.06495, 'accuracy': 0.9693, 'precision': 0.69271, 'recall': 0.32386, 'f1': 0.44137, 'auc': 0.86437}
2025-08-16 06:35:01,019 - INFO - val: {'epoch': 54, 'time_epoch': 4.35518, 'loss': 0.07136237, 'lr': 0, 'params': 451793, 'time_iter': 0.03376, 'accuracy': 0.98347, 'precision': 0.65854, 'recall': 0.33333, 'f1': 0.44262, 'auc': 0.79873}
2025-08-16 06:35:05,392 - INFO - test: {'epoch': 54, 'time_epoch': 4.3547, 'loss': 0.11475476, 'lr': 0, 'params': 451793, 'time_iter': 0.03376, 'accuracy': 0.96985, 'precision': 0.54839, 'recall': 0.26154, 'f1': 0.35417, 'auc': 0.77106}
2025-08-16 06:35:05,395 - INFO - > Epoch 54: took 75.7s (avg 77.6s) | Best so far: epoch 54	train_loss: 0.1062 train_auc: 0.8644	val_loss: 0.0714 val_auc: 0.7987	test_loss: 0.1148 test_auc: 0.7711
2025-08-16 06:36:13,650 - INFO - train: {'epoch': 55, 'time_epoch': 68.17583, 'eta': 3031.24662, 'eta_hours': 0.84201, 'loss': 0.10568241, 'lr': 4.587e-05, 'params': 451793, 'time_iter': 0.06625, 'accuracy': 0.96921, 'precision': 0.68528, 'recall': 0.32873, 'f1': 0.44432, 'auc': 0.86642}
2025-08-16 06:36:18,021 - INFO - val: {'epoch': 55, 'time_epoch': 4.34869, 'loss': 0.07233032, 'lr': 0, 'params': 451793, 'time_iter': 0.03371, 'accuracy': 0.98371, 'precision': 0.68421, 'recall': 0.32099, 'f1': 0.43697, 'auc': 0.78779}
2025-08-16 06:36:22,383 - INFO - test: {'epoch': 55, 'time_epoch': 4.34351, 'loss': 0.11706228, 'lr': 0, 'params': 451793, 'time_iter': 0.03367, 'accuracy': 0.96864, 'precision': 0.5082, 'recall': 0.23846, 'f1': 0.32461, 'auc': 0.76537}
2025-08-16 06:36:22,387 - INFO - > Epoch 55: took 77.0s (avg 77.6s) | Best so far: epoch 54	train_loss: 0.1062 train_auc: 0.8644	val_loss: 0.0714 val_auc: 0.7987	test_loss: 0.1148 test_auc: 0.7711
2025-08-16 06:37:28,888 - INFO - train: {'epoch': 56, 'time_epoch': 66.41491, 'eta': 2960.48599, 'eta_hours': 0.82236, 'loss': 0.10588044, 'lr': 4.423e-05, 'params': 451793, 'time_iter': 0.06454, 'accuracy': 0.97064, 'precision': 0.71803, 'recall': 0.35552, 'f1': 0.47557, 'auc': 0.86489}
2025-08-16 06:37:33,208 - INFO - val: {'epoch': 56, 'time_epoch': 4.29856, 'loss': 0.07516152, 'lr': 0, 'params': 451793, 'time_iter': 0.03332, 'accuracy': 0.98225, 'precision': 0.58696, 'recall': 0.33333, 'f1': 0.4252, 'auc': 0.77701}
2025-08-16 06:37:37,526 - INFO - test: {'epoch': 56, 'time_epoch': 4.30029, 'loss': 0.11763287, 'lr': 0, 'params': 451793, 'time_iter': 0.03334, 'accuracy': 0.96985, 'precision': 0.55769, 'recall': 0.22308, 'f1': 0.31868, 'auc': 0.7577}
2025-08-16 06:37:37,528 - INFO - > Epoch 56: took 75.1s (avg 77.5s) | Best so far: epoch 54	train_loss: 0.1062 train_auc: 0.8644	val_loss: 0.0714 val_auc: 0.7987	test_loss: 0.1148 test_auc: 0.7711
2025-08-16 06:38:45,934 - INFO - train: {'epoch': 57, 'time_epoch': 68.32338, 'eta': 2891.25721, 'eta_hours': 0.80313, 'loss': 0.10571196, 'lr': 4.259e-05, 'params': 451793, 'time_iter': 0.0664, 'accuracy': 0.96979, 'precision': 0.69508, 'recall': 0.34416, 'f1': 0.46037, 'auc': 0.86284}
2025-08-16 06:38:50,186 - INFO - val: {'epoch': 57, 'time_epoch': 4.23065, 'loss': 0.07342739, 'lr': 0, 'params': 451793, 'time_iter': 0.0328, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.78125}
2025-08-16 06:38:54,423 - INFO - test: {'epoch': 57, 'time_epoch': 4.22038, 'loss': 0.11766851, 'lr': 0, 'params': 451793, 'time_iter': 0.03272, 'accuracy': 0.96864, 'precision': 0.50847, 'recall': 0.23077, 'f1': 0.31746, 'auc': 0.75831}
2025-08-16 06:38:54,429 - INFO - > Epoch 57: took 76.9s (avg 77.5s) | Best so far: epoch 54	train_loss: 0.1062 train_auc: 0.8644	val_loss: 0.0714 val_auc: 0.7987	test_loss: 0.1148 test_auc: 0.7711
2025-08-16 06:40:02,880 - INFO - train: {'epoch': 58, 'time_epoch': 68.35431, 'eta': 2822.08062, 'eta_hours': 0.78391, 'loss': 0.10391535, 'lr': 4.096e-05, 'params': 451793, 'time_iter': 0.06643, 'accuracy': 0.96951, 'precision': 0.68618, 'recall': 0.34253, 'f1': 0.45696, 'auc': 0.87059}
2025-08-16 06:40:07,311 - INFO - val: {'epoch': 58, 'time_epoch': 4.40608, 'loss': 0.07339444, 'lr': 0, 'params': 451793, 'time_iter': 0.03416, 'accuracy': 0.98274, 'precision': 0.61905, 'recall': 0.32099, 'f1': 0.42276, 'auc': 0.78125}
2025-08-16 06:40:11,700 - INFO - test: {'epoch': 58, 'time_epoch': 4.37042, 'loss': 0.11872618, 'lr': 0, 'params': 451793, 'time_iter': 0.03388, 'accuracy': 0.96912, 'precision': 0.52174, 'recall': 0.27692, 'f1': 0.36181, 'auc': 0.75241}
2025-08-16 06:40:11,702 - INFO - > Epoch 58: took 77.3s (avg 77.5s) | Best so far: epoch 54	train_loss: 0.1062 train_auc: 0.8644	val_loss: 0.0714 val_auc: 0.7987	test_loss: 0.1148 test_auc: 0.7711
2025-08-16 06:41:19,864 - INFO - train: {'epoch': 59, 'time_epoch': 68.07843, 'eta': 2752.74751, 'eta_hours': 0.76465, 'loss': 0.10476579, 'lr': 3.934e-05, 'params': 451793, 'time_iter': 0.06616, 'accuracy': 0.97018, 'precision': 0.70744, 'recall': 0.3474, 'f1': 0.46598, 'auc': 0.86806}
2025-08-16 06:41:24,042 - INFO - val: {'epoch': 59, 'time_epoch': 4.15502, 'loss': 0.07249241, 'lr': 0, 'params': 451793, 'time_iter': 0.03221, 'accuracy': 0.98395, 'precision': 0.72727, 'recall': 0.2963, 'f1': 0.42105, 'auc': 0.76861}
2025-08-16 06:41:28,211 - INFO - test: {'epoch': 59, 'time_epoch': 4.15109, 'loss': 0.11833881, 'lr': 0, 'params': 451793, 'time_iter': 0.03218, 'accuracy': 0.97034, 'precision': 0.59091, 'recall': 0.2, 'f1': 0.29885, 'auc': 0.74666}
2025-08-16 06:41:28,213 - INFO - > Epoch 59: took 76.5s (avg 77.5s) | Best so far: epoch 54	train_loss: 0.1062 train_auc: 0.8644	val_loss: 0.0714 val_auc: 0.7987	test_loss: 0.1148 test_auc: 0.7711
2025-08-16 06:42:36,431 - INFO - train: {'epoch': 60, 'time_epoch': 68.13455, 'eta': 2683.49143, 'eta_hours': 0.74541, 'loss': 0.10374291, 'lr': 3.773e-05, 'params': 451793, 'time_iter': 0.06621, 'accuracy': 0.97018, 'precision': 0.69764, 'recall': 0.35958, 'f1': 0.47456, 'auc': 0.87513}
2025-08-16 06:42:40,732 - INFO - val: {'epoch': 60, 'time_epoch': 4.27874, 'loss': 0.07172873, 'lr': 0, 'params': 451793, 'time_iter': 0.03317, 'accuracy': 0.98371, 'precision': 0.69444, 'recall': 0.30864, 'f1': 0.42735, 'auc': 0.78406}
2025-08-16 06:42:45,053 - INFO - test: {'epoch': 60, 'time_epoch': 4.30326, 'loss': 0.11776517, 'lr': 0, 'params': 451793, 'time_iter': 0.03336, 'accuracy': 0.97034, 'precision': 0.57143, 'recall': 0.24615, 'f1': 0.34409, 'auc': 0.75899}
2025-08-16 06:42:45,056 - INFO - > Epoch 60: took 76.8s (avg 77.5s) | Best so far: epoch 54	train_loss: 0.1062 train_auc: 0.8644	val_loss: 0.0714 val_auc: 0.7987	test_loss: 0.1148 test_auc: 0.7711
2025-08-16 06:43:53,967 - INFO - train: {'epoch': 61, 'time_epoch': 68.83486, 'eta': 2614.70074, 'eta_hours': 0.72631, 'loss': 0.10359723, 'lr': 3.613e-05, 'params': 451793, 'time_iter': 0.06689, 'accuracy': 0.97018, 'precision': 0.71022, 'recall': 0.34416, 'f1': 0.46364, 'auc': 0.87578}
2025-08-16 06:43:58,458 - INFO - val: {'epoch': 61, 'time_epoch': 4.46741, 'loss': 0.0748974, 'lr': 0, 'params': 451793, 'time_iter': 0.03463, 'accuracy': 0.98177, 'precision': 0.55769, 'recall': 0.35802, 'f1': 0.43609, 'auc': 0.78871}
2025-08-16 06:44:02,858 - INFO - test: {'epoch': 61, 'time_epoch': 4.37732, 'loss': 0.1232432, 'lr': 0, 'params': 451793, 'time_iter': 0.03393, 'accuracy': 0.96693, 'precision': 0.46739, 'recall': 0.33077, 'f1': 0.38739, 'auc': 0.75275}
2025-08-16 06:44:02,861 - INFO - > Epoch 61: took 77.8s (avg 77.5s) | Best so far: epoch 54	train_loss: 0.1062 train_auc: 0.8644	val_loss: 0.0714 val_auc: 0.7987	test_loss: 0.1148 test_auc: 0.7711
2025-08-16 06:45:14,269 - INFO - train: {'epoch': 62, 'time_epoch': 71.32691, 'eta': 2547.37224, 'eta_hours': 0.7076, 'loss': 0.10318229, 'lr': 3.455e-05, 'params': 451793, 'time_iter': 0.06932, 'accuracy': 0.97034, 'precision': 0.70579, 'recall': 0.35633, 'f1': 0.47357, 'auc': 0.87527}
2025-08-16 06:45:18,744 - INFO - val: {'epoch': 62, 'time_epoch': 4.45238, 'loss': 0.07228928, 'lr': 0, 'params': 451793, 'time_iter': 0.03451, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.79694}
2025-08-16 06:45:23,148 - INFO - test: {'epoch': 62, 'time_epoch': 4.38419, 'loss': 0.11752021, 'lr': 0, 'params': 451793, 'time_iter': 0.03399, 'accuracy': 0.96937, 'precision': 0.53448, 'recall': 0.23846, 'f1': 0.32979, 'auc': 0.76446}
2025-08-16 06:45:23,156 - INFO - > Epoch 62: took 80.3s (avg 77.5s) | Best so far: epoch 54	train_loss: 0.1062 train_auc: 0.8644	val_loss: 0.0714 val_auc: 0.7987	test_loss: 0.1148 test_auc: 0.7711
2025-08-16 06:46:34,444 - INFO - train: {'epoch': 63, 'time_epoch': 71.19503, 'eta': 2479.8446, 'eta_hours': 0.68885, 'loss': 0.10374085, 'lr': 3.299e-05, 'params': 451793, 'time_iter': 0.06919, 'accuracy': 0.97027, 'precision': 0.70617, 'recall': 0.35308, 'f1': 0.47078, 'auc': 0.87696}
2025-08-16 06:46:38,888 - INFO - val: {'epoch': 63, 'time_epoch': 4.41821, 'loss': 0.07291224, 'lr': 0, 'params': 451793, 'time_iter': 0.03425, 'accuracy': 0.98371, 'precision': 0.68421, 'recall': 0.32099, 'f1': 0.43697, 'auc': 0.77157}
2025-08-16 06:46:43,314 - INFO - test: {'epoch': 63, 'time_epoch': 4.40822, 'loss': 0.12157402, 'lr': 0, 'params': 451793, 'time_iter': 0.03417, 'accuracy': 0.96888, 'precision': 0.52273, 'recall': 0.17692, 'f1': 0.26437, 'auc': 0.75225}
2025-08-16 06:46:43,316 - INFO - > Epoch 63: took 80.2s (avg 77.6s) | Best so far: epoch 54	train_loss: 0.1062 train_auc: 0.8644	val_loss: 0.0714 val_auc: 0.7987	test_loss: 0.1148 test_auc: 0.7711
2025-08-16 06:47:54,575 - INFO - train: {'epoch': 64, 'time_epoch': 71.17462, 'eta': 2412.19313, 'eta_hours': 0.67005, 'loss': 0.10377784, 'lr': 3.144e-05, 'params': 451793, 'time_iter': 0.06917, 'accuracy': 0.96982, 'precision': 0.69305, 'recall': 0.34821, 'f1': 0.46353, 'auc': 0.87134}
2025-08-16 06:47:59,001 - INFO - val: {'epoch': 64, 'time_epoch': 4.40104, 'loss': 0.07192746, 'lr': 0, 'params': 451793, 'time_iter': 0.03412, 'accuracy': 0.9842, 'precision': 0.72222, 'recall': 0.32099, 'f1': 0.44444, 'auc': 0.77736}
2025-08-16 06:48:03,358 - INFO - test: {'epoch': 64, 'time_epoch': 4.33578, 'loss': 0.12005245, 'lr': 0, 'params': 451793, 'time_iter': 0.03361, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.20769, 'f1': 0.29348, 'auc': 0.75928}
2025-08-16 06:48:03,360 - INFO - > Epoch 64: took 80.0s (avg 77.6s) | Best so far: epoch 54	train_loss: 0.1062 train_auc: 0.8644	val_loss: 0.0714 val_auc: 0.7987	test_loss: 0.1148 test_auc: 0.7711
2025-08-16 06:49:13,907 - INFO - train: {'epoch': 65, 'time_epoch': 70.46318, 'eta': 2344.0684, 'eta_hours': 0.65113, 'loss': 0.10209086, 'lr': 2.992e-05, 'params': 451793, 'time_iter': 0.06848, 'accuracy': 0.97, 'precision': 0.6979, 'recall': 0.35065, 'f1': 0.46677, 'auc': 0.87904}
2025-08-16 06:49:18,030 - INFO - val: {'epoch': 65, 'time_epoch': 4.10146, 'loss': 0.07161597, 'lr': 0, 'params': 451793, 'time_iter': 0.03179, 'accuracy': 0.98298, 'precision': 0.62791, 'recall': 0.33333, 'f1': 0.43548, 'auc': 0.79169}
2025-08-16 06:49:22,156 - INFO - test: {'epoch': 65, 'time_epoch': 4.10901, 'loss': 0.11769904, 'lr': 0, 'params': 451793, 'time_iter': 0.03185, 'accuracy': 0.96937, 'precision': 0.52857, 'recall': 0.28462, 'f1': 0.37, 'auc': 0.75555}
2025-08-16 06:49:22,158 - INFO - > Epoch 65: took 78.8s (avg 77.6s) | Best so far: epoch 54	train_loss: 0.1062 train_auc: 0.8644	val_loss: 0.0714 val_auc: 0.7987	test_loss: 0.1148 test_auc: 0.7711
2025-08-16 06:50:30,646 - INFO - train: {'epoch': 66, 'time_epoch': 68.39957, 'eta': 2274.85746, 'eta_hours': 0.6319, 'loss': 0.10255249, 'lr': 2.841e-05, 'params': 451793, 'time_iter': 0.06647, 'accuracy': 0.97146, 'precision': 0.74457, 'recall': 0.36201, 'f1': 0.48717, 'auc': 0.87584}
2025-08-16 06:50:34,893 - INFO - val: {'epoch': 66, 'time_epoch': 4.22115, 'loss': 0.07229208, 'lr': 0, 'params': 451793, 'time_iter': 0.03272, 'accuracy': 0.98395, 'precision': 0.68293, 'recall': 0.34568, 'f1': 0.45902, 'auc': 0.79133}
2025-08-16 06:50:39,195 - INFO - test: {'epoch': 66, 'time_epoch': 4.28465, 'loss': 0.11978695, 'lr': 0, 'params': 451793, 'time_iter': 0.03321, 'accuracy': 0.96961, 'precision': 0.54237, 'recall': 0.24615, 'f1': 0.33862, 'auc': 0.76001}
2025-08-16 06:50:39,198 - INFO - > Epoch 66: took 77.0s (avg 77.6s) | Best so far: epoch 54	train_loss: 0.1062 train_auc: 0.8644	val_loss: 0.0714 val_auc: 0.7987	test_loss: 0.1148 test_auc: 0.7711
2025-08-16 06:51:46,949 - INFO - train: {'epoch': 67, 'time_epoch': 67.66463, 'eta': 2205.32453, 'eta_hours': 0.61259, 'loss': 0.1017244, 'lr': 2.693e-05, 'params': 451793, 'time_iter': 0.06576, 'accuracy': 0.96985, 'precision': 0.68634, 'recall': 0.35877, 'f1': 0.47122, 'auc': 0.88087}
2025-08-16 06:51:51,252 - INFO - val: {'epoch': 67, 'time_epoch': 4.27924, 'loss': 0.07087729, 'lr': 0, 'params': 451793, 'time_iter': 0.03317, 'accuracy': 0.98347, 'precision': 0.69697, 'recall': 0.28395, 'f1': 0.40351, 'auc': 0.7905}
2025-08-16 06:51:55,560 - INFO - test: {'epoch': 67, 'time_epoch': 4.28933, 'loss': 0.11686966, 'lr': 0, 'params': 451793, 'time_iter': 0.03325, 'accuracy': 0.96912, 'precision': 0.5283, 'recall': 0.21538, 'f1': 0.30601, 'auc': 0.75565}
2025-08-16 06:51:55,563 - INFO - > Epoch 67: took 76.4s (avg 77.6s) | Best so far: epoch 54	train_loss: 0.1062 train_auc: 0.8644	val_loss: 0.0714 val_auc: 0.7987	test_loss: 0.1148 test_auc: 0.7711
2025-08-16 06:53:03,692 - INFO - train: {'epoch': 68, 'time_epoch': 68.04513, 'eta': 2136.0167, 'eta_hours': 0.59334, 'loss': 0.10101494, 'lr': 2.548e-05, 'params': 451793, 'time_iter': 0.06613, 'accuracy': 0.97027, 'precision': 0.70353, 'recall': 0.35633, 'f1': 0.47306, 'auc': 0.88618}
2025-08-16 06:53:07,918 - INFO - val: {'epoch': 68, 'time_epoch': 4.2045, 'loss': 0.07117266, 'lr': 0, 'params': 451793, 'time_iter': 0.03259, 'accuracy': 0.98395, 'precision': 0.68293, 'recall': 0.34568, 'f1': 0.45902, 'auc': 0.7933}
2025-08-16 06:53:12,147 - INFO - test: {'epoch': 68, 'time_epoch': 4.21193, 'loss': 0.11926108, 'lr': 0, 'params': 451793, 'time_iter': 0.03265, 'accuracy': 0.96961, 'precision': 0.54386, 'recall': 0.23846, 'f1': 0.33155, 'auc': 0.75872}
2025-08-16 06:53:12,150 - INFO - > Epoch 68: took 76.6s (avg 77.6s) | Best so far: epoch 54	train_loss: 0.1062 train_auc: 0.8644	val_loss: 0.0714 val_auc: 0.7987	test_loss: 0.1148 test_auc: 0.7711
2025-08-16 06:54:20,574 - INFO - train: {'epoch': 69, 'time_epoch': 68.34465, 'eta': 2066.87332, 'eta_hours': 0.57413, 'loss': 0.10040543, 'lr': 2.405e-05, 'params': 451793, 'time_iter': 0.06642, 'accuracy': 0.97061, 'precision': 0.70801, 'recall': 0.36607, 'f1': 0.48261, 'auc': 0.88582}
2025-08-16 06:54:24,827 - INFO - val: {'epoch': 69, 'time_epoch': 4.23247, 'loss': 0.07010773, 'lr': 0, 'params': 451793, 'time_iter': 0.03281, 'accuracy': 0.9842, 'precision': 0.73529, 'recall': 0.30864, 'f1': 0.43478, 'auc': 0.79992}
2025-08-16 06:54:29,069 - INFO - test: {'epoch': 69, 'time_epoch': 4.2244, 'loss': 0.11832439, 'lr': 0, 'params': 451793, 'time_iter': 0.03275, 'accuracy': 0.96937, 'precision': 0.53846, 'recall': 0.21538, 'f1': 0.30769, 'auc': 0.76482}
2025-08-16 06:54:29,072 - INFO - > Epoch 69: took 76.9s (avg 77.6s) | Best so far: epoch 69	train_loss: 0.1004 train_auc: 0.8858	val_loss: 0.0701 val_auc: 0.7999	test_loss: 0.1183 test_auc: 0.7648
2025-08-16 06:55:37,968 - INFO - train: {'epoch': 70, 'time_epoch': 68.81108, 'eta': 1997.94295, 'eta_hours': 0.55498, 'loss': 0.10202217, 'lr': 2.265e-05, 'params': 451793, 'time_iter': 0.06687, 'accuracy': 0.97073, 'precision': 0.71659, 'recall': 0.3612, 'f1': 0.4803, 'auc': 0.88118}
2025-08-16 06:55:42,348 - INFO - val: {'epoch': 70, 'time_epoch': 4.35714, 'loss': 0.07276336, 'lr': 0, 'params': 451793, 'time_iter': 0.03378, 'accuracy': 0.98371, 'precision': 0.675, 'recall': 0.33333, 'f1': 0.44628, 'auc': 0.78691}
2025-08-16 06:55:46,755 - INFO - test: {'epoch': 70, 'time_epoch': 4.38794, 'loss': 0.11959836, 'lr': 0, 'params': 451793, 'time_iter': 0.03402, 'accuracy': 0.97034, 'precision': 0.5625, 'recall': 0.27692, 'f1': 0.37113, 'auc': 0.75485}
2025-08-16 06:55:46,757 - INFO - > Epoch 70: took 77.7s (avg 77.6s) | Best so far: epoch 69	train_loss: 0.1004 train_auc: 0.8858	val_loss: 0.0701 val_auc: 0.7999	test_loss: 0.1183 test_auc: 0.7648
2025-08-16 06:56:55,136 - INFO - train: {'epoch': 71, 'time_epoch': 68.29652, 'eta': 1928.81578, 'eta_hours': 0.53578, 'loss': 0.09978401, 'lr': 2.128e-05, 'params': 451793, 'time_iter': 0.06637, 'accuracy': 0.97076, 'precision': 0.71635, 'recall': 0.36282, 'f1': 0.48168, 'auc': 0.88758}
2025-08-16 06:56:59,457 - INFO - val: {'epoch': 71, 'time_epoch': 4.2987, 'loss': 0.07239132, 'lr': 0, 'params': 451793, 'time_iter': 0.03332, 'accuracy': 0.98274, 'precision': 0.6087, 'recall': 0.34568, 'f1': 0.44094, 'auc': 0.80275}
2025-08-16 06:57:03,718 - INFO - test: {'epoch': 71, 'time_epoch': 4.24343, 'loss': 0.12038022, 'lr': 0, 'params': 451793, 'time_iter': 0.03289, 'accuracy': 0.97009, 'precision': 0.54667, 'recall': 0.31538, 'f1': 0.4, 'auc': 0.75565}
2025-08-16 06:57:03,721 - INFO - > Epoch 71: took 77.0s (avg 77.6s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 06:58:12,193 - INFO - train: {'epoch': 72, 'time_epoch': 68.38786, 'eta': 1859.74516, 'eta_hours': 0.5166, 'loss': 0.09978356, 'lr': 1.995e-05, 'params': 451793, 'time_iter': 0.06646, 'accuracy': 0.97091, 'precision': 0.7186, 'recall': 0.36688, 'f1': 0.48576, 'auc': 0.88713}
2025-08-16 06:58:16,502 - INFO - val: {'epoch': 72, 'time_epoch': 4.28739, 'loss': 0.07156166, 'lr': 0, 'params': 451793, 'time_iter': 0.03324, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.79197}
2025-08-16 06:58:20,792 - INFO - test: {'epoch': 72, 'time_epoch': 4.27214, 'loss': 0.11970132, 'lr': 0, 'params': 451793, 'time_iter': 0.03312, 'accuracy': 0.96937, 'precision': 0.53571, 'recall': 0.23077, 'f1': 0.32258, 'auc': 0.75073}
2025-08-16 06:58:20,794 - INFO - > Epoch 72: took 77.1s (avg 77.6s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 06:59:28,760 - INFO - train: {'epoch': 73, 'time_epoch': 67.88429, 'eta': 1790.51605, 'eta_hours': 0.49737, 'loss': 0.09914491, 'lr': 1.864e-05, 'params': 451793, 'time_iter': 0.06597, 'accuracy': 0.97143, 'precision': 0.72671, 'recall': 0.37987, 'f1': 0.49893, 'auc': 0.8861}
2025-08-16 06:59:33,027 - INFO - val: {'epoch': 73, 'time_epoch': 4.24239, 'loss': 0.07128649, 'lr': 0, 'params': 451793, 'time_iter': 0.03289, 'accuracy': 0.9842, 'precision': 0.73529, 'recall': 0.30864, 'f1': 0.43478, 'auc': 0.79981}
2025-08-16 06:59:37,308 - INFO - test: {'epoch': 73, 'time_epoch': 4.26255, 'loss': 0.12006068, 'lr': 0, 'params': 451793, 'time_iter': 0.03304, 'accuracy': 0.97155, 'precision': 0.61404, 'recall': 0.26923, 'f1': 0.37433, 'auc': 0.75055}
2025-08-16 06:59:37,310 - INFO - > Epoch 73: took 76.5s (avg 77.5s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:00:43,431 - INFO - train: {'epoch': 74, 'time_epoch': 66.03651, 'eta': 1720.70689, 'eta_hours': 0.47797, 'loss': 0.10027799, 'lr': 1.737e-05, 'params': 451793, 'time_iter': 0.06418, 'accuracy': 0.97128, 'precision': 0.72742, 'recall': 0.37256, 'f1': 0.49275, 'auc': 0.88188}
2025-08-16 07:00:47,637 - INFO - val: {'epoch': 74, 'time_epoch': 4.18498, 'loss': 0.07089856, 'lr': 0, 'params': 451793, 'time_iter': 0.03244, 'accuracy': 0.98347, 'precision': 0.65116, 'recall': 0.34568, 'f1': 0.45161, 'auc': 0.8016}
2025-08-16 07:00:51,836 - INFO - test: {'epoch': 74, 'time_epoch': 4.18116, 'loss': 0.11839317, 'lr': 0, 'params': 451793, 'time_iter': 0.03241, 'accuracy': 0.97009, 'precision': 0.55072, 'recall': 0.29231, 'f1': 0.38191, 'auc': 0.75209}
2025-08-16 07:00:51,839 - INFO - > Epoch 74: took 74.5s (avg 77.5s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:01:59,504 - INFO - train: {'epoch': 75, 'time_epoch': 67.58194, 'eta': 1651.48503, 'eta_hours': 0.45875, 'loss': 0.10073687, 'lr': 1.614e-05, 'params': 451793, 'time_iter': 0.06568, 'accuracy': 0.97161, 'precision': 0.74267, 'recall': 0.37013, 'f1': 0.49404, 'auc': 0.8802}
2025-08-16 07:02:03,768 - INFO - val: {'epoch': 75, 'time_epoch': 4.24213, 'loss': 0.07065418, 'lr': 0, 'params': 451793, 'time_iter': 0.03288, 'accuracy': 0.98395, 'precision': 0.67442, 'recall': 0.35802, 'f1': 0.46774, 'auc': 0.79899}
2025-08-16 07:02:07,989 - INFO - test: {'epoch': 75, 'time_epoch': 4.20507, 'loss': 0.11885687, 'lr': 0, 'params': 451793, 'time_iter': 0.0326, 'accuracy': 0.96985, 'precision': 0.5375, 'recall': 0.33077, 'f1': 0.40952, 'auc': 0.75778}
2025-08-16 07:02:07,991 - INFO - > Epoch 75: took 76.2s (avg 77.5s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:03:14,964 - INFO - train: {'epoch': 76, 'time_epoch': 66.8846, 'eta': 1582.09748, 'eta_hours': 0.43947, 'loss': 0.1002697, 'lr': 1.494e-05, 'params': 451793, 'time_iter': 0.065, 'accuracy': 0.971, 'precision': 0.71254, 'recall': 0.37825, 'f1': 0.49417, 'auc': 0.8882}
2025-08-16 07:03:19,177 - INFO - val: {'epoch': 76, 'time_epoch': 4.19098, 'loss': 0.07060553, 'lr': 0, 'params': 451793, 'time_iter': 0.03249, 'accuracy': 0.98395, 'precision': 0.71429, 'recall': 0.30864, 'f1': 0.43103, 'auc': 0.79955}
2025-08-16 07:03:23,416 - INFO - test: {'epoch': 76, 'time_epoch': 4.22062, 'loss': 0.1195376, 'lr': 0, 'params': 451793, 'time_iter': 0.03272, 'accuracy': 0.96985, 'precision': 0.55357, 'recall': 0.23846, 'f1': 0.33333, 'auc': 0.75236}
2025-08-16 07:03:23,418 - INFO - > Epoch 76: took 75.4s (avg 77.5s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:04:30,451 - INFO - train: {'epoch': 77, 'time_epoch': 66.95679, 'eta': 1512.79446, 'eta_hours': 0.42022, 'loss': 0.10001411, 'lr': 1.378e-05, 'params': 451793, 'time_iter': 0.06507, 'accuracy': 0.97076, 'precision': 0.71565, 'recall': 0.36364, 'f1': 0.48224, 'auc': 0.88254}
2025-08-16 07:04:34,475 - INFO - val: {'epoch': 77, 'time_epoch': 4.00261, 'loss': 0.07256636, 'lr': 0, 'params': 451793, 'time_iter': 0.03103, 'accuracy': 0.98347, 'precision': 0.68571, 'recall': 0.2963, 'f1': 0.41379, 'auc': 0.78597}
2025-08-16 07:04:38,543 - INFO - test: {'epoch': 77, 'time_epoch': 4.05121, 'loss': 0.12319486, 'lr': 0, 'params': 451793, 'time_iter': 0.0314, 'accuracy': 0.96985, 'precision': 0.56818, 'recall': 0.19231, 'f1': 0.28736, 'auc': 0.75172}
2025-08-16 07:04:38,546 - INFO - > Epoch 77: took 75.1s (avg 77.4s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:05:46,353 - INFO - train: {'epoch': 78, 'time_epoch': 67.72301, 'eta': 1443.75452, 'eta_hours': 0.40104, 'loss': 0.09826366, 'lr': 1.266e-05, 'params': 451793, 'time_iter': 0.06581, 'accuracy': 0.97182, 'precision': 0.7394, 'recall': 0.38231, 'f1': 0.50401, 'auc': 0.89298}
2025-08-16 07:05:50,615 - INFO - val: {'epoch': 78, 'time_epoch': 4.23929, 'loss': 0.07195435, 'lr': 0, 'params': 451793, 'time_iter': 0.03286, 'accuracy': 0.98371, 'precision': 0.69444, 'recall': 0.30864, 'f1': 0.42735, 'auc': 0.78957}
2025-08-16 07:05:54,878 - INFO - test: {'epoch': 78, 'time_epoch': 4.24582, 'loss': 0.12062818, 'lr': 0, 'params': 451793, 'time_iter': 0.03291, 'accuracy': 0.96937, 'precision': 0.53571, 'recall': 0.23077, 'f1': 0.32258, 'auc': 0.75152}
2025-08-16 07:05:54,880 - INFO - > Epoch 78: took 76.3s (avg 77.4s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:07:02,876 - INFO - train: {'epoch': 79, 'time_epoch': 67.91205, 'eta': 1374.79476, 'eta_hours': 0.38189, 'loss': 0.09905713, 'lr': 1.158e-05, 'params': 451793, 'time_iter': 0.066, 'accuracy': 0.97207, 'precision': 0.75614, 'recall': 0.375, 'f1': 0.50136, 'auc': 0.88824}
2025-08-16 07:07:07,151 - INFO - val: {'epoch': 79, 'time_epoch': 4.25292, 'loss': 0.07171433, 'lr': 0, 'params': 451793, 'time_iter': 0.03297, 'accuracy': 0.98347, 'precision': 0.68571, 'recall': 0.2963, 'f1': 0.41379, 'auc': 0.79326}
2025-08-16 07:07:11,376 - INFO - test: {'epoch': 79, 'time_epoch': 4.20692, 'loss': 0.12239378, 'lr': 0, 'params': 451793, 'time_iter': 0.03261, 'accuracy': 0.97009, 'precision': 0.58537, 'recall': 0.18462, 'f1': 0.2807, 'auc': 0.74956}
2025-08-16 07:07:11,379 - INFO - > Epoch 79: took 76.5s (avg 77.4s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:08:19,264 - INFO - train: {'epoch': 80, 'time_epoch': 67.80262, 'eta': 1305.83521, 'eta_hours': 0.36273, 'loss': 0.09967098, 'lr': 1.054e-05, 'params': 451793, 'time_iter': 0.06589, 'accuracy': 0.97082, 'precision': 0.71118, 'recall': 0.37175, 'f1': 0.48827, 'auc': 0.8884}
2025-08-16 07:08:23,335 - INFO - val: {'epoch': 80, 'time_epoch': 4.04844, 'loss': 0.07237755, 'lr': 0, 'params': 451793, 'time_iter': 0.03138, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.79356}
2025-08-16 07:08:27,383 - INFO - test: {'epoch': 80, 'time_epoch': 4.03135, 'loss': 0.12249219, 'lr': 0, 'params': 451793, 'time_iter': 0.03125, 'accuracy': 0.97034, 'precision': 0.58696, 'recall': 0.20769, 'f1': 0.30682, 'auc': 0.74865}
2025-08-16 07:08:27,385 - INFO - > Epoch 80: took 76.0s (avg 77.4s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:09:33,806 - INFO - train: {'epoch': 81, 'time_epoch': 66.34158, 'eta': 1236.58315, 'eta_hours': 0.3435, 'loss': 0.09938289, 'lr': 9.55e-06, 'params': 451793, 'time_iter': 0.06447, 'accuracy': 0.97131, 'precision': 0.72291, 'recall': 0.37906, 'f1': 0.49734, 'auc': 0.88887}
2025-08-16 07:09:37,944 - INFO - val: {'epoch': 81, 'time_epoch': 4.11507, 'loss': 0.07219772, 'lr': 0, 'params': 451793, 'time_iter': 0.0319, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.78627}
2025-08-16 07:09:42,229 - INFO - test: {'epoch': 81, 'time_epoch': 4.2674, 'loss': 0.12053248, 'lr': 0, 'params': 451793, 'time_iter': 0.03308, 'accuracy': 0.96961, 'precision': 0.54237, 'recall': 0.24615, 'f1': 0.33862, 'auc': 0.75323}
2025-08-16 07:09:42,231 - INFO - > Epoch 81: took 74.8s (avg 77.3s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:10:50,420 - INFO - train: {'epoch': 82, 'time_epoch': 68.1038, 'eta': 1167.76217, 'eta_hours': 0.32438, 'loss': 0.09866966, 'lr': 8.6e-06, 'params': 451793, 'time_iter': 0.06618, 'accuracy': 0.97125, 'precision': 0.73366, 'recall': 0.36445, 'f1': 0.48698, 'auc': 0.8923}
2025-08-16 07:10:54,429 - INFO - val: {'epoch': 82, 'time_epoch': 3.9877, 'loss': 0.0728903, 'lr': 0, 'params': 451793, 'time_iter': 0.03091, 'accuracy': 0.98322, 'precision': 0.64286, 'recall': 0.33333, 'f1': 0.43902, 'auc': 0.79079}
2025-08-16 07:10:58,594 - INFO - test: {'epoch': 82, 'time_epoch': 4.14711, 'loss': 0.12121599, 'lr': 0, 'params': 451793, 'time_iter': 0.03215, 'accuracy': 0.96937, 'precision': 0.53125, 'recall': 0.26154, 'f1': 0.35052, 'auc': 0.75328}
2025-08-16 07:10:58,598 - INFO - > Epoch 82: took 76.4s (avg 77.3s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:12:05,581 - INFO - train: {'epoch': 83, 'time_epoch': 66.90078, 'eta': 1098.72911, 'eta_hours': 0.3052, 'loss': 0.0989078, 'lr': 7.7e-06, 'params': 451793, 'time_iter': 0.06502, 'accuracy': 0.97152, 'precision': 0.73906, 'recall': 0.37013, 'f1': 0.49324, 'auc': 0.89226}
2025-08-16 07:12:09,890 - INFO - val: {'epoch': 83, 'time_epoch': 4.25846, 'loss': 0.07191272, 'lr': 0, 'params': 451793, 'time_iter': 0.03301, 'accuracy': 0.98347, 'precision': 0.65854, 'recall': 0.33333, 'f1': 0.44262, 'auc': 0.79249}
2025-08-16 07:12:14,263 - INFO - test: {'epoch': 83, 'time_epoch': 4.35565, 'loss': 0.12019935, 'lr': 0, 'params': 451793, 'time_iter': 0.03376, 'accuracy': 0.96937, 'precision': 0.53226, 'recall': 0.25385, 'f1': 0.34375, 'auc': 0.75347}
2025-08-16 07:12:14,266 - INFO - > Epoch 83: took 75.7s (avg 77.3s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:13:21,601 - INFO - train: {'epoch': 84, 'time_epoch': 67.25212, 'eta': 1029.80823, 'eta_hours': 0.28606, 'loss': 0.09747347, 'lr': 6.84e-06, 'params': 451793, 'time_iter': 0.06536, 'accuracy': 0.97167, 'precision': 0.7259, 'recall': 0.39123, 'f1': 0.50844, 'auc': 0.8922}
2025-08-16 07:13:25,934 - INFO - val: {'epoch': 84, 'time_epoch': 4.30856, 'loss': 0.07203462, 'lr': 0, 'params': 451793, 'time_iter': 0.0334, 'accuracy': 0.98347, 'precision': 0.65854, 'recall': 0.33333, 'f1': 0.44262, 'auc': 0.79447}
2025-08-16 07:13:30,237 - INFO - test: {'epoch': 84, 'time_epoch': 4.2835, 'loss': 0.12071912, 'lr': 0, 'params': 451793, 'time_iter': 0.03321, 'accuracy': 0.96888, 'precision': 0.51562, 'recall': 0.25385, 'f1': 0.34021, 'auc': 0.75508}
2025-08-16 07:13:30,239 - INFO - > Epoch 84: took 76.0s (avg 77.3s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:14:37,554 - INFO - train: {'epoch': 85, 'time_epoch': 67.23083, 'eta': 960.92269, 'eta_hours': 0.26692, 'loss': 0.09823236, 'lr': 6.03e-06, 'params': 451793, 'time_iter': 0.06534, 'accuracy': 0.97195, 'precision': 0.74178, 'recall': 0.38474, 'f1': 0.50668, 'auc': 0.89315}
2025-08-16 07:14:41,704 - INFO - val: {'epoch': 85, 'time_epoch': 4.12802, 'loss': 0.07175961, 'lr': 0, 'params': 451793, 'time_iter': 0.032, 'accuracy': 0.98322, 'precision': 0.66667, 'recall': 0.2963, 'f1': 0.41026, 'auc': 0.79302}
2025-08-16 07:14:45,845 - INFO - test: {'epoch': 85, 'time_epoch': 4.12349, 'loss': 0.12076608, 'lr': 0, 'params': 451793, 'time_iter': 0.03197, 'accuracy': 0.96937, 'precision': 0.53448, 'recall': 0.23846, 'f1': 0.32979, 'auc': 0.75046}
2025-08-16 07:14:45,848 - INFO - > Epoch 85: took 75.6s (avg 77.3s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:15:52,214 - INFO - train: {'epoch': 86, 'time_epoch': 66.28264, 'eta': 891.9335, 'eta_hours': 0.24776, 'loss': 0.09902833, 'lr': 5.26e-06, 'params': 451793, 'time_iter': 0.06441, 'accuracy': 0.9717, 'precision': 0.74794, 'recall': 0.36851, 'f1': 0.49375, 'auc': 0.88921}
2025-08-16 07:15:56,471 - INFO - val: {'epoch': 86, 'time_epoch': 4.23598, 'loss': 0.07281635, 'lr': 0, 'params': 451793, 'time_iter': 0.03284, 'accuracy': 0.98347, 'precision': 0.65116, 'recall': 0.34568, 'f1': 0.45161, 'auc': 0.78898}
2025-08-16 07:16:00,701 - INFO - test: {'epoch': 86, 'time_epoch': 4.21208, 'loss': 0.12145739, 'lr': 0, 'params': 451793, 'time_iter': 0.03265, 'accuracy': 0.96912, 'precision': 0.52381, 'recall': 0.25385, 'f1': 0.34197, 'auc': 0.75535}
2025-08-16 07:16:00,703 - INFO - > Epoch 86: took 74.9s (avg 77.3s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:17:09,035 - INFO - train: {'epoch': 87, 'time_epoch': 68.24549, 'eta': 823.27349, 'eta_hours': 0.22869, 'loss': 0.09824132, 'lr': 4.55e-06, 'params': 451793, 'time_iter': 0.06632, 'accuracy': 0.97094, 'precision': 0.71037, 'recall': 0.37825, 'f1': 0.49364, 'auc': 0.89381}
2025-08-16 07:17:13,153 - INFO - val: {'epoch': 87, 'time_epoch': 4.09293, 'loss': 0.07253925, 'lr': 0, 'params': 451793, 'time_iter': 0.03173, 'accuracy': 0.98298, 'precision': 0.65714, 'recall': 0.28395, 'f1': 0.39655, 'auc': 0.78886}
2025-08-16 07:17:17,275 - INFO - test: {'epoch': 87, 'time_epoch': 4.0785, 'loss': 0.12244004, 'lr': 0, 'params': 451793, 'time_iter': 0.03162, 'accuracy': 0.97034, 'precision': 0.59091, 'recall': 0.2, 'f1': 0.29885, 'auc': 0.75327}
2025-08-16 07:17:17,285 - INFO - > Epoch 87: took 76.6s (avg 77.2s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:18:22,599 - INFO - train: {'epoch': 88, 'time_epoch': 65.23168, 'eta': 754.2503, 'eta_hours': 0.20951, 'loss': 0.09778211, 'lr': 3.89e-06, 'params': 451793, 'time_iter': 0.06339, 'accuracy': 0.97189, 'precision': 0.74404, 'recall': 0.37987, 'f1': 0.50296, 'auc': 0.88934}
2025-08-16 07:18:26,765 - INFO - val: {'epoch': 88, 'time_epoch': 4.14485, 'loss': 0.07245191, 'lr': 0, 'params': 451793, 'time_iter': 0.03213, 'accuracy': 0.98322, 'precision': 0.66667, 'recall': 0.2963, 'f1': 0.41026, 'auc': 0.79228}
2025-08-16 07:18:30,906 - INFO - test: {'epoch': 88, 'time_epoch': 4.12364, 'loss': 0.12261752, 'lr': 0, 'params': 451793, 'time_iter': 0.03197, 'accuracy': 0.96937, 'precision': 0.54, 'recall': 0.20769, 'f1': 0.3, 'auc': 0.75087}
2025-08-16 07:18:30,909 - INFO - > Epoch 88: took 73.6s (avg 77.2s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:19:39,462 - INFO - train: {'epoch': 89, 'time_epoch': 68.46505, 'eta': 685.67063, 'eta_hours': 0.19046, 'loss': 0.09770319, 'lr': 3.27e-06, 'params': 451793, 'time_iter': 0.06654, 'accuracy': 0.97219, 'precision': 0.74574, 'recall': 0.39042, 'f1': 0.51252, 'auc': 0.89102}
2025-08-16 07:19:43,631 - INFO - val: {'epoch': 89, 'time_epoch': 4.1477, 'loss': 0.07222686, 'lr': 0, 'params': 451793, 'time_iter': 0.03215, 'accuracy': 0.98225, 'precision': 0.6, 'recall': 0.2963, 'f1': 0.39669, 'auc': 0.79706}
2025-08-16 07:19:47,794 - INFO - test: {'epoch': 89, 'time_epoch': 4.14675, 'loss': 0.12056017, 'lr': 0, 'params': 451793, 'time_iter': 0.03215, 'accuracy': 0.96961, 'precision': 0.54237, 'recall': 0.24615, 'f1': 0.33862, 'auc': 0.75388}
2025-08-16 07:19:47,797 - INFO - > Epoch 89: took 76.9s (avg 77.2s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:20:54,592 - INFO - train: {'epoch': 90, 'time_epoch': 66.70843, 'eta': 616.91974, 'eta_hours': 0.17137, 'loss': 0.09668529, 'lr': 2.71e-06, 'params': 451793, 'time_iter': 0.06483, 'accuracy': 0.97252, 'precision': 0.74551, 'recall': 0.40422, 'f1': 0.52421, 'auc': 0.89243}
2025-08-16 07:20:58,783 - INFO - val: {'epoch': 90, 'time_epoch': 4.16641, 'loss': 0.07259446, 'lr': 0, 'params': 451793, 'time_iter': 0.0323, 'accuracy': 0.98347, 'precision': 0.65854, 'recall': 0.33333, 'f1': 0.44262, 'auc': 0.79188}
2025-08-16 07:21:02,961 - INFO - test: {'epoch': 90, 'time_epoch': 4.16104, 'loss': 0.12225491, 'lr': 0, 'params': 451793, 'time_iter': 0.03226, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.25385, 'f1': 0.33673, 'auc': 0.75223}
2025-08-16 07:21:02,964 - INFO - > Epoch 90: took 75.2s (avg 77.2s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:22:10,355 - INFO - train: {'epoch': 91, 'time_epoch': 67.30952, 'eta': 548.26553, 'eta_hours': 0.1523, 'loss': 0.09662477, 'lr': 2.2e-06, 'params': 451793, 'time_iter': 0.06541, 'accuracy': 0.97231, 'precision': 0.74429, 'recall': 0.39692, 'f1': 0.51773, 'auc': 0.89383}
2025-08-16 07:22:14,450 - INFO - val: {'epoch': 91, 'time_epoch': 4.07235, 'loss': 0.07200758, 'lr': 0, 'params': 451793, 'time_iter': 0.03157, 'accuracy': 0.98274, 'precision': 0.625, 'recall': 0.30864, 'f1': 0.41322, 'auc': 0.79379}
2025-08-16 07:22:18,542 - INFO - test: {'epoch': 91, 'time_epoch': 4.07518, 'loss': 0.12086399, 'lr': 0, 'params': 451793, 'time_iter': 0.03159, 'accuracy': 0.96912, 'precision': 0.52542, 'recall': 0.23846, 'f1': 0.32804, 'auc': 0.75296}
2025-08-16 07:22:18,544 - INFO - > Epoch 91: took 75.6s (avg 77.2s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:23:26,132 - INFO - train: {'epoch': 92, 'time_epoch': 67.50361, 'eta': 479.65484, 'eta_hours': 0.13324, 'loss': 0.09802763, 'lr': 1.74e-06, 'params': 451793, 'time_iter': 0.0656, 'accuracy': 0.97189, 'precision': 0.74022, 'recall': 0.38393, 'f1': 0.50561, 'auc': 0.88714}
2025-08-16 07:23:30,469 - INFO - val: {'epoch': 92, 'time_epoch': 4.31173, 'loss': 0.07187572, 'lr': 0, 'params': 451793, 'time_iter': 0.03342, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.79322}
2025-08-16 07:23:34,735 - INFO - test: {'epoch': 92, 'time_epoch': 4.24806, 'loss': 0.12161985, 'lr': 0, 'params': 451793, 'time_iter': 0.03293, 'accuracy': 0.96912, 'precision': 0.52459, 'recall': 0.24615, 'f1': 0.33508, 'auc': 0.75274}
2025-08-16 07:23:34,737 - INFO - > Epoch 92: took 76.2s (avg 77.2s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:24:41,132 - INFO - train: {'epoch': 93, 'time_epoch': 66.31295, 'eta': 410.99171, 'eta_hours': 0.11416, 'loss': 0.09782078, 'lr': 1.33e-06, 'params': 451793, 'time_iter': 0.06444, 'accuracy': 0.97113, 'precision': 0.7224, 'recall': 0.37175, 'f1': 0.49089, 'auc': 0.89408}
2025-08-16 07:24:45,357 - INFO - val: {'epoch': 93, 'time_epoch': 4.19715, 'loss': 0.07275593, 'lr': 0, 'params': 451793, 'time_iter': 0.03254, 'accuracy': 0.98322, 'precision': 0.63636, 'recall': 0.34568, 'f1': 0.448, 'auc': 0.7946}
2025-08-16 07:24:49,612 - INFO - test: {'epoch': 93, 'time_epoch': 4.23833, 'loss': 0.12233608, 'lr': 0, 'params': 451793, 'time_iter': 0.03286, 'accuracy': 0.96961, 'precision': 0.53623, 'recall': 0.28462, 'f1': 0.37186, 'auc': 0.75523}
2025-08-16 07:24:49,614 - INFO - > Epoch 93: took 74.9s (avg 77.1s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:25:57,808 - INFO - train: {'epoch': 94, 'time_epoch': 68.10912, 'eta': 342.47259, 'eta_hours': 0.09513, 'loss': 0.0979651, 'lr': 9.8e-07, 'params': 451793, 'time_iter': 0.06619, 'accuracy': 0.97249, 'precision': 0.75038, 'recall': 0.39773, 'f1': 0.51989, 'auc': 0.89209}
2025-08-16 07:26:02,074 - INFO - val: {'epoch': 94, 'time_epoch': 4.24141, 'loss': 0.07205507, 'lr': 0, 'params': 451793, 'time_iter': 0.03288, 'accuracy': 0.98322, 'precision': 0.66667, 'recall': 0.2963, 'f1': 0.41026, 'auc': 0.79447}
2025-08-16 07:26:06,323 - INFO - test: {'epoch': 94, 'time_epoch': 4.23062, 'loss': 0.12200487, 'lr': 0, 'params': 451793, 'time_iter': 0.0328, 'accuracy': 0.96961, 'precision': 0.54717, 'recall': 0.22308, 'f1': 0.31694, 'auc': 0.75283}
2025-08-16 07:26:06,325 - INFO - > Epoch 94: took 76.7s (avg 77.1s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:27:13,136 - INFO - train: {'epoch': 95, 'time_epoch': 66.71042, 'eta': 273.90374, 'eta_hours': 0.07608, 'loss': 0.09672353, 'lr': 6.8e-07, 'params': 451793, 'time_iter': 0.06483, 'accuracy': 0.97237, 'precision': 0.73926, 'recall': 0.40503, 'f1': 0.52334, 'auc': 0.8965}
2025-08-16 07:27:17,353 - INFO - val: {'epoch': 95, 'time_epoch': 4.19402, 'loss': 0.07151416, 'lr': 0, 'params': 451793, 'time_iter': 0.03251, 'accuracy': 0.98347, 'precision': 0.66667, 'recall': 0.32099, 'f1': 0.43333, 'auc': 0.79454}
2025-08-16 07:27:21,560 - INFO - test: {'epoch': 95, 'time_epoch': 4.18787, 'loss': 0.1206111, 'lr': 0, 'params': 451793, 'time_iter': 0.03246, 'accuracy': 0.96864, 'precision': 0.50847, 'recall': 0.23077, 'f1': 0.31746, 'auc': 0.75415}
2025-08-16 07:27:21,563 - INFO - > Epoch 95: took 75.2s (avg 77.1s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:28:27,789 - INFO - train: {'epoch': 96, 'time_epoch': 66.13551, 'eta': 205.35542, 'eta_hours': 0.05704, 'loss': 0.09658743, 'lr': 4.4e-07, 'params': 451793, 'time_iter': 0.06427, 'accuracy': 0.97185, 'precision': 0.72973, 'recall': 0.39448, 'f1': 0.51212, 'auc': 0.8925}
2025-08-16 07:28:32,039 - INFO - val: {'epoch': 96, 'time_epoch': 4.22813, 'loss': 0.07266973, 'lr': 0, 'params': 451793, 'time_iter': 0.03278, 'accuracy': 0.98322, 'precision': 0.66667, 'recall': 0.2963, 'f1': 0.41026, 'auc': 0.78754}
2025-08-16 07:28:36,286 - INFO - test: {'epoch': 96, 'time_epoch': 4.22947, 'loss': 0.12247303, 'lr': 0, 'params': 451793, 'time_iter': 0.03279, 'accuracy': 0.96912, 'precision': 0.53061, 'recall': 0.2, 'f1': 0.2905, 'auc': 0.7524}
2025-08-16 07:28:36,289 - INFO - > Epoch 96: took 74.7s (avg 77.1s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:29:43,919 - INFO - train: {'epoch': 97, 'time_epoch': 67.54604, 'eta': 136.88513, 'eta_hours': 0.03802, 'loss': 0.09821385, 'lr': 2.5e-07, 'params': 451793, 'time_iter': 0.06564, 'accuracy': 0.97179, 'precision': 0.74595, 'recall': 0.37419, 'f1': 0.49838, 'auc': 0.89024}
2025-08-16 07:29:48,230 - INFO - val: {'epoch': 97, 'time_epoch': 4.28649, 'loss': 0.07285453, 'lr': 0, 'params': 451793, 'time_iter': 0.03323, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.79128}
2025-08-16 07:29:52,514 - INFO - test: {'epoch': 97, 'time_epoch': 4.26526, 'loss': 0.12265561, 'lr': 0, 'params': 451793, 'time_iter': 0.03306, 'accuracy': 0.96985, 'precision': 0.56, 'recall': 0.21538, 'f1': 0.31111, 'auc': 0.75315}
2025-08-16 07:29:52,516 - INFO - > Epoch 97: took 76.2s (avg 77.1s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:30:59,861 - INFO - train: {'epoch': 98, 'time_epoch': 67.25905, 'eta': 68.43061, 'eta_hours': 0.01901, 'loss': 0.09812601, 'lr': 1.1e-07, 'params': 451793, 'time_iter': 0.06536, 'accuracy': 0.9717, 'precision': 0.73927, 'recall': 0.37744, 'f1': 0.49973, 'auc': 0.88935}
2025-08-16 07:31:04,130 - INFO - val: {'epoch': 98, 'time_epoch': 4.24401, 'loss': 0.07197633, 'lr': 0, 'params': 451793, 'time_iter': 0.0329, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.79556}
2025-08-16 07:31:08,351 - INFO - test: {'epoch': 98, 'time_epoch': 4.20433, 'loss': 0.12135961, 'lr': 0, 'params': 451793, 'time_iter': 0.03259, 'accuracy': 0.96985, 'precision': 0.55556, 'recall': 0.23077, 'f1': 0.32609, 'auc': 0.75336}
2025-08-16 07:31:08,354 - INFO - > Epoch 98: took 75.8s (avg 77.1s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:32:15,707 - INFO - train: {'epoch': 99, 'time_epoch': 67.26716, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.09703853, 'lr': 3e-08, 'params': 451793, 'time_iter': 0.06537, 'accuracy': 0.97225, 'precision': 0.74501, 'recall': 0.39367, 'f1': 0.51514, 'auc': 0.89544}
2025-08-16 07:32:19,971 - INFO - val: {'epoch': 99, 'time_epoch': 4.24244, 'loss': 0.07251411, 'lr': 0, 'params': 451793, 'time_iter': 0.03289, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.79162}
2025-08-16 07:32:24,229 - INFO - test: {'epoch': 99, 'time_epoch': 4.23971, 'loss': 0.12137183, 'lr': 0, 'params': 451793, 'time_iter': 0.03287, 'accuracy': 0.96912, 'precision': 0.52542, 'recall': 0.23846, 'f1': 0.32804, 'auc': 0.75479}
2025-08-16 07:32:24,454 - INFO - > Epoch 99: took 75.9s (avg 77.0s) | Best so far: epoch 71	train_loss: 0.0998 train_auc: 0.8876	val_loss: 0.0724 val_auc: 0.8027	test_loss: 0.1204 test_auc: 0.7557
2025-08-16 07:32:24,454 - INFO - Avg time per epoch: 77.05s
2025-08-16 07:32:24,454 - INFO - Total train loop time: 2.14h
2025-08-16 07:32:24,564 - INFO - ============================================================
2025-08-16 07:32:24,564 - INFO - Starting PK-Explainer Analysis (Enhanced Version)
2025-08-16 07:32:24,564 - INFO - ============================================================
2025-08-16 07:32:24,564 - INFO - Dataset: ogbg-molhiv
2025-08-16 07:32:24,564 - INFO - Model type: VanillaModel
2025-08-16 07:32:24,564 - INFO - GNN types available: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 07:32:25,135 - INFO - Saved model state to results/molhiv/molhiv-Vanilla-45/model_for_ablation.pt
2025-08-16 07:32:25,135 - INFO - 
Performing ablation study...
2025-08-16 07:32:25,170 - INFO - Getting baseline performance...
2025-08-16 07:32:25,203 - WARNING - Could not extract GNN mapping from optimal weights, attempting to infer from layers...
2025-08-16 07:32:25,203 - INFO - Final GNN mapping: {}
2025-08-16 07:32:29,440 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22207, 'loss': 0.12137183, 'lr': 0, 'params': 451793, 'time_iter': 0.03273, 'accuracy': 0.96912, 'precision': 0.52542, 'recall': 0.23846, 'f1': 0.32804, 'auc': 0.75479}
2025-08-16 07:32:29,443 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:32:29,443 - INFO - Baseline auc: 0.7548
2025-08-16 07:32:33,721 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22969, 'loss': 0.12049092, 'lr': 0, 'params': 451793, 'time_iter': 0.03279, 'accuracy': 0.96985, 'precision': 0.54839, 'recall': 0.26154, 'f1': 0.35417, 'auc': 0.75814}
2025-08-16 07:32:33,724 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:33,724 - INFO - Layer 0 (Layer_0), Head 0: drop=-0.0044
2025-08-16 07:32:38,016 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24108, 'loss': 0.12143496, 'lr': 0, 'params': 451793, 'time_iter': 0.03288, 'accuracy': 0.97034, 'precision': 0.56897, 'recall': 0.25385, 'f1': 0.35106, 'auc': 0.75456}
2025-08-16 07:32:38,018 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:38,018 - INFO - Layer 0 (Layer_0), Head 1: drop=0.0003
2025-08-16 07:32:42,302 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23534, 'loss': 0.12125514, 'lr': 0, 'params': 451793, 'time_iter': 0.03283, 'accuracy': 0.96937, 'precision': 0.53571, 'recall': 0.23077, 'f1': 0.32258, 'auc': 0.75599}
2025-08-16 07:32:42,304 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:42,304 - INFO - Layer 0 (Layer_0), Head 2: drop=-0.0016
2025-08-16 07:32:46,568 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21599, 'loss': 0.12255735, 'lr': 0, 'params': 451793, 'time_iter': 0.03268, 'accuracy': 0.96985, 'precision': 0.55556, 'recall': 0.23077, 'f1': 0.32609, 'auc': 0.75583}
2025-08-16 07:32:46,570 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:46,571 - INFO - Layer 0 (Layer_0), Head 3: drop=-0.0014
2025-08-16 07:32:50,863 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24337, 'loss': 0.12248375, 'lr': 0, 'params': 451793, 'time_iter': 0.03289, 'accuracy': 0.96864, 'precision': 0.5102, 'recall': 0.19231, 'f1': 0.27933, 'auc': 0.75607}
2025-08-16 07:32:50,865 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:32:50,865 - INFO - Layer 1 (Layer_1), Head 0: drop=-0.0017
2025-08-16 07:32:55,161 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2473, 'loss': 0.12106664, 'lr': 0, 'params': 451793, 'time_iter': 0.03292, 'accuracy': 0.96961, 'precision': 0.54386, 'recall': 0.23846, 'f1': 0.33155, 'auc': 0.75562}
2025-08-16 07:32:55,163 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:55,163 - INFO - Layer 1 (Layer_1), Head 1: drop=-0.0011
2025-08-16 07:32:59,444 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23159, 'loss': 0.12147009, 'lr': 0, 'params': 451793, 'time_iter': 0.0328, 'accuracy': 0.96985, 'precision': 0.55769, 'recall': 0.22308, 'f1': 0.31868, 'auc': 0.7609}
2025-08-16 07:32:59,446 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:32:59,446 - INFO - Layer 1 (Layer_1), Head 2: drop=-0.0081
2025-08-16 07:33:03,753 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25731, 'loss': 0.12216581, 'lr': 0, 'params': 451793, 'time_iter': 0.033, 'accuracy': 0.96961, 'precision': 0.54902, 'recall': 0.21538, 'f1': 0.30939, 'auc': 0.75725}
2025-08-16 07:33:03,755 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:33:03,755 - INFO - Layer 1 (Layer_1), Head 3: drop=-0.0033
2025-08-16 07:33:08,039 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23413, 'loss': 0.12184896, 'lr': 0, 'params': 451793, 'time_iter': 0.03282, 'accuracy': 0.96912, 'precision': 0.52941, 'recall': 0.20769, 'f1': 0.29834, 'auc': 0.75383}
2025-08-16 07:33:08,040 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:08,040 - INFO - Layer 2 (Layer_2), Head 0: drop=0.0013
2025-08-16 07:33:12,345 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25485, 'loss': 0.12013805, 'lr': 0, 'params': 451793, 'time_iter': 0.03298, 'accuracy': 0.96985, 'precision': 0.54839, 'recall': 0.26154, 'f1': 0.35417, 'auc': 0.75665}
2025-08-16 07:33:12,347 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:33:12,347 - INFO - Layer 2 (Layer_2), Head 1: drop=-0.0025
2025-08-16 07:33:16,643 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24724, 'loss': 0.12075148, 'lr': 0, 'params': 451793, 'time_iter': 0.03292, 'accuracy': 0.96961, 'precision': 0.54545, 'recall': 0.23077, 'f1': 0.32432, 'auc': 0.75171}
2025-08-16 07:33:16,646 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:16,646 - INFO - Layer 2 (Layer_2), Head 2: drop=0.0041
2025-08-16 07:33:20,925 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23028, 'loss': 0.1215167, 'lr': 0, 'params': 451793, 'time_iter': 0.03279, 'accuracy': 0.97009, 'precision': 0.56604, 'recall': 0.23077, 'f1': 0.32787, 'auc': 0.75597}
2025-08-16 07:33:20,927 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:33:20,927 - INFO - Layer 2 (Layer_2), Head 3: drop=-0.0016
2025-08-16 07:33:25,240 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26348, 'loss': 0.12172018, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.96912, 'precision': 0.5283, 'recall': 0.21538, 'f1': 0.30601, 'auc': 0.75333}
2025-08-16 07:33:25,242 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:25,242 - INFO - Layer 3 (Layer_3), Head 0: drop=0.0019
2025-08-16 07:33:29,534 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24341, 'loss': 0.12064219, 'lr': 0, 'params': 451793, 'time_iter': 0.03289, 'accuracy': 0.96864, 'precision': 0.50877, 'recall': 0.22308, 'f1': 0.31016, 'auc': 0.75893}
2025-08-16 07:33:29,537 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:33:29,537 - INFO - Layer 3 (Layer_3), Head 1: drop=-0.0055
2025-08-16 07:33:33,861 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27515, 'loss': 0.12038316, 'lr': 0, 'params': 451793, 'time_iter': 0.03314, 'accuracy': 0.96888, 'precision': 0.51667, 'recall': 0.23846, 'f1': 0.32632, 'auc': 0.75509}
2025-08-16 07:33:33,863 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:33:33,864 - INFO - Layer 3 (Layer_3), Head 2: drop=-0.0004
2025-08-16 07:33:38,185 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27201, 'loss': 0.12018039, 'lr': 0, 'params': 451793, 'time_iter': 0.03312, 'accuracy': 0.96961, 'precision': 0.54545, 'recall': 0.23077, 'f1': 0.32432, 'auc': 0.75795}
2025-08-16 07:33:38,187 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:38,187 - INFO - Layer 3 (Layer_3), Head 3: drop=-0.0042
2025-08-16 07:33:42,508 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27142, 'loss': 0.12120313, 'lr': 0, 'params': 451793, 'time_iter': 0.03311, 'accuracy': 0.96937, 'precision': 0.53846, 'recall': 0.21538, 'f1': 0.30769, 'auc': 0.75523}
2025-08-16 07:33:42,510 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:33:42,510 - INFO - Layer 4 (Layer_4), Head 0: drop=-0.0006
2025-08-16 07:33:46,836 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27631, 'loss': 0.1223347, 'lr': 0, 'params': 451793, 'time_iter': 0.03315, 'accuracy': 0.97034, 'precision': 0.59091, 'recall': 0.2, 'f1': 0.29885, 'auc': 0.75626}
2025-08-16 07:33:46,838 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:46,838 - INFO - Layer 4 (Layer_4), Head 1: drop=-0.0019
2025-08-16 07:33:51,151 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26445, 'loss': 0.11956292, 'lr': 0, 'params': 451793, 'time_iter': 0.03306, 'accuracy': 0.96937, 'precision': 0.53333, 'recall': 0.24615, 'f1': 0.33684, 'auc': 0.75843}
2025-08-16 07:33:51,153 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:51,154 - INFO - Layer 4 (Layer_4), Head 2: drop=-0.0048
2025-08-16 07:33:55,449 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24733, 'loss': 0.12053165, 'lr': 0, 'params': 451793, 'time_iter': 0.03293, 'accuracy': 0.97009, 'precision': 0.5614, 'recall': 0.24615, 'f1': 0.34225, 'auc': 0.75872}
2025-08-16 07:33:55,452 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:55,452 - INFO - Layer 4 (Layer_4), Head 3: drop=-0.0052
2025-08-16 07:33:59,767 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2667, 'loss': 0.11990457, 'lr': 0, 'params': 451793, 'time_iter': 0.03308, 'accuracy': 0.96961, 'precision': 0.54386, 'recall': 0.23846, 'f1': 0.33155, 'auc': 0.75882}
2025-08-16 07:33:59,769 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:33:59,769 - INFO - Layer 5 (Layer_5), Head 0: drop=-0.0053
2025-08-16 07:34:04,118 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29935, 'loss': 0.1215504, 'lr': 0, 'params': 451793, 'time_iter': 0.03333, 'accuracy': 0.96937, 'precision': 0.53571, 'recall': 0.23077, 'f1': 0.32258, 'auc': 0.75285}
2025-08-16 07:34:04,120 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:04,120 - INFO - Layer 5 (Layer_5), Head 1: drop=0.0026
2025-08-16 07:34:08,462 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.29278, 'loss': 0.11976373, 'lr': 0, 'params': 451793, 'time_iter': 0.03328, 'accuracy': 0.96937, 'precision': 0.53448, 'recall': 0.23846, 'f1': 0.32979, 'auc': 0.75585}
2025-08-16 07:34:08,464 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:08,464 - INFO - Layer 5 (Layer_5), Head 2: drop=-0.0014
2025-08-16 07:34:12,784 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26989, 'loss': 0.12055454, 'lr': 0, 'params': 451793, 'time_iter': 0.0331, 'accuracy': 0.96985, 'precision': 0.55357, 'recall': 0.23846, 'f1': 0.33333, 'auc': 0.75215}
2025-08-16 07:34:12,786 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:34:12,786 - INFO - Layer 5 (Layer_5), Head 3: drop=0.0035
2025-08-16 07:34:17,123 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.28483, 'loss': 0.11950038, 'lr': 0, 'params': 451793, 'time_iter': 0.03322, 'accuracy': 0.96937, 'precision': 0.53571, 'recall': 0.23077, 'f1': 0.32258, 'auc': 0.75258}
2025-08-16 07:34:17,125 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:34:17,125 - INFO - Layer 6 (Layer_6), Head 0: drop=0.0029
2025-08-16 07:34:21,436 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26191, 'loss': 0.12128322, 'lr': 0, 'params': 451793, 'time_iter': 0.03304, 'accuracy': 0.96888, 'precision': 0.51724, 'recall': 0.23077, 'f1': 0.31915, 'auc': 0.75478}
2025-08-16 07:34:21,438 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:21,438 - INFO - Layer 6 (Layer_6), Head 1: drop=0.0000
2025-08-16 07:34:25,744 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25627, 'loss': 0.11999498, 'lr': 0, 'params': 451793, 'time_iter': 0.03299, 'accuracy': 0.96864, 'precision': 0.5082, 'recall': 0.23846, 'f1': 0.32461, 'auc': 0.75716}
2025-08-16 07:34:25,746 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:34:25,746 - INFO - Layer 6 (Layer_6), Head 2: drop=-0.0031
2025-08-16 07:34:30,051 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25519, 'loss': 0.1213027, 'lr': 0, 'params': 451793, 'time_iter': 0.03299, 'accuracy': 0.97009, 'precision': 0.56364, 'recall': 0.23846, 'f1': 0.33514, 'auc': 0.75322}
2025-08-16 07:34:30,052 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:30,052 - INFO - Layer 6 (Layer_6), Head 3: drop=0.0021
2025-08-16 07:34:34,369 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26589, 'loss': 0.12019949, 'lr': 0, 'params': 451793, 'time_iter': 0.03307, 'accuracy': 0.96937, 'precision': 0.53704, 'recall': 0.22308, 'f1': 0.31522, 'auc': 0.75248}
2025-08-16 07:34:34,371 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:34,371 - INFO - Layer 7 (Layer_7), Head 0: drop=0.0031
2025-08-16 07:34:38,725 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.30455, 'loss': 0.1206597, 'lr': 0, 'params': 451793, 'time_iter': 0.03337, 'accuracy': 0.96937, 'precision': 0.53704, 'recall': 0.22308, 'f1': 0.31522, 'auc': 0.75261}
2025-08-16 07:34:38,726 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:38,726 - INFO - Layer 7 (Layer_7), Head 1: drop=0.0029
2025-08-16 07:34:43,050 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27327, 'loss': 0.12095608, 'lr': 0, 'params': 451793, 'time_iter': 0.03313, 'accuracy': 0.96912, 'precision': 0.52632, 'recall': 0.23077, 'f1': 0.32086, 'auc': 0.7524}
2025-08-16 07:34:43,051 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:43,052 - INFO - Layer 7 (Layer_7), Head 2: drop=0.0032
2025-08-16 07:34:47,359 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25792, 'loss': 0.11986138, 'lr': 0, 'params': 451793, 'time_iter': 0.03301, 'accuracy': 0.96985, 'precision': 0.55357, 'recall': 0.23846, 'f1': 0.33333, 'auc': 0.75255}
2025-08-16 07:34:47,360 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:47,361 - INFO - Layer 7 (Layer_7), Head 3: drop=0.0030
2025-08-16 07:34:51,659 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24991, 'loss': 0.12002396, 'lr': 0, 'params': 451793, 'time_iter': 0.03295, 'accuracy': 0.96937, 'precision': 0.53704, 'recall': 0.22308, 'f1': 0.31522, 'auc': 0.75599}
2025-08-16 07:34:51,661 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:51,661 - INFO - Layer 8 (Layer_8), Head 0: drop=-0.0016
2025-08-16 07:34:55,968 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25818, 'loss': 0.11991489, 'lr': 0, 'params': 451793, 'time_iter': 0.03301, 'accuracy': 0.96985, 'precision': 0.55556, 'recall': 0.23077, 'f1': 0.32609, 'auc': 0.75118}
2025-08-16 07:34:55,970 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:34:55,970 - INFO - Layer 8 (Layer_8), Head 1: drop=0.0048
2025-08-16 07:35:00,286 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26578, 'loss': 0.119106, 'lr': 0, 'params': 451793, 'time_iter': 0.03307, 'accuracy': 0.96937, 'precision': 0.53448, 'recall': 0.23846, 'f1': 0.32979, 'auc': 0.75579}
2025-08-16 07:35:00,288 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:00,288 - INFO - Layer 8 (Layer_8), Head 2: drop=-0.0013
2025-08-16 07:35:04,640 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.30327, 'loss': 0.12058222, 'lr': 0, 'params': 451793, 'time_iter': 0.03336, 'accuracy': 0.96961, 'precision': 0.54545, 'recall': 0.23077, 'f1': 0.32432, 'auc': 0.75217}
2025-08-16 07:35:04,642 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:04,642 - INFO - Layer 8 (Layer_8), Head 3: drop=0.0035
2025-08-16 07:35:08,951 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25976, 'loss': 0.12043069, 'lr': 0, 'params': 451793, 'time_iter': 0.03302, 'accuracy': 0.96961, 'precision': 0.54545, 'recall': 0.23077, 'f1': 0.32432, 'auc': 0.75514}
2025-08-16 07:35:08,953 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:08,953 - INFO - Layer 9 (Layer_9), Head 0: drop=-0.0005
2025-08-16 07:35:13,279 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.27619, 'loss': 0.12059291, 'lr': 0, 'params': 451793, 'time_iter': 0.03315, 'accuracy': 0.96961, 'precision': 0.54386, 'recall': 0.23846, 'f1': 0.33155, 'auc': 0.75176}
2025-08-16 07:35:13,280 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:13,281 - INFO - Layer 9 (Layer_9), Head 1: drop=0.0040
2025-08-16 07:35:17,644 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.31261, 'loss': 0.12009377, 'lr': 0, 'params': 451793, 'time_iter': 0.03343, 'accuracy': 0.96985, 'precision': 0.55556, 'recall': 0.23077, 'f1': 0.32609, 'auc': 0.75425}
2025-08-16 07:35:17,646 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:35:17,647 - INFO - Layer 9 (Layer_9), Head 2: drop=0.0007
2025-08-16 07:35:21,938 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2413, 'loss': 0.12023748, 'lr': 0, 'params': 451793, 'time_iter': 0.03288, 'accuracy': 0.96985, 'precision': 0.55556, 'recall': 0.23077, 'f1': 0.32609, 'auc': 0.75357}
2025-08-16 07:35:21,940 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:21,940 - INFO - Layer 9 (Layer_9), Head 3: drop=0.0016
2025-08-16 07:35:26,238 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24806, 'loss': 0.12050624, 'lr': 0, 'params': 451793, 'time_iter': 0.03293, 'accuracy': 0.96961, 'precision': 0.54386, 'recall': 0.23846, 'f1': 0.33155, 'auc': 0.75266}
2025-08-16 07:35:26,240 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:35:26,240 - INFO - Layer 10 (Layer_10), Head 0: drop=0.0028
2025-08-16 07:35:30,532 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24227, 'loss': 0.12107298, 'lr': 0, 'params': 451793, 'time_iter': 0.03289, 'accuracy': 0.96912, 'precision': 0.52727, 'recall': 0.22308, 'f1': 0.31351, 'auc': 0.75217}
2025-08-16 07:35:30,534 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:35:30,534 - INFO - Layer 10 (Layer_10), Head 1: drop=0.0035
2025-08-16 07:35:34,822 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23753, 'loss': 0.12061705, 'lr': 0, 'params': 451793, 'time_iter': 0.03285, 'accuracy': 0.96985, 'precision': 0.55556, 'recall': 0.23077, 'f1': 0.32609, 'auc': 0.75401}
2025-08-16 07:35:34,824 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:34,824 - INFO - Layer 10 (Layer_10), Head 2: drop=0.0010
2025-08-16 07:35:39,121 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24573, 'loss': 0.12014437, 'lr': 0, 'params': 451793, 'time_iter': 0.03291, 'accuracy': 0.96985, 'precision': 0.55556, 'recall': 0.23077, 'f1': 0.32609, 'auc': 0.75424}
2025-08-16 07:35:39,123 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:35:39,123 - INFO - Layer 10 (Layer_10), Head 3: drop=0.0007
2025-08-16 07:35:43,439 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26507, 'loss': 0.12087738, 'lr': 0, 'params': 451793, 'time_iter': 0.03306, 'accuracy': 0.97009, 'precision': 0.56604, 'recall': 0.23077, 'f1': 0.32787, 'auc': 0.75388}
2025-08-16 07:35:43,440 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:35:43,441 - INFO - Layer 11 (Layer_11), Head 0: drop=0.0012
2025-08-16 07:35:47,704 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21459, 'loss': 0.12061348, 'lr': 0, 'params': 451793, 'time_iter': 0.03267, 'accuracy': 0.96985, 'precision': 0.55357, 'recall': 0.23846, 'f1': 0.33333, 'auc': 0.75403}
2025-08-16 07:35:47,707 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:35:47,707 - INFO - Layer 11 (Layer_11), Head 1: drop=0.0010
2025-08-16 07:35:51,977 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21932, 'loss': 0.12119252, 'lr': 0, 'params': 451793, 'time_iter': 0.03271, 'accuracy': 0.97009, 'precision': 0.5614, 'recall': 0.24615, 'f1': 0.34225, 'auc': 0.75285}
2025-08-16 07:35:51,978 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:35:51,979 - INFO - Layer 11 (Layer_11), Head 2: drop=0.0026
2025-08-16 07:35:56,271 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24294, 'loss': 0.12048516, 'lr': 0, 'params': 451793, 'time_iter': 0.03289, 'accuracy': 0.96985, 'precision': 0.55556, 'recall': 0.23077, 'f1': 0.32609, 'auc': 0.75473}
2025-08-16 07:35:56,273 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:35:56,273 - INFO - Layer 11 (Layer_11), Head 3: drop=0.0001
2025-08-16 07:36:00,573 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25004, 'loss': 0.12113438, 'lr': 0, 'params': 451793, 'time_iter': 0.03295, 'accuracy': 0.97009, 'precision': 0.56364, 'recall': 0.23846, 'f1': 0.33514, 'auc': 0.75568}
2025-08-16 07:36:00,575 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:36:00,575 - INFO - Layer 12 (Layer_12), Head 0: drop=-0.0012
2025-08-16 07:36:04,860 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23492, 'loss': 0.12125644, 'lr': 0, 'params': 451793, 'time_iter': 0.03283, 'accuracy': 0.96985, 'precision': 0.55357, 'recall': 0.23846, 'f1': 0.33333, 'auc': 0.75457}
2025-08-16 07:36:04,861 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:36:04,861 - INFO - Layer 12 (Layer_12), Head 1: drop=0.0003
2025-08-16 07:36:09,125 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21367, 'loss': 0.12065002, 'lr': 0, 'params': 451793, 'time_iter': 0.03266, 'accuracy': 0.96961, 'precision': 0.54237, 'recall': 0.24615, 'f1': 0.33862, 'auc': 0.75536}
2025-08-16 07:36:09,127 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:36:09,128 - INFO - Layer 12 (Layer_12), Head 2: drop=-0.0008
2025-08-16 07:36:13,414 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23725, 'loss': 0.12098419, 'lr': 0, 'params': 451793, 'time_iter': 0.03285, 'accuracy': 0.96985, 'precision': 0.55172, 'recall': 0.24615, 'f1': 0.34043, 'auc': 0.75593}
2025-08-16 07:36:13,416 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:36:13,416 - INFO - Layer 12 (Layer_12), Head 3: drop=-0.0015
2025-08-16 07:36:17,697 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23161, 'loss': 0.12122139, 'lr': 0, 'params': 451793, 'time_iter': 0.0328, 'accuracy': 0.96961, 'precision': 0.54386, 'recall': 0.23846, 'f1': 0.33155, 'auc': 0.75514}
2025-08-16 07:36:17,700 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:36:17,700 - INFO - Layer 13 (Layer_13), Head 0: drop=-0.0005
2025-08-16 07:36:21,991 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24171, 'loss': 0.12147738, 'lr': 0, 'params': 451793, 'time_iter': 0.03288, 'accuracy': 0.96961, 'precision': 0.54386, 'recall': 0.23846, 'f1': 0.33155, 'auc': 0.75487}
2025-08-16 07:36:21,993 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:36:21,993 - INFO - Layer 13 (Layer_13), Head 1: drop=-0.0001
2025-08-16 07:36:26,283 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24067, 'loss': 0.12096792, 'lr': 0, 'params': 451793, 'time_iter': 0.03287, 'accuracy': 0.96961, 'precision': 0.54386, 'recall': 0.23846, 'f1': 0.33155, 'auc': 0.75617}
2025-08-16 07:36:26,284 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:36:26,285 - INFO - Layer 13 (Layer_13), Head 2: drop=-0.0018
2025-08-16 07:36:30,567 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23275, 'loss': 0.12113851, 'lr': 0, 'params': 451793, 'time_iter': 0.03281, 'accuracy': 0.96961, 'precision': 0.54386, 'recall': 0.23846, 'f1': 0.33155, 'auc': 0.75415}
2025-08-16 07:36:30,569 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:36:30,569 - INFO - Layer 13 (Layer_13), Head 3: drop=0.0008
2025-08-16 07:36:34,861 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24109, 'loss': 0.12135347, 'lr': 0, 'params': 451793, 'time_iter': 0.03288, 'accuracy': 0.96961, 'precision': 0.54386, 'recall': 0.23846, 'f1': 0.33155, 'auc': 0.75468}
2025-08-16 07:36:34,863 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:36:34,863 - INFO - Layer 14 (Layer_14), Head 0: drop=0.0001
2025-08-16 07:36:39,194 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.28103, 'loss': 0.12056018, 'lr': 0, 'params': 451793, 'time_iter': 0.03319, 'accuracy': 0.96961, 'precision': 0.54386, 'recall': 0.23846, 'f1': 0.33155, 'auc': 0.7548}
2025-08-16 07:36:39,196 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:36:39,196 - INFO - Layer 14 (Layer_14), Head 1: drop=-0.0000
2025-08-16 07:36:43,507 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2611, 'loss': 0.12160039, 'lr': 0, 'params': 451793, 'time_iter': 0.03303, 'accuracy': 0.96961, 'precision': 0.54237, 'recall': 0.24615, 'f1': 0.33862, 'auc': 0.75577}
2025-08-16 07:36:43,509 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:36:43,509 - INFO - Layer 14 (Layer_14), Head 2: drop=-0.0013
2025-08-16 07:36:47,790 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23231, 'loss': 0.12181322, 'lr': 0, 'params': 451793, 'time_iter': 0.03281, 'accuracy': 0.96985, 'precision': 0.55357, 'recall': 0.23846, 'f1': 0.33333, 'auc': 0.7558}
2025-08-16 07:36:47,792 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:36:47,793 - INFO - Layer 14 (Layer_14), Head 3: drop=-0.0013
2025-08-16 07:36:47,795 - INFO - 
FIDELITY METRICS:
2025-08-16 07:36:47,796 - INFO - Fidelity (top 30 heads): 0.0020
2025-08-16 07:36:47,796 - INFO - Fidelity- (bottom 30 heads): -0.0023
2025-08-16 07:36:47,796 - INFO - 
GNN distribution in important heads:
2025-08-16 07:36:47,796 - INFO -   Layer_10: 4 heads
2025-08-16 07:36:47,796 - INFO -   Layer_7: 4 heads
2025-08-16 07:36:47,796 - INFO -   Layer_11: 4 heads
2025-08-16 07:36:47,796 - INFO -   Layer_9: 3 heads
2025-08-16 07:36:47,796 - INFO -   Layer_6: 3 heads
2025-08-16 07:36:47,796 - INFO -   Layer_8: 2 heads
2025-08-16 07:36:47,796 - INFO -   Layer_2: 2 heads
2025-08-16 07:36:47,796 - INFO -   Layer_5: 2 heads
2025-08-16 07:36:47,796 - INFO -   Layer_14: 2 heads
2025-08-16 07:36:47,797 - INFO -   Layer_3: 1 heads
2025-08-16 07:36:47,797 - INFO -   Layer_13: 1 heads
2025-08-16 07:36:47,797 - INFO -   Layer_0: 1 heads
2025-08-16 07:36:47,797 - INFO -   Layer_12: 1 heads
2025-08-16 07:36:47,797 - INFO - 
Interpretability Analysis:
2025-08-16 07:36:47,797 - INFO -   Fidelity: 0.0020
2025-08-16 07:36:47,797 - INFO -   Fidelity-: -0.0023
2025-08-16 07:36:47,797 - INFO -   Total heads tested: 60
2025-08-16 07:36:48,039 - INFO - Excel results saved to results/molhiv/molhiv-Vanilla-45/pk_explainer_results.xlsx
2025-08-16 07:36:49,265 - INFO - Saved visualizations to results/molhiv/molhiv-Vanilla-45/pk_explainer_results
2025-08-16 07:36:49,267 - INFO - 
PK-Explainer results saved to:
2025-08-16 07:36:49,267 - INFO -   - Excel: results/molhiv/molhiv-Vanilla-45/pk_explainer_results.xlsx
2025-08-16 07:36:49,267 - INFO -   - JSON: results/molhiv/molhiv-Vanilla-45/pk_explainer_results.json
2025-08-16 07:36:49,267 - INFO -   - Visualizations: results/molhiv/molhiv-Vanilla-45/pk_explainer_results
2025-08-16 07:36:49,295 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-45
2025-08-16 07:36:49,295 - INFO - Total time: 8133.56s (2.26h)
2025-08-16 07:36:49,333 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-45/agg
2025-08-16 07:36:49,333 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-16 07:36:49,333 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-45
2025-08-16 07:36:49,333 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-45/test_results/
Completed seed 45. Results saved in results/molhiv/molhiv-Vanilla-45
----------------------------------------
Running experiment with seed: 47
Starting training for seed 47...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/confignas.yaml
Using device: cuda
2025-08-16 07:36:58,819 - INFO - GPU Mem: 25.2GB
2025-08-16 07:36:58,819 - INFO - Run directory: results/molhiv/molhiv-Vanilla-47
2025-08-16 07:36:58,820 - INFO - Seed: 47
2025-08-16 07:36:58,820 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-16 07:36:58,820 - INFO - Routing mode: none
2025-08-16 07:36:58,820 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 07:36:58,820 - INFO - Number of layers: 15
2025-08-16 07:36:58,820 - INFO - Uncertainty enabled: False
2025-08-16 07:36:58,820 - INFO - Training mode: custom
2025-08-16 07:36:58,820 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-16 07:36:58,820 - INFO - Additional features: Router weights logging + JSON export
2025-08-16 07:37:05,290 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 07:37:05,292 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 07:37:05,293 - INFO -   undirected: True
2025-08-16 07:37:05,293 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 07:37:05,293 - INFO -   avg num_nodes/graph: 25
2025-08-16 07:37:05,293 - INFO -   num node features: 9
2025-08-16 07:37:05,294 - INFO -   num edge features: 3
2025-08-16 07:37:05,294 - INFO -   num tasks: 1
2025-08-16 07:37:05,294 - INFO -   num classes: 2
2025-08-16 07:37:05,294 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 07:37:05,294 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 07:37:05,297 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 10%|█         | 4162/41127 [00:10<01:29, 414.20it/s] 16%|█▌        | 6446/41127 [00:20<01:53, 304.95it/s] 23%|██▎       | 9299/41127 [00:30<01:47, 295.33it/s] 31%|███       | 12733/41127 [00:40<01:30, 313.84it/s] 37%|███▋      | 15029/41127 [00:50<01:32, 282.05it/s] 42%|████▏     | 17085/41127 [01:02<01:40, 238.47it/s] 50%|████▉     | 20362/41127 [01:12<01:18, 266.14it/s] 57%|█████▋    | 23588/41127 [01:22<01:02, 281.96it/s] 66%|██████▌   | 27033/41127 [01:32<00:47, 299.21it/s] 73%|███████▎  | 29827/41127 [01:42<00:38, 293.07it/s] 79%|███████▉  | 32462/41127 [01:52<00:30, 283.32it/s] 85%|████████▍ | 34908/41127 [02:03<00:22, 270.61it/s] 91%|█████████ | 37287/41127 [02:13<00:14, 260.11it/s] 96%|█████████▋| 39619/41127 [02:23<00:06, 250.97it/s] 96%|█████████▋| 39619/41127 [02:33<00:06, 250.97it/s]100%|█████████▉| 40986/41127 [02:33<00:00, 214.51it/s]100%|██████████| 41127/41127 [02:36<00:00, 263.17it/s]
2025-08-16 07:39:42,778 - INFO - Done! Took 00:02:37.48
2025-08-16 07:39:42,931 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 07:39:43,227 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-16 07:39:43,227 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-08-16 07:39:43,227 - INFO - Inner model has get_darts_model: False
2025-08-16 07:39:43,231 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-08-16 07:39:43,234 - INFO - Number of parameters: 451,793
2025-08-16 07:39:43,234 - INFO - Starting optimized training: 2025-08-16 07:39:43.234278
2025-08-16 07:39:49,300 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 07:39:49,301 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 07:39:49,302 - INFO -   undirected: True
2025-08-16 07:39:49,302 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 07:39:49,302 - INFO -   avg num_nodes/graph: 25
2025-08-16 07:39:49,302 - INFO -   num node features: 9
2025-08-16 07:39:49,303 - INFO -   num edge features: 3
2025-08-16 07:39:49,303 - INFO -   num tasks: 1
2025-08-16 07:39:49,303 - INFO -   num classes: 2
2025-08-16 07:39:49,303 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 07:39:49,303 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 07:39:49,306 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 10%|▉         | 3947/41127 [00:10<01:35, 388.86it/s] 15%|█▌        | 6204/41127 [00:20<01:59, 291.60it/s] 20%|██        | 8373/41127 [00:30<02:07, 257.71it/s] 27%|██▋       | 11294/41127 [00:40<01:49, 271.22it/s] 36%|███▌      | 14738/41127 [00:50<01:29, 296.07it/s] 41%|████      | 16794/41127 [01:05<01:46, 228.16it/s] 49%|████▉     | 20132/41127 [01:15<01:21, 259.16it/s] 57%|█████▋    | 23294/41127 [01:25<01:04, 276.00it/s] 64%|██████▍   | 26389/41127 [01:35<00:51, 285.83it/s] 71%|███████▏  | 29332/41127 [01:45<00:41, 287.09it/s] 76%|███████▋  | 31388/41127 [01:55<00:37, 261.12it/s] 83%|████████▎ | 34292/41127 [02:05<00:25, 269.66it/s] 88%|████████▊ | 36348/41127 [02:16<00:19, 246.04it/s] 95%|█████████▍| 38997/41127 [02:26<00:08, 250.76it/s] 95%|█████████▍| 38997/41127 [02:39<00:08, 250.76it/s]100%|█████████▉| 40976/41127 [02:39<00:00, 214.07it/s]100%|██████████| 41127/41127 [02:42<00:00, 253.36it/s]
2025-08-16 07:42:32,749 - INFO - Done! Took 00:02:43.45
2025-08-16 07:42:32,889 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 07:42:33,031 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-16 07:42:33,031 - INFO - Start from epoch 0
2025-08-16 07:43:45,993 - INFO - train: {'epoch': 0, 'time_epoch': 72.86041, 'eta': 7213.18101, 'eta_hours': 2.00366, 'loss': 0.71941173, 'lr': 0.0, 'params': 451793, 'time_iter': 0.07081, 'accuracy': 0.05574, 'precision': 0.03786, 'recall': 0.99188, 'f1': 0.07293, 'auc': 0.51739}
2025-08-16 07:43:46,113 - INFO - ...computing epoch stats took: 0.20s
2025-08-16 07:43:50,657 - INFO - val: {'epoch': 0, 'time_epoch': 4.52753, 'loss': 0.71477123, 'lr': 0, 'params': 451793, 'time_iter': 0.0351, 'accuracy': 0.0231, 'precision': 0.01976, 'recall': 1.0, 'f1': 0.03876, 'auc': 0.56404}
2025-08-16 07:43:50,708 - INFO - ...computing epoch stats took: 0.06s
2025-08-16 07:43:55,254 - INFO - test: {'epoch': 0, 'time_epoch': 4.53011, 'loss': 0.71682137, 'lr': 0, 'params': 451793, 'time_iter': 0.03512, 'accuracy': 0.04012, 'precision': 0.03165, 'recall': 0.99231, 'f1': 0.06134, 'auc': 0.5408}
2025-08-16 07:43:55,301 - INFO - ...computing epoch stats took: 0.06s
2025-08-16 07:43:55,302 - INFO - > Epoch 0: took 82.3s (avg 82.3s) | Best so far: epoch 0	train_loss: 0.7194 train_auc: 0.5174	val_loss: 0.7148 val_auc: 0.5640	test_loss: 0.7168 test_auc: 0.5408
2025-08-16 07:45:05,636 - INFO - train: {'epoch': 1, 'time_epoch': 70.24122, 'eta': 7011.98007, 'eta_hours': 1.94777, 'loss': 0.51571079, 'lr': 2e-05, 'params': 451793, 'time_iter': 0.06826, 'accuracy': 0.85587, 'precision': 0.04416, 'recall': 0.13799, 'f1': 0.0669, 'auc': 0.54201}
2025-08-16 07:45:05,643 - INFO - ...computing epoch stats took: 0.08s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:45:10,064 - INFO - val: {'epoch': 1, 'time_epoch': 4.40334, 'loss': 0.30149309, 'lr': 0, 'params': 451793, 'time_iter': 0.03413, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.48953}
2025-08-16 07:45:10,066 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:45:14,323 - INFO - test: {'epoch': 1, 'time_epoch': 4.24213, 'loss': 0.29581026, 'lr': 0, 'params': 451793, 'time_iter': 0.03288, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.59646}
2025-08-16 07:45:14,325 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 07:45:14,326 - INFO - > Epoch 1: took 79.0s (avg 80.6s) | Best so far: epoch 0	train_loss: 0.7194 train_auc: 0.5174	val_loss: 0.7148 val_auc: 0.5640	test_loss: 0.7168 test_auc: 0.5408
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:46:21,487 - INFO - train: {'epoch': 2, 'time_epoch': 67.08436, 'eta': 6796.01366, 'eta_hours': 1.88778, 'loss': 0.21246387, 'lr': 4e-05, 'params': 451793, 'time_iter': 0.06519, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.57546}
2025-08-16 07:46:21,496 - INFO - ...computing epoch stats took: 0.07s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:46:25,837 - INFO - val: {'epoch': 2, 'time_epoch': 4.32285, 'loss': 0.1129374, 'lr': 0, 'params': 451793, 'time_iter': 0.03351, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.55858}
2025-08-16 07:46:25,840 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:46:30,132 - INFO - test: {'epoch': 2, 'time_epoch': 4.27669, 'loss': 0.14655807, 'lr': 0, 'params': 451793, 'time_iter': 0.03315, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.60354}
2025-08-16 07:46:30,135 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 07:46:30,136 - INFO - > Epoch 2: took 75.8s (avg 79.0s) | Best so far: epoch 0	train_loss: 0.7194 train_auc: 0.5174	val_loss: 0.7148 val_auc: 0.5640	test_loss: 0.7168 test_auc: 0.5408
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:47:37,775 - INFO - train: {'epoch': 3, 'time_epoch': 67.57011, 'eta': 6666.14634, 'eta_hours': 1.85171, 'loss': 0.16333583, 'lr': 6e-05, 'params': 451793, 'time_iter': 0.06567, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.60364}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:47:42,145 - INFO - val: {'epoch': 3, 'time_epoch': 4.34291, 'loss': 0.10315405, 'lr': 0, 'params': 451793, 'time_iter': 0.03367, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.56009}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:47:46,430 - INFO - test: {'epoch': 3, 'time_epoch': 4.26573, 'loss': 0.13837632, 'lr': 0, 'params': 451793, 'time_iter': 0.03307, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.63707}
2025-08-16 07:47:46,433 - INFO - > Epoch 3: took 76.3s (avg 78.4s) | Best so far: epoch 0	train_loss: 0.7194 train_auc: 0.5174	val_loss: 0.7148 val_auc: 0.5640	test_loss: 0.7168 test_auc: 0.5408
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:48:55,524 - INFO - train: {'epoch': 4, 'time_epoch': 69.01422, 'eta': 6588.636, 'eta_hours': 1.83018, 'loss': 0.15841172, 'lr': 8e-05, 'params': 451793, 'time_iter': 0.06707, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.62798}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:48:59,935 - INFO - val: {'epoch': 4, 'time_epoch': 4.38323, 'loss': 0.09729136, 'lr': 0, 'params': 451793, 'time_iter': 0.03398, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.65316}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:49:04,480 - INFO - test: {'epoch': 4, 'time_epoch': 4.43954, 'loss': 0.13955614, 'lr': 0, 'params': 451793, 'time_iter': 0.03442, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6382}
2025-08-16 07:49:04,605 - INFO - > Epoch 4: took 78.2s (avg 78.3s) | Best so far: epoch 4	train_loss: 0.1584 train_auc: 0.6280	val_loss: 0.0973 val_auc: 0.6532	test_loss: 0.1396 test_auc: 0.6382
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:50:14,540 - INFO - train: {'epoch': 5, 'time_epoch': 69.86145, 'eta': 6527.23104, 'eta_hours': 1.81312, 'loss': 0.15288339, 'lr': 0.0001, 'params': 451793, 'time_iter': 0.06789, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67449}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:50:18,832 - INFO - val: {'epoch': 5, 'time_epoch': 4.26968, 'loss': 0.09552872, 'lr': 0, 'params': 451793, 'time_iter': 0.0331, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67869}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:50:23,150 - INFO - test: {'epoch': 5, 'time_epoch': 4.30097, 'loss': 0.12943064, 'lr': 0, 'params': 451793, 'time_iter': 0.03334, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70644}
2025-08-16 07:50:23,152 - INFO - > Epoch 5: took 78.5s (avg 78.4s) | Best so far: epoch 5	train_loss: 0.1529 train_auc: 0.6745	val_loss: 0.0955 val_auc: 0.6787	test_loss: 0.1294 test_auc: 0.7064
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:51:33,057 - INFO - train: {'epoch': 6, 'time_epoch': 69.82981, 'eta': 6462.98949, 'eta_hours': 1.79527, 'loss': 0.14771118, 'lr': 9.997e-05, 'params': 451793, 'time_iter': 0.06786, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70826}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:51:37,451 - INFO - val: {'epoch': 6, 'time_epoch': 4.37237, 'loss': 0.0891937, 'lr': 0, 'params': 451793, 'time_iter': 0.03389, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70513}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:51:41,886 - INFO - test: {'epoch': 6, 'time_epoch': 4.41844, 'loss': 0.13053825, 'lr': 0, 'params': 451793, 'time_iter': 0.03425, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70563}
2025-08-16 07:51:41,888 - INFO - > Epoch 6: took 78.7s (avg 78.4s) | Best so far: epoch 6	train_loss: 0.1477 train_auc: 0.7083	val_loss: 0.0892 val_auc: 0.7051	test_loss: 0.1305 test_auc: 0.7056
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:52:52,086 - INFO - train: {'epoch': 7, 'time_epoch': 70.12531, 'eta': 6400.74918, 'eta_hours': 1.77799, 'loss': 0.14453976, 'lr': 9.989e-05, 'params': 451793, 'time_iter': 0.06815, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72328}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:52:56,259 - INFO - val: {'epoch': 7, 'time_epoch': 4.15347, 'loss': 0.08912315, 'lr': 0, 'params': 451793, 'time_iter': 0.0322, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72301}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:53:00,431 - INFO - test: {'epoch': 7, 'time_epoch': 4.1553, 'loss': 0.12807734, 'lr': 0, 'params': 451793, 'time_iter': 0.03221, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72188}
2025-08-16 07:53:00,435 - INFO - > Epoch 7: took 78.5s (avg 78.4s) | Best so far: epoch 7	train_loss: 0.1445 train_auc: 0.7233	val_loss: 0.0891 val_auc: 0.7230	test_loss: 0.1281 test_auc: 0.7219
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:54:09,781 - INFO - train: {'epoch': 8, 'time_epoch': 69.27412, 'eta': 6328.15012, 'eta_hours': 1.75782, 'loss': 0.14184874, 'lr': 9.975e-05, 'params': 451793, 'time_iter': 0.06732, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73313}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:54:14,078 - INFO - val: {'epoch': 8, 'time_epoch': 4.27461, 'loss': 0.09027886, 'lr': 0, 'params': 451793, 'time_iter': 0.03314, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68016}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:54:18,355 - INFO - test: {'epoch': 8, 'time_epoch': 4.2612, 'loss': 0.12470433, 'lr': 0, 'params': 451793, 'time_iter': 0.03303, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7352}
2025-08-16 07:54:18,358 - INFO - > Epoch 8: took 77.9s (avg 78.4s) | Best so far: epoch 7	train_loss: 0.1445 train_auc: 0.7233	val_loss: 0.0891 val_auc: 0.7230	test_loss: 0.1281 test_auc: 0.7219
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:55:30,039 - INFO - train: {'epoch': 9, 'time_epoch': 71.6036, 'eta': 6277.18142, 'eta_hours': 1.74366, 'loss': 0.13922849, 'lr': 9.956e-05, 'params': 451793, 'time_iter': 0.06959, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74261}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:55:34,402 - INFO - val: {'epoch': 9, 'time_epoch': 4.34012, 'loss': 0.08743935, 'lr': 0, 'params': 451793, 'time_iter': 0.03364, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69532}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:55:38,799 - INFO - test: {'epoch': 9, 'time_epoch': 4.38115, 'loss': 0.12605031, 'lr': 0, 'params': 451793, 'time_iter': 0.03396, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7078}
2025-08-16 07:55:38,802 - INFO - > Epoch 9: took 80.4s (avg 78.6s) | Best so far: epoch 7	train_loss: 0.1445 train_auc: 0.7233	val_loss: 0.0891 val_auc: 0.7230	test_loss: 0.1281 test_auc: 0.7219
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:56:48,381 - INFO - train: {'epoch': 10, 'time_epoch': 69.50435, 'eta': 6205.47608, 'eta_hours': 1.72374, 'loss': 0.13834711, 'lr': 9.932e-05, 'params': 451793, 'time_iter': 0.06755, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75067}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:56:52,808 - INFO - val: {'epoch': 10, 'time_epoch': 4.40542, 'loss': 0.09233077, 'lr': 0, 'params': 451793, 'time_iter': 0.03415, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70561}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:56:57,233 - INFO - test: {'epoch': 10, 'time_epoch': 4.40714, 'loss': 0.12947322, 'lr': 0, 'params': 451793, 'time_iter': 0.03416, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71017}
2025-08-16 07:56:57,235 - INFO - > Epoch 10: took 78.4s (avg 78.6s) | Best so far: epoch 7	train_loss: 0.1445 train_auc: 0.7233	val_loss: 0.0891 val_auc: 0.7230	test_loss: 0.1281 test_auc: 0.7219
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:58:08,276 - INFO - train: {'epoch': 11, 'time_epoch': 70.97492, 'eta': 6144.92173, 'eta_hours': 1.70692, 'loss': 0.1365634, 'lr': 9.902e-05, 'params': 451793, 'time_iter': 0.06897, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75619}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:58:12,673 - INFO - val: {'epoch': 11, 'time_epoch': 4.37397, 'loss': 0.08641977, 'lr': 0, 'params': 451793, 'time_iter': 0.03391, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71666}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:58:17,074 - INFO - test: {'epoch': 11, 'time_epoch': 4.38372, 'loss': 0.12061605, 'lr': 0, 'params': 451793, 'time_iter': 0.03398, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7447}
2025-08-16 07:58:17,077 - INFO - > Epoch 11: took 79.8s (avg 78.7s) | Best so far: epoch 7	train_loss: 0.1445 train_auc: 0.7233	val_loss: 0.0891 val_auc: 0.7230	test_loss: 0.1281 test_auc: 0.7219
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:59:27,626 - INFO - train: {'epoch': 12, 'time_epoch': 70.47366, 'eta': 6079.40963, 'eta_hours': 1.68872, 'loss': 0.13424715, 'lr': 9.867e-05, 'params': 451793, 'time_iter': 0.06849, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76489}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:59:32,093 - INFO - val: {'epoch': 12, 'time_epoch': 4.44027, 'loss': 0.08440228, 'lr': 0, 'params': 451793, 'time_iter': 0.03442, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73594}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 07:59:36,436 - INFO - test: {'epoch': 12, 'time_epoch': 4.32487, 'loss': 0.11649116, 'lr': 0, 'params': 451793, 'time_iter': 0.03353, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7651}
2025-08-16 07:59:36,440 - INFO - > Epoch 12: took 79.4s (avg 78.7s) | Best so far: epoch 12	train_loss: 0.1342 train_auc: 0.7649	val_loss: 0.0844 val_auc: 0.7359	test_loss: 0.1165 test_auc: 0.7651
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 08:00:46,387 - INFO - train: {'epoch': 13, 'time_epoch': 69.872, 'eta': 6009.49285, 'eta_hours': 1.6693, 'loss': 0.13374071, 'lr': 9.826e-05, 'params': 451793, 'time_iter': 0.0679, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.77215}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 08:00:50,861 - INFO - val: {'epoch': 13, 'time_epoch': 4.45219, 'loss': 0.09112809, 'lr': 0, 'params': 451793, 'time_iter': 0.03451, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71558}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 08:00:55,326 - INFO - test: {'epoch': 13, 'time_epoch': 4.44804, 'loss': 0.11974273, 'lr': 0, 'params': 451793, 'time_iter': 0.03448, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.77219}
2025-08-16 08:00:55,329 - INFO - > Epoch 13: took 78.9s (avg 78.7s) | Best so far: epoch 12	train_loss: 0.1342 train_auc: 0.7649	val_loss: 0.0844 val_auc: 0.7359	test_loss: 0.1165 test_auc: 0.7651
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 08:02:06,626 - INFO - train: {'epoch': 14, 'time_epoch': 71.22249, 'eta': 5947.2348, 'eta_hours': 1.65201, 'loss': 0.13220516, 'lr': 9.78e-05, 'params': 451793, 'time_iter': 0.06922, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7748}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 08:02:11,162 - INFO - val: {'epoch': 14, 'time_epoch': 4.50803, 'loss': 0.08280174, 'lr': 0, 'params': 451793, 'time_iter': 0.03495, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7618}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 08:02:15,646 - INFO - test: {'epoch': 14, 'time_epoch': 4.46462, 'loss': 0.11754358, 'lr': 0, 'params': 451793, 'time_iter': 0.03461, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75865}
2025-08-16 08:02:15,649 - INFO - > Epoch 14: took 80.3s (avg 78.8s) | Best so far: epoch 14	train_loss: 0.1322 train_auc: 0.7748	val_loss: 0.0828 val_auc: 0.7618	test_loss: 0.1175 test_auc: 0.7587
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 08:03:25,311 - INFO - train: {'epoch': 15, 'time_epoch': 69.59741, 'eta': 5875.32453, 'eta_hours': 1.63203, 'loss': 0.13162177, 'lr': 9.729e-05, 'params': 451793, 'time_iter': 0.06764, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.77397}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 08:03:29,740 - INFO - val: {'epoch': 15, 'time_epoch': 4.40727, 'loss': 0.0858235, 'lr': 0, 'params': 451793, 'time_iter': 0.03416, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73733}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 08:03:34,167 - INFO - test: {'epoch': 15, 'time_epoch': 4.40998, 'loss': 0.12064025, 'lr': 0, 'params': 451793, 'time_iter': 0.03419, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74004}
2025-08-16 08:03:34,169 - INFO - > Epoch 15: took 78.5s (avg 78.8s) | Best so far: epoch 14	train_loss: 0.1322 train_auc: 0.7748	val_loss: 0.0828 val_auc: 0.7618	test_loss: 0.1175 test_auc: 0.7587
2025-08-16 08:04:44,841 - INFO - train: {'epoch': 16, 'time_epoch': 70.58273, 'eta': 5808.49702, 'eta_hours': 1.61347, 'loss': 0.12993625, 'lr': 9.673e-05, 'params': 451793, 'time_iter': 0.06859, 'accuracy': 0.96262, 'precision': 1.0, 'recall': 0.00162, 'f1': 0.00324, 'auc': 0.78804}
2025-08-16 08:04:49,354 - INFO - val: {'epoch': 16, 'time_epoch': 4.48785, 'loss': 0.0853273, 'lr': 0, 'params': 451793, 'time_iter': 0.03479, 'accuracy': 0.98104, 'precision': 0.6, 'recall': 0.11111, 'f1': 0.1875, 'auc': 0.75664}
2025-08-16 08:04:53,820 - INFO - test: {'epoch': 16, 'time_epoch': 4.44572, 'loss': 0.12279254, 'lr': 0, 'params': 451793, 'time_iter': 0.03446, 'accuracy': 0.96937, 'precision': 0.59091, 'recall': 0.1, 'f1': 0.17105, 'auc': 0.73985}
2025-08-16 08:04:53,824 - INFO - > Epoch 16: took 79.7s (avg 78.9s) | Best so far: epoch 14	train_loss: 0.1322 train_auc: 0.7748	val_loss: 0.0828 val_auc: 0.7618	test_loss: 0.1175 test_auc: 0.7587
2025-08-16 08:06:05,510 - INFO - train: {'epoch': 17, 'time_epoch': 71.5941, 'eta': 5745.85964, 'eta_hours': 1.59607, 'loss': 0.12884438, 'lr': 9.611e-05, 'params': 451793, 'time_iter': 0.06958, 'accuracy': 0.96258, 'precision': 0.53333, 'recall': 0.00649, 'f1': 0.01283, 'auc': 0.79116}
2025-08-16 08:06:09,694 - INFO - val: {'epoch': 17, 'time_epoch': 4.15696, 'loss': 0.07968425, 'lr': 0, 'params': 451793, 'time_iter': 0.03222, 'accuracy': 0.98128, 'precision': 0.83333, 'recall': 0.06173, 'f1': 0.11494, 'auc': 0.77153}
2025-08-16 08:06:13,884 - INFO - test: {'epoch': 17, 'time_epoch': 4.17148, 'loss': 0.11614999, 'lr': 0, 'params': 451793, 'time_iter': 0.03234, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.00769, 'f1': 0.01515, 'auc': 0.76158}
2025-08-16 08:06:13,887 - INFO - > Epoch 17: took 80.1s (avg 78.9s) | Best so far: epoch 17	train_loss: 0.1288 train_auc: 0.7912	val_loss: 0.0797 val_auc: 0.7715	test_loss: 0.1161 test_auc: 0.7616
2025-08-16 08:07:23,618 - INFO - train: {'epoch': 18, 'time_epoch': 69.64304, 'eta': 5673.96175, 'eta_hours': 1.5761, 'loss': 0.12749059, 'lr': 9.545e-05, 'params': 451793, 'time_iter': 0.06768, 'accuracy': 0.96313, 'precision': 0.62667, 'recall': 0.03815, 'f1': 0.07192, 'auc': 0.79775}
2025-08-16 08:07:27,915 - INFO - val: {'epoch': 18, 'time_epoch': 4.27322, 'loss': 0.07985776, 'lr': 0, 'params': 451793, 'time_iter': 0.03313, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.07407, 'f1': 0.12903, 'auc': 0.76555}
2025-08-16 08:07:32,327 - INFO - test: {'epoch': 18, 'time_epoch': 4.39283, 'loss': 0.12020931, 'lr': 0, 'params': 451793, 'time_iter': 0.03405, 'accuracy': 0.96815, 'precision': 0.42857, 'recall': 0.02308, 'f1': 0.0438, 'auc': 0.7638}
2025-08-16 08:07:32,330 - INFO - > Epoch 18: took 78.4s (avg 78.9s) | Best so far: epoch 17	train_loss: 0.1288 train_auc: 0.7912	val_loss: 0.0797 val_auc: 0.7715	test_loss: 0.1161 test_auc: 0.7616
2025-08-16 08:08:42,907 - INFO - train: {'epoch': 19, 'time_epoch': 70.49332, 'eta': 5605.69046, 'eta_hours': 1.55714, 'loss': 0.12598582, 'lr': 9.474e-05, 'params': 451793, 'time_iter': 0.06851, 'accuracy': 0.96368, 'precision': 0.62416, 'recall': 0.07549, 'f1': 0.13469, 'auc': 0.80525}
2025-08-16 08:08:47,146 - INFO - val: {'epoch': 19, 'time_epoch': 4.21705, 'loss': 0.08047708, 'lr': 0, 'params': 451793, 'time_iter': 0.03269, 'accuracy': 0.98079, 'precision': 0.55556, 'recall': 0.12346, 'f1': 0.20202, 'auc': 0.77727}
2025-08-16 08:08:51,365 - INFO - test: {'epoch': 19, 'time_epoch': 4.20076, 'loss': 0.11623632, 'lr': 0, 'params': 451793, 'time_iter': 0.03256, 'accuracy': 0.96693, 'precision': 0.33333, 'recall': 0.04615, 'f1': 0.08108, 'auc': 0.75232}
2025-08-16 08:08:51,368 - INFO - > Epoch 19: took 79.0s (avg 78.9s) | Best so far: epoch 19	train_loss: 0.1260 train_auc: 0.8053	val_loss: 0.0805 val_auc: 0.7773	test_loss: 0.1162 test_auc: 0.7523
2025-08-16 08:10:05,177 - INFO - train: {'epoch': 20, 'time_epoch': 73.71886, 'eta': 5549.34173, 'eta_hours': 1.54148, 'loss': 0.125184, 'lr': 9.397e-05, 'params': 451793, 'time_iter': 0.07164, 'accuracy': 0.96413, 'precision': 0.64286, 'recall': 0.09497, 'f1': 0.16549, 'auc': 0.80109}
2025-08-16 08:10:09,319 - INFO - val: {'epoch': 20, 'time_epoch': 4.1184, 'loss': 0.07845643, 'lr': 0, 'params': 451793, 'time_iter': 0.03193, 'accuracy': 0.97982, 'precision': 0.4375, 'recall': 0.08642, 'f1': 0.14433, 'auc': 0.77578}
2025-08-16 08:10:13,506 - INFO - test: {'epoch': 20, 'time_epoch': 4.16842, 'loss': 0.11782256, 'lr': 0, 'params': 451793, 'time_iter': 0.03231, 'accuracy': 0.96718, 'precision': 0.38095, 'recall': 0.06154, 'f1': 0.10596, 'auc': 0.74478}
2025-08-16 08:10:13,509 - INFO - > Epoch 20: took 82.1s (avg 79.1s) | Best so far: epoch 19	train_loss: 0.1260 train_auc: 0.8053	val_loss: 0.0805 val_auc: 0.7773	test_loss: 0.1162 test_auc: 0.7523
2025-08-16 08:11:23,273 - INFO - train: {'epoch': 21, 'time_epoch': 69.67575, 'eta': 5477.07926, 'eta_hours': 1.52141, 'loss': 0.12467326, 'lr': 9.316e-05, 'params': 451793, 'time_iter': 0.06771, 'accuracy': 0.96453, 'precision': 0.63052, 'recall': 0.12744, 'f1': 0.21202, 'auc': 0.80314}
2025-08-16 08:11:27,515 - INFO - val: {'epoch': 21, 'time_epoch': 4.2184, 'loss': 0.07950877, 'lr': 0, 'params': 451793, 'time_iter': 0.0327, 'accuracy': 0.98152, 'precision': 0.6087, 'recall': 0.17284, 'f1': 0.26923, 'auc': 0.7883}
2025-08-16 08:11:31,925 - INFO - test: {'epoch': 21, 'time_epoch': 4.39169, 'loss': 0.12075935, 'lr': 0, 'params': 451793, 'time_iter': 0.03404, 'accuracy': 0.96912, 'precision': 0.55556, 'recall': 0.11538, 'f1': 0.19108, 'auc': 0.7421}
2025-08-16 08:11:31,928 - INFO - > Epoch 21: took 78.4s (avg 79.0s) | Best so far: epoch 21	train_loss: 0.1247 train_auc: 0.8031	val_loss: 0.0795 val_auc: 0.7883	test_loss: 0.1208 test_auc: 0.7421
2025-08-16 08:12:42,646 - INFO - train: {'epoch': 22, 'time_epoch': 70.63419, 'eta': 5408.2504, 'eta_hours': 1.50229, 'loss': 0.12171361, 'lr': 9.23e-05, 'params': 451793, 'time_iter': 0.06864, 'accuracy': 0.96456, 'precision': 0.6051, 'recall': 0.15422, 'f1': 0.2458, 'auc': 0.81751}
2025-08-16 08:12:47,129 - INFO - val: {'epoch': 22, 'time_epoch': 4.45928, 'loss': 0.07772182, 'lr': 0, 'params': 451793, 'time_iter': 0.03457, 'accuracy': 0.98201, 'precision': 0.60606, 'recall': 0.24691, 'f1': 0.35088, 'auc': 0.78441}
2025-08-16 08:12:51,599 - INFO - test: {'epoch': 22, 'time_epoch': 4.45068, 'loss': 0.11798838, 'lr': 0, 'params': 451793, 'time_iter': 0.0345, 'accuracy': 0.96985, 'precision': 0.6, 'recall': 0.13846, 'f1': 0.225, 'auc': 0.75011}
2025-08-16 08:12:51,601 - INFO - > Epoch 22: took 79.7s (avg 79.1s) | Best so far: epoch 21	train_loss: 0.1247 train_auc: 0.8031	val_loss: 0.0795 val_auc: 0.7883	test_loss: 0.1208 test_auc: 0.7421
2025-08-16 08:14:02,575 - INFO - train: {'epoch': 23, 'time_epoch': 70.88892, 'eta': 5340.07773, 'eta_hours': 1.48335, 'loss': 0.12209594, 'lr': 9.14e-05, 'params': 451793, 'time_iter': 0.06889, 'accuracy': 0.96489, 'precision': 0.60724, 'recall': 0.17695, 'f1': 0.27404, 'auc': 0.81078}
2025-08-16 08:14:07,023 - INFO - val: {'epoch': 23, 'time_epoch': 4.42303, 'loss': 0.07829212, 'lr': 0, 'params': 451793, 'time_iter': 0.03429, 'accuracy': 0.98055, 'precision': 0.52632, 'recall': 0.12346, 'f1': 0.2, 'auc': 0.75615}
2025-08-16 08:14:11,429 - INFO - test: {'epoch': 23, 'time_epoch': 4.38586, 'loss': 0.11725486, 'lr': 0, 'params': 451793, 'time_iter': 0.034, 'accuracy': 0.9718, 'precision': 0.73333, 'recall': 0.16923, 'f1': 0.275, 'auc': 0.75073}
2025-08-16 08:14:11,433 - INFO - > Epoch 23: took 79.8s (avg 79.1s) | Best so far: epoch 21	train_loss: 0.1247 train_auc: 0.8031	val_loss: 0.0795 val_auc: 0.7883	test_loss: 0.1208 test_auc: 0.7421
2025-08-16 08:15:20,600 - INFO - train: {'epoch': 24, 'time_epoch': 69.07622, 'eta': 5266.24966, 'eta_hours': 1.46285, 'loss': 0.12072573, 'lr': 9.045e-05, 'params': 451793, 'time_iter': 0.06713, 'accuracy': 0.96562, 'precision': 0.65831, 'recall': 0.17045, 'f1': 0.27079, 'auc': 0.81979}
2025-08-16 08:15:25,036 - INFO - val: {'epoch': 24, 'time_epoch': 4.41273, 'loss': 0.07526382, 'lr': 0, 'params': 451793, 'time_iter': 0.03421, 'accuracy': 0.98152, 'precision': 0.59259, 'recall': 0.19753, 'f1': 0.2963, 'auc': 0.78347}
2025-08-16 08:15:29,463 - INFO - test: {'epoch': 24, 'time_epoch': 4.40877, 'loss': 0.11961504, 'lr': 0, 'params': 451793, 'time_iter': 0.03418, 'accuracy': 0.96985, 'precision': 0.58333, 'recall': 0.16154, 'f1': 0.25301, 'auc': 0.74587}
2025-08-16 08:15:29,466 - INFO - > Epoch 24: took 78.0s (avg 79.1s) | Best so far: epoch 21	train_loss: 0.1247 train_auc: 0.8031	val_loss: 0.0795 val_auc: 0.7883	test_loss: 0.1208 test_auc: 0.7421
2025-08-16 08:16:40,428 - INFO - train: {'epoch': 25, 'time_epoch': 70.87324, 'eta': 5197.90171, 'eta_hours': 1.44386, 'loss': 0.12127888, 'lr': 8.946e-05, 'params': 451793, 'time_iter': 0.06888, 'accuracy': 0.96453, 'precision': 0.59366, 'recall': 0.16721, 'f1': 0.26092, 'auc': 0.81992}
2025-08-16 08:16:44,899 - INFO - val: {'epoch': 25, 'time_epoch': 4.44828, 'loss': 0.0756022, 'lr': 0, 'params': 451793, 'time_iter': 0.03448, 'accuracy': 0.98274, 'precision': 0.72727, 'recall': 0.19753, 'f1': 0.31068, 'auc': 0.76081}
2025-08-16 08:16:49,297 - INFO - test: {'epoch': 25, 'time_epoch': 4.37947, 'loss': 0.11579526, 'lr': 0, 'params': 451793, 'time_iter': 0.03395, 'accuracy': 0.97277, 'precision': 0.8, 'recall': 0.18462, 'f1': 0.3, 'auc': 0.74978}
2025-08-16 08:16:49,300 - INFO - > Epoch 25: took 79.8s (avg 79.1s) | Best so far: epoch 21	train_loss: 0.1247 train_auc: 0.8031	val_loss: 0.0795 val_auc: 0.7883	test_loss: 0.1208 test_auc: 0.7421
2025-08-16 08:17:59,573 - INFO - train: {'epoch': 26, 'time_epoch': 70.1851, 'eta': 5127.50619, 'eta_hours': 1.42431, 'loss': 0.11934237, 'lr': 8.842e-05, 'params': 451793, 'time_iter': 0.06821, 'accuracy': 0.96581, 'precision': 0.64042, 'recall': 0.19805, 'f1': 0.30254, 'auc': 0.8185}
2025-08-16 08:18:04,048 - INFO - val: {'epoch': 26, 'time_epoch': 4.4511, 'loss': 0.07573948, 'lr': 0, 'params': 451793, 'time_iter': 0.0345, 'accuracy': 0.98371, 'precision': 0.81818, 'recall': 0.22222, 'f1': 0.34951, 'auc': 0.78578}
2025-08-16 08:18:08,524 - INFO - test: {'epoch': 26, 'time_epoch': 4.44218, 'loss': 0.12234228, 'lr': 0, 'params': 451793, 'time_iter': 0.03444, 'accuracy': 0.96766, 'precision': 0.44828, 'recall': 0.1, 'f1': 0.16352, 'auc': 0.73425}
2025-08-16 08:18:08,574 - INFO - > Epoch 26: took 79.3s (avg 79.1s) | Best so far: epoch 21	train_loss: 0.1247 train_auc: 0.8031	val_loss: 0.0795 val_auc: 0.7883	test_loss: 0.1208 test_auc: 0.7421
2025-08-16 08:19:18,448 - INFO - train: {'epoch': 27, 'time_epoch': 69.74972, 'eta': 5056.00614, 'eta_hours': 1.40445, 'loss': 0.11986971, 'lr': 8.734e-05, 'params': 451793, 'time_iter': 0.06778, 'accuracy': 0.96626, 'precision': 0.6525, 'recall': 0.21185, 'f1': 0.31985, 'auc': 0.8161}
2025-08-16 08:19:22,872 - INFO - val: {'epoch': 27, 'time_epoch': 4.40116, 'loss': 0.07439737, 'lr': 0, 'params': 451793, 'time_iter': 0.03412, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.78455}
2025-08-16 08:19:27,318 - INFO - test: {'epoch': 27, 'time_epoch': 4.42768, 'loss': 0.11885518, 'lr': 0, 'params': 451793, 'time_iter': 0.03432, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.23846, 'f1': 0.32292, 'auc': 0.76362}
2025-08-16 08:19:27,321 - INFO - > Epoch 27: took 78.7s (avg 79.1s) | Best so far: epoch 21	train_loss: 0.1247 train_auc: 0.8031	val_loss: 0.0795 val_auc: 0.7883	test_loss: 0.1208 test_auc: 0.7421
2025-08-16 08:20:36,815 - INFO - train: {'epoch': 28, 'time_epoch': 69.40774, 'eta': 4983.78954, 'eta_hours': 1.38439, 'loss': 0.1191119, 'lr': 8.622e-05, 'params': 451793, 'time_iter': 0.06745, 'accuracy': 0.96544, 'precision': 0.62338, 'recall': 0.19481, 'f1': 0.29685, 'auc': 0.82336}
2025-08-16 08:20:41,063 - INFO - val: {'epoch': 28, 'time_epoch': 4.22471, 'loss': 0.07519101, 'lr': 0, 'params': 451793, 'time_iter': 0.03275, 'accuracy': 0.98201, 'precision': 0.62069, 'recall': 0.22222, 'f1': 0.32727, 'auc': 0.80024}
2025-08-16 08:20:45,318 - INFO - test: {'epoch': 28, 'time_epoch': 4.23758, 'loss': 0.1206852, 'lr': 0, 'params': 451793, 'time_iter': 0.03285, 'accuracy': 0.97009, 'precision': 0.58537, 'recall': 0.18462, 'f1': 0.2807, 'auc': 0.74467}
2025-08-16 08:20:45,321 - INFO - > Epoch 28: took 78.0s (avg 79.0s) | Best so far: epoch 28	train_loss: 0.1191 train_auc: 0.8234	val_loss: 0.0752 val_auc: 0.8002	test_loss: 0.1207 test_auc: 0.7447
2025-08-16 08:21:56,038 - INFO - train: {'epoch': 29, 'time_epoch': 70.63248, 'eta': 4914.61793, 'eta_hours': 1.36517, 'loss': 0.11802535, 'lr': 8.506e-05, 'params': 451793, 'time_iter': 0.06864, 'accuracy': 0.96584, 'precision': 0.62676, 'recall': 0.21672, 'f1': 0.32207, 'auc': 0.82282}
2025-08-16 08:22:00,362 - INFO - val: {'epoch': 29, 'time_epoch': 4.30031, 'loss': 0.07474155, 'lr': 0, 'params': 451793, 'time_iter': 0.03334, 'accuracy': 0.98177, 'precision': 0.6, 'recall': 0.22222, 'f1': 0.32432, 'auc': 0.79137}
2025-08-16 08:22:04,758 - INFO - test: {'epoch': 29, 'time_epoch': 4.37754, 'loss': 0.11976299, 'lr': 0, 'params': 451793, 'time_iter': 0.03393, 'accuracy': 0.97058, 'precision': 0.62162, 'recall': 0.17692, 'f1': 0.27545, 'auc': 0.73465}
2025-08-16 08:22:04,760 - INFO - > Epoch 29: took 79.4s (avg 79.1s) | Best so far: epoch 28	train_loss: 0.1191 train_auc: 0.8234	val_loss: 0.0752 val_auc: 0.8002	test_loss: 0.1207 test_auc: 0.7447
2025-08-16 08:23:13,897 - INFO - train: {'epoch': 30, 'time_epoch': 69.04677, 'eta': 4841.82258, 'eta_hours': 1.34495, 'loss': 0.11701082, 'lr': 8.386e-05, 'params': 451793, 'time_iter': 0.0671, 'accuracy': 0.96641, 'precision': 0.64733, 'recall': 0.22646, 'f1': 0.33554, 'auc': 0.82958}
2025-08-16 08:23:18,266 - INFO - val: {'epoch': 30, 'time_epoch': 4.34259, 'loss': 0.07622111, 'lr': 0, 'params': 451793, 'time_iter': 0.03366, 'accuracy': 0.98298, 'precision': 0.65714, 'recall': 0.28395, 'f1': 0.39655, 'auc': 0.76679}
2025-08-16 08:23:22,624 - INFO - test: {'epoch': 30, 'time_epoch': 4.33611, 'loss': 0.12190157, 'lr': 0, 'params': 451793, 'time_iter': 0.03361, 'accuracy': 0.96888, 'precision': 0.52632, 'recall': 0.15385, 'f1': 0.2381, 'auc': 0.74647}
2025-08-16 08:23:22,627 - INFO - > Epoch 30: took 77.9s (avg 79.0s) | Best so far: epoch 28	train_loss: 0.1191 train_auc: 0.8234	val_loss: 0.0752 val_auc: 0.8002	test_loss: 0.1207 test_auc: 0.7447
2025-08-16 08:24:32,534 - INFO - train: {'epoch': 31, 'time_epoch': 69.81903, 'eta': 4770.90258, 'eta_hours': 1.32525, 'loss': 0.11753621, 'lr': 8.263e-05, 'params': 451793, 'time_iter': 0.06785, 'accuracy': 0.96541, 'precision': 0.61463, 'recall': 0.20455, 'f1': 0.30694, 'auc': 0.82096}
2025-08-16 08:24:36,806 - INFO - val: {'epoch': 31, 'time_epoch': 4.24945, 'loss': 0.07403587, 'lr': 0, 'params': 451793, 'time_iter': 0.03294, 'accuracy': 0.98322, 'precision': 0.64286, 'recall': 0.33333, 'f1': 0.43902, 'auc': 0.77843}
2025-08-16 08:24:41,071 - INFO - test: {'epoch': 31, 'time_epoch': 4.24677, 'loss': 0.11727555, 'lr': 0, 'params': 451793, 'time_iter': 0.03292, 'accuracy': 0.96864, 'precision': 0.5098, 'recall': 0.2, 'f1': 0.28729, 'auc': 0.75887}
2025-08-16 08:24:41,073 - INFO - > Epoch 31: took 78.4s (avg 79.0s) | Best so far: epoch 28	train_loss: 0.1191 train_auc: 0.8234	val_loss: 0.0752 val_auc: 0.8002	test_loss: 0.1207 test_auc: 0.7447
2025-08-16 08:25:48,518 - INFO - train: {'epoch': 32, 'time_epoch': 67.35735, 'eta': 4695.05134, 'eta_hours': 1.30418, 'loss': 0.11628018, 'lr': 8.136e-05, 'params': 451793, 'time_iter': 0.06546, 'accuracy': 0.96632, 'precision': 0.625, 'recall': 0.25162, 'f1': 0.3588, 'auc': 0.82537}
2025-08-16 08:25:52,769 - INFO - val: {'epoch': 32, 'time_epoch': 4.22857, 'loss': 0.07316376, 'lr': 0, 'params': 451793, 'time_iter': 0.03278, 'accuracy': 0.98322, 'precision': 0.64286, 'recall': 0.33333, 'f1': 0.43902, 'auc': 0.78344}
2025-08-16 08:25:57,104 - INFO - test: {'epoch': 32, 'time_epoch': 4.31784, 'loss': 0.11440283, 'lr': 0, 'params': 451793, 'time_iter': 0.03347, 'accuracy': 0.96791, 'precision': 0.48571, 'recall': 0.26154, 'f1': 0.34, 'auc': 0.76728}
2025-08-16 08:25:57,107 - INFO - > Epoch 32: took 76.0s (avg 78.9s) | Best so far: epoch 28	train_loss: 0.1191 train_auc: 0.8234	val_loss: 0.0752 val_auc: 0.8002	test_loss: 0.1207 test_auc: 0.7447
2025-08-16 08:27:06,208 - INFO - train: {'epoch': 33, 'time_epoch': 69.01759, 'eta': 4622.92258, 'eta_hours': 1.28415, 'loss': 0.11481668, 'lr': 8.005e-05, 'params': 451793, 'time_iter': 0.06707, 'accuracy': 0.96769, 'precision': 0.67495, 'recall': 0.26461, 'f1': 0.38017, 'auc': 0.83233}
2025-08-16 08:27:10,242 - INFO - val: {'epoch': 33, 'time_epoch': 4.01217, 'loss': 0.07106659, 'lr': 0, 'params': 451793, 'time_iter': 0.0311, 'accuracy': 0.98298, 'precision': 0.66667, 'recall': 0.2716, 'f1': 0.38596, 'auc': 0.81761}
2025-08-16 08:27:14,299 - INFO - test: {'epoch': 33, 'time_epoch': 4.04011, 'loss': 0.12096761, 'lr': 0, 'params': 451793, 'time_iter': 0.03132, 'accuracy': 0.96864, 'precision': 0.51429, 'recall': 0.13846, 'f1': 0.21818, 'auc': 0.73767}
2025-08-16 08:27:14,302 - INFO - > Epoch 33: took 77.2s (avg 78.9s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:28:20,083 - INFO - train: {'epoch': 34, 'time_epoch': 65.69193, 'eta': 4544.79536, 'eta_hours': 1.26244, 'loss': 0.11487, 'lr': 7.872e-05, 'params': 451793, 'time_iter': 0.06384, 'accuracy': 0.96693, 'precision': 0.65584, 'recall': 0.24594, 'f1': 0.35773, 'auc': 0.8354}
2025-08-16 08:28:24,294 - INFO - val: {'epoch': 34, 'time_epoch': 4.17445, 'loss': 0.07280633, 'lr': 0, 'params': 451793, 'time_iter': 0.03236, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.79432}
2025-08-16 08:28:28,459 - INFO - test: {'epoch': 34, 'time_epoch': 4.14725, 'loss': 0.11870264, 'lr': 0, 'params': 451793, 'time_iter': 0.03215, 'accuracy': 0.97009, 'precision': 0.5614, 'recall': 0.24615, 'f1': 0.34225, 'auc': 0.74281}
2025-08-16 08:28:28,462 - INFO - > Epoch 34: took 74.2s (avg 78.7s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:29:35,860 - INFO - train: {'epoch': 35, 'time_epoch': 67.31368, 'eta': 4470.2421, 'eta_hours': 1.24173, 'loss': 0.11394609, 'lr': 7.735e-05, 'params': 451793, 'time_iter': 0.06542, 'accuracy': 0.96772, 'precision': 0.65858, 'recall': 0.28653, 'f1': 0.39932, 'auc': 0.83247}
2025-08-16 08:29:40,154 - INFO - val: {'epoch': 35, 'time_epoch': 4.26801, 'loss': 0.07336073, 'lr': 0, 'params': 451793, 'time_iter': 0.03309, 'accuracy': 0.98274, 'precision': 0.65625, 'recall': 0.25926, 'f1': 0.37168, 'auc': 0.76356}
2025-08-16 08:29:44,462 - INFO - test: {'epoch': 35, 'time_epoch': 4.2889, 'loss': 0.11908622, 'lr': 0, 'params': 451793, 'time_iter': 0.03325, 'accuracy': 0.97034, 'precision': 0.57407, 'recall': 0.23846, 'f1': 0.33696, 'auc': 0.74797}
2025-08-16 08:29:44,465 - INFO - > Epoch 35: took 76.0s (avg 78.7s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:30:51,175 - INFO - train: {'epoch': 36, 'time_epoch': 66.62668, 'eta': 4394.9104, 'eta_hours': 1.22081, 'loss': 0.11465118, 'lr': 7.595e-05, 'params': 451793, 'time_iter': 0.06475, 'accuracy': 0.9673, 'precision': 0.65354, 'recall': 0.26948, 'f1': 0.38161, 'auc': 0.83225}
2025-08-16 08:30:55,451 - INFO - val: {'epoch': 36, 'time_epoch': 4.25367, 'loss': 0.07596447, 'lr': 0, 'params': 451793, 'time_iter': 0.03297, 'accuracy': 0.98225, 'precision': 0.61111, 'recall': 0.2716, 'f1': 0.37607, 'auc': 0.77613}
2025-08-16 08:30:59,709 - INFO - test: {'epoch': 36, 'time_epoch': 4.24135, 'loss': 0.11836621, 'lr': 0, 'params': 451793, 'time_iter': 0.03288, 'accuracy': 0.97034, 'precision': 0.58696, 'recall': 0.20769, 'f1': 0.30682, 'auc': 0.75469}
2025-08-16 08:30:59,711 - INFO - > Epoch 36: took 75.2s (avg 78.6s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:32:06,805 - INFO - train: {'epoch': 37, 'time_epoch': 67.00972, 'eta': 4320.66183, 'eta_hours': 1.20018, 'loss': 0.1126581, 'lr': 7.452e-05, 'params': 451793, 'time_iter': 0.06512, 'accuracy': 0.96696, 'precision': 0.6381, 'recall': 0.27192, 'f1': 0.38133, 'auc': 0.84362}
2025-08-16 08:32:10,739 - INFO - val: {'epoch': 37, 'time_epoch': 3.9131, 'loss': 0.07358928, 'lr': 0, 'params': 451793, 'time_iter': 0.03033, 'accuracy': 0.98371, 'precision': 0.71875, 'recall': 0.28395, 'f1': 0.40708, 'auc': 0.75782}
2025-08-16 08:32:14,712 - INFO - test: {'epoch': 37, 'time_epoch': 3.95646, 'loss': 0.11559828, 'lr': 0, 'params': 451793, 'time_iter': 0.03067, 'accuracy': 0.97034, 'precision': 0.58, 'recall': 0.22308, 'f1': 0.32222, 'auc': 0.74437}
2025-08-16 08:32:14,714 - INFO - > Epoch 37: took 75.0s (avg 78.5s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:33:21,427 - INFO - train: {'epoch': 38, 'time_epoch': 66.63041, 'eta': 4246.1912, 'eta_hours': 1.1795, 'loss': 0.11290484, 'lr': 7.307e-05, 'params': 451793, 'time_iter': 0.06475, 'accuracy': 0.96727, 'precision': 0.64706, 'recall': 0.27679, 'f1': 0.38772, 'auc': 0.83678}
2025-08-16 08:33:25,701 - INFO - val: {'epoch': 38, 'time_epoch': 4.24985, 'loss': 0.07093202, 'lr': 0, 'params': 451793, 'time_iter': 0.03294, 'accuracy': 0.98322, 'precision': 0.67647, 'recall': 0.28395, 'f1': 0.4, 'auc': 0.78211}
2025-08-16 08:33:29,926 - INFO - test: {'epoch': 38, 'time_epoch': 4.20736, 'loss': 0.11746377, 'lr': 0, 'params': 451793, 'time_iter': 0.03262, 'accuracy': 0.97034, 'precision': 0.57143, 'recall': 0.24615, 'f1': 0.34409, 'auc': 0.75339}
2025-08-16 08:33:29,929 - INFO - > Epoch 38: took 75.2s (avg 78.4s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:34:37,249 - INFO - train: {'epoch': 39, 'time_epoch': 67.24008, 'eta': 4173.0271, 'eta_hours': 1.15917, 'loss': 0.11297926, 'lr': 7.159e-05, 'params': 451793, 'time_iter': 0.06535, 'accuracy': 0.96702, 'precision': 0.63148, 'recall': 0.28653, 'f1': 0.39419, 'auc': 0.8366}
2025-08-16 08:34:41,384 - INFO - val: {'epoch': 39, 'time_epoch': 4.11223, 'loss': 0.08099777, 'lr': 0, 'params': 451793, 'time_iter': 0.03188, 'accuracy': 0.98055, 'precision': 0.51111, 'recall': 0.28395, 'f1': 0.36508, 'auc': 0.7439}
2025-08-16 08:34:45,467 - INFO - test: {'epoch': 39, 'time_epoch': 4.06615, 'loss': 0.12138658, 'lr': 0, 'params': 451793, 'time_iter': 0.03152, 'accuracy': 0.96742, 'precision': 0.46552, 'recall': 0.20769, 'f1': 0.28723, 'auc': 0.7487}
2025-08-16 08:34:45,469 - INFO - > Epoch 39: took 75.5s (avg 78.3s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:35:49,649 - INFO - train: {'epoch': 40, 'time_epoch': 64.09951, 'eta': 4095.6326, 'eta_hours': 1.13768, 'loss': 0.11206061, 'lr': 7.008e-05, 'params': 451793, 'time_iter': 0.06229, 'accuracy': 0.96793, 'precision': 0.67456, 'recall': 0.2776, 'f1': 0.39333, 'auc': 0.84221}
2025-08-16 08:35:53,642 - INFO - val: {'epoch': 40, 'time_epoch': 3.96971, 'loss': 0.07111889, 'lr': 0, 'params': 451793, 'time_iter': 0.03077, 'accuracy': 0.98322, 'precision': 0.65789, 'recall': 0.30864, 'f1': 0.42017, 'auc': 0.80329}
2025-08-16 08:35:57,648 - INFO - test: {'epoch': 40, 'time_epoch': 3.98921, 'loss': 0.11824224, 'lr': 0, 'params': 451793, 'time_iter': 0.03092, 'accuracy': 0.96985, 'precision': 0.54839, 'recall': 0.26154, 'f1': 0.35417, 'auc': 0.76219}
2025-08-16 08:35:57,650 - INFO - > Epoch 40: took 72.2s (avg 78.2s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:37:04,289 - INFO - train: {'epoch': 41, 'time_epoch': 66.5595, 'eta': 4022.26834, 'eta_hours': 1.1173, 'loss': 0.11083571, 'lr': 6.856e-05, 'params': 451793, 'time_iter': 0.06468, 'accuracy': 0.96842, 'precision': 0.6797, 'recall': 0.29627, 'f1': 0.41266, 'auc': 0.84837}
2025-08-16 08:37:08,273 - INFO - val: {'epoch': 41, 'time_epoch': 3.96253, 'loss': 0.06909358, 'lr': 0, 'params': 451793, 'time_iter': 0.03072, 'accuracy': 0.98444, 'precision': 0.7931, 'recall': 0.28395, 'f1': 0.41818, 'auc': 0.79468}
2025-08-16 08:37:12,239 - INFO - test: {'epoch': 41, 'time_epoch': 3.9493, 'loss': 0.11720246, 'lr': 0, 'params': 451793, 'time_iter': 0.03061, 'accuracy': 0.97155, 'precision': 0.65116, 'recall': 0.21538, 'f1': 0.3237, 'auc': 0.74885}
2025-08-16 08:37:12,241 - INFO - > Epoch 41: took 74.6s (avg 78.1s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:38:16,238 - INFO - train: {'epoch': 42, 'time_epoch': 63.91638, 'eta': 3945.71691, 'eta_hours': 1.09603, 'loss': 0.10886682, 'lr': 6.701e-05, 'params': 451793, 'time_iter': 0.06212, 'accuracy': 0.96951, 'precision': 0.71087, 'recall': 0.31331, 'f1': 0.43493, 'auc': 0.84863}
2025-08-16 08:38:20,379 - INFO - val: {'epoch': 42, 'time_epoch': 4.11955, 'loss': 0.07323259, 'lr': 0, 'params': 451793, 'time_iter': 0.03193, 'accuracy': 0.98177, 'precision': 0.575, 'recall': 0.28395, 'f1': 0.38017, 'auc': 0.78958}
2025-08-16 08:38:24,588 - INFO - test: {'epoch': 42, 'time_epoch': 4.1912, 'loss': 0.12188955, 'lr': 0, 'params': 451793, 'time_iter': 0.03249, 'accuracy': 0.96742, 'precision': 0.46154, 'recall': 0.18462, 'f1': 0.26374, 'auc': 0.7515}
2025-08-16 08:38:24,590 - INFO - > Epoch 42: took 72.3s (avg 77.9s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:39:33,238 - INFO - train: {'epoch': 43, 'time_epoch': 68.56398, 'eta': 3875.65492, 'eta_hours': 1.07657, 'loss': 0.11058823, 'lr': 6.545e-05, 'params': 451793, 'time_iter': 0.06663, 'accuracy': 0.9686, 'precision': 0.68598, 'recall': 0.29789, 'f1': 0.41539, 'auc': 0.84411}
2025-08-16 08:39:37,355 - INFO - val: {'epoch': 43, 'time_epoch': 4.09535, 'loss': 0.07287966, 'lr': 0, 'params': 451793, 'time_iter': 0.03175, 'accuracy': 0.98322, 'precision': 0.7, 'recall': 0.25926, 'f1': 0.37838, 'auc': 0.76406}
2025-08-16 08:39:41,519 - INFO - test: {'epoch': 43, 'time_epoch': 4.14762, 'loss': 0.11691015, 'lr': 0, 'params': 451793, 'time_iter': 0.03215, 'accuracy': 0.97253, 'precision': 0.74286, 'recall': 0.2, 'f1': 0.31515, 'auc': 0.76721}
2025-08-16 08:39:41,522 - INFO - > Epoch 43: took 76.9s (avg 77.9s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:40:48,800 - INFO - train: {'epoch': 44, 'time_epoch': 67.19182, 'eta': 3803.98243, 'eta_hours': 1.05666, 'loss': 0.10985373, 'lr': 6.387e-05, 'params': 451793, 'time_iter': 0.0653, 'accuracy': 0.96812, 'precision': 0.65858, 'recall': 0.30844, 'f1': 0.42012, 'auc': 0.84747}
2025-08-16 08:40:53,102 - INFO - val: {'epoch': 44, 'time_epoch': 4.27587, 'loss': 0.07480869, 'lr': 0, 'params': 451793, 'time_iter': 0.03315, 'accuracy': 0.98298, 'precision': 0.67742, 'recall': 0.25926, 'f1': 0.375, 'auc': 0.76352}
2025-08-16 08:40:57,405 - INFO - test: {'epoch': 44, 'time_epoch': 4.28322, 'loss': 0.12427225, 'lr': 0, 'params': 451793, 'time_iter': 0.0332, 'accuracy': 0.96693, 'precision': 0.43478, 'recall': 0.15385, 'f1': 0.22727, 'auc': 0.74809}
2025-08-16 08:40:57,408 - INFO - > Epoch 44: took 75.9s (avg 77.9s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:42:02,795 - INFO - train: {'epoch': 45, 'time_epoch': 65.3016, 'eta': 3730.28579, 'eta_hours': 1.03619, 'loss': 0.10902572, 'lr': 6.227e-05, 'params': 451793, 'time_iter': 0.06346, 'accuracy': 0.96967, 'precision': 0.71747, 'recall': 0.31331, 'f1': 0.43616, 'auc': 0.84689}
2025-08-16 08:42:07,035 - INFO - val: {'epoch': 45, 'time_epoch': 4.2179, 'loss': 0.07037373, 'lr': 0, 'params': 451793, 'time_iter': 0.0327, 'accuracy': 0.98322, 'precision': 0.66667, 'recall': 0.2963, 'f1': 0.41026, 'auc': 0.7859}
2025-08-16 08:42:11,248 - INFO - test: {'epoch': 45, 'time_epoch': 4.19649, 'loss': 0.11448987, 'lr': 0, 'params': 451793, 'time_iter': 0.03253, 'accuracy': 0.97058, 'precision': 0.58182, 'recall': 0.24615, 'f1': 0.34595, 'auc': 0.7596}
2025-08-16 08:42:11,251 - INFO - > Epoch 45: took 73.8s (avg 77.8s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:43:18,255 - INFO - train: {'epoch': 46, 'time_epoch': 66.91947, 'eta': 3658.7708, 'eta_hours': 1.01633, 'loss': 0.10898058, 'lr': 6.066e-05, 'params': 451793, 'time_iter': 0.06503, 'accuracy': 0.96842, 'precision': 0.67019, 'recall': 0.30844, 'f1': 0.42246, 'auc': 0.85132}
2025-08-16 08:43:22,466 - INFO - val: {'epoch': 46, 'time_epoch': 4.18897, 'loss': 0.07456553, 'lr': 0, 'params': 451793, 'time_iter': 0.03247, 'accuracy': 0.98055, 'precision': 0.50794, 'recall': 0.39506, 'f1': 0.44444, 'auc': 0.79703}
2025-08-16 08:43:26,659 - INFO - test: {'epoch': 46, 'time_epoch': 4.17526, 'loss': 0.12007023, 'lr': 0, 'params': 451793, 'time_iter': 0.03237, 'accuracy': 0.96596, 'precision': 0.44444, 'recall': 0.30769, 'f1': 0.36364, 'auc': 0.76841}
2025-08-16 08:43:26,661 - INFO - > Epoch 46: took 75.4s (avg 77.7s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:44:33,677 - INFO - train: {'epoch': 47, 'time_epoch': 66.93083, 'eta': 3587.4596, 'eta_hours': 0.99652, 'loss': 0.10904399, 'lr': 5.904e-05, 'params': 451793, 'time_iter': 0.06504, 'accuracy': 0.96863, 'precision': 0.68182, 'recall': 0.30438, 'f1': 0.42088, 'auc': 0.85475}
2025-08-16 08:44:38,015 - INFO - val: {'epoch': 47, 'time_epoch': 4.31568, 'loss': 0.07526498, 'lr': 0, 'params': 451793, 'time_iter': 0.03345, 'accuracy': 0.98274, 'precision': 0.60417, 'recall': 0.35802, 'f1': 0.44961, 'auc': 0.75054}
2025-08-16 08:44:42,364 - INFO - test: {'epoch': 47, 'time_epoch': 4.33128, 'loss': 0.11708762, 'lr': 0, 'params': 451793, 'time_iter': 0.03358, 'accuracy': 0.96985, 'precision': 0.55, 'recall': 0.25385, 'f1': 0.34737, 'auc': 0.76107}
2025-08-16 08:44:42,366 - INFO - > Epoch 47: took 75.7s (avg 77.7s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:45:50,013 - INFO - train: {'epoch': 48, 'time_epoch': 67.56261, 'eta': 3516.98474, 'eta_hours': 0.97694, 'loss': 0.10896129, 'lr': 5.741e-05, 'params': 451793, 'time_iter': 0.06566, 'accuracy': 0.969, 'precision': 0.69065, 'recall': 0.31169, 'f1': 0.42953, 'auc': 0.85235}
2025-08-16 08:45:54,182 - INFO - val: {'epoch': 48, 'time_epoch': 4.14723, 'loss': 0.07309864, 'lr': 0, 'params': 451793, 'time_iter': 0.03215, 'accuracy': 0.98322, 'precision': 0.64286, 'recall': 0.33333, 'f1': 0.43902, 'auc': 0.77558}
2025-08-16 08:45:58,367 - INFO - test: {'epoch': 48, 'time_epoch': 4.16869, 'loss': 0.11699535, 'lr': 0, 'params': 451793, 'time_iter': 0.03232, 'accuracy': 0.96985, 'precision': 0.56522, 'recall': 0.2, 'f1': 0.29545, 'auc': 0.76087}
2025-08-16 08:45:58,370 - INFO - > Epoch 48: took 76.0s (avg 77.7s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:47:05,314 - INFO - train: {'epoch': 49, 'time_epoch': 66.86062, 'eta': 3445.9244, 'eta_hours': 0.9572, 'loss': 0.1084838, 'lr': 5.577e-05, 'params': 451793, 'time_iter': 0.06498, 'accuracy': 0.96863, 'precision': 0.68051, 'recall': 0.30601, 'f1': 0.42217, 'auc': 0.85613}
2025-08-16 08:47:09,427 - INFO - val: {'epoch': 49, 'time_epoch': 4.09178, 'loss': 0.0726344, 'lr': 0, 'params': 451793, 'time_iter': 0.03172, 'accuracy': 0.98225, 'precision': 0.58, 'recall': 0.35802, 'f1': 0.44275, 'auc': 0.79234}
2025-08-16 08:47:13,542 - INFO - test: {'epoch': 49, 'time_epoch': 4.0979, 'loss': 0.11677785, 'lr': 0, 'params': 451793, 'time_iter': 0.03177, 'accuracy': 0.96912, 'precision': 0.52308, 'recall': 0.26154, 'f1': 0.34872, 'auc': 0.77673}
2025-08-16 08:47:13,544 - INFO - > Epoch 49: took 75.2s (avg 77.6s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:48:19,194 - INFO - train: {'epoch': 50, 'time_epoch': 65.57089, 'eta': 3373.78959, 'eta_hours': 0.93716, 'loss': 0.10772536, 'lr': 5.413e-05, 'params': 451793, 'time_iter': 0.06372, 'accuracy': 0.9693, 'precision': 0.69138, 'recall': 0.32549, 'f1': 0.4426, 'auc': 0.85408}
2025-08-16 08:48:23,196 - INFO - val: {'epoch': 50, 'time_epoch': 3.98151, 'loss': 0.07496816, 'lr': 0, 'params': 451793, 'time_iter': 0.03086, 'accuracy': 0.98298, 'precision': 0.67742, 'recall': 0.25926, 'f1': 0.375, 'auc': 0.75407}
2025-08-16 08:48:27,308 - INFO - test: {'epoch': 50, 'time_epoch': 4.09468, 'loss': 0.11567659, 'lr': 0, 'params': 451793, 'time_iter': 0.03174, 'accuracy': 0.97009, 'precision': 0.55738, 'recall': 0.26154, 'f1': 0.35602, 'auc': 0.7615}
2025-08-16 08:48:27,310 - INFO - > Epoch 50: took 73.8s (avg 77.5s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:49:34,047 - INFO - train: {'epoch': 51, 'time_epoch': 66.65507, 'eta': 3302.90803, 'eta_hours': 0.91747, 'loss': 0.1067439, 'lr': 5.248e-05, 'params': 451793, 'time_iter': 0.06478, 'accuracy': 0.97006, 'precision': 0.71111, 'recall': 0.33766, 'f1': 0.4579, 'auc': 0.85876}
2025-08-16 08:49:38,346 - INFO - val: {'epoch': 51, 'time_epoch': 4.27609, 'loss': 0.07026867, 'lr': 0, 'params': 451793, 'time_iter': 0.03315, 'accuracy': 0.98347, 'precision': 0.6383, 'recall': 0.37037, 'f1': 0.46875, 'auc': 0.79304}
2025-08-16 08:49:42,649 - INFO - test: {'epoch': 51, 'time_epoch': 4.28554, 'loss': 0.11596768, 'lr': 0, 'params': 451793, 'time_iter': 0.03322, 'accuracy': 0.96961, 'precision': 0.53333, 'recall': 0.30769, 'f1': 0.39024, 'auc': 0.77192}
2025-08-16 08:49:42,652 - INFO - > Epoch 51: took 75.3s (avg 77.5s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:50:48,977 - INFO - train: {'epoch': 52, 'time_epoch': 66.24858, 'eta': 3231.82548, 'eta_hours': 0.89773, 'loss': 0.10627436, 'lr': 5.083e-05, 'params': 451793, 'time_iter': 0.06438, 'accuracy': 0.96967, 'precision': 0.70383, 'recall': 0.32792, 'f1': 0.4474, 'auc': 0.85951}
2025-08-16 08:50:53,129 - INFO - val: {'epoch': 52, 'time_epoch': 4.13155, 'loss': 0.07280374, 'lr': 0, 'params': 451793, 'time_iter': 0.03203, 'accuracy': 0.98177, 'precision': 0.57895, 'recall': 0.2716, 'f1': 0.36975, 'auc': 0.77813}
2025-08-16 08:50:57,284 - INFO - test: {'epoch': 52, 'time_epoch': 4.13753, 'loss': 0.11929944, 'lr': 0, 'params': 451793, 'time_iter': 0.03207, 'accuracy': 0.97107, 'precision': 0.59649, 'recall': 0.26154, 'f1': 0.36364, 'auc': 0.75694}
2025-08-16 08:50:57,286 - INFO - > Epoch 52: took 74.6s (avg 77.4s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:52:04,963 - INFO - train: {'epoch': 53, 'time_epoch': 67.59371, 'eta': 3162.06781, 'eta_hours': 0.87835, 'loss': 0.10711423, 'lr': 4.917e-05, 'params': 451793, 'time_iter': 0.06569, 'accuracy': 0.96924, 'precision': 0.689, 'recall': 0.32549, 'f1': 0.44212, 'auc': 0.86076}
2025-08-16 08:52:09,111 - INFO - val: {'epoch': 53, 'time_epoch': 4.12687, 'loss': 0.07361881, 'lr': 0, 'params': 451793, 'time_iter': 0.03199, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.76033}
2025-08-16 08:52:13,280 - INFO - test: {'epoch': 53, 'time_epoch': 4.15132, 'loss': 0.11922945, 'lr': 0, 'params': 451793, 'time_iter': 0.03218, 'accuracy': 0.96961, 'precision': 0.55102, 'recall': 0.20769, 'f1': 0.30168, 'auc': 0.76072}
2025-08-16 08:52:13,282 - INFO - > Epoch 53: took 76.0s (avg 77.4s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:53:20,076 - INFO - train: {'epoch': 54, 'time_epoch': 66.67835, 'eta': 3091.63991, 'eta_hours': 0.85879, 'loss': 0.10609989, 'lr': 4.752e-05, 'params': 451793, 'time_iter': 0.0648, 'accuracy': 0.96927, 'precision': 0.68697, 'recall': 0.32955, 'f1': 0.44542, 'auc': 0.86442}
2025-08-16 08:53:24,255 - INFO - val: {'epoch': 54, 'time_epoch': 4.15761, 'loss': 0.07301849, 'lr': 0, 'params': 451793, 'time_iter': 0.03223, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.77557}
2025-08-16 08:53:28,431 - INFO - test: {'epoch': 54, 'time_epoch': 4.15884, 'loss': 0.1176036, 'lr': 0, 'params': 451793, 'time_iter': 0.03224, 'accuracy': 0.97058, 'precision': 0.6, 'recall': 0.20769, 'f1': 0.30857, 'auc': 0.75641}
2025-08-16 08:53:28,433 - INFO - > Epoch 54: took 75.2s (avg 77.4s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:54:37,009 - INFO - train: {'epoch': 55, 'time_epoch': 68.48517, 'eta': 3022.76556, 'eta_hours': 0.83966, 'loss': 0.10543977, 'lr': 4.587e-05, 'params': 451793, 'time_iter': 0.06656, 'accuracy': 0.96921, 'precision': 0.68342, 'recall': 0.33117, 'f1': 0.44615, 'auc': 0.86943}
2025-08-16 08:54:41,311 - INFO - val: {'epoch': 55, 'time_epoch': 4.27689, 'loss': 0.07105307, 'lr': 0, 'params': 451793, 'time_iter': 0.03315, 'accuracy': 0.98298, 'precision': 0.68966, 'recall': 0.24691, 'f1': 0.36364, 'auc': 0.79851}
2025-08-16 08:54:45,555 - INFO - test: {'epoch': 55, 'time_epoch': 4.22636, 'loss': 0.12058763, 'lr': 0, 'params': 451793, 'time_iter': 0.03276, 'accuracy': 0.97107, 'precision': 0.65714, 'recall': 0.17692, 'f1': 0.27879, 'auc': 0.75842}
2025-08-16 08:54:45,558 - INFO - > Epoch 55: took 77.1s (avg 77.4s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:55:53,799 - INFO - train: {'epoch': 56, 'time_epoch': 68.15914, 'eta': 2953.65892, 'eta_hours': 0.82046, 'loss': 0.10496711, 'lr': 4.423e-05, 'params': 451793, 'time_iter': 0.06624, 'accuracy': 0.96994, 'precision': 0.70489, 'recall': 0.33929, 'f1': 0.45808, 'auc': 0.86382}
2025-08-16 08:55:57,854 - INFO - val: {'epoch': 56, 'time_epoch': 4.03278, 'loss': 0.0722281, 'lr': 0, 'params': 451793, 'time_iter': 0.03126, 'accuracy': 0.98249, 'precision': 0.63636, 'recall': 0.25926, 'f1': 0.36842, 'auc': 0.77889}
2025-08-16 08:56:01,908 - INFO - test: {'epoch': 56, 'time_epoch': 4.03714, 'loss': 0.11840943, 'lr': 0, 'params': 451793, 'time_iter': 0.0313, 'accuracy': 0.97204, 'precision': 0.66667, 'recall': 0.23077, 'f1': 0.34286, 'auc': 0.76385}
2025-08-16 08:56:01,911 - INFO - > Epoch 56: took 76.4s (avg 77.3s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:57:08,265 - INFO - train: {'epoch': 57, 'time_epoch': 66.27121, 'eta': 2883.21782, 'eta_hours': 0.80089, 'loss': 0.1053223, 'lr': 4.259e-05, 'params': 451793, 'time_iter': 0.0644, 'accuracy': 0.97003, 'precision': 0.71207, 'recall': 0.33523, 'f1': 0.45585, 'auc': 0.85958}
2025-08-16 08:57:12,448 - INFO - val: {'epoch': 57, 'time_epoch': 4.16227, 'loss': 0.07204303, 'lr': 0, 'params': 451793, 'time_iter': 0.03227, 'accuracy': 0.98201, 'precision': 0.6, 'recall': 0.25926, 'f1': 0.36207, 'auc': 0.78993}
2025-08-16 08:57:16,692 - INFO - test: {'epoch': 57, 'time_epoch': 4.2266, 'loss': 0.11625384, 'lr': 0, 'params': 451793, 'time_iter': 0.03276, 'accuracy': 0.97058, 'precision': 0.56716, 'recall': 0.29231, 'f1': 0.38579, 'auc': 0.76945}
2025-08-16 08:57:16,694 - INFO - > Epoch 57: took 74.8s (avg 77.3s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:58:23,978 - INFO - train: {'epoch': 58, 'time_epoch': 67.19832, 'eta': 2813.56234, 'eta_hours': 0.78155, 'loss': 0.10440202, 'lr': 4.096e-05, 'params': 451793, 'time_iter': 0.0653, 'accuracy': 0.97034, 'precision': 0.71477, 'recall': 0.34578, 'f1': 0.46608, 'auc': 0.86535}
2025-08-16 08:58:28,321 - INFO - val: {'epoch': 58, 'time_epoch': 4.31906, 'loss': 0.07069776, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.98322, 'precision': 0.7, 'recall': 0.25926, 'f1': 0.37838, 'auc': 0.76746}
2025-08-16 08:58:32,655 - INFO - test: {'epoch': 58, 'time_epoch': 4.31529, 'loss': 0.11459465, 'lr': 0, 'params': 451793, 'time_iter': 0.03345, 'accuracy': 0.97228, 'precision': 0.63793, 'recall': 0.28462, 'f1': 0.39362, 'auc': 0.75685}
2025-08-16 08:58:32,657 - INFO - > Epoch 58: took 76.0s (avg 77.3s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 08:59:40,864 - INFO - train: {'epoch': 59, 'time_epoch': 68.11734, 'eta': 2744.60145, 'eta_hours': 0.76239, 'loss': 0.10292087, 'lr': 3.934e-05, 'params': 451793, 'time_iter': 0.0662, 'accuracy': 0.9707, 'precision': 0.72408, 'recall': 0.35146, 'f1': 0.47322, 'auc': 0.87088}
2025-08-16 08:59:45,071 - INFO - val: {'epoch': 59, 'time_epoch': 4.18345, 'loss': 0.07268715, 'lr': 0, 'params': 451793, 'time_iter': 0.03243, 'accuracy': 0.98347, 'precision': 0.70968, 'recall': 0.2716, 'f1': 0.39286, 'auc': 0.75684}
2025-08-16 08:59:49,218 - INFO - test: {'epoch': 59, 'time_epoch': 4.12456, 'loss': 0.11920665, 'lr': 0, 'params': 451793, 'time_iter': 0.03197, 'accuracy': 0.96961, 'precision': 0.55319, 'recall': 0.2, 'f1': 0.29379, 'auc': 0.76448}
2025-08-16 08:59:49,221 - INFO - > Epoch 59: took 76.6s (avg 77.3s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:00:54,832 - INFO - train: {'epoch': 60, 'time_epoch': 65.51787, 'eta': 2674.00626, 'eta_hours': 0.74278, 'loss': 0.10407069, 'lr': 3.773e-05, 'params': 451793, 'time_iter': 0.06367, 'accuracy': 0.96988, 'precision': 0.69983, 'recall': 0.34253, 'f1': 0.45995, 'auc': 0.87194}
2025-08-16 09:00:59,039 - INFO - val: {'epoch': 60, 'time_epoch': 4.18435, 'loss': 0.07276084, 'lr': 0, 'params': 451793, 'time_iter': 0.03244, 'accuracy': 0.98201, 'precision': 0.62963, 'recall': 0.20988, 'f1': 0.31481, 'auc': 0.76983}
2025-08-16 09:01:03,253 - INFO - test: {'epoch': 60, 'time_epoch': 4.19689, 'loss': 0.11688028, 'lr': 0, 'params': 451793, 'time_iter': 0.03253, 'accuracy': 0.97131, 'precision': 0.64286, 'recall': 0.20769, 'f1': 0.31395, 'auc': 0.76798}
2025-08-16 09:01:03,256 - INFO - > Epoch 60: took 74.0s (avg 77.2s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:02:10,495 - INFO - train: {'epoch': 61, 'time_epoch': 67.15592, 'eta': 2604.57882, 'eta_hours': 0.72349, 'loss': 0.10360448, 'lr': 3.613e-05, 'params': 451793, 'time_iter': 0.06526, 'accuracy': 0.97082, 'precision': 0.72006, 'recall': 0.3612, 'f1': 0.48108, 'auc': 0.8664}
2025-08-16 09:02:14,850 - INFO - val: {'epoch': 61, 'time_epoch': 4.32996, 'loss': 0.07213561, 'lr': 0, 'params': 451793, 'time_iter': 0.03357, 'accuracy': 0.98274, 'precision': 0.65625, 'recall': 0.25926, 'f1': 0.37168, 'auc': 0.78177}
2025-08-16 09:02:19,185 - INFO - test: {'epoch': 61, 'time_epoch': 4.31567, 'loss': 0.12203625, 'lr': 0, 'params': 451793, 'time_iter': 0.03345, 'accuracy': 0.96985, 'precision': 0.58333, 'recall': 0.16154, 'f1': 0.25301, 'auc': 0.75173}
2025-08-16 09:02:19,188 - INFO - > Epoch 61: took 75.9s (avg 77.2s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:03:26,781 - INFO - train: {'epoch': 62, 'time_epoch': 67.50948, 'eta': 2535.43114, 'eta_hours': 0.70429, 'loss': 0.10255907, 'lr': 3.455e-05, 'params': 451793, 'time_iter': 0.06561, 'accuracy': 0.97094, 'precision': 0.72476, 'recall': 0.3612, 'f1': 0.48212, 'auc': 0.87358}
2025-08-16 09:03:31,080 - INFO - val: {'epoch': 62, 'time_epoch': 4.27552, 'loss': 0.0722452, 'lr': 0, 'params': 451793, 'time_iter': 0.03314, 'accuracy': 0.98079, 'precision': 0.52273, 'recall': 0.28395, 'f1': 0.368, 'auc': 0.79046}
2025-08-16 09:03:35,385 - INFO - test: {'epoch': 62, 'time_epoch': 4.2861, 'loss': 0.11896677, 'lr': 0, 'params': 451793, 'time_iter': 0.03323, 'accuracy': 0.96766, 'precision': 0.47692, 'recall': 0.23846, 'f1': 0.31795, 'auc': 0.76733}
2025-08-16 09:03:35,387 - INFO - > Epoch 62: took 76.2s (avg 77.2s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:04:42,880 - INFO - train: {'epoch': 63, 'time_epoch': 67.40872, 'eta': 2466.27797, 'eta_hours': 0.68508, 'loss': 0.10202331, 'lr': 3.299e-05, 'params': 451793, 'time_iter': 0.06551, 'accuracy': 0.97113, 'precision': 0.72524, 'recall': 0.36851, 'f1': 0.4887, 'auc': 0.87759}
2025-08-16 09:04:47,096 - INFO - val: {'epoch': 63, 'time_epoch': 4.19397, 'loss': 0.07045513, 'lr': 0, 'params': 451793, 'time_iter': 0.03251, 'accuracy': 0.98201, 'precision': 0.6, 'recall': 0.25926, 'f1': 0.36207, 'auc': 0.79828}
2025-08-16 09:04:51,297 - INFO - test: {'epoch': 63, 'time_epoch': 4.1836, 'loss': 0.11988338, 'lr': 0, 'params': 451793, 'time_iter': 0.03243, 'accuracy': 0.96985, 'precision': 0.54545, 'recall': 0.27692, 'f1': 0.36735, 'auc': 0.75739}
2025-08-16 09:04:51,299 - INFO - > Epoch 63: took 75.9s (avg 77.2s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:05:58,563 - INFO - train: {'epoch': 64, 'time_epoch': 67.18496, 'eta': 2397.05799, 'eta_hours': 0.66585, 'loss': 0.10292774, 'lr': 3.144e-05, 'params': 451793, 'time_iter': 0.06529, 'accuracy': 0.97067, 'precision': 0.72513, 'recall': 0.34903, 'f1': 0.47123, 'auc': 0.87329}
2025-08-16 09:06:02,735 - INFO - val: {'epoch': 64, 'time_epoch': 4.1489, 'loss': 0.07085383, 'lr': 0, 'params': 451793, 'time_iter': 0.03216, 'accuracy': 0.98274, 'precision': 0.63158, 'recall': 0.2963, 'f1': 0.40336, 'auc': 0.79535}
2025-08-16 09:06:06,857 - INFO - test: {'epoch': 64, 'time_epoch': 4.10418, 'loss': 0.1188455, 'lr': 0, 'params': 451793, 'time_iter': 0.03182, 'accuracy': 0.97058, 'precision': 0.56522, 'recall': 0.3, 'f1': 0.39196, 'auc': 0.75922}
2025-08-16 09:06:06,860 - INFO - > Epoch 64: took 75.6s (avg 77.1s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:07:12,894 - INFO - train: {'epoch': 65, 'time_epoch': 65.9474, 'eta': 2327.26215, 'eta_hours': 0.64646, 'loss': 0.10253533, 'lr': 2.992e-05, 'params': 451793, 'time_iter': 0.06409, 'accuracy': 0.9704, 'precision': 0.71429, 'recall': 0.34903, 'f1': 0.46892, 'auc': 0.87443}
2025-08-16 09:07:17,195 - INFO - val: {'epoch': 65, 'time_epoch': 4.2757, 'loss': 0.07094547, 'lr': 0, 'params': 451793, 'time_iter': 0.03314, 'accuracy': 0.98177, 'precision': 0.57143, 'recall': 0.2963, 'f1': 0.39024, 'auc': 0.80362}
2025-08-16 09:07:21,474 - INFO - test: {'epoch': 65, 'time_epoch': 4.26087, 'loss': 0.12095503, 'lr': 0, 'params': 451793, 'time_iter': 0.03303, 'accuracy': 0.96888, 'precision': 0.51562, 'recall': 0.25385, 'f1': 0.34021, 'auc': 0.76767}
2025-08-16 09:07:21,477 - INFO - > Epoch 65: took 74.6s (avg 77.1s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:08:29,282 - INFO - train: {'epoch': 66, 'time_epoch': 67.71811, 'eta': 2258.45333, 'eta_hours': 0.62735, 'loss': 0.10145755, 'lr': 2.841e-05, 'params': 451793, 'time_iter': 0.06581, 'accuracy': 0.97146, 'precision': 0.73899, 'recall': 0.36769, 'f1': 0.49106, 'auc': 0.87725}
2025-08-16 09:08:33,574 - INFO - val: {'epoch': 66, 'time_epoch': 4.26959, 'loss': 0.07336628, 'lr': 0, 'params': 451793, 'time_iter': 0.0331, 'accuracy': 0.98152, 'precision': 0.54902, 'recall': 0.34568, 'f1': 0.42424, 'auc': 0.79283}
2025-08-16 09:08:37,865 - INFO - test: {'epoch': 66, 'time_epoch': 4.27224, 'loss': 0.12203977, 'lr': 0, 'params': 451793, 'time_iter': 0.03312, 'accuracy': 0.96596, 'precision': 0.44792, 'recall': 0.33077, 'f1': 0.38053, 'auc': 0.77314}
2025-08-16 09:08:37,868 - INFO - > Epoch 66: took 76.4s (avg 77.1s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:09:45,426 - INFO - train: {'epoch': 67, 'time_epoch': 67.47364, 'eta': 2189.56155, 'eta_hours': 0.60821, 'loss': 0.10172554, 'lr': 2.693e-05, 'params': 451793, 'time_iter': 0.06557, 'accuracy': 0.971, 'precision': 0.72638, 'recall': 0.36201, 'f1': 0.48321, 'auc': 0.87369}
2025-08-16 09:09:49,809 - INFO - val: {'epoch': 67, 'time_epoch': 4.33712, 'loss': 0.070032, 'lr': 0, 'params': 451793, 'time_iter': 0.03362, 'accuracy': 0.98347, 'precision': 0.66667, 'recall': 0.32099, 'f1': 0.43333, 'auc': 0.77585}
2025-08-16 09:09:54,197 - INFO - test: {'epoch': 67, 'time_epoch': 4.34373, 'loss': 0.11705576, 'lr': 0, 'params': 451793, 'time_iter': 0.03367, 'accuracy': 0.97107, 'precision': 0.64865, 'recall': 0.18462, 'f1': 0.28743, 'auc': 0.76198}
2025-08-16 09:09:54,200 - INFO - > Epoch 67: took 76.3s (avg 77.1s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:11:02,648 - INFO - train: {'epoch': 68, 'time_epoch': 68.35951, 'eta': 2121.10887, 'eta_hours': 0.5892, 'loss': 0.10211061, 'lr': 2.548e-05, 'params': 451793, 'time_iter': 0.06643, 'accuracy': 0.97082, 'precision': 0.72896, 'recall': 0.35146, 'f1': 0.47426, 'auc': 0.8759}
2025-08-16 09:11:06,944 - INFO - val: {'epoch': 68, 'time_epoch': 4.2708, 'loss': 0.0714626, 'lr': 0, 'params': 451793, 'time_iter': 0.03311, 'accuracy': 0.98249, 'precision': 0.64516, 'recall': 0.24691, 'f1': 0.35714, 'auc': 0.78247}
2025-08-16 09:11:11,218 - INFO - test: {'epoch': 68, 'time_epoch': 4.25564, 'loss': 0.1209477, 'lr': 0, 'params': 451793, 'time_iter': 0.03299, 'accuracy': 0.97082, 'precision': 0.61905, 'recall': 0.2, 'f1': 0.30233, 'auc': 0.75536}
2025-08-16 09:11:11,221 - INFO - > Epoch 68: took 77.0s (avg 77.1s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:12:18,202 - INFO - train: {'epoch': 69, 'time_epoch': 66.89666, 'eta': 2052.03191, 'eta_hours': 0.57001, 'loss': 0.10088946, 'lr': 2.405e-05, 'params': 451793, 'time_iter': 0.06501, 'accuracy': 0.97216, 'precision': 0.76962, 'recall': 0.36607, 'f1': 0.49615, 'auc': 0.87779}
2025-08-16 09:12:22,503 - INFO - val: {'epoch': 69, 'time_epoch': 4.28008, 'loss': 0.0727783, 'lr': 0, 'params': 451793, 'time_iter': 0.03318, 'accuracy': 0.98225, 'precision': 0.6, 'recall': 0.2963, 'f1': 0.39669, 'auc': 0.7651}
2025-08-16 09:12:26,796 - INFO - test: {'epoch': 69, 'time_epoch': 4.27461, 'loss': 0.12117339, 'lr': 0, 'params': 451793, 'time_iter': 0.03314, 'accuracy': 0.96864, 'precision': 0.5082, 'recall': 0.23846, 'f1': 0.32461, 'auc': 0.76151}
2025-08-16 09:12:26,799 - INFO - > Epoch 69: took 75.6s (avg 77.1s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:13:34,120 - INFO - train: {'epoch': 70, 'time_epoch': 67.23361, 'eta': 1983.154, 'eta_hours': 0.55088, 'loss': 0.10062287, 'lr': 2.265e-05, 'params': 451793, 'time_iter': 0.06534, 'accuracy': 0.97149, 'precision': 0.73633, 'recall': 0.37175, 'f1': 0.49407, 'auc': 0.88224}
2025-08-16 09:13:38,263 - INFO - val: {'epoch': 70, 'time_epoch': 4.1224, 'loss': 0.07184381, 'lr': 0, 'params': 451793, 'time_iter': 0.03196, 'accuracy': 0.98201, 'precision': 0.60606, 'recall': 0.24691, 'f1': 0.35088, 'auc': 0.77798}
2025-08-16 09:13:42,393 - INFO - test: {'epoch': 70, 'time_epoch': 4.11391, 'loss': 0.11736813, 'lr': 0, 'params': 451793, 'time_iter': 0.03189, 'accuracy': 0.97131, 'precision': 0.625, 'recall': 0.23077, 'f1': 0.33708, 'auc': 0.76531}
2025-08-16 09:13:42,396 - INFO - > Epoch 70: took 75.6s (avg 77.0s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:14:49,676 - INFO - train: {'epoch': 71, 'time_epoch': 67.19526, 'eta': 1914.30685, 'eta_hours': 0.53175, 'loss': 0.10038498, 'lr': 2.128e-05, 'params': 451793, 'time_iter': 0.0653, 'accuracy': 0.97149, 'precision': 0.7371, 'recall': 0.37094, 'f1': 0.49352, 'auc': 0.88027}
2025-08-16 09:14:53,798 - INFO - val: {'epoch': 71, 'time_epoch': 4.10194, 'loss': 0.07338959, 'lr': 0, 'params': 451793, 'time_iter': 0.0318, 'accuracy': 0.98201, 'precision': 0.59459, 'recall': 0.2716, 'f1': 0.37288, 'auc': 0.75789}
2025-08-16 09:14:57,929 - INFO - test: {'epoch': 71, 'time_epoch': 4.11387, 'loss': 0.11816866, 'lr': 0, 'params': 451793, 'time_iter': 0.03189, 'accuracy': 0.97155, 'precision': 0.65854, 'recall': 0.20769, 'f1': 0.31579, 'auc': 0.76259}
2025-08-16 09:14:57,931 - INFO - > Epoch 71: took 75.5s (avg 77.0s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:16:05,495 - INFO - train: {'epoch': 72, 'time_epoch': 67.48196, 'eta': 1845.611, 'eta_hours': 0.51267, 'loss': 0.10037819, 'lr': 1.995e-05, 'params': 451793, 'time_iter': 0.06558, 'accuracy': 0.97097, 'precision': 0.72668, 'recall': 0.36039, 'f1': 0.48182, 'auc': 0.88357}
2025-08-16 09:16:09,608 - INFO - val: {'epoch': 72, 'time_epoch': 4.09177, 'loss': 0.07053431, 'lr': 0, 'params': 451793, 'time_iter': 0.03172, 'accuracy': 0.98322, 'precision': 0.73077, 'recall': 0.23457, 'f1': 0.35514, 'auc': 0.78399}
2025-08-16 09:16:13,755 - INFO - test: {'epoch': 72, 'time_epoch': 4.12979, 'loss': 0.1183778, 'lr': 0, 'params': 451793, 'time_iter': 0.03201, 'accuracy': 0.97155, 'precision': 0.69697, 'recall': 0.17692, 'f1': 0.28221, 'auc': 0.76343}
2025-08-16 09:16:13,757 - INFO - > Epoch 72: took 75.8s (avg 77.0s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:17:20,299 - INFO - train: {'epoch': 73, 'time_epoch': 66.46242, 'eta': 1776.58974, 'eta_hours': 0.4935, 'loss': 0.0996483, 'lr': 1.864e-05, 'params': 451793, 'time_iter': 0.06459, 'accuracy': 0.9714, 'precision': 0.72913, 'recall': 0.37581, 'f1': 0.49598, 'auc': 0.88242}
2025-08-16 09:17:24,492 - INFO - val: {'epoch': 73, 'time_epoch': 4.17227, 'loss': 0.07211138, 'lr': 0, 'params': 451793, 'time_iter': 0.03234, 'accuracy': 0.98347, 'precision': 0.68571, 'recall': 0.2963, 'f1': 0.41379, 'auc': 0.76199}
2025-08-16 09:17:28,768 - INFO - test: {'epoch': 73, 'time_epoch': 4.25832, 'loss': 0.12027169, 'lr': 0, 'params': 451793, 'time_iter': 0.03301, 'accuracy': 0.97155, 'precision': 0.65116, 'recall': 0.21538, 'f1': 0.3237, 'auc': 0.75978}
2025-08-16 09:17:28,770 - INFO - > Epoch 73: took 75.0s (avg 77.0s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:18:36,271 - INFO - train: {'epoch': 74, 'time_epoch': 67.41405, 'eta': 1707.95392, 'eta_hours': 0.47443, 'loss': 0.10076311, 'lr': 1.737e-05, 'params': 451793, 'time_iter': 0.06551, 'accuracy': 0.97158, 'precision': 0.73534, 'recall': 0.37662, 'f1': 0.49812, 'auc': 0.8769}
2025-08-16 09:18:40,500 - INFO - val: {'epoch': 74, 'time_epoch': 4.20403, 'loss': 0.07171998, 'lr': 0, 'params': 451793, 'time_iter': 0.03259, 'accuracy': 0.98249, 'precision': 0.65517, 'recall': 0.23457, 'f1': 0.34545, 'auc': 0.78057}
2025-08-16 09:18:44,690 - INFO - test: {'epoch': 74, 'time_epoch': 4.17136, 'loss': 0.11776699, 'lr': 0, 'params': 451793, 'time_iter': 0.03234, 'accuracy': 0.97107, 'precision': 0.64865, 'recall': 0.18462, 'f1': 0.28743, 'auc': 0.7518}
2025-08-16 09:18:44,693 - INFO - > Epoch 74: took 75.9s (avg 77.0s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:19:51,575 - INFO - train: {'epoch': 75, 'time_epoch': 66.79803, 'eta': 1639.15572, 'eta_hours': 0.45532, 'loss': 0.10059145, 'lr': 1.614e-05, 'params': 451793, 'time_iter': 0.06492, 'accuracy': 0.97149, 'precision': 0.71875, 'recall': 0.39205, 'f1': 0.50735, 'auc': 0.8783}
2025-08-16 09:19:55,793 - INFO - val: {'epoch': 75, 'time_epoch': 4.19411, 'loss': 0.07228275, 'lr': 0, 'params': 451793, 'time_iter': 0.03251, 'accuracy': 0.98274, 'precision': 0.66667, 'recall': 0.24691, 'f1': 0.36036, 'auc': 0.76752}
2025-08-16 09:20:00,019 - INFO - test: {'epoch': 75, 'time_epoch': 4.20879, 'loss': 0.12048111, 'lr': 0, 'params': 451793, 'time_iter': 0.03263, 'accuracy': 0.97107, 'precision': 0.67742, 'recall': 0.16154, 'f1': 0.26087, 'auc': 0.75394}
2025-08-16 09:20:00,022 - INFO - > Epoch 75: took 75.3s (avg 76.9s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:21:06,983 - INFO - train: {'epoch': 76, 'time_epoch': 66.88317, 'eta': 1570.43491, 'eta_hours': 0.43623, 'loss': 0.09933155, 'lr': 1.494e-05, 'params': 451793, 'time_iter': 0.065, 'accuracy': 0.97179, 'precision': 0.74837, 'recall': 0.37175, 'f1': 0.49675, 'auc': 0.8869}
2025-08-16 09:21:10,935 - INFO - val: {'epoch': 76, 'time_epoch': 3.93256, 'loss': 0.07216609, 'lr': 0, 'params': 451793, 'time_iter': 0.03048, 'accuracy': 0.98274, 'precision': 0.66667, 'recall': 0.24691, 'f1': 0.36036, 'auc': 0.77207}
2025-08-16 09:21:14,987 - INFO - test: {'epoch': 76, 'time_epoch': 4.03425, 'loss': 0.11957627, 'lr': 0, 'params': 451793, 'time_iter': 0.03127, 'accuracy': 0.96961, 'precision': 0.56098, 'recall': 0.17692, 'f1': 0.26901, 'auc': 0.75908}
2025-08-16 09:21:14,989 - INFO - > Epoch 76: took 75.0s (avg 76.9s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:22:22,031 - INFO - train: {'epoch': 77, 'time_epoch': 66.95492, 'eta': 1501.78145, 'eta_hours': 0.41716, 'loss': 0.10002851, 'lr': 1.378e-05, 'params': 451793, 'time_iter': 0.06507, 'accuracy': 0.97185, 'precision': 0.74598, 'recall': 0.37662, 'f1': 0.50054, 'auc': 0.87978}
2025-08-16 09:22:26,322 - INFO - val: {'epoch': 77, 'time_epoch': 4.26993, 'loss': 0.07147582, 'lr': 0, 'params': 451793, 'time_iter': 0.0331, 'accuracy': 0.98347, 'precision': 0.69697, 'recall': 0.28395, 'f1': 0.40351, 'auc': 0.77531}
2025-08-16 09:22:30,602 - INFO - test: {'epoch': 77, 'time_epoch': 4.26109, 'loss': 0.12078698, 'lr': 0, 'params': 451793, 'time_iter': 0.03303, 'accuracy': 0.97058, 'precision': 0.60465, 'recall': 0.2, 'f1': 0.30058, 'auc': 0.75782}
2025-08-16 09:22:30,604 - INFO - > Epoch 77: took 75.6s (avg 76.9s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:23:37,594 - INFO - train: {'epoch': 78, 'time_epoch': 66.91448, 'eta': 1433.16025, 'eta_hours': 0.3981, 'loss': 0.0997244, 'lr': 1.266e-05, 'params': 451793, 'time_iter': 0.06503, 'accuracy': 0.97085, 'precision': 0.7184, 'recall': 0.36445, 'f1': 0.48358, 'auc': 0.88248}
2025-08-16 09:23:41,724 - INFO - val: {'epoch': 78, 'time_epoch': 4.10822, 'loss': 0.07183833, 'lr': 0, 'params': 451793, 'time_iter': 0.03185, 'accuracy': 0.98249, 'precision': 0.64516, 'recall': 0.24691, 'f1': 0.35714, 'auc': 0.78309}
2025-08-16 09:23:45,876 - INFO - test: {'epoch': 78, 'time_epoch': 4.13515, 'loss': 0.12150529, 'lr': 0, 'params': 451793, 'time_iter': 0.03206, 'accuracy': 0.97009, 'precision': 0.5814, 'recall': 0.19231, 'f1': 0.28902, 'auc': 0.75985}
2025-08-16 09:23:45,879 - INFO - > Epoch 78: took 75.3s (avg 76.9s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:24:53,712 - INFO - train: {'epoch': 79, 'time_epoch': 67.7091, 'eta': 1364.78036, 'eta_hours': 0.37911, 'loss': 0.09932665, 'lr': 1.158e-05, 'params': 451793, 'time_iter': 0.0658, 'accuracy': 0.97137, 'precision': 0.73312, 'recall': 0.37013, 'f1': 0.49191, 'auc': 0.88783}
2025-08-16 09:24:58,031 - INFO - val: {'epoch': 79, 'time_epoch': 4.29769, 'loss': 0.07446466, 'lr': 0, 'params': 451793, 'time_iter': 0.03332, 'accuracy': 0.98128, 'precision': 0.54348, 'recall': 0.30864, 'f1': 0.3937, 'auc': 0.78206}
2025-08-16 09:25:02,387 - INFO - test: {'epoch': 79, 'time_epoch': 4.33784, 'loss': 0.12014889, 'lr': 0, 'params': 451793, 'time_iter': 0.03363, 'accuracy': 0.96888, 'precision': 0.51515, 'recall': 0.26154, 'f1': 0.34694, 'auc': 0.76408}
2025-08-16 09:25:02,389 - INFO - > Epoch 79: took 76.5s (avg 76.9s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:26:11,209 - INFO - train: {'epoch': 80, 'time_epoch': 68.73208, 'eta': 1296.657, 'eta_hours': 0.36018, 'loss': 0.09859171, 'lr': 1.054e-05, 'params': 451793, 'time_iter': 0.0668, 'accuracy': 0.97182, 'precision': 0.73498, 'recall': 0.38718, 'f1': 0.50718, 'auc': 0.88661}
2025-08-16 09:26:15,445 - INFO - val: {'epoch': 80, 'time_epoch': 4.21531, 'loss': 0.07196825, 'lr': 0, 'params': 451793, 'time_iter': 0.03268, 'accuracy': 0.98225, 'precision': 0.61111, 'recall': 0.2716, 'f1': 0.37607, 'auc': 0.79094}
2025-08-16 09:26:19,578 - INFO - test: {'epoch': 80, 'time_epoch': 4.11583, 'loss': 0.12111482, 'lr': 0, 'params': 451793, 'time_iter': 0.03191, 'accuracy': 0.97058, 'precision': 0.60465, 'recall': 0.2, 'f1': 0.30058, 'auc': 0.75866}
2025-08-16 09:26:19,580 - INFO - > Epoch 80: took 77.2s (avg 76.9s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:27:25,396 - INFO - train: {'epoch': 81, 'time_epoch': 65.73729, 'eta': 1227.8614, 'eta_hours': 0.34107, 'loss': 0.09705796, 'lr': 9.55e-06, 'params': 451793, 'time_iter': 0.06388, 'accuracy': 0.97255, 'precision': 0.74663, 'recall': 0.40422, 'f1': 0.52449, 'auc': 0.88993}
2025-08-16 09:27:29,357 - INFO - val: {'epoch': 81, 'time_epoch': 3.94098, 'loss': 0.07343174, 'lr': 0, 'params': 451793, 'time_iter': 0.03055, 'accuracy': 0.98201, 'precision': 0.59459, 'recall': 0.2716, 'f1': 0.37288, 'auc': 0.77443}
2025-08-16 09:27:33,310 - INFO - test: {'epoch': 81, 'time_epoch': 3.93647, 'loss': 0.12060956, 'lr': 0, 'params': 451793, 'time_iter': 0.03052, 'accuracy': 0.97107, 'precision': 0.60784, 'recall': 0.23846, 'f1': 0.34254, 'auc': 0.76028}
2025-08-16 09:27:33,312 - INFO - > Epoch 81: took 73.7s (avg 76.8s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:28:39,967 - INFO - train: {'epoch': 82, 'time_epoch': 66.57271, 'eta': 1159.3106, 'eta_hours': 0.32203, 'loss': 0.0992979, 'lr': 8.6e-06, 'params': 451793, 'time_iter': 0.0647, 'accuracy': 0.97106, 'precision': 0.71472, 'recall': 0.37825, 'f1': 0.49469, 'auc': 0.88569}
2025-08-16 09:28:44,072 - INFO - val: {'epoch': 82, 'time_epoch': 4.08539, 'loss': 0.07245163, 'lr': 0, 'params': 451793, 'time_iter': 0.03167, 'accuracy': 0.98249, 'precision': 0.64516, 'recall': 0.24691, 'f1': 0.35714, 'auc': 0.77871}
2025-08-16 09:28:48,145 - INFO - test: {'epoch': 82, 'time_epoch': 4.05585, 'loss': 0.12002639, 'lr': 0, 'params': 451793, 'time_iter': 0.03144, 'accuracy': 0.97155, 'precision': 0.68571, 'recall': 0.18462, 'f1': 0.29091, 'auc': 0.75402}
2025-08-16 09:28:48,147 - INFO - > Epoch 82: took 74.8s (avg 76.8s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:29:52,235 - INFO - train: {'epoch': 83, 'time_epoch': 64.00502, 'eta': 1090.31782, 'eta_hours': 0.30287, 'loss': 0.09758745, 'lr': 7.7e-06, 'params': 451793, 'time_iter': 0.0622, 'accuracy': 0.97179, 'precision': 0.74281, 'recall': 0.37744, 'f1': 0.50054, 'auc': 0.89128}
2025-08-16 09:29:56,459 - INFO - val: {'epoch': 83, 'time_epoch': 4.20208, 'loss': 0.07320754, 'lr': 0, 'params': 451793, 'time_iter': 0.03257, 'accuracy': 0.98274, 'precision': 0.66667, 'recall': 0.24691, 'f1': 0.36036, 'auc': 0.77143}
2025-08-16 09:30:00,702 - INFO - test: {'epoch': 83, 'time_epoch': 4.22488, 'loss': 0.12011097, 'lr': 0, 'params': 451793, 'time_iter': 0.03275, 'accuracy': 0.96961, 'precision': 0.55556, 'recall': 0.19231, 'f1': 0.28571, 'auc': 0.75796}
2025-08-16 09:30:00,704 - INFO - > Epoch 83: took 72.6s (avg 76.8s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:31:07,691 - INFO - train: {'epoch': 84, 'time_epoch': 66.90352, 'eta': 1021.9539, 'eta_hours': 0.28388, 'loss': 0.09729221, 'lr': 6.84e-06, 'params': 451793, 'time_iter': 0.06502, 'accuracy': 0.97231, 'precision': 0.75117, 'recall': 0.38961, 'f1': 0.51309, 'auc': 0.89067}
2025-08-16 09:31:11,725 - INFO - val: {'epoch': 84, 'time_epoch': 4.01271, 'loss': 0.07361105, 'lr': 0, 'params': 451793, 'time_iter': 0.03111, 'accuracy': 0.98249, 'precision': 0.62162, 'recall': 0.28395, 'f1': 0.38983, 'auc': 0.76979}
2025-08-16 09:31:15,775 - INFO - test: {'epoch': 84, 'time_epoch': 4.03298, 'loss': 0.12018444, 'lr': 0, 'params': 451793, 'time_iter': 0.03126, 'accuracy': 0.96937, 'precision': 0.53448, 'recall': 0.23846, 'f1': 0.32979, 'auc': 0.76088}
2025-08-16 09:31:15,777 - INFO - > Epoch 84: took 75.1s (avg 76.7s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:32:21,953 - INFO - train: {'epoch': 85, 'time_epoch': 66.09443, 'eta': 953.49222, 'eta_hours': 0.26486, 'loss': 0.0997358, 'lr': 6.03e-06, 'params': 451793, 'time_iter': 0.06423, 'accuracy': 0.97179, 'precision': 0.73602, 'recall': 0.38474, 'f1': 0.50533, 'auc': 0.8827}
2025-08-16 09:32:26,165 - INFO - val: {'epoch': 85, 'time_epoch': 4.18997, 'loss': 0.07211796, 'lr': 0, 'params': 451793, 'time_iter': 0.03248, 'accuracy': 0.98274, 'precision': 0.66667, 'recall': 0.24691, 'f1': 0.36036, 'auc': 0.76824}
2025-08-16 09:32:30,380 - INFO - test: {'epoch': 85, 'time_epoch': 4.19878, 'loss': 0.11876366, 'lr': 0, 'params': 451793, 'time_iter': 0.03255, 'accuracy': 0.97082, 'precision': 0.625, 'recall': 0.19231, 'f1': 0.29412, 'auc': 0.75655}
2025-08-16 09:32:30,382 - INFO - > Epoch 85: took 74.6s (avg 76.7s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:33:36,130 - INFO - train: {'epoch': 86, 'time_epoch': 65.66155, 'eta': 885.02029, 'eta_hours': 0.24584, 'loss': 0.09889128, 'lr': 5.26e-06, 'params': 451793, 'time_iter': 0.06381, 'accuracy': 0.97167, 'precision': 0.73148, 'recall': 0.38474, 'f1': 0.50426, 'auc': 0.88476}
2025-08-16 09:33:40,367 - INFO - val: {'epoch': 86, 'time_epoch': 4.21223, 'loss': 0.0725542, 'lr': 0, 'params': 451793, 'time_iter': 0.03265, 'accuracy': 0.98249, 'precision': 0.62857, 'recall': 0.2716, 'f1': 0.37931, 'auc': 0.77279}
2025-08-16 09:33:44,558 - INFO - test: {'epoch': 86, 'time_epoch': 4.1725, 'loss': 0.1194003, 'lr': 0, 'params': 451793, 'time_iter': 0.03234, 'accuracy': 0.97155, 'precision': 0.62264, 'recall': 0.25385, 'f1': 0.36066, 'auc': 0.76283}
2025-08-16 09:33:44,560 - INFO - > Epoch 86: took 74.2s (avg 76.7s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:34:51,002 - INFO - train: {'epoch': 87, 'time_epoch': 66.35801, 'eta': 816.70719, 'eta_hours': 0.22686, 'loss': 0.09887542, 'lr': 4.55e-06, 'params': 451793, 'time_iter': 0.06449, 'accuracy': 0.97176, 'precision': 0.74318, 'recall': 0.37581, 'f1': 0.49919, 'auc': 0.88214}
2025-08-16 09:34:55,264 - INFO - val: {'epoch': 87, 'time_epoch': 4.24068, 'loss': 0.07237426, 'lr': 0, 'params': 451793, 'time_iter': 0.03287, 'accuracy': 0.98249, 'precision': 0.62857, 'recall': 0.2716, 'f1': 0.37931, 'auc': 0.76897}
2025-08-16 09:34:59,495 - INFO - test: {'epoch': 87, 'time_epoch': 4.21361, 'loss': 0.12052449, 'lr': 0, 'params': 451793, 'time_iter': 0.03266, 'accuracy': 0.96912, 'precision': 0.52632, 'recall': 0.23077, 'f1': 0.32086, 'auc': 0.76074}
2025-08-16 09:34:59,497 - INFO - > Epoch 87: took 74.9s (avg 76.7s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:36:05,640 - INFO - train: {'epoch': 88, 'time_epoch': 66.06153, 'eta': 748.40139, 'eta_hours': 0.20789, 'loss': 0.09725826, 'lr': 3.89e-06, 'params': 451793, 'time_iter': 0.0642, 'accuracy': 0.97234, 'precision': 0.75314, 'recall': 0.3888, 'f1': 0.51285, 'auc': 0.88718}
2025-08-16 09:36:09,639 - INFO - val: {'epoch': 88, 'time_epoch': 3.97802, 'loss': 0.0731534, 'lr': 0, 'params': 451793, 'time_iter': 0.03084, 'accuracy': 0.98274, 'precision': 0.65625, 'recall': 0.25926, 'f1': 0.37168, 'auc': 0.76338}
2025-08-16 09:36:13,660 - INFO - test: {'epoch': 88, 'time_epoch': 4.00488, 'loss': 0.11997756, 'lr': 0, 'params': 451793, 'time_iter': 0.03105, 'accuracy': 0.96937, 'precision': 0.54, 'recall': 0.20769, 'f1': 0.3, 'auc': 0.75835}
2025-08-16 09:36:13,677 - INFO - > Epoch 88: took 74.2s (avg 76.6s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:37:20,348 - INFO - train: {'epoch': 89, 'time_epoch': 66.58252, 'eta': 680.20335, 'eta_hours': 0.18895, 'loss': 0.09780169, 'lr': 3.27e-06, 'params': 451793, 'time_iter': 0.06471, 'accuracy': 0.97116, 'precision': 0.7187, 'recall': 0.37744, 'f1': 0.49494, 'auc': 0.89249}
2025-08-16 09:37:24,628 - INFO - val: {'epoch': 89, 'time_epoch': 4.255, 'loss': 0.07394114, 'lr': 0, 'params': 451793, 'time_iter': 0.03298, 'accuracy': 0.98177, 'precision': 0.575, 'recall': 0.28395, 'f1': 0.38017, 'auc': 0.76213}
2025-08-16 09:37:28,819 - INFO - test: {'epoch': 89, 'time_epoch': 4.17366, 'loss': 0.11917982, 'lr': 0, 'params': 451793, 'time_iter': 0.03235, 'accuracy': 0.97082, 'precision': 0.58621, 'recall': 0.26154, 'f1': 0.3617, 'auc': 0.75737}
2025-08-16 09:37:28,822 - INFO - > Epoch 89: took 75.1s (avg 76.6s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:38:35,391 - INFO - train: {'epoch': 90, 'time_epoch': 66.48496, 'eta': 612.03116, 'eta_hours': 0.17001, 'loss': 0.0973074, 'lr': 2.71e-06, 'params': 451793, 'time_iter': 0.06461, 'accuracy': 0.97195, 'precision': 0.74103, 'recall': 0.38555, 'f1': 0.50721, 'auc': 0.88833}
2025-08-16 09:38:39,595 - INFO - val: {'epoch': 90, 'time_epoch': 4.18221, 'loss': 0.0721606, 'lr': 0, 'params': 451793, 'time_iter': 0.03242, 'accuracy': 0.98225, 'precision': 0.61765, 'recall': 0.25926, 'f1': 0.36522, 'auc': 0.7763}
2025-08-16 09:38:43,793 - INFO - test: {'epoch': 90, 'time_epoch': 4.18106, 'loss': 0.12201559, 'lr': 0, 'params': 451793, 'time_iter': 0.03241, 'accuracy': 0.96937, 'precision': 0.54348, 'recall': 0.19231, 'f1': 0.28409, 'auc': 0.75942}
2025-08-16 09:38:43,795 - INFO - > Epoch 90: took 75.0s (avg 76.6s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:39:49,279 - INFO - train: {'epoch': 91, 'time_epoch': 65.3944, 'eta': 543.80082, 'eta_hours': 0.15106, 'loss': 0.09758672, 'lr': 2.2e-06, 'params': 451793, 'time_iter': 0.06355, 'accuracy': 0.97261, 'precision': 0.76651, 'recall': 0.38636, 'f1': 0.51376, 'auc': 0.88897}
2025-08-16 09:39:53,431 - INFO - val: {'epoch': 91, 'time_epoch': 4.13072, 'loss': 0.07211854, 'lr': 0, 'params': 451793, 'time_iter': 0.03202, 'accuracy': 0.98298, 'precision': 0.67742, 'recall': 0.25926, 'f1': 0.375, 'auc': 0.7666}
2025-08-16 09:39:57,624 - INFO - test: {'epoch': 91, 'time_epoch': 4.17528, 'loss': 0.1208475, 'lr': 0, 'params': 451793, 'time_iter': 0.03237, 'accuracy': 0.97034, 'precision': 0.58333, 'recall': 0.21538, 'f1': 0.31461, 'auc': 0.76205}
2025-08-16 09:39:57,626 - INFO - > Epoch 91: took 73.8s (avg 76.6s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:41:04,569 - INFO - train: {'epoch': 92, 'time_epoch': 66.86155, 'eta': 475.74191, 'eta_hours': 0.13215, 'loss': 0.09622604, 'lr': 1.74e-06, 'params': 451793, 'time_iter': 0.06498, 'accuracy': 0.97258, 'precision': 0.76274, 'recall': 0.3888, 'f1': 0.51505, 'auc': 0.88796}
2025-08-16 09:41:08,557 - INFO - val: {'epoch': 92, 'time_epoch': 3.96776, 'loss': 0.07271861, 'lr': 0, 'params': 451793, 'time_iter': 0.03076, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.7704}
2025-08-16 09:41:12,538 - INFO - test: {'epoch': 92, 'time_epoch': 3.96525, 'loss': 0.12018189, 'lr': 0, 'params': 451793, 'time_iter': 0.03074, 'accuracy': 0.96985, 'precision': 0.56, 'recall': 0.21538, 'f1': 0.31111, 'auc': 0.76187}
2025-08-16 09:41:12,541 - INFO - > Epoch 92: took 74.9s (avg 76.6s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:42:18,186 - INFO - train: {'epoch': 93, 'time_epoch': 65.56126, 'eta': 407.62547, 'eta_hours': 0.11323, 'loss': 0.09832258, 'lr': 1.33e-06, 'params': 451793, 'time_iter': 0.06371, 'accuracy': 0.9721, 'precision': 0.74379, 'recall': 0.3888, 'f1': 0.51066, 'auc': 0.88403}
2025-08-16 09:42:22,390 - INFO - val: {'epoch': 93, 'time_epoch': 4.18298, 'loss': 0.07281328, 'lr': 0, 'params': 451793, 'time_iter': 0.03243, 'accuracy': 0.98274, 'precision': 0.65625, 'recall': 0.25926, 'f1': 0.37168, 'auc': 0.76783}
2025-08-16 09:42:26,615 - INFO - test: {'epoch': 93, 'time_epoch': 4.20748, 'loss': 0.12080978, 'lr': 0, 'params': 451793, 'time_iter': 0.03262, 'accuracy': 0.97009, 'precision': 0.58537, 'recall': 0.18462, 'f1': 0.2807, 'auc': 0.75825}
2025-08-16 09:42:26,617 - INFO - > Epoch 93: took 74.1s (avg 76.5s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:43:32,855 - INFO - train: {'epoch': 94, 'time_epoch': 66.15382, 'eta': 339.59401, 'eta_hours': 0.09433, 'loss': 0.0962774, 'lr': 9.8e-07, 'params': 451793, 'time_iter': 0.06429, 'accuracy': 0.97261, 'precision': 0.76145, 'recall': 0.39123, 'f1': 0.51689, 'auc': 0.89636}
2025-08-16 09:43:36,943 - INFO - val: {'epoch': 94, 'time_epoch': 4.06433, 'loss': 0.07343885, 'lr': 0, 'params': 451793, 'time_iter': 0.03151, 'accuracy': 0.98201, 'precision': 0.59459, 'recall': 0.2716, 'f1': 0.37288, 'auc': 0.7668}
2025-08-16 09:43:41,016 - INFO - test: {'epoch': 94, 'time_epoch': 4.05643, 'loss': 0.11985828, 'lr': 0, 'params': 451793, 'time_iter': 0.03145, 'accuracy': 0.97009, 'precision': 0.56604, 'recall': 0.23077, 'f1': 0.32787, 'auc': 0.75965}
2025-08-16 09:43:41,019 - INFO - > Epoch 94: took 74.4s (avg 76.5s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:44:46,202 - INFO - train: {'epoch': 95, 'time_epoch': 65.1011, 'eta': 271.5578, 'eta_hours': 0.07543, 'loss': 0.09724623, 'lr': 6.8e-07, 'params': 451793, 'time_iter': 0.06327, 'accuracy': 0.97182, 'precision': 0.74716, 'recall': 0.37419, 'f1': 0.49865, 'auc': 0.89505}
2025-08-16 09:44:50,180 - INFO - val: {'epoch': 95, 'time_epoch': 3.95835, 'loss': 0.07276601, 'lr': 0, 'params': 451793, 'time_iter': 0.03068, 'accuracy': 0.98249, 'precision': 0.63636, 'recall': 0.25926, 'f1': 0.36842, 'auc': 0.76947}
2025-08-16 09:44:54,163 - INFO - test: {'epoch': 95, 'time_epoch': 3.96675, 'loss': 0.12067117, 'lr': 0, 'params': 451793, 'time_iter': 0.03075, 'accuracy': 0.96961, 'precision': 0.55319, 'recall': 0.2, 'f1': 0.29379, 'auc': 0.75933}
2025-08-16 09:44:54,165 - INFO - > Epoch 95: took 73.1s (avg 76.5s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:45:59,691 - INFO - train: {'epoch': 96, 'time_epoch': 65.44038, 'eta': 203.59261, 'eta_hours': 0.05655, 'loss': 0.09770779, 'lr': 4.4e-07, 'params': 451793, 'time_iter': 0.0636, 'accuracy': 0.97225, 'precision': 0.75935, 'recall': 0.37906, 'f1': 0.50568, 'auc': 0.89233}
2025-08-16 09:46:03,883 - INFO - val: {'epoch': 96, 'time_epoch': 4.17097, 'loss': 0.0736665, 'lr': 0, 'params': 451793, 'time_iter': 0.03233, 'accuracy': 0.98177, 'precision': 0.57895, 'recall': 0.2716, 'f1': 0.36975, 'auc': 0.76988}
2025-08-16 09:46:08,010 - INFO - test: {'epoch': 96, 'time_epoch': 4.10967, 'loss': 0.12088887, 'lr': 0, 'params': 451793, 'time_iter': 0.03186, 'accuracy': 0.96937, 'precision': 0.53125, 'recall': 0.26154, 'f1': 0.35052, 'auc': 0.76381}
2025-08-16 09:46:08,012 - INFO - > Epoch 96: took 73.8s (avg 76.4s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:47:14,495 - INFO - train: {'epoch': 97, 'time_epoch': 66.39813, 'eta': 135.69848, 'eta_hours': 0.03769, 'loss': 0.09723231, 'lr': 2.5e-07, 'params': 451793, 'time_iter': 0.06453, 'accuracy': 0.97295, 'precision': 0.76887, 'recall': 0.39692, 'f1': 0.52355, 'auc': 0.88944}
2025-08-16 09:47:18,818 - INFO - val: {'epoch': 97, 'time_epoch': 4.29776, 'loss': 0.07233291, 'lr': 0, 'params': 451793, 'time_iter': 0.03332, 'accuracy': 0.98249, 'precision': 0.63636, 'recall': 0.25926, 'f1': 0.36842, 'auc': 0.77413}
2025-08-16 09:47:23,108 - INFO - test: {'epoch': 97, 'time_epoch': 4.27155, 'loss': 0.11990727, 'lr': 0, 'params': 451793, 'time_iter': 0.03311, 'accuracy': 0.97082, 'precision': 0.60417, 'recall': 0.22308, 'f1': 0.32584, 'auc': 0.76093}
2025-08-16 09:47:23,110 - INFO - > Epoch 97: took 75.1s (avg 76.4s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:48:26,808 - INFO - train: {'epoch': 98, 'time_epoch': 63.62291, 'eta': 67.80655, 'eta_hours': 0.01884, 'loss': 0.09672125, 'lr': 1.1e-07, 'params': 451793, 'time_iter': 0.06183, 'accuracy': 0.97261, 'precision': 0.759, 'recall': 0.39367, 'f1': 0.51844, 'auc': 0.89125}
2025-08-16 09:48:30,745 - INFO - val: {'epoch': 98, 'time_epoch': 3.91686, 'loss': 0.07249785, 'lr': 0, 'params': 451793, 'time_iter': 0.03036, 'accuracy': 0.98298, 'precision': 0.67742, 'recall': 0.25926, 'f1': 0.375, 'auc': 0.77013}
2025-08-16 09:48:34,695 - INFO - test: {'epoch': 98, 'time_epoch': 3.93391, 'loss': 0.1215277, 'lr': 0, 'params': 451793, 'time_iter': 0.0305, 'accuracy': 0.96961, 'precision': 0.55814, 'recall': 0.18462, 'f1': 0.27746, 'auc': 0.75988}
2025-08-16 09:48:34,697 - INFO - > Epoch 98: took 71.6s (avg 76.4s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:49:42,190 - INFO - train: {'epoch': 99, 'time_epoch': 67.40557, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.09676976, 'lr': 3e-08, 'params': 451793, 'time_iter': 0.06551, 'accuracy': 0.97201, 'precision': 0.74335, 'recall': 0.38555, 'f1': 0.50775, 'auc': 0.89161}
2025-08-16 09:49:46,202 - INFO - val: {'epoch': 99, 'time_epoch': 3.98985, 'loss': 0.07211874, 'lr': 0, 'params': 451793, 'time_iter': 0.03093, 'accuracy': 0.98298, 'precision': 0.7037, 'recall': 0.23457, 'f1': 0.35185, 'auc': 0.77827}
2025-08-16 09:49:50,194 - INFO - test: {'epoch': 99, 'time_epoch': 3.97495, 'loss': 0.12189627, 'lr': 0, 'params': 451793, 'time_iter': 0.03081, 'accuracy': 0.9718, 'precision': 0.68421, 'recall': 0.2, 'f1': 0.30952, 'auc': 0.75806}
2025-08-16 09:49:50,409 - INFO - > Epoch 99: took 75.5s (avg 76.4s) | Best so far: epoch 33	train_loss: 0.1148 train_auc: 0.8323	val_loss: 0.0711 val_auc: 0.8176	test_loss: 0.1210 test_auc: 0.7377
2025-08-16 09:49:50,410 - INFO - Avg time per epoch: 76.37s
2025-08-16 09:49:50,410 - INFO - Total train loop time: 2.12h
2025-08-16 09:49:50,491 - INFO - ============================================================
2025-08-16 09:49:50,491 - INFO - Starting PK-Explainer Analysis (Enhanced Version)
2025-08-16 09:49:50,491 - INFO - ============================================================
2025-08-16 09:49:50,491 - INFO - Dataset: ogbg-molhiv
2025-08-16 09:49:50,492 - INFO - Model type: VanillaModel
2025-08-16 09:49:50,492 - INFO - GNN types available: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 09:49:50,533 - INFO - Saved model state to results/molhiv/molhiv-Vanilla-47/model_for_ablation.pt
2025-08-16 09:49:50,533 - INFO - 
Performing ablation study...
2025-08-16 09:49:50,567 - INFO - Getting baseline performance...
2025-08-16 09:49:50,600 - WARNING - Could not extract GNN mapping from optimal weights, attempting to infer from layers...
2025-08-16 09:49:50,600 - INFO - Final GNN mapping: {}
2025-08-16 09:49:54,630 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.01531, 'loss': 0.12189626, 'lr': 0, 'params': 451793, 'time_iter': 0.03113, 'accuracy': 0.9718, 'precision': 0.68421, 'recall': 0.2, 'f1': 0.30952, 'auc': 0.75806}
2025-08-16 09:49:54,633 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:49:54,633 - INFO - Baseline auc: 0.7581
2025-08-16 09:49:58,741 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.05959, 'loss': 0.12085514, 'lr': 0, 'params': 451793, 'time_iter': 0.03147, 'accuracy': 0.9718, 'precision': 0.68421, 'recall': 0.2, 'f1': 0.30952, 'auc': 0.75765}
2025-08-16 09:49:58,743 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:49:58,743 - INFO - Layer 0 (Layer_0), Head 0: drop=0.0005
2025-08-16 09:50:02,968 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.17362, 'loss': 0.12026316, 'lr': 0, 'params': 451793, 'time_iter': 0.03235, 'accuracy': 0.97204, 'precision': 0.7027, 'recall': 0.2, 'f1': 0.31138, 'auc': 0.75986}
2025-08-16 09:50:02,970 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:50:02,970 - INFO - Layer 0 (Layer_0), Head 1: drop=-0.0024
2025-08-16 09:50:07,167 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.14904, 'loss': 0.12135829, 'lr': 0, 'params': 451793, 'time_iter': 0.03216, 'accuracy': 0.97155, 'precision': 0.65854, 'recall': 0.20769, 'f1': 0.31579, 'auc': 0.75677}
2025-08-16 09:50:07,169 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:50:07,169 - INFO - Layer 0 (Layer_0), Head 2: drop=0.0017
2025-08-16 09:50:11,353 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.13473, 'loss': 0.12149181, 'lr': 0, 'params': 451793, 'time_iter': 0.03205, 'accuracy': 0.97253, 'precision': 0.75758, 'recall': 0.19231, 'f1': 0.30675, 'auc': 0.75257}
2025-08-16 09:50:11,355 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:50:11,355 - INFO - Layer 0 (Layer_0), Head 3: drop=0.0072
2025-08-16 09:50:15,550 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.14676, 'loss': 0.12061306, 'lr': 0, 'params': 451793, 'time_iter': 0.03215, 'accuracy': 0.97155, 'precision': 0.66667, 'recall': 0.2, 'f1': 0.30769, 'auc': 0.76044}
2025-08-16 09:50:15,552 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:50:15,552 - INFO - Layer 1 (Layer_1), Head 0: drop=-0.0031
2025-08-16 09:50:19,744 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.14347, 'loss': 0.12352871, 'lr': 0, 'params': 451793, 'time_iter': 0.03212, 'accuracy': 0.97107, 'precision': 0.66667, 'recall': 0.16923, 'f1': 0.26994, 'auc': 0.75943}
2025-08-16 09:50:19,746 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:50:19,746 - INFO - Layer 1 (Layer_1), Head 1: drop=-0.0018
2025-08-16 09:50:23,929 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.13375, 'loss': 0.12231813, 'lr': 0, 'params': 451793, 'time_iter': 0.03204, 'accuracy': 0.9718, 'precision': 0.71875, 'recall': 0.17692, 'f1': 0.28395, 'auc': 0.75709}
2025-08-16 09:50:23,931 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:50:23,931 - INFO - Layer 1 (Layer_1), Head 2: drop=0.0013
2025-08-16 09:50:28,089 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.10996, 'loss': 0.12116664, 'lr': 0, 'params': 451793, 'time_iter': 0.03186, 'accuracy': 0.97253, 'precision': 0.71795, 'recall': 0.21538, 'f1': 0.33136, 'auc': 0.75909}
2025-08-16 09:50:28,092 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:50:28,092 - INFO - Layer 1 (Layer_1), Head 3: drop=-0.0014
2025-08-16 09:50:32,266 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.12552, 'loss': 0.12106023, 'lr': 0, 'params': 451793, 'time_iter': 0.03198, 'accuracy': 0.9718, 'precision': 0.68421, 'recall': 0.2, 'f1': 0.30952, 'auc': 0.75939}
2025-08-16 09:50:32,268 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:50:32,268 - INFO - Layer 2 (Layer_2), Head 0: drop=-0.0018
2025-08-16 09:50:36,443 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.12698, 'loss': 0.12355641, 'lr': 0, 'params': 451793, 'time_iter': 0.03199, 'accuracy': 0.97131, 'precision': 0.6875, 'recall': 0.16923, 'f1': 0.2716, 'auc': 0.75456}
2025-08-16 09:50:36,445 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:50:36,446 - INFO - Layer 2 (Layer_2), Head 1: drop=0.0046
2025-08-16 09:50:40,673 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.17915, 'loss': 0.12083596, 'lr': 0, 'params': 451793, 'time_iter': 0.0324, 'accuracy': 0.97204, 'precision': 0.71429, 'recall': 0.19231, 'f1': 0.30303, 'auc': 0.76023}
2025-08-16 09:50:40,676 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:50:40,676 - INFO - Layer 2 (Layer_2), Head 2: drop=-0.0029
2025-08-16 09:50:44,964 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23868, 'loss': 0.12047167, 'lr': 0, 'params': 451793, 'time_iter': 0.03286, 'accuracy': 0.97107, 'precision': 0.62791, 'recall': 0.20769, 'f1': 0.31214, 'auc': 0.75729}
2025-08-16 09:50:44,967 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:50:44,967 - INFO - Layer 2 (Layer_2), Head 3: drop=0.0010
2025-08-16 09:50:49,248 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23164, 'loss': 0.12187667, 'lr': 0, 'params': 451793, 'time_iter': 0.0328, 'accuracy': 0.97253, 'precision': 0.72973, 'recall': 0.20769, 'f1': 0.32335, 'auc': 0.75614}
2025-08-16 09:50:49,250 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:50:49,250 - INFO - Layer 3 (Layer_3), Head 0: drop=0.0025
2025-08-16 09:50:53,519 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21955, 'loss': 0.12060946, 'lr': 0, 'params': 451793, 'time_iter': 0.03271, 'accuracy': 0.97131, 'precision': 0.65, 'recall': 0.2, 'f1': 0.30588, 'auc': 0.76164}
2025-08-16 09:50:53,521 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:50:53,521 - INFO - Layer 3 (Layer_3), Head 1: drop=-0.0047
2025-08-16 09:50:57,811 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24055, 'loss': 0.12239725, 'lr': 0, 'params': 451793, 'time_iter': 0.03287, 'accuracy': 0.97131, 'precision': 0.66667, 'recall': 0.18462, 'f1': 0.28916, 'auc': 0.7553}
2025-08-16 09:50:57,813 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:50:57,813 - INFO - Layer 3 (Layer_3), Head 2: drop=0.0036
2025-08-16 09:51:02,093 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.231, 'loss': 0.12078892, 'lr': 0, 'params': 451793, 'time_iter': 0.0328, 'accuracy': 0.97204, 'precision': 0.71429, 'recall': 0.19231, 'f1': 0.30303, 'auc': 0.75819}
2025-08-16 09:51:02,095 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:51:02,095 - INFO - Layer 3 (Layer_3), Head 3: drop=-0.0002
2025-08-16 09:51:06,336 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.19139, 'loss': 0.11986952, 'lr': 0, 'params': 451793, 'time_iter': 0.03249, 'accuracy': 0.97155, 'precision': 0.66667, 'recall': 0.2, 'f1': 0.30769, 'auc': 0.76095}
2025-08-16 09:51:06,338 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:51:06,338 - INFO - Layer 4 (Layer_4), Head 0: drop=-0.0038
2025-08-16 09:51:10,621 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23305, 'loss': 0.12089479, 'lr': 0, 'params': 451793, 'time_iter': 0.03281, 'accuracy': 0.97155, 'precision': 0.66667, 'recall': 0.2, 'f1': 0.30769, 'auc': 0.76027}
2025-08-16 09:51:10,623 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:51:10,623 - INFO - Layer 4 (Layer_4), Head 1: drop=-0.0029
2025-08-16 09:51:14,882 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.20881, 'loss': 0.12204617, 'lr': 0, 'params': 451793, 'time_iter': 0.03263, 'accuracy': 0.9718, 'precision': 0.69444, 'recall': 0.19231, 'f1': 0.3012, 'auc': 0.76398}
2025-08-16 09:51:14,884 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:51:14,884 - INFO - Layer 4 (Layer_4), Head 2: drop=-0.0078
2025-08-16 09:51:19,104 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.17176, 'loss': 0.1220141, 'lr': 0, 'params': 451793, 'time_iter': 0.03234, 'accuracy': 0.97058, 'precision': 0.60976, 'recall': 0.19231, 'f1': 0.2924, 'auc': 0.75669}
2025-08-16 09:51:19,107 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:51:19,107 - INFO - Layer 4 (Layer_4), Head 3: drop=0.0018
2025-08-16 09:51:23,323 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.1666, 'loss': 0.12211008, 'lr': 0, 'params': 451793, 'time_iter': 0.0323, 'accuracy': 0.9718, 'precision': 0.69444, 'recall': 0.19231, 'f1': 0.3012, 'auc': 0.75634}
2025-08-16 09:51:23,325 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:51:23,325 - INFO - Layer 5 (Layer_5), Head 0: drop=0.0023
2025-08-16 09:51:27,586 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21125, 'loss': 0.12152325, 'lr': 0, 'params': 451793, 'time_iter': 0.03265, 'accuracy': 0.9718, 'precision': 0.70588, 'recall': 0.18462, 'f1': 0.29268, 'auc': 0.7573}
2025-08-16 09:51:27,588 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:51:27,588 - INFO - Layer 5 (Layer_5), Head 1: drop=0.0010
2025-08-16 09:51:31,855 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21684, 'loss': 0.1208091, 'lr': 0, 'params': 451793, 'time_iter': 0.03269, 'accuracy': 0.9718, 'precision': 0.69444, 'recall': 0.19231, 'f1': 0.3012, 'auc': 0.75779}
2025-08-16 09:51:31,856 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:51:31,857 - INFO - Layer 5 (Layer_5), Head 2: drop=0.0004
2025-08-16 09:51:36,153 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.24791, 'loss': 0.12221331, 'lr': 0, 'params': 451793, 'time_iter': 0.03293, 'accuracy': 0.97107, 'precision': 0.64103, 'recall': 0.19231, 'f1': 0.29586, 'auc': 0.76069}
2025-08-16 09:51:36,155 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:51:36,156 - INFO - Layer 5 (Layer_5), Head 3: drop=-0.0035
2025-08-16 09:51:40,455 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.25001, 'loss': 0.12213705, 'lr': 0, 'params': 451793, 'time_iter': 0.03295, 'accuracy': 0.97204, 'precision': 0.71429, 'recall': 0.19231, 'f1': 0.30303, 'auc': 0.75589}
2025-08-16 09:51:40,456 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:51:40,457 - INFO - Layer 6 (Layer_6), Head 0: drop=0.0029
2025-08-16 09:51:44,773 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.26698, 'loss': 0.12086958, 'lr': 0, 'params': 451793, 'time_iter': 0.03308, 'accuracy': 0.9718, 'precision': 0.68421, 'recall': 0.2, 'f1': 0.30952, 'auc': 0.75843}
2025-08-16 09:51:44,774 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:51:44,775 - INFO - Layer 6 (Layer_6), Head 1: drop=-0.0005
2025-08-16 09:51:49,064 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23996, 'loss': 0.12174987, 'lr': 0, 'params': 451793, 'time_iter': 0.03287, 'accuracy': 0.97155, 'precision': 0.70968, 'recall': 0.16923, 'f1': 0.27329, 'auc': 0.76218}
2025-08-16 09:51:49,066 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:51:49,066 - INFO - Layer 6 (Layer_6), Head 2: drop=-0.0054
2025-08-16 09:51:53,351 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23545, 'loss': 0.12054445, 'lr': 0, 'params': 451793, 'time_iter': 0.03283, 'accuracy': 0.97155, 'precision': 0.68571, 'recall': 0.18462, 'f1': 0.29091, 'auc': 0.7614}
2025-08-16 09:51:53,353 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:51:53,353 - INFO - Layer 6 (Layer_6), Head 3: drop=-0.0044
2025-08-16 09:51:57,628 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22598, 'loss': 0.1217453, 'lr': 0, 'params': 451793, 'time_iter': 0.03276, 'accuracy': 0.9718, 'precision': 0.70588, 'recall': 0.18462, 'f1': 0.29268, 'auc': 0.75716}
2025-08-16 09:51:57,630 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:51:57,630 - INFO - Layer 7 (Layer_7), Head 0: drop=0.0012
2025-08-16 09:52:01,943 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2644, 'loss': 0.12183842, 'lr': 0, 'params': 451793, 'time_iter': 0.03306, 'accuracy': 0.97155, 'precision': 0.67568, 'recall': 0.19231, 'f1': 0.2994, 'auc': 0.75691}
2025-08-16 09:52:01,946 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:52:01,946 - INFO - Layer 7 (Layer_7), Head 1: drop=0.0015
2025-08-16 09:52:06,222 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22717, 'loss': 0.12120204, 'lr': 0, 'params': 451793, 'time_iter': 0.03277, 'accuracy': 0.9718, 'precision': 0.71875, 'recall': 0.17692, 'f1': 0.28395, 'auc': 0.7553}
2025-08-16 09:52:06,224 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:52:06,224 - INFO - Layer 7 (Layer_7), Head 2: drop=0.0036
2025-08-16 09:52:10,504 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23111, 'loss': 0.12139938, 'lr': 0, 'params': 451793, 'time_iter': 0.0328, 'accuracy': 0.97204, 'precision': 0.7027, 'recall': 0.2, 'f1': 0.31138, 'auc': 0.75855}
2025-08-16 09:52:10,506 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:52:10,506 - INFO - Layer 7 (Layer_7), Head 3: drop=-0.0006
2025-08-16 09:52:14,794 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23864, 'loss': 0.12216649, 'lr': 0, 'params': 451793, 'time_iter': 0.03286, 'accuracy': 0.9718, 'precision': 0.69444, 'recall': 0.19231, 'f1': 0.3012, 'auc': 0.75732}
2025-08-16 09:52:14,796 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:52:14,796 - INFO - Layer 8 (Layer_8), Head 0: drop=0.0010
2025-08-16 09:52:19,080 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23392, 'loss': 0.12172876, 'lr': 0, 'params': 451793, 'time_iter': 0.03282, 'accuracy': 0.97155, 'precision': 0.69697, 'recall': 0.17692, 'f1': 0.28221, 'auc': 0.75808}
2025-08-16 09:52:19,082 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:52:19,082 - INFO - Layer 8 (Layer_8), Head 1: drop=-0.0000
2025-08-16 09:52:23,367 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23537, 'loss': 0.12195311, 'lr': 0, 'params': 451793, 'time_iter': 0.03283, 'accuracy': 0.97155, 'precision': 0.69697, 'recall': 0.17692, 'f1': 0.28221, 'auc': 0.76055}
2025-08-16 09:52:23,369 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:52:23,369 - INFO - Layer 8 (Layer_8), Head 2: drop=-0.0033
2025-08-16 09:52:27,658 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23964, 'loss': 0.12157663, 'lr': 0, 'params': 451793, 'time_iter': 0.03287, 'accuracy': 0.97107, 'precision': 0.66667, 'recall': 0.16923, 'f1': 0.26994, 'auc': 0.76021}
2025-08-16 09:52:27,660 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:52:27,660 - INFO - Layer 8 (Layer_8), Head 3: drop=-0.0028
2025-08-16 09:52:31,949 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.2393, 'loss': 0.12176466, 'lr': 0, 'params': 451793, 'time_iter': 0.03286, 'accuracy': 0.9718, 'precision': 0.69444, 'recall': 0.19231, 'f1': 0.3012, 'auc': 0.75937}
2025-08-16 09:52:31,951 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:52:31,951 - INFO - Layer 9 (Layer_9), Head 0: drop=-0.0017
2025-08-16 09:52:36,235 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23396, 'loss': 0.12144591, 'lr': 0, 'params': 451793, 'time_iter': 0.03282, 'accuracy': 0.97107, 'precision': 0.66667, 'recall': 0.16923, 'f1': 0.26994, 'auc': 0.75879}
2025-08-16 09:52:36,237 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:52:36,238 - INFO - Layer 9 (Layer_9), Head 1: drop=-0.0010
2025-08-16 09:52:40,526 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.23919, 'loss': 0.12217012, 'lr': 0, 'params': 451793, 'time_iter': 0.03286, 'accuracy': 0.9718, 'precision': 0.70588, 'recall': 0.18462, 'f1': 0.29268, 'auc': 0.75935}
2025-08-16 09:52:40,528 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:52:40,528 - INFO - Layer 9 (Layer_9), Head 2: drop=-0.0017
2025-08-16 09:52:44,790 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.21316, 'loss': 0.12207252, 'lr': 0, 'params': 451793, 'time_iter': 0.03266, 'accuracy': 0.9718, 'precision': 0.71875, 'recall': 0.17692, 'f1': 0.28395, 'auc': 0.76169}
2025-08-16 09:52:44,792 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:52:44,792 - INFO - Layer 9 (Layer_9), Head 3: drop=-0.0048
2025-08-16 09:52:48,980 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.1402, 'loss': 0.12249295, 'lr': 0, 'params': 451793, 'time_iter': 0.03209, 'accuracy': 0.97155, 'precision': 0.68571, 'recall': 0.18462, 'f1': 0.29091, 'auc': 0.75953}
2025-08-16 09:52:48,982 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:52:48,983 - INFO - Layer 10 (Layer_10), Head 0: drop=-0.0019
2025-08-16 09:52:53,177 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.14607, 'loss': 0.12190994, 'lr': 0, 'params': 451793, 'time_iter': 0.03214, 'accuracy': 0.9718, 'precision': 0.68421, 'recall': 0.2, 'f1': 0.30952, 'auc': 0.75897}
2025-08-16 09:52:53,180 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:52:53,180 - INFO - Layer 10 (Layer_10), Head 1: drop=-0.0012
2025-08-16 09:52:57,373 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.145, 'loss': 0.12232913, 'lr': 0, 'params': 451793, 'time_iter': 0.03213, 'accuracy': 0.9718, 'precision': 0.68421, 'recall': 0.2, 'f1': 0.30952, 'auc': 0.75733}
2025-08-16 09:52:57,375 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:52:57,375 - INFO - Layer 10 (Layer_10), Head 2: drop=0.0010
2025-08-16 09:53:01,584 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.16019, 'loss': 0.12199893, 'lr': 0, 'params': 451793, 'time_iter': 0.03225, 'accuracy': 0.9718, 'precision': 0.68421, 'recall': 0.2, 'f1': 0.30952, 'auc': 0.75875}
2025-08-16 09:53:01,585 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:01,586 - INFO - Layer 10 (Layer_10), Head 3: drop=-0.0009
2025-08-16 09:53:05,785 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.15085, 'loss': 0.12200666, 'lr': 0, 'params': 451793, 'time_iter': 0.03218, 'accuracy': 0.97131, 'precision': 0.65, 'recall': 0.2, 'f1': 0.30588, 'auc': 0.75965}
2025-08-16 09:53:05,787 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:05,787 - INFO - Layer 11 (Layer_11), Head 0: drop=-0.0021
2025-08-16 09:53:09,968 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.13275, 'loss': 0.12167866, 'lr': 0, 'params': 451793, 'time_iter': 0.03204, 'accuracy': 0.97107, 'precision': 0.64103, 'recall': 0.19231, 'f1': 0.29586, 'auc': 0.75795}
2025-08-16 09:53:09,971 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:09,971 - INFO - Layer 11 (Layer_11), Head 1: drop=0.0001
2025-08-16 09:53:14,186 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.1674, 'loss': 0.12150256, 'lr': 0, 'params': 451793, 'time_iter': 0.03231, 'accuracy': 0.97155, 'precision': 0.67568, 'recall': 0.19231, 'f1': 0.2994, 'auc': 0.75986}
2025-08-16 09:53:14,188 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:14,189 - INFO - Layer 11 (Layer_11), Head 2: drop=-0.0024
2025-08-16 09:53:18,396 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.15898, 'loss': 0.12187338, 'lr': 0, 'params': 451793, 'time_iter': 0.03224, 'accuracy': 0.97107, 'precision': 0.64103, 'recall': 0.19231, 'f1': 0.29586, 'auc': 0.75942}
2025-08-16 09:53:18,398 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:18,398 - INFO - Layer 11 (Layer_11), Head 3: drop=-0.0018
2025-08-16 09:53:22,591 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.14426, 'loss': 0.12109017, 'lr': 0, 'params': 451793, 'time_iter': 0.03213, 'accuracy': 0.97155, 'precision': 0.66667, 'recall': 0.2, 'f1': 0.30769, 'auc': 0.75901}
2025-08-16 09:53:22,593 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:22,593 - INFO - Layer 12 (Layer_12), Head 0: drop=-0.0013
2025-08-16 09:53:26,775 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.13336, 'loss': 0.12053292, 'lr': 0, 'params': 451793, 'time_iter': 0.03204, 'accuracy': 0.97107, 'precision': 0.63415, 'recall': 0.2, 'f1': 0.30409, 'auc': 0.76006}
2025-08-16 09:53:26,776 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:26,777 - INFO - Layer 12 (Layer_12), Head 1: drop=-0.0026
2025-08-16 09:53:30,959 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.13349, 'loss': 0.12108031, 'lr': 0, 'params': 451793, 'time_iter': 0.03204, 'accuracy': 0.97131, 'precision': 0.65, 'recall': 0.2, 'f1': 0.30588, 'auc': 0.76016}
2025-08-16 09:53:30,961 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:30,961 - INFO - Layer 12 (Layer_12), Head 2: drop=-0.0028
2025-08-16 09:53:35,143 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.13425, 'loss': 0.12141173, 'lr': 0, 'params': 451793, 'time_iter': 0.03205, 'accuracy': 0.97155, 'precision': 0.66667, 'recall': 0.2, 'f1': 0.30769, 'auc': 0.75978}
2025-08-16 09:53:35,146 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:35,146 - INFO - Layer 12 (Layer_12), Head 3: drop=-0.0023
2025-08-16 09:53:39,341 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.14615, 'loss': 0.12087947, 'lr': 0, 'params': 451793, 'time_iter': 0.03214, 'accuracy': 0.97131, 'precision': 0.65789, 'recall': 0.19231, 'f1': 0.29762, 'auc': 0.7604}
2025-08-16 09:53:39,343 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:39,343 - INFO - Layer 13 (Layer_13), Head 0: drop=-0.0031
2025-08-16 09:53:43,553 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.16046, 'loss': 0.12219964, 'lr': 0, 'params': 451793, 'time_iter': 0.03225, 'accuracy': 0.97155, 'precision': 0.67568, 'recall': 0.19231, 'f1': 0.2994, 'auc': 0.76034}
2025-08-16 09:53:43,554 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:43,555 - INFO - Layer 13 (Layer_13), Head 1: drop=-0.0030
2025-08-16 09:53:47,727 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.12375, 'loss': 0.12132232, 'lr': 0, 'params': 451793, 'time_iter': 0.03197, 'accuracy': 0.9718, 'precision': 0.68421, 'recall': 0.2, 'f1': 0.30952, 'auc': 0.75962}
2025-08-16 09:53:47,729 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:47,729 - INFO - Layer 13 (Layer_13), Head 2: drop=-0.0021
2025-08-16 09:53:51,902 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.12415, 'loss': 0.12165795, 'lr': 0, 'params': 451793, 'time_iter': 0.03197, 'accuracy': 0.97155, 'precision': 0.66667, 'recall': 0.2, 'f1': 0.30769, 'auc': 0.75945}
2025-08-16 09:53:51,904 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:51,904 - INFO - Layer 13 (Layer_13), Head 3: drop=-0.0018
2025-08-16 09:53:56,085 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.13278, 'loss': 0.12054977, 'lr': 0, 'params': 451793, 'time_iter': 0.03204, 'accuracy': 0.97228, 'precision': 0.75, 'recall': 0.18462, 'f1': 0.2963, 'auc': 0.75994}
2025-08-16 09:53:56,087 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:53:56,088 - INFO - Layer 14 (Layer_14), Head 0: drop=-0.0025
2025-08-16 09:54:00,279 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.14251, 'loss': 0.12136261, 'lr': 0, 'params': 451793, 'time_iter': 0.03211, 'accuracy': 0.97155, 'precision': 0.67568, 'recall': 0.19231, 'f1': 0.2994, 'auc': 0.75978}
2025-08-16 09:54:00,282 - INFO - ...computing epoch stats took: 0.02s
2025-08-16 09:54:00,282 - INFO - Layer 14 (Layer_14), Head 1: drop=-0.0023
2025-08-16 09:54:04,464 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.13377, 'loss': 0.12207001, 'lr': 0, 'params': 451793, 'time_iter': 0.03204, 'accuracy': 0.97155, 'precision': 0.67568, 'recall': 0.19231, 'f1': 0.2994, 'auc': 0.75908}
2025-08-16 09:54:04,466 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:54:04,466 - INFO - Layer 14 (Layer_14), Head 2: drop=-0.0013
2025-08-16 09:54:08,640 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.12575, 'loss': 0.12220108, 'lr': 0, 'params': 451793, 'time_iter': 0.03198, 'accuracy': 0.97155, 'precision': 0.67568, 'recall': 0.19231, 'f1': 0.2994, 'auc': 0.75885}
2025-08-16 09:54:08,642 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 09:54:08,642 - INFO - Layer 14 (Layer_14), Head 3: drop=-0.0010
2025-08-16 09:54:08,645 - INFO - 
FIDELITY METRICS:
2025-08-16 09:54:08,646 - INFO - Fidelity (top 30 heads): 0.0010
2025-08-16 09:54:08,646 - INFO - Fidelity- (bottom 30 heads): -0.0030
2025-08-16 09:54:08,646 - INFO - 
GNN distribution in important heads:
2025-08-16 09:54:08,646 - INFO -   Layer_7: 4 heads
2025-08-16 09:54:08,646 - INFO -   Layer_0: 3 heads
2025-08-16 09:54:08,646 - INFO -   Layer_3: 3 heads
2025-08-16 09:54:08,646 - INFO -   Layer_5: 3 heads
2025-08-16 09:54:08,646 - INFO -   Layer_10: 3 heads
2025-08-16 09:54:08,646 - INFO -   Layer_2: 2 heads
2025-08-16 09:54:08,646 - INFO -   Layer_6: 2 heads
2025-08-16 09:54:08,646 - INFO -   Layer_1: 2 heads
2025-08-16 09:54:08,646 - INFO -   Layer_8: 2 heads
2025-08-16 09:54:08,646 - INFO -   Layer_14: 2 heads
2025-08-16 09:54:08,646 - INFO -   Layer_4: 1 heads
2025-08-16 09:54:08,646 - INFO -   Layer_11: 1 heads
2025-08-16 09:54:08,646 - INFO -   Layer_9: 1 heads
2025-08-16 09:54:08,646 - INFO -   Layer_12: 1 heads
2025-08-16 09:54:08,646 - INFO - 
Interpretability Analysis:
2025-08-16 09:54:08,646 - INFO -   Fidelity: 0.0010
2025-08-16 09:54:08,646 - INFO -   Fidelity-: -0.0030
2025-08-16 09:54:08,646 - INFO -   Total heads tested: 60
2025-08-16 09:54:08,885 - INFO - Excel results saved to results/molhiv/molhiv-Vanilla-47/pk_explainer_results.xlsx
2025-08-16 09:54:10,102 - INFO - Saved visualizations to results/molhiv/molhiv-Vanilla-47/pk_explainer_results
2025-08-16 09:54:10,104 - INFO - 
PK-Explainer results saved to:
2025-08-16 09:54:10,104 - INFO -   - Excel: results/molhiv/molhiv-Vanilla-47/pk_explainer_results.xlsx
2025-08-16 09:54:10,105 - INFO -   - JSON: results/molhiv/molhiv-Vanilla-47/pk_explainer_results.json
2025-08-16 09:54:10,105 - INFO -   - Visualizations: results/molhiv/molhiv-Vanilla-47/pk_explainer_results
2025-08-16 09:54:10,115 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-47
2025-08-16 09:54:10,116 - INFO - Total time: 8066.88s (2.24h)
2025-08-16 09:54:10,128 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-47/agg
2025-08-16 09:54:10,128 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-16 09:54:10,129 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-47
2025-08-16 09:54:10,129 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-47/test_results/
Completed seed 47. Results saved in results/molhiv/molhiv-Vanilla-47
----------------------------------------
Running experiment with seed: 49
Starting training for seed 49...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/confignas.yaml
Using device: cuda
2025-08-16 09:54:19,504 - INFO - GPU Mem: 25.2GB
2025-08-16 09:54:19,504 - INFO - Run directory: results/molhiv/molhiv-Vanilla-49
2025-08-16 09:54:19,504 - INFO - Seed: 49
2025-08-16 09:54:19,505 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-16 09:54:19,505 - INFO - Routing mode: none
2025-08-16 09:54:19,505 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-16 09:54:19,505 - INFO - Number of layers: 15
2025-08-16 09:54:19,505 - INFO - Uncertainty enabled: False
2025-08-16 09:54:19,505 - INFO - Training mode: custom
2025-08-16 09:54:19,505 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-16 09:54:19,505 - INFO - Additional features: Router weights logging + JSON export
2025-08-16 09:54:25,845 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 09:54:25,848 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 09:54:25,849 - INFO -   undirected: True
2025-08-16 09:54:25,849 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 09:54:25,849 - INFO -   avg num_nodes/graph: 25
2025-08-16 09:54:25,850 - INFO -   num node features: 9
2025-08-16 09:54:25,850 - INFO -   num edge features: 3
2025-08-16 09:54:25,850 - INFO -   num tasks: 1
2025-08-16 09:54:25,850 - INFO -   num classes: 2
2025-08-16 09:54:25,850 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 09:54:25,850 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 09:54:25,853 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 10%|▉         | 4107/41127 [00:10<01:30, 410.69it/s] 15%|█▍        | 6163/41127 [00:20<02:01, 288.05it/s] 20%|█▉        | 8219/41127 [00:30<02:14, 245.42it/s] 27%|██▋       | 11285/41127 [00:40<01:50, 269.21it/s] 36%|███▌      | 14738/41127 [00:50<01:29, 294.93it/s] 36%|███▌      | 14738/41127 [01:03<01:29, 294.93it/s] 40%|████      | 16479/41127 [01:03<01:46, 230.38it/s] 48%|████▊     | 19942/41127 [01:13<01:19, 265.57it/s] 56%|█████▋    | 23186/41127 [01:23<01:03, 282.40it/s] 64%|██████▍   | 26461/41127 [01:33<00:49, 295.97it/s] 71%|███████▏  | 29331/41127 [01:44<00:40, 291.84it/s] 76%|███████▌  | 31136/41127 [01:54<00:38, 257.70it/s] 83%|████████▎ | 34292/41127 [02:04<00:24, 274.44it/s] 88%|████████▊ | 36262/41127 [02:14<00:19, 251.29it/s] 95%|█████████▍| 38924/41127 [02:24<00:08, 255.62it/s] 99%|█████████▉| 40742/41127 [02:34<00:01, 233.15it/s]100%|██████████| 41127/41127 [02:38<00:00, 258.99it/s]
2025-08-16 09:57:05,781 - INFO - Done! Took 00:02:39.93
2025-08-16 09:57:05,928 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 09:57:06,118 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-16 09:57:06,118 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-08-16 09:57:06,118 - INFO - Inner model has get_darts_model: False
2025-08-16 09:57:06,122 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-08-16 09:57:06,125 - INFO - Number of parameters: 451,793
2025-08-16 09:57:06,125 - INFO - Starting optimized training: 2025-08-16 09:57:06.125632
2025-08-16 09:57:12,091 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 09:57:12,092 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-16 09:57:12,092 - INFO -   undirected: True
2025-08-16 09:57:12,093 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 09:57:12,093 - INFO -   avg num_nodes/graph: 25
2025-08-16 09:57:12,093 - INFO -   num node features: 9
2025-08-16 09:57:12,093 - INFO -   num edge features: 3
2025-08-16 09:57:12,093 - INFO -   num tasks: 1
2025-08-16 09:57:12,094 - INFO -   num classes: 2
2025-08-16 09:57:12,094 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-16 09:57:12,094 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-16 09:57:12,097 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 10%|█         | 4118/41127 [00:10<01:29, 411.78it/s] 15%|█▌        | 6204/41127 [00:20<02:00, 290.99it/s] 21%|██        | 8660/41127 [00:30<02:00, 270.31it/s] 29%|██▉       | 11994/41127 [00:40<01:39, 293.44it/s] 36%|███▌      | 14751/41127 [00:50<01:31, 286.78it/s] 41%|████      | 16807/41127 [01:04<01:45, 229.98it/s] 49%|████▉     | 20160/41127 [01:14<01:20, 261.60it/s] 57%|█████▋    | 23524/41127 [01:24<01:01, 284.05it/s] 65%|██████▍   | 26536/41127 [01:34<00:50, 289.19it/s] 71%|███████▏  | 29350/41127 [01:44<00:41, 285.87it/s] 77%|███████▋  | 31588/41127 [01:54<00:35, 266.94it/s] 84%|████████▍ | 34478/41127 [02:04<00:24, 272.75it/s] 89%|████████▉ | 36719/41127 [02:14<00:17, 258.20it/s] 95%|█████████▌| 39265/41127 [02:24<00:07, 256.80it/s] 95%|█████████▌| 39265/41127 [02:37<00:07, 256.80it/s]100%|█████████▉| 41030/41127 [02:37<00:00, 211.39it/s]100%|██████████| 41127/41127 [02:38<00:00, 259.18it/s]
2025-08-16 09:59:51,902 - INFO - Done! Took 00:02:39.81
2025-08-16 09:59:52,044 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-16 09:59:52,047 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-16 09:59:52,048 - INFO - Start from epoch 0
2025-08-16 10:01:05,025 - INFO - train: {'epoch': 0, 'time_epoch': 72.88107, 'eta': 7215.22578, 'eta_hours': 2.00423, 'loss': 0.71854298, 'lr': 0.0, 'params': 451793, 'time_iter': 0.07083, 'accuracy': 0.04185, 'precision': 0.03747, 'recall': 0.99594, 'f1': 0.07222, 'auc': 0.45872}
2025-08-16 10:01:05,036 - INFO - ...computing epoch stats took: 0.09s
2025-08-16 10:01:09,692 - INFO - val: {'epoch': 0, 'time_epoch': 4.64177, 'loss': 0.71709819, 'lr': 0, 'params': 451793, 'time_iter': 0.03598, 'accuracy': 0.01994, 'precision': 0.0197, 'recall': 1.0, 'f1': 0.03864, 'auc': 0.49204}
2025-08-16 10:01:09,695 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 10:01:14,364 - INFO - test: {'epoch': 0, 'time_epoch': 4.65532, 'loss': 0.71892876, 'lr': 0, 'params': 451793, 'time_iter': 0.03609, 'accuracy': 0.03258, 'precision': 0.03164, 'recall': 1.0, 'f1': 0.06134, 'auc': 0.40686}
2025-08-16 10:01:14,367 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 10:01:14,367 - INFO - > Epoch 0: took 82.3s (avg 82.3s) | Best so far: epoch 0	train_loss: 0.7185 train_auc: 0.4587	val_loss: 0.7171 val_auc: 0.4920	test_loss: 0.7189 test_auc: 0.4069
2025-08-16 10:02:23,731 - INFO - train: {'epoch': 1, 'time_epoch': 69.27485, 'eta': 6965.63992, 'eta_hours': 1.9349, 'loss': 0.4847809, 'lr': 2e-05, 'params': 451793, 'time_iter': 0.06732, 'accuracy': 0.87845, 'precision': 0.03806, 'recall': 0.09253, 'f1': 0.05394, 'auc': 0.51795}
2025-08-16 10:02:23,739 - INFO - ...computing epoch stats took: 0.08s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:02:27,999 - INFO - val: {'epoch': 1, 'time_epoch': 4.24387, 'loss': 0.24041797, 'lr': 0, 'params': 451793, 'time_iter': 0.0329, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.5517}
2025-08-16 10:02:28,001 - INFO - ...computing epoch stats took: 0.01s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:02:32,241 - INFO - test: {'epoch': 1, 'time_epoch': 4.22534, 'loss': 0.25166343, 'lr': 0, 'params': 451793, 'time_iter': 0.03275, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.57857}
2025-08-16 10:02:32,243 - INFO - ...computing epoch stats took: 0.01s
2025-08-16 10:02:32,243 - INFO - > Epoch 1: took 77.9s (avg 80.1s) | Best so far: epoch 1	train_loss: 0.4848 train_auc: 0.5180	val_loss: 0.2404 val_auc: 0.5517	test_loss: 0.2517 test_auc: 0.5786
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:03:42,058 - INFO - train: {'epoch': 2, 'time_epoch': 69.73765, 'eta': 6851.22539, 'eta_hours': 1.90312, 'loss': 0.20173041, 'lr': 4e-05, 'params': 451793, 'time_iter': 0.06777, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.57899}
2025-08-16 10:03:42,067 - INFO - ...computing epoch stats took: 0.07s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:03:46,427 - INFO - val: {'epoch': 2, 'time_epoch': 4.34237, 'loss': 0.11586284, 'lr': 0, 'params': 451793, 'time_iter': 0.03366, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.60745}
2025-08-16 10:03:46,430 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:03:50,715 - INFO - test: {'epoch': 2, 'time_epoch': 4.26818, 'loss': 0.14534141, 'lr': 0, 'params': 451793, 'time_iter': 0.03309, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66001}
2025-08-16 10:03:50,727 - INFO - ...computing epoch stats took: 0.03s
2025-08-16 10:03:50,728 - INFO - > Epoch 2: took 78.5s (avg 79.6s) | Best so far: epoch 2	train_loss: 0.2017 train_auc: 0.5790	val_loss: 0.1159 val_auc: 0.6075	test_loss: 0.1453 test_auc: 0.6600
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:05:00,747 - INFO - train: {'epoch': 3, 'time_epoch': 69.94923, 'eta': 6764.22713, 'eta_hours': 1.87895, 'loss': 0.15857008, 'lr': 6e-05, 'params': 451793, 'time_iter': 0.06798, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.63964}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:05:05,209 - INFO - val: {'epoch': 3, 'time_epoch': 4.32954, 'loss': 0.1013807, 'lr': 0, 'params': 451793, 'time_iter': 0.03356, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.59414}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:05:09,479 - INFO - test: {'epoch': 3, 'time_epoch': 4.25314, 'loss': 0.13026831, 'lr': 0, 'params': 451793, 'time_iter': 0.03297, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70814}
2025-08-16 10:05:09,481 - INFO - > Epoch 3: took 78.8s (avg 79.4s) | Best so far: epoch 2	train_loss: 0.2017 train_auc: 0.5790	val_loss: 0.1159 val_auc: 0.6075	test_loss: 0.1453 test_auc: 0.6600
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:06:18,602 - INFO - train: {'epoch': 4, 'time_epoch': 69.04791, 'eta': 6666.92348, 'eta_hours': 1.85192, 'loss': 0.15266459, 'lr': 8e-05, 'params': 451793, 'time_iter': 0.0671, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66393}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:06:22,925 - INFO - val: {'epoch': 4, 'time_epoch': 4.30091, 'loss': 0.10032922, 'lr': 0, 'params': 451793, 'time_iter': 0.03334, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.65334}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:06:27,238 - INFO - test: {'epoch': 4, 'time_epoch': 4.29738, 'loss': 0.12906711, 'lr': 0, 'params': 451793, 'time_iter': 0.03331, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70666}
2025-08-16 10:06:27,241 - INFO - > Epoch 4: took 77.8s (avg 79.0s) | Best so far: epoch 4	train_loss: 0.1527 train_auc: 0.6639	val_loss: 0.1003 val_auc: 0.6533	test_loss: 0.1291 test_auc: 0.7067
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:07:37,954 - INFO - train: {'epoch': 5, 'time_epoch': 70.64138, 'eta': 6604.00267, 'eta_hours': 1.83445, 'loss': 0.14745211, 'lr': 0.0001, 'params': 451793, 'time_iter': 0.06865, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6977}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:07:42,067 - INFO - val: {'epoch': 5, 'time_epoch': 4.09174, 'loss': 0.09494342, 'lr': 0, 'params': 451793, 'time_iter': 0.03172, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69828}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:07:46,238 - INFO - test: {'epoch': 5, 'time_epoch': 4.15424, 'loss': 0.12159188, 'lr': 0, 'params': 451793, 'time_iter': 0.0322, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72902}
2025-08-16 10:07:46,241 - INFO - > Epoch 5: took 79.0s (avg 79.0s) | Best so far: epoch 5	train_loss: 0.1475 train_auc: 0.6977	val_loss: 0.0949 val_auc: 0.6983	test_loss: 0.1216 test_auc: 0.7290
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:08:55,415 - INFO - train: {'epoch': 6, 'time_epoch': 69.10554, 'eta': 6518.47131, 'eta_hours': 1.81069, 'loss': 0.14350553, 'lr': 9.997e-05, 'params': 451793, 'time_iter': 0.06716, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7183}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:08:59,740 - INFO - val: {'epoch': 6, 'time_epoch': 4.30191, 'loss': 0.09725404, 'lr': 0, 'params': 451793, 'time_iter': 0.03335, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72144}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:09:04,055 - INFO - test: {'epoch': 6, 'time_epoch': 4.29899, 'loss': 0.12892368, 'lr': 0, 'params': 451793, 'time_iter': 0.03333, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71735}
2025-08-16 10:09:04,058 - INFO - > Epoch 6: took 77.8s (avg 78.9s) | Best so far: epoch 6	train_loss: 0.1435 train_auc: 0.7183	val_loss: 0.0973 val_auc: 0.7214	test_loss: 0.1289 test_auc: 0.7174
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:10:14,932 - INFO - train: {'epoch': 7, 'time_epoch': 70.80146, 'eta': 6456.54943, 'eta_hours': 1.79349, 'loss': 0.13950862, 'lr': 9.989e-05, 'params': 451793, 'time_iter': 0.06881, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74326}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:10:19,078 - INFO - val: {'epoch': 7, 'time_epoch': 4.12522, 'loss': 0.08900101, 'lr': 0, 'params': 451793, 'time_iter': 0.03198, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72237}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:10:23,283 - INFO - test: {'epoch': 7, 'time_epoch': 4.1875, 'loss': 0.11805037, 'lr': 0, 'params': 451793, 'time_iter': 0.03246, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76005}
2025-08-16 10:10:23,285 - INFO - > Epoch 7: took 79.2s (avg 78.9s) | Best so far: epoch 7	train_loss: 0.1395 train_auc: 0.7433	val_loss: 0.0890 val_auc: 0.7224	test_loss: 0.1181 test_auc: 0.7601
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:11:30,851 - INFO - train: {'epoch': 8, 'time_epoch': 67.48999, 'eta': 6359.17171, 'eta_hours': 1.76644, 'loss': 0.13768411, 'lr': 9.975e-05, 'params': 451793, 'time_iter': 0.06559, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74756}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:11:35,018 - INFO - val: {'epoch': 8, 'time_epoch': 4.14108, 'loss': 0.08625398, 'lr': 0, 'params': 451793, 'time_iter': 0.0321, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.77651}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:11:39,129 - INFO - test: {'epoch': 8, 'time_epoch': 4.09185, 'loss': 0.11948035, 'lr': 0, 'params': 451793, 'time_iter': 0.03172, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73531}
2025-08-16 10:11:39,132 - INFO - > Epoch 8: took 75.8s (avg 78.6s) | Best so far: epoch 8	train_loss: 0.1377 train_auc: 0.7476	val_loss: 0.0863 val_auc: 0.7765	test_loss: 0.1195 test_auc: 0.7353
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:12:48,989 - INFO - train: {'epoch': 9, 'time_epoch': 69.78429, 'eta': 6288.42024, 'eta_hours': 1.74678, 'loss': 0.13660452, 'lr': 9.956e-05, 'params': 451793, 'time_iter': 0.06782, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75509}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:12:53,357 - INFO - val: {'epoch': 9, 'time_epoch': 4.34191, 'loss': 0.08662866, 'lr': 0, 'params': 451793, 'time_iter': 0.03366, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74828}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-16 10:12:57,676 - INFO - test: {'epoch': 9, 'time_epoch': 4.30094, 'loss': 0.11682476, 'lr': 0, 'params': 451793, 'time_iter': 0.03334, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7522}
2025-08-16 10:12:57,679 - INFO - > Epoch 9: took 78.5s (avg 78.6s) | Best so far: epoch 8	train_loss: 0.1377 train_auc: 0.7476	val_loss: 0.0863 val_auc: 0.7765	test_loss: 0.1195 test_auc: 0.7353
2025-08-16 10:14:06,672 - INFO - train: {'epoch': 10, 'time_epoch': 68.90776, 'eta': 6210.75269, 'eta_hours': 1.72521, 'loss': 0.1342641, 'lr': 9.932e-05, 'params': 451793, 'time_iter': 0.06697, 'accuracy': 0.96243, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76384}
2025-08-16 10:14:10,977 - INFO - val: {'epoch': 10, 'time_epoch': 4.27827, 'loss': 0.08961342, 'lr': 0, 'params': 451793, 'time_iter': 0.03316, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.01235, 'f1': 0.0241, 'auc': 0.75923}
2025-08-16 10:14:15,261 - INFO - test: {'epoch': 10, 'time_epoch': 4.26253, 'loss': 0.12130104, 'lr': 0, 'params': 451793, 'time_iter': 0.03304, 'accuracy': 0.96961, 'precision': 0.72727, 'recall': 0.06154, 'f1': 0.11348, 'auc': 0.74747}
2025-08-16 10:14:15,264 - INFO - > Epoch 10: took 77.6s (avg 78.5s) | Best so far: epoch 8	train_loss: 0.1377 train_auc: 0.7476	val_loss: 0.0863 val_auc: 0.7765	test_loss: 0.1195 test_auc: 0.7353
2025-08-16 10:15:24,066 - INFO - train: {'epoch': 11, 'time_epoch': 68.7194, 'eta': 6133.16384, 'eta_hours': 1.70366, 'loss': 0.13323401, 'lr': 9.902e-05, 'params': 451793, 'time_iter': 0.06678, 'accuracy': 0.96271, 'precision': 0.54545, 'recall': 0.02435, 'f1': 0.04662, 'auc': 0.76931}
2025-08-16 10:15:28,157 - INFO - val: {'epoch': 11, 'time_epoch': 4.06526, 'loss': 0.09064002, 'lr': 0, 'params': 451793, 'time_iter': 0.03151, 'accuracy': 0.97885, 'precision': 0.2, 'recall': 0.02469, 'f1': 0.04396, 'auc': 0.74559}
2025-08-16 10:15:32,231 - INFO - test: {'epoch': 11, 'time_epoch': 4.05612, 'loss': 0.11829313, 'lr': 0, 'params': 451793, 'time_iter': 0.03144, 'accuracy': 0.96791, 'precision': 0.45833, 'recall': 0.08462, 'f1': 0.14286, 'auc': 0.76932}
2025-08-16 10:15:32,235 - INFO - > Epoch 11: took 77.0s (avg 78.3s) | Best so far: epoch 8	train_loss: 0.1377 train_auc: 0.7476	val_loss: 0.0863 val_auc: 0.7765	test_loss: 0.1195 test_auc: 0.7353
2025-08-16 10:16:41,344 - INFO - train: {'epoch': 12, 'time_epoch': 69.01972, 'eta': 6058.94931, 'eta_hours': 1.68304, 'loss': 0.13157048, 'lr': 9.867e-05, 'params': 451793, 'time_iter': 0.06707, 'accuracy': 0.9628, 'precision': 0.54878, 'recall': 0.03653, 'f1': 0.06849, 'auc': 0.77608}
2025-08-16 10:16:45,739 - INFO - val: {'epoch': 12, 'time_epoch': 4.36935, 'loss': 0.09050018, 'lr': 0, 'params': 451793, 'time_iter': 0.03387, 'accuracy': 0.97812, 'precision': 0.23529, 'recall': 0.04938, 'f1': 0.08163, 'auc': 0.7929}
2025-08-16 10:16:50,065 - INFO - test: {'epoch': 12, 'time_epoch': 4.30724, 'loss': 0.12163283, 'lr': 0, 'params': 451793, 'time_iter': 0.03339, 'accuracy': 0.96766, 'precision': 0.46809, 'recall': 0.16923, 'f1': 0.24859, 'auc': 0.76411}
2025-08-16 10:16:50,069 - INFO - > Epoch 12: took 77.8s (avg 78.3s) | Best so far: epoch 12	train_loss: 0.1316 train_auc: 0.7761	val_loss: 0.0905 val_auc: 0.7929	test_loss: 0.1216 test_auc: 0.7641
2025-08-16 10:17:57,138 - INFO - train: {'epoch': 13, 'time_epoch': 66.9816, 'eta': 5972.95705, 'eta_hours': 1.65915, 'loss': 0.13082028, 'lr': 9.826e-05, 'params': 451793, 'time_iter': 0.06509, 'accuracy': 0.96277, 'precision': 0.52448, 'recall': 0.06088, 'f1': 0.10909, 'auc': 0.78115}
2025-08-16 10:18:01,483 - INFO - val: {'epoch': 13, 'time_epoch': 4.3155, 'loss': 0.08601872, 'lr': 0, 'params': 451793, 'time_iter': 0.03345, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.04938, 'f1': 0.08989, 'auc': 0.76548}
2025-08-16 10:18:05,807 - INFO - test: {'epoch': 13, 'time_epoch': 4.30654, 'loss': 0.11869265, 'lr': 0, 'params': 451793, 'time_iter': 0.03338, 'accuracy': 0.96985, 'precision': 0.71429, 'recall': 0.07692, 'f1': 0.13889, 'auc': 0.75124}
2025-08-16 10:18:05,810 - INFO - > Epoch 13: took 75.7s (avg 78.1s) | Best so far: epoch 12	train_loss: 0.1316 train_auc: 0.7761	val_loss: 0.0905 val_auc: 0.7929	test_loss: 0.1216 test_auc: 0.7641
2025-08-16 10:19:14,629 - INFO - train: {'epoch': 14, 'time_epoch': 68.72966, 'eta': 5899.4052, 'eta_hours': 1.63872, 'loss': 0.12946829, 'lr': 9.78e-05, 'params': 451793, 'time_iter': 0.06679, 'accuracy': 0.96283, 'precision': 0.536, 'recall': 0.05438, 'f1': 0.09875, 'auc': 0.79091}
2025-08-16 10:19:19,062 - INFO - val: {'epoch': 14, 'time_epoch': 4.41017, 'loss': 0.08604544, 'lr': 0, 'params': 451793, 'time_iter': 0.03419, 'accuracy': 0.98055, 'precision': 0.52381, 'recall': 0.1358, 'f1': 0.21569, 'auc': 0.76679}
2025-08-16 10:19:23,483 - INFO - test: {'epoch': 14, 'time_epoch': 4.40257, 'loss': 0.11760897, 'lr': 0, 'params': 451793, 'time_iter': 0.03413, 'accuracy': 0.96888, 'precision': 0.53125, 'recall': 0.13077, 'f1': 0.20988, 'auc': 0.76501}
2025-08-16 10:19:23,486 - INFO - > Epoch 14: took 77.7s (avg 78.1s) | Best so far: epoch 12	train_loss: 0.1316 train_auc: 0.7761	val_loss: 0.0905 val_auc: 0.7929	test_loss: 0.1216 test_auc: 0.7641
2025-08-16 10:20:33,249 - INFO - train: {'epoch': 15, 'time_epoch': 69.67522, 'eta': 5831.42033, 'eta_hours': 1.61984, 'loss': 0.127255, 'lr': 9.729e-05, 'params': 451793, 'time_iter': 0.06771, 'accuracy': 0.96328, 'precision': 0.56897, 'recall': 0.08036, 'f1': 0.14083, 'auc': 0.7939}
2025-08-16 10:20:37,722 - INFO - val: {'epoch': 15, 'time_epoch': 4.44884, 'loss': 0.08622194, 'lr': 0, 'params': 451793, 'time_iter': 0.03449, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.1358, 'f1': 0.21359, 'auc': 0.76384}
2025-08-16 10:20:42,164 - INFO - test: {'epoch': 15, 'time_epoch': 4.42335, 'loss': 0.11516732, 'lr': 0, 'params': 451793, 'time_iter': 0.03429, 'accuracy': 0.97058, 'precision': 0.68, 'recall': 0.13077, 'f1': 0.21935, 'auc': 0.75827}
2025-08-16 10:20:42,167 - INFO - > Epoch 15: took 78.7s (avg 78.1s) | Best so far: epoch 12	train_loss: 0.1316 train_auc: 0.7761	val_loss: 0.0905 val_auc: 0.7929	test_loss: 0.1216 test_auc: 0.7641
2025-08-16 10:21:52,544 - INFO - train: {'epoch': 16, 'time_epoch': 70.28804, 'eta': 5766.2286, 'eta_hours': 1.60173, 'loss': 0.1286598, 'lr': 9.673e-05, 'params': 451793, 'time_iter': 0.06831, 'accuracy': 0.96347, 'precision': 0.57143, 'recall': 0.0974, 'f1': 0.16644, 'auc': 0.786}
2025-08-16 10:21:56,989 - INFO - val: {'epoch': 16, 'time_epoch': 4.42142, 'loss': 0.08697396, 'lr': 0, 'params': 451793, 'time_iter': 0.03427, 'accuracy': 0.97933, 'precision': 0.4, 'recall': 0.09877, 'f1': 0.15842, 'auc': 0.77216}
2025-08-16 10:22:01,371 - INFO - test: {'epoch': 16, 'time_epoch': 4.36373, 'loss': 0.11739147, 'lr': 0, 'params': 451793, 'time_iter': 0.03383, 'accuracy': 0.96912, 'precision': 0.57143, 'recall': 0.09231, 'f1': 0.15894, 'auc': 0.76258}
2025-08-16 10:22:01,374 - INFO - > Epoch 16: took 79.2s (avg 78.2s) | Best so far: epoch 12	train_loss: 0.1316 train_auc: 0.7761	val_loss: 0.0905 val_auc: 0.7929	test_loss: 0.1216 test_auc: 0.7641
2025-08-16 10:23:11,731 - INFO - train: {'epoch': 17, 'time_epoch': 70.27061, 'eta': 5700.39121, 'eta_hours': 1.58344, 'loss': 0.1265654, 'lr': 9.611e-05, 'params': 451793, 'time_iter': 0.06829, 'accuracy': 0.96426, 'precision': 0.59859, 'recall': 0.13799, 'f1': 0.22427, 'auc': 0.79729}
2025-08-16 10:23:16,077 - INFO - val: {'epoch': 17, 'time_epoch': 4.31328, 'loss': 0.08325384, 'lr': 0, 'params': 451793, 'time_iter': 0.03344, 'accuracy': 0.98079, 'precision': 0.58333, 'recall': 0.08642, 'f1': 0.15054, 'auc': 0.77645}
2025-08-16 10:23:20,387 - INFO - test: {'epoch': 17, 'time_epoch': 4.29133, 'loss': 0.11970082, 'lr': 0, 'params': 451793, 'time_iter': 0.03327, 'accuracy': 0.96791, 'precision': 0.45, 'recall': 0.06923, 'f1': 0.12, 'auc': 0.74989}
2025-08-16 10:23:20,391 - INFO - > Epoch 17: took 79.0s (avg 78.2s) | Best so far: epoch 12	train_loss: 0.1316 train_auc: 0.7761	val_loss: 0.0905 val_auc: 0.7929	test_loss: 0.1216 test_auc: 0.7641
2025-08-16 10:24:30,788 - INFO - train: {'epoch': 18, 'time_epoch': 70.2994, 'eta': 5634.20988, 'eta_hours': 1.56506, 'loss': 0.1250883, 'lr': 9.545e-05, 'params': 451793, 'time_iter': 0.06832, 'accuracy': 0.96359, 'precision': 0.55484, 'recall': 0.13961, 'f1': 0.22309, 'auc': 0.80632}
2025-08-16 10:24:35,173 - INFO - val: {'epoch': 18, 'time_epoch': 4.36117, 'loss': 0.08247391, 'lr': 0, 'params': 451793, 'time_iter': 0.03381, 'accuracy': 0.98055, 'precision': 0.52174, 'recall': 0.14815, 'f1': 0.23077, 'auc': 0.76625}
2025-08-16 10:24:39,700 - INFO - test: {'epoch': 18, 'time_epoch': 4.50683, 'loss': 0.11366937, 'lr': 0, 'params': 451793, 'time_iter': 0.03494, 'accuracy': 0.97009, 'precision': 0.56364, 'recall': 0.23846, 'f1': 0.33514, 'auc': 0.7676}
2025-08-16 10:24:39,703 - INFO - > Epoch 18: took 79.3s (avg 78.3s) | Best so far: epoch 12	train_loss: 0.1316 train_auc: 0.7761	val_loss: 0.0905 val_auc: 0.7929	test_loss: 0.1216 test_auc: 0.7641
2025-08-16 10:25:51,974 - INFO - train: {'epoch': 19, 'time_epoch': 72.1816, 'eta': 5575.14556, 'eta_hours': 1.54865, 'loss': 0.1242228, 'lr': 9.474e-05, 'params': 451793, 'time_iter': 0.07015, 'accuracy': 0.96565, 'precision': 0.66887, 'recall': 0.16396, 'f1': 0.26336, 'auc': 0.80187}
2025-08-16 10:25:56,537 - INFO - val: {'epoch': 19, 'time_epoch': 4.53351, 'loss': 0.0811385, 'lr': 0, 'params': 451793, 'time_iter': 0.03514, 'accuracy': 0.98055, 'precision': 0.52174, 'recall': 0.14815, 'f1': 0.23077, 'auc': 0.78697}
2025-08-16 10:26:01,133 - INFO - test: {'epoch': 19, 'time_epoch': 4.57405, 'loss': 0.11534367, 'lr': 0, 'params': 451793, 'time_iter': 0.03546, 'accuracy': 0.96985, 'precision': 0.55769, 'recall': 0.22308, 'f1': 0.31868, 'auc': 0.75101}
2025-08-16 10:26:01,136 - INFO - > Epoch 19: took 81.4s (avg 78.5s) | Best so far: epoch 12	train_loss: 0.1316 train_auc: 0.7761	val_loss: 0.0905 val_auc: 0.7929	test_loss: 0.1216 test_auc: 0.7641
2025-08-16 10:27:15,608 - INFO - train: {'epoch': 20, 'time_epoch': 74.38222, 'eta': 5523.11047, 'eta_hours': 1.5342, 'loss': 0.12437694, 'lr': 9.397e-05, 'params': 451793, 'time_iter': 0.07229, 'accuracy': 0.9641, 'precision': 0.57349, 'recall': 0.16153, 'f1': 0.25206, 'auc': 0.80243}
2025-08-16 10:27:20,235 - INFO - val: {'epoch': 20, 'time_epoch': 4.59563, 'loss': 0.08199135, 'lr': 0, 'params': 451793, 'time_iter': 0.03563, 'accuracy': 0.98104, 'precision': 0.56522, 'recall': 0.16049, 'f1': 0.25, 'auc': 0.79132}
2025-08-16 10:27:24,835 - INFO - test: {'epoch': 20, 'time_epoch': 4.57895, 'loss': 0.11570724, 'lr': 0, 'params': 451793, 'time_iter': 0.0355, 'accuracy': 0.96766, 'precision': 0.45946, 'recall': 0.13077, 'f1': 0.20359, 'auc': 0.75929}
2025-08-16 10:27:24,838 - INFO - > Epoch 20: took 83.7s (avg 78.7s) | Best so far: epoch 12	train_loss: 0.1316 train_auc: 0.7761	val_loss: 0.0905 val_auc: 0.7929	test_loss: 0.1216 test_auc: 0.7641
2025-08-16 10:28:38,804 - INFO - train: {'epoch': 21, 'time_epoch': 73.87446, 'eta': 5467.2436, 'eta_hours': 1.51868, 'loss': 0.12220227, 'lr': 9.316e-05, 'params': 451793, 'time_iter': 0.07179, 'accuracy': 0.96441, 'precision': 0.58047, 'recall': 0.17857, 'f1': 0.27312, 'auc': 0.81515}
2025-08-16 10:28:43,358 - INFO - val: {'epoch': 21, 'time_epoch': 4.52683, 'loss': 0.07958488, 'lr': 0, 'params': 451793, 'time_iter': 0.03509, 'accuracy': 0.98079, 'precision': 0.54545, 'recall': 0.14815, 'f1': 0.23301, 'auc': 0.77864}
2025-08-16 10:28:47,948 - INFO - test: {'epoch': 21, 'time_epoch': 4.56739, 'loss': 0.1147211, 'lr': 0, 'params': 451793, 'time_iter': 0.03541, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.11538, 'f1': 0.1875, 'auc': 0.74495}
2025-08-16 10:28:47,967 - INFO - > Epoch 21: took 83.1s (avg 78.9s) | Best so far: epoch 12	train_loss: 0.1316 train_auc: 0.7761	val_loss: 0.0905 val_auc: 0.7929	test_loss: 0.1216 test_auc: 0.7641
2025-08-16 10:30:01,953 - INFO - train: {'epoch': 22, 'time_epoch': 73.84155, 'eta': 5409.70067, 'eta_hours': 1.50269, 'loss': 0.12209462, 'lr': 9.23e-05, 'params': 451793, 'time_iter': 0.07176, 'accuracy': 0.96532, 'precision': 0.62133, 'recall': 0.18912, 'f1': 0.28998, 'auc': 0.8111}
2025-08-16 10:30:06,732 - INFO - val: {'epoch': 22, 'time_epoch': 4.75151, 'loss': 0.08338727, 'lr': 0, 'params': 451793, 'time_iter': 0.03683, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.17284, 'f1': 0.25688, 'auc': 0.75362}
2025-08-16 10:30:11,428 - INFO - test: {'epoch': 22, 'time_epoch': 4.67011, 'loss': 0.1166201, 'lr': 0, 'params': 451793, 'time_iter': 0.0362, 'accuracy': 0.96937, 'precision': 0.52564, 'recall': 0.31538, 'f1': 0.39423, 'auc': 0.74796}
2025-08-16 10:30:11,431 - INFO - > Epoch 22: took 83.5s (avg 79.1s) | Best so far: epoch 12	train_loss: 0.1316 train_auc: 0.7761	val_loss: 0.0905 val_auc: 0.7929	test_loss: 0.1216 test_auc: 0.7641
2025-08-16 10:31:23,370 - INFO - train: {'epoch': 23, 'time_epoch': 71.84866, 'eta': 5344.4887, 'eta_hours': 1.48458, 'loss': 0.12136414, 'lr': 9.14e-05, 'params': 451793, 'time_iter': 0.06982, 'accuracy': 0.96605, 'precision': 0.64198, 'recall': 0.21104, 'f1': 0.31765, 'auc': 0.81534}
2025-08-16 10:31:27,669 - INFO - val: {'epoch': 23, 'time_epoch': 4.27254, 'loss': 0.08036899, 'lr': 0, 'params': 451793, 'time_iter': 0.03312, 'accuracy': 0.98152, 'precision': 0.59259, 'recall': 0.19753, 'f1': 0.2963, 'auc': 0.77542}
2025-08-16 10:31:32,004 - INFO - test: {'epoch': 23, 'time_epoch': 4.31606, 'loss': 0.11427976, 'lr': 0, 'params': 451793, 'time_iter': 0.03346, 'accuracy': 0.97034, 'precision': 0.55405, 'recall': 0.31538, 'f1': 0.40196, 'auc': 0.75068}
2025-08-16 10:31:32,007 - INFO - > Epoch 23: took 80.6s (avg 79.2s) | Best so far: epoch 12	train_loss: 0.1316 train_auc: 0.7761	val_loss: 0.0905 val_auc: 0.7929	test_loss: 0.1216 test_auc: 0.7641
2025-08-16 10:32:41,564 - INFO - train: {'epoch': 24, 'time_epoch': 69.47152, 'eta': 5271.61437, 'eta_hours': 1.46434, 'loss': 0.12108318, 'lr': 9.045e-05, 'params': 451793, 'time_iter': 0.06751, 'accuracy': 0.96535, 'precision': 0.61111, 'recall': 0.20536, 'f1': 0.30741, 'auc': 0.81605}
2025-08-16 10:32:45,844 - INFO - val: {'epoch': 24, 'time_epoch': 4.25762, 'loss': 0.07760943, 'lr': 0, 'params': 451793, 'time_iter': 0.033, 'accuracy': 0.98079, 'precision': 0.52941, 'recall': 0.22222, 'f1': 0.31304, 'auc': 0.79582}
2025-08-16 10:32:50,219 - INFO - test: {'epoch': 24, 'time_epoch': 4.35569, 'loss': 0.11464698, 'lr': 0, 'params': 451793, 'time_iter': 0.03377, 'accuracy': 0.96937, 'precision': 0.52381, 'recall': 0.33846, 'f1': 0.41121, 'auc': 0.75935}
2025-08-16 10:32:50,221 - INFO - > Epoch 24: took 78.2s (avg 79.1s) | Best so far: epoch 24	train_loss: 0.1211 train_auc: 0.8161	val_loss: 0.0776 val_auc: 0.7958	test_loss: 0.1146 test_auc: 0.7593
2025-08-16 10:34:00,319 - INFO - train: {'epoch': 25, 'time_epoch': 70.00844, 'eta': 5200.52996, 'eta_hours': 1.44459, 'loss': 0.12039272, 'lr': 8.946e-05, 'params': 451793, 'time_iter': 0.06804, 'accuracy': 0.96605, 'precision': 0.64198, 'recall': 0.21104, 'f1': 0.31765, 'auc': 0.81779}
2025-08-16 10:34:04,743 - INFO - val: {'epoch': 25, 'time_epoch': 4.40024, 'loss': 0.07770341, 'lr': 0, 'params': 451793, 'time_iter': 0.03411, 'accuracy': 0.98104, 'precision': 0.55556, 'recall': 0.18519, 'f1': 0.27778, 'auc': 0.77777}
2025-08-16 10:34:09,150 - INFO - test: {'epoch': 25, 'time_epoch': 4.38806, 'loss': 0.11335693, 'lr': 0, 'params': 451793, 'time_iter': 0.03402, 'accuracy': 0.97058, 'precision': 0.56716, 'recall': 0.29231, 'f1': 0.38579, 'auc': 0.76271}
2025-08-16 10:34:09,152 - INFO - > Epoch 25: took 78.9s (avg 79.1s) | Best so far: epoch 24	train_loss: 0.1211 train_auc: 0.8161	val_loss: 0.0776 val_auc: 0.7958	test_loss: 0.1146 test_auc: 0.7593
2025-08-16 10:35:19,611 - INFO - train: {'epoch': 26, 'time_epoch': 70.37063, 'eta': 5130.5045, 'eta_hours': 1.42514, 'loss': 0.1195127, 'lr': 8.842e-05, 'params': 451793, 'time_iter': 0.06839, 'accuracy': 0.96599, 'precision': 0.61945, 'recall': 0.23782, 'f1': 0.3437, 'auc': 0.81966}
2025-08-16 10:35:24,039 - INFO - val: {'epoch': 26, 'time_epoch': 4.39975, 'loss': 0.08035426, 'lr': 0, 'params': 451793, 'time_iter': 0.03411, 'accuracy': 0.97982, 'precision': 0.46875, 'recall': 0.18519, 'f1': 0.26549, 'auc': 0.78034}
2025-08-16 10:35:28,394 - INFO - test: {'epoch': 26, 'time_epoch': 4.33557, 'loss': 0.11412777, 'lr': 0, 'params': 451793, 'time_iter': 0.03361, 'accuracy': 0.96985, 'precision': 0.53261, 'recall': 0.37692, 'f1': 0.44144, 'auc': 0.76229}
2025-08-16 10:35:28,398 - INFO - > Epoch 26: took 79.2s (avg 79.1s) | Best so far: epoch 24	train_loss: 0.1211 train_auc: 0.8161	val_loss: 0.0776 val_auc: 0.7958	test_loss: 0.1146 test_auc: 0.7593
2025-08-16 10:36:37,666 - INFO - train: {'epoch': 27, 'time_epoch': 69.178, 'eta': 5057.38763, 'eta_hours': 1.40483, 'loss': 0.11901839, 'lr': 8.734e-05, 'params': 451793, 'time_iter': 0.06723, 'accuracy': 0.96568, 'precision': 0.61785, 'recall': 0.21916, 'f1': 0.32355, 'auc': 0.82569}
2025-08-16 10:36:42,062 - INFO - val: {'epoch': 27, 'time_epoch': 4.3719, 'loss': 0.07828453, 'lr': 0, 'params': 451793, 'time_iter': 0.03389, 'accuracy': 0.98006, 'precision': 0.48649, 'recall': 0.22222, 'f1': 0.30508, 'auc': 0.78432}
2025-08-16 10:36:46,465 - INFO - test: {'epoch': 27, 'time_epoch': 4.38435, 'loss': 0.11442974, 'lr': 0, 'params': 451793, 'time_iter': 0.03399, 'accuracy': 0.96937, 'precision': 0.525, 'recall': 0.32308, 'f1': 0.4, 'auc': 0.75281}
2025-08-16 10:36:46,468 - INFO - > Epoch 27: took 78.1s (avg 79.1s) | Best so far: epoch 24	train_loss: 0.1211 train_auc: 0.8161	val_loss: 0.0776 val_auc: 0.7958	test_loss: 0.1146 test_auc: 0.7593
2025-08-16 10:37:56,061 - INFO - train: {'epoch': 28, 'time_epoch': 69.50377, 'eta': 4985.33999, 'eta_hours': 1.38482, 'loss': 0.11754761, 'lr': 8.622e-05, 'params': 451793, 'time_iter': 0.06754, 'accuracy': 0.96663, 'precision': 0.64823, 'recall': 0.23782, 'f1': 0.34798, 'auc': 0.82556}
2025-08-16 10:38:00,441 - INFO - val: {'epoch': 28, 'time_epoch': 4.35247, 'loss': 0.07933725, 'lr': 0, 'params': 451793, 'time_iter': 0.03374, 'accuracy': 0.97958, 'precision': 0.46154, 'recall': 0.22222, 'f1': 0.3, 'auc': 0.77264}
2025-08-16 10:38:04,766 - INFO - test: {'epoch': 28, 'time_epoch': 4.30495, 'loss': 0.11537771, 'lr': 0, 'params': 451793, 'time_iter': 0.03337, 'accuracy': 0.96791, 'precision': 0.48936, 'recall': 0.35385, 'f1': 0.41071, 'auc': 0.76644}
2025-08-16 10:38:04,769 - INFO - > Epoch 28: took 78.3s (avg 79.1s) | Best so far: epoch 24	train_loss: 0.1211 train_auc: 0.8161	val_loss: 0.0776 val_auc: 0.7958	test_loss: 0.1146 test_auc: 0.7593
2025-08-16 10:39:14,257 - INFO - train: {'epoch': 29, 'time_epoch': 69.37348, 'eta': 4913.15793, 'eta_hours': 1.36477, 'loss': 0.11664531, 'lr': 8.506e-05, 'params': 451793, 'time_iter': 0.06742, 'accuracy': 0.96644, 'precision': 0.63008, 'recall': 0.25162, 'f1': 0.35963, 'auc': 0.82632}
2025-08-16 10:39:18,621 - INFO - val: {'epoch': 29, 'time_epoch': 4.34042, 'loss': 0.08469451, 'lr': 0, 'params': 451793, 'time_iter': 0.03365, 'accuracy': 0.97739, 'precision': 0.34211, 'recall': 0.16049, 'f1': 0.21849, 'auc': 0.79979}
2025-08-16 10:39:23,013 - INFO - test: {'epoch': 29, 'time_epoch': 4.37341, 'loss': 0.12208705, 'lr': 0, 'params': 451793, 'time_iter': 0.0339, 'accuracy': 0.96596, 'precision': 0.43056, 'recall': 0.23846, 'f1': 0.30693, 'auc': 0.75819}
2025-08-16 10:39:23,015 - INFO - > Epoch 29: took 78.2s (avg 79.0s) | Best so far: epoch 29	train_loss: 0.1166 train_auc: 0.8263	val_loss: 0.0847 val_auc: 0.7998	test_loss: 0.1221 test_auc: 0.7582
2025-08-16 10:40:32,921 - INFO - train: {'epoch': 30, 'time_epoch': 69.81889, 'eta': 4842.14845, 'eta_hours': 1.34504, 'loss': 0.1171221, 'lr': 8.386e-05, 'params': 451793, 'time_iter': 0.06785, 'accuracy': 0.96711, 'precision': 0.6589, 'recall': 0.25244, 'f1': 0.36502, 'auc': 0.83076}
2025-08-16 10:40:37,090 - INFO - val: {'epoch': 30, 'time_epoch': 4.14778, 'loss': 0.07722171, 'lr': 0, 'params': 451793, 'time_iter': 0.03215, 'accuracy': 0.98055, 'precision': 0.51429, 'recall': 0.22222, 'f1': 0.31034, 'auc': 0.79514}
2025-08-16 10:40:41,257 - INFO - test: {'epoch': 30, 'time_epoch': 4.1506, 'loss': 0.1151595, 'lr': 0, 'params': 451793, 'time_iter': 0.03218, 'accuracy': 0.96985, 'precision': 0.53409, 'recall': 0.36154, 'f1': 0.43119, 'auc': 0.75982}
2025-08-16 10:40:41,259 - INFO - > Epoch 30: took 78.2s (avg 79.0s) | Best so far: epoch 29	train_loss: 0.1166 train_auc: 0.8263	val_loss: 0.0847 val_auc: 0.7998	test_loss: 0.1221 test_auc: 0.7582
2025-08-16 10:41:48,739 - INFO - train: {'epoch': 31, 'time_epoch': 67.39268, 'eta': 4766.05771, 'eta_hours': 1.3239, 'loss': 0.11558594, 'lr': 8.263e-05, 'params': 451793, 'time_iter': 0.06549, 'accuracy': 0.96784, 'precision': 0.67611, 'recall': 0.2711, 'f1': 0.38702, 'auc': 0.82816}
2025-08-16 10:41:53,078 - INFO - val: {'epoch': 31, 'time_epoch': 4.31501, 'loss': 0.07419004, 'lr': 0, 'params': 451793, 'time_iter': 0.03345, 'accuracy': 0.98274, 'precision': 0.69231, 'recall': 0.22222, 'f1': 0.33645, 'auc': 0.79847}
2025-08-16 10:41:57,429 - INFO - test: {'epoch': 31, 'time_epoch': 4.33197, 'loss': 0.11134283, 'lr': 0, 'params': 451793, 'time_iter': 0.03358, 'accuracy': 0.96985, 'precision': 0.54688, 'recall': 0.26923, 'f1': 0.36082, 'auc': 0.76102}
2025-08-16 10:41:57,432 - INFO - > Epoch 31: took 76.2s (avg 78.9s) | Best so far: epoch 29	train_loss: 0.1166 train_auc: 0.8263	val_loss: 0.0847 val_auc: 0.7998	test_loss: 0.1221 test_auc: 0.7582
2025-08-16 10:43:04,842 - INFO - train: {'epoch': 32, 'time_epoch': 67.32683, 'eta': 4690.3604, 'eta_hours': 1.30288, 'loss': 0.11567167, 'lr': 8.136e-05, 'params': 451793, 'time_iter': 0.06543, 'accuracy': 0.96693, 'precision': 0.64173, 'recall': 0.26461, 'f1': 0.37471, 'auc': 0.8331}
2025-08-16 10:43:09,082 - INFO - val: {'epoch': 32, 'time_epoch': 4.21737, 'loss': 0.0834029, 'lr': 0, 'params': 451793, 'time_iter': 0.03269, 'accuracy': 0.97982, 'precision': 0.48148, 'recall': 0.32099, 'f1': 0.38519, 'auc': 0.7839}
2025-08-16 10:43:13,375 - INFO - test: {'epoch': 32, 'time_epoch': 4.27558, 'loss': 0.12246856, 'lr': 0, 'params': 451793, 'time_iter': 0.03314, 'accuracy': 0.9662, 'precision': 0.46087, 'recall': 0.40769, 'f1': 0.43265, 'auc': 0.76294}
2025-08-16 10:43:13,378 - INFO - > Epoch 32: took 75.9s (avg 78.8s) | Best so far: epoch 29	train_loss: 0.1166 train_auc: 0.8263	val_loss: 0.0847 val_auc: 0.7998	test_loss: 0.1221 test_auc: 0.7582
2025-08-16 10:44:20,201 - INFO - train: {'epoch': 33, 'time_epoch': 66.74309, 'eta': 4614.02235, 'eta_hours': 1.28167, 'loss': 0.11357738, 'lr': 8.005e-05, 'params': 451793, 'time_iter': 0.06486, 'accuracy': 0.96809, 'precision': 0.67636, 'recall': 0.28328, 'f1': 0.39931, 'auc': 0.83923}
2025-08-16 10:44:24,301 - INFO - val: {'epoch': 33, 'time_epoch': 4.07832, 'loss': 0.07426724, 'lr': 0, 'params': 451793, 'time_iter': 0.03161, 'accuracy': 0.98079, 'precision': 0.53125, 'recall': 0.20988, 'f1': 0.30088, 'auc': 0.80209}
2025-08-16 10:44:28,378 - INFO - test: {'epoch': 33, 'time_epoch': 4.06046, 'loss': 0.11190603, 'lr': 0, 'params': 451793, 'time_iter': 0.03148, 'accuracy': 0.97009, 'precision': 0.54667, 'recall': 0.31538, 'f1': 0.4, 'auc': 0.75783}
2025-08-16 10:44:28,381 - INFO - > Epoch 33: took 75.0s (avg 78.7s) | Best so far: epoch 33	train_loss: 0.1136 train_auc: 0.8392	val_loss: 0.0743 val_auc: 0.8021	test_loss: 0.1119 test_auc: 0.7578
2025-08-16 10:45:35,450 - INFO - train: {'epoch': 34, 'time_epoch': 66.9873, 'eta': 4538.68611, 'eta_hours': 1.26075, 'loss': 0.11469442, 'lr': 7.872e-05, 'params': 451793, 'time_iter': 0.0651, 'accuracy': 0.9666, 'precision': 0.63221, 'recall': 0.25812, 'f1': 0.36657, 'auc': 0.83706}
2025-08-16 10:45:39,753 - INFO - val: {'epoch': 34, 'time_epoch': 4.27862, 'loss': 0.07873504, 'lr': 0, 'params': 451793, 'time_iter': 0.03317, 'accuracy': 0.98006, 'precision': 0.4878, 'recall': 0.24691, 'f1': 0.32787, 'auc': 0.77386}
2025-08-16 10:45:44,096 - INFO - test: {'epoch': 34, 'time_epoch': 4.32347, 'loss': 0.11299808, 'lr': 0, 'params': 451793, 'time_iter': 0.03352, 'accuracy': 0.96985, 'precision': 0.53488, 'recall': 0.35385, 'f1': 0.42593, 'auc': 0.76178}
2025-08-16 10:45:44,099 - INFO - > Epoch 34: took 75.7s (avg 78.6s) | Best so far: epoch 33	train_loss: 0.1136 train_auc: 0.8392	val_loss: 0.0743 val_auc: 0.8021	test_loss: 0.1119 test_auc: 0.7578
2025-08-16 10:46:51,666 - INFO - train: {'epoch': 35, 'time_epoch': 67.48228, 'eta': 4464.69365, 'eta_hours': 1.24019, 'loss': 0.11338077, 'lr': 7.735e-05, 'params': 451793, 'time_iter': 0.06558, 'accuracy': 0.96809, 'precision': 0.68127, 'recall': 0.2776, 'f1': 0.39446, 'auc': 0.83865}
2025-08-16 10:46:56,019 - INFO - val: {'epoch': 35, 'time_epoch': 4.32747, 'loss': 0.07389555, 'lr': 0, 'params': 451793, 'time_iter': 0.03355, 'accuracy': 0.98225, 'precision': 0.625, 'recall': 0.24691, 'f1': 0.35398, 'auc': 0.79912}
2025-08-16 10:47:00,331 - INFO - test: {'epoch': 35, 'time_epoch': 4.29277, 'loss': 0.11333509, 'lr': 0, 'params': 451793, 'time_iter': 0.03328, 'accuracy': 0.97034, 'precision': 0.55556, 'recall': 0.30769, 'f1': 0.39604, 'auc': 0.75459}
2025-08-16 10:47:00,333 - INFO - > Epoch 35: took 76.2s (avg 78.6s) | Best so far: epoch 33	train_loss: 0.1136 train_auc: 0.8392	val_loss: 0.0743 val_auc: 0.8021	test_loss: 0.1119 test_auc: 0.7578
2025-08-16 10:48:07,992 - INFO - train: {'epoch': 36, 'time_epoch': 67.57647, 'eta': 4391.21349, 'eta_hours': 1.21978, 'loss': 0.11277466, 'lr': 7.595e-05, 'params': 451793, 'time_iter': 0.06567, 'accuracy': 0.96766, 'precision': 0.66092, 'recall': 0.28003, 'f1': 0.39339, 'auc': 0.84208}
2025-08-16 10:48:12,215 - INFO - val: {'epoch': 36, 'time_epoch': 4.20015, 'loss': 0.07856258, 'lr': 0, 'params': 451793, 'time_iter': 0.03256, 'accuracy': 0.98225, 'precision': 0.58696, 'recall': 0.33333, 'f1': 0.4252, 'auc': 0.78421}
2025-08-16 10:48:16,504 - INFO - test: {'epoch': 36, 'time_epoch': 4.27146, 'loss': 0.11902576, 'lr': 0, 'params': 451793, 'time_iter': 0.03311, 'accuracy': 0.96548, 'precision': 0.43023, 'recall': 0.28462, 'f1': 0.34259, 'auc': 0.73268}
2025-08-16 10:48:16,507 - INFO - > Epoch 36: took 76.2s (avg 78.5s) | Best so far: epoch 33	train_loss: 0.1136 train_auc: 0.8392	val_loss: 0.0743 val_auc: 0.8021	test_loss: 0.1119 test_auc: 0.7578
2025-08-16 10:49:24,146 - INFO - train: {'epoch': 37, 'time_epoch': 67.55279, 'eta': 4318.0054, 'eta_hours': 1.19945, 'loss': 0.11140194, 'lr': 7.452e-05, 'params': 451793, 'time_iter': 0.06565, 'accuracy': 0.96806, 'precision': 0.68064, 'recall': 0.27679, 'f1': 0.39354, 'auc': 0.84609}
2025-08-16 10:49:28,417 - INFO - val: {'epoch': 37, 'time_epoch': 4.24567, 'loss': 0.07703508, 'lr': 0, 'params': 451793, 'time_iter': 0.03291, 'accuracy': 0.98249, 'precision': 0.65517, 'recall': 0.23457, 'f1': 0.34545, 'auc': 0.77814}
2025-08-16 10:49:32,672 - INFO - test: {'epoch': 37, 'time_epoch': 4.23618, 'loss': 0.11652325, 'lr': 0, 'params': 451793, 'time_iter': 0.03284, 'accuracy': 0.97107, 'precision': 0.56962, 'recall': 0.34615, 'f1': 0.43062, 'auc': 0.72774}
2025-08-16 10:49:32,675 - INFO - > Epoch 37: took 76.2s (avg 78.4s) | Best so far: epoch 33	train_loss: 0.1136 train_auc: 0.8392	val_loss: 0.0743 val_auc: 0.8021	test_loss: 0.1119 test_auc: 0.7578
2025-08-16 10:50:39,852 - INFO - train: {'epoch': 38, 'time_epoch': 67.0915, 'eta': 4244.36583, 'eta_hours': 1.17899, 'loss': 0.11193158, 'lr': 7.307e-05, 'params': 451793, 'time_iter': 0.0652, 'accuracy': 0.96848, 'precision': 0.68571, 'recall': 0.29221, 'f1': 0.40979, 'auc': 0.84389}
2025-08-16 10:50:44,155 - INFO - val: {'epoch': 38, 'time_epoch': 4.28002, 'loss': 0.08218569, 'lr': 0, 'params': 451793, 'time_iter': 0.03318, 'accuracy': 0.97885, 'precision': 0.45, 'recall': 0.33333, 'f1': 0.38298, 'auc': 0.80513}
2025-08-16 10:50:48,456 - INFO - test: {'epoch': 38, 'time_epoch': 4.28302, 'loss': 0.12150822, 'lr': 0, 'params': 451793, 'time_iter': 0.0332, 'accuracy': 0.96669, 'precision': 0.47107, 'recall': 0.43846, 'f1': 0.45418, 'auc': 0.76309}
2025-08-16 10:50:48,458 - INFO - > Epoch 38: took 75.8s (avg 78.4s) | Best so far: epoch 38	train_loss: 0.1119 train_auc: 0.8439	val_loss: 0.0822 val_auc: 0.8051	test_loss: 0.1215 test_auc: 0.7631
2025-08-16 10:51:56,000 - INFO - train: {'epoch': 39, 'time_epoch': 67.45423, 'eta': 4171.59775, 'eta_hours': 1.15878, 'loss': 0.11121653, 'lr': 7.159e-05, 'params': 451793, 'time_iter': 0.06555, 'accuracy': 0.96839, 'precision': 0.67647, 'recall': 0.2987, 'f1': 0.41441, 'auc': 0.84819}
2025-08-16 10:52:00,358 - INFO - val: {'epoch': 39, 'time_epoch': 4.33182, 'loss': 0.07290055, 'lr': 0, 'params': 451793, 'time_iter': 0.03358, 'accuracy': 0.98249, 'precision': 0.63636, 'recall': 0.25926, 'f1': 0.36842, 'auc': 0.80991}
2025-08-16 10:52:04,695 - INFO - test: {'epoch': 39, 'time_epoch': 4.31811, 'loss': 0.11133221, 'lr': 0, 'params': 451793, 'time_iter': 0.03347, 'accuracy': 0.97204, 'precision': 0.61194, 'recall': 0.31538, 'f1': 0.41624, 'auc': 0.75753}
2025-08-16 10:52:04,707 - INFO - > Epoch 39: took 76.2s (avg 78.3s) | Best so far: epoch 39	train_loss: 0.1112 train_auc: 0.8482	val_loss: 0.0729 val_auc: 0.8099	test_loss: 0.1113 test_auc: 0.7575
2025-08-16 10:53:11,256 - INFO - train: {'epoch': 40, 'time_epoch': 66.46399, 'eta': 4097.66391, 'eta_hours': 1.13824, 'loss': 0.10998972, 'lr': 7.008e-05, 'params': 451793, 'time_iter': 0.06459, 'accuracy': 0.96775, 'precision': 0.65241, 'recall': 0.29708, 'f1': 0.40825, 'auc': 0.85174}
2025-08-16 10:53:15,503 - INFO - val: {'epoch': 40, 'time_epoch': 4.22511, 'loss': 0.07606623, 'lr': 0, 'params': 451793, 'time_iter': 0.03275, 'accuracy': 0.98249, 'precision': 0.61538, 'recall': 0.2963, 'f1': 0.4, 'auc': 0.77649}
2025-08-16 10:53:19,724 - INFO - test: {'epoch': 40, 'time_epoch': 4.20386, 'loss': 0.11592946, 'lr': 0, 'params': 451793, 'time_iter': 0.03259, 'accuracy': 0.96985, 'precision': 0.53571, 'recall': 0.34615, 'f1': 0.42056, 'auc': 0.74633}
2025-08-16 10:53:19,726 - INFO - > Epoch 40: took 75.0s (avg 78.2s) | Best so far: epoch 39	train_loss: 0.1112 train_auc: 0.8482	val_loss: 0.0729 val_auc: 0.8099	test_loss: 0.1113 test_auc: 0.7575
2025-08-16 10:54:26,190 - INFO - train: {'epoch': 41, 'time_epoch': 66.37474, 'eta': 4023.96253, 'eta_hours': 1.11777, 'loss': 0.11049425, 'lr': 6.856e-05, 'params': 451793, 'time_iter': 0.0645, 'accuracy': 0.96839, 'precision': 0.68113, 'recall': 0.29302, 'f1': 0.40976, 'auc': 0.84855}
2025-08-16 10:54:30,567 - INFO - val: {'epoch': 41, 'time_epoch': 4.34985, 'loss': 0.0732243, 'lr': 0, 'params': 451793, 'time_iter': 0.03372, 'accuracy': 0.98177, 'precision': 0.57143, 'recall': 0.2963, 'f1': 0.39024, 'auc': 0.8005}
2025-08-16 10:54:34,838 - INFO - test: {'epoch': 41, 'time_epoch': 4.25256, 'loss': 0.11756044, 'lr': 0, 'params': 451793, 'time_iter': 0.03297, 'accuracy': 0.96937, 'precision': 0.52273, 'recall': 0.35385, 'f1': 0.42202, 'auc': 0.74129}
2025-08-16 10:54:34,841 - INFO - > Epoch 41: took 75.1s (avg 78.2s) | Best so far: epoch 39	train_loss: 0.1112 train_auc: 0.8482	val_loss: 0.0729 val_auc: 0.8099	test_loss: 0.1113 test_auc: 0.7575
2025-08-16 10:55:41,161 - INFO - train: {'epoch': 42, 'time_epoch': 66.22904, 'eta': 3950.40878, 'eta_hours': 1.09734, 'loss': 0.10933907, 'lr': 6.701e-05, 'params': 451793, 'time_iter': 0.06436, 'accuracy': 0.96848, 'precision': 0.67442, 'recall': 0.30601, 'f1': 0.42099, 'auc': 0.85253}
2025-08-16 10:55:45,469 - INFO - val: {'epoch': 42, 'time_epoch': 4.2851, 'loss': 0.0730227, 'lr': 0, 'params': 451793, 'time_iter': 0.03322, 'accuracy': 0.98249, 'precision': 0.65517, 'recall': 0.23457, 'f1': 0.34545, 'auc': 0.81067}
2025-08-16 10:55:49,757 - INFO - test: {'epoch': 42, 'time_epoch': 4.26979, 'loss': 0.11519785, 'lr': 0, 'params': 451793, 'time_iter': 0.0331, 'accuracy': 0.96937, 'precision': 0.52857, 'recall': 0.28462, 'f1': 0.37, 'auc': 0.75129}
2025-08-16 10:55:49,759 - INFO - > Epoch 42: took 74.9s (avg 78.1s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 10:56:55,640 - INFO - train: {'epoch': 43, 'time_epoch': 65.79318, 'eta': 3876.63325, 'eta_hours': 1.07684, 'loss': 0.10797394, 'lr': 6.545e-05, 'params': 451793, 'time_iter': 0.06394, 'accuracy': 0.96927, 'precision': 0.69982, 'recall': 0.31412, 'f1': 0.43361, 'auc': 0.85342}
2025-08-16 10:56:59,823 - INFO - val: {'epoch': 43, 'time_epoch': 4.15851, 'loss': 0.07678855, 'lr': 0, 'params': 451793, 'time_iter': 0.03224, 'accuracy': 0.98152, 'precision': 0.58065, 'recall': 0.22222, 'f1': 0.32143, 'auc': 0.79443}
2025-08-16 10:57:03,989 - INFO - test: {'epoch': 43, 'time_epoch': 4.14854, 'loss': 0.11532479, 'lr': 0, 'params': 451793, 'time_iter': 0.03216, 'accuracy': 0.96888, 'precision': 0.51316, 'recall': 0.3, 'f1': 0.37864, 'auc': 0.74588}
2025-08-16 10:57:03,992 - INFO - > Epoch 43: took 74.2s (avg 78.0s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 10:58:11,312 - INFO - train: {'epoch': 44, 'time_epoch': 67.2381, 'eta': 3804.9785, 'eta_hours': 1.05694, 'loss': 0.10907923, 'lr': 6.387e-05, 'params': 451793, 'time_iter': 0.06534, 'accuracy': 0.96994, 'precision': 0.71658, 'recall': 0.3263, 'f1': 0.44841, 'auc': 0.84699}
2025-08-16 10:58:15,607 - INFO - val: {'epoch': 44, 'time_epoch': 4.2696, 'loss': 0.07356651, 'lr': 0, 'params': 451793, 'time_iter': 0.0331, 'accuracy': 0.98249, 'precision': 0.60465, 'recall': 0.32099, 'f1': 0.41935, 'auc': 0.79561}
2025-08-16 10:58:19,883 - INFO - test: {'epoch': 44, 'time_epoch': 4.25694, 'loss': 0.11685156, 'lr': 0, 'params': 451793, 'time_iter': 0.033, 'accuracy': 0.97034, 'precision': 0.55, 'recall': 0.33846, 'f1': 0.41905, 'auc': 0.74276}
2025-08-16 10:58:19,886 - INFO - > Epoch 44: took 75.9s (avg 78.0s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 10:59:26,331 - INFO - train: {'epoch': 45, 'time_epoch': 66.36308, 'eta': 3732.48858, 'eta_hours': 1.0368, 'loss': 0.10803406, 'lr': 6.227e-05, 'params': 451793, 'time_iter': 0.06449, 'accuracy': 0.96964, 'precision': 0.71455, 'recall': 0.31494, 'f1': 0.43718, 'auc': 0.85653}
2025-08-16 10:59:30,444 - INFO - val: {'epoch': 45, 'time_epoch': 4.09154, 'loss': 0.07874433, 'lr': 0, 'params': 451793, 'time_iter': 0.03172, 'accuracy': 0.9786, 'precision': 0.4186, 'recall': 0.22222, 'f1': 0.29032, 'auc': 0.79445}
2025-08-16 10:59:34,756 - INFO - test: {'epoch': 45, 'time_epoch': 4.29417, 'loss': 0.12258012, 'lr': 0, 'params': 451793, 'time_iter': 0.03329, 'accuracy': 0.96864, 'precision': 0.50602, 'recall': 0.32308, 'f1': 0.39437, 'auc': 0.73364}
2025-08-16 10:59:34,758 - INFO - > Epoch 45: took 74.9s (avg 77.9s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:00:42,293 - INFO - train: {'epoch': 46, 'time_epoch': 67.44624, 'eta': 3661.48082, 'eta_hours': 1.01708, 'loss': 0.10749541, 'lr': 6.066e-05, 'params': 451793, 'time_iter': 0.06555, 'accuracy': 0.96869, 'precision': 0.68773, 'recall': 0.30032, 'f1': 0.41808, 'auc': 0.8651}
2025-08-16 11:00:46,526 - INFO - val: {'epoch': 46, 'time_epoch': 4.2081, 'loss': 0.07522187, 'lr': 0, 'params': 451793, 'time_iter': 0.03262, 'accuracy': 0.98006, 'precision': 0.48936, 'recall': 0.28395, 'f1': 0.35938, 'auc': 0.79552}
2025-08-16 11:00:50,683 - INFO - test: {'epoch': 46, 'time_epoch': 4.13887, 'loss': 0.11809932, 'lr': 0, 'params': 451793, 'time_iter': 0.03208, 'accuracy': 0.96791, 'precision': 0.4881, 'recall': 0.31538, 'f1': 0.38318, 'auc': 0.75436}
2025-08-16 11:00:50,686 - INFO - > Epoch 46: took 75.9s (avg 77.8s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:01:57,915 - INFO - train: {'epoch': 47, 'time_epoch': 67.14666, 'eta': 3590.2969, 'eta_hours': 0.9973, 'loss': 0.10684672, 'lr': 5.904e-05, 'params': 451793, 'time_iter': 0.06525, 'accuracy': 0.96912, 'precision': 0.69495, 'recall': 0.3125, 'f1': 0.43113, 'auc': 0.86084}
2025-08-16 11:02:02,055 - INFO - val: {'epoch': 47, 'time_epoch': 4.11813, 'loss': 0.07596088, 'lr': 0, 'params': 451793, 'time_iter': 0.03192, 'accuracy': 0.98225, 'precision': 0.625, 'recall': 0.24691, 'f1': 0.35398, 'auc': 0.78421}
2025-08-16 11:02:06,189 - INFO - test: {'epoch': 47, 'time_epoch': 4.11719, 'loss': 0.11507373, 'lr': 0, 'params': 451793, 'time_iter': 0.03192, 'accuracy': 0.96985, 'precision': 0.54412, 'recall': 0.28462, 'f1': 0.37374, 'auc': 0.74118}
2025-08-16 11:02:06,192 - INFO - > Epoch 47: took 75.5s (avg 77.8s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:03:11,804 - INFO - train: {'epoch': 48, 'time_epoch': 65.53191, 'eta': 3517.59711, 'eta_hours': 0.97711, 'loss': 0.10637339, 'lr': 5.741e-05, 'params': 451793, 'time_iter': 0.06369, 'accuracy': 0.96951, 'precision': 0.69913, 'recall': 0.3263, 'f1': 0.44494, 'auc': 0.86267}
2025-08-16 11:03:15,906 - INFO - val: {'epoch': 48, 'time_epoch': 4.08144, 'loss': 0.07844062, 'lr': 0, 'params': 451793, 'time_iter': 0.03164, 'accuracy': 0.98079, 'precision': 0.52083, 'recall': 0.30864, 'f1': 0.3876, 'auc': 0.79108}
2025-08-16 11:03:20,006 - INFO - test: {'epoch': 48, 'time_epoch': 4.084, 'loss': 0.12420211, 'lr': 0, 'params': 451793, 'time_iter': 0.03166, 'accuracy': 0.96693, 'precision': 0.47115, 'recall': 0.37692, 'f1': 0.4188, 'auc': 0.75285}
2025-08-16 11:03:20,008 - INFO - > Epoch 48: took 73.8s (avg 77.7s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:04:27,317 - INFO - train: {'epoch': 49, 'time_epoch': 67.22177, 'eta': 3446.8739, 'eta_hours': 0.95746, 'loss': 0.10636224, 'lr': 5.577e-05, 'params': 451793, 'time_iter': 0.06533, 'accuracy': 0.9693, 'precision': 0.68687, 'recall': 0.33117, 'f1': 0.44688, 'auc': 0.86198}
2025-08-16 11:04:31,650 - INFO - val: {'epoch': 49, 'time_epoch': 4.3106, 'loss': 0.07418273, 'lr': 0, 'params': 451793, 'time_iter': 0.03342, 'accuracy': 0.98249, 'precision': 0.61538, 'recall': 0.2963, 'f1': 0.4, 'auc': 0.78844}
2025-08-16 11:04:35,912 - INFO - test: {'epoch': 49, 'time_epoch': 4.24471, 'loss': 0.11806098, 'lr': 0, 'params': 451793, 'time_iter': 0.0329, 'accuracy': 0.96937, 'precision': 0.52174, 'recall': 0.36923, 'f1': 0.43243, 'auc': 0.75892}
2025-08-16 11:04:35,914 - INFO - > Epoch 49: took 75.9s (avg 77.7s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:05:43,341 - INFO - train: {'epoch': 50, 'time_epoch': 67.34512, 'eta': 3376.4065, 'eta_hours': 0.93789, 'loss': 0.10632114, 'lr': 5.413e-05, 'params': 451793, 'time_iter': 0.06545, 'accuracy': 0.96967, 'precision': 0.70172, 'recall': 0.33036, 'f1': 0.44923, 'auc': 0.85853}
2025-08-16 11:05:47,476 - INFO - val: {'epoch': 50, 'time_epoch': 4.11369, 'loss': 0.0765989, 'lr': 0, 'params': 451793, 'time_iter': 0.03189, 'accuracy': 0.98006, 'precision': 0.48889, 'recall': 0.2716, 'f1': 0.34921, 'auc': 0.79102}
2025-08-16 11:05:51,613 - INFO - test: {'epoch': 50, 'time_epoch': 4.11952, 'loss': 0.11536706, 'lr': 0, 'params': 451793, 'time_iter': 0.03193, 'accuracy': 0.97034, 'precision': 0.54651, 'recall': 0.36154, 'f1': 0.43519, 'auc': 0.76031}
2025-08-16 11:05:51,616 - INFO - > Epoch 50: took 75.7s (avg 77.6s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:06:58,068 - INFO - train: {'epoch': 51, 'time_epoch': 66.37001, 'eta': 3305.1591, 'eta_hours': 0.9181, 'loss': 0.10518484, 'lr': 5.248e-05, 'params': 451793, 'time_iter': 0.0645, 'accuracy': 0.96979, 'precision': 0.71636, 'recall': 0.31981, 'f1': 0.4422, 'auc': 0.86845}
2025-08-16 11:07:02,313 - INFO - val: {'epoch': 51, 'time_epoch': 4.22295, 'loss': 0.07733236, 'lr': 0, 'params': 451793, 'time_iter': 0.03274, 'accuracy': 0.98177, 'precision': 0.56818, 'recall': 0.30864, 'f1': 0.4, 'auc': 0.768}
2025-08-16 11:07:06,541 - INFO - test: {'epoch': 51, 'time_epoch': 4.20975, 'loss': 0.11951233, 'lr': 0, 'params': 451793, 'time_iter': 0.03263, 'accuracy': 0.97009, 'precision': 0.54118, 'recall': 0.35385, 'f1': 0.42791, 'auc': 0.75364}
2025-08-16 11:07:06,544 - INFO - > Epoch 51: took 74.9s (avg 77.6s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:08:13,337 - INFO - train: {'epoch': 52, 'time_epoch': 66.71158, 'eta': 3234.39865, 'eta_hours': 0.89844, 'loss': 0.10477745, 'lr': 5.083e-05, 'params': 451793, 'time_iter': 0.06483, 'accuracy': 0.97049, 'precision': 0.72384, 'recall': 0.34253, 'f1': 0.46501, 'auc': 0.867}
2025-08-16 11:08:17,367 - INFO - val: {'epoch': 52, 'time_epoch': 4.00858, 'loss': 0.07389686, 'lr': 0, 'params': 451793, 'time_iter': 0.03107, 'accuracy': 0.98201, 'precision': 0.58974, 'recall': 0.28395, 'f1': 0.38333, 'auc': 0.78404}
2025-08-16 11:08:21,491 - INFO - test: {'epoch': 52, 'time_epoch': 4.10664, 'loss': 0.11426441, 'lr': 0, 'params': 451793, 'time_iter': 0.03183, 'accuracy': 0.97009, 'precision': 0.55224, 'recall': 0.28462, 'f1': 0.37563, 'auc': 0.7563}
2025-08-16 11:08:21,494 - INFO - > Epoch 52: took 74.9s (avg 77.5s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:09:29,054 - INFO - train: {'epoch': 53, 'time_epoch': 67.47282, 'eta': 3164.43662, 'eta_hours': 0.87901, 'loss': 0.10513944, 'lr': 4.917e-05, 'params': 451793, 'time_iter': 0.06557, 'accuracy': 0.97012, 'precision': 0.71429, 'recall': 0.33685, 'f1': 0.4578, 'auc': 0.86395}
2025-08-16 11:09:33,357 - INFO - val: {'epoch': 53, 'time_epoch': 4.27915, 'loss': 0.06922748, 'lr': 0, 'params': 451793, 'time_iter': 0.03317, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.79675}
2025-08-16 11:09:37,648 - INFO - test: {'epoch': 53, 'time_epoch': 4.27426, 'loss': 0.11463343, 'lr': 0, 'params': 451793, 'time_iter': 0.03313, 'accuracy': 0.97228, 'precision': 0.61429, 'recall': 0.33077, 'f1': 0.43, 'auc': 0.74374}
2025-08-16 11:09:37,650 - INFO - > Epoch 53: took 76.2s (avg 77.5s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:10:43,823 - INFO - train: {'epoch': 54, 'time_epoch': 66.08773, 'eta': 3093.43185, 'eta_hours': 0.85929, 'loss': 0.10378472, 'lr': 4.752e-05, 'params': 451793, 'time_iter': 0.06423, 'accuracy': 0.97009, 'precision': 0.71088, 'recall': 0.33929, 'f1': 0.45934, 'auc': 0.86834}
2025-08-16 11:10:48,019 - INFO - val: {'epoch': 54, 'time_epoch': 4.16999, 'loss': 0.07541043, 'lr': 0, 'params': 451793, 'time_iter': 0.03233, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.30864, 'f1': 0.38168, 'auc': 0.80203}
2025-08-16 11:10:52,183 - INFO - test: {'epoch': 54, 'time_epoch': 4.14546, 'loss': 0.12150411, 'lr': 0, 'params': 451793, 'time_iter': 0.03214, 'accuracy': 0.96645, 'precision': 0.45833, 'recall': 0.33846, 'f1': 0.38938, 'auc': 0.74809}
2025-08-16 11:10:52,186 - INFO - > Epoch 54: took 74.5s (avg 77.5s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:11:58,687 - INFO - train: {'epoch': 55, 'time_epoch': 66.41827, 'eta': 3022.8624, 'eta_hours': 0.83968, 'loss': 0.10294441, 'lr': 4.587e-05, 'params': 451793, 'time_iter': 0.06455, 'accuracy': 0.97052, 'precision': 0.71761, 'recall': 0.35065, 'f1': 0.4711, 'auc': 0.875}
2025-08-16 11:12:03,019 - INFO - val: {'epoch': 55, 'time_epoch': 4.30701, 'loss': 0.07280441, 'lr': 0, 'params': 451793, 'time_iter': 0.03339, 'accuracy': 0.98249, 'precision': 0.62857, 'recall': 0.2716, 'f1': 0.37931, 'auc': 0.79134}
2025-08-16 11:12:07,346 - INFO - test: {'epoch': 55, 'time_epoch': 4.30813, 'loss': 0.11723633, 'lr': 0, 'params': 451793, 'time_iter': 0.0334, 'accuracy': 0.96961, 'precision': 0.53165, 'recall': 0.32308, 'f1': 0.40191, 'auc': 0.74466}
2025-08-16 11:12:07,348 - INFO - > Epoch 55: took 75.2s (avg 77.4s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:13:13,757 - INFO - train: {'epoch': 56, 'time_epoch': 66.32581, 'eta': 2952.36886, 'eta_hours': 0.8201, 'loss': 0.10292106, 'lr': 4.423e-05, 'params': 451793, 'time_iter': 0.06446, 'accuracy': 0.96994, 'precision': 0.7042, 'recall': 0.3401, 'f1': 0.45868, 'auc': 0.87398}
2025-08-16 11:13:18,012 - INFO - val: {'epoch': 56, 'time_epoch': 4.23047, 'loss': 0.07195951, 'lr': 0, 'params': 451793, 'time_iter': 0.03279, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.79931}
2025-08-16 11:13:22,259 - INFO - test: {'epoch': 56, 'time_epoch': 4.22787, 'loss': 0.11842728, 'lr': 0, 'params': 451793, 'time_iter': 0.03277, 'accuracy': 0.97082, 'precision': 0.56098, 'recall': 0.35385, 'f1': 0.43396, 'auc': 0.74488}
2025-08-16 11:13:22,261 - INFO - > Epoch 56: took 74.9s (avg 77.4s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:14:29,201 - INFO - train: {'epoch': 57, 'time_epoch': 66.85354, 'eta': 2882.40118, 'eta_hours': 0.80067, 'loss': 0.10356541, 'lr': 4.259e-05, 'params': 451793, 'time_iter': 0.06497, 'accuracy': 0.9703, 'precision': 0.71647, 'recall': 0.34253, 'f1': 0.46348, 'auc': 0.87148}
2025-08-16 11:14:33,284 - INFO - val: {'epoch': 57, 'time_epoch': 4.05909, 'loss': 0.07509563, 'lr': 0, 'params': 451793, 'time_iter': 0.03147, 'accuracy': 0.98177, 'precision': 0.56818, 'recall': 0.30864, 'f1': 0.4, 'auc': 0.78851}
2025-08-16 11:14:37,348 - INFO - test: {'epoch': 57, 'time_epoch': 4.04644, 'loss': 0.12033266, 'lr': 0, 'params': 451793, 'time_iter': 0.03137, 'accuracy': 0.96864, 'precision': 0.50538, 'recall': 0.36154, 'f1': 0.42152, 'auc': 0.75032}
2025-08-16 11:14:37,350 - INFO - > Epoch 57: took 75.1s (avg 77.3s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:15:43,300 - INFO - train: {'epoch': 58, 'time_epoch': 65.86688, 'eta': 2811.85341, 'eta_hours': 0.78107, 'loss': 0.10232185, 'lr': 4.096e-05, 'params': 451793, 'time_iter': 0.06401, 'accuracy': 0.97097, 'precision': 0.72893, 'recall': 0.35795, 'f1': 0.48013, 'auc': 0.87738}
2025-08-16 11:15:47,583 - INFO - val: {'epoch': 58, 'time_epoch': 4.2607, 'loss': 0.07102749, 'lr': 0, 'params': 451793, 'time_iter': 0.03303, 'accuracy': 0.98395, 'precision': 0.72727, 'recall': 0.2963, 'f1': 0.42105, 'auc': 0.79213}
2025-08-16 11:15:51,853 - INFO - test: {'epoch': 58, 'time_epoch': 4.25189, 'loss': 0.11791038, 'lr': 0, 'params': 451793, 'time_iter': 0.03296, 'accuracy': 0.96937, 'precision': 0.52326, 'recall': 0.34615, 'f1': 0.41667, 'auc': 0.74883}
2025-08-16 11:15:51,855 - INFO - > Epoch 58: took 74.5s (avg 77.3s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:16:57,614 - INFO - train: {'epoch': 59, 'time_epoch': 65.67245, 'eta': 2741.33206, 'eta_hours': 0.76148, 'loss': 0.10304946, 'lr': 3.934e-05, 'params': 451793, 'time_iter': 0.06382, 'accuracy': 0.97027, 'precision': 0.71897, 'recall': 0.33847, 'f1': 0.46026, 'auc': 0.87515}
2025-08-16 11:17:01,859 - INFO - val: {'epoch': 59, 'time_epoch': 4.22104, 'loss': 0.07617129, 'lr': 0, 'params': 451793, 'time_iter': 0.03272, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.25926, 'f1': 0.34146, 'auc': 0.78741}
2025-08-16 11:17:06,006 - INFO - test: {'epoch': 59, 'time_epoch': 4.13032, 'loss': 0.12099627, 'lr': 0, 'params': 451793, 'time_iter': 0.03202, 'accuracy': 0.96888, 'precision': 0.5122, 'recall': 0.32308, 'f1': 0.39623, 'auc': 0.7414}
2025-08-16 11:17:06,009 - INFO - > Epoch 59: took 74.2s (avg 77.2s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:18:12,486 - INFO - train: {'epoch': 60, 'time_epoch': 66.39382, 'eta': 2671.43089, 'eta_hours': 0.74206, 'loss': 0.10201748, 'lr': 3.773e-05, 'params': 451793, 'time_iter': 0.06452, 'accuracy': 0.97058, 'precision': 0.71711, 'recall': 0.3539, 'f1': 0.47391, 'auc': 0.87933}
2025-08-16 11:18:16,724 - INFO - val: {'epoch': 60, 'time_epoch': 4.21314, 'loss': 0.07717262, 'lr': 0, 'params': 451793, 'time_iter': 0.03266, 'accuracy': 0.97958, 'precision': 0.47059, 'recall': 0.2963, 'f1': 0.36364, 'auc': 0.78375}
2025-08-16 11:18:20,940 - INFO - test: {'epoch': 60, 'time_epoch': 4.19791, 'loss': 0.12140914, 'lr': 0, 'params': 451793, 'time_iter': 0.03254, 'accuracy': 0.96815, 'precision': 0.49485, 'recall': 0.36923, 'f1': 0.42291, 'auc': 0.74064}
2025-08-16 11:18:20,943 - INFO - > Epoch 60: took 74.9s (avg 77.2s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:19:26,400 - INFO - train: {'epoch': 61, 'time_epoch': 65.37464, 'eta': 2601.01821, 'eta_hours': 0.72251, 'loss': 0.10172852, 'lr': 3.613e-05, 'params': 451793, 'time_iter': 0.06353, 'accuracy': 0.97094, 'precision': 0.72924, 'recall': 0.35633, 'f1': 0.47874, 'auc': 0.87601}
2025-08-16 11:19:30,538 - INFO - val: {'epoch': 61, 'time_epoch': 4.11506, 'loss': 0.07278778, 'lr': 0, 'params': 451793, 'time_iter': 0.0319, 'accuracy': 0.98298, 'precision': 0.68966, 'recall': 0.24691, 'f1': 0.36364, 'auc': 0.78574}
2025-08-16 11:19:34,668 - INFO - test: {'epoch': 61, 'time_epoch': 4.11245, 'loss': 0.11734208, 'lr': 0, 'params': 451793, 'time_iter': 0.03188, 'accuracy': 0.97058, 'precision': 0.57895, 'recall': 0.25385, 'f1': 0.35294, 'auc': 0.74858}
2025-08-16 11:19:34,670 - INFO - > Epoch 61: took 73.7s (avg 77.1s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:20:42,092 - INFO - train: {'epoch': 62, 'time_epoch': 67.34477, 'eta': 2531.92252, 'eta_hours': 0.70331, 'loss': 0.10113962, 'lr': 3.455e-05, 'params': 451793, 'time_iter': 0.06545, 'accuracy': 0.97021, 'precision': 0.70792, 'recall': 0.34821, 'f1': 0.46681, 'auc': 0.88069}
2025-08-16 11:20:46,377 - INFO - val: {'epoch': 62, 'time_epoch': 4.26033, 'loss': 0.0730644, 'lr': 0, 'params': 451793, 'time_iter': 0.03303, 'accuracy': 0.98322, 'precision': 0.6875, 'recall': 0.2716, 'f1': 0.38938, 'auc': 0.7913}
2025-08-16 11:20:50,645 - INFO - test: {'epoch': 62, 'time_epoch': 4.23671, 'loss': 0.11937213, 'lr': 0, 'params': 451793, 'time_iter': 0.03284, 'accuracy': 0.96961, 'precision': 0.53086, 'recall': 0.33077, 'f1': 0.40758, 'auc': 0.73999}
2025-08-16 11:20:50,664 - INFO - > Epoch 62: took 76.0s (avg 77.1s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:21:56,836 - INFO - train: {'epoch': 63, 'time_epoch': 66.09313, 'eta': 2462.1775, 'eta_hours': 0.68394, 'loss': 0.10064708, 'lr': 3.299e-05, 'params': 451793, 'time_iter': 0.06423, 'accuracy': 0.97097, 'precision': 0.72968, 'recall': 0.35714, 'f1': 0.47956, 'auc': 0.8801}
2025-08-16 11:22:00,993 - INFO - val: {'epoch': 63, 'time_epoch': 4.13489, 'loss': 0.07552831, 'lr': 0, 'params': 451793, 'time_iter': 0.03205, 'accuracy': 0.98152, 'precision': 0.55556, 'recall': 0.30864, 'f1': 0.39683, 'auc': 0.79305}
2025-08-16 11:22:05,130 - INFO - test: {'epoch': 63, 'time_epoch': 4.12078, 'loss': 0.12017194, 'lr': 0, 'params': 451793, 'time_iter': 0.03194, 'accuracy': 0.96864, 'precision': 0.50549, 'recall': 0.35385, 'f1': 0.41629, 'auc': 0.74611}
2025-08-16 11:22:05,132 - INFO - > Epoch 63: took 74.5s (avg 77.1s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:23:11,132 - INFO - train: {'epoch': 64, 'time_epoch': 65.91562, 'eta': 2392.44927, 'eta_hours': 0.66457, 'loss': 0.10018829, 'lr': 3.144e-05, 'params': 451793, 'time_iter': 0.06406, 'accuracy': 0.97161, 'precision': 0.73576, 'recall': 0.37744, 'f1': 0.49893, 'auc': 0.8794}
2025-08-16 11:23:15,431 - INFO - val: {'epoch': 64, 'time_epoch': 4.27735, 'loss': 0.07123681, 'lr': 0, 'params': 451793, 'time_iter': 0.03316, 'accuracy': 0.98225, 'precision': 0.58696, 'recall': 0.33333, 'f1': 0.4252, 'auc': 0.80808}
2025-08-16 11:23:19,765 - INFO - test: {'epoch': 64, 'time_epoch': 4.3154, 'loss': 0.12008602, 'lr': 0, 'params': 451793, 'time_iter': 0.03345, 'accuracy': 0.96937, 'precision': 0.52326, 'recall': 0.34615, 'f1': 0.41667, 'auc': 0.74512}
2025-08-16 11:23:19,767 - INFO - > Epoch 64: took 74.6s (avg 77.0s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:24:27,670 - INFO - train: {'epoch': 65, 'time_epoch': 67.82039, 'eta': 2323.81781, 'eta_hours': 0.6455, 'loss': 0.10036782, 'lr': 2.992e-05, 'params': 451793, 'time_iter': 0.06591, 'accuracy': 0.97143, 'precision': 0.74746, 'recall': 0.35795, 'f1': 0.48408, 'auc': 0.88291}
2025-08-16 11:24:31,849 - INFO - val: {'epoch': 65, 'time_epoch': 4.15678, 'loss': 0.06957664, 'lr': 0, 'params': 451793, 'time_iter': 0.03222, 'accuracy': 0.98322, 'precision': 0.65789, 'recall': 0.30864, 'f1': 0.42017, 'auc': 0.79613}
2025-08-16 11:24:36,030 - INFO - test: {'epoch': 65, 'time_epoch': 4.16339, 'loss': 0.11781727, 'lr': 0, 'params': 451793, 'time_iter': 0.03227, 'accuracy': 0.97082, 'precision': 0.56098, 'recall': 0.35385, 'f1': 0.43396, 'auc': 0.74984}
2025-08-16 11:24:36,033 - INFO - > Epoch 65: took 76.3s (avg 77.0s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:25:43,807 - INFO - train: {'epoch': 66, 'time_epoch': 67.68642, 'eta': 2255.14458, 'eta_hours': 0.62643, 'loss': 0.09948866, 'lr': 2.841e-05, 'params': 451793, 'time_iter': 0.06578, 'accuracy': 0.97106, 'precision': 0.73411, 'recall': 0.35633, 'f1': 0.47978, 'auc': 0.88852}
2025-08-16 11:25:48,167 - INFO - val: {'epoch': 66, 'time_epoch': 4.31986, 'loss': 0.07512228, 'lr': 0, 'params': 451793, 'time_iter': 0.03349, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.28395, 'f1': 0.3622, 'auc': 0.79171}
2025-08-16 11:25:52,515 - INFO - test: {'epoch': 66, 'time_epoch': 4.33084, 'loss': 0.12191947, 'lr': 0, 'params': 451793, 'time_iter': 0.03357, 'accuracy': 0.96693, 'precision': 0.46809, 'recall': 0.33846, 'f1': 0.39286, 'auc': 0.74622}
2025-08-16 11:25:52,517 - INFO - > Epoch 66: took 76.5s (avg 77.0s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:26:59,346 - INFO - train: {'epoch': 67, 'time_epoch': 66.74635, 'eta': 2186.05799, 'eta_hours': 0.60724, 'loss': 0.09970119, 'lr': 2.693e-05, 'params': 451793, 'time_iter': 0.06487, 'accuracy': 0.97189, 'precision': 0.74022, 'recall': 0.38393, 'f1': 0.50561, 'auc': 0.88648}
2025-08-16 11:27:03,594 - INFO - val: {'epoch': 67, 'time_epoch': 4.22627, 'loss': 0.07132854, 'lr': 0, 'params': 451793, 'time_iter': 0.03276, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.79}
2025-08-16 11:27:07,823 - INFO - test: {'epoch': 67, 'time_epoch': 4.2113, 'loss': 0.11710681, 'lr': 0, 'params': 451793, 'time_iter': 0.03265, 'accuracy': 0.97009, 'precision': 0.54545, 'recall': 0.32308, 'f1': 0.4058, 'auc': 0.75369}
2025-08-16 11:27:07,826 - INFO - > Epoch 67: took 75.3s (avg 77.0s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:28:14,700 - INFO - train: {'epoch': 68, 'time_epoch': 66.79225, 'eta': 2117.05985, 'eta_hours': 0.58807, 'loss': 0.098884, 'lr': 2.548e-05, 'params': 451793, 'time_iter': 0.06491, 'accuracy': 0.97219, 'precision': 0.75441, 'recall': 0.38149, 'f1': 0.50674, 'auc': 0.88472}
2025-08-16 11:28:18,685 - INFO - val: {'epoch': 68, 'time_epoch': 3.96357, 'loss': 0.07303638, 'lr': 0, 'params': 451793, 'time_iter': 0.03073, 'accuracy': 0.98225, 'precision': 0.59524, 'recall': 0.30864, 'f1': 0.4065, 'auc': 0.79247}
2025-08-16 11:28:22,671 - INFO - test: {'epoch': 68, 'time_epoch': 3.96842, 'loss': 0.11885693, 'lr': 0, 'params': 451793, 'time_iter': 0.03076, 'accuracy': 0.96864, 'precision': 0.50602, 'recall': 0.32308, 'f1': 0.39437, 'auc': 0.74704}
2025-08-16 11:28:22,674 - INFO - > Epoch 68: took 74.8s (avg 77.0s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:29:27,037 - INFO - train: {'epoch': 69, 'time_epoch': 64.2766, 'eta': 2047.0466, 'eta_hours': 0.56862, 'loss': 0.10039906, 'lr': 2.405e-05, 'params': 451793, 'time_iter': 0.06247, 'accuracy': 0.97134, 'precision': 0.73496, 'recall': 0.36688, 'f1': 0.48944, 'auc': 0.88138}
2025-08-16 11:29:31,010 - INFO - val: {'epoch': 69, 'time_epoch': 3.95194, 'loss': 0.0716448, 'lr': 0, 'params': 451793, 'time_iter': 0.03064, 'accuracy': 0.98201, 'precision': 0.5814, 'recall': 0.30864, 'f1': 0.40323, 'auc': 0.80424}
2025-08-16 11:29:34,991 - INFO - test: {'epoch': 69, 'time_epoch': 3.9628, 'loss': 0.11856695, 'lr': 0, 'params': 451793, 'time_iter': 0.03072, 'accuracy': 0.96864, 'precision': 0.50602, 'recall': 0.32308, 'f1': 0.39437, 'auc': 0.753}
2025-08-16 11:29:34,994 - INFO - > Epoch 69: took 72.3s (avg 76.9s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:30:41,973 - INFO - train: {'epoch': 70, 'time_epoch': 66.8931, 'eta': 1978.26366, 'eta_hours': 0.54952, 'loss': 0.09866125, 'lr': 2.265e-05, 'params': 451793, 'time_iter': 0.06501, 'accuracy': 0.9714, 'precision': 0.72913, 'recall': 0.37581, 'f1': 0.49598, 'auc': 0.89218}
2025-08-16 11:30:46,198 - INFO - val: {'epoch': 70, 'time_epoch': 4.203, 'loss': 0.07714683, 'lr': 0, 'params': 451793, 'time_iter': 0.03258, 'accuracy': 0.98006, 'precision': 0.4898, 'recall': 0.2963, 'f1': 0.36923, 'auc': 0.78564}
2025-08-16 11:30:50,378 - INFO - test: {'epoch': 70, 'time_epoch': 4.16401, 'loss': 0.12312445, 'lr': 0, 'params': 451793, 'time_iter': 0.03228, 'accuracy': 0.96645, 'precision': 0.45745, 'recall': 0.33077, 'f1': 0.38393, 'auc': 0.74053}
2025-08-16 11:30:50,381 - INFO - > Epoch 70: took 75.4s (avg 76.9s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:31:57,885 - INFO - train: {'epoch': 71, 'time_epoch': 67.42235, 'eta': 1909.73903, 'eta_hours': 0.53048, 'loss': 0.09924706, 'lr': 2.128e-05, 'params': 451793, 'time_iter': 0.06552, 'accuracy': 0.97185, 'precision': 0.75, 'recall': 0.37256, 'f1': 0.49783, 'auc': 0.88303}
2025-08-16 11:32:02,071 - INFO - val: {'epoch': 71, 'time_epoch': 4.1644, 'loss': 0.07249387, 'lr': 0, 'params': 451793, 'time_iter': 0.03228, 'accuracy': 0.98395, 'precision': 0.69231, 'recall': 0.33333, 'f1': 0.45, 'auc': 0.77667}
2025-08-16 11:32:06,372 - INFO - test: {'epoch': 71, 'time_epoch': 4.28346, 'loss': 0.11948754, 'lr': 0, 'params': 451793, 'time_iter': 0.03321, 'accuracy': 0.97058, 'precision': 0.55422, 'recall': 0.35385, 'f1': 0.43192, 'auc': 0.74254}
2025-08-16 11:32:06,374 - INFO - > Epoch 71: took 76.0s (avg 76.9s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:33:14,086 - INFO - train: {'epoch': 72, 'time_epoch': 67.6293, 'eta': 1841.32115, 'eta_hours': 0.51148, 'loss': 0.09785384, 'lr': 1.995e-05, 'params': 451793, 'time_iter': 0.06572, 'accuracy': 0.97234, 'precision': 0.75235, 'recall': 0.38961, 'f1': 0.51337, 'auc': 0.88905}
2025-08-16 11:33:18,380 - INFO - val: {'epoch': 72, 'time_epoch': 4.27187, 'loss': 0.07106854, 'lr': 0, 'params': 451793, 'time_iter': 0.03312, 'accuracy': 0.98274, 'precision': 0.63158, 'recall': 0.2963, 'f1': 0.40336, 'auc': 0.79261}
2025-08-16 11:33:22,668 - INFO - test: {'epoch': 72, 'time_epoch': 4.27156, 'loss': 0.12101812, 'lr': 0, 'params': 451793, 'time_iter': 0.03311, 'accuracy': 0.96864, 'precision': 0.50649, 'recall': 0.3, 'f1': 0.37681, 'auc': 0.74311}
2025-08-16 11:33:22,671 - INFO - > Epoch 72: took 76.3s (avg 76.9s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:34:29,993 - INFO - train: {'epoch': 73, 'time_epoch': 67.23925, 'eta': 1772.78754, 'eta_hours': 0.49244, 'loss': 0.0985548, 'lr': 1.864e-05, 'params': 451793, 'time_iter': 0.06534, 'accuracy': 0.97207, 'precision': 0.74881, 'recall': 0.38231, 'f1': 0.50618, 'auc': 0.88662}
2025-08-16 11:34:34,275 - INFO - val: {'epoch': 73, 'time_epoch': 4.25624, 'loss': 0.0735543, 'lr': 0, 'params': 451793, 'time_iter': 0.03299, 'accuracy': 0.98347, 'precision': 0.65116, 'recall': 0.34568, 'f1': 0.45161, 'auc': 0.79023}
2025-08-16 11:34:38,535 - INFO - test: {'epoch': 73, 'time_epoch': 4.24233, 'loss': 0.12114062, 'lr': 0, 'params': 451793, 'time_iter': 0.03289, 'accuracy': 0.96791, 'precision': 0.4898, 'recall': 0.36923, 'f1': 0.42105, 'auc': 0.74689}
2025-08-16 11:34:38,538 - INFO - > Epoch 73: took 75.9s (avg 76.8s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:35:45,946 - INFO - train: {'epoch': 74, 'time_epoch': 67.3247, 'eta': 1704.31692, 'eta_hours': 0.47342, 'loss': 0.09883626, 'lr': 1.737e-05, 'params': 451793, 'time_iter': 0.06543, 'accuracy': 0.97128, 'precision': 0.73108, 'recall': 0.36851, 'f1': 0.49002, 'auc': 0.88841}
2025-08-16 11:35:50,106 - INFO - val: {'epoch': 74, 'time_epoch': 4.13862, 'loss': 0.0767174, 'lr': 0, 'params': 451793, 'time_iter': 0.03208, 'accuracy': 0.98104, 'precision': 0.5283, 'recall': 0.34568, 'f1': 0.41791, 'auc': 0.79232}
2025-08-16 11:35:54,339 - INFO - test: {'epoch': 74, 'time_epoch': 4.21435, 'loss': 0.12497461, 'lr': 0, 'params': 451793, 'time_iter': 0.03267, 'accuracy': 0.96766, 'precision': 0.48485, 'recall': 0.36923, 'f1': 0.41921, 'auc': 0.74551}
2025-08-16 11:35:54,342 - INFO - > Epoch 74: took 75.8s (avg 76.8s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:37:01,578 - INFO - train: {'epoch': 75, 'time_epoch': 67.1505, 'eta': 1635.82145, 'eta_hours': 0.45439, 'loss': 0.09839825, 'lr': 1.614e-05, 'params': 451793, 'time_iter': 0.06526, 'accuracy': 0.97128, 'precision': 0.72742, 'recall': 0.37256, 'f1': 0.49275, 'auc': 0.8891}
2025-08-16 11:37:05,876 - INFO - val: {'epoch': 75, 'time_epoch': 4.27598, 'loss': 0.07068129, 'lr': 0, 'params': 451793, 'time_iter': 0.03315, 'accuracy': 0.98347, 'precision': 0.72414, 'recall': 0.25926, 'f1': 0.38182, 'auc': 0.78902}
2025-08-16 11:37:10,155 - INFO - test: {'epoch': 75, 'time_epoch': 4.26256, 'loss': 0.11896946, 'lr': 0, 'params': 451793, 'time_iter': 0.03304, 'accuracy': 0.97155, 'precision': 0.60317, 'recall': 0.29231, 'f1': 0.39378, 'auc': 0.74834}
2025-08-16 11:37:10,158 - INFO - > Epoch 75: took 75.8s (avg 76.8s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:38:17,332 - INFO - train: {'epoch': 76, 'time_epoch': 67.08979, 'eta': 1567.34278, 'eta_hours': 0.43537, 'loss': 0.09696715, 'lr': 1.494e-05, 'params': 451793, 'time_iter': 0.0652, 'accuracy': 0.97222, 'precision': 0.76066, 'recall': 0.37662, 'f1': 0.5038, 'auc': 0.8934}
2025-08-16 11:38:21,669 - INFO - val: {'epoch': 76, 'time_epoch': 4.31133, 'loss': 0.07525131, 'lr': 0, 'params': 451793, 'time_iter': 0.03342, 'accuracy': 0.98201, 'precision': 0.57447, 'recall': 0.33333, 'f1': 0.42188, 'auc': 0.78868}
2025-08-16 11:38:25,979 - INFO - test: {'epoch': 76, 'time_epoch': 4.2915, 'loss': 0.12396545, 'lr': 0, 'params': 451793, 'time_iter': 0.03327, 'accuracy': 0.96742, 'precision': 0.47917, 'recall': 0.35385, 'f1': 0.40708, 'auc': 0.74539}
2025-08-16 11:38:25,981 - INFO - > Epoch 76: took 75.8s (avg 76.8s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:39:31,124 - INFO - train: {'epoch': 77, 'time_epoch': 65.06082, 'eta': 1498.32745, 'eta_hours': 0.4162, 'loss': 0.09749054, 'lr': 1.378e-05, 'params': 451793, 'time_iter': 0.06323, 'accuracy': 0.97225, 'precision': 0.74203, 'recall': 0.39692, 'f1': 0.51719, 'auc': 0.88907}
2025-08-16 11:39:35,231 - INFO - val: {'epoch': 77, 'time_epoch': 4.08561, 'loss': 0.07163316, 'lr': 0, 'params': 451793, 'time_iter': 0.03167, 'accuracy': 0.98322, 'precision': 0.65789, 'recall': 0.30864, 'f1': 0.42017, 'auc': 0.79708}
2025-08-16 11:39:39,330 - INFO - test: {'epoch': 77, 'time_epoch': 4.08221, 'loss': 0.11947533, 'lr': 0, 'params': 451793, 'time_iter': 0.03165, 'accuracy': 0.96912, 'precision': 0.51899, 'recall': 0.31538, 'f1': 0.39234, 'auc': 0.74438}
2025-08-16 11:39:39,333 - INFO - > Epoch 77: took 73.4s (avg 76.8s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:40:47,788 - INFO - train: {'epoch': 78, 'time_epoch': 68.37019, 'eta': 1430.29194, 'eta_hours': 0.3973, 'loss': 0.09659784, 'lr': 1.266e-05, 'params': 451793, 'time_iter': 0.06644, 'accuracy': 0.97216, 'precision': 0.74765, 'recall': 0.38718, 'f1': 0.51016, 'auc': 0.89413}
2025-08-16 11:40:52,023 - INFO - val: {'epoch': 78, 'time_epoch': 4.21474, 'loss': 0.07147959, 'lr': 0, 'params': 451793, 'time_iter': 0.03267, 'accuracy': 0.98298, 'precision': 0.62222, 'recall': 0.34568, 'f1': 0.44444, 'auc': 0.7963}
2025-08-16 11:40:56,298 - INFO - test: {'epoch': 78, 'time_epoch': 4.25772, 'loss': 0.12165718, 'lr': 0, 'params': 451793, 'time_iter': 0.03301, 'accuracy': 0.96888, 'precision': 0.5119, 'recall': 0.33077, 'f1': 0.40187, 'auc': 0.7463}
2025-08-16 11:40:56,301 - INFO - > Epoch 78: took 77.0s (avg 76.8s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:42:03,486 - INFO - train: {'epoch': 79, 'time_epoch': 67.09848, 'eta': 1361.93014, 'eta_hours': 0.37831, 'loss': 0.09790522, 'lr': 1.158e-05, 'params': 451793, 'time_iter': 0.06521, 'accuracy': 0.9721, 'precision': 0.74921, 'recall': 0.38312, 'f1': 0.50698, 'auc': 0.88863}
2025-08-16 11:42:07,582 - INFO - val: {'epoch': 79, 'time_epoch': 4.07512, 'loss': 0.07510237, 'lr': 0, 'params': 451793, 'time_iter': 0.03159, 'accuracy': 0.98152, 'precision': 0.55556, 'recall': 0.30864, 'f1': 0.39683, 'auc': 0.78845}
2025-08-16 11:42:11,811 - INFO - test: {'epoch': 79, 'time_epoch': 4.21168, 'loss': 0.12529715, 'lr': 0, 'params': 451793, 'time_iter': 0.03265, 'accuracy': 0.96766, 'precision': 0.48421, 'recall': 0.35385, 'f1': 0.40889, 'auc': 0.74772}
2025-08-16 11:42:11,814 - INFO - > Epoch 79: took 75.5s (avg 76.7s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:43:19,061 - INFO - train: {'epoch': 80, 'time_epoch': 67.16812, 'eta': 1293.61586, 'eta_hours': 0.35934, 'loss': 0.0963274, 'lr': 1.054e-05, 'params': 451793, 'time_iter': 0.06528, 'accuracy': 0.97237, 'precision': 0.74581, 'recall': 0.39773, 'f1': 0.51879, 'auc': 0.89198}
2025-08-16 11:43:23,217 - INFO - val: {'epoch': 80, 'time_epoch': 4.13238, 'loss': 0.07155402, 'lr': 0, 'params': 451793, 'time_iter': 0.03203, 'accuracy': 0.98249, 'precision': 0.61538, 'recall': 0.2963, 'f1': 0.4, 'auc': 0.78926}
2025-08-16 11:43:27,443 - INFO - test: {'epoch': 80, 'time_epoch': 4.2082, 'loss': 0.12221897, 'lr': 0, 'params': 451793, 'time_iter': 0.03262, 'accuracy': 0.96912, 'precision': 0.52055, 'recall': 0.29231, 'f1': 0.37438, 'auc': 0.74324}
2025-08-16 11:43:27,446 - INFO - > Epoch 80: took 75.6s (avg 76.7s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:44:34,548 - INFO - train: {'epoch': 81, 'time_epoch': 67.0186, 'eta': 1225.29672, 'eta_hours': 0.34036, 'loss': 0.09655336, 'lr': 9.55e-06, 'params': 451793, 'time_iter': 0.06513, 'accuracy': 0.97198, 'precision': 0.74525, 'recall': 0.38231, 'f1': 0.50536, 'auc': 0.89084}
2025-08-16 11:44:38,816 - INFO - val: {'epoch': 81, 'time_epoch': 4.24688, 'loss': 0.07149721, 'lr': 0, 'params': 451793, 'time_iter': 0.03292, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.78823}
2025-08-16 11:44:43,082 - INFO - test: {'epoch': 81, 'time_epoch': 4.24832, 'loss': 0.1212956, 'lr': 0, 'params': 451793, 'time_iter': 0.03293, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.31538, 'f1': 0.38679, 'auc': 0.74656}
2025-08-16 11:44:43,085 - INFO - > Epoch 81: took 75.6s (avg 76.7s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:45:48,748 - INFO - train: {'epoch': 82, 'time_epoch': 65.5849, 'eta': 1156.71526, 'eta_hours': 0.32131, 'loss': 0.09564052, 'lr': 8.6e-06, 'params': 451793, 'time_iter': 0.06374, 'accuracy': 0.97237, 'precision': 0.75513, 'recall': 0.38799, 'f1': 0.5126, 'auc': 0.89498}
2025-08-16 11:45:52,875 - INFO - val: {'epoch': 82, 'time_epoch': 4.10582, 'loss': 0.07038701, 'lr': 0, 'params': 451793, 'time_iter': 0.03183, 'accuracy': 0.98371, 'precision': 0.675, 'recall': 0.33333, 'f1': 0.44628, 'auc': 0.79789}
2025-08-16 11:45:57,009 - INFO - test: {'epoch': 82, 'time_epoch': 4.11726, 'loss': 0.12010127, 'lr': 0, 'params': 451793, 'time_iter': 0.03192, 'accuracy': 0.96937, 'precision': 0.52564, 'recall': 0.31538, 'f1': 0.39423, 'auc': 0.74934}
2025-08-16 11:45:57,012 - INFO - > Epoch 82: took 73.9s (avg 76.7s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:47:04,342 - INFO - train: {'epoch': 83, 'time_epoch': 67.24831, 'eta': 1088.522, 'eta_hours': 0.30237, 'loss': 0.09631281, 'lr': 7.7e-06, 'params': 451793, 'time_iter': 0.06535, 'accuracy': 0.97167, 'precision': 0.73148, 'recall': 0.38474, 'f1': 0.50426, 'auc': 0.89479}
2025-08-16 11:47:08,643 - INFO - val: {'epoch': 83, 'time_epoch': 4.27984, 'loss': 0.07065981, 'lr': 0, 'params': 451793, 'time_iter': 0.03318, 'accuracy': 0.98322, 'precision': 0.67647, 'recall': 0.28395, 'f1': 0.4, 'auc': 0.78864}
2025-08-16 11:47:12,942 - INFO - test: {'epoch': 83, 'time_epoch': 4.28071, 'loss': 0.12178579, 'lr': 0, 'params': 451793, 'time_iter': 0.03318, 'accuracy': 0.96985, 'precision': 0.54286, 'recall': 0.29231, 'f1': 0.38, 'auc': 0.74258}
2025-08-16 11:47:12,945 - INFO - > Epoch 83: took 75.9s (avg 76.7s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:48:19,059 - INFO - train: {'epoch': 84, 'time_epoch': 66.03213, 'eta': 1020.13634, 'eta_hours': 0.28337, 'loss': 0.09635878, 'lr': 6.84e-06, 'params': 451793, 'time_iter': 0.06417, 'accuracy': 0.97268, 'precision': 0.76303, 'recall': 0.39205, 'f1': 0.51796, 'auc': 0.89179}
2025-08-16 11:48:23,343 - INFO - val: {'epoch': 84, 'time_epoch': 4.26284, 'loss': 0.07241403, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.98201, 'precision': 0.58974, 'recall': 0.28395, 'f1': 0.38333, 'auc': 0.79111}
2025-08-16 11:48:27,589 - INFO - test: {'epoch': 84, 'time_epoch': 4.22843, 'loss': 0.1237761, 'lr': 0, 'params': 451793, 'time_iter': 0.03278, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.33846, 'f1': 0.40367, 'auc': 0.7444}
2025-08-16 11:48:27,591 - INFO - > Epoch 84: took 74.6s (avg 76.7s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:49:33,562 - INFO - train: {'epoch': 85, 'time_epoch': 65.89215, 'eta': 951.78263, 'eta_hours': 0.26438, 'loss': 0.09581898, 'lr': 6.03e-06, 'params': 451793, 'time_iter': 0.06404, 'accuracy': 0.97179, 'precision': 0.74127, 'recall': 0.37906, 'f1': 0.50161, 'auc': 0.89772}
2025-08-16 11:49:37,846 - INFO - val: {'epoch': 85, 'time_epoch': 4.26151, 'loss': 0.07164899, 'lr': 0, 'params': 451793, 'time_iter': 0.03303, 'accuracy': 0.98347, 'precision': 0.65854, 'recall': 0.33333, 'f1': 0.44262, 'auc': 0.79341}
2025-08-16 11:49:42,108 - INFO - test: {'epoch': 85, 'time_epoch': 4.24465, 'loss': 0.12349412, 'lr': 0, 'params': 451793, 'time_iter': 0.0329, 'accuracy': 0.96888, 'precision': 0.51163, 'recall': 0.33846, 'f1': 0.40741, 'auc': 0.74796}
2025-08-16 11:49:42,111 - INFO - > Epoch 85: took 74.5s (avg 76.6s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:50:49,307 - INFO - train: {'epoch': 86, 'time_epoch': 67.1118, 'eta': 883.66776, 'eta_hours': 0.24546, 'loss': 0.09779, 'lr': 5.26e-06, 'params': 451793, 'time_iter': 0.06522, 'accuracy': 0.97146, 'precision': 0.72784, 'recall': 0.37987, 'f1': 0.4992, 'auc': 0.88963}
2025-08-16 11:50:53,317 - INFO - val: {'epoch': 86, 'time_epoch': 3.9874, 'loss': 0.07367309, 'lr': 0, 'params': 451793, 'time_iter': 0.03091, 'accuracy': 0.98152, 'precision': 0.55556, 'recall': 0.30864, 'f1': 0.39683, 'auc': 0.79477}
2025-08-16 11:50:57,347 - INFO - test: {'epoch': 86, 'time_epoch': 4.01192, 'loss': 0.12496762, 'lr': 0, 'params': 451793, 'time_iter': 0.0311, 'accuracy': 0.96791, 'precision': 0.48864, 'recall': 0.33077, 'f1': 0.3945, 'auc': 0.74837}
2025-08-16 11:50:57,350 - INFO - > Epoch 86: took 75.2s (avg 76.6s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:52:04,525 - INFO - train: {'epoch': 87, 'time_epoch': 67.09409, 'eta': 815.57327, 'eta_hours': 0.22655, 'loss': 0.09605081, 'lr': 4.55e-06, 'params': 451793, 'time_iter': 0.0652, 'accuracy': 0.97298, 'precision': 0.76024, 'recall': 0.40666, 'f1': 0.52988, 'auc': 0.89595}
2025-08-16 11:52:08,684 - INFO - val: {'epoch': 87, 'time_epoch': 4.1377, 'loss': 0.07165912, 'lr': 0, 'params': 451793, 'time_iter': 0.03208, 'accuracy': 0.98322, 'precision': 0.65789, 'recall': 0.30864, 'f1': 0.42017, 'auc': 0.79425}
2025-08-16 11:52:12,837 - INFO - test: {'epoch': 87, 'time_epoch': 4.13546, 'loss': 0.12258134, 'lr': 0, 'params': 451793, 'time_iter': 0.03206, 'accuracy': 0.96937, 'precision': 0.52381, 'recall': 0.33846, 'f1': 0.41121, 'auc': 0.74512}
2025-08-16 11:52:12,839 - INFO - > Epoch 87: took 75.5s (avg 76.6s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:53:19,961 - INFO - train: {'epoch': 88, 'time_epoch': 67.03335, 'eta': 747.49375, 'eta_hours': 0.20764, 'loss': 0.09599544, 'lr': 3.89e-06, 'params': 451793, 'time_iter': 0.06514, 'accuracy': 0.97219, 'precision': 0.74422, 'recall': 0.39205, 'f1': 0.51356, 'auc': 0.89412}
2025-08-16 11:53:24,167 - INFO - val: {'epoch': 88, 'time_epoch': 4.18157, 'loss': 0.07178211, 'lr': 0, 'params': 451793, 'time_iter': 0.03242, 'accuracy': 0.98371, 'precision': 0.66667, 'recall': 0.34568, 'f1': 0.45528, 'auc': 0.79315}
2025-08-16 11:53:28,314 - INFO - test: {'epoch': 88, 'time_epoch': 4.12947, 'loss': 0.12230603, 'lr': 0, 'params': 451793, 'time_iter': 0.03201, 'accuracy': 0.96815, 'precision': 0.49412, 'recall': 0.32308, 'f1': 0.3907, 'auc': 0.74961}
2025-08-16 11:53:28,316 - INFO - > Epoch 88: took 75.5s (avg 76.6s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:54:35,613 - INFO - train: {'epoch': 89, 'time_epoch': 67.20929, 'eta': 679.45703, 'eta_hours': 0.18874, 'loss': 0.09491771, 'lr': 3.27e-06, 'params': 451793, 'time_iter': 0.06532, 'accuracy': 0.97219, 'precision': 0.7536, 'recall': 0.38231, 'f1': 0.50727, 'auc': 0.8969}
2025-08-16 11:54:40,000 - INFO - val: {'epoch': 89, 'time_epoch': 4.36304, 'loss': 0.07532254, 'lr': 0, 'params': 451793, 'time_iter': 0.03382, 'accuracy': 0.98201, 'precision': 0.57447, 'recall': 0.33333, 'f1': 0.42188, 'auc': 0.79024}
2025-08-16 11:54:44,339 - INFO - test: {'epoch': 89, 'time_epoch': 4.32111, 'loss': 0.12618246, 'lr': 0, 'params': 451793, 'time_iter': 0.0335, 'accuracy': 0.96791, 'precision': 0.48958, 'recall': 0.36154, 'f1': 0.41593, 'auc': 0.74635}
2025-08-16 11:54:44,342 - INFO - > Epoch 89: took 76.0s (avg 76.6s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:55:52,001 - INFO - train: {'epoch': 90, 'time_epoch': 67.57524, 'eta': 611.47469, 'eta_hours': 0.16985, 'loss': 0.09402279, 'lr': 2.71e-06, 'params': 451793, 'time_iter': 0.06567, 'accuracy': 0.97207, 'precision': 0.73185, 'recall': 0.40097, 'f1': 0.51809, 'auc': 0.90003}
2025-08-16 11:55:56,244 - INFO - val: {'epoch': 90, 'time_epoch': 4.22122, 'loss': 0.07159155, 'lr': 0, 'params': 451793, 'time_iter': 0.03272, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.79318}
2025-08-16 11:56:00,475 - INFO - test: {'epoch': 90, 'time_epoch': 4.21405, 'loss': 0.12287753, 'lr': 0, 'params': 451793, 'time_iter': 0.03267, 'accuracy': 0.96815, 'precision': 0.49398, 'recall': 0.31538, 'f1': 0.38498, 'auc': 0.74734}
2025-08-16 11:56:00,477 - INFO - > Epoch 90: took 76.1s (avg 76.6s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:57:08,595 - INFO - train: {'epoch': 91, 'time_epoch': 68.03144, 'eta': 543.54087, 'eta_hours': 0.15098, 'loss': 0.09571654, 'lr': 2.2e-06, 'params': 451793, 'time_iter': 0.06611, 'accuracy': 0.97249, 'precision': 0.7481, 'recall': 0.40016, 'f1': 0.52142, 'auc': 0.89713}
2025-08-16 11:57:12,871 - INFO - val: {'epoch': 91, 'time_epoch': 4.25337, 'loss': 0.07142373, 'lr': 0, 'params': 451793, 'time_iter': 0.03297, 'accuracy': 0.98274, 'precision': 0.625, 'recall': 0.30864, 'f1': 0.41322, 'auc': 0.79412}
2025-08-16 11:57:17,174 - INFO - test: {'epoch': 91, 'time_epoch': 4.2863, 'loss': 0.12302106, 'lr': 0, 'params': 451793, 'time_iter': 0.03323, 'accuracy': 0.96815, 'precision': 0.49383, 'recall': 0.30769, 'f1': 0.37915, 'auc': 0.74901}
2025-08-16 11:57:17,177 - INFO - > Epoch 91: took 76.7s (avg 76.6s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:58:22,653 - INFO - train: {'epoch': 92, 'time_epoch': 65.3927, 'eta': 475.40633, 'eta_hours': 0.13206, 'loss': 0.09658611, 'lr': 1.74e-06, 'params': 451793, 'time_iter': 0.06355, 'accuracy': 0.97246, 'precision': 0.76375, 'recall': 0.38312, 'f1': 0.51027, 'auc': 0.89403}
2025-08-16 11:58:26,927 - INFO - val: {'epoch': 92, 'time_epoch': 4.2521, 'loss': 0.07185708, 'lr': 0, 'params': 451793, 'time_iter': 0.03296, 'accuracy': 0.98395, 'precision': 0.69231, 'recall': 0.33333, 'f1': 0.45, 'auc': 0.78865}
2025-08-16 11:58:31,230 - INFO - test: {'epoch': 92, 'time_epoch': 4.28429, 'loss': 0.12185801, 'lr': 0, 'params': 451793, 'time_iter': 0.03321, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.33077, 'f1': 0.39815, 'auc': 0.74881}
2025-08-16 11:58:31,232 - INFO - > Epoch 92: took 74.1s (avg 76.5s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 11:59:38,363 - INFO - train: {'epoch': 93, 'time_epoch': 67.05009, 'eta': 407.43592, 'eta_hours': 0.11318, 'loss': 0.09549135, 'lr': 1.33e-06, 'params': 451793, 'time_iter': 0.06516, 'accuracy': 0.97331, 'precision': 0.76737, 'recall': 0.41234, 'f1': 0.53643, 'auc': 0.89012}
2025-08-16 11:59:42,608 - INFO - val: {'epoch': 93, 'time_epoch': 4.22305, 'loss': 0.07133912, 'lr': 0, 'params': 451793, 'time_iter': 0.03274, 'accuracy': 0.98298, 'precision': 0.65714, 'recall': 0.28395, 'f1': 0.39655, 'auc': 0.78673}
2025-08-16 11:59:46,855 - INFO - test: {'epoch': 93, 'time_epoch': 4.23036, 'loss': 0.12238742, 'lr': 0, 'params': 451793, 'time_iter': 0.03279, 'accuracy': 0.96912, 'precision': 0.52, 'recall': 0.3, 'f1': 0.38049, 'auc': 0.75009}
2025-08-16 11:59:46,858 - INFO - > Epoch 93: took 75.6s (avg 76.5s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 12:00:54,586 - INFO - train: {'epoch': 94, 'time_epoch': 67.64726, 'eta': 339.51632, 'eta_hours': 0.09431, 'loss': 0.09447907, 'lr': 9.8e-07, 'params': 451793, 'time_iter': 0.06574, 'accuracy': 0.97243, 'precision': 0.74734, 'recall': 0.39854, 'f1': 0.51985, 'auc': 0.90111}
2025-08-16 12:00:58,923 - INFO - val: {'epoch': 94, 'time_epoch': 4.31136, 'loss': 0.07230753, 'lr': 0, 'params': 451793, 'time_iter': 0.03342, 'accuracy': 0.98225, 'precision': 0.59524, 'recall': 0.30864, 'f1': 0.4065, 'auc': 0.79439}
2025-08-16 12:01:03,258 - INFO - test: {'epoch': 94, 'time_epoch': 4.31746, 'loss': 0.12329948, 'lr': 0, 'params': 451793, 'time_iter': 0.03347, 'accuracy': 0.96815, 'precision': 0.49412, 'recall': 0.32308, 'f1': 0.3907, 'auc': 0.74732}
2025-08-16 12:01:03,261 - INFO - > Epoch 94: took 76.4s (avg 76.5s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 12:02:10,282 - INFO - train: {'epoch': 95, 'time_epoch': 66.93976, 'eta': 271.57291, 'eta_hours': 0.07544, 'loss': 0.09659838, 'lr': 6.8e-07, 'params': 451793, 'time_iter': 0.06505, 'accuracy': 0.97234, 'precision': 0.75394, 'recall': 0.38799, 'f1': 0.51233, 'auc': 0.89222}
2025-08-16 12:02:14,316 - INFO - val: {'epoch': 95, 'time_epoch': 4.0126, 'loss': 0.07213178, 'lr': 0, 'params': 451793, 'time_iter': 0.03111, 'accuracy': 0.98395, 'precision': 0.67442, 'recall': 0.35802, 'f1': 0.46774, 'auc': 0.78906}
2025-08-16 12:02:18,541 - INFO - test: {'epoch': 95, 'time_epoch': 4.20803, 'loss': 0.12276785, 'lr': 0, 'params': 451793, 'time_iter': 0.03262, 'accuracy': 0.96912, 'precision': 0.51685, 'recall': 0.35385, 'f1': 0.42009, 'auc': 0.74731}
2025-08-16 12:02:18,544 - INFO - > Epoch 95: took 75.3s (avg 76.5s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 12:03:25,757 - INFO - train: {'epoch': 96, 'time_epoch': 67.12935, 'eta': 203.65605, 'eta_hours': 0.05657, 'loss': 0.09589638, 'lr': 4.4e-07, 'params': 451793, 'time_iter': 0.06524, 'accuracy': 0.97176, 'precision': 0.73561, 'recall': 0.38393, 'f1': 0.50453, 'auc': 0.89753}
2025-08-16 12:03:29,927 - INFO - val: {'epoch': 96, 'time_epoch': 4.14665, 'loss': 0.07207977, 'lr': 0, 'params': 451793, 'time_iter': 0.03214, 'accuracy': 0.98347, 'precision': 0.65116, 'recall': 0.34568, 'f1': 0.45161, 'auc': 0.79452}
2025-08-16 12:03:34,101 - INFO - test: {'epoch': 96, 'time_epoch': 4.15606, 'loss': 0.12343286, 'lr': 0, 'params': 451793, 'time_iter': 0.03222, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.34615, 'f1': 0.40909, 'auc': 0.74709}
2025-08-16 12:03:34,104 - INFO - > Epoch 96: took 75.6s (avg 76.5s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 12:04:40,856 - INFO - train: {'epoch': 97, 'time_epoch': 66.66586, 'eta': 135.74582, 'eta_hours': 0.03771, 'loss': 0.09622653, 'lr': 2.5e-07, 'params': 451793, 'time_iter': 0.06479, 'accuracy': 0.97234, 'precision': 0.75968, 'recall': 0.38231, 'f1': 0.50864, 'auc': 0.89473}
2025-08-16 12:04:45,128 - INFO - val: {'epoch': 97, 'time_epoch': 4.24772, 'loss': 0.07241348, 'lr': 0, 'params': 451793, 'time_iter': 0.03293, 'accuracy': 0.98322, 'precision': 0.64286, 'recall': 0.33333, 'f1': 0.43902, 'auc': 0.79612}
2025-08-16 12:04:49,256 - INFO - test: {'epoch': 97, 'time_epoch': 4.10972, 'loss': 0.12333257, 'lr': 0, 'params': 451793, 'time_iter': 0.03186, 'accuracy': 0.96888, 'precision': 0.51163, 'recall': 0.33846, 'f1': 0.40741, 'auc': 0.74736}
2025-08-16 12:04:49,259 - INFO - > Epoch 97: took 75.2s (avg 76.5s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 12:05:55,366 - INFO - train: {'epoch': 98, 'time_epoch': 66.02068, 'eta': 67.8542, 'eta_hours': 0.01885, 'loss': 0.09654061, 'lr': 1.1e-07, 'params': 451793, 'time_iter': 0.06416, 'accuracy': 0.9724, 'precision': 0.75313, 'recall': 0.39123, 'f1': 0.51496, 'auc': 0.89271}
2025-08-16 12:05:59,515 - INFO - val: {'epoch': 98, 'time_epoch': 4.12719, 'loss': 0.07146507, 'lr': 0, 'params': 451793, 'time_iter': 0.03199, 'accuracy': 0.98371, 'precision': 0.66667, 'recall': 0.34568, 'f1': 0.45528, 'auc': 0.79863}
2025-08-16 12:06:03,668 - INFO - test: {'epoch': 98, 'time_epoch': 4.13582, 'loss': 0.12239774, 'lr': 0, 'params': 451793, 'time_iter': 0.03206, 'accuracy': 0.96864, 'precision': 0.50562, 'recall': 0.34615, 'f1': 0.41096, 'auc': 0.75057}
2025-08-16 12:06:03,670 - INFO - > Epoch 98: took 74.4s (avg 76.5s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 12:07:10,717 - INFO - train: {'epoch': 99, 'time_epoch': 66.96216, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.09463728, 'lr': 3e-08, 'params': 451793, 'time_iter': 0.06507, 'accuracy': 0.97313, 'precision': 0.76444, 'recall': 0.40828, 'f1': 0.53228, 'auc': 0.89661}
2025-08-16 12:07:15,003 - INFO - val: {'epoch': 99, 'time_epoch': 4.2633, 'loss': 0.07115405, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.98395, 'precision': 0.69231, 'recall': 0.33333, 'f1': 0.45, 'auc': 0.79349}
2025-08-16 12:07:19,311 - INFO - test: {'epoch': 99, 'time_epoch': 4.28924, 'loss': 0.12136473, 'lr': 0, 'params': 451793, 'time_iter': 0.03325, 'accuracy': 0.96888, 'precision': 0.51282, 'recall': 0.30769, 'f1': 0.38462, 'auc': 0.75034}
2025-08-16 12:07:19,441 - INFO - > Epoch 99: took 75.6s (avg 76.5s) | Best so far: epoch 42	train_loss: 0.1093 train_auc: 0.8525	val_loss: 0.0730 val_auc: 0.8107	test_loss: 0.1152 test_auc: 0.7513
2025-08-16 12:07:19,441 - INFO - Avg time per epoch: 76.47s
2025-08-16 12:07:19,441 - INFO - Total train loop time: 2.12h

All experiments completed!
