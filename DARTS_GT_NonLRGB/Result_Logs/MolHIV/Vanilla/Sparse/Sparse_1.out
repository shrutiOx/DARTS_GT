Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          376Gi        20Gi       305Gi       1.7Gi        50Gi       351Gi
Swap:         1.9Gi       3.0Mi       1.9Gi
Fri Jul  4 17:40:25 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:1D:00.0 Off |                    0 |
| N/A   30C    P0             42W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 41
Starting training for seed 41...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/confignas.yaml
Using device: cuda
2025-07-04 17:41:44,206 - INFO - GPU Mem: 34.1GB
2025-07-04 17:41:44,206 - INFO - Run directory: results/molhiv/molhiv-Vanilla-41
2025-07-04 17:41:44,206 - INFO - Seed: 41
2025-07-04 17:41:44,206 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-07-04 17:41:44,207 - INFO - Routing mode: none
2025-07-04 17:41:44,207 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-07-04 17:41:44,207 - INFO - Number of layers: 15
2025-07-04 17:41:44,207 - INFO - Uncertainty enabled: False
2025-07-04 17:41:44,207 - INFO - Training mode: custom
2025-07-04 17:41:44,207 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-07-04 17:41:44,207 - INFO - Additional features: Router weights logging + JSON export
2025-07-04 17:41:53,402 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-04 17:41:53,404 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-07-04 17:41:53,516 - INFO -   undirected: True
2025-07-04 17:41:53,516 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-04 17:41:53,517 - INFO -   avg num_nodes/graph: 25
2025-07-04 17:41:53,517 - INFO -   num node features: 9
2025-07-04 17:41:53,517 - INFO -   num edge features: 3
2025-07-04 17:41:53,517 - INFO -   num tasks: 1
2025-07-04 17:41:53,517 - INFO -   num classes: 2
2025-07-04 17:41:53,517 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-07-04 17:41:53,518 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-07-04 17:41:53,521 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 18%|█▊        | 7381/41127 [00:10<00:45, 738.09it/s] 36%|███▌      | 14751/41127 [00:20<00:35, 737.42it/s] 53%|█████▎    | 21948/41127 [00:30<00:26, 729.28it/s] 71%|███████▏  | 29334/41127 [00:40<00:16, 732.96it/s] 88%|████████▊ | 36302/41127 [00:50<00:06, 719.89it/s]100%|██████████| 41127/41127 [00:56<00:00, 727.02it/s]
2025-07-04 17:42:51,087 - INFO - Done! Took 00:00:57.57
2025-07-04 17:42:51,404 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-07-04 17:42:51,569 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-07-04 17:42:51,570 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-07-04 17:42:51,570 - INFO - Inner model has get_darts_model: False
2025-07-04 17:42:51,574 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-07-04 17:42:51,576 - INFO - Number of parameters: 451,793
2025-07-04 17:42:51,576 - INFO - Starting optimized training: 2025-07-04 17:42:51.576930
2025-07-04 17:42:57,755 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-04 17:42:57,755 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-07-04 17:42:57,756 - INFO -   undirected: True
2025-07-04 17:42:57,756 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-04 17:42:57,756 - INFO -   avg num_nodes/graph: 25
2025-07-04 17:42:57,757 - INFO -   num node features: 9
2025-07-04 17:42:57,757 - INFO -   num edge features: 3
2025-07-04 17:42:57,757 - INFO -   num tasks: 1
2025-07-04 17:42:57,757 - INFO -   num classes: 2
2025-07-04 17:42:57,757 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-07-04 17:42:57,757 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-07-04 17:42:57,760 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 18%|█▊        | 7542/41127 [00:10<00:44, 754.13it/s] 36%|███▌      | 14907/41127 [00:20<00:35, 743.73it/s] 54%|█████▎    | 22075/41127 [00:30<00:26, 731.41it/s] 71%|███████   | 29165/41127 [00:40<00:16, 722.53it/s] 89%|████████▊ | 36405/41127 [00:50<00:06, 723.03it/s]100%|██████████| 41127/41127 [00:56<00:00, 723.53it/s]
2025-07-04 17:43:55,578 - INFO - Done! Took 00:00:57.82
2025-07-04 17:43:55,726 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-07-04 17:43:55,730 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-07-04 17:43:55,730 - INFO - Start from epoch 0
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:45:14,713 - INFO - train: {'epoch': 0, 'time_epoch': 77.88499, 'eta': 7710.61382, 'eta_hours': 2.14184, 'loss': 0.64553239, 'lr': 0.0, 'params': 451793, 'time_iter': 0.07569, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.54815}
2025-07-04 17:45:14,722 - INFO - ...computing epoch stats took: 1.08s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:45:19,222 - INFO - val: {'epoch': 0, 'time_epoch': 4.48396, 'loss': 0.64428301, 'lr': 0, 'params': 451793, 'time_iter': 0.03476, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.57096}
2025-07-04 17:45:19,225 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:45:24,341 - INFO - test: {'epoch': 0, 'time_epoch': 5.09987, 'loss': 0.64384035, 'lr': 0, 'params': 451793, 'time_iter': 0.03953, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.61957}
2025-07-04 17:45:24,343 - INFO - ...computing epoch stats took: 0.02s
2025-07-04 17:45:24,344 - INFO - > Epoch 0: took 88.6s (avg 88.6s) | Best so far: epoch 0	train_loss: 0.6455 train_auc: 0.5482	val_loss: 0.6443 val_auc: 0.5710	test_loss: 0.6438 test_auc: 0.6196
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:46:34,739 - INFO - train: {'epoch': 1, 'time_epoch': 70.33337, 'eta': 7262.69959, 'eta_hours': 2.01742, 'loss': 0.38217875, 'lr': 2e-05, 'params': 451793, 'time_iter': 0.06835, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.54461}
2025-07-04 17:46:34,749 - INFO - ...computing epoch stats took: 0.05s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:46:38,893 - INFO - val: {'epoch': 1, 'time_epoch': 4.12826, 'loss': 0.20049401, 'lr': 0, 'params': 451793, 'time_iter': 0.032, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.58386}
2025-07-04 17:46:38,896 - INFO - ...computing epoch stats took: 0.01s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:46:42,982 - INFO - test: {'epoch': 1, 'time_epoch': 4.07126, 'loss': 0.20868054, 'lr': 0, 'params': 451793, 'time_iter': 0.03156, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.59633}
2025-07-04 17:46:42,984 - INFO - ...computing epoch stats took: 0.01s
2025-07-04 17:46:42,984 - INFO - > Epoch 1: took 78.6s (avg 83.6s) | Best so far: epoch 1	train_loss: 0.3822 train_auc: 0.5446	val_loss: 0.2005 val_auc: 0.5839	test_loss: 0.2087 test_auc: 0.5963
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:47:53,606 - INFO - train: {'epoch': 2, 'time_epoch': 70.56254, 'eta': 7073.91587, 'eta_hours': 1.96498, 'loss': 0.1847689, 'lr': 4e-05, 'params': 451793, 'time_iter': 0.06857, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.60294}
2025-07-04 17:47:53,616 - INFO - ...computing epoch stats took: 0.04s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:47:57,746 - INFO - val: {'epoch': 2, 'time_epoch': 4.11294, 'loss': 0.11280219, 'lr': 0, 'params': 451793, 'time_iter': 0.03188, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.47945}
2025-07-04 17:47:57,749 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:48:01,909 - INFO - test: {'epoch': 2, 'time_epoch': 4.14149, 'loss': 0.14329147, 'lr': 0, 'params': 451793, 'time_iter': 0.0321, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.56749}
2025-07-04 17:48:01,913 - INFO - ...computing epoch stats took: 0.02s
2025-07-04 17:48:01,913 - INFO - > Epoch 2: took 78.9s (avg 82.1s) | Best so far: epoch 1	train_loss: 0.3822 train_auc: 0.5446	val_loss: 0.2005 val_auc: 0.5839	test_loss: 0.2087 test_auc: 0.5963
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:49:13,208 - INFO - train: {'epoch': 3, 'time_epoch': 71.23376, 'eta': 6960.35195, 'eta_hours': 1.93343, 'loss': 0.15728957, 'lr': 6e-05, 'params': 451793, 'time_iter': 0.06923, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.63754}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:49:17,383 - INFO - val: {'epoch': 3, 'time_epoch': 4.15075, 'loss': 0.09988671, 'lr': 0, 'params': 451793, 'time_iter': 0.03218, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.61614}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:49:21,524 - INFO - test: {'epoch': 3, 'time_epoch': 4.12283, 'loss': 0.13123085, 'lr': 0, 'params': 451793, 'time_iter': 0.03196, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68745}
2025-07-04 17:49:21,527 - INFO - > Epoch 3: took 79.6s (avg 81.4s) | Best so far: epoch 3	train_loss: 0.1573 train_auc: 0.6375	val_loss: 0.0999 val_auc: 0.6161	test_loss: 0.1312 test_auc: 0.6875
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:50:32,201 - INFO - train: {'epoch': 4, 'time_epoch': 70.61489, 'eta': 6851.96145, 'eta_hours': 1.90332, 'loss': 0.15166991, 'lr': 8e-05, 'params': 451793, 'time_iter': 0.06862, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66775}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:50:36,405 - INFO - val: {'epoch': 4, 'time_epoch': 4.17808, 'loss': 0.10068828, 'lr': 0, 'params': 451793, 'time_iter': 0.03239, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.61959}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:50:40,502 - INFO - test: {'epoch': 4, 'time_epoch': 4.07461, 'loss': 0.13209692, 'lr': 0, 'params': 451793, 'time_iter': 0.03159, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67536}
2025-07-04 17:50:40,505 - INFO - > Epoch 4: took 79.0s (avg 81.0s) | Best so far: epoch 4	train_loss: 0.1517 train_auc: 0.6677	val_loss: 0.1007 val_auc: 0.6196	test_loss: 0.1321 test_auc: 0.6754
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:51:51,290 - INFO - train: {'epoch': 5, 'time_epoch': 70.71946, 'eta': 6757.8011, 'eta_hours': 1.87717, 'loss': 0.14640124, 'lr': 0.0001, 'params': 451793, 'time_iter': 0.06873, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70668}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:51:55,799 - INFO - val: {'epoch': 5, 'time_epoch': 4.48344, 'loss': 0.09735133, 'lr': 0, 'params': 451793, 'time_iter': 0.03476, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.62212}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:52:00,280 - INFO - test: {'epoch': 5, 'time_epoch': 4.45853, 'loss': 0.12444287, 'lr': 0, 'params': 451793, 'time_iter': 0.03456, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70569}
2025-07-04 17:52:00,283 - INFO - > Epoch 5: took 79.8s (avg 80.8s) | Best so far: epoch 5	train_loss: 0.1464 train_auc: 0.7067	val_loss: 0.0974 val_auc: 0.6221	test_loss: 0.1244 test_auc: 0.7057
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:53:12,645 - INFO - train: {'epoch': 6, 'time_epoch': 72.29975, 'eta': 6691.33351, 'eta_hours': 1.8587, 'loss': 0.14236951, 'lr': 9.997e-05, 'params': 451793, 'time_iter': 0.07026, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72874}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:53:16,904 - INFO - val: {'epoch': 6, 'time_epoch': 4.23012, 'loss': 0.09031295, 'lr': 0, 'params': 451793, 'time_iter': 0.03279, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66124}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:53:21,189 - INFO - test: {'epoch': 6, 'time_epoch': 4.26317, 'loss': 0.12096437, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74545}
2025-07-04 17:53:21,193 - INFO - > Epoch 6: took 80.9s (avg 80.8s) | Best so far: epoch 6	train_loss: 0.1424 train_auc: 0.7287	val_loss: 0.0903 val_auc: 0.6612	test_loss: 0.1210 test_auc: 0.7454
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:54:32,943 - INFO - train: {'epoch': 7, 'time_epoch': 71.68982, 'eta': 6616.3937, 'eta_hours': 1.83789, 'loss': 0.13924007, 'lr': 9.989e-05, 'params': 451793, 'time_iter': 0.06967, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74667}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:54:37,120 - INFO - val: {'epoch': 7, 'time_epoch': 4.15174, 'loss': 0.09287756, 'lr': 0, 'params': 451793, 'time_iter': 0.03218, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68259}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:54:41,317 - INFO - test: {'epoch': 7, 'time_epoch': 4.17051, 'loss': 0.12304861, 'lr': 0, 'params': 451793, 'time_iter': 0.03233, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72042}
2025-07-04 17:54:41,320 - INFO - > Epoch 7: took 80.1s (avg 80.7s) | Best so far: epoch 7	train_loss: 0.1392 train_auc: 0.7467	val_loss: 0.0929 val_auc: 0.6826	test_loss: 0.1230 test_auc: 0.7204
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:55:52,513 - INFO - train: {'epoch': 8, 'time_epoch': 71.13196, 'eta': 6536.53551, 'eta_hours': 1.8157, 'loss': 0.13771232, 'lr': 9.975e-05, 'params': 451793, 'time_iter': 0.06913, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75155}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:55:56,691 - INFO - val: {'epoch': 8, 'time_epoch': 4.15244, 'loss': 0.08739428, 'lr': 0, 'params': 451793, 'time_iter': 0.03219, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6877}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:56:00,852 - INFO - test: {'epoch': 8, 'time_epoch': 4.14345, 'loss': 0.11640249, 'lr': 0, 'params': 451793, 'time_iter': 0.03212, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75307}
2025-07-04 17:56:00,855 - INFO - > Epoch 8: took 79.5s (avg 80.6s) | Best so far: epoch 8	train_loss: 0.1377 train_auc: 0.7516	val_loss: 0.0874 val_auc: 0.6877	test_loss: 0.1164 test_auc: 0.7531
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:57:12,788 - INFO - train: {'epoch': 9, 'time_epoch': 71.87055, 'eta': 6465.06987, 'eta_hours': 1.79585, 'loss': 0.13527901, 'lr': 9.956e-05, 'params': 451793, 'time_iter': 0.06985, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75713}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:57:16,962 - INFO - val: {'epoch': 9, 'time_epoch': 4.15018, 'loss': 0.08764966, 'lr': 0, 'params': 451793, 'time_iter': 0.03217, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68486}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:57:21,139 - INFO - test: {'epoch': 9, 'time_epoch': 4.15914, 'loss': 0.1185397, 'lr': 0, 'params': 451793, 'time_iter': 0.03224, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75705}
2025-07-04 17:57:21,143 - INFO - > Epoch 9: took 80.3s (avg 80.5s) | Best so far: epoch 8	train_loss: 0.1377 train_auc: 0.7516	val_loss: 0.0874 val_auc: 0.6877	test_loss: 0.1164 test_auc: 0.7531
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:58:33,859 - INFO - train: {'epoch': 10, 'time_epoch': 72.6515, 'eta': 6399.84916, 'eta_hours': 1.77774, 'loss': 0.13337221, 'lr': 9.932e-05, 'params': 451793, 'time_iter': 0.0706, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76559}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:58:38,075 - INFO - val: {'epoch': 10, 'time_epoch': 4.19042, 'loss': 0.08576692, 'lr': 0, 'params': 451793, 'time_iter': 0.03248, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71644}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:58:42,104 - INFO - test: {'epoch': 10, 'time_epoch': 4.00766, 'loss': 0.1193787, 'lr': 0, 'params': 451793, 'time_iter': 0.03107, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75171}
2025-07-04 17:58:42,106 - INFO - > Epoch 10: took 81.0s (avg 80.6s) | Best so far: epoch 10	train_loss: 0.1334 train_auc: 0.7656	val_loss: 0.0858 val_auc: 0.7164	test_loss: 0.1194 test_auc: 0.7517
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:59:53,037 - INFO - train: {'epoch': 11, 'time_epoch': 70.8688, 'eta': 6320.31687, 'eta_hours': 1.75564, 'loss': 0.13336009, 'lr': 9.902e-05, 'params': 451793, 'time_iter': 0.06887, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76946}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 17:59:57,251 - INFO - val: {'epoch': 11, 'time_epoch': 4.18981, 'loss': 0.08693042, 'lr': 0, 'params': 451793, 'time_iter': 0.03248, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67775}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 18:00:01,449 - INFO - test: {'epoch': 11, 'time_epoch': 4.17918, 'loss': 0.11947463, 'lr': 0, 'params': 451793, 'time_iter': 0.0324, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75009}
2025-07-04 18:00:01,451 - INFO - > Epoch 11: took 79.3s (avg 80.5s) | Best so far: epoch 10	train_loss: 0.1334 train_auc: 0.7656	val_loss: 0.0858 val_auc: 0.7164	test_loss: 0.1194 test_auc: 0.7517
2025-07-04 18:01:12,596 - INFO - train: {'epoch': 12, 'time_epoch': 71.07102, 'eta': 6243.47078, 'eta_hours': 1.7343, 'loss': 0.13105849, 'lr': 9.867e-05, 'params': 451793, 'time_iter': 0.06907, 'accuracy': 0.96258, 'precision': 0.66667, 'recall': 0.00162, 'f1': 0.00324, 'auc': 0.78106}
2025-07-04 18:01:16,610 - INFO - val: {'epoch': 12, 'time_epoch': 3.98867, 'loss': 0.08378916, 'lr': 0, 'params': 451793, 'time_iter': 0.03092, 'accuracy': 0.98152, 'precision': 0.85714, 'recall': 0.07407, 'f1': 0.13636, 'auc': 0.72145}
2025-07-04 18:01:20,627 - INFO - test: {'epoch': 12, 'time_epoch': 3.99883, 'loss': 0.11640628, 'lr': 0, 'params': 451793, 'time_iter': 0.031, 'accuracy': 0.96888, 'precision': 1.0, 'recall': 0.01538, 'f1': 0.0303, 'auc': 0.76153}
2025-07-04 18:01:20,630 - INFO - > Epoch 12: took 79.2s (avg 80.4s) | Best so far: epoch 12	train_loss: 0.1311 train_auc: 0.7811	val_loss: 0.0838 val_auc: 0.7215	test_loss: 0.1164 test_auc: 0.7615
2025-07-04 18:02:31,821 - INFO - train: {'epoch': 13, 'time_epoch': 71.11444, 'eta': 6167.71641, 'eta_hours': 1.71325, 'loss': 0.12923333, 'lr': 9.826e-05, 'params': 451793, 'time_iter': 0.06911, 'accuracy': 0.96286, 'precision': 0.69231, 'recall': 0.01461, 'f1': 0.02862, 'auc': 0.78854}
2025-07-04 18:02:36,077 - INFO - val: {'epoch': 13, 'time_epoch': 4.22707, 'loss': 0.08649702, 'lr': 0, 'params': 451793, 'time_iter': 0.03277, 'accuracy': 0.98104, 'precision': 0.71429, 'recall': 0.06173, 'f1': 0.11364, 'auc': 0.7105}
2025-07-04 18:02:40,397 - INFO - test: {'epoch': 13, 'time_epoch': 4.29987, 'loss': 0.11809402, 'lr': 0, 'params': 451793, 'time_iter': 0.03333, 'accuracy': 0.96888, 'precision': 0.66667, 'recall': 0.03077, 'f1': 0.05882, 'auc': 0.75112}
2025-07-04 18:02:40,399 - INFO - > Epoch 13: took 79.8s (avg 80.3s) | Best so far: epoch 12	train_loss: 0.1311 train_auc: 0.7811	val_loss: 0.0838 val_auc: 0.7215	test_loss: 0.1164 test_auc: 0.7615
2025-07-04 18:03:52,046 - INFO - train: {'epoch': 14, 'time_epoch': 71.5693, 'eta': 6095.15825, 'eta_hours': 1.6931, 'loss': 0.12867091, 'lr': 9.78e-05, 'params': 451793, 'time_iter': 0.06955, 'accuracy': 0.96322, 'precision': 0.64474, 'recall': 0.03977, 'f1': 0.07492, 'auc': 0.7918}
2025-07-04 18:03:56,198 - INFO - val: {'epoch': 14, 'time_epoch': 4.12629, 'loss': 0.0846563, 'lr': 0, 'params': 451793, 'time_iter': 0.03199, 'accuracy': 0.98201, 'precision': 0.68421, 'recall': 0.16049, 'f1': 0.26, 'auc': 0.72446}
2025-07-04 18:04:00,309 - INFO - test: {'epoch': 14, 'time_epoch': 4.09072, 'loss': 0.11564925, 'lr': 0, 'params': 451793, 'time_iter': 0.03171, 'accuracy': 0.97058, 'precision': 0.66667, 'recall': 0.13846, 'f1': 0.2293, 'auc': 0.76941}
2025-07-04 18:04:00,311 - INFO - > Epoch 14: took 79.9s (avg 80.3s) | Best so far: epoch 14	train_loss: 0.1287 train_auc: 0.7918	val_loss: 0.0847 val_auc: 0.7245	test_loss: 0.1156 test_auc: 0.7694
2025-07-04 18:05:12,724 - INFO - train: {'epoch': 15, 'time_epoch': 72.33727, 'eta': 6026.75554, 'eta_hours': 1.6741, 'loss': 0.12821956, 'lr': 9.729e-05, 'params': 451793, 'time_iter': 0.0703, 'accuracy': 0.96337, 'precision': 0.67089, 'recall': 0.04302, 'f1': 0.08085, 'auc': 0.79418}
2025-07-04 18:05:17,189 - INFO - val: {'epoch': 15, 'time_epoch': 4.43727, 'loss': 0.08574367, 'lr': 0, 'params': 451793, 'time_iter': 0.0344, 'accuracy': 0.98201, 'precision': 0.81818, 'recall': 0.11111, 'f1': 0.19565, 'auc': 0.71474}
2025-07-04 18:05:21,474 - INFO - test: {'epoch': 15, 'time_epoch': 4.26428, 'loss': 0.11548899, 'lr': 0, 'params': 451793, 'time_iter': 0.03306, 'accuracy': 0.97131, 'precision': 0.8, 'recall': 0.12308, 'f1': 0.21333, 'auc': 0.76598}
2025-07-04 18:05:21,478 - INFO - > Epoch 15: took 81.2s (avg 80.4s) | Best so far: epoch 14	train_loss: 0.1287 train_auc: 0.7918	val_loss: 0.0847 val_auc: 0.7245	test_loss: 0.1156 test_auc: 0.7694
2025-07-04 18:06:33,506 - INFO - train: {'epoch': 16, 'time_epoch': 71.94859, 'eta': 5955.99225, 'eta_hours': 1.65444, 'loss': 0.12656919, 'lr': 9.673e-05, 'params': 451793, 'time_iter': 0.06992, 'accuracy': 0.9635, 'precision': 0.6069, 'recall': 0.07143, 'f1': 0.12781, 'auc': 0.79865}
2025-07-04 18:06:37,836 - INFO - val: {'epoch': 16, 'time_epoch': 4.29938, 'loss': 0.08455265, 'lr': 0, 'params': 451793, 'time_iter': 0.03333, 'accuracy': 0.98347, 'precision': 0.76, 'recall': 0.23457, 'f1': 0.35849, 'auc': 0.72978}
2025-07-04 18:06:42,116 - INFO - test: {'epoch': 16, 'time_epoch': 4.25902, 'loss': 0.11899788, 'lr': 0, 'params': 451793, 'time_iter': 0.03302, 'accuracy': 0.97009, 'precision': 0.6129, 'recall': 0.14615, 'f1': 0.23602, 'auc': 0.74582}
2025-07-04 18:06:42,118 - INFO - > Epoch 16: took 80.6s (avg 80.4s) | Best so far: epoch 16	train_loss: 0.1266 train_auc: 0.7986	val_loss: 0.0846 val_auc: 0.7298	test_loss: 0.1190 test_auc: 0.7458
2025-07-04 18:07:54,386 - INFO - train: {'epoch': 17, 'time_epoch': 72.1891, 'eta': 5886.1929, 'eta_hours': 1.63505, 'loss': 0.12511762, 'lr': 9.611e-05, 'params': 451793, 'time_iter': 0.07015, 'accuracy': 0.96429, 'precision': 0.66286, 'recall': 0.09416, 'f1': 0.16489, 'auc': 0.80857}
2025-07-04 18:07:58,466 - INFO - val: {'epoch': 17, 'time_epoch': 4.05526, 'loss': 0.08566821, 'lr': 0, 'params': 451793, 'time_iter': 0.03144, 'accuracy': 0.98128, 'precision': 0.57692, 'recall': 0.18519, 'f1': 0.28037, 'auc': 0.71315}
2025-07-04 18:08:02,640 - INFO - test: {'epoch': 17, 'time_epoch': 4.15345, 'loss': 0.11587262, 'lr': 0, 'params': 451793, 'time_iter': 0.0322, 'accuracy': 0.97058, 'precision': 0.62162, 'recall': 0.17692, 'f1': 0.27545, 'auc': 0.76545}
2025-07-04 18:08:02,643 - INFO - > Epoch 17: took 80.5s (avg 80.4s) | Best so far: epoch 16	train_loss: 0.1266 train_auc: 0.7986	val_loss: 0.0846 val_auc: 0.7298	test_loss: 0.1190 test_auc: 0.7458
2025-07-04 18:09:14,558 - INFO - train: {'epoch': 18, 'time_epoch': 71.83712, 'eta': 5814.64146, 'eta_hours': 1.61518, 'loss': 0.12480472, 'lr': 9.545e-05, 'params': 451793, 'time_iter': 0.06981, 'accuracy': 0.96444, 'precision': 0.63717, 'recall': 0.11688, 'f1': 0.19753, 'auc': 0.80238}
2025-07-04 18:09:18,872 - INFO - val: {'epoch': 18, 'time_epoch': 4.28474, 'loss': 0.08268541, 'lr': 0, 'params': 451793, 'time_iter': 0.03322, 'accuracy': 0.98274, 'precision': 0.75, 'recall': 0.18519, 'f1': 0.29703, 'auc': 0.73421}
2025-07-04 18:09:23,047 - INFO - test: {'epoch': 18, 'time_epoch': 4.15484, 'loss': 0.11911944, 'lr': 0, 'params': 451793, 'time_iter': 0.03221, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.07692, 'f1': 0.13333, 'auc': 0.75076}
2025-07-04 18:09:23,051 - INFO - > Epoch 18: took 80.4s (avg 80.4s) | Best so far: epoch 18	train_loss: 0.1248 train_auc: 0.8024	val_loss: 0.0827 val_auc: 0.7342	test_loss: 0.1191 test_auc: 0.7508
2025-07-04 18:10:35,516 - INFO - train: {'epoch': 19, 'time_epoch': 72.38776, 'eta': 5745.26402, 'eta_hours': 1.59591, 'loss': 0.12192318, 'lr': 9.474e-05, 'params': 451793, 'time_iter': 0.07035, 'accuracy': 0.96508, 'precision': 0.66023, 'recall': 0.1388, 'f1': 0.22938, 'auc': 0.81238}
2025-07-04 18:10:39,817 - INFO - val: {'epoch': 19, 'time_epoch': 4.26941, 'loss': 0.07827243, 'lr': 0, 'params': 451793, 'time_iter': 0.0331, 'accuracy': 0.98274, 'precision': 0.72727, 'recall': 0.19753, 'f1': 0.31068, 'auc': 0.76055}
2025-07-04 18:10:44,011 - INFO - test: {'epoch': 19, 'time_epoch': 4.17061, 'loss': 0.11653468, 'lr': 0, 'params': 451793, 'time_iter': 0.03233, 'accuracy': 0.97107, 'precision': 0.67742, 'recall': 0.16154, 'f1': 0.26087, 'auc': 0.75326}
2025-07-04 18:10:44,016 - INFO - > Epoch 19: took 81.0s (avg 80.4s) | Best so far: epoch 19	train_loss: 0.1219 train_auc: 0.8124	val_loss: 0.0783 val_auc: 0.7605	test_loss: 0.1165 test_auc: 0.7533
2025-07-04 18:11:55,979 - INFO - train: {'epoch': 20, 'time_epoch': 71.88185, 'eta': 5673.69669, 'eta_hours': 1.57603, 'loss': 0.1211446, 'lr': 9.397e-05, 'params': 451793, 'time_iter': 0.06986, 'accuracy': 0.96559, 'precision': 0.64451, 'recall': 0.18101, 'f1': 0.28264, 'auc': 0.81911}
2025-07-04 18:12:00,134 - INFO - val: {'epoch': 20, 'time_epoch': 4.12575, 'loss': 0.08191664, 'lr': 0, 'params': 451793, 'time_iter': 0.03198, 'accuracy': 0.98225, 'precision': 0.65385, 'recall': 0.20988, 'f1': 0.31776, 'auc': 0.7355}
2025-07-04 18:12:04,315 - INFO - test: {'epoch': 20, 'time_epoch': 4.15961, 'loss': 0.12251187, 'lr': 0, 'params': 451793, 'time_iter': 0.03225, 'accuracy': 0.97034, 'precision': 0.65385, 'recall': 0.13077, 'f1': 0.21795, 'auc': 0.7124}
2025-07-04 18:12:04,318 - INFO - > Epoch 20: took 80.3s (avg 80.4s) | Best so far: epoch 19	train_loss: 0.1219 train_auc: 0.8124	val_loss: 0.0783 val_auc: 0.7605	test_loss: 0.1165 test_auc: 0.7533
2025-07-04 18:13:15,793 - INFO - train: {'epoch': 21, 'time_epoch': 71.39565, 'eta': 5600.37697, 'eta_hours': 1.55566, 'loss': 0.12164205, 'lr': 9.316e-05, 'params': 451793, 'time_iter': 0.06938, 'accuracy': 0.9655, 'precision': 0.6633, 'recall': 0.1599, 'f1': 0.25768, 'auc': 0.81048}
2025-07-04 18:13:20,005 - INFO - val: {'epoch': 21, 'time_epoch': 4.18607, 'loss': 0.07731567, 'lr': 0, 'params': 451793, 'time_iter': 0.03245, 'accuracy': 0.98274, 'precision': 0.77778, 'recall': 0.17284, 'f1': 0.28283, 'auc': 0.751}
2025-07-04 18:13:24,179 - INFO - test: {'epoch': 21, 'time_epoch': 4.14083, 'loss': 0.12098022, 'lr': 0, 'params': 451793, 'time_iter': 0.0321, 'accuracy': 0.97058, 'precision': 0.69565, 'recall': 0.12308, 'f1': 0.20915, 'auc': 0.75112}
2025-07-04 18:13:24,199 - INFO - > Epoch 21: took 79.9s (avg 80.4s) | Best so far: epoch 19	train_loss: 0.1219 train_auc: 0.8124	val_loss: 0.0783 val_auc: 0.7605	test_loss: 0.1165 test_auc: 0.7533
2025-07-04 18:14:36,095 - INFO - train: {'epoch': 22, 'time_epoch': 71.81839, 'eta': 5528.63983, 'eta_hours': 1.53573, 'loss': 0.11977486, 'lr': 9.23e-05, 'params': 451793, 'time_iter': 0.06979, 'accuracy': 0.96477, 'precision': 0.59194, 'recall': 0.19075, 'f1': 0.28852, 'auc': 0.82319}
2025-07-04 18:14:40,595 - INFO - val: {'epoch': 22, 'time_epoch': 4.47431, 'loss': 0.07774293, 'lr': 0, 'params': 451793, 'time_iter': 0.03468, 'accuracy': 0.98347, 'precision': 0.74074, 'recall': 0.24691, 'f1': 0.37037, 'auc': 0.74258}
2025-07-04 18:14:44,951 - INFO - test: {'epoch': 22, 'time_epoch': 4.33727, 'loss': 0.11805974, 'lr': 0, 'params': 451793, 'time_iter': 0.03362, 'accuracy': 0.97155, 'precision': 0.72414, 'recall': 0.16154, 'f1': 0.26415, 'auc': 0.75026}
2025-07-04 18:14:44,954 - INFO - > Epoch 22: took 80.8s (avg 80.4s) | Best so far: epoch 19	train_loss: 0.1219 train_auc: 0.8124	val_loss: 0.0783 val_auc: 0.7605	test_loss: 0.1165 test_auc: 0.7533
2025-07-04 18:15:57,186 - INFO - train: {'epoch': 23, 'time_epoch': 72.15371, 'eta': 5457.95777, 'eta_hours': 1.5161, 'loss': 0.11973534, 'lr': 9.14e-05, 'params': 451793, 'time_iter': 0.07012, 'accuracy': 0.96572, 'precision': 0.63472, 'recall': 0.19886, 'f1': 0.30284, 'auc': 0.82224}
2025-07-04 18:16:01,498 - INFO - val: {'epoch': 23, 'time_epoch': 4.2834, 'loss': 0.07865034, 'lr': 0, 'params': 451793, 'time_iter': 0.0332, 'accuracy': 0.98274, 'precision': 0.70833, 'recall': 0.20988, 'f1': 0.32381, 'auc': 0.73601}
2025-07-04 18:16:05,663 - INFO - test: {'epoch': 23, 'time_epoch': 4.14617, 'loss': 0.11899926, 'lr': 0, 'params': 451793, 'time_iter': 0.03214, 'accuracy': 0.97155, 'precision': 0.78261, 'recall': 0.13846, 'f1': 0.23529, 'auc': 0.75518}
2025-07-04 18:16:05,665 - INFO - > Epoch 23: took 80.7s (avg 80.4s) | Best so far: epoch 19	train_loss: 0.1219 train_auc: 0.8124	val_loss: 0.0783 val_auc: 0.7605	test_loss: 0.1165 test_auc: 0.7533
2025-07-04 18:17:17,158 - INFO - train: {'epoch': 24, 'time_epoch': 71.41112, 'eta': 5384.93018, 'eta_hours': 1.49581, 'loss': 0.11910197, 'lr': 9.045e-05, 'params': 451793, 'time_iter': 0.0694, 'accuracy': 0.96568, 'precision': 0.62233, 'recall': 0.21266, 'f1': 0.317, 'auc': 0.81628}
2025-07-04 18:17:21,351 - INFO - val: {'epoch': 24, 'time_epoch': 4.16713, 'loss': 0.07931623, 'lr': 0, 'params': 451793, 'time_iter': 0.0323, 'accuracy': 0.98322, 'precision': 0.6875, 'recall': 0.2716, 'f1': 0.38938, 'auc': 0.73018}
2025-07-04 18:17:25,502 - INFO - test: {'epoch': 24, 'time_epoch': 4.12914, 'loss': 0.12031973, 'lr': 0, 'params': 451793, 'time_iter': 0.03201, 'accuracy': 0.96961, 'precision': 0.56757, 'recall': 0.16154, 'f1': 0.2515, 'auc': 0.74708}
2025-07-04 18:17:25,506 - INFO - > Epoch 24: took 79.8s (avg 80.4s) | Best so far: epoch 19	train_loss: 0.1219 train_auc: 0.8124	val_loss: 0.0783 val_auc: 0.7605	test_loss: 0.1165 test_auc: 0.7533
2025-07-04 18:18:37,972 - INFO - train: {'epoch': 25, 'time_epoch': 72.38409, 'eta': 5314.79618, 'eta_hours': 1.47633, 'loss': 0.11745327, 'lr': 8.946e-05, 'params': 451793, 'time_iter': 0.07034, 'accuracy': 0.96648, 'precision': 0.65693, 'recall': 0.21916, 'f1': 0.32867, 'auc': 0.82489}
2025-07-04 18:18:42,216 - INFO - val: {'epoch': 25, 'time_epoch': 4.21788, 'loss': 0.07511007, 'lr': 0, 'params': 451793, 'time_iter': 0.0327, 'accuracy': 0.98347, 'precision': 0.76, 'recall': 0.23457, 'f1': 0.35849, 'auc': 0.75878}
2025-07-04 18:18:46,318 - INFO - test: {'epoch': 25, 'time_epoch': 4.08, 'loss': 0.11689558, 'lr': 0, 'params': 451793, 'time_iter': 0.03163, 'accuracy': 0.97009, 'precision': 0.76923, 'recall': 0.07692, 'f1': 0.13986, 'auc': 0.7545}
2025-07-04 18:18:46,321 - INFO - > Epoch 25: took 80.8s (avg 80.4s) | Best so far: epoch 19	train_loss: 0.1219 train_auc: 0.8124	val_loss: 0.0783 val_auc: 0.7605	test_loss: 0.1165 test_auc: 0.7533
2025-07-04 18:19:58,545 - INFO - train: {'epoch': 26, 'time_epoch': 72.14729, 'eta': 5243.85526, 'eta_hours': 1.45663, 'loss': 0.11671253, 'lr': 8.842e-05, 'params': 451793, 'time_iter': 0.07011, 'accuracy': 0.96578, 'precision': 0.63184, 'recall': 0.20617, 'f1': 0.31089, 'auc': 0.83609}
2025-07-04 18:20:02,868 - INFO - val: {'epoch': 26, 'time_epoch': 4.29388, 'loss': 0.07795089, 'lr': 0, 'params': 451793, 'time_iter': 0.03329, 'accuracy': 0.98298, 'precision': 0.65714, 'recall': 0.28395, 'f1': 0.39655, 'auc': 0.77342}
2025-07-04 18:20:07,094 - INFO - test: {'epoch': 26, 'time_epoch': 4.20343, 'loss': 0.11871506, 'lr': 0, 'params': 451793, 'time_iter': 0.03258, 'accuracy': 0.97034, 'precision': 0.60526, 'recall': 0.17692, 'f1': 0.27381, 'auc': 0.74468}
2025-07-04 18:20:07,110 - INFO - > Epoch 26: took 80.8s (avg 80.4s) | Best so far: epoch 26	train_loss: 0.1167 train_auc: 0.8361	val_loss: 0.0780 val_auc: 0.7734	test_loss: 0.1187 test_auc: 0.7447
2025-07-04 18:21:19,035 - INFO - train: {'epoch': 27, 'time_epoch': 71.61559, 'eta': 5171.46095, 'eta_hours': 1.43652, 'loss': 0.11687262, 'lr': 8.734e-05, 'params': 451793, 'time_iter': 0.0696, 'accuracy': 0.96684, 'precision': 0.65632, 'recall': 0.24026, 'f1': 0.35175, 'auc': 0.82497}
2025-07-04 18:21:23,240 - INFO - val: {'epoch': 27, 'time_epoch': 4.17982, 'loss': 0.07624255, 'lr': 0, 'params': 451793, 'time_iter': 0.0324, 'accuracy': 0.98371, 'precision': 0.69444, 'recall': 0.30864, 'f1': 0.42735, 'auc': 0.78681}
2025-07-04 18:21:27,596 - INFO - test: {'epoch': 27, 'time_epoch': 4.33602, 'loss': 0.11932443, 'lr': 0, 'params': 451793, 'time_iter': 0.03361, 'accuracy': 0.96937, 'precision': 0.54348, 'recall': 0.19231, 'f1': 0.28409, 'auc': 0.75525}
2025-07-04 18:21:27,600 - INFO - > Epoch 27: took 80.5s (avg 80.4s) | Best so far: epoch 27	train_loss: 0.1169 train_auc: 0.8250	val_loss: 0.0762 val_auc: 0.7868	test_loss: 0.1193 test_auc: 0.7552
2025-07-04 18:22:41,444 - INFO - train: {'epoch': 28, 'time_epoch': 73.76906, 'eta': 5104.39264, 'eta_hours': 1.41789, 'loss': 0.1148353, 'lr': 8.622e-05, 'params': 451793, 'time_iter': 0.07169, 'accuracy': 0.96742, 'precision': 0.66878, 'recall': 0.25731, 'f1': 0.37163, 'auc': 0.83216}
2025-07-04 18:22:45,651 - INFO - val: {'epoch': 28, 'time_epoch': 4.18187, 'loss': 0.07779213, 'lr': 0, 'params': 451793, 'time_iter': 0.03242, 'accuracy': 0.98249, 'precision': 0.60976, 'recall': 0.30864, 'f1': 0.40984, 'auc': 0.76567}
2025-07-04 18:22:49,873 - INFO - test: {'epoch': 28, 'time_epoch': 4.20172, 'loss': 0.11582692, 'lr': 0, 'params': 451793, 'time_iter': 0.03257, 'accuracy': 0.97009, 'precision': 0.56604, 'recall': 0.23077, 'f1': 0.32787, 'auc': 0.76732}
2025-07-04 18:22:49,876 - INFO - > Epoch 28: took 82.3s (avg 80.5s) | Best so far: epoch 27	train_loss: 0.1169 train_auc: 0.8250	val_loss: 0.0762 val_auc: 0.7868	test_loss: 0.1193 test_auc: 0.7552
2025-07-04 18:24:00,166 - INFO - train: {'epoch': 29, 'time_epoch': 70.21201, 'eta': 5028.5778, 'eta_hours': 1.39683, 'loss': 0.11578569, 'lr': 8.506e-05, 'params': 451793, 'time_iter': 0.06823, 'accuracy': 0.96711, 'precision': 0.65496, 'recall': 0.25731, 'f1': 0.36946, 'auc': 0.83475}
2025-07-04 18:24:04,537 - INFO - val: {'epoch': 29, 'time_epoch': 4.34555, 'loss': 0.07687246, 'lr': 0, 'params': 451793, 'time_iter': 0.03369, 'accuracy': 0.98322, 'precision': 0.66667, 'recall': 0.2963, 'f1': 0.41026, 'auc': 0.73737}
2025-07-04 18:24:08,895 - INFO - test: {'epoch': 29, 'time_epoch': 4.33736, 'loss': 0.11924552, 'lr': 0, 'params': 451793, 'time_iter': 0.03362, 'accuracy': 0.97082, 'precision': 0.625, 'recall': 0.19231, 'f1': 0.29412, 'auc': 0.74757}
2025-07-04 18:24:08,897 - INFO - > Epoch 29: took 79.0s (avg 80.4s) | Best so far: epoch 27	train_loss: 0.1169 train_auc: 0.8250	val_loss: 0.0762 val_auc: 0.7868	test_loss: 0.1193 test_auc: 0.7552
2025-07-04 18:25:19,978 - INFO - train: {'epoch': 30, 'time_epoch': 71.0027, 'eta': 4954.88437, 'eta_hours': 1.37636, 'loss': 0.11471652, 'lr': 8.386e-05, 'params': 451793, 'time_iter': 0.069, 'accuracy': 0.96799, 'precision': 0.67793, 'recall': 0.27679, 'f1': 0.39308, 'auc': 0.83593}
2025-07-04 18:25:24,236 - INFO - val: {'epoch': 30, 'time_epoch': 4.22873, 'loss': 0.07543962, 'lr': 0, 'params': 451793, 'time_iter': 0.03278, 'accuracy': 0.98347, 'precision': 0.67568, 'recall': 0.30864, 'f1': 0.42373, 'auc': 0.77036}
2025-07-04 18:25:28,461 - INFO - test: {'epoch': 30, 'time_epoch': 4.2008, 'loss': 0.11645584, 'lr': 0, 'params': 451793, 'time_iter': 0.03256, 'accuracy': 0.97058, 'precision': 0.58824, 'recall': 0.23077, 'f1': 0.33149, 'auc': 0.76297}
2025-07-04 18:25:28,465 - INFO - > Epoch 30: took 79.6s (avg 80.4s) | Best so far: epoch 27	train_loss: 0.1169 train_auc: 0.8250	val_loss: 0.0762 val_auc: 0.7868	test_loss: 0.1193 test_auc: 0.7552
2025-07-04 18:26:42,284 - INFO - train: {'epoch': 31, 'time_epoch': 73.72984, 'eta': 4887.15428, 'eta_hours': 1.35754, 'loss': 0.11352999, 'lr': 8.263e-05, 'params': 451793, 'time_iter': 0.07165, 'accuracy': 0.96711, 'precision': 0.64591, 'recall': 0.26948, 'f1': 0.3803, 'auc': 0.84134}
2025-07-04 18:26:46,844 - INFO - val: {'epoch': 31, 'time_epoch': 4.47834, 'loss': 0.07397847, 'lr': 0, 'params': 451793, 'time_iter': 0.03472, 'accuracy': 0.98249, 'precision': 0.61538, 'recall': 0.2963, 'f1': 0.4, 'auc': 0.81664}
2025-07-04 18:26:51,304 - INFO - test: {'epoch': 31, 'time_epoch': 4.43388, 'loss': 0.11512877, 'lr': 0, 'params': 451793, 'time_iter': 0.03437, 'accuracy': 0.96937, 'precision': 0.54545, 'recall': 0.18462, 'f1': 0.27586, 'auc': 0.76902}
2025-07-04 18:26:51,311 - INFO - > Epoch 31: took 82.8s (avg 80.5s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:27:58,389 - INFO - train: {'epoch': 32, 'time_epoch': 67.01112, 'eta': 4805.41954, 'eta_hours': 1.33484, 'loss': 0.11192126, 'lr': 8.136e-05, 'params': 451793, 'time_iter': 0.06512, 'accuracy': 0.96839, 'precision': 0.68045, 'recall': 0.29383, 'f1': 0.41043, 'auc': 0.84629}
2025-07-04 18:28:02,044 - INFO - val: {'epoch': 32, 'time_epoch': 3.62666, 'loss': 0.07393886, 'lr': 0, 'params': 451793, 'time_iter': 0.02811, 'accuracy': 0.98371, 'precision': 0.69444, 'recall': 0.30864, 'f1': 0.42735, 'auc': 0.77811}
2025-07-04 18:28:05,683 - INFO - test: {'epoch': 32, 'time_epoch': 3.62101, 'loss': 0.12295053, 'lr': 0, 'params': 451793, 'time_iter': 0.02807, 'accuracy': 0.96961, 'precision': 0.61905, 'recall': 0.1, 'f1': 0.17219, 'auc': 0.73327}
2025-07-04 18:28:05,686 - INFO - > Epoch 32: took 74.4s (avg 80.3s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:29:11,913 - INFO - train: {'epoch': 33, 'time_epoch': 66.15941, 'eta': 4722.89758, 'eta_hours': 1.31192, 'loss': 0.11324821, 'lr': 8.005e-05, 'params': 451793, 'time_iter': 0.06429, 'accuracy': 0.96748, 'precision': 0.65759, 'recall': 0.27435, 'f1': 0.38717, 'auc': 0.84396}
2025-07-04 18:29:16,201 - INFO - val: {'epoch': 33, 'time_epoch': 4.24276, 'loss': 0.07484867, 'lr': 0, 'params': 451793, 'time_iter': 0.03289, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.78017}
2025-07-04 18:29:20,804 - INFO - test: {'epoch': 33, 'time_epoch': 4.5829, 'loss': 0.11447243, 'lr': 0, 'params': 451793, 'time_iter': 0.03553, 'accuracy': 0.97034, 'precision': 0.58696, 'recall': 0.20769, 'f1': 0.30682, 'auc': 0.76982}
2025-07-04 18:29:20,809 - INFO - > Epoch 33: took 75.1s (avg 80.1s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:30:45,967 - INFO - train: {'epoch': 34, 'time_epoch': 85.06585, 'eta': 4676.42257, 'eta_hours': 1.29901, 'loss': 0.11223894, 'lr': 7.872e-05, 'params': 451793, 'time_iter': 0.08267, 'accuracy': 0.96803, 'precision': 0.68672, 'recall': 0.26867, 'f1': 0.38623, 'auc': 0.84478}
2025-07-04 18:30:50,767 - INFO - val: {'epoch': 34, 'time_epoch': 4.75109, 'loss': 0.07437933, 'lr': 0, 'params': 451793, 'time_iter': 0.03683, 'accuracy': 0.98371, 'precision': 0.69444, 'recall': 0.30864, 'f1': 0.42735, 'auc': 0.78305}
2025-07-04 18:30:55,449 - INFO - test: {'epoch': 34, 'time_epoch': 4.65235, 'loss': 0.11426312, 'lr': 0, 'params': 451793, 'time_iter': 0.03606, 'accuracy': 0.97082, 'precision': 0.60417, 'recall': 0.22308, 'f1': 0.32584, 'auc': 0.78181}
2025-07-04 18:30:55,452 - INFO - > Epoch 34: took 94.6s (avg 80.6s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:32:25,467 - INFO - train: {'epoch': 35, 'time_epoch': 89.91904, 'eta': 4636.43153, 'eta_hours': 1.2879, 'loss': 0.11183345, 'lr': 7.735e-05, 'params': 451793, 'time_iter': 0.08738, 'accuracy': 0.96803, 'precision': 0.67928, 'recall': 0.27679, 'f1': 0.39331, 'auc': 0.84475}
2025-07-04 18:32:30,259 - INFO - val: {'epoch': 35, 'time_epoch': 4.75687, 'loss': 0.07364946, 'lr': 0, 'params': 451793, 'time_iter': 0.03687, 'accuracy': 0.98371, 'precision': 0.69444, 'recall': 0.30864, 'f1': 0.42735, 'auc': 0.79753}
2025-07-04 18:32:35,084 - INFO - test: {'epoch': 35, 'time_epoch': 4.7979, 'loss': 0.11675511, 'lr': 0, 'params': 451793, 'time_iter': 0.03719, 'accuracy': 0.97034, 'precision': 0.64286, 'recall': 0.13846, 'f1': 0.22785, 'auc': 0.77221}
2025-07-04 18:32:35,089 - INFO - > Epoch 35: took 99.6s (avg 81.1s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:34:02,658 - INFO - train: {'epoch': 36, 'time_epoch': 87.47235, 'eta': 4589.57569, 'eta_hours': 1.27488, 'loss': 0.11228114, 'lr': 7.595e-05, 'params': 451793, 'time_iter': 0.08501, 'accuracy': 0.96693, 'precision': 0.639, 'recall': 0.26867, 'f1': 0.37829, 'auc': 0.84657}
2025-07-04 18:34:07,316 - INFO - val: {'epoch': 36, 'time_epoch': 4.61815, 'loss': 0.07654605, 'lr': 0, 'params': 451793, 'time_iter': 0.0358, 'accuracy': 0.98249, 'precision': 0.60465, 'recall': 0.32099, 'f1': 0.41935, 'auc': 0.78815}
2025-07-04 18:34:11,988 - INFO - test: {'epoch': 36, 'time_epoch': 4.62385, 'loss': 0.1117098, 'lr': 0, 'params': 451793, 'time_iter': 0.03584, 'accuracy': 0.97082, 'precision': 0.57143, 'recall': 0.30769, 'f1': 0.4, 'auc': 0.78027}
2025-07-04 18:34:11,991 - INFO - > Epoch 36: took 96.9s (avg 81.5s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:35:30,284 - INFO - train: {'epoch': 37, 'time_epoch': 78.19843, 'eta': 4525.45101, 'eta_hours': 1.25707, 'loss': 0.1103564, 'lr': 7.452e-05, 'params': 451793, 'time_iter': 0.07599, 'accuracy': 0.96954, 'precision': 0.71375, 'recall': 0.31169, 'f1': 0.4339, 'auc': 0.84323}
2025-07-04 18:35:34,995 - INFO - val: {'epoch': 37, 'time_epoch': 4.66632, 'loss': 0.07516632, 'lr': 0, 'params': 451793, 'time_iter': 0.03617, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.77916}
2025-07-04 18:35:39,544 - INFO - test: {'epoch': 37, 'time_epoch': 4.52281, 'loss': 0.11590289, 'lr': 0, 'params': 451793, 'time_iter': 0.03506, 'accuracy': 0.97082, 'precision': 0.625, 'recall': 0.19231, 'f1': 0.29412, 'auc': 0.76752}
2025-07-04 18:35:39,547 - INFO - > Epoch 37: took 87.6s (avg 81.7s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:36:57,135 - INFO - train: {'epoch': 38, 'time_epoch': 77.50148, 'eta': 4459.51449, 'eta_hours': 1.23875, 'loss': 0.10924377, 'lr': 7.307e-05, 'params': 451793, 'time_iter': 0.07532, 'accuracy': 0.96888, 'precision': 0.69772, 'recall': 0.29789, 'f1': 0.41752, 'auc': 0.85265}
2025-07-04 18:37:01,770 - INFO - val: {'epoch': 38, 'time_epoch': 4.60542, 'loss': 0.07467257, 'lr': 0, 'params': 451793, 'time_iter': 0.0357, 'accuracy': 0.98371, 'precision': 0.69444, 'recall': 0.30864, 'f1': 0.42735, 'auc': 0.78497}
2025-07-04 18:37:06,325 - INFO - test: {'epoch': 38, 'time_epoch': 4.53341, 'loss': 0.11869855, 'lr': 0, 'params': 451793, 'time_iter': 0.03514, 'accuracy': 0.97034, 'precision': 0.60526, 'recall': 0.17692, 'f1': 0.27381, 'auc': 0.77147}
2025-07-04 18:37:06,327 - INFO - > Epoch 38: took 86.8s (avg 81.8s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:38:23,291 - INFO - train: {'epoch': 39, 'time_epoch': 76.87491, 'eta': 4392.05986, 'eta_hours': 1.22002, 'loss': 0.11138904, 'lr': 7.159e-05, 'params': 451793, 'time_iter': 0.07471, 'accuracy': 0.96872, 'precision': 0.69557, 'recall': 0.29302, 'f1': 0.41234, 'auc': 0.84503}
2025-07-04 18:38:27,840 - INFO - val: {'epoch': 39, 'time_epoch': 4.52005, 'loss': 0.07754121, 'lr': 0, 'params': 451793, 'time_iter': 0.03504, 'accuracy': 0.98177, 'precision': 0.56522, 'recall': 0.32099, 'f1': 0.40945, 'auc': 0.7637}
2025-07-04 18:38:32,357 - INFO - test: {'epoch': 39, 'time_epoch': 4.49616, 'loss': 0.11610743, 'lr': 0, 'params': 451793, 'time_iter': 0.03485, 'accuracy': 0.96888, 'precision': 0.51515, 'recall': 0.26154, 'f1': 0.34694, 'auc': 0.77944}
2025-07-04 18:38:32,360 - INFO - > Epoch 39: took 86.0s (avg 81.9s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:39:50,338 - INFO - train: {'epoch': 40, 'time_epoch': 77.89039, 'eta': 4325.60702, 'eta_hours': 1.20156, 'loss': 0.10921179, 'lr': 7.008e-05, 'params': 451793, 'time_iter': 0.0757, 'accuracy': 0.96827, 'precision': 0.67279, 'recall': 0.29708, 'f1': 0.41216, 'auc': 0.85352}
2025-07-04 18:39:54,973 - INFO - val: {'epoch': 40, 'time_epoch': 4.60317, 'loss': 0.07751115, 'lr': 0, 'params': 451793, 'time_iter': 0.03568, 'accuracy': 0.98249, 'precision': 0.61538, 'recall': 0.2963, 'f1': 0.4, 'auc': 0.73836}
2025-07-04 18:39:59,584 - INFO - test: {'epoch': 40, 'time_epoch': 4.58552, 'loss': 0.11691125, 'lr': 0, 'params': 451793, 'time_iter': 0.03555, 'accuracy': 0.97107, 'precision': 0.63415, 'recall': 0.2, 'f1': 0.30409, 'auc': 0.76619}
2025-07-04 18:39:59,587 - INFO - > Epoch 40: took 87.2s (avg 82.0s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:41:16,801 - INFO - train: {'epoch': 41, 'time_epoch': 77.12509, 'eta': 4257.55268, 'eta_hours': 1.18265, 'loss': 0.10950155, 'lr': 6.856e-05, 'params': 451793, 'time_iter': 0.07495, 'accuracy': 0.96857, 'precision': 0.69112, 'recall': 0.29058, 'f1': 0.40914, 'auc': 0.85681}
2025-07-04 18:41:21,440 - INFO - val: {'epoch': 41, 'time_epoch': 4.61008, 'loss': 0.07414829, 'lr': 0, 'params': 451793, 'time_iter': 0.03574, 'accuracy': 0.98274, 'precision': 0.625, 'recall': 0.30864, 'f1': 0.41322, 'auc': 0.80526}
2025-07-04 18:41:26,082 - INFO - test: {'epoch': 41, 'time_epoch': 4.62043, 'loss': 0.11691388, 'lr': 0, 'params': 451793, 'time_iter': 0.03582, 'accuracy': 0.97009, 'precision': 0.56863, 'recall': 0.22308, 'f1': 0.32044, 'auc': 0.77512}
2025-07-04 18:41:26,085 - INFO - > Epoch 41: took 86.5s (avg 82.2s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:42:43,385 - INFO - train: {'epoch': 42, 'time_epoch': 77.21223, 'eta': 4189.19196, 'eta_hours': 1.16366, 'loss': 0.10826957, 'lr': 6.701e-05, 'params': 451793, 'time_iter': 0.07504, 'accuracy': 0.96875, 'precision': 0.68345, 'recall': 0.30844, 'f1': 0.42506, 'auc': 0.86126}
2025-07-04 18:42:47,912 - INFO - val: {'epoch': 42, 'time_epoch': 4.49738, 'loss': 0.07387808, 'lr': 0, 'params': 451793, 'time_iter': 0.03486, 'accuracy': 0.98347, 'precision': 0.67568, 'recall': 0.30864, 'f1': 0.42373, 'auc': 0.77505}
2025-07-04 18:42:52,485 - INFO - test: {'epoch': 42, 'time_epoch': 4.53749, 'loss': 0.11304593, 'lr': 0, 'params': 451793, 'time_iter': 0.03517, 'accuracy': 0.97058, 'precision': 0.60465, 'recall': 0.2, 'f1': 0.30058, 'auc': 0.77734}
2025-07-04 18:42:52,505 - INFO - > Epoch 42: took 86.4s (avg 82.3s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:44:10,425 - INFO - train: {'epoch': 43, 'time_epoch': 77.8333, 'eta': 4121.21935, 'eta_hours': 1.14478, 'loss': 0.10836841, 'lr': 6.545e-05, 'params': 451793, 'time_iter': 0.07564, 'accuracy': 0.96875, 'precision': 0.69173, 'recall': 0.2987, 'f1': 0.41723, 'auc': 0.85763}
2025-07-04 18:44:14,975 - INFO - val: {'epoch': 43, 'time_epoch': 4.52203, 'loss': 0.07415283, 'lr': 0, 'params': 451793, 'time_iter': 0.03505, 'accuracy': 0.98347, 'precision': 0.68571, 'recall': 0.2963, 'f1': 0.41379, 'auc': 0.7679}
2025-07-04 18:44:19,491 - INFO - test: {'epoch': 43, 'time_epoch': 4.49423, 'loss': 0.11571186, 'lr': 0, 'params': 451793, 'time_iter': 0.03484, 'accuracy': 0.97107, 'precision': 0.65714, 'recall': 0.17692, 'f1': 0.27879, 'auc': 0.76981}
2025-07-04 18:44:19,494 - INFO - > Epoch 43: took 87.0s (avg 82.4s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:45:36,741 - INFO - train: {'epoch': 44, 'time_epoch': 77.15753, 'eta': 4051.98256, 'eta_hours': 1.12555, 'loss': 0.10641768, 'lr': 6.387e-05, 'params': 451793, 'time_iter': 0.07498, 'accuracy': 0.96973, 'precision': 0.70557, 'recall': 0.32873, 'f1': 0.4485, 'auc': 0.86556}
2025-07-04 18:45:41,305 - INFO - val: {'epoch': 44, 'time_epoch': 4.53379, 'loss': 0.07524943, 'lr': 0, 'params': 451793, 'time_iter': 0.03515, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.77422}
2025-07-04 18:45:45,851 - INFO - test: {'epoch': 44, 'time_epoch': 4.52481, 'loss': 0.11768223, 'lr': 0, 'params': 451793, 'time_iter': 0.03508, 'accuracy': 0.97058, 'precision': 0.57895, 'recall': 0.25385, 'f1': 0.35294, 'auc': 0.76101}
2025-07-04 18:45:45,853 - INFO - > Epoch 44: took 86.4s (avg 82.4s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:47:03,229 - INFO - train: {'epoch': 45, 'time_epoch': 77.28665, 'eta': 3982.55295, 'eta_hours': 1.10626, 'loss': 0.10659827, 'lr': 6.227e-05, 'params': 451793, 'time_iter': 0.07511, 'accuracy': 0.96833, 'precision': 0.66964, 'recall': 0.30438, 'f1': 0.41853, 'auc': 0.86564}
2025-07-04 18:47:07,848 - INFO - val: {'epoch': 45, 'time_epoch': 4.59039, 'loss': 0.07442819, 'lr': 0, 'params': 451793, 'time_iter': 0.03558, 'accuracy': 0.98152, 'precision': 0.57576, 'recall': 0.23457, 'f1': 0.33333, 'auc': 0.78803}
2025-07-04 18:47:12,365 - INFO - test: {'epoch': 45, 'time_epoch': 4.49449, 'loss': 0.11610957, 'lr': 0, 'params': 451793, 'time_iter': 0.03484, 'accuracy': 0.96985, 'precision': 0.5625, 'recall': 0.20769, 'f1': 0.30337, 'auc': 0.76654}
2025-07-04 18:47:12,368 - INFO - > Epoch 45: took 86.5s (avg 82.5s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:48:29,946 - INFO - train: {'epoch': 46, 'time_epoch': 77.49271, 'eta': 3913.02137, 'eta_hours': 1.08695, 'loss': 0.10760526, 'lr': 6.066e-05, 'params': 451793, 'time_iter': 0.07531, 'accuracy': 0.96924, 'precision': 0.70073, 'recall': 0.31169, 'f1': 0.43146, 'auc': 0.86001}
2025-07-04 18:48:34,469 - INFO - val: {'epoch': 46, 'time_epoch': 4.49481, 'loss': 0.07739146, 'lr': 0, 'params': 451793, 'time_iter': 0.03484, 'accuracy': 0.98225, 'precision': 0.59524, 'recall': 0.30864, 'f1': 0.4065, 'auc': 0.77383}
2025-07-04 18:48:38,993 - INFO - test: {'epoch': 46, 'time_epoch': 4.50178, 'loss': 0.12066801, 'lr': 0, 'params': 451793, 'time_iter': 0.0349, 'accuracy': 0.96961, 'precision': 0.55556, 'recall': 0.19231, 'f1': 0.28571, 'auc': 0.77159}
2025-07-04 18:48:38,995 - INFO - > Epoch 46: took 86.6s (avg 82.6s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:49:56,844 - INFO - train: {'epoch': 47, 'time_epoch': 77.76054, 'eta': 3843.44822, 'eta_hours': 1.06762, 'loss': 0.10486074, 'lr': 5.904e-05, 'params': 451793, 'time_iter': 0.07557, 'accuracy': 0.97027, 'precision': 0.72438, 'recall': 0.33279, 'f1': 0.45606, 'auc': 0.86561}
2025-07-04 18:50:01,405 - INFO - val: {'epoch': 47, 'time_epoch': 4.53235, 'loss': 0.07734351, 'lr': 0, 'params': 451793, 'time_iter': 0.03513, 'accuracy': 0.98322, 'precision': 0.65, 'recall': 0.32099, 'f1': 0.42975, 'auc': 0.7643}
2025-07-04 18:50:05,969 - INFO - test: {'epoch': 47, 'time_epoch': 4.54092, 'loss': 0.11743076, 'lr': 0, 'params': 451793, 'time_iter': 0.0352, 'accuracy': 0.97082, 'precision': 0.58065, 'recall': 0.27692, 'f1': 0.375, 'auc': 0.76206}
2025-07-04 18:50:05,972 - INFO - > Epoch 47: took 87.0s (avg 82.7s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:51:23,656 - INFO - train: {'epoch': 48, 'time_epoch': 77.59787, 'eta': 3773.37159, 'eta_hours': 1.04816, 'loss': 0.10536182, 'lr': 5.741e-05, 'params': 451793, 'time_iter': 0.07541, 'accuracy': 0.96961, 'precision': 0.70423, 'recall': 0.32468, 'f1': 0.44444, 'auc': 0.87017}
2025-07-04 18:51:28,223 - INFO - val: {'epoch': 48, 'time_epoch': 4.53861, 'loss': 0.07533403, 'lr': 0, 'params': 451793, 'time_iter': 0.03518, 'accuracy': 0.98225, 'precision': 0.60526, 'recall': 0.28395, 'f1': 0.38655, 'auc': 0.79626}
2025-07-04 18:51:32,812 - INFO - test: {'epoch': 48, 'time_epoch': 4.56796, 'loss': 0.12202297, 'lr': 0, 'params': 451793, 'time_iter': 0.03541, 'accuracy': 0.97107, 'precision': 0.63415, 'recall': 0.2, 'f1': 0.30409, 'auc': 0.75859}
2025-07-04 18:51:32,815 - INFO - > Epoch 48: took 86.8s (avg 82.8s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:52:50,303 - INFO - train: {'epoch': 49, 'time_epoch': 77.40165, 'eta': 3702.79788, 'eta_hours': 1.02855, 'loss': 0.1047779, 'lr': 5.577e-05, 'params': 451793, 'time_iter': 0.07522, 'accuracy': 0.96954, 'precision': 0.69759, 'recall': 0.32955, 'f1': 0.44763, 'auc': 0.87244}
2025-07-04 18:52:54,830 - INFO - val: {'epoch': 49, 'time_epoch': 4.49915, 'loss': 0.07676924, 'lr': 0, 'params': 451793, 'time_iter': 0.03488, 'accuracy': 0.98249, 'precision': 0.60465, 'recall': 0.32099, 'f1': 0.41935, 'auc': 0.75091}
2025-07-04 18:52:59,363 - INFO - test: {'epoch': 49, 'time_epoch': 4.51097, 'loss': 0.11740176, 'lr': 0, 'params': 451793, 'time_iter': 0.03497, 'accuracy': 0.96961, 'precision': 0.54237, 'recall': 0.24615, 'f1': 0.33862, 'auc': 0.77181}
2025-07-04 18:52:59,366 - INFO - > Epoch 49: took 86.5s (avg 82.9s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:54:16,590 - INFO - train: {'epoch': 50, 'time_epoch': 77.1376, 'eta': 3631.70271, 'eta_hours': 1.00881, 'loss': 0.10413312, 'lr': 5.413e-05, 'params': 451793, 'time_iter': 0.07496, 'accuracy': 0.97073, 'precision': 0.73391, 'recall': 0.34253, 'f1': 0.46707, 'auc': 0.86996}
2025-07-04 18:54:21,154 - INFO - val: {'epoch': 50, 'time_epoch': 4.52792, 'loss': 0.0751181, 'lr': 0, 'params': 451793, 'time_iter': 0.0351, 'accuracy': 0.98274, 'precision': 0.63158, 'recall': 0.2963, 'f1': 0.40336, 'auc': 0.78314}
2025-07-04 18:54:25,708 - INFO - test: {'epoch': 50, 'time_epoch': 4.53255, 'loss': 0.1172314, 'lr': 0, 'params': 451793, 'time_iter': 0.03514, 'accuracy': 0.97082, 'precision': 0.58929, 'recall': 0.25385, 'f1': 0.35484, 'auc': 0.77305}
2025-07-04 18:54:25,711 - INFO - > Epoch 50: took 86.3s (avg 82.9s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:55:45,060 - INFO - train: {'epoch': 51, 'time_epoch': 79.25568, 'eta': 3562.3303, 'eta_hours': 0.98954, 'loss': 0.10359417, 'lr': 5.248e-05, 'params': 451793, 'time_iter': 0.07702, 'accuracy': 0.9703, 'precision': 0.7187, 'recall': 0.3401, 'f1': 0.46171, 'auc': 0.87221}
2025-07-04 18:55:49,998 - INFO - val: {'epoch': 51, 'time_epoch': 4.90801, 'loss': 0.07715844, 'lr': 0, 'params': 451793, 'time_iter': 0.03805, 'accuracy': 0.98152, 'precision': 0.57143, 'recall': 0.24691, 'f1': 0.34483, 'auc': 0.78036}
2025-07-04 18:55:54,909 - INFO - test: {'epoch': 51, 'time_epoch': 4.8873, 'loss': 0.11838141, 'lr': 0, 'params': 451793, 'time_iter': 0.03789, 'accuracy': 0.97034, 'precision': 0.57407, 'recall': 0.23846, 'f1': 0.33696, 'auc': 0.76711}
2025-07-04 18:55:54,912 - INFO - > Epoch 51: took 89.2s (avg 83.1s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:57:16,010 - INFO - train: {'epoch': 52, 'time_epoch': 81.00715, 'eta': 3494.13812, 'eta_hours': 0.97059, 'loss': 0.10371361, 'lr': 5.083e-05, 'params': 451793, 'time_iter': 0.07872, 'accuracy': 0.97061, 'precision': 0.7212, 'recall': 0.35065, 'f1': 0.47187, 'auc': 0.8733}
2025-07-04 18:57:20,523 - INFO - val: {'epoch': 52, 'time_epoch': 4.48531, 'loss': 0.07371797, 'lr': 0, 'params': 451793, 'time_iter': 0.03477, 'accuracy': 0.98274, 'precision': 0.63158, 'recall': 0.2963, 'f1': 0.40336, 'auc': 0.80606}
2025-07-04 18:57:25,107 - INFO - test: {'epoch': 52, 'time_epoch': 4.56254, 'loss': 0.11526601, 'lr': 0, 'params': 451793, 'time_iter': 0.03537, 'accuracy': 0.97058, 'precision': 0.57895, 'recall': 0.25385, 'f1': 0.35294, 'auc': 0.77516}
2025-07-04 18:57:25,110 - INFO - > Epoch 52: took 90.2s (avg 83.2s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 18:58:41,321 - INFO - train: {'epoch': 53, 'time_epoch': 76.12517, 'eta': 3421.31259, 'eta_hours': 0.95036, 'loss': 0.10305366, 'lr': 4.917e-05, 'params': 451793, 'time_iter': 0.07398, 'accuracy': 0.971, 'precision': 0.73244, 'recall': 0.35552, 'f1': 0.47869, 'auc': 0.87431}
2025-07-04 18:58:45,843 - INFO - val: {'epoch': 53, 'time_epoch': 4.49369, 'loss': 0.0737275, 'lr': 0, 'params': 451793, 'time_iter': 0.03483, 'accuracy': 0.98225, 'precision': 0.59524, 'recall': 0.30864, 'f1': 0.4065, 'auc': 0.80613}
2025-07-04 18:58:50,375 - INFO - test: {'epoch': 53, 'time_epoch': 4.50878, 'loss': 0.11915202, 'lr': 0, 'params': 451793, 'time_iter': 0.03495, 'accuracy': 0.96985, 'precision': 0.56, 'recall': 0.21538, 'f1': 0.31111, 'auc': 0.76577}
2025-07-04 18:58:50,377 - INFO - > Epoch 53: took 85.3s (avg 83.2s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:00:07,776 - INFO - train: {'epoch': 54, 'time_epoch': 77.30879, 'eta': 3349.33549, 'eta_hours': 0.93037, 'loss': 0.10277924, 'lr': 4.752e-05, 'params': 451793, 'time_iter': 0.07513, 'accuracy': 0.97088, 'precision': 0.73064, 'recall': 0.35227, 'f1': 0.47536, 'auc': 0.8773}
2025-07-04 19:00:12,386 - INFO - val: {'epoch': 54, 'time_epoch': 4.58281, 'loss': 0.07509661, 'lr': 0, 'params': 451793, 'time_iter': 0.03553, 'accuracy': 0.98322, 'precision': 0.66667, 'recall': 0.2963, 'f1': 0.41026, 'auc': 0.78557}
2025-07-04 19:00:16,940 - INFO - test: {'epoch': 54, 'time_epoch': 4.53066, 'loss': 0.12056522, 'lr': 0, 'params': 451793, 'time_iter': 0.03512, 'accuracy': 0.96961, 'precision': 0.56757, 'recall': 0.16154, 'f1': 0.2515, 'auc': 0.76632}
2025-07-04 19:00:16,943 - INFO - > Epoch 54: took 86.6s (avg 83.3s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:01:34,450 - INFO - train: {'epoch': 55, 'time_epoch': 77.42065, 'eta': 3277.25586, 'eta_hours': 0.91035, 'loss': 0.10298154, 'lr': 4.587e-05, 'params': 451793, 'time_iter': 0.07524, 'accuracy': 0.971, 'precision': 0.74048, 'recall': 0.3474, 'f1': 0.47293, 'auc': 0.8784}
2025-07-04 19:01:39,047 - INFO - val: {'epoch': 55, 'time_epoch': 4.56609, 'loss': 0.07688142, 'lr': 0, 'params': 451793, 'time_iter': 0.0354, 'accuracy': 0.98152, 'precision': 0.55102, 'recall': 0.33333, 'f1': 0.41538, 'auc': 0.79202}
2025-07-04 19:01:43,689 - INFO - test: {'epoch': 55, 'time_epoch': 4.61599, 'loss': 0.11987535, 'lr': 0, 'params': 451793, 'time_iter': 0.03578, 'accuracy': 0.96937, 'precision': 0.53125, 'recall': 0.26154, 'f1': 0.35052, 'auc': 0.7605}
2025-07-04 19:01:43,693 - INFO - > Epoch 55: took 86.7s (avg 83.4s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:03:01,243 - INFO - train: {'epoch': 56, 'time_epoch': 77.46216, 'eta': 3205.02015, 'eta_hours': 0.89028, 'loss': 0.10151729, 'lr': 4.423e-05, 'params': 451793, 'time_iter': 0.07528, 'accuracy': 0.97058, 'precision': 0.71154, 'recall': 0.36039, 'f1': 0.47845, 'auc': 0.88422}
2025-07-04 19:03:05,899 - INFO - val: {'epoch': 56, 'time_epoch': 4.62178, 'loss': 0.07444384, 'lr': 0, 'params': 451793, 'time_iter': 0.03583, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.78822}
2025-07-04 19:03:10,424 - INFO - test: {'epoch': 56, 'time_epoch': 4.49992, 'loss': 0.12077294, 'lr': 0, 'params': 451793, 'time_iter': 0.03488, 'accuracy': 0.97058, 'precision': 0.58182, 'recall': 0.24615, 'f1': 0.34595, 'auc': 0.76186}
2025-07-04 19:03:10,427 - INFO - > Epoch 56: took 86.7s (avg 83.4s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:04:27,817 - INFO - train: {'epoch': 57, 'time_epoch': 77.30259, 'eta': 3132.48866, 'eta_hours': 0.87014, 'loss': 0.10139012, 'lr': 4.259e-05, 'params': 451793, 'time_iter': 0.07512, 'accuracy': 0.9707, 'precision': 0.72483, 'recall': 0.35065, 'f1': 0.47265, 'auc': 0.87899}
2025-07-04 19:04:32,370 - INFO - val: {'epoch': 57, 'time_epoch': 4.51673, 'loss': 0.0760866, 'lr': 0, 'params': 451793, 'time_iter': 0.03501, 'accuracy': 0.98225, 'precision': 0.6, 'recall': 0.2963, 'f1': 0.39669, 'auc': 0.78205}
2025-07-04 19:04:36,875 - INFO - test: {'epoch': 57, 'time_epoch': 4.48414, 'loss': 0.12096452, 'lr': 0, 'params': 451793, 'time_iter': 0.03476, 'accuracy': 0.96961, 'precision': 0.53731, 'recall': 0.27692, 'f1': 0.36548, 'auc': 0.76338}
2025-07-04 19:04:36,878 - INFO - > Epoch 57: took 86.5s (avg 83.5s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:05:54,296 - INFO - train: {'epoch': 58, 'time_epoch': 77.33096, 'eta': 3059.81515, 'eta_hours': 0.84995, 'loss': 0.10068896, 'lr': 4.096e-05, 'params': 451793, 'time_iter': 0.07515, 'accuracy': 0.9711, 'precision': 0.72846, 'recall': 0.36364, 'f1': 0.48511, 'auc': 0.88293}
2025-07-04 19:05:58,844 - INFO - val: {'epoch': 58, 'time_epoch': 4.51998, 'loss': 0.07613235, 'lr': 0, 'params': 451793, 'time_iter': 0.03504, 'accuracy': 0.98274, 'precision': 0.625, 'recall': 0.30864, 'f1': 0.41322, 'auc': 0.76913}
2025-07-04 19:06:03,385 - INFO - test: {'epoch': 58, 'time_epoch': 4.51867, 'loss': 0.12177907, 'lr': 0, 'params': 451793, 'time_iter': 0.03503, 'accuracy': 0.96888, 'precision': 0.51852, 'recall': 0.21538, 'f1': 0.30435, 'auc': 0.76214}
2025-07-04 19:06:03,388 - INFO - > Epoch 58: took 86.5s (avg 83.5s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:07:20,932 - INFO - train: {'epoch': 59, 'time_epoch': 77.45516, 'eta': 2987.0692, 'eta_hours': 0.82974, 'loss': 0.09989011, 'lr': 3.934e-05, 'params': 451793, 'time_iter': 0.07527, 'accuracy': 0.97061, 'precision': 0.70671, 'recall': 0.36769, 'f1': 0.48372, 'auc': 0.88541}
2025-07-04 19:07:25,483 - INFO - val: {'epoch': 59, 'time_epoch': 4.52286, 'loss': 0.07392987, 'lr': 0, 'params': 451793, 'time_iter': 0.03506, 'accuracy': 0.98371, 'precision': 0.70588, 'recall': 0.2963, 'f1': 0.41739, 'auc': 0.78945}
2025-07-04 19:07:30,076 - INFO - test: {'epoch': 59, 'time_epoch': 4.56972, 'loss': 0.1199694, 'lr': 0, 'params': 451793, 'time_iter': 0.03542, 'accuracy': 0.96937, 'precision': 0.54, 'recall': 0.20769, 'f1': 0.3, 'auc': 0.76312}
2025-07-04 19:07:30,079 - INFO - > Epoch 59: took 86.7s (avg 83.6s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:08:47,260 - INFO - train: {'epoch': 60, 'time_epoch': 77.0902, 'eta': 2913.93551, 'eta_hours': 0.80943, 'loss': 0.09910218, 'lr': 3.773e-05, 'params': 451793, 'time_iter': 0.07492, 'accuracy': 0.97125, 'precision': 0.72843, 'recall': 0.37013, 'f1': 0.49085, 'auc': 0.88285}
2025-07-04 19:08:51,831 - INFO - val: {'epoch': 60, 'time_epoch': 4.53992, 'loss': 0.07460422, 'lr': 0, 'params': 451793, 'time_iter': 0.03519, 'accuracy': 0.98225, 'precision': 0.58696, 'recall': 0.33333, 'f1': 0.4252, 'auc': 0.79996}
2025-07-04 19:08:56,382 - INFO - test: {'epoch': 60, 'time_epoch': 4.5257, 'loss': 0.1205248, 'lr': 0, 'params': 451793, 'time_iter': 0.03508, 'accuracy': 0.96961, 'precision': 0.54545, 'recall': 0.23077, 'f1': 0.32432, 'auc': 0.7644}
2025-07-04 19:08:56,385 - INFO - > Epoch 60: took 86.3s (avg 83.6s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:10:14,273 - INFO - train: {'epoch': 61, 'time_epoch': 77.80055, 'eta': 2841.10957, 'eta_hours': 0.7892, 'loss': 0.10053463, 'lr': 3.613e-05, 'params': 451793, 'time_iter': 0.07561, 'accuracy': 0.97116, 'precision': 0.72859, 'recall': 0.36607, 'f1': 0.4873, 'auc': 0.88558}
2025-07-04 19:10:18,836 - INFO - val: {'epoch': 61, 'time_epoch': 4.53254, 'loss': 0.07528208, 'lr': 0, 'params': 451793, 'time_iter': 0.03514, 'accuracy': 0.98274, 'precision': 0.625, 'recall': 0.30864, 'f1': 0.41322, 'auc': 0.77067}
2025-07-04 19:10:23,402 - INFO - test: {'epoch': 61, 'time_epoch': 4.53983, 'loss': 0.11837322, 'lr': 0, 'params': 451793, 'time_iter': 0.03519, 'accuracy': 0.97131, 'precision': 0.61538, 'recall': 0.24615, 'f1': 0.35165, 'auc': 0.77161}
2025-07-04 19:10:23,405 - INFO - > Epoch 61: took 87.0s (avg 83.7s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:11:40,731 - INFO - train: {'epoch': 62, 'time_epoch': 77.23758, 'eta': 2767.79506, 'eta_hours': 0.76883, 'loss': 0.10066789, 'lr': 3.455e-05, 'params': 451793, 'time_iter': 0.07506, 'accuracy': 0.97024, 'precision': 0.71048, 'recall': 0.34659, 'f1': 0.4659, 'auc': 0.88777}
2025-07-04 19:11:45,319 - INFO - val: {'epoch': 62, 'time_epoch': 4.5601, 'loss': 0.07507171, 'lr': 0, 'params': 451793, 'time_iter': 0.03535, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.79529}
2025-07-04 19:11:49,900 - INFO - test: {'epoch': 62, 'time_epoch': 4.54483, 'loss': 0.12069782, 'lr': 0, 'params': 451793, 'time_iter': 0.03523, 'accuracy': 0.96961, 'precision': 0.55102, 'recall': 0.20769, 'f1': 0.30168, 'auc': 0.76492}
2025-07-04 19:11:49,927 - INFO - > Epoch 62: took 86.5s (avg 83.7s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:13:07,258 - INFO - train: {'epoch': 63, 'time_epoch': 77.24259, 'eta': 2694.36078, 'eta_hours': 0.74843, 'loss': 0.09919638, 'lr': 3.299e-05, 'params': 451793, 'time_iter': 0.07507, 'accuracy': 0.9711, 'precision': 0.73071, 'recall': 0.3612, 'f1': 0.48343, 'auc': 0.88634}
2025-07-04 19:13:11,825 - INFO - val: {'epoch': 63, 'time_epoch': 4.53797, 'loss': 0.07562666, 'lr': 0, 'params': 451793, 'time_iter': 0.03518, 'accuracy': 0.98347, 'precision': 0.68571, 'recall': 0.2963, 'f1': 0.41379, 'auc': 0.76952}
2025-07-04 19:13:16,380 - INFO - test: {'epoch': 63, 'time_epoch': 4.53257, 'loss': 0.12026066, 'lr': 0, 'params': 451793, 'time_iter': 0.03514, 'accuracy': 0.97034, 'precision': 0.59091, 'recall': 0.2, 'f1': 0.29885, 'auc': 0.76132}
2025-07-04 19:13:16,383 - INFO - > Epoch 63: took 86.5s (avg 83.8s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:14:34,079 - INFO - train: {'epoch': 64, 'time_epoch': 77.61053, 'eta': 2621.00744, 'eta_hours': 0.72806, 'loss': 0.09941867, 'lr': 3.144e-05, 'params': 451793, 'time_iter': 0.07542, 'accuracy': 0.97113, 'precision': 0.73579, 'recall': 0.35714, 'f1': 0.48087, 'auc': 0.8914}
2025-07-04 19:14:38,613 - INFO - val: {'epoch': 64, 'time_epoch': 4.50521, 'loss': 0.07636426, 'lr': 0, 'params': 451793, 'time_iter': 0.03492, 'accuracy': 0.98298, 'precision': 0.63415, 'recall': 0.32099, 'f1': 0.42623, 'auc': 0.7843}
2025-07-04 19:14:43,161 - INFO - test: {'epoch': 64, 'time_epoch': 4.52547, 'loss': 0.12077025, 'lr': 0, 'params': 451793, 'time_iter': 0.03508, 'accuracy': 0.97009, 'precision': 0.55738, 'recall': 0.26154, 'f1': 0.35602, 'auc': 0.76472}
2025-07-04 19:14:43,165 - INFO - > Epoch 64: took 86.8s (avg 83.8s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:16:00,142 - INFO - train: {'epoch': 65, 'time_epoch': 76.88899, 'eta': 2547.1534, 'eta_hours': 0.70754, 'loss': 0.09889769, 'lr': 2.992e-05, 'params': 451793, 'time_iter': 0.07472, 'accuracy': 0.9711, 'precision': 0.72846, 'recall': 0.36364, 'f1': 0.48511, 'auc': 0.88932}
2025-07-04 19:16:04,749 - INFO - val: {'epoch': 65, 'time_epoch': 4.5798, 'loss': 0.07526301, 'lr': 0, 'params': 451793, 'time_iter': 0.0355, 'accuracy': 0.98225, 'precision': 0.60526, 'recall': 0.28395, 'f1': 0.38655, 'auc': 0.78963}
2025-07-04 19:16:09,391 - INFO - test: {'epoch': 65, 'time_epoch': 4.61949, 'loss': 0.12233461, 'lr': 0, 'params': 451793, 'time_iter': 0.03581, 'accuracy': 0.96912, 'precision': 0.52941, 'recall': 0.20769, 'f1': 0.29834, 'auc': 0.76047}
2025-07-04 19:16:09,394 - INFO - > Epoch 65: took 86.2s (avg 83.8s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:17:26,664 - INFO - train: {'epoch': 66, 'time_epoch': 77.18372, 'eta': 2473.35392, 'eta_hours': 0.68704, 'loss': 0.09852055, 'lr': 2.841e-05, 'params': 451793, 'time_iter': 0.07501, 'accuracy': 0.97195, 'precision': 0.75537, 'recall': 0.37094, 'f1': 0.49755, 'auc': 0.89109}
2025-07-04 19:17:31,491 - INFO - val: {'epoch': 66, 'time_epoch': 4.73574, 'loss': 0.07636506, 'lr': 0, 'params': 451793, 'time_iter': 0.03671, 'accuracy': 0.98177, 'precision': 0.57143, 'recall': 0.2963, 'f1': 0.39024, 'auc': 0.78136}
2025-07-04 19:17:36,525 - INFO - test: {'epoch': 66, 'time_epoch': 5.0098, 'loss': 0.12283816, 'lr': 0, 'params': 451793, 'time_iter': 0.03884, 'accuracy': 0.96961, 'precision': 0.54902, 'recall': 0.21538, 'f1': 0.30939, 'auc': 0.76759}
2025-07-04 19:17:36,528 - INFO - > Epoch 66: took 87.1s (avg 83.9s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:18:58,833 - INFO - train: {'epoch': 67, 'time_epoch': 82.20769, 'eta': 2401.81913, 'eta_hours': 0.66717, 'loss': 0.09781112, 'lr': 2.693e-05, 'params': 451793, 'time_iter': 0.07989, 'accuracy': 0.97228, 'precision': 0.76059, 'recall': 0.37906, 'f1': 0.50596, 'auc': 0.89205}
2025-07-04 19:19:03,629 - INFO - val: {'epoch': 67, 'time_epoch': 4.76882, 'loss': 0.07665552, 'lr': 0, 'params': 451793, 'time_iter': 0.03697, 'accuracy': 0.98177, 'precision': 0.575, 'recall': 0.28395, 'f1': 0.38017, 'auc': 0.78598}
2025-07-04 19:19:08,350 - INFO - test: {'epoch': 67, 'time_epoch': 4.69854, 'loss': 0.12292837, 'lr': 0, 'params': 451793, 'time_iter': 0.03642, 'accuracy': 0.96961, 'precision': 0.53846, 'recall': 0.26923, 'f1': 0.35897, 'auc': 0.769}
2025-07-04 19:19:08,353 - INFO - > Epoch 67: took 91.8s (avg 84.0s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:20:25,379 - INFO - train: {'epoch': 68, 'time_epoch': 76.94131, 'eta': 2327.60893, 'eta_hours': 0.64656, 'loss': 0.09807911, 'lr': 2.548e-05, 'params': 451793, 'time_iter': 0.07477, 'accuracy': 0.97158, 'precision': 0.74384, 'recall': 0.36769, 'f1': 0.49212, 'auc': 0.89518}
2025-07-04 19:20:29,903 - INFO - val: {'epoch': 68, 'time_epoch': 4.49465, 'loss': 0.07635671, 'lr': 0, 'params': 451793, 'time_iter': 0.03484, 'accuracy': 0.98274, 'precision': 0.61364, 'recall': 0.33333, 'f1': 0.432, 'auc': 0.77009}
2025-07-04 19:20:34,437 - INFO - test: {'epoch': 68, 'time_epoch': 4.51242, 'loss': 0.12289225, 'lr': 0, 'params': 451793, 'time_iter': 0.03498, 'accuracy': 0.96888, 'precision': 0.51667, 'recall': 0.23846, 'f1': 0.32632, 'auc': 0.76427}
2025-07-04 19:20:34,440 - INFO - > Epoch 68: took 86.1s (avg 84.0s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:21:52,108 - INFO - train: {'epoch': 69, 'time_epoch': 77.58116, 'eta': 2253.59491, 'eta_hours': 0.626, 'loss': 0.09712159, 'lr': 2.405e-05, 'params': 451793, 'time_iter': 0.07539, 'accuracy': 0.97189, 'precision': 0.7456, 'recall': 0.37825, 'f1': 0.50188, 'auc': 0.89276}
2025-07-04 19:21:56,670 - INFO - val: {'epoch': 69, 'time_epoch': 4.5345, 'loss': 0.07681568, 'lr': 0, 'params': 451793, 'time_iter': 0.03515, 'accuracy': 0.98128, 'precision': 0.54, 'recall': 0.33333, 'f1': 0.41221, 'auc': 0.79479}
2025-07-04 19:22:01,213 - INFO - test: {'epoch': 69, 'time_epoch': 4.52105, 'loss': 0.12220467, 'lr': 0, 'params': 451793, 'time_iter': 0.03505, 'accuracy': 0.96888, 'precision': 0.51351, 'recall': 0.29231, 'f1': 0.37255, 'auc': 0.77482}
2025-07-04 19:22:01,216 - INFO - > Epoch 69: took 86.8s (avg 84.1s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:23:19,194 - INFO - train: {'epoch': 70, 'time_epoch': 77.89046, 'eta': 2179.60675, 'eta_hours': 0.60545, 'loss': 0.09714104, 'lr': 2.265e-05, 'params': 451793, 'time_iter': 0.0757, 'accuracy': 0.97216, 'precision': 0.75079, 'recall': 0.38393, 'f1': 0.50806, 'auc': 0.89357}
2025-07-04 19:23:23,748 - INFO - val: {'epoch': 70, 'time_epoch': 4.52707, 'loss': 0.07643551, 'lr': 0, 'params': 451793, 'time_iter': 0.03509, 'accuracy': 0.98225, 'precision': 0.60526, 'recall': 0.28395, 'f1': 0.38655, 'auc': 0.77972}
2025-07-04 19:23:28,310 - INFO - test: {'epoch': 70, 'time_epoch': 4.54059, 'loss': 0.12232028, 'lr': 0, 'params': 451793, 'time_iter': 0.0352, 'accuracy': 0.97034, 'precision': 0.57143, 'recall': 0.24615, 'f1': 0.34409, 'auc': 0.76918}
2025-07-04 19:23:28,313 - INFO - > Epoch 70: took 87.1s (avg 84.1s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:24:45,637 - INFO - train: {'epoch': 71, 'time_epoch': 77.23571, 'eta': 2105.25556, 'eta_hours': 0.58479, 'loss': 0.09857785, 'lr': 2.128e-05, 'params': 451793, 'time_iter': 0.07506, 'accuracy': 0.97137, 'precision': 0.72656, 'recall': 0.37744, 'f1': 0.49679, 'auc': 0.88705}
2025-07-04 19:24:50,205 - INFO - val: {'epoch': 71, 'time_epoch': 4.53939, 'loss': 0.07620463, 'lr': 0, 'params': 451793, 'time_iter': 0.03519, 'accuracy': 0.98152, 'precision': 0.57143, 'recall': 0.24691, 'f1': 0.34483, 'auc': 0.80344}
2025-07-04 19:24:54,778 - INFO - test: {'epoch': 71, 'time_epoch': 4.53412, 'loss': 0.12400044, 'lr': 0, 'params': 451793, 'time_iter': 0.03515, 'accuracy': 0.96791, 'precision': 0.48214, 'recall': 0.20769, 'f1': 0.29032, 'auc': 0.76209}
2025-07-04 19:24:54,783 - INFO - > Epoch 71: took 86.5s (avg 84.2s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:26:11,750 - INFO - train: {'epoch': 72, 'time_epoch': 76.87951, 'eta': 2030.6936, 'eta_hours': 0.56408, 'loss': 0.09650043, 'lr': 1.995e-05, 'params': 451793, 'time_iter': 0.07471, 'accuracy': 0.97167, 'precision': 0.73511, 'recall': 0.38068, 'f1': 0.5016, 'auc': 0.89916}
2025-07-04 19:26:16,364 - INFO - val: {'epoch': 72, 'time_epoch': 4.58626, 'loss': 0.07670955, 'lr': 0, 'params': 451793, 'time_iter': 0.03555, 'accuracy': 0.98177, 'precision': 0.575, 'recall': 0.28395, 'f1': 0.38017, 'auc': 0.79069}
2025-07-04 19:26:20,959 - INFO - test: {'epoch': 72, 'time_epoch': 4.5729, 'loss': 0.12306892, 'lr': 0, 'params': 451793, 'time_iter': 0.03545, 'accuracy': 0.96937, 'precision': 0.54, 'recall': 0.20769, 'f1': 0.3, 'auc': 0.76575}
2025-07-04 19:26:20,962 - INFO - > Epoch 72: took 86.2s (avg 84.2s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:27:38,647 - INFO - train: {'epoch': 73, 'time_epoch': 77.5971, 'eta': 1956.32113, 'eta_hours': 0.54342, 'loss': 0.09689614, 'lr': 1.864e-05, 'params': 451793, 'time_iter': 0.07541, 'accuracy': 0.97152, 'precision': 0.73676, 'recall': 0.37256, 'f1': 0.49488, 'auc': 0.89717}
2025-07-04 19:27:43,161 - INFO - val: {'epoch': 73, 'time_epoch': 4.48387, 'loss': 0.07716488, 'lr': 0, 'params': 451793, 'time_iter': 0.03476, 'accuracy': 0.98249, 'precision': 0.63636, 'recall': 0.25926, 'f1': 0.36842, 'auc': 0.77989}
2025-07-04 19:27:47,757 - INFO - test: {'epoch': 73, 'time_epoch': 4.57524, 'loss': 0.12547973, 'lr': 0, 'params': 451793, 'time_iter': 0.03547, 'accuracy': 0.96961, 'precision': 0.56098, 'recall': 0.17692, 'f1': 0.26901, 'auc': 0.76516}
2025-07-04 19:27:47,760 - INFO - > Epoch 73: took 86.8s (avg 84.2s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:29:04,981 - INFO - train: {'epoch': 74, 'time_epoch': 77.13397, 'eta': 1881.70829, 'eta_hours': 0.5227, 'loss': 0.09634481, 'lr': 1.737e-05, 'params': 451793, 'time_iter': 0.07496, 'accuracy': 0.97192, 'precision': 0.74444, 'recall': 0.38068, 'f1': 0.50376, 'auc': 0.89676}
2025-07-04 19:29:09,510 - INFO - val: {'epoch': 74, 'time_epoch': 4.50188, 'loss': 0.07599142, 'lr': 0, 'params': 451793, 'time_iter': 0.0349, 'accuracy': 0.98201, 'precision': 0.58974, 'recall': 0.28395, 'f1': 0.38333, 'auc': 0.8033}
2025-07-04 19:29:14,051 - INFO - test: {'epoch': 74, 'time_epoch': 4.51762, 'loss': 0.12447933, 'lr': 0, 'params': 451793, 'time_iter': 0.03502, 'accuracy': 0.96888, 'precision': 0.51667, 'recall': 0.23846, 'f1': 0.32632, 'auc': 0.76268}
2025-07-04 19:29:14,054 - INFO - > Epoch 74: took 86.3s (avg 84.2s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:30:31,405 - INFO - train: {'epoch': 75, 'time_epoch': 77.21843, 'eta': 1807.05578, 'eta_hours': 0.50196, 'loss': 0.09513017, 'lr': 1.614e-05, 'params': 451793, 'time_iter': 0.07504, 'accuracy': 0.97179, 'precision': 0.73824, 'recall': 0.38231, 'f1': 0.50374, 'auc': 0.9036}
2025-07-04 19:30:36,006 - INFO - val: {'epoch': 75, 'time_epoch': 4.57286, 'loss': 0.07625445, 'lr': 0, 'params': 451793, 'time_iter': 0.03545, 'accuracy': 0.98201, 'precision': 0.57143, 'recall': 0.34568, 'f1': 0.43077, 'auc': 0.80217}
2025-07-04 19:30:40,568 - INFO - test: {'epoch': 75, 'time_epoch': 4.54112, 'loss': 0.12345432, 'lr': 0, 'params': 451793, 'time_iter': 0.0352, 'accuracy': 0.96937, 'precision': 0.52703, 'recall': 0.3, 'f1': 0.38235, 'auc': 0.76432}
2025-07-04 19:30:40,571 - INFO - > Epoch 75: took 86.5s (avg 84.3s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:31:58,569 - INFO - train: {'epoch': 76, 'time_epoch': 77.90945, 'eta': 1732.54303, 'eta_hours': 0.48126, 'loss': 0.09492969, 'lr': 1.494e-05, 'params': 451793, 'time_iter': 0.07571, 'accuracy': 0.97277, 'precision': 0.76006, 'recall': 0.39854, 'f1': 0.5229, 'auc': 0.89789}
2025-07-04 19:32:03,115 - INFO - val: {'epoch': 76, 'time_epoch': 4.51739, 'loss': 0.07639922, 'lr': 0, 'params': 451793, 'time_iter': 0.03502, 'accuracy': 0.98177, 'precision': 0.575, 'recall': 0.28395, 'f1': 0.38017, 'auc': 0.79601}
2025-07-04 19:32:07,611 - INFO - test: {'epoch': 76, 'time_epoch': 4.47506, 'loss': 0.12683329, 'lr': 0, 'params': 451793, 'time_iter': 0.03469, 'accuracy': 0.96912, 'precision': 0.52632, 'recall': 0.23077, 'f1': 0.32086, 'auc': 0.75678}
2025-07-04 19:32:07,626 - INFO - > Epoch 76: took 87.1s (avg 84.3s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:33:24,477 - INFO - train: {'epoch': 77, 'time_epoch': 76.76466, 'eta': 1657.6203, 'eta_hours': 0.46045, 'loss': 0.09513533, 'lr': 1.378e-05, 'params': 451793, 'time_iter': 0.0746, 'accuracy': 0.97243, 'precision': 0.74885, 'recall': 0.39692, 'f1': 0.51883, 'auc': 0.90127}
2025-07-04 19:33:29,044 - INFO - val: {'epoch': 77, 'time_epoch': 4.49753, 'loss': 0.07608629, 'lr': 0, 'params': 451793, 'time_iter': 0.03486, 'accuracy': 0.98201, 'precision': 0.6, 'recall': 0.25926, 'f1': 0.36207, 'auc': 0.79878}
2025-07-04 19:33:33,565 - INFO - test: {'epoch': 77, 'time_epoch': 4.49867, 'loss': 0.12702867, 'lr': 0, 'params': 451793, 'time_iter': 0.03487, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.18462, 'f1': 0.26966, 'auc': 0.75507}
2025-07-04 19:33:33,569 - INFO - > Epoch 77: took 85.9s (avg 84.3s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:34:50,616 - INFO - train: {'epoch': 78, 'time_epoch': 76.95845, 'eta': 1582.70244, 'eta_hours': 0.43964, 'loss': 0.09521747, 'lr': 1.266e-05, 'params': 451793, 'time_iter': 0.07479, 'accuracy': 0.97292, 'precision': 0.76682, 'recall': 0.39773, 'f1': 0.52378, 'auc': 0.89875}
2025-07-04 19:34:55,208 - INFO - val: {'epoch': 78, 'time_epoch': 4.56331, 'loss': 0.07431379, 'lr': 0, 'params': 451793, 'time_iter': 0.03537, 'accuracy': 0.98152, 'precision': 0.57143, 'recall': 0.24691, 'f1': 0.34483, 'auc': 0.81455}
2025-07-04 19:34:59,786 - INFO - test: {'epoch': 78, 'time_epoch': 4.51129, 'loss': 0.12410916, 'lr': 0, 'params': 451793, 'time_iter': 0.03497, 'accuracy': 0.96985, 'precision': 0.55769, 'recall': 0.22308, 'f1': 0.31868, 'auc': 0.76085}
2025-07-04 19:34:59,839 - INFO - > Epoch 78: took 86.3s (avg 84.4s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:36:17,638 - INFO - train: {'epoch': 79, 'time_epoch': 77.71218, 'eta': 1507.92201, 'eta_hours': 0.41887, 'loss': 0.09611488, 'lr': 1.158e-05, 'params': 451793, 'time_iter': 0.07552, 'accuracy': 0.97173, 'precision': 0.7352, 'recall': 0.38312, 'f1': 0.50374, 'auc': 0.89821}
2025-07-04 19:36:22,130 - INFO - val: {'epoch': 79, 'time_epoch': 4.46567, 'loss': 0.0747751, 'lr': 0, 'params': 451793, 'time_iter': 0.03462, 'accuracy': 0.98371, 'precision': 0.73333, 'recall': 0.2716, 'f1': 0.3964, 'auc': 0.78489}
2025-07-04 19:36:26,649 - INFO - test: {'epoch': 79, 'time_epoch': 4.4959, 'loss': 0.12209918, 'lr': 0, 'params': 451793, 'time_iter': 0.03485, 'accuracy': 0.97009, 'precision': 0.5814, 'recall': 0.19231, 'f1': 0.28902, 'auc': 0.76139}
2025-07-04 19:36:26,652 - INFO - > Epoch 79: took 86.8s (avg 84.4s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:37:43,901 - INFO - train: {'epoch': 80, 'time_epoch': 77.16136, 'eta': 1432.93998, 'eta_hours': 0.39804, 'loss': 0.09580933, 'lr': 1.054e-05, 'params': 451793, 'time_iter': 0.07499, 'accuracy': 0.97137, 'precision': 0.72586, 'recall': 0.37825, 'f1': 0.49733, 'auc': 0.90035}
2025-07-04 19:37:48,456 - INFO - val: {'epoch': 80, 'time_epoch': 4.52405, 'loss': 0.07458749, 'lr': 0, 'params': 451793, 'time_iter': 0.03507, 'accuracy': 0.98249, 'precision': 0.63636, 'recall': 0.25926, 'f1': 0.36842, 'auc': 0.80862}
2025-07-04 19:37:52,983 - INFO - test: {'epoch': 80, 'time_epoch': 4.50591, 'loss': 0.12540798, 'lr': 0, 'params': 451793, 'time_iter': 0.03493, 'accuracy': 0.96961, 'precision': 0.55556, 'recall': 0.19231, 'f1': 0.28571, 'auc': 0.76674}
2025-07-04 19:37:52,986 - INFO - > Epoch 80: took 86.3s (avg 84.4s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:39:10,601 - INFO - train: {'epoch': 81, 'time_epoch': 77.52515, 'eta': 1357.98466, 'eta_hours': 0.37722, 'loss': 0.09548071, 'lr': 9.55e-06, 'params': 451793, 'time_iter': 0.07534, 'accuracy': 0.97252, 'precision': 0.76198, 'recall': 0.38718, 'f1': 0.51346, 'auc': 0.89637}
2025-07-04 19:39:15,211 - INFO - val: {'epoch': 81, 'time_epoch': 4.57964, 'loss': 0.07574257, 'lr': 0, 'params': 451793, 'time_iter': 0.0355, 'accuracy': 0.98249, 'precision': 0.62162, 'recall': 0.28395, 'f1': 0.38983, 'auc': 0.79813}
2025-07-04 19:39:19,862 - INFO - test: {'epoch': 81, 'time_epoch': 4.627, 'loss': 0.12647372, 'lr': 0, 'params': 451793, 'time_iter': 0.03587, 'accuracy': 0.97009, 'precision': 0.57778, 'recall': 0.2, 'f1': 0.29714, 'auc': 0.76067}
2025-07-04 19:39:19,872 - INFO - > Epoch 81: took 86.9s (avg 84.4s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:40:42,555 - INFO - train: {'epoch': 82, 'time_epoch': 82.58763, 'eta': 1284.0043, 'eta_hours': 0.35667, 'loss': 0.09499462, 'lr': 8.6e-06, 'params': 451793, 'time_iter': 0.08026, 'accuracy': 0.97213, 'precision': 0.75444, 'recall': 0.37906, 'f1': 0.50459, 'auc': 0.90157}
2025-07-04 19:40:47,376 - INFO - val: {'epoch': 82, 'time_epoch': 4.78733, 'loss': 0.07633997, 'lr': 0, 'params': 451793, 'time_iter': 0.03711, 'accuracy': 0.98225, 'precision': 0.60526, 'recall': 0.28395, 'f1': 0.38655, 'auc': 0.78673}
2025-07-04 19:40:51,935 - INFO - test: {'epoch': 82, 'time_epoch': 4.53691, 'loss': 0.12534481, 'lr': 0, 'params': 451793, 'time_iter': 0.03517, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.18462, 'f1': 0.26966, 'auc': 0.76157}
2025-07-04 19:40:51,938 - INFO - > Epoch 82: took 92.1s (avg 84.5s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:42:09,275 - INFO - train: {'epoch': 83, 'time_epoch': 77.24777, 'eta': 1208.8019, 'eta_hours': 0.33578, 'loss': 0.09494581, 'lr': 7.7e-06, 'params': 451793, 'time_iter': 0.07507, 'accuracy': 0.97268, 'precision': 0.75113, 'recall': 0.40422, 'f1': 0.52559, 'auc': 0.89946}
2025-07-04 19:42:13,786 - INFO - val: {'epoch': 83, 'time_epoch': 4.47939, 'loss': 0.07441159, 'lr': 0, 'params': 451793, 'time_iter': 0.03472, 'accuracy': 0.98225, 'precision': 0.6, 'recall': 0.2963, 'f1': 0.39669, 'auc': 0.80257}
2025-07-04 19:42:18,309 - INFO - test: {'epoch': 83, 'time_epoch': 4.48593, 'loss': 0.12289197, 'lr': 0, 'params': 451793, 'time_iter': 0.03477, 'accuracy': 0.97058, 'precision': 0.57895, 'recall': 0.25385, 'f1': 0.35294, 'auc': 0.76927}
2025-07-04 19:42:18,326 - INFO - > Epoch 83: took 86.4s (avg 84.6s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:43:35,313 - INFO - train: {'epoch': 84, 'time_epoch': 76.89968, 'eta': 1133.48994, 'eta_hours': 0.31486, 'loss': 0.09398519, 'lr': 6.84e-06, 'params': 451793, 'time_iter': 0.07473, 'accuracy': 0.97316, 'precision': 0.76723, 'recall': 0.40666, 'f1': 0.53156, 'auc': 0.90445}
2025-07-04 19:43:39,941 - INFO - val: {'epoch': 84, 'time_epoch': 4.59797, 'loss': 0.07708653, 'lr': 0, 'params': 451793, 'time_iter': 0.03564, 'accuracy': 0.98249, 'precision': 0.6, 'recall': 0.33333, 'f1': 0.42857, 'auc': 0.78179}
2025-07-04 19:43:44,473 - INFO - test: {'epoch': 84, 'time_epoch': 4.51023, 'loss': 0.12348407, 'lr': 0, 'params': 451793, 'time_iter': 0.03496, 'accuracy': 0.97009, 'precision': 0.55072, 'recall': 0.29231, 'f1': 0.38191, 'auc': 0.76543}
2025-07-04 19:43:44,476 - INFO - > Epoch 84: took 86.2s (avg 84.6s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:45:02,283 - INFO - train: {'epoch': 85, 'time_epoch': 77.71128, 'eta': 1058.27317, 'eta_hours': 0.29396, 'loss': 0.09439915, 'lr': 6.03e-06, 'params': 451793, 'time_iter': 0.07552, 'accuracy': 0.97201, 'precision': 0.74184, 'recall': 0.38718, 'f1': 0.5088, 'auc': 0.90471}
2025-07-04 19:45:06,924 - INFO - val: {'epoch': 85, 'time_epoch': 4.60273, 'loss': 0.07538026, 'lr': 0, 'params': 451793, 'time_iter': 0.03568, 'accuracy': 0.98249, 'precision': 0.60976, 'recall': 0.30864, 'f1': 0.40984, 'auc': 0.79675}
2025-07-04 19:45:11,496 - INFO - test: {'epoch': 85, 'time_epoch': 4.54567, 'loss': 0.12323935, 'lr': 0, 'params': 451793, 'time_iter': 0.03524, 'accuracy': 0.97058, 'precision': 0.57143, 'recall': 0.27692, 'f1': 0.37306, 'auc': 0.76601}
2025-07-04 19:45:11,499 - INFO - > Epoch 85: took 87.0s (avg 84.6s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:46:28,676 - INFO - train: {'epoch': 86, 'time_epoch': 77.08993, 'eta': 982.90622, 'eta_hours': 0.27303, 'loss': 0.09373622, 'lr': 5.26e-06, 'params': 451793, 'time_iter': 0.07492, 'accuracy': 0.9728, 'precision': 0.75804, 'recall': 0.40179, 'f1': 0.5252, 'auc': 0.90284}
2025-07-04 19:46:33,207 - INFO - val: {'epoch': 86, 'time_epoch': 4.50271, 'loss': 0.07619514, 'lr': 0, 'params': 451793, 'time_iter': 0.0349, 'accuracy': 0.98177, 'precision': 0.575, 'recall': 0.28395, 'f1': 0.38017, 'auc': 0.7893}
2025-07-04 19:46:37,765 - INFO - test: {'epoch': 86, 'time_epoch': 4.53671, 'loss': 0.12355389, 'lr': 0, 'params': 451793, 'time_iter': 0.03517, 'accuracy': 0.96985, 'precision': 0.55172, 'recall': 0.24615, 'f1': 0.34043, 'auc': 0.76405}
2025-07-04 19:46:37,768 - INFO - > Epoch 86: took 86.3s (avg 84.6s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:47:54,797 - INFO - train: {'epoch': 87, 'time_epoch': 76.94195, 'eta': 907.47993, 'eta_hours': 0.25208, 'loss': 0.0931591, 'lr': 4.55e-06, 'params': 451793, 'time_iter': 0.07477, 'accuracy': 0.97362, 'precision': 0.77829, 'recall': 0.41315, 'f1': 0.53977, 'auc': 0.90273}
2025-07-04 19:47:59,361 - INFO - val: {'epoch': 87, 'time_epoch': 4.53637, 'loss': 0.07498307, 'lr': 0, 'params': 451793, 'time_iter': 0.03517, 'accuracy': 0.98201, 'precision': 0.59459, 'recall': 0.2716, 'f1': 0.37288, 'auc': 0.80074}
2025-07-04 19:48:03,947 - INFO - test: {'epoch': 87, 'time_epoch': 4.56326, 'loss': 0.12381548, 'lr': 0, 'params': 451793, 'time_iter': 0.03537, 'accuracy': 0.97034, 'precision': 0.58, 'recall': 0.22308, 'f1': 0.32222, 'auc': 0.76212}
2025-07-04 19:48:03,954 - INFO - > Epoch 87: took 86.2s (avg 84.6s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:49:21,503 - INFO - train: {'epoch': 88, 'time_epoch': 77.46118, 'eta': 832.08375, 'eta_hours': 0.23113, 'loss': 0.09556955, 'lr': 3.89e-06, 'params': 451793, 'time_iter': 0.07528, 'accuracy': 0.97292, 'precision': 0.7728, 'recall': 0.39205, 'f1': 0.52019, 'auc': 0.89574}
2025-07-04 19:49:26,163 - INFO - val: {'epoch': 88, 'time_epoch': 4.63081, 'loss': 0.07565783, 'lr': 0, 'params': 451793, 'time_iter': 0.0359, 'accuracy': 0.98201, 'precision': 0.58974, 'recall': 0.28395, 'f1': 0.38333, 'auc': 0.80136}
2025-07-04 19:49:30,820 - INFO - test: {'epoch': 88, 'time_epoch': 4.63577, 'loss': 0.12494327, 'lr': 0, 'params': 451793, 'time_iter': 0.03594, 'accuracy': 0.96912, 'precision': 0.52727, 'recall': 0.22308, 'f1': 0.31351, 'auc': 0.76793}
2025-07-04 19:49:30,823 - INFO - > Epoch 88: took 86.9s (avg 84.7s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:50:48,110 - INFO - train: {'epoch': 89, 'time_epoch': 77.19894, 'eta': 756.61255, 'eta_hours': 0.21017, 'loss': 0.09314891, 'lr': 3.27e-06, 'params': 451793, 'time_iter': 0.07502, 'accuracy': 0.97255, 'precision': 0.75504, 'recall': 0.39529, 'f1': 0.51891, 'auc': 0.91017}
2025-07-04 19:50:52,628 - INFO - val: {'epoch': 89, 'time_epoch': 4.49067, 'loss': 0.07525653, 'lr': 0, 'params': 451793, 'time_iter': 0.03481, 'accuracy': 0.98249, 'precision': 0.62162, 'recall': 0.28395, 'f1': 0.38983, 'auc': 0.79864}
2025-07-04 19:50:57,141 - INFO - test: {'epoch': 89, 'time_epoch': 4.49157, 'loss': 0.12459899, 'lr': 0, 'params': 451793, 'time_iter': 0.03482, 'accuracy': 0.96937, 'precision': 0.54, 'recall': 0.20769, 'f1': 0.3, 'auc': 0.76435}
2025-07-04 19:50:57,144 - INFO - > Epoch 89: took 86.3s (avg 84.7s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:52:15,206 - INFO - train: {'epoch': 90, 'time_epoch': 77.97386, 'eta': 681.18001, 'eta_hours': 0.18922, 'loss': 0.09233499, 'lr': 2.71e-06, 'params': 451793, 'time_iter': 0.07578, 'accuracy': 0.97277, 'precision': 0.75301, 'recall': 0.40584, 'f1': 0.52743, 'auc': 0.90804}
2025-07-04 19:52:19,790 - INFO - val: {'epoch': 90, 'time_epoch': 4.55529, 'loss': 0.07691496, 'lr': 0, 'params': 451793, 'time_iter': 0.03531, 'accuracy': 0.98177, 'precision': 0.575, 'recall': 0.28395, 'f1': 0.38017, 'auc': 0.79476}
2025-07-04 19:52:24,336 - INFO - test: {'epoch': 90, 'time_epoch': 4.5233, 'loss': 0.12424765, 'lr': 0, 'params': 451793, 'time_iter': 0.03506, 'accuracy': 0.96937, 'precision': 0.52857, 'recall': 0.28462, 'f1': 0.37, 'auc': 0.76372}
2025-07-04 19:52:24,340 - INFO - > Epoch 90: took 87.2s (avg 84.7s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:53:42,207 - INFO - train: {'epoch': 91, 'time_epoch': 77.77997, 'eta': 605.67537, 'eta_hours': 0.16824, 'loss': 0.09434366, 'lr': 2.2e-06, 'params': 451793, 'time_iter': 0.07559, 'accuracy': 0.97237, 'precision': 0.74069, 'recall': 0.40341, 'f1': 0.52233, 'auc': 0.9051}
2025-07-04 19:53:46,765 - INFO - val: {'epoch': 91, 'time_epoch': 4.53153, 'loss': 0.07589482, 'lr': 0, 'params': 451793, 'time_iter': 0.03513, 'accuracy': 0.98225, 'precision': 0.60526, 'recall': 0.28395, 'f1': 0.38655, 'auc': 0.80001}
2025-07-04 19:53:51,372 - INFO - test: {'epoch': 91, 'time_epoch': 4.5855, 'loss': 0.12488846, 'lr': 0, 'params': 451793, 'time_iter': 0.03555, 'accuracy': 0.96937, 'precision': 0.53846, 'recall': 0.21538, 'f1': 0.30769, 'auc': 0.76491}
2025-07-04 19:53:51,375 - INFO - > Epoch 91: took 87.0s (avg 84.7s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:55:08,994 - INFO - train: {'epoch': 92, 'time_epoch': 77.52014, 'eta': 530.10224, 'eta_hours': 0.14725, 'loss': 0.09275428, 'lr': 1.74e-06, 'params': 451793, 'time_iter': 0.07534, 'accuracy': 0.97265, 'precision': 0.75382, 'recall': 0.40016, 'f1': 0.5228, 'auc': 0.90652}
2025-07-04 19:55:13,569 - INFO - val: {'epoch': 92, 'time_epoch': 4.54522, 'loss': 0.07578038, 'lr': 0, 'params': 451793, 'time_iter': 0.03523, 'accuracy': 0.98225, 'precision': 0.60526, 'recall': 0.28395, 'f1': 0.38655, 'auc': 0.7999}
2025-07-04 19:55:18,263 - INFO - test: {'epoch': 92, 'time_epoch': 4.62364, 'loss': 0.1256394, 'lr': 0, 'params': 451793, 'time_iter': 0.03584, 'accuracy': 0.96937, 'precision': 0.53846, 'recall': 0.21538, 'f1': 0.30769, 'auc': 0.76438}
2025-07-04 19:55:18,266 - INFO - > Epoch 92: took 86.9s (avg 84.8s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:56:35,523 - INFO - train: {'epoch': 93, 'time_epoch': 77.1698, 'eta': 454.46532, 'eta_hours': 0.12624, 'loss': 0.094068, 'lr': 1.33e-06, 'params': 451793, 'time_iter': 0.07499, 'accuracy': 0.97261, 'precision': 0.759, 'recall': 0.39367, 'f1': 0.51844, 'auc': 0.90396}
2025-07-04 19:56:40,114 - INFO - val: {'epoch': 93, 'time_epoch': 4.51332, 'loss': 0.07681491, 'lr': 0, 'params': 451793, 'time_iter': 0.03499, 'accuracy': 0.98201, 'precision': 0.58974, 'recall': 0.28395, 'f1': 0.38333, 'auc': 0.79599}
2025-07-04 19:56:44,662 - INFO - test: {'epoch': 93, 'time_epoch': 4.52581, 'loss': 0.12667354, 'lr': 0, 'params': 451793, 'time_iter': 0.03508, 'accuracy': 0.96912, 'precision': 0.5283, 'recall': 0.21538, 'f1': 0.30601, 'auc': 0.76608}
2025-07-04 19:56:44,665 - INFO - > Epoch 93: took 86.4s (avg 84.8s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:58:01,950 - INFO - train: {'epoch': 94, 'time_epoch': 77.19515, 'eta': 378.79747, 'eta_hours': 0.10522, 'loss': 0.09280678, 'lr': 9.8e-07, 'params': 451793, 'time_iter': 0.07502, 'accuracy': 0.97271, 'precision': 0.74777, 'recall': 0.40909, 'f1': 0.52886, 'auc': 0.90974}
2025-07-04 19:58:06,598 - INFO - val: {'epoch': 94, 'time_epoch': 4.61712, 'loss': 0.07566323, 'lr': 0, 'params': 451793, 'time_iter': 0.03579, 'accuracy': 0.98177, 'precision': 0.575, 'recall': 0.28395, 'f1': 0.38017, 'auc': 0.80072}
2025-07-04 19:58:11,761 - INFO - test: {'epoch': 94, 'time_epoch': 5.14154, 'loss': 0.12382962, 'lr': 0, 'params': 451793, 'time_iter': 0.03986, 'accuracy': 0.96912, 'precision': 0.52727, 'recall': 0.22308, 'f1': 0.31351, 'auc': 0.76766}
2025-07-04 19:58:11,764 - INFO - > Epoch 94: took 87.1s (avg 84.8s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 19:59:29,271 - INFO - train: {'epoch': 95, 'time_epoch': 77.41902, 'eta': 303.10712, 'eta_hours': 0.0842, 'loss': 0.09374311, 'lr': 6.8e-07, 'params': 451793, 'time_iter': 0.07524, 'accuracy': 0.97301, 'precision': 0.7622, 'recall': 0.40584, 'f1': 0.52966, 'auc': 0.90573}
2025-07-04 19:59:33,812 - INFO - val: {'epoch': 95, 'time_epoch': 4.51174, 'loss': 0.07420433, 'lr': 0, 'params': 451793, 'time_iter': 0.03497, 'accuracy': 0.98225, 'precision': 0.60526, 'recall': 0.28395, 'f1': 0.38655, 'auc': 0.80896}
2025-07-04 19:59:38,366 - INFO - test: {'epoch': 95, 'time_epoch': 4.53128, 'loss': 0.12358039, 'lr': 0, 'params': 451793, 'time_iter': 0.03513, 'accuracy': 0.96985, 'precision': 0.56, 'recall': 0.21538, 'f1': 0.31111, 'auc': 0.76706}
2025-07-04 19:59:38,371 - INFO - > Epoch 95: took 86.6s (avg 84.8s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 20:00:58,058 - INFO - train: {'epoch': 96, 'time_epoch': 79.59414, 'eta': 227.4484, 'eta_hours': 0.06318, 'loss': 0.09404079, 'lr': 4.4e-07, 'params': 451793, 'time_iter': 0.07735, 'accuracy': 0.97289, 'precision': 0.75148, 'recall': 0.41234, 'f1': 0.53249, 'auc': 0.90642}
2025-07-04 20:01:03,152 - INFO - val: {'epoch': 96, 'time_epoch': 5.05649, 'loss': 0.07616812, 'lr': 0, 'params': 451793, 'time_iter': 0.0392, 'accuracy': 0.98177, 'precision': 0.575, 'recall': 0.28395, 'f1': 0.38017, 'auc': 0.79891}
2025-07-04 20:01:08,117 - INFO - test: {'epoch': 96, 'time_epoch': 4.94169, 'loss': 0.12593768, 'lr': 0, 'params': 451793, 'time_iter': 0.03831, 'accuracy': 0.96888, 'precision': 0.51724, 'recall': 0.23077, 'f1': 0.31915, 'auc': 0.75968}
2025-07-04 20:01:08,124 - INFO - > Epoch 96: took 89.8s (avg 84.9s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 20:02:28,325 - INFO - train: {'epoch': 97, 'time_epoch': 80.11207, 'eta': 151.71994, 'eta_hours': 0.04214, 'loss': 0.0935308, 'lr': 2.5e-07, 'params': 451793, 'time_iter': 0.07785, 'accuracy': 0.97295, 'precision': 0.75296, 'recall': 0.41315, 'f1': 0.53354, 'auc': 0.9084}
2025-07-04 20:02:32,901 - INFO - val: {'epoch': 97, 'time_epoch': 4.54829, 'loss': 0.07556902, 'lr': 0, 'params': 451793, 'time_iter': 0.03526, 'accuracy': 0.98201, 'precision': 0.58974, 'recall': 0.28395, 'f1': 0.38333, 'auc': 0.80304}
2025-07-04 20:02:37,460 - INFO - test: {'epoch': 97, 'time_epoch': 4.52763, 'loss': 0.12526852, 'lr': 0, 'params': 451793, 'time_iter': 0.0351, 'accuracy': 0.96937, 'precision': 0.53571, 'recall': 0.23077, 'f1': 0.32258, 'auc': 0.76156}
2025-07-04 20:02:37,464 - INFO - > Epoch 97: took 89.3s (avg 84.9s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 20:03:53,859 - INFO - train: {'epoch': 98, 'time_epoch': 76.26679, 'eta': 75.86408, 'eta_hours': 0.02107, 'loss': 0.09320645, 'lr': 1.1e-07, 'params': 451793, 'time_iter': 0.07412, 'accuracy': 0.97274, 'precision': 0.7605, 'recall': 0.39692, 'f1': 0.5216, 'auc': 0.90788}
2025-07-04 20:03:58,409 - INFO - val: {'epoch': 98, 'time_epoch': 4.51969, 'loss': 0.0740738, 'lr': 0, 'params': 451793, 'time_iter': 0.03504, 'accuracy': 0.98225, 'precision': 0.60526, 'recall': 0.28395, 'f1': 0.38655, 'auc': 0.80601}
2025-07-04 20:04:02,960 - INFO - test: {'epoch': 98, 'time_epoch': 4.52103, 'loss': 0.12335971, 'lr': 0, 'params': 451793, 'time_iter': 0.03505, 'accuracy': 0.96985, 'precision': 0.55357, 'recall': 0.23846, 'f1': 0.33333, 'auc': 0.7706}
2025-07-04 20:04:02,963 - INFO - > Epoch 98: took 85.5s (avg 84.9s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 20:05:19,334 - INFO - train: {'epoch': 99, 'time_epoch': 76.28444, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.09282215, 'lr': 3e-08, 'params': 451793, 'time_iter': 0.07413, 'accuracy': 0.97265, 'precision': 0.75776, 'recall': 0.3961, 'f1': 0.52026, 'auc': 0.91035}
2025-07-04 20:05:23,827 - INFO - val: {'epoch': 99, 'time_epoch': 4.46305, 'loss': 0.07578799, 'lr': 0, 'params': 451793, 'time_iter': 0.0346, 'accuracy': 0.98201, 'precision': 0.58974, 'recall': 0.28395, 'f1': 0.38333, 'auc': 0.79675}
2025-07-04 20:05:28,319 - INFO - test: {'epoch': 99, 'time_epoch': 4.47084, 'loss': 0.12458297, 'lr': 0, 'params': 451793, 'time_iter': 0.03466, 'accuracy': 0.96937, 'precision': 0.53704, 'recall': 0.22308, 'f1': 0.31522, 'auc': 0.76186}
2025-07-04 20:05:28,448 - INFO - > Epoch 99: took 85.4s (avg 84.9s) | Best so far: epoch 31	train_loss: 0.1135 train_auc: 0.8413	val_loss: 0.0740 val_auc: 0.8166	test_loss: 0.1151 test_auc: 0.7690
2025-07-04 20:05:28,448 - INFO - Avg time per epoch: 84.93s
2025-07-04 20:05:28,448 - INFO - Total train loop time: 2.36h
2025-07-04 20:05:28,449 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-41
2025-07-04 20:05:28,450 - INFO - Total time: 8556.87s (2.38h)
2025-07-04 20:05:28,470 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-41/agg
2025-07-04 20:05:28,470 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-07-04 20:05:28,470 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-41
2025-07-04 20:05:28,470 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-41/test_results/
Completed seed 41. Results saved in results/molhiv/molhiv-Vanilla-41
----------------------------------------
Running experiment with seed: 45
Starting training for seed 45...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/confignas.yaml
Using device: cuda
2025-07-04 20:05:44,149 - INFO - GPU Mem: 34.1GB
2025-07-04 20:05:44,149 - INFO - Run directory: results/molhiv/molhiv-Vanilla-45
2025-07-04 20:05:44,149 - INFO - Seed: 45
2025-07-04 20:05:44,149 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-07-04 20:05:44,149 - INFO - Routing mode: none
2025-07-04 20:05:44,149 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-07-04 20:05:44,149 - INFO - Number of layers: 15
2025-07-04 20:05:44,149 - INFO - Uncertainty enabled: False
2025-07-04 20:05:44,149 - INFO - Training mode: custom
2025-07-04 20:05:44,149 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-07-04 20:05:44,149 - INFO - Additional features: Router weights logging + JSON export
2025-07-04 20:05:51,105 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-04 20:05:51,119 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-07-04 20:05:51,121 - INFO -   undirected: True
2025-07-04 20:05:51,121 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-04 20:05:51,121 - INFO -   avg num_nodes/graph: 25
2025-07-04 20:05:51,122 - INFO -   num node features: 9
2025-07-04 20:05:51,122 - INFO -   num edge features: 3
2025-07-04 20:05:51,122 - INFO -   num tasks: 1
2025-07-04 20:05:51,122 - INFO -   num classes: 2
2025-07-04 20:05:51,122 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-07-04 20:05:51,122 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-07-04 20:05:51,126 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  0%|          | 0/41127 [00:13<?, ?it/s]  5%|▍         | 2016/41127 [00:13<04:26, 146.84it/s]  9%|▊         | 3504/41127 [00:23<04:15, 147.16it/s] 12%|█▏        | 5030/41127 [00:34<04:04, 147.57it/s] 13%|█▎        | 5274/41127 [00:44<05:56, 100.44it/s] 15%|█▍        | 5984/41127 [00:54<06:33, 89.42it/s]  15%|█▌        | 6317/41127 [01:05<08:19, 69.68it/s] 16%|█▌        | 6527/41127 [01:16<10:49, 53.25it/s] 17%|█▋        | 6922/41127 [01:26<11:46, 48.40it/s] 19%|█▉        | 7890/41127 [01:36<08:49, 62.75it/s] 23%|██▎       | 9298/41127 [01:46<06:10, 85.98it/s] 25%|██▌       | 10384/41127 [01:56<05:31, 92.75it/s] 26%|██▋       | 10870/41127 [02:07<06:24, 78.61it/s] 30%|███       | 12521/41127 [02:17<04:34, 104.32it/s] 34%|███▎      | 13799/41127 [02:27<04:08, 109.83it/s] 35%|███▍      | 14339/41127 [02:37<04:51, 91.95it/s]  36%|███▌      | 14752/41127 [02:48<05:47, 75.82it/s] 38%|███▊      | 15479/41127 [02:58<05:42, 74.91it/s] 38%|███▊      | 15519/41127 [03:09<08:02, 53.09it/s] 40%|███▉      | 16306/41127 [03:19<06:54, 59.83it/s] 40%|████      | 16466/41127 [03:29<08:44, 47.02it/s] 40%|████      | 16540/41127 [03:40<11:48, 34.70it/s] 45%|████▍     | 18468/41127 [03:50<04:41, 80.39it/s] 47%|████▋     | 19277/41127 [04:00<04:33, 79.96it/s] 49%|████▊     | 20008/41127 [04:10<04:31, 77.70it/s] 51%|█████▏    | 21125/41127 [04:21<03:51, 86.40it/s] 53%|█████▎    | 21984/41127 [04:31<03:42, 86.22it/s] 56%|█████▌    | 23109/41127 [04:41<03:15, 92.21it/s] 58%|█████▊    | 23731/41127 [04:52<03:29, 83.05it/s] 61%|██████    | 24916/41127 [05:02<02:55, 92.25it/s] 64%|██████▍   | 26387/41127 [05:13<02:18, 106.32it/s] 66%|██████▌   | 27099/41127 [05:23<02:25, 96.09it/s]  71%|███████   | 29088/41127 [05:33<01:35, 126.29it/s] 71%|███████   | 29273/41127 [05:43<02:07, 92.88it/s]  72%|███████▏  | 29416/41127 [05:53<02:48, 69.71it/s] 74%|███████▍  | 30351/41127 [06:04<02:21, 76.33it/s] 76%|███████▌  | 31092/41127 [06:14<02:13, 75.07it/s] 76%|███████▋  | 31417/41127 [06:24<02:35, 62.50it/s] 79%|███████▉  | 32463/41127 [06:34<01:56, 74.28it/s] 80%|████████  | 32942/41127 [06:44<02:03, 66.48it/s] 83%|████████▎ | 34219/41127 [06:54<01:21, 84.62it/s] 84%|████████▍ | 34582/41127 [07:05<01:35, 68.48it/s] 85%|████████▌ | 35157/41127 [07:16<01:33, 64.16it/s] 86%|████████▋ | 35505/41127 [07:26<01:42, 54.87it/s] 89%|████████▊ | 36478/41127 [07:36<01:09, 66.54it/s] 93%|█████████▎| 38151/41127 [07:47<00:31, 94.34it/s] 94%|█████████▍| 38725/41127 [07:57<00:28, 82.90it/s] 95%|█████████▌| 39218/41127 [08:08<00:26, 72.08it/s] 96%|█████████▋| 39620/41127 [08:18<00:24, 61.71it/s] 97%|█████████▋| 40068/41127 [08:29<00:19, 55.67it/s] 98%|█████████▊| 40349/41127 [08:39<00:16, 47.53it/s] 99%|█████████▉| 40746/41127 [08:50<00:08, 44.69it/s]100%|█████████▉| 40986/41127 [09:00<00:03, 38.17it/s]100%|██████████| 41127/41127 [09:10<00:00, 74.77it/s]
2025-07-04 20:15:02,455 - INFO - Done! Took 00:09:11.33
2025-07-04 20:15:02,619 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-07-04 20:15:02,752 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-07-04 20:15:02,752 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-07-04 20:15:02,752 - INFO - Inner model has get_darts_model: False
2025-07-04 20:15:02,760 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-07-04 20:15:02,764 - INFO - Number of parameters: 451,793
2025-07-04 20:15:02,764 - INFO - Starting optimized training: 2025-07-04 20:15:02.764188
2025-07-04 20:15:09,265 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-04 20:15:09,265 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-07-04 20:15:09,266 - INFO -   undirected: True
2025-07-04 20:15:09,266 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-04 20:15:09,267 - INFO -   avg num_nodes/graph: 25
2025-07-04 20:15:09,267 - INFO -   num node features: 9
2025-07-04 20:15:09,267 - INFO -   num edge features: 3
2025-07-04 20:15:09,267 - INFO -   num tasks: 1
2025-07-04 20:15:09,267 - INFO -   num classes: 2
2025-07-04 20:15:09,267 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-07-04 20:15:09,268 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-07-04 20:15:09,271 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  5%|▍         | 2056/41127 [00:14<04:29, 144.83it/s]  5%|▍         | 2056/41127 [00:25<04:29, 144.83it/s] 10%|▉         | 4003/41127 [00:26<03:58, 155.36it/s] 12%|█▏        | 5047/41127 [00:36<04:30, 133.20it/s] 14%|█▎        | 5601/41127 [00:46<05:40, 104.32it/s] 15%|█▍        | 6025/41127 [00:57<07:11, 81.32it/s]  16%|█▌        | 6448/41127 [01:07<08:24, 68.80it/s] 16%|█▌        | 6562/41127 [01:17<11:23, 50.55it/s] 18%|█▊        | 7242/41127 [01:27<10:08, 55.64it/s] 21%|██        | 8584/41127 [01:38<06:50, 79.30it/s] 24%|██▍       | 9905/41127 [01:48<05:27, 95.25it/s] 26%|██▌       | 10636/41127 [01:58<05:50, 87.10it/s] 28%|██▊       | 11713/41127 [02:08<05:15, 93.23it/s] 32%|███▏      | 12978/41127 [02:18<04:32, 103.15it/s] 34%|███▎      | 13836/41127 [02:28<04:38, 97.96it/s]  36%|███▌      | 14737/41127 [02:38<04:38, 94.84it/s] 36%|███▌      | 14757/41127 [02:49<06:36, 66.53it/s] 38%|███▊      | 15507/41127 [02:59<06:15, 68.23it/s] 38%|███▊      | 15608/41127 [03:09<08:23, 50.67it/s] 40%|███▉      | 16401/41127 [03:20<07:02, 58.47it/s] 40%|████      | 16472/41127 [03:30<09:33, 42.96it/s] 42%|████▏     | 17342/41127 [03:40<07:09, 55.42it/s] 45%|████▌     | 18652/41127 [03:51<04:52, 76.96it/s] 48%|████▊     | 19616/41127 [04:01<04:26, 80.80it/s] 51%|█████     | 20801/41127 [04:11<03:41, 91.64it/s] 52%|█████▏    | 21226/41127 [04:21<04:17, 77.23it/s] 55%|█████▍    | 22460/41127 [04:31<03:25, 90.86it/s] 57%|█████▋    | 23587/41127 [04:42<03:04, 95.07it/s] 60%|█████▉    | 24480/41127 [04:53<03:01, 91.66it/s] 62%|██████▏   | 25591/41127 [05:03<02:41, 96.37it/s] 65%|██████▍   | 26608/41127 [05:14<02:31, 95.88it/s] 69%|██████▉   | 28370/41127 [05:25<01:48, 117.37it/s] 71%|███████   | 29265/41127 [05:35<01:49, 108.12it/s] 71%|███████▏  | 29348/41127 [05:45<02:29, 78.63it/s]  74%|███████▎  | 30327/41127 [05:56<02:10, 82.72it/s] 76%|███████▌  | 31088/41127 [06:06<02:05, 80.31it/s] 76%|███████▌  | 31129/41127 [06:17<02:55, 57.06it/s] 79%|███████▊  | 32366/41127 [06:27<01:54, 76.43it/s] 80%|████████  | 32904/41127 [06:37<02:00, 68.29it/s] 83%|████████▎ | 34181/41127 [06:48<01:23, 83.55it/s] 84%|████████▍ | 34557/41127 [06:58<01:34, 69.82it/s] 85%|████████▍ | 34913/41127 [07:08<01:43, 59.85it/s] 86%|████████▌ | 35437/41127 [07:19<01:39, 57.41it/s] 87%|████████▋ | 35615/41127 [07:29<02:00, 45.68it/s] 90%|█████████ | 37185/41127 [07:39<00:50, 77.84it/s] 93%|█████████▎| 38400/41127 [07:49<00:30, 89.56it/s] 94%|█████████▍| 38766/41127 [08:00<00:32, 73.59it/s] 96%|█████████▌| 39405/41127 [08:10<00:24, 69.70it/s] 97%|█████████▋| 40059/41127 [08:21<00:15, 67.03it/s] 98%|█████████▊| 40157/41127 [08:31<00:19, 49.92it/s] 98%|█████████▊| 40481/41127 [08:41<00:14, 44.60it/s]100%|█████████▉| 40934/41127 [08:52<00:04, 44.08it/s]100%|█████████▉| 41028/41127 [09:02<00:02, 33.58it/s]100%|██████████| 41127/41127 [09:08<00:00, 75.03it/s]
2025-07-04 20:24:18,672 - INFO - Done! Took 00:09:09.40
2025-07-04 20:24:18,833 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-07-04 20:24:18,846 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-07-04 20:24:18,847 - INFO - Start from epoch 0
2025-07-04 20:25:42,955 - INFO - train: {'epoch': 0, 'time_epoch': 83.9045, 'eta': 8306.5459, 'eta_hours': 2.30737, 'loss': 0.62549572, 'lr': 0.0, 'params': 451793, 'time_iter': 0.08154, 'accuracy': 0.96222, 'precision': 0.07692, 'recall': 0.00081, 'f1': 0.00161, 'auc': 0.4713}
2025-07-04 20:25:42,966 - INFO - ...computing epoch stats took: 0.18s
2025-07-04 20:25:48,223 - INFO - val: {'epoch': 0, 'time_epoch': 5.23696, 'loss': 0.62598024, 'lr': 0, 'params': 451793, 'time_iter': 0.0406, 'accuracy': 0.98006, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.43285}
2025-07-04 20:25:48,227 - INFO - ...computing epoch stats took: 0.02s
2025-07-04 20:25:53,484 - INFO - test: {'epoch': 0, 'time_epoch': 5.23223, 'loss': 0.62910126, 'lr': 0, 'params': 451793, 'time_iter': 0.04056, 'accuracy': 0.96815, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.41876}
2025-07-04 20:25:53,487 - INFO - ...computing epoch stats took: 0.02s
2025-07-04 20:25:53,488 - INFO - > Epoch 0: took 94.6s (avg 94.6s) | Best so far: epoch 0	train_loss: 0.6255 train_auc: 0.4713	val_loss: 0.6260 val_auc: 0.4329	test_loss: 0.6291 test_auc: 0.4188
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:27:20,085 - INFO - train: {'epoch': 1, 'time_epoch': 86.36365, 'eta': 8343.13976, 'eta_hours': 2.31754, 'loss': 0.49426241, 'lr': 2e-05, 'params': 451793, 'time_iter': 0.08393, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.51144}
2025-07-04 20:27:20,093 - INFO - ...computing epoch stats took: 0.21s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:27:24,715 - INFO - val: {'epoch': 1, 'time_epoch': 4.59757, 'loss': 0.31273544, 'lr': 0, 'params': 451793, 'time_iter': 0.03564, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.51592}
2025-07-04 20:27:24,718 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:27:29,346 - INFO - test: {'epoch': 1, 'time_epoch': 4.61008, 'loss': 0.316119, 'lr': 0, 'params': 451793, 'time_iter': 0.03574, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.50434}
2025-07-04 20:27:29,349 - INFO - ...computing epoch stats took: 0.02s
2025-07-04 20:27:29,349 - INFO - > Epoch 1: took 95.9s (avg 95.3s) | Best so far: epoch 1	train_loss: 0.4943 train_auc: 0.5114	val_loss: 0.3127 val_auc: 0.5159	test_loss: 0.3161 test_auc: 0.5043
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:28:46,996 - INFO - train: {'epoch': 2, 'time_epoch': 77.42916, 'eta': 8008.87997, 'eta_hours': 2.22469, 'loss': 0.21045026, 'lr': 4e-05, 'params': 451793, 'time_iter': 0.07525, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.5535}
2025-07-04 20:28:47,008 - INFO - ...computing epoch stats took: 0.20s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:28:51,596 - INFO - val: {'epoch': 2, 'time_epoch': 4.56894, 'loss': 0.10839908, 'lr': 0, 'params': 451793, 'time_iter': 0.03542, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.62978}
2025-07-04 20:28:51,599 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:28:56,227 - INFO - test: {'epoch': 2, 'time_epoch': 4.6081, 'loss': 0.1481394, 'lr': 0, 'params': 451793, 'time_iter': 0.03572, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.61011}
2025-07-04 20:28:56,230 - INFO - ...computing epoch stats took: 0.02s
2025-07-04 20:28:56,231 - INFO - > Epoch 2: took 86.9s (avg 92.5s) | Best so far: epoch 2	train_loss: 0.2105 train_auc: 0.5535	val_loss: 0.1084 val_auc: 0.6298	test_loss: 0.1481 test_auc: 0.6101
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:30:13,405 - INFO - train: {'epoch': 3, 'time_epoch': 76.98452, 'eta': 7792.36407, 'eta_hours': 2.16455, 'loss': 0.1593767, 'lr': 6e-05, 'params': 451793, 'time_iter': 0.07481, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.61145}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:30:17,894 - INFO - val: {'epoch': 3, 'time_epoch': 4.46169, 'loss': 0.10124401, 'lr': 0, 'params': 451793, 'time_iter': 0.03459, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.62144}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:30:22,364 - INFO - test: {'epoch': 3, 'time_epoch': 4.4503, 'loss': 0.13860169, 'lr': 0, 'params': 451793, 'time_iter': 0.0345, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.64076}
2025-07-04 20:30:22,366 - INFO - > Epoch 3: took 86.1s (avg 90.9s) | Best so far: epoch 2	train_loss: 0.2105 train_auc: 0.5535	val_loss: 0.1084 val_auc: 0.6298	test_loss: 0.1481 test_auc: 0.6101
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:31:39,268 - INFO - train: {'epoch': 4, 'time_epoch': 76.67231, 'eta': 7625.72869, 'eta_hours': 2.11826, 'loss': 0.15238469, 'lr': 8e-05, 'params': 451793, 'time_iter': 0.07451, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.65753}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:31:43,763 - INFO - val: {'epoch': 4, 'time_epoch': 4.46906, 'loss': 0.091136, 'lr': 0, 'params': 451793, 'time_iter': 0.03464, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6825}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:31:48,251 - INFO - test: {'epoch': 4, 'time_epoch': 4.46779, 'loss': 0.13024697, 'lr': 0, 'params': 451793, 'time_iter': 0.03463, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69072}
2025-07-04 20:31:48,254 - INFO - > Epoch 4: took 85.9s (avg 89.9s) | Best so far: epoch 4	train_loss: 0.1524 train_auc: 0.6575	val_loss: 0.0911 val_auc: 0.6825	test_loss: 0.1302 test_auc: 0.6907
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:33:04,494 - INFO - train: {'epoch': 5, 'time_epoch': 76.05263, 'eta': 7479.37277, 'eta_hours': 2.0776, 'loss': 0.14896546, 'lr': 0.0001, 'params': 451793, 'time_iter': 0.07391, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68209}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:33:09,043 - INFO - val: {'epoch': 5, 'time_epoch': 4.52438, 'loss': 0.09300256, 'lr': 0, 'params': 451793, 'time_iter': 0.03507, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67499}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:33:13,618 - INFO - test: {'epoch': 5, 'time_epoch': 4.54918, 'loss': 0.12943806, 'lr': 0, 'params': 451793, 'time_iter': 0.03526, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70669}
2025-07-04 20:33:13,624 - INFO - > Epoch 5: took 85.4s (avg 89.1s) | Best so far: epoch 4	train_loss: 0.1524 train_auc: 0.6575	val_loss: 0.0911 val_auc: 0.6825	test_loss: 0.1302 test_auc: 0.6907
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:34:28,024 - INFO - train: {'epoch': 6, 'time_epoch': 74.23607, 'eta': 7328.96916, 'eta_hours': 2.03582, 'loss': 0.14436424, 'lr': 9.997e-05, 'params': 451793, 'time_iter': 0.07214, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71879}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:34:32,476 - INFO - val: {'epoch': 6, 'time_epoch': 4.4179, 'loss': 0.09173493, 'lr': 0, 'params': 451793, 'time_iter': 0.03425, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70518}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:34:36,898 - INFO - test: {'epoch': 6, 'time_epoch': 4.38541, 'loss': 0.13054152, 'lr': 0, 'params': 451793, 'time_iter': 0.034, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73586}
2025-07-04 20:34:36,900 - INFO - > Epoch 6: took 83.3s (avg 88.3s) | Best so far: epoch 6	train_loss: 0.1444 train_auc: 0.7188	val_loss: 0.0917 val_auc: 0.7052	test_loss: 0.1305 test_auc: 0.7359
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:35:51,115 - INFO - train: {'epoch': 7, 'time_epoch': 74.03194, 'eta': 7195.25992, 'eta_hours': 1.99868, 'loss': 0.14263246, 'lr': 9.989e-05, 'params': 451793, 'time_iter': 0.07195, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72342}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:35:55,593 - INFO - val: {'epoch': 7, 'time_epoch': 4.45393, 'loss': 0.09386286, 'lr': 0, 'params': 451793, 'time_iter': 0.03453, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68801}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:36:00,070 - INFO - test: {'epoch': 7, 'time_epoch': 4.4568, 'loss': 0.12759909, 'lr': 0, 'params': 451793, 'time_iter': 0.03455, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70887}
2025-07-04 20:36:00,072 - INFO - > Epoch 7: took 83.2s (avg 87.7s) | Best so far: epoch 6	train_loss: 0.1444 train_auc: 0.7188	val_loss: 0.0917 val_auc: 0.7052	test_loss: 0.1305 test_auc: 0.7359
2025-07-04 20:37:15,155 - INFO - train: {'epoch': 8, 'time_epoch': 74.85499, 'eta': 7083.13425, 'eta_hours': 1.96754, 'loss': 0.14040349, 'lr': 9.975e-05, 'params': 451793, 'time_iter': 0.07275, 'accuracy': 0.96258, 'precision': 1.0, 'recall': 0.00081, 'f1': 0.00162, 'auc': 0.73666}
2025-07-04 20:37:19,668 - INFO - val: {'epoch': 8, 'time_epoch': 4.48764, 'loss': 0.08848512, 'lr': 0, 'params': 451793, 'time_iter': 0.03479, 'accuracy': 0.98055, 'precision': 1.0, 'recall': 0.01235, 'f1': 0.02439, 'auc': 0.74566}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 20:37:24,186 - INFO - test: {'epoch': 8, 'time_epoch': 4.49642, 'loss': 0.12094057, 'lr': 0, 'params': 451793, 'time_iter': 0.03486, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74413}
2025-07-04 20:37:24,194 - INFO - > Epoch 8: took 84.1s (avg 87.3s) | Best so far: epoch 8	train_loss: 0.1404 train_auc: 0.7367	val_loss: 0.0885 val_auc: 0.7457	test_loss: 0.1209 test_auc: 0.7441
2025-07-04 20:38:38,221 - INFO - train: {'epoch': 9, 'time_epoch': 73.8189, 'eta': 6969.13798, 'eta_hours': 1.93587, 'loss': 0.13864799, 'lr': 9.956e-05, 'params': 451793, 'time_iter': 0.07174, 'accuracy': 0.96268, 'precision': 0.64286, 'recall': 0.00731, 'f1': 0.01445, 'auc': 0.74258}
2025-07-04 20:38:42,721 - INFO - val: {'epoch': 9, 'time_epoch': 4.47324, 'loss': 0.08731797, 'lr': 0, 'params': 451793, 'time_iter': 0.03468, 'accuracy': 0.98152, 'precision': 0.64706, 'recall': 0.1358, 'f1': 0.22449, 'auc': 0.74047}
2025-07-04 20:38:47,639 - INFO - test: {'epoch': 9, 'time_epoch': 4.89528, 'loss': 0.1190718, 'lr': 0, 'params': 451793, 'time_iter': 0.03795, 'accuracy': 0.97034, 'precision': 0.7, 'recall': 0.10769, 'f1': 0.18667, 'auc': 0.7456}
2025-07-04 20:38:47,642 - INFO - > Epoch 9: took 83.4s (avg 86.9s) | Best so far: epoch 8	train_loss: 0.1404 train_auc: 0.7367	val_loss: 0.0885 val_auc: 0.7457	test_loss: 0.1209 test_auc: 0.7441
2025-07-04 20:40:06,431 - INFO - train: {'epoch': 10, 'time_epoch': 78.57823, 'eta': 6900.95394, 'eta_hours': 1.91693, 'loss': 0.13672837, 'lr': 9.932e-05, 'params': 451793, 'time_iter': 0.07636, 'accuracy': 0.96277, 'precision': 0.5814, 'recall': 0.02029, 'f1': 0.03922, 'auc': 0.75704}
2025-07-04 20:40:11,038 - INFO - val: {'epoch': 10, 'time_epoch': 4.57795, 'loss': 0.08191359, 'lr': 0, 'params': 451793, 'time_iter': 0.03549, 'accuracy': 0.98104, 'precision': 0.66667, 'recall': 0.07407, 'f1': 0.13333, 'auc': 0.7656}
2025-07-04 20:40:15,710 - INFO - test: {'epoch': 10, 'time_epoch': 4.651, 'loss': 0.1244387, 'lr': 0, 'params': 451793, 'time_iter': 0.03605, 'accuracy': 0.96864, 'precision': 1.0, 'recall': 0.00769, 'f1': 0.01527, 'auc': 0.74553}
2025-07-04 20:40:15,712 - INFO - > Epoch 10: took 88.1s (avg 87.0s) | Best so far: epoch 10	train_loss: 0.1367 train_auc: 0.7570	val_loss: 0.0819 val_auc: 0.7656	test_loss: 0.1244 test_auc: 0.7455
2025-07-04 20:41:29,938 - INFO - train: {'epoch': 11, 'time_epoch': 74.03414, 'eta': 6797.71424, 'eta_hours': 1.88825, 'loss': 0.13537783, 'lr': 9.902e-05, 'params': 451793, 'time_iter': 0.07195, 'accuracy': 0.96325, 'precision': 0.58647, 'recall': 0.06331, 'f1': 0.11429, 'auc': 0.75296}
2025-07-04 20:41:34,361 - INFO - val: {'epoch': 11, 'time_epoch': 4.39696, 'loss': 0.08379659, 'lr': 0, 'params': 451793, 'time_iter': 0.03408, 'accuracy': 0.98055, 'precision': 0.54545, 'recall': 0.07407, 'f1': 0.13043, 'auc': 0.75935}
2025-07-04 20:41:38,781 - INFO - test: {'epoch': 11, 'time_epoch': 4.39557, 'loss': 0.11816835, 'lr': 0, 'params': 451793, 'time_iter': 0.03407, 'accuracy': 0.97034, 'precision': 0.75, 'recall': 0.09231, 'f1': 0.16438, 'auc': 0.75996}
2025-07-04 20:41:38,784 - INFO - > Epoch 11: took 83.1s (avg 86.7s) | Best so far: epoch 10	train_loss: 0.1367 train_auc: 0.7570	val_loss: 0.0819 val_auc: 0.7656	test_loss: 0.1244 test_auc: 0.7455
2025-07-04 20:42:52,670 - INFO - train: {'epoch': 12, 'time_epoch': 73.68343, 'eta': 6696.62064, 'eta_hours': 1.86017, 'loss': 0.13255652, 'lr': 9.867e-05, 'params': 451793, 'time_iter': 0.07161, 'accuracy': 0.96417, 'precision': 0.64641, 'recall': 0.09497, 'f1': 0.16561, 'auc': 0.7706}
2025-07-04 20:42:57,101 - INFO - val: {'epoch': 12, 'time_epoch': 4.40596, 'loss': 0.08484668, 'lr': 0, 'params': 451793, 'time_iter': 0.03415, 'accuracy': 0.98055, 'precision': 0.52632, 'recall': 0.12346, 'f1': 0.2, 'auc': 0.75906}
2025-07-04 20:43:01,528 - INFO - test: {'epoch': 12, 'time_epoch': 4.40581, 'loss': 0.12087849, 'lr': 0, 'params': 451793, 'time_iter': 0.03415, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.08462, 'f1': 0.14474, 'auc': 0.73834}
2025-07-04 20:43:01,531 - INFO - > Epoch 12: took 82.7s (avg 86.4s) | Best so far: epoch 10	train_loss: 0.1367 train_auc: 0.7570	val_loss: 0.0819 val_auc: 0.7656	test_loss: 0.1244 test_auc: 0.7455
2025-07-04 20:44:15,799 - INFO - train: {'epoch': 13, 'time_epoch': 74.0365, 'eta': 6601.61166, 'eta_hours': 1.83378, 'loss': 0.13027074, 'lr': 9.826e-05, 'params': 451793, 'time_iter': 0.07195, 'accuracy': 0.9641, 'precision': 0.61233, 'recall': 0.11282, 'f1': 0.19054, 'auc': 0.79041}
2025-07-04 20:44:20,233 - INFO - val: {'epoch': 13, 'time_epoch': 4.40707, 'loss': 0.0845622, 'lr': 0, 'params': 451793, 'time_iter': 0.03416, 'accuracy': 0.98177, 'precision': 0.65, 'recall': 0.16049, 'f1': 0.25743, 'auc': 0.77006}
2025-07-04 20:44:24,663 - INFO - test: {'epoch': 13, 'time_epoch': 4.40828, 'loss': 0.1179411, 'lr': 0, 'params': 451793, 'time_iter': 0.03417, 'accuracy': 0.96985, 'precision': 0.61538, 'recall': 0.12308, 'f1': 0.20513, 'auc': 0.75006}
2025-07-04 20:44:24,665 - INFO - > Epoch 13: took 83.1s (avg 86.1s) | Best so far: epoch 13	train_loss: 0.1303 train_auc: 0.7904	val_loss: 0.0846 val_auc: 0.7701	test_loss: 0.1179 test_auc: 0.7501
2025-07-04 20:45:39,298 - INFO - train: {'epoch': 14, 'time_epoch': 74.41019, 'eta': 6511.51654, 'eta_hours': 1.80875, 'loss': 0.13101557, 'lr': 9.78e-05, 'params': 451793, 'time_iter': 0.07231, 'accuracy': 0.96417, 'precision': 0.60729, 'recall': 0.12175, 'f1': 0.20284, 'auc': 0.77626}
2025-07-04 20:45:43,762 - INFO - val: {'epoch': 14, 'time_epoch': 4.4386, 'loss': 0.07983466, 'lr': 0, 'params': 451793, 'time_iter': 0.03441, 'accuracy': 0.98128, 'precision': 0.59091, 'recall': 0.16049, 'f1': 0.25243, 'auc': 0.77683}
2025-07-04 20:45:48,218 - INFO - test: {'epoch': 14, 'time_epoch': 4.43392, 'loss': 0.11813773, 'lr': 0, 'params': 451793, 'time_iter': 0.03437, 'accuracy': 0.96742, 'precision': 0.42308, 'recall': 0.08462, 'f1': 0.14103, 'auc': 0.75491}
2025-07-04 20:45:48,220 - INFO - > Epoch 14: took 83.6s (avg 86.0s) | Best so far: epoch 14	train_loss: 0.1310 train_auc: 0.7763	val_loss: 0.0798 val_auc: 0.7768	test_loss: 0.1181 test_auc: 0.7549
2025-07-04 20:47:02,544 - INFO - train: {'epoch': 15, 'time_epoch': 74.08847, 'eta': 6421.69302, 'eta_hours': 1.7838, 'loss': 0.12905434, 'lr': 9.729e-05, 'params': 451793, 'time_iter': 0.072, 'accuracy': 0.96386, 'precision': 0.58175, 'recall': 0.12419, 'f1': 0.20468, 'auc': 0.79572}
2025-07-04 20:47:07,033 - INFO - val: {'epoch': 15, 'time_epoch': 4.4576, 'loss': 0.0815388, 'lr': 0, 'params': 451793, 'time_iter': 0.03456, 'accuracy': 0.98104, 'precision': 0.56522, 'recall': 0.16049, 'f1': 0.25, 'auc': 0.73054}
2025-07-04 20:47:11,517 - INFO - test: {'epoch': 15, 'time_epoch': 4.46193, 'loss': 0.12005703, 'lr': 0, 'params': 451793, 'time_iter': 0.03459, 'accuracy': 0.96791, 'precision': 0.47368, 'recall': 0.13846, 'f1': 0.21429, 'auc': 0.74938}
2025-07-04 20:47:11,519 - INFO - > Epoch 15: took 83.3s (avg 85.8s) | Best so far: epoch 14	train_loss: 0.1310 train_auc: 0.7763	val_loss: 0.0798 val_auc: 0.7768	test_loss: 0.1181 test_auc: 0.7549
2025-07-04 20:48:25,983 - INFO - train: {'epoch': 16, 'time_epoch': 74.23646, 'eta': 6334.44321, 'eta_hours': 1.75957, 'loss': 0.12829494, 'lr': 9.673e-05, 'params': 451793, 'time_iter': 0.07214, 'accuracy': 0.96423, 'precision': 0.59259, 'recall': 0.14286, 'f1': 0.23022, 'auc': 0.79463}
2025-07-04 20:48:30,395 - INFO - val: {'epoch': 16, 'time_epoch': 4.38702, 'loss': 0.08613271, 'lr': 0, 'params': 451793, 'time_iter': 0.03401, 'accuracy': 0.98128, 'precision': 0.7, 'recall': 0.08642, 'f1': 0.15385, 'auc': 0.70218}
2025-07-04 20:48:34,822 - INFO - test: {'epoch': 16, 'time_epoch': 4.40567, 'loss': 0.13032945, 'lr': 0, 'params': 451793, 'time_iter': 0.03415, 'accuracy': 0.96742, 'precision': 0.3, 'recall': 0.02308, 'f1': 0.04286, 'auc': 0.72037}
2025-07-04 20:48:34,824 - INFO - > Epoch 16: took 83.3s (avg 85.6s) | Best so far: epoch 14	train_loss: 0.1310 train_auc: 0.7763	val_loss: 0.0798 val_auc: 0.7768	test_loss: 0.1181 test_auc: 0.7549
2025-07-04 20:49:49,214 - INFO - train: {'epoch': 17, 'time_epoch': 74.17526, 'eta': 6248.36053, 'eta_hours': 1.73566, 'loss': 0.12770658, 'lr': 9.611e-05, 'params': 451793, 'time_iter': 0.07208, 'accuracy': 0.96444, 'precision': 0.6069, 'recall': 0.14286, 'f1': 0.23127, 'auc': 0.79301}
2025-07-04 20:49:53,667 - INFO - val: {'epoch': 17, 'time_epoch': 4.42659, 'loss': 0.07855953, 'lr': 0, 'params': 451793, 'time_iter': 0.03431, 'accuracy': 0.98104, 'precision': 0.56522, 'recall': 0.16049, 'f1': 0.25, 'auc': 0.77983}
2025-07-04 20:49:58,096 - INFO - test: {'epoch': 17, 'time_epoch': 4.40886, 'loss': 0.11729689, 'lr': 0, 'params': 451793, 'time_iter': 0.03418, 'accuracy': 0.96985, 'precision': 0.56522, 'recall': 0.2, 'f1': 0.29545, 'auc': 0.75591}
2025-07-04 20:49:58,098 - INFO - > Epoch 17: took 83.3s (avg 85.5s) | Best so far: epoch 17	train_loss: 0.1277 train_auc: 0.7930	val_loss: 0.0786 val_auc: 0.7798	test_loss: 0.1173 test_auc: 0.7559
2025-07-04 20:51:12,516 - INFO - train: {'epoch': 18, 'time_epoch': 74.19248, 'eta': 6163.6047, 'eta_hours': 1.71211, 'loss': 0.12635707, 'lr': 9.545e-05, 'params': 451793, 'time_iter': 0.0721, 'accuracy': 0.96438, 'precision': 0.60274, 'recall': 0.14286, 'f1': 0.23097, 'auc': 0.79682}
2025-07-04 20:51:17,011 - INFO - val: {'epoch': 18, 'time_epoch': 4.46139, 'loss': 0.07921197, 'lr': 0, 'params': 451793, 'time_iter': 0.03458, 'accuracy': 0.98079, 'precision': 0.54545, 'recall': 0.14815, 'f1': 0.23301, 'auc': 0.78158}
2025-07-04 20:51:21,525 - INFO - test: {'epoch': 18, 'time_epoch': 4.49009, 'loss': 0.11878173, 'lr': 0, 'params': 451793, 'time_iter': 0.03481, 'accuracy': 0.96742, 'precision': 0.4375, 'recall': 0.10769, 'f1': 0.17284, 'auc': 0.74946}
2025-07-04 20:51:21,528 - INFO - > Epoch 18: took 83.4s (avg 85.4s) | Best so far: epoch 18	train_loss: 0.1264 train_auc: 0.7968	val_loss: 0.0792 val_auc: 0.7816	test_loss: 0.1188 test_auc: 0.7495
2025-07-04 20:52:36,269 - INFO - train: {'epoch': 19, 'time_epoch': 74.56506, 'eta': 6081.39551, 'eta_hours': 1.68928, 'loss': 0.12516746, 'lr': 9.474e-05, 'params': 451793, 'time_iter': 0.07246, 'accuracy': 0.96459, 'precision': 0.60308, 'recall': 0.15909, 'f1': 0.25177, 'auc': 0.80476}
2025-07-04 20:52:40,787 - INFO - val: {'epoch': 19, 'time_epoch': 4.49165, 'loss': 0.08135763, 'lr': 0, 'params': 451793, 'time_iter': 0.03482, 'accuracy': 0.98177, 'precision': 0.58824, 'recall': 0.24691, 'f1': 0.34783, 'auc': 0.75513}
2025-07-04 20:52:45,285 - INFO - test: {'epoch': 19, 'time_epoch': 4.4763, 'loss': 0.11794155, 'lr': 0, 'params': 451793, 'time_iter': 0.0347, 'accuracy': 0.97155, 'precision': 0.62264, 'recall': 0.25385, 'f1': 0.36066, 'auc': 0.74493}
2025-07-04 20:52:45,287 - INFO - > Epoch 19: took 83.8s (avg 85.3s) | Best so far: epoch 18	train_loss: 0.1264 train_auc: 0.7968	val_loss: 0.0792 val_auc: 0.7816	test_loss: 0.1188 test_auc: 0.7495
2025-07-04 20:53:59,755 - INFO - train: {'epoch': 20, 'time_epoch': 74.25968, 'eta': 5998.76551, 'eta_hours': 1.66632, 'loss': 0.12509649, 'lr': 9.397e-05, 'params': 451793, 'time_iter': 0.07217, 'accuracy': 0.9648, 'precision': 0.61012, 'recall': 0.1664, 'f1': 0.26148, 'auc': 0.79963}
2025-07-04 20:54:04,282 - INFO - val: {'epoch': 20, 'time_epoch': 4.50065, 'loss': 0.07718547, 'lr': 0, 'params': 451793, 'time_iter': 0.03489, 'accuracy': 0.98104, 'precision': 0.56, 'recall': 0.17284, 'f1': 0.26415, 'auc': 0.7653}
2025-07-04 20:54:08,695 - INFO - test: {'epoch': 20, 'time_epoch': 4.39229, 'loss': 0.11584626, 'lr': 0, 'params': 451793, 'time_iter': 0.03405, 'accuracy': 0.97082, 'precision': 0.69231, 'recall': 0.13846, 'f1': 0.23077, 'auc': 0.75072}
2025-07-04 20:54:08,697 - INFO - > Epoch 20: took 83.4s (avg 85.2s) | Best so far: epoch 18	train_loss: 0.1264 train_auc: 0.7968	val_loss: 0.0792 val_auc: 0.7816	test_loss: 0.1188 test_auc: 0.7495
2025-07-04 20:55:22,968 - INFO - train: {'epoch': 21, 'time_epoch': 74.05651, 'eta': 5916.17613, 'eta_hours': 1.64338, 'loss': 0.12287045, 'lr': 9.316e-05, 'params': 451793, 'time_iter': 0.07197, 'accuracy': 0.96523, 'precision': 0.62571, 'recall': 0.17776, 'f1': 0.27686, 'auc': 0.8118}
2025-07-04 20:55:27,452 - INFO - val: {'epoch': 21, 'time_epoch': 4.45736, 'loss': 0.08008311, 'lr': 0, 'params': 451793, 'time_iter': 0.03455, 'accuracy': 0.98225, 'precision': 0.60526, 'recall': 0.28395, 'f1': 0.38655, 'auc': 0.76577}
2025-07-04 20:55:31,916 - INFO - test: {'epoch': 21, 'time_epoch': 4.43199, 'loss': 0.11857391, 'lr': 0, 'params': 451793, 'time_iter': 0.03436, 'accuracy': 0.96669, 'precision': 0.45977, 'recall': 0.30769, 'f1': 0.36866, 'auc': 0.76188}
2025-07-04 20:55:31,918 - INFO - > Epoch 21: took 83.2s (avg 85.1s) | Best so far: epoch 18	train_loss: 0.1264 train_auc: 0.7968	val_loss: 0.0792 val_auc: 0.7816	test_loss: 0.1188 test_auc: 0.7495
2025-07-04 20:56:46,164 - INFO - train: {'epoch': 22, 'time_epoch': 74.0534, 'eta': 5834.31833, 'eta_hours': 1.62064, 'loss': 0.12292489, 'lr': 9.23e-05, 'params': 451793, 'time_iter': 0.07197, 'accuracy': 0.96535, 'precision': 0.61979, 'recall': 0.19318, 'f1': 0.29455, 'auc': 0.81138}
2025-07-04 20:56:50,723 - INFO - val: {'epoch': 22, 'time_epoch': 4.53139, 'loss': 0.07480851, 'lr': 0, 'params': 451793, 'time_iter': 0.03513, 'accuracy': 0.98177, 'precision': 0.58333, 'recall': 0.25926, 'f1': 0.35897, 'auc': 0.80456}
2025-07-04 20:56:55,182 - INFO - test: {'epoch': 22, 'time_epoch': 4.43726, 'loss': 0.11568742, 'lr': 0, 'params': 451793, 'time_iter': 0.0344, 'accuracy': 0.96961, 'precision': 0.53333, 'recall': 0.30769, 'f1': 0.39024, 'auc': 0.76386}
2025-07-04 20:56:55,184 - INFO - > Epoch 22: took 83.3s (avg 85.1s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 20:58:14,884 - INFO - train: {'epoch': 23, 'time_epoch': 79.48643, 'eta': 5770.31549, 'eta_hours': 1.60287, 'loss': 0.1219435, 'lr': 9.14e-05, 'params': 451793, 'time_iter': 0.07725, 'accuracy': 0.96535, 'precision': 0.62169, 'recall': 0.19075, 'f1': 0.29193, 'auc': 0.80965}
2025-07-04 20:58:19,496 - INFO - val: {'epoch': 23, 'time_epoch': 4.58581, 'loss': 0.07548528, 'lr': 0, 'params': 451793, 'time_iter': 0.03555, 'accuracy': 0.98395, 'precision': 0.7027, 'recall': 0.32099, 'f1': 0.44068, 'auc': 0.78266}
2025-07-04 20:58:24,014 - INFO - test: {'epoch': 23, 'time_epoch': 4.49551, 'loss': 0.11448322, 'lr': 0, 'params': 451793, 'time_iter': 0.03485, 'accuracy': 0.97009, 'precision': 0.54795, 'recall': 0.30769, 'f1': 0.39409, 'auc': 0.75913}
2025-07-04 20:58:24,016 - INFO - > Epoch 23: took 88.8s (avg 85.2s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 20:59:38,947 - INFO - train: {'epoch': 24, 'time_epoch': 74.7286, 'eta': 5690.80047, 'eta_hours': 1.58078, 'loss': 0.1205319, 'lr': 9.045e-05, 'params': 451793, 'time_iter': 0.07262, 'accuracy': 0.96462, 'precision': 0.58673, 'recall': 0.18669, 'f1': 0.28325, 'auc': 0.8216}
2025-07-04 20:59:43,352 - INFO - val: {'epoch': 24, 'time_epoch': 4.37868, 'loss': 0.07470226, 'lr': 0, 'params': 451793, 'time_iter': 0.03394, 'accuracy': 0.98249, 'precision': 0.65517, 'recall': 0.23457, 'f1': 0.34545, 'auc': 0.78516}
2025-07-04 20:59:47,754 - INFO - test: {'epoch': 24, 'time_epoch': 4.3819, 'loss': 0.11731879, 'lr': 0, 'params': 451793, 'time_iter': 0.03397, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.11538, 'f1': 0.1875, 'auc': 0.7388}
2025-07-04 20:59:47,756 - INFO - > Epoch 24: took 83.7s (avg 85.2s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:01:01,798 - INFO - train: {'epoch': 25, 'time_epoch': 73.90737, 'eta': 5609.3163, 'eta_hours': 1.55814, 'loss': 0.11978337, 'lr': 8.946e-05, 'params': 451793, 'time_iter': 0.07182, 'accuracy': 0.96578, 'precision': 0.62383, 'recall': 0.21672, 'f1': 0.32169, 'auc': 0.82063}
2025-07-04 21:01:06,228 - INFO - val: {'epoch': 25, 'time_epoch': 4.40552, 'loss': 0.07333041, 'lr': 0, 'params': 451793, 'time_iter': 0.03415, 'accuracy': 0.98201, 'precision': 0.60606, 'recall': 0.24691, 'f1': 0.35088, 'auc': 0.78846}
2025-07-04 21:01:10,647 - INFO - test: {'epoch': 25, 'time_epoch': 4.39747, 'loss': 0.1160788, 'lr': 0, 'params': 451793, 'time_iter': 0.03409, 'accuracy': 0.96888, 'precision': 0.52083, 'recall': 0.19231, 'f1': 0.2809, 'auc': 0.74978}
2025-07-04 21:01:10,649 - INFO - > Epoch 25: took 82.9s (avg 85.1s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:02:24,910 - INFO - train: {'epoch': 26, 'time_epoch': 74.05743, 'eta': 5528.79908, 'eta_hours': 1.53578, 'loss': 0.11940192, 'lr': 8.842e-05, 'params': 451793, 'time_iter': 0.07197, 'accuracy': 0.96556, 'precision': 0.61174, 'recall': 0.21997, 'f1': 0.32358, 'auc': 0.82226}
2025-07-04 21:02:29,575 - INFO - val: {'epoch': 26, 'time_epoch': 4.6374, 'loss': 0.07669857, 'lr': 0, 'params': 451793, 'time_iter': 0.03595, 'accuracy': 0.98347, 'precision': 0.70968, 'recall': 0.2716, 'f1': 0.39286, 'auc': 0.74119}
2025-07-04 21:02:34,019 - INFO - test: {'epoch': 26, 'time_epoch': 4.42148, 'loss': 0.11514787, 'lr': 0, 'params': 451793, 'time_iter': 0.03428, 'accuracy': 0.96888, 'precision': 0.52778, 'recall': 0.14615, 'f1': 0.22892, 'auc': 0.74272}
2025-07-04 21:02:34,022 - INFO - > Epoch 26: took 83.4s (avg 85.0s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:03:48,284 - INFO - train: {'epoch': 27, 'time_epoch': 74.02168, 'eta': 5448.65136, 'eta_hours': 1.51351, 'loss': 0.12029638, 'lr': 8.734e-05, 'params': 451793, 'time_iter': 0.07194, 'accuracy': 0.96581, 'precision': 0.62954, 'recall': 0.21104, 'f1': 0.31611, 'auc': 0.81972}
2025-07-04 21:03:52,725 - INFO - val: {'epoch': 27, 'time_epoch': 4.41553, 'loss': 0.07510322, 'lr': 0, 'params': 451793, 'time_iter': 0.03423, 'accuracy': 0.98347, 'precision': 0.70968, 'recall': 0.2716, 'f1': 0.39286, 'auc': 0.76069}
2025-07-04 21:03:57,144 - INFO - test: {'epoch': 27, 'time_epoch': 4.39798, 'loss': 0.11742482, 'lr': 0, 'params': 451793, 'time_iter': 0.03409, 'accuracy': 0.96888, 'precision': 0.52778, 'recall': 0.14615, 'f1': 0.22892, 'auc': 0.76274}
2025-07-04 21:03:57,146 - INFO - > Epoch 27: took 83.1s (avg 84.9s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:05:11,268 - INFO - train: {'epoch': 28, 'time_epoch': 73.92605, 'eta': 5368.69198, 'eta_hours': 1.4913, 'loss': 0.11802428, 'lr': 8.622e-05, 'params': 451793, 'time_iter': 0.07184, 'accuracy': 0.96638, 'precision': 0.64253, 'recall': 0.23052, 'f1': 0.33931, 'auc': 0.82625}
2025-07-04 21:05:15,737 - INFO - val: {'epoch': 28, 'time_epoch': 4.44288, 'loss': 0.07704878, 'lr': 0, 'params': 451793, 'time_iter': 0.03444, 'accuracy': 0.98249, 'precision': 0.64516, 'recall': 0.24691, 'f1': 0.35714, 'auc': 0.73759}
2025-07-04 21:05:20,181 - INFO - test: {'epoch': 28, 'time_epoch': 4.42291, 'loss': 0.11805267, 'lr': 0, 'params': 451793, 'time_iter': 0.03429, 'accuracy': 0.96888, 'precision': 0.52632, 'recall': 0.15385, 'f1': 0.2381, 'auc': 0.7425}
2025-07-04 21:05:20,183 - INFO - > Epoch 28: took 83.0s (avg 84.9s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:06:34,944 - INFO - train: {'epoch': 29, 'time_epoch': 74.5785, 'eta': 5290.65722, 'eta_hours': 1.46963, 'loss': 0.11775183, 'lr': 8.506e-05, 'params': 451793, 'time_iter': 0.07248, 'accuracy': 0.96593, 'precision': 0.62642, 'recall': 0.22321, 'f1': 0.32914, 'auc': 0.82906}
2025-07-04 21:06:39,463 - INFO - val: {'epoch': 29, 'time_epoch': 4.4925, 'loss': 0.07218295, 'lr': 0, 'params': 451793, 'time_iter': 0.03483, 'accuracy': 0.98444, 'precision': 0.77419, 'recall': 0.2963, 'f1': 0.42857, 'auc': 0.78151}
2025-07-04 21:06:43,991 - INFO - test: {'epoch': 29, 'time_epoch': 4.50639, 'loss': 0.11464984, 'lr': 0, 'params': 451793, 'time_iter': 0.03493, 'accuracy': 0.96864, 'precision': 0.50943, 'recall': 0.20769, 'f1': 0.29508, 'auc': 0.74388}
2025-07-04 21:06:43,993 - INFO - > Epoch 29: took 83.8s (avg 84.8s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:07:58,341 - INFO - train: {'epoch': 30, 'time_epoch': 74.15117, 'eta': 5211.89427, 'eta_hours': 1.44775, 'loss': 0.11789277, 'lr': 8.386e-05, 'params': 451793, 'time_iter': 0.07206, 'accuracy': 0.9666, 'precision': 0.64811, 'recall': 0.2362, 'f1': 0.34622, 'auc': 0.83322}
2025-07-04 21:08:02,768 - INFO - val: {'epoch': 30, 'time_epoch': 4.40209, 'loss': 0.07395374, 'lr': 0, 'params': 451793, 'time_iter': 0.03412, 'accuracy': 0.98298, 'precision': 0.67742, 'recall': 0.25926, 'f1': 0.375, 'auc': 0.76746}
2025-07-04 21:08:07,193 - INFO - test: {'epoch': 30, 'time_epoch': 4.4047, 'loss': 0.1175457, 'lr': 0, 'params': 451793, 'time_iter': 0.03414, 'accuracy': 0.97058, 'precision': 0.58824, 'recall': 0.23077, 'f1': 0.33149, 'auc': 0.75307}
2025-07-04 21:08:07,196 - INFO - > Epoch 30: took 83.2s (avg 84.8s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:09:21,436 - INFO - train: {'epoch': 31, 'time_epoch': 74.0207, 'eta': 5133.14233, 'eta_hours': 1.42587, 'loss': 0.11665745, 'lr': 8.263e-05, 'params': 451793, 'time_iter': 0.07193, 'accuracy': 0.96572, 'precision': 0.6097, 'recall': 0.23458, 'f1': 0.3388, 'auc': 0.83925}
2025-07-04 21:09:25,874 - INFO - val: {'epoch': 31, 'time_epoch': 4.41138, 'loss': 0.07516303, 'lr': 0, 'params': 451793, 'time_iter': 0.0342, 'accuracy': 0.98152, 'precision': 0.55319, 'recall': 0.32099, 'f1': 0.40625, 'auc': 0.79243}
2025-07-04 21:09:30,318 - INFO - test: {'epoch': 31, 'time_epoch': 4.42323, 'loss': 0.11906349, 'lr': 0, 'params': 451793, 'time_iter': 0.03429, 'accuracy': 0.9662, 'precision': 0.44444, 'recall': 0.27692, 'f1': 0.34123, 'auc': 0.75105}
2025-07-04 21:09:30,320 - INFO - > Epoch 31: took 83.1s (avg 84.7s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:10:44,920 - INFO - train: {'epoch': 32, 'time_epoch': 74.40096, 'eta': 5055.44917, 'eta_hours': 1.40429, 'loss': 0.11579095, 'lr': 8.136e-05, 'params': 451793, 'time_iter': 0.0723, 'accuracy': 0.96672, 'precision': 0.65055, 'recall': 0.24026, 'f1': 0.35092, 'auc': 0.83062}
2025-07-04 21:10:49,395 - INFO - val: {'epoch': 32, 'time_epoch': 4.44814, 'loss': 0.07142628, 'lr': 0, 'params': 451793, 'time_iter': 0.03448, 'accuracy': 0.98371, 'precision': 0.73333, 'recall': 0.2716, 'f1': 0.3964, 'auc': 0.78744}
2025-07-04 21:10:53,855 - INFO - test: {'epoch': 32, 'time_epoch': 4.43808, 'loss': 0.11655501, 'lr': 0, 'params': 451793, 'time_iter': 0.0344, 'accuracy': 0.97034, 'precision': 0.58, 'recall': 0.22308, 'f1': 0.32222, 'auc': 0.73478}
2025-07-04 21:10:53,857 - INFO - > Epoch 32: took 83.5s (avg 84.7s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:12:08,437 - INFO - train: {'epoch': 33, 'time_epoch': 74.41174, 'eta': 4977.9706, 'eta_hours': 1.38277, 'loss': 0.11501064, 'lr': 8.005e-05, 'params': 451793, 'time_iter': 0.07231, 'accuracy': 0.96769, 'precision': 0.67715, 'recall': 0.26218, 'f1': 0.378, 'auc': 0.83815}
2025-07-04 21:12:12,850 - INFO - val: {'epoch': 33, 'time_epoch': 4.38747, 'loss': 0.07272136, 'lr': 0, 'params': 451793, 'time_iter': 0.03401, 'accuracy': 0.98322, 'precision': 0.8, 'recall': 0.19753, 'f1': 0.31683, 'auc': 0.78415}
2025-07-04 21:12:17,273 - INFO - test: {'epoch': 33, 'time_epoch': 4.40301, 'loss': 0.12075448, 'lr': 0, 'params': 451793, 'time_iter': 0.03413, 'accuracy': 0.96912, 'precision': 0.61538, 'recall': 0.06154, 'f1': 0.11189, 'auc': 0.74456}
2025-07-04 21:12:17,276 - INFO - > Epoch 33: took 83.4s (avg 84.7s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:13:32,277 - INFO - train: {'epoch': 34, 'time_epoch': 74.78696, 'eta': 4901.3641, 'eta_hours': 1.36149, 'loss': 0.11463595, 'lr': 7.872e-05, 'params': 451793, 'time_iter': 0.07268, 'accuracy': 0.96708, 'precision': 0.65553, 'recall': 0.25487, 'f1': 0.36704, 'auc': 0.83998}
2025-07-04 21:13:37,054 - INFO - val: {'epoch': 34, 'time_epoch': 4.74729, 'loss': 0.07105291, 'lr': 0, 'params': 451793, 'time_iter': 0.0368, 'accuracy': 0.98274, 'precision': 0.63158, 'recall': 0.2963, 'f1': 0.40336, 'auc': 0.79506}
2025-07-04 21:13:41,787 - INFO - test: {'epoch': 34, 'time_epoch': 4.71142, 'loss': 0.11649712, 'lr': 0, 'params': 451793, 'time_iter': 0.03652, 'accuracy': 0.97131, 'precision': 0.6, 'recall': 0.27692, 'f1': 0.37895, 'auc': 0.74767}
2025-07-04 21:13:41,789 - INFO - > Epoch 34: took 84.5s (avg 84.7s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:15:00,331 - INFO - train: {'epoch': 35, 'time_epoch': 78.31749, 'eta': 4831.13519, 'eta_hours': 1.34198, 'loss': 0.11438836, 'lr': 7.735e-05, 'params': 451793, 'time_iter': 0.07611, 'accuracy': 0.96708, 'precision': 0.64466, 'recall': 0.26948, 'f1': 0.38008, 'auc': 0.84036}
2025-07-04 21:15:05,082 - INFO - val: {'epoch': 35, 'time_epoch': 4.71978, 'loss': 0.07479055, 'lr': 0, 'params': 451793, 'time_iter': 0.03659, 'accuracy': 0.98347, 'precision': 0.69697, 'recall': 0.28395, 'f1': 0.40351, 'auc': 0.77578}
2025-07-04 21:15:09,875 - INFO - test: {'epoch': 35, 'time_epoch': 4.76808, 'loss': 0.11574181, 'lr': 0, 'params': 451793, 'time_iter': 0.03696, 'accuracy': 0.97131, 'precision': 0.61538, 'recall': 0.24615, 'f1': 0.35165, 'auc': 0.74574}
2025-07-04 21:15:09,878 - INFO - > Epoch 35: took 88.1s (avg 84.8s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:16:23,814 - INFO - train: {'epoch': 36, 'time_epoch': 73.68734, 'eta': 4752.58529, 'eta_hours': 1.32016, 'loss': 0.11328421, 'lr': 7.595e-05, 'params': 451793, 'time_iter': 0.07161, 'accuracy': 0.96705, 'precision': 0.64341, 'recall': 0.26948, 'f1': 0.37986, 'auc': 0.8418}
2025-07-04 21:16:28,232 - INFO - val: {'epoch': 36, 'time_epoch': 4.39239, 'loss': 0.07362265, 'lr': 0, 'params': 451793, 'time_iter': 0.03405, 'accuracy': 0.98347, 'precision': 0.69697, 'recall': 0.28395, 'f1': 0.40351, 'auc': 0.75909}
2025-07-04 21:16:32,647 - INFO - test: {'epoch': 36, 'time_epoch': 4.39396, 'loss': 0.12160937, 'lr': 0, 'params': 451793, 'time_iter': 0.03406, 'accuracy': 0.96791, 'precision': 0.46667, 'recall': 0.10769, 'f1': 0.175, 'auc': 0.741}
2025-07-04 21:16:32,649 - INFO - > Epoch 36: took 82.8s (avg 84.7s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:17:46,737 - INFO - train: {'epoch': 37, 'time_epoch': 73.87858, 'eta': 4674.60334, 'eta_hours': 1.2985, 'loss': 0.11289563, 'lr': 7.452e-05, 'params': 451793, 'time_iter': 0.0718, 'accuracy': 0.96736, 'precision': 0.64576, 'recall': 0.28409, 'f1': 0.39459, 'auc': 0.84345}
2025-07-04 21:17:51,185 - INFO - val: {'epoch': 37, 'time_epoch': 4.42258, 'loss': 0.07237949, 'lr': 0, 'params': 451793, 'time_iter': 0.03428, 'accuracy': 0.98225, 'precision': 0.59091, 'recall': 0.32099, 'f1': 0.416, 'auc': 0.79807}
2025-07-04 21:17:55,617 - INFO - test: {'epoch': 37, 'time_epoch': 4.41077, 'loss': 0.11613394, 'lr': 0, 'params': 451793, 'time_iter': 0.03419, 'accuracy': 0.97155, 'precision': 0.59155, 'recall': 0.32308, 'f1': 0.41791, 'auc': 0.74885}
2025-07-04 21:17:55,619 - INFO - > Epoch 37: took 83.0s (avg 84.7s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:19:10,010 - INFO - train: {'epoch': 38, 'time_epoch': 74.17865, 'eta': 4597.30116, 'eta_hours': 1.27703, 'loss': 0.111372, 'lr': 7.307e-05, 'params': 451793, 'time_iter': 0.07209, 'accuracy': 0.9679, 'precision': 0.66794, 'recall': 0.28409, 'f1': 0.39863, 'auc': 0.84638}
2025-07-04 21:19:14,458 - INFO - val: {'epoch': 38, 'time_epoch': 4.42186, 'loss': 0.07288474, 'lr': 0, 'params': 451793, 'time_iter': 0.03428, 'accuracy': 0.98274, 'precision': 0.65625, 'recall': 0.25926, 'f1': 0.37168, 'auc': 0.79435}
2025-07-04 21:19:18,917 - INFO - test: {'epoch': 38, 'time_epoch': 4.4376, 'loss': 0.11344728, 'lr': 0, 'params': 451793, 'time_iter': 0.0344, 'accuracy': 0.97204, 'precision': 0.64706, 'recall': 0.25385, 'f1': 0.36464, 'auc': 0.74493}
2025-07-04 21:19:18,920 - INFO - > Epoch 38: took 83.3s (avg 84.6s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:20:33,314 - INFO - train: {'epoch': 39, 'time_epoch': 74.17954, 'eta': 4520.15649, 'eta_hours': 1.2556, 'loss': 0.11125771, 'lr': 7.159e-05, 'params': 451793, 'time_iter': 0.07209, 'accuracy': 0.96778, 'precision': 0.66412, 'recall': 0.28247, 'f1': 0.39636, 'auc': 0.84314}
2025-07-04 21:20:37,787 - INFO - val: {'epoch': 39, 'time_epoch': 4.44787, 'loss': 0.07254671, 'lr': 0, 'params': 451793, 'time_iter': 0.03448, 'accuracy': 0.98249, 'precision': 0.61538, 'recall': 0.2963, 'f1': 0.4, 'auc': 0.78472}
2025-07-04 21:20:42,237 - INFO - test: {'epoch': 39, 'time_epoch': 4.4288, 'loss': 0.11659499, 'lr': 0, 'params': 451793, 'time_iter': 0.03433, 'accuracy': 0.96864, 'precision': 0.50602, 'recall': 0.32308, 'f1': 0.39437, 'auc': 0.74628}
2025-07-04 21:20:42,239 - INFO - > Epoch 39: took 83.3s (avg 84.6s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:21:57,323 - INFO - train: {'epoch': 40, 'time_epoch': 74.81082, 'eta': 4444.06489, 'eta_hours': 1.23446, 'loss': 0.11097051, 'lr': 7.008e-05, 'params': 451793, 'time_iter': 0.0727, 'accuracy': 0.96766, 'precision': 0.64947, 'recall': 0.29627, 'f1': 0.40691, 'auc': 0.85128}
2025-07-04 21:22:01,927 - INFO - val: {'epoch': 40, 'time_epoch': 4.57726, 'loss': 0.07483288, 'lr': 0, 'params': 451793, 'time_iter': 0.03548, 'accuracy': 0.98298, 'precision': 0.63415, 'recall': 0.32099, 'f1': 0.42623, 'auc': 0.75879}
2025-07-04 21:22:06,413 - INFO - test: {'epoch': 40, 'time_epoch': 4.46322, 'loss': 0.11699476, 'lr': 0, 'params': 451793, 'time_iter': 0.0346, 'accuracy': 0.97107, 'precision': 0.58462, 'recall': 0.29231, 'f1': 0.38974, 'auc': 0.73546}
2025-07-04 21:22:06,415 - INFO - > Epoch 40: took 84.2s (avg 84.6s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:23:21,136 - INFO - train: {'epoch': 41, 'time_epoch': 74.49068, 'eta': 4367.59218, 'eta_hours': 1.21322, 'loss': 0.11016718, 'lr': 6.856e-05, 'params': 451793, 'time_iter': 0.07239, 'accuracy': 0.969, 'precision': 0.70076, 'recall': 0.30032, 'f1': 0.42045, 'auc': 0.85019}
2025-07-04 21:23:25,590 - INFO - val: {'epoch': 41, 'time_epoch': 4.4256, 'loss': 0.07209089, 'lr': 0, 'params': 451793, 'time_iter': 0.03431, 'accuracy': 0.98371, 'precision': 0.71875, 'recall': 0.28395, 'f1': 0.40708, 'auc': 0.77392}
2025-07-04 21:23:30,014 - INFO - test: {'epoch': 41, 'time_epoch': 4.40057, 'loss': 0.11957154, 'lr': 0, 'params': 451793, 'time_iter': 0.03411, 'accuracy': 0.96961, 'precision': 0.6087, 'recall': 0.10769, 'f1': 0.18301, 'auc': 0.74082}
2025-07-04 21:23:30,016 - INFO - > Epoch 41: took 83.6s (avg 84.6s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:24:44,365 - INFO - train: {'epoch': 42, 'time_epoch': 74.1291, 'eta': 4290.73235, 'eta_hours': 1.19187, 'loss': 0.10866165, 'lr': 6.701e-05, 'params': 451793, 'time_iter': 0.07204, 'accuracy': 0.96854, 'precision': 0.6855, 'recall': 0.29545, 'f1': 0.41293, 'auc': 0.85635}
2025-07-04 21:24:48,819 - INFO - val: {'epoch': 42, 'time_epoch': 4.42854, 'loss': 0.07412026, 'lr': 0, 'params': 451793, 'time_iter': 0.03433, 'accuracy': 0.98322, 'precision': 0.65789, 'recall': 0.30864, 'f1': 0.42017, 'auc': 0.78691}
2025-07-04 21:24:53,287 - INFO - test: {'epoch': 42, 'time_epoch': 4.43292, 'loss': 0.11674192, 'lr': 0, 'params': 451793, 'time_iter': 0.03436, 'accuracy': 0.96985, 'precision': 0.54054, 'recall': 0.30769, 'f1': 0.39216, 'auc': 0.76492}
2025-07-04 21:24:53,311 - INFO - > Epoch 42: took 83.3s (avg 84.5s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:26:07,526 - INFO - train: {'epoch': 43, 'time_epoch': 73.98026, 'eta': 4213.80722, 'eta_hours': 1.1705, 'loss': 0.11024033, 'lr': 6.545e-05, 'params': 451793, 'time_iter': 0.0719, 'accuracy': 0.96793, 'precision': 0.65775, 'recall': 0.29951, 'f1': 0.4116, 'auc': 0.85381}
2025-07-04 21:26:12,004 - INFO - val: {'epoch': 43, 'time_epoch': 4.4524, 'loss': 0.07303001, 'lr': 0, 'params': 451793, 'time_iter': 0.03451, 'accuracy': 0.98274, 'precision': 0.63889, 'recall': 0.28395, 'f1': 0.39316, 'auc': 0.7731}
2025-07-04 21:26:16,515 - INFO - test: {'epoch': 43, 'time_epoch': 4.48943, 'loss': 0.11709674, 'lr': 0, 'params': 451793, 'time_iter': 0.0348, 'accuracy': 0.97107, 'precision': 0.60784, 'recall': 0.23846, 'f1': 0.34254, 'auc': 0.73841}
2025-07-04 21:26:16,517 - INFO - > Epoch 43: took 83.2s (avg 84.5s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:27:31,395 - INFO - train: {'epoch': 44, 'time_epoch': 74.65571, 'eta': 4137.83851, 'eta_hours': 1.1494, 'loss': 0.10940201, 'lr': 6.387e-05, 'params': 451793, 'time_iter': 0.07255, 'accuracy': 0.96818, 'precision': 0.6729, 'recall': 0.29221, 'f1': 0.40747, 'auc': 0.85225}
2025-07-04 21:27:35,825 - INFO - val: {'epoch': 44, 'time_epoch': 4.40357, 'loss': 0.07584476, 'lr': 0, 'params': 451793, 'time_iter': 0.03414, 'accuracy': 0.98104, 'precision': 0.52941, 'recall': 0.33333, 'f1': 0.40909, 'auc': 0.79857}
2025-07-04 21:27:40,250 - INFO - test: {'epoch': 44, 'time_epoch': 4.40453, 'loss': 0.12163453, 'lr': 0, 'params': 451793, 'time_iter': 0.03414, 'accuracy': 0.96645, 'precision': 0.46154, 'recall': 0.36923, 'f1': 0.41026, 'auc': 0.75444}
2025-07-04 21:27:40,253 - INFO - > Epoch 44: took 83.7s (avg 84.5s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:28:54,555 - INFO - train: {'epoch': 45, 'time_epoch': 74.12728, 'eta': 4061.30656, 'eta_hours': 1.12814, 'loss': 0.10880804, 'lr': 6.227e-05, 'params': 451793, 'time_iter': 0.07204, 'accuracy': 0.96812, 'precision': 0.66486, 'recall': 0.29951, 'f1': 0.41298, 'auc': 0.86146}
2025-07-04 21:28:59,018 - INFO - val: {'epoch': 45, 'time_epoch': 4.43667, 'loss': 0.07540519, 'lr': 0, 'params': 451793, 'time_iter': 0.03439, 'accuracy': 0.98249, 'precision': 0.62857, 'recall': 0.2716, 'f1': 0.37931, 'auc': 0.74497}
2025-07-04 21:29:03,481 - INFO - test: {'epoch': 45, 'time_epoch': 4.44214, 'loss': 0.11518694, 'lr': 0, 'params': 451793, 'time_iter': 0.03444, 'accuracy': 0.97009, 'precision': 0.55932, 'recall': 0.25385, 'f1': 0.34921, 'auc': 0.73958}
2025-07-04 21:29:03,483 - INFO - > Epoch 45: took 83.2s (avg 84.4s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:30:18,150 - INFO - train: {'epoch': 46, 'time_epoch': 74.45653, 'eta': 3985.24822, 'eta_hours': 1.10701, 'loss': 0.10794109, 'lr': 6.066e-05, 'params': 451793, 'time_iter': 0.07236, 'accuracy': 0.96891, 'precision': 0.68761, 'recall': 0.31088, 'f1': 0.42817, 'auc': 0.85679}
2025-07-04 21:30:22,634 - INFO - val: {'epoch': 46, 'time_epoch': 4.45781, 'loss': 0.07207405, 'lr': 0, 'params': 451793, 'time_iter': 0.03456, 'accuracy': 0.98371, 'precision': 0.71875, 'recall': 0.28395, 'f1': 0.40708, 'auc': 0.78584}
2025-07-04 21:30:27,100 - INFO - test: {'epoch': 46, 'time_epoch': 4.4451, 'loss': 0.11631857, 'lr': 0, 'params': 451793, 'time_iter': 0.03446, 'accuracy': 0.97058, 'precision': 0.57895, 'recall': 0.25385, 'f1': 0.35294, 'auc': 0.74146}
2025-07-04 21:30:27,102 - INFO - > Epoch 46: took 83.6s (avg 84.4s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:31:55,835 - INFO - train: {'epoch': 47, 'time_epoch': 88.4877, 'eta': 3924.45706, 'eta_hours': 1.09013, 'loss': 0.10846183, 'lr': 5.904e-05, 'params': 451793, 'time_iter': 0.08599, 'accuracy': 0.96851, 'precision': 0.66955, 'recall': 0.31412, 'f1': 0.42762, 'auc': 0.85657}
2025-07-04 21:32:00,618 - INFO - val: {'epoch': 47, 'time_epoch': 4.75426, 'loss': 0.07465236, 'lr': 0, 'params': 451793, 'time_iter': 0.03685, 'accuracy': 0.98249, 'precision': 0.6, 'recall': 0.33333, 'f1': 0.42857, 'auc': 0.78824}
2025-07-04 21:32:05,230 - INFO - test: {'epoch': 47, 'time_epoch': 4.59037, 'loss': 0.11768792, 'lr': 0, 'params': 451793, 'time_iter': 0.03558, 'accuracy': 0.96985, 'precision': 0.54545, 'recall': 0.27692, 'f1': 0.36735, 'auc': 0.74146}
2025-07-04 21:32:05,232 - INFO - > Epoch 47: took 98.1s (avg 84.7s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:33:22,836 - INFO - train: {'epoch': 48, 'time_epoch': 77.37428, 'eta': 3850.9684, 'eta_hours': 1.06971, 'loss': 0.10740903, 'lr': 5.741e-05, 'params': 451793, 'time_iter': 0.07519, 'accuracy': 0.96906, 'precision': 0.69176, 'recall': 0.31331, 'f1': 0.43128, 'auc': 0.86226}
2025-07-04 21:33:27,327 - INFO - val: {'epoch': 48, 'time_epoch': 4.46452, 'loss': 0.07241818, 'lr': 0, 'params': 451793, 'time_iter': 0.03461, 'accuracy': 0.98298, 'precision': 0.63415, 'recall': 0.32099, 'f1': 0.42623, 'auc': 0.79551}
2025-07-04 21:33:31,827 - INFO - test: {'epoch': 48, 'time_epoch': 4.47951, 'loss': 0.11818317, 'lr': 0, 'params': 451793, 'time_iter': 0.03472, 'accuracy': 0.96985, 'precision': 0.55172, 'recall': 0.24615, 'f1': 0.34043, 'auc': 0.73901}
2025-07-04 21:33:31,830 - INFO - > Epoch 48: took 86.6s (avg 84.8s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:34:48,053 - INFO - train: {'epoch': 49, 'time_epoch': 76.01528, 'eta': 3775.96531, 'eta_hours': 1.04888, 'loss': 0.10779452, 'lr': 5.577e-05, 'params': 451793, 'time_iter': 0.07387, 'accuracy': 0.96936, 'precision': 0.7029, 'recall': 0.31494, 'f1': 0.43498, 'auc': 0.86061}
2025-07-04 21:34:52,529 - INFO - val: {'epoch': 49, 'time_epoch': 4.44718, 'loss': 0.07262035, 'lr': 0, 'params': 451793, 'time_iter': 0.03447, 'accuracy': 0.98395, 'precision': 0.7027, 'recall': 0.32099, 'f1': 0.44068, 'auc': 0.77419}
2025-07-04 21:34:57,026 - INFO - test: {'epoch': 49, 'time_epoch': 4.47422, 'loss': 0.11852141, 'lr': 0, 'params': 451793, 'time_iter': 0.03468, 'accuracy': 0.96937, 'precision': 0.54762, 'recall': 0.17692, 'f1': 0.26744, 'auc': 0.73479}
2025-07-04 21:34:57,029 - INFO - > Epoch 49: took 85.2s (avg 84.8s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:36:13,942 - INFO - train: {'epoch': 50, 'time_epoch': 76.68123, 'eta': 3701.56236, 'eta_hours': 1.02821, 'loss': 0.10547234, 'lr': 5.413e-05, 'params': 451793, 'time_iter': 0.07452, 'accuracy': 0.96909, 'precision': 0.68313, 'recall': 0.32549, 'f1': 0.4409, 'auc': 0.87081}
2025-07-04 21:36:18,436 - INFO - val: {'epoch': 50, 'time_epoch': 4.46683, 'loss': 0.07115496, 'lr': 0, 'params': 451793, 'time_iter': 0.03463, 'accuracy': 0.98395, 'precision': 0.69231, 'recall': 0.33333, 'f1': 0.45, 'auc': 0.79159}
2025-07-04 21:36:22,947 - INFO - test: {'epoch': 50, 'time_epoch': 4.48821, 'loss': 0.11628109, 'lr': 0, 'params': 451793, 'time_iter': 0.03479, 'accuracy': 0.97131, 'precision': 0.61538, 'recall': 0.24615, 'f1': 0.35165, 'auc': 0.73647}
2025-07-04 21:36:22,949 - INFO - > Epoch 50: took 85.9s (avg 84.8s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:37:40,571 - INFO - train: {'epoch': 51, 'time_epoch': 77.40419, 'eta': 3627.73914, 'eta_hours': 1.00771, 'loss': 0.1062425, 'lr': 5.248e-05, 'params': 451793, 'time_iter': 0.07522, 'accuracy': 0.96924, 'precision': 0.69164, 'recall': 0.32224, 'f1': 0.43965, 'auc': 0.86632}
2025-07-04 21:37:45,120 - INFO - val: {'epoch': 51, 'time_epoch': 4.52272, 'loss': 0.07542273, 'lr': 0, 'params': 451793, 'time_iter': 0.03506, 'accuracy': 0.98177, 'precision': 0.56522, 'recall': 0.32099, 'f1': 0.40945, 'auc': 0.79082}
2025-07-04 21:37:49,701 - INFO - test: {'epoch': 51, 'time_epoch': 4.55901, 'loss': 0.11736447, 'lr': 0, 'params': 451793, 'time_iter': 0.03534, 'accuracy': 0.97082, 'precision': 0.6, 'recall': 0.23077, 'f1': 0.33333, 'auc': 0.75394}
2025-07-04 21:37:49,703 - INFO - > Epoch 51: took 86.8s (avg 84.8s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:39:06,484 - INFO - train: {'epoch': 52, 'time_epoch': 76.5612, 'eta': 3553.03323, 'eta_hours': 0.98695, 'loss': 0.1062048, 'lr': 5.083e-05, 'params': 451793, 'time_iter': 0.0744, 'accuracy': 0.96994, 'precision': 0.7084, 'recall': 0.33523, 'f1': 0.4551, 'auc': 0.86648}
2025-07-04 21:39:11,155 - INFO - val: {'epoch': 52, 'time_epoch': 4.64277, 'loss': 0.0736116, 'lr': 0, 'params': 451793, 'time_iter': 0.03599, 'accuracy': 0.98395, 'precision': 0.71429, 'recall': 0.30864, 'f1': 0.43103, 'auc': 0.78683}
2025-07-04 21:39:15,745 - INFO - test: {'epoch': 52, 'time_epoch': 4.56825, 'loss': 0.11692995, 'lr': 0, 'params': 451793, 'time_iter': 0.03541, 'accuracy': 0.97058, 'precision': 0.58491, 'recall': 0.23846, 'f1': 0.3388, 'auc': 0.74316}
2025-07-04 21:39:15,747 - INFO - > Epoch 52: took 86.0s (avg 84.8s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:40:32,748 - INFO - train: {'epoch': 53, 'time_epoch': 76.80357, 'eta': 3478.46507, 'eta_hours': 0.96624, 'loss': 0.10491497, 'lr': 4.917e-05, 'params': 451793, 'time_iter': 0.07464, 'accuracy': 0.96945, 'precision': 0.70524, 'recall': 0.31656, 'f1': 0.43697, 'auc': 0.87099}
2025-07-04 21:40:37,248 - INFO - val: {'epoch': 53, 'time_epoch': 4.47479, 'loss': 0.07112515, 'lr': 0, 'params': 451793, 'time_iter': 0.03469, 'accuracy': 0.98298, 'precision': 0.61702, 'recall': 0.35802, 'f1': 0.45312, 'auc': 0.79648}
2025-07-04 21:40:41,714 - INFO - test: {'epoch': 53, 'time_epoch': 4.44465, 'loss': 0.11714873, 'lr': 0, 'params': 451793, 'time_iter': 0.03445, 'accuracy': 0.9718, 'precision': 0.60938, 'recall': 0.3, 'f1': 0.40206, 'auc': 0.75095}
2025-07-04 21:40:41,716 - INFO - > Epoch 53: took 86.0s (avg 84.9s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:41:58,285 - INFO - train: {'epoch': 54, 'time_epoch': 76.37894, 'eta': 3403.46819, 'eta_hours': 0.94541, 'loss': 0.10474104, 'lr': 4.752e-05, 'params': 451793, 'time_iter': 0.07423, 'accuracy': 0.96958, 'precision': 0.68659, 'recall': 0.34497, 'f1': 0.45921, 'auc': 0.8713}
2025-07-04 21:42:02,821 - INFO - val: {'epoch': 54, 'time_epoch': 4.5057, 'loss': 0.07053754, 'lr': 0, 'params': 451793, 'time_iter': 0.03493, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.80289}
2025-07-04 21:42:07,353 - INFO - test: {'epoch': 54, 'time_epoch': 4.50874, 'loss': 0.11554348, 'lr': 0, 'params': 451793, 'time_iter': 0.03495, 'accuracy': 0.97107, 'precision': 0.61224, 'recall': 0.23077, 'f1': 0.3352, 'auc': 0.75182}
2025-07-04 21:42:07,355 - INFO - > Epoch 54: took 85.6s (avg 84.9s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:43:23,869 - INFO - train: {'epoch': 55, 'time_epoch': 76.29459, 'eta': 3328.35568, 'eta_hours': 0.92454, 'loss': 0.10571486, 'lr': 4.587e-05, 'params': 451793, 'time_iter': 0.07414, 'accuracy': 0.96939, 'precision': 0.69565, 'recall': 0.32468, 'f1': 0.44272, 'auc': 0.86511}
2025-07-04 21:43:28,430 - INFO - val: {'epoch': 55, 'time_epoch': 4.53445, 'loss': 0.07160185, 'lr': 0, 'params': 451793, 'time_iter': 0.03515, 'accuracy': 0.98371, 'precision': 0.71875, 'recall': 0.28395, 'f1': 0.40708, 'auc': 0.80421}
2025-07-04 21:43:33,040 - INFO - test: {'epoch': 55, 'time_epoch': 4.58894, 'loss': 0.11863294, 'lr': 0, 'params': 451793, 'time_iter': 0.03557, 'accuracy': 0.97009, 'precision': 0.56364, 'recall': 0.23846, 'f1': 0.33514, 'auc': 0.75551}
2025-07-04 21:43:33,043 - INFO - > Epoch 55: took 85.7s (avg 84.9s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:44:49,800 - INFO - train: {'epoch': 56, 'time_epoch': 76.55488, 'eta': 3253.39806, 'eta_hours': 0.90372, 'loss': 0.10429249, 'lr': 4.423e-05, 'params': 451793, 'time_iter': 0.0744, 'accuracy': 0.97015, 'precision': 0.70903, 'recall': 0.34416, 'f1': 0.46339, 'auc': 0.8681}
2025-07-04 21:44:54,294 - INFO - val: {'epoch': 56, 'time_epoch': 4.46603, 'loss': 0.07419978, 'lr': 0, 'params': 451793, 'time_iter': 0.03462, 'accuracy': 0.98274, 'precision': 0.63158, 'recall': 0.2963, 'f1': 0.40336, 'auc': 0.77823}
2025-07-04 21:44:58,878 - INFO - test: {'epoch': 56, 'time_epoch': 4.52714, 'loss': 0.11874386, 'lr': 0, 'params': 451793, 'time_iter': 0.03509, 'accuracy': 0.96961, 'precision': 0.54902, 'recall': 0.21538, 'f1': 0.30939, 'auc': 0.74019}
2025-07-04 21:44:58,881 - INFO - > Epoch 56: took 85.8s (avg 84.9s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:46:15,892 - INFO - train: {'epoch': 57, 'time_epoch': 76.79726, 'eta': 3178.56087, 'eta_hours': 0.88293, 'loss': 0.10403719, 'lr': 4.259e-05, 'params': 451793, 'time_iter': 0.07463, 'accuracy': 0.97003, 'precision': 0.70707, 'recall': 0.34091, 'f1': 0.46002, 'auc': 0.87084}
2025-07-04 21:46:20,438 - INFO - val: {'epoch': 57, 'time_epoch': 4.5196, 'loss': 0.07098852, 'lr': 0, 'params': 451793, 'time_iter': 0.03504, 'accuracy': 0.98371, 'precision': 0.71875, 'recall': 0.28395, 'f1': 0.40708, 'auc': 0.80236}
2025-07-04 21:46:24,966 - INFO - test: {'epoch': 57, 'time_epoch': 4.50565, 'loss': 0.11696836, 'lr': 0, 'params': 451793, 'time_iter': 0.03493, 'accuracy': 0.97155, 'precision': 0.65116, 'recall': 0.21538, 'f1': 0.3237, 'auc': 0.74807}
2025-07-04 21:46:24,969 - INFO - > Epoch 57: took 86.1s (avg 84.9s) | Best so far: epoch 22	train_loss: 0.1229 train_auc: 0.8114	val_loss: 0.0748 val_auc: 0.8046	test_loss: 0.1157 test_auc: 0.7639
2025-07-04 21:47:41,607 - INFO - train: {'epoch': 58, 'time_epoch': 76.4126, 'eta': 3103.38993, 'eta_hours': 0.86205, 'loss': 0.10302933, 'lr': 4.096e-05, 'params': 451793, 'time_iter': 0.07426, 'accuracy': 0.9697, 'precision': 0.69357, 'recall': 0.34172, 'f1': 0.45786, 'auc': 0.87795}
2025-07-04 21:47:46,263 - INFO - val: {'epoch': 58, 'time_epoch': 4.62974, 'loss': 0.07049584, 'lr': 0, 'params': 451793, 'time_iter': 0.03589, 'accuracy': 0.98274, 'precision': 0.6087, 'recall': 0.34568, 'f1': 0.44094, 'auc': 0.80833}
2025-07-04 21:47:50,786 - INFO - test: {'epoch': 58, 'time_epoch': 4.50127, 'loss': 0.11935027, 'lr': 0, 'params': 451793, 'time_iter': 0.03489, 'accuracy': 0.97082, 'precision': 0.57353, 'recall': 0.3, 'f1': 0.39394, 'auc': 0.7441}
2025-07-04 21:47:50,788 - INFO - > Epoch 58: took 85.8s (avg 84.9s) | Best so far: epoch 58	train_loss: 0.1030 train_auc: 0.8780	val_loss: 0.0705 val_auc: 0.8083	test_loss: 0.1194 test_auc: 0.7441
2025-07-04 21:49:17,519 - INFO - train: {'epoch': 59, 'time_epoch': 86.52118, 'eta': 3034.91665, 'eta_hours': 0.84303, 'loss': 0.10361819, 'lr': 3.934e-05, 'params': 451793, 'time_iter': 0.08408, 'accuracy': 0.97064, 'precision': 0.71732, 'recall': 0.35633, 'f1': 0.47614, 'auc': 0.87365}
2025-07-04 21:49:22,386 - INFO - val: {'epoch': 59, 'time_epoch': 4.83927, 'loss': 0.07294865, 'lr': 0, 'params': 451793, 'time_iter': 0.03751, 'accuracy': 0.98371, 'precision': 0.81818, 'recall': 0.22222, 'f1': 0.34951, 'auc': 0.77019}
2025-07-04 21:49:26,869 - INFO - test: {'epoch': 59, 'time_epoch': 4.46231, 'loss': 0.12059997, 'lr': 0, 'params': 451793, 'time_iter': 0.03459, 'accuracy': 0.96912, 'precision': 0.56, 'recall': 0.10769, 'f1': 0.18065, 'auc': 0.73703}
2025-07-04 21:49:26,871 - INFO - > Epoch 59: took 96.1s (avg 85.1s) | Best so far: epoch 58	train_loss: 0.1030 train_auc: 0.8780	val_loss: 0.0705 val_auc: 0.8083	test_loss: 0.1194 test_auc: 0.7441
2025-07-04 21:50:44,417 - INFO - train: {'epoch': 60, 'time_epoch': 77.36133, 'eta': 2959.99534, 'eta_hours': 0.82222, 'loss': 0.10270136, 'lr': 3.773e-05, 'params': 451793, 'time_iter': 0.07518, 'accuracy': 0.97006, 'precision': 0.70016, 'recall': 0.35065, 'f1': 0.46728, 'auc': 0.87629}
2025-07-04 21:50:48,892 - INFO - val: {'epoch': 60, 'time_epoch': 4.44873, 'loss': 0.07187806, 'lr': 0, 'params': 451793, 'time_iter': 0.03449, 'accuracy': 0.98274, 'precision': 0.625, 'recall': 0.30864, 'f1': 0.41322, 'auc': 0.79562}
2025-07-04 21:50:53,354 - INFO - test: {'epoch': 60, 'time_epoch': 4.44179, 'loss': 0.11671119, 'lr': 0, 'params': 451793, 'time_iter': 0.03443, 'accuracy': 0.97107, 'precision': 0.59649, 'recall': 0.26154, 'f1': 0.36364, 'auc': 0.74689}
2025-07-04 21:50:53,357 - INFO - > Epoch 60: took 86.5s (avg 85.2s) | Best so far: epoch 58	train_loss: 0.1030 train_auc: 0.8780	val_loss: 0.0705 val_auc: 0.8083	test_loss: 0.1194 test_auc: 0.7441
2025-07-04 21:52:10,134 - INFO - train: {'epoch': 61, 'time_epoch': 76.57305, 'eta': 2884.51219, 'eta_hours': 0.80125, 'loss': 0.10202249, 'lr': 3.613e-05, 'params': 451793, 'time_iter': 0.07442, 'accuracy': 0.97058, 'precision': 0.71019, 'recall': 0.36201, 'f1': 0.47957, 'auc': 0.87832}
2025-07-04 21:52:14,642 - INFO - val: {'epoch': 61, 'time_epoch': 4.47224, 'loss': 0.07138842, 'lr': 0, 'params': 451793, 'time_iter': 0.03467, 'accuracy': 0.98298, 'precision': 0.62222, 'recall': 0.34568, 'f1': 0.44444, 'auc': 0.7973}
2025-07-04 21:52:19,098 - INFO - test: {'epoch': 61, 'time_epoch': 4.43514, 'loss': 0.12339638, 'lr': 0, 'params': 451793, 'time_iter': 0.03438, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.33077, 'f1': 0.39815, 'auc': 0.74351}
2025-07-04 21:52:19,120 - INFO - > Epoch 61: took 85.8s (avg 85.2s) | Best so far: epoch 58	train_loss: 0.1030 train_auc: 0.8780	val_loss: 0.0705 val_auc: 0.8083	test_loss: 0.1194 test_auc: 0.7441
2025-07-04 21:53:35,297 - INFO - train: {'epoch': 62, 'time_epoch': 75.9573, 'eta': 2808.6328, 'eta_hours': 0.78018, 'loss': 0.10233732, 'lr': 3.455e-05, 'params': 451793, 'time_iter': 0.07382, 'accuracy': 0.97027, 'precision': 0.70752, 'recall': 0.35146, 'f1': 0.46963, 'auc': 0.87901}
2025-07-04 21:53:39,939 - INFO - val: {'epoch': 62, 'time_epoch': 4.61558, 'loss': 0.07101327, 'lr': 0, 'params': 451793, 'time_iter': 0.03578, 'accuracy': 0.98322, 'precision': 0.63636, 'recall': 0.34568, 'f1': 0.448, 'auc': 0.79866}
2025-07-04 21:53:44,432 - INFO - test: {'epoch': 62, 'time_epoch': 4.45754, 'loss': 0.11813262, 'lr': 0, 'params': 451793, 'time_iter': 0.03455, 'accuracy': 0.96985, 'precision': 0.55556, 'recall': 0.23077, 'f1': 0.32609, 'auc': 0.74445}
2025-07-04 21:53:44,434 - INFO - > Epoch 62: took 85.3s (avg 85.2s) | Best so far: epoch 58	train_loss: 0.1030 train_auc: 0.8780	val_loss: 0.0705 val_auc: 0.8083	test_loss: 0.1194 test_auc: 0.7441
2025-07-04 21:55:05,785 - INFO - train: {'epoch': 63, 'time_epoch': 81.12568, 'eta': 2735.65819, 'eta_hours': 0.75991, 'loss': 0.10226854, 'lr': 3.299e-05, 'params': 451793, 'time_iter': 0.07884, 'accuracy': 0.97037, 'precision': 0.70894, 'recall': 0.3539, 'f1': 0.47212, 'auc': 0.88366}
2025-07-04 21:55:10,924 - INFO - val: {'epoch': 63, 'time_epoch': 5.10586, 'loss': 0.07263091, 'lr': 0, 'params': 451793, 'time_iter': 0.03958, 'accuracy': 0.98395, 'precision': 0.71429, 'recall': 0.30864, 'f1': 0.43103, 'auc': 0.78471}
2025-07-04 21:55:15,757 - INFO - test: {'epoch': 63, 'time_epoch': 4.80965, 'loss': 0.11827659, 'lr': 0, 'params': 451793, 'time_iter': 0.03728, 'accuracy': 0.97082, 'precision': 0.6, 'recall': 0.23077, 'f1': 0.33333, 'auc': 0.74653}
2025-07-04 21:55:15,759 - INFO - > Epoch 63: took 91.3s (avg 85.3s) | Best so far: epoch 58	train_loss: 0.1030 train_auc: 0.8780	val_loss: 0.0705 val_auc: 0.8083	test_loss: 0.1194 test_auc: 0.7441
2025-07-04 21:56:37,902 - INFO - train: {'epoch': 64, 'time_epoch': 81.93323, 'eta': 2662.86762, 'eta_hours': 0.73969, 'loss': 0.10230348, 'lr': 3.144e-05, 'params': 451793, 'time_iter': 0.07962, 'accuracy': 0.97043, 'precision': 0.70989, 'recall': 0.35552, 'f1': 0.47377, 'auc': 0.8766}
2025-07-04 21:56:42,376 - INFO - val: {'epoch': 64, 'time_epoch': 4.4482, 'loss': 0.07144185, 'lr': 0, 'params': 451793, 'time_iter': 0.03448, 'accuracy': 0.9842, 'precision': 0.73529, 'recall': 0.30864, 'f1': 0.43478, 'auc': 0.79271}
2025-07-04 21:56:47,118 - INFO - test: {'epoch': 64, 'time_epoch': 4.71867, 'loss': 0.12006053, 'lr': 0, 'params': 451793, 'time_iter': 0.03658, 'accuracy': 0.97009, 'precision': 0.5814, 'recall': 0.19231, 'f1': 0.28902, 'auc': 0.74786}
2025-07-04 21:56:47,121 - INFO - > Epoch 64: took 91.4s (avg 85.4s) | Best so far: epoch 58	train_loss: 0.1030 train_auc: 0.8780	val_loss: 0.0705 val_auc: 0.8083	test_loss: 0.1194 test_auc: 0.7441
2025-07-04 21:58:06,158 - INFO - train: {'epoch': 65, 'time_epoch': 78.84131, 'eta': 2588.20718, 'eta_hours': 0.71895, 'loss': 0.10100231, 'lr': 2.992e-05, 'params': 451793, 'time_iter': 0.07662, 'accuracy': 0.9711, 'precision': 0.7292, 'recall': 0.36282, 'f1': 0.48455, 'auc': 0.88357}
2025-07-04 21:58:10,932 - INFO - val: {'epoch': 65, 'time_epoch': 4.74789, 'loss': 0.07092822, 'lr': 0, 'params': 451793, 'time_iter': 0.03681, 'accuracy': 0.98371, 'precision': 0.675, 'recall': 0.33333, 'f1': 0.44628, 'auc': 0.79289}
2025-07-04 21:58:15,402 - INFO - test: {'epoch': 65, 'time_epoch': 4.4483, 'loss': 0.11656624, 'lr': 0, 'params': 451793, 'time_iter': 0.03448, 'accuracy': 0.9718, 'precision': 0.625, 'recall': 0.26923, 'f1': 0.37634, 'auc': 0.74813}
2025-07-04 21:58:15,404 - INFO - > Epoch 65: took 88.3s (avg 85.4s) | Best so far: epoch 58	train_loss: 0.1030 train_auc: 0.8780	val_loss: 0.0705 val_auc: 0.8083	test_loss: 0.1194 test_auc: 0.7441
2025-07-04 21:59:31,856 - INFO - train: {'epoch': 66, 'time_epoch': 76.25845, 'eta': 2512.14979, 'eta_hours': 0.69782, 'loss': 0.10139153, 'lr': 2.841e-05, 'params': 451793, 'time_iter': 0.07411, 'accuracy': 0.97082, 'precision': 0.72078, 'recall': 0.36039, 'f1': 0.48052, 'auc': 0.8844}
2025-07-04 21:59:36,342 - INFO - val: {'epoch': 66, 'time_epoch': 4.46052, 'loss': 0.0713605, 'lr': 0, 'params': 451793, 'time_iter': 0.03458, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.79884}
2025-07-04 21:59:40,833 - INFO - test: {'epoch': 66, 'time_epoch': 4.47073, 'loss': 0.11989339, 'lr': 0, 'params': 451793, 'time_iter': 0.03466, 'accuracy': 0.97034, 'precision': 0.57692, 'recall': 0.23077, 'f1': 0.32967, 'auc': 0.74893}
2025-07-04 21:59:40,836 - INFO - > Epoch 66: took 85.4s (avg 85.4s) | Best so far: epoch 58	train_loss: 0.1030 train_auc: 0.8780	val_loss: 0.0705 val_auc: 0.8083	test_loss: 0.1194 test_auc: 0.7441
2025-07-04 22:00:57,007 - INFO - train: {'epoch': 67, 'time_epoch': 75.95094, 'eta': 2435.94177, 'eta_hours': 0.67665, 'loss': 0.10111267, 'lr': 2.693e-05, 'params': 451793, 'time_iter': 0.07381, 'accuracy': 0.97131, 'precision': 0.73684, 'recall': 0.36364, 'f1': 0.48696, 'auc': 0.88046}
2025-07-04 22:01:01,507 - INFO - val: {'epoch': 67, 'time_epoch': 4.47417, 'loss': 0.07026982, 'lr': 0, 'params': 451793, 'time_iter': 0.03468, 'accuracy': 0.98444, 'precision': 0.75758, 'recall': 0.30864, 'f1': 0.4386, 'auc': 0.7975}
2025-07-04 22:01:06,001 - INFO - test: {'epoch': 67, 'time_epoch': 4.47258, 'loss': 0.11581071, 'lr': 0, 'params': 451793, 'time_iter': 0.03467, 'accuracy': 0.97253, 'precision': 0.66667, 'recall': 0.26154, 'f1': 0.37569, 'auc': 0.74123}
2025-07-04 22:01:06,003 - INFO - > Epoch 67: took 85.2s (avg 85.4s) | Best so far: epoch 58	train_loss: 0.1030 train_auc: 0.8780	val_loss: 0.0705 val_auc: 0.8083	test_loss: 0.1194 test_auc: 0.7441
2025-07-04 22:02:23,066 - INFO - train: {'epoch': 68, 'time_epoch': 76.83625, 'eta': 2360.13896, 'eta_hours': 0.65559, 'loss': 0.1011551, 'lr': 2.548e-05, 'params': 451793, 'time_iter': 0.07467, 'accuracy': 0.97097, 'precision': 0.73435, 'recall': 0.35227, 'f1': 0.47614, 'auc': 0.88682}
2025-07-04 22:02:27,851 - INFO - val: {'epoch': 68, 'time_epoch': 4.75426, 'loss': 0.07054323, 'lr': 0, 'params': 451793, 'time_iter': 0.03685, 'accuracy': 0.98395, 'precision': 0.7027, 'recall': 0.32099, 'f1': 0.44068, 'auc': 0.79784}
2025-07-04 22:02:32,373 - INFO - test: {'epoch': 68, 'time_epoch': 4.49706, 'loss': 0.11639038, 'lr': 0, 'params': 451793, 'time_iter': 0.03486, 'accuracy': 0.97277, 'precision': 0.6875, 'recall': 0.25385, 'f1': 0.37079, 'auc': 0.75075}
2025-07-04 22:02:32,375 - INFO - > Epoch 68: took 86.4s (avg 85.4s) | Best so far: epoch 58	train_loss: 0.1030 train_auc: 0.8780	val_loss: 0.0705 val_auc: 0.8083	test_loss: 0.1194 test_auc: 0.7441
2025-07-04 22:03:50,422 - INFO - train: {'epoch': 69, 'time_epoch': 77.83464, 'eta': 2284.7345, 'eta_hours': 0.63465, 'loss': 0.09930243, 'lr': 2.405e-05, 'params': 451793, 'time_iter': 0.07564, 'accuracy': 0.97149, 'precision': 0.73041, 'recall': 0.37825, 'f1': 0.4984, 'auc': 0.88764}
2025-07-04 22:03:55,059 - INFO - val: {'epoch': 69, 'time_epoch': 4.60771, 'loss': 0.07065869, 'lr': 0, 'params': 451793, 'time_iter': 0.03572, 'accuracy': 0.98395, 'precision': 0.7027, 'recall': 0.32099, 'f1': 0.44068, 'auc': 0.79532}
2025-07-04 22:03:59,653 - INFO - test: {'epoch': 69, 'time_epoch': 4.57198, 'loss': 0.11810921, 'lr': 0, 'params': 451793, 'time_iter': 0.03544, 'accuracy': 0.97107, 'precision': 0.62222, 'recall': 0.21538, 'f1': 0.32, 'auc': 0.75522}
2025-07-04 22:03:59,655 - INFO - > Epoch 69: took 87.3s (avg 85.4s) | Best so far: epoch 58	train_loss: 0.1030 train_auc: 0.8780	val_loss: 0.0705 val_auc: 0.8083	test_loss: 0.1194 test_auc: 0.7441
2025-07-04 22:05:18,259 - INFO - train: {'epoch': 70, 'time_epoch': 78.36873, 'eta': 2209.47973, 'eta_hours': 0.61374, 'loss': 0.09997116, 'lr': 2.265e-05, 'params': 451793, 'time_iter': 0.07616, 'accuracy': 0.97128, 'precision': 0.72248, 'recall': 0.37825, 'f1': 0.49654, 'auc': 0.88679}
2025-07-04 22:05:22,865 - INFO - val: {'epoch': 70, 'time_epoch': 4.57951, 'loss': 0.07223845, 'lr': 0, 'params': 451793, 'time_iter': 0.0355, 'accuracy': 0.98371, 'precision': 0.675, 'recall': 0.33333, 'f1': 0.44628, 'auc': 0.78633}
2025-07-04 22:05:27,566 - INFO - test: {'epoch': 70, 'time_epoch': 4.679, 'loss': 0.11923681, 'lr': 0, 'params': 451793, 'time_iter': 0.03627, 'accuracy': 0.97058, 'precision': 0.59184, 'recall': 0.22308, 'f1': 0.32402, 'auc': 0.75112}
2025-07-04 22:05:27,568 - INFO - > Epoch 70: took 87.9s (avg 85.5s) | Best so far: epoch 58	train_loss: 0.1030 train_auc: 0.8780	val_loss: 0.0705 val_auc: 0.8083	test_loss: 0.1194 test_auc: 0.7441
2025-07-04 22:06:46,896 - INFO - train: {'epoch': 71, 'time_epoch': 79.10426, 'eta': 2134.42451, 'eta_hours': 0.5929, 'loss': 0.09866216, 'lr': 2.128e-05, 'params': 451793, 'time_iter': 0.07687, 'accuracy': 0.97152, 'precision': 0.72939, 'recall': 0.38068, 'f1': 0.50027, 'auc': 0.88737}
2025-07-04 22:06:51,617 - INFO - val: {'epoch': 71, 'time_epoch': 4.69521, 'loss': 0.06911468, 'lr': 0, 'params': 451793, 'time_iter': 0.0364, 'accuracy': 0.98371, 'precision': 0.675, 'recall': 0.33333, 'f1': 0.44628, 'auc': 0.81153}
2025-07-04 22:06:56,238 - INFO - test: {'epoch': 71, 'time_epoch': 4.59845, 'loss': 0.11661866, 'lr': 0, 'params': 451793, 'time_iter': 0.03565, 'accuracy': 0.97204, 'precision': 0.62712, 'recall': 0.28462, 'f1': 0.39153, 'auc': 0.7568}
2025-07-04 22:06:56,242 - INFO - > Epoch 71: took 88.7s (avg 85.5s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:08:14,779 - INFO - train: {'epoch': 72, 'time_epoch': 78.33683, 'eta': 2058.97451, 'eta_hours': 0.57194, 'loss': 0.09987019, 'lr': 1.995e-05, 'params': 451793, 'time_iter': 0.07613, 'accuracy': 0.97091, 'precision': 0.72358, 'recall': 0.3612, 'f1': 0.48186, 'auc': 0.88653}
2025-07-04 22:08:19,398 - INFO - val: {'epoch': 72, 'time_epoch': 4.59243, 'loss': 0.07073641, 'lr': 0, 'params': 451793, 'time_iter': 0.0356, 'accuracy': 0.98371, 'precision': 0.70588, 'recall': 0.2963, 'f1': 0.41739, 'auc': 0.79834}
2025-07-04 22:08:23,999 - INFO - test: {'epoch': 72, 'time_epoch': 4.5773, 'loss': 0.11767808, 'lr': 0, 'params': 451793, 'time_iter': 0.03548, 'accuracy': 0.97107, 'precision': 0.64103, 'recall': 0.19231, 'f1': 0.29586, 'auc': 0.74591}
2025-07-04 22:08:24,001 - INFO - > Epoch 72: took 87.8s (avg 85.5s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:09:42,694 - INFO - train: {'epoch': 73, 'time_epoch': 78.47742, 'eta': 1983.49588, 'eta_hours': 0.55097, 'loss': 0.09887897, 'lr': 1.864e-05, 'params': 451793, 'time_iter': 0.07627, 'accuracy': 0.97094, 'precision': 0.7233, 'recall': 0.36282, 'f1': 0.48324, 'auc': 0.88917}
2025-07-04 22:09:47,356 - INFO - val: {'epoch': 73, 'time_epoch': 4.63525, 'loss': 0.07019955, 'lr': 0, 'params': 451793, 'time_iter': 0.03593, 'accuracy': 0.9842, 'precision': 0.73529, 'recall': 0.30864, 'f1': 0.43478, 'auc': 0.80006}
2025-07-04 22:09:51,988 - INFO - test: {'epoch': 73, 'time_epoch': 4.61018, 'loss': 0.11825552, 'lr': 0, 'params': 451793, 'time_iter': 0.03574, 'accuracy': 0.97228, 'precision': 0.65385, 'recall': 0.26154, 'f1': 0.37363, 'auc': 0.74969}
2025-07-04 22:09:51,990 - INFO - > Epoch 73: took 88.0s (avg 85.6s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:11:10,885 - INFO - train: {'epoch': 74, 'time_epoch': 78.67855, 'eta': 1908.00432, 'eta_hours': 0.53, 'loss': 0.09868238, 'lr': 1.737e-05, 'params': 451793, 'time_iter': 0.07646, 'accuracy': 0.97167, 'precision': 0.73077, 'recall': 0.38555, 'f1': 0.50478, 'auc': 0.89015}
2025-07-04 22:11:15,581 - INFO - val: {'epoch': 74, 'time_epoch': 4.66882, 'loss': 0.07051938, 'lr': 0, 'params': 451793, 'time_iter': 0.03619, 'accuracy': 0.98371, 'precision': 0.68421, 'recall': 0.32099, 'f1': 0.43697, 'auc': 0.79728}
2025-07-04 22:11:20,232 - INFO - test: {'epoch': 74, 'time_epoch': 4.62988, 'loss': 0.11723386, 'lr': 0, 'params': 451793, 'time_iter': 0.03589, 'accuracy': 0.9718, 'precision': 0.625, 'recall': 0.26923, 'f1': 0.37634, 'auc': 0.74452}
2025-07-04 22:11:20,234 - INFO - > Epoch 74: took 88.2s (avg 85.6s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:12:38,861 - INFO - train: {'epoch': 75, 'time_epoch': 78.41976, 'eta': 1832.34718, 'eta_hours': 0.50899, 'loss': 0.09910526, 'lr': 1.614e-05, 'params': 451793, 'time_iter': 0.07621, 'accuracy': 0.97173, 'precision': 0.73742, 'recall': 0.38068, 'f1': 0.50214, 'auc': 0.88206}
2025-07-04 22:12:43,462 - INFO - val: {'epoch': 75, 'time_epoch': 4.57155, 'loss': 0.0693321, 'lr': 0, 'params': 451793, 'time_iter': 0.03544, 'accuracy': 0.98395, 'precision': 0.69231, 'recall': 0.33333, 'f1': 0.45, 'auc': 0.80579}
2025-07-04 22:12:48,047 - INFO - test: {'epoch': 75, 'time_epoch': 4.56407, 'loss': 0.11658167, 'lr': 0, 'params': 451793, 'time_iter': 0.03538, 'accuracy': 0.97155, 'precision': 0.60656, 'recall': 0.28462, 'f1': 0.38743, 'auc': 0.74976}
2025-07-04 22:12:48,050 - INFO - > Epoch 75: took 87.8s (avg 85.6s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:14:06,516 - INFO - train: {'epoch': 76, 'time_epoch': 78.26826, 'eta': 1756.57302, 'eta_hours': 0.48794, 'loss': 0.09913125, 'lr': 1.494e-05, 'params': 451793, 'time_iter': 0.07606, 'accuracy': 0.97085, 'precision': 0.71097, 'recall': 0.37338, 'f1': 0.48962, 'auc': 0.89105}
2025-07-04 22:14:11,174 - INFO - val: {'epoch': 76, 'time_epoch': 4.63107, 'loss': 0.0702258, 'lr': 0, 'params': 451793, 'time_iter': 0.0359, 'accuracy': 0.98347, 'precision': 0.67568, 'recall': 0.30864, 'f1': 0.42373, 'auc': 0.7992}
2025-07-04 22:14:15,838 - INFO - test: {'epoch': 76, 'time_epoch': 4.63801, 'loss': 0.11735171, 'lr': 0, 'params': 451793, 'time_iter': 0.03595, 'accuracy': 0.9718, 'precision': 0.63462, 'recall': 0.25385, 'f1': 0.36264, 'auc': 0.74602}
2025-07-04 22:14:15,841 - INFO - > Epoch 76: took 87.8s (avg 85.7s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:15:34,728 - INFO - train: {'epoch': 77, 'time_epoch': 78.68556, 'eta': 1680.85262, 'eta_hours': 0.4669, 'loss': 0.09834076, 'lr': 1.378e-05, 'params': 451793, 'time_iter': 0.07647, 'accuracy': 0.97158, 'precision': 0.73312, 'recall': 0.37906, 'f1': 0.49973, 'auc': 0.88504}
2025-07-04 22:15:39,320 - INFO - val: {'epoch': 77, 'time_epoch': 4.56516, 'loss': 0.07268173, 'lr': 0, 'params': 451793, 'time_iter': 0.03539, 'accuracy': 0.98347, 'precision': 0.68571, 'recall': 0.2963, 'f1': 0.41379, 'auc': 0.79368}
2025-07-04 22:15:43,888 - INFO - test: {'epoch': 77, 'time_epoch': 4.5453, 'loss': 0.12239143, 'lr': 0, 'params': 451793, 'time_iter': 0.03523, 'accuracy': 0.97155, 'precision': 0.65854, 'recall': 0.20769, 'f1': 0.31579, 'auc': 0.75001}
2025-07-04 22:15:43,891 - INFO - > Epoch 77: took 88.0s (avg 85.7s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:17:02,412 - INFO - train: {'epoch': 78, 'time_epoch': 78.28576, 'eta': 1604.95087, 'eta_hours': 0.44582, 'loss': 0.09727593, 'lr': 1.266e-05, 'params': 451793, 'time_iter': 0.07608, 'accuracy': 0.97195, 'precision': 0.73733, 'recall': 0.38961, 'f1': 0.50982, 'auc': 0.89184}
2025-07-04 22:17:07,077 - INFO - val: {'epoch': 78, 'time_epoch': 4.63856, 'loss': 0.07209428, 'lr': 0, 'params': 451793, 'time_iter': 0.03596, 'accuracy': 0.98395, 'precision': 0.7027, 'recall': 0.32099, 'f1': 0.44068, 'auc': 0.791}
2025-07-04 22:17:11,721 - INFO - test: {'epoch': 78, 'time_epoch': 4.62148, 'loss': 0.11799177, 'lr': 0, 'params': 451793, 'time_iter': 0.03583, 'accuracy': 0.9718, 'precision': 0.62963, 'recall': 0.26154, 'f1': 0.36957, 'auc': 0.74899}
2025-07-04 22:17:11,723 - INFO - > Epoch 78: took 87.8s (avg 85.7s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:18:30,068 - INFO - train: {'epoch': 79, 'time_epoch': 78.13023, 'eta': 1528.95063, 'eta_hours': 0.42471, 'loss': 0.09796856, 'lr': 1.158e-05, 'params': 451793, 'time_iter': 0.07593, 'accuracy': 0.97201, 'precision': 0.75285, 'recall': 0.37581, 'f1': 0.50135, 'auc': 0.89208}
2025-07-04 22:18:34,686 - INFO - val: {'epoch': 79, 'time_epoch': 4.59023, 'loss': 0.07194027, 'lr': 0, 'params': 451793, 'time_iter': 0.03558, 'accuracy': 0.98347, 'precision': 0.68571, 'recall': 0.2963, 'f1': 0.41379, 'auc': 0.79729}
2025-07-04 22:18:39,283 - INFO - test: {'epoch': 79, 'time_epoch': 4.57611, 'loss': 0.12070236, 'lr': 0, 'params': 451793, 'time_iter': 0.03547, 'accuracy': 0.97107, 'precision': 0.66667, 'recall': 0.16923, 'f1': 0.26994, 'auc': 0.74826}
2025-07-04 22:18:39,286 - INFO - > Epoch 79: took 87.6s (avg 85.8s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:19:57,668 - INFO - train: {'epoch': 80, 'time_epoch': 78.2218, 'eta': 1452.91929, 'eta_hours': 0.40359, 'loss': 0.09848969, 'lr': 1.054e-05, 'params': 451793, 'time_iter': 0.07602, 'accuracy': 0.97113, 'precision': 0.72816, 'recall': 0.36526, 'f1': 0.48649, 'auc': 0.89354}
2025-07-04 22:20:02,267 - INFO - val: {'epoch': 80, 'time_epoch': 4.57242, 'loss': 0.07161457, 'lr': 0, 'params': 451793, 'time_iter': 0.03545, 'accuracy': 0.98371, 'precision': 0.70588, 'recall': 0.2963, 'f1': 0.41739, 'auc': 0.80537}
2025-07-04 22:20:06,953 - INFO - test: {'epoch': 80, 'time_epoch': 4.66394, 'loss': 0.11975905, 'lr': 0, 'params': 451793, 'time_iter': 0.03615, 'accuracy': 0.97204, 'precision': 0.66667, 'recall': 0.23077, 'f1': 0.34286, 'auc': 0.75486}
2025-07-04 22:20:06,955 - INFO - > Epoch 80: took 87.7s (avg 85.8s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:21:25,908 - INFO - train: {'epoch': 81, 'time_epoch': 78.69242, 'eta': 1376.93782, 'eta_hours': 0.38248, 'loss': 0.09827477, 'lr': 9.55e-06, 'params': 451793, 'time_iter': 0.07647, 'accuracy': 0.97146, 'precision': 0.72163, 'recall': 0.38718, 'f1': 0.50396, 'auc': 0.89124}
2025-07-04 22:21:30,526 - INFO - val: {'epoch': 81, 'time_epoch': 4.59063, 'loss': 0.070847, 'lr': 0, 'params': 451793, 'time_iter': 0.03559, 'accuracy': 0.98347, 'precision': 0.67568, 'recall': 0.30864, 'f1': 0.42373, 'auc': 0.80462}
2025-07-04 22:21:35,105 - INFO - test: {'epoch': 81, 'time_epoch': 4.55714, 'loss': 0.11739126, 'lr': 0, 'params': 451793, 'time_iter': 0.03533, 'accuracy': 0.97107, 'precision': 0.60377, 'recall': 0.24615, 'f1': 0.34973, 'auc': 0.75987}
2025-07-04 22:21:35,111 - INFO - > Epoch 81: took 88.2s (avg 85.8s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:22:54,263 - INFO - train: {'epoch': 82, 'time_epoch': 78.92022, 'eta': 1300.93769, 'eta_hours': 0.36137, 'loss': 0.09744743, 'lr': 8.6e-06, 'params': 451793, 'time_iter': 0.0767, 'accuracy': 0.97189, 'precision': 0.73652, 'recall': 0.38799, 'f1': 0.50824, 'auc': 0.89674}
2025-07-04 22:22:58,951 - INFO - val: {'epoch': 82, 'time_epoch': 4.65971, 'loss': 0.07182945, 'lr': 0, 'params': 451793, 'time_iter': 0.03612, 'accuracy': 0.98322, 'precision': 0.64286, 'recall': 0.33333, 'f1': 0.43902, 'auc': 0.80042}
2025-07-04 22:23:03,580 - INFO - test: {'epoch': 82, 'time_epoch': 4.60656, 'loss': 0.11794679, 'lr': 0, 'params': 451793, 'time_iter': 0.03571, 'accuracy': 0.9718, 'precision': 0.625, 'recall': 0.26923, 'f1': 0.37634, 'auc': 0.75397}
2025-07-04 22:23:03,588 - INFO - > Epoch 82: took 88.5s (avg 85.8s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:24:21,938 - INFO - train: {'epoch': 83, 'time_epoch': 78.12103, 'eta': 1224.71581, 'eta_hours': 0.3402, 'loss': 0.09747544, 'lr': 7.7e-06, 'params': 451793, 'time_iter': 0.07592, 'accuracy': 0.97116, 'precision': 0.72354, 'recall': 0.37175, 'f1': 0.49115, 'auc': 0.89286}
2025-07-04 22:24:26,656 - INFO - val: {'epoch': 83, 'time_epoch': 4.69012, 'loss': 0.07176906, 'lr': 0, 'params': 451793, 'time_iter': 0.03636, 'accuracy': 0.9842, 'precision': 0.71053, 'recall': 0.33333, 'f1': 0.45378, 'auc': 0.79364}
2025-07-04 22:24:31,343 - INFO - test: {'epoch': 83, 'time_epoch': 4.65046, 'loss': 0.11724279, 'lr': 0, 'params': 451793, 'time_iter': 0.03605, 'accuracy': 0.97107, 'precision': 0.6, 'recall': 0.25385, 'f1': 0.35676, 'auc': 0.75834}
2025-07-04 22:24:31,354 - INFO - > Epoch 83: took 87.8s (avg 85.9s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:25:50,527 - INFO - train: {'epoch': 84, 'time_epoch': 78.97005, 'eta': 1148.59907, 'eta_hours': 0.31906, 'loss': 0.09681788, 'lr': 6.84e-06, 'params': 451793, 'time_iter': 0.07674, 'accuracy': 0.97207, 'precision': 0.73966, 'recall': 0.39205, 'f1': 0.51247, 'auc': 0.89499}
2025-07-04 22:25:55,319 - INFO - val: {'epoch': 84, 'time_epoch': 4.76372, 'loss': 0.07135381, 'lr': 0, 'params': 451793, 'time_iter': 0.03693, 'accuracy': 0.98444, 'precision': 0.71795, 'recall': 0.34568, 'f1': 0.46667, 'auc': 0.79751}
2025-07-04 22:25:59,947 - INFO - test: {'epoch': 84, 'time_epoch': 4.60602, 'loss': 0.11803826, 'lr': 0, 'params': 451793, 'time_iter': 0.03571, 'accuracy': 0.97107, 'precision': 0.59016, 'recall': 0.27692, 'f1': 0.37696, 'auc': 0.76066}
2025-07-04 22:25:59,950 - INFO - > Epoch 84: took 88.6s (avg 85.9s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:27:17,839 - INFO - train: {'epoch': 85, 'time_epoch': 77.66004, 'eta': 1072.20271, 'eta_hours': 0.29783, 'loss': 0.0966358, 'lr': 6.03e-06, 'params': 451793, 'time_iter': 0.07547, 'accuracy': 0.97192, 'precision': 0.74444, 'recall': 0.38068, 'f1': 0.50376, 'auc': 0.89884}
2025-07-04 22:27:22,310 - INFO - val: {'epoch': 85, 'time_epoch': 4.44574, 'loss': 0.0718025, 'lr': 0, 'params': 451793, 'time_iter': 0.03446, 'accuracy': 0.9842, 'precision': 0.71053, 'recall': 0.33333, 'f1': 0.45378, 'auc': 0.79199}
2025-07-04 22:27:26,789 - INFO - test: {'epoch': 85, 'time_epoch': 4.45686, 'loss': 0.11741462, 'lr': 0, 'params': 451793, 'time_iter': 0.03455, 'accuracy': 0.9718, 'precision': 0.63462, 'recall': 0.25385, 'f1': 0.36264, 'auc': 0.75332}
2025-07-04 22:27:26,794 - INFO - > Epoch 85: took 86.8s (avg 85.9s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:28:43,254 - INFO - train: {'epoch': 86, 'time_epoch': 76.23814, 'eta': 995.56484, 'eta_hours': 0.27655, 'loss': 0.09684619, 'lr': 5.26e-06, 'params': 451793, 'time_iter': 0.07409, 'accuracy': 0.9724, 'precision': 0.76471, 'recall': 0.37987, 'f1': 0.50759, 'auc': 0.89279}
2025-07-04 22:28:47,792 - INFO - val: {'epoch': 86, 'time_epoch': 4.50647, 'loss': 0.07106764, 'lr': 0, 'params': 451793, 'time_iter': 0.03493, 'accuracy': 0.98395, 'precision': 0.7027, 'recall': 0.32099, 'f1': 0.44068, 'auc': 0.79915}
2025-07-04 22:28:52,293 - INFO - test: {'epoch': 86, 'time_epoch': 4.47943, 'loss': 0.11884636, 'lr': 0, 'params': 451793, 'time_iter': 0.03472, 'accuracy': 0.97058, 'precision': 0.58491, 'recall': 0.23846, 'f1': 0.3388, 'auc': 0.75589}
2025-07-04 22:28:52,295 - INFO - > Epoch 86: took 85.5s (avg 85.9s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:30:08,450 - INFO - train: {'epoch': 87, 'time_epoch': 75.92015, 'eta': 918.89269, 'eta_hours': 0.25525, 'loss': 0.09729036, 'lr': 4.55e-06, 'params': 451793, 'time_iter': 0.07378, 'accuracy': 0.97161, 'precision': 0.72576, 'recall': 0.3888, 'f1': 0.50634, 'auc': 0.89606}
2025-07-04 22:30:12,941 - INFO - val: {'epoch': 87, 'time_epoch': 4.46405, 'loss': 0.07148979, 'lr': 0, 'params': 451793, 'time_iter': 0.03461, 'accuracy': 0.9842, 'precision': 0.75, 'recall': 0.2963, 'f1': 0.42478, 'auc': 0.79058}
2025-07-04 22:30:17,416 - INFO - test: {'epoch': 87, 'time_epoch': 4.45429, 'loss': 0.11953301, 'lr': 0, 'params': 451793, 'time_iter': 0.03453, 'accuracy': 0.97131, 'precision': 0.66667, 'recall': 0.18462, 'f1': 0.28916, 'auc': 0.75696}
2025-07-04 22:30:17,418 - INFO - > Epoch 87: took 85.1s (avg 85.9s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:31:33,601 - INFO - train: {'epoch': 88, 'time_epoch': 75.94912, 'eta': 842.24102, 'eta_hours': 0.23396, 'loss': 0.09713544, 'lr': 3.89e-06, 'params': 451793, 'time_iter': 0.07381, 'accuracy': 0.97216, 'precision': 0.74687, 'recall': 0.38799, 'f1': 0.51068, 'auc': 0.8968}
2025-07-04 22:31:38,096 - INFO - val: {'epoch': 88, 'time_epoch': 4.46024, 'loss': 0.07160866, 'lr': 0, 'params': 451793, 'time_iter': 0.03458, 'accuracy': 0.98347, 'precision': 0.67568, 'recall': 0.30864, 'f1': 0.42373, 'auc': 0.79639}
2025-07-04 22:31:42,575 - INFO - test: {'epoch': 88, 'time_epoch': 4.45766, 'loss': 0.11962407, 'lr': 0, 'params': 451793, 'time_iter': 0.03456, 'accuracy': 0.9718, 'precision': 0.675, 'recall': 0.20769, 'f1': 0.31765, 'auc': 0.75286}
2025-07-04 22:31:42,577 - INFO - > Epoch 88: took 85.2s (avg 85.9s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:32:59,002 - INFO - train: {'epoch': 89, 'time_epoch': 76.23829, 'eta': 765.63709, 'eta_hours': 0.21268, 'loss': 0.09638855, 'lr': 3.27e-06, 'params': 451793, 'time_iter': 0.07409, 'accuracy': 0.97228, 'precision': 0.75397, 'recall': 0.38555, 'f1': 0.5102, 'auc': 0.89679}
2025-07-04 22:33:03,594 - INFO - val: {'epoch': 89, 'time_epoch': 4.56488, 'loss': 0.07172775, 'lr': 0, 'params': 451793, 'time_iter': 0.03539, 'accuracy': 0.98322, 'precision': 0.64286, 'recall': 0.33333, 'f1': 0.43902, 'auc': 0.79742}
2025-07-04 22:33:08,108 - INFO - test: {'epoch': 89, 'time_epoch': 4.49041, 'loss': 0.11788269, 'lr': 0, 'params': 451793, 'time_iter': 0.03481, 'accuracy': 0.97058, 'precision': 0.57627, 'recall': 0.26154, 'f1': 0.35979, 'auc': 0.75539}
2025-07-04 22:33:08,111 - INFO - > Epoch 89: took 85.5s (avg 85.9s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:34:26,047 - INFO - train: {'epoch': 90, 'time_epoch': 77.72058, 'eta': 689.18779, 'eta_hours': 0.19144, 'loss': 0.09643996, 'lr': 2.71e-06, 'params': 451793, 'time_iter': 0.07553, 'accuracy': 0.97185, 'precision': 0.73042, 'recall': 0.39367, 'f1': 0.5116, 'auc': 0.8978}
2025-07-04 22:34:30,746 - INFO - val: {'epoch': 90, 'time_epoch': 4.67008, 'loss': 0.07220255, 'lr': 0, 'params': 451793, 'time_iter': 0.0362, 'accuracy': 0.98347, 'precision': 0.65854, 'recall': 0.33333, 'f1': 0.44262, 'auc': 0.7957}
2025-07-04 22:34:35,429 - INFO - test: {'epoch': 90, 'time_epoch': 4.66185, 'loss': 0.11950821, 'lr': 0, 'params': 451793, 'time_iter': 0.03614, 'accuracy': 0.97009, 'precision': 0.55932, 'recall': 0.25385, 'f1': 0.34921, 'auc': 0.75466}
2025-07-04 22:34:35,432 - INFO - > Epoch 90: took 87.3s (avg 85.9s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:35:54,877 - INFO - train: {'epoch': 91, 'time_epoch': 79.23177, 'eta': 612.84227, 'eta_hours': 0.17023, 'loss': 0.09656465, 'lr': 2.2e-06, 'params': 451793, 'time_iter': 0.077, 'accuracy': 0.97225, 'precision': 0.74057, 'recall': 0.39854, 'f1': 0.51821, 'auc': 0.89513}
2025-07-04 22:35:59,629 - INFO - val: {'epoch': 91, 'time_epoch': 4.72496, 'loss': 0.07093233, 'lr': 0, 'params': 451793, 'time_iter': 0.03663, 'accuracy': 0.98371, 'precision': 0.68421, 'recall': 0.32099, 'f1': 0.43697, 'auc': 0.80236}
2025-07-04 22:36:04,393 - INFO - test: {'epoch': 91, 'time_epoch': 4.74133, 'loss': 0.11792375, 'lr': 0, 'params': 451793, 'time_iter': 0.03675, 'accuracy': 0.97082, 'precision': 0.59615, 'recall': 0.23846, 'f1': 0.34066, 'auc': 0.7561}
2025-07-04 22:36:04,399 - INFO - > Epoch 91: took 89.0s (avg 85.9s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:37:24,668 - INFO - train: {'epoch': 92, 'time_epoch': 80.07217, 'eta': 536.49794, 'eta_hours': 0.14903, 'loss': 0.09637485, 'lr': 1.74e-06, 'params': 451793, 'time_iter': 0.07782, 'accuracy': 0.97274, 'precision': 0.76295, 'recall': 0.39448, 'f1': 0.52006, 'auc': 0.89463}
2025-07-04 22:37:29,304 - INFO - val: {'epoch': 92, 'time_epoch': 4.60986, 'loss': 0.07168046, 'lr': 0, 'params': 451793, 'time_iter': 0.03574, 'accuracy': 0.98371, 'precision': 0.68421, 'recall': 0.32099, 'f1': 0.43697, 'auc': 0.79829}
2025-07-04 22:37:33,937 - INFO - test: {'epoch': 92, 'time_epoch': 4.5631, 'loss': 0.11862713, 'lr': 0, 'params': 451793, 'time_iter': 0.03537, 'accuracy': 0.97082, 'precision': 0.58621, 'recall': 0.26154, 'f1': 0.3617, 'auc': 0.7555}
2025-07-04 22:37:33,939 - INFO - > Epoch 92: took 89.5s (avg 86.0s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:38:50,530 - INFO - train: {'epoch': 93, 'time_epoch': 76.37972, 'eta': 459.8386, 'eta_hours': 0.12773, 'loss': 0.09689767, 'lr': 1.33e-06, 'params': 451793, 'time_iter': 0.07423, 'accuracy': 0.97222, 'precision': 0.74537, 'recall': 0.39205, 'f1': 0.51383, 'auc': 0.89141}
2025-07-04 22:38:55,071 - INFO - val: {'epoch': 93, 'time_epoch': 4.5139, 'loss': 0.07140643, 'lr': 0, 'params': 451793, 'time_iter': 0.03499, 'accuracy': 0.98322, 'precision': 0.64286, 'recall': 0.33333, 'f1': 0.43902, 'auc': 0.80186}
2025-07-04 22:38:59,598 - INFO - test: {'epoch': 93, 'time_epoch': 4.50537, 'loss': 0.11915724, 'lr': 0, 'params': 451793, 'time_iter': 0.03493, 'accuracy': 0.97107, 'precision': 0.58462, 'recall': 0.29231, 'f1': 0.38974, 'auc': 0.75305}
2025-07-04 22:38:59,600 - INFO - > Epoch 93: took 85.7s (avg 86.0s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:40:15,389 - INFO - train: {'epoch': 94, 'time_epoch': 75.57887, 'eta': 383.14299, 'eta_hours': 0.10643, 'loss': 0.09699111, 'lr': 9.8e-07, 'params': 451793, 'time_iter': 0.07345, 'accuracy': 0.97258, 'precision': 0.75542, 'recall': 0.3961, 'f1': 0.5197, 'auc': 0.8934}
2025-07-04 22:40:19,881 - INFO - val: {'epoch': 94, 'time_epoch': 4.46433, 'loss': 0.07116739, 'lr': 0, 'params': 451793, 'time_iter': 0.03461, 'accuracy': 0.98347, 'precision': 0.68571, 'recall': 0.2963, 'f1': 0.41379, 'auc': 0.80132}
2025-07-04 22:40:24,367 - INFO - test: {'epoch': 94, 'time_epoch': 4.46388, 'loss': 0.11999464, 'lr': 0, 'params': 451793, 'time_iter': 0.0346, 'accuracy': 0.9718, 'precision': 0.66667, 'recall': 0.21538, 'f1': 0.32558, 'auc': 0.7574}
2025-07-04 22:40:24,370 - INFO - > Epoch 94: took 84.8s (avg 86.0s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:41:40,474 - INFO - train: {'epoch': 95, 'time_epoch': 75.89081, 'eta': 306.48365, 'eta_hours': 0.08513, 'loss': 0.09629175, 'lr': 6.8e-07, 'params': 451793, 'time_iter': 0.07375, 'accuracy': 0.97216, 'precision': 0.73442, 'recall': 0.40179, 'f1': 0.51941, 'auc': 0.89942}
2025-07-04 22:41:45,021 - INFO - val: {'epoch': 95, 'time_epoch': 4.52056, 'loss': 0.07097144, 'lr': 0, 'params': 451793, 'time_iter': 0.03504, 'accuracy': 0.98371, 'precision': 0.675, 'recall': 0.33333, 'f1': 0.44628, 'auc': 0.80129}
2025-07-04 22:41:49,603 - INFO - test: {'epoch': 95, 'time_epoch': 4.56015, 'loss': 0.11818998, 'lr': 0, 'params': 451793, 'time_iter': 0.03535, 'accuracy': 0.97107, 'precision': 0.60377, 'recall': 0.24615, 'f1': 0.34973, 'auc': 0.75484}
2025-07-04 22:41:49,606 - INFO - > Epoch 95: took 85.2s (avg 85.9s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:43:07,135 - INFO - train: {'epoch': 96, 'time_epoch': 77.30272, 'eta': 229.88383, 'eta_hours': 0.06386, 'loss': 0.09592526, 'lr': 4.4e-07, 'params': 451793, 'time_iter': 0.07512, 'accuracy': 0.97234, 'precision': 0.74247, 'recall': 0.40016, 'f1': 0.52004, 'auc': 0.89804}
2025-07-04 22:43:11,729 - INFO - val: {'epoch': 96, 'time_epoch': 4.56864, 'loss': 0.07128339, 'lr': 0, 'params': 451793, 'time_iter': 0.03542, 'accuracy': 0.98395, 'precision': 0.7027, 'recall': 0.32099, 'f1': 0.44068, 'auc': 0.79934}
2025-07-04 22:43:16,244 - INFO - test: {'epoch': 96, 'time_epoch': 4.49281, 'loss': 0.11924099, 'lr': 0, 'params': 451793, 'time_iter': 0.03483, 'accuracy': 0.97228, 'precision': 0.7, 'recall': 0.21538, 'f1': 0.32941, 'auc': 0.75543}
2025-07-04 22:43:16,247 - INFO - > Epoch 96: took 86.6s (avg 86.0s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:44:35,247 - INFO - train: {'epoch': 97, 'time_epoch': 78.7905, 'eta': 153.30002, 'eta_hours': 0.04258, 'loss': 0.09741393, 'lr': 2.5e-07, 'params': 451793, 'time_iter': 0.07657, 'accuracy': 0.97213, 'precision': 0.7496, 'recall': 0.38393, 'f1': 0.50778, 'auc': 0.89362}
2025-07-04 22:44:39,800 - INFO - val: {'epoch': 97, 'time_epoch': 4.52825, 'loss': 0.07081648, 'lr': 0, 'params': 451793, 'time_iter': 0.0351, 'accuracy': 0.98371, 'precision': 0.69444, 'recall': 0.30864, 'f1': 0.42735, 'auc': 0.80409}
2025-07-04 22:44:44,561 - INFO - test: {'epoch': 97, 'time_epoch': 4.73786, 'loss': 0.11932807, 'lr': 0, 'params': 451793, 'time_iter': 0.03673, 'accuracy': 0.9718, 'precision': 0.65909, 'recall': 0.22308, 'f1': 0.33333, 'auc': 0.7586}
2025-07-04 22:44:44,563 - INFO - > Epoch 97: took 88.3s (avg 86.0s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:46:05,306 - INFO - train: {'epoch': 98, 'time_epoch': 80.54176, 'eta': 76.68932, 'eta_hours': 0.0213, 'loss': 0.09709035, 'lr': 1.1e-07, 'params': 451793, 'time_iter': 0.07827, 'accuracy': 0.9721, 'precision': 0.73933, 'recall': 0.39367, 'f1': 0.51377, 'auc': 0.89708}
2025-07-04 22:46:09,780 - INFO - val: {'epoch': 98, 'time_epoch': 4.44828, 'loss': 0.07152199, 'lr': 0, 'params': 451793, 'time_iter': 0.03448, 'accuracy': 0.98347, 'precision': 0.67568, 'recall': 0.30864, 'f1': 0.42373, 'auc': 0.79767}
2025-07-04 22:46:14,223 - INFO - test: {'epoch': 98, 'time_epoch': 4.42151, 'loss': 0.11891155, 'lr': 0, 'params': 451793, 'time_iter': 0.03428, 'accuracy': 0.97228, 'precision': 0.68182, 'recall': 0.23077, 'f1': 0.34483, 'auc': 0.75915}
2025-07-04 22:46:14,226 - INFO - > Epoch 98: took 89.7s (avg 86.0s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:47:31,653 - INFO - train: {'epoch': 99, 'time_epoch': 77.1886, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.09560789, 'lr': 3e-08, 'params': 451793, 'time_iter': 0.07501, 'accuracy': 0.97268, 'precision': 0.77162, 'recall': 0.38393, 'f1': 0.51274, 'auc': 0.89863}
2025-07-04 22:47:36,165 - INFO - val: {'epoch': 99, 'time_epoch': 4.48653, 'loss': 0.07153245, 'lr': 0, 'params': 451793, 'time_iter': 0.03478, 'accuracy': 0.98371, 'precision': 0.68421, 'recall': 0.32099, 'f1': 0.43697, 'auc': 0.79602}
2025-07-04 22:47:40,675 - INFO - test: {'epoch': 99, 'time_epoch': 4.48858, 'loss': 0.11837756, 'lr': 0, 'params': 451793, 'time_iter': 0.0348, 'accuracy': 0.97107, 'precision': 0.60784, 'recall': 0.23846, 'f1': 0.34254, 'auc': 0.75507}
2025-07-04 22:47:40,826 - INFO - > Epoch 99: took 86.5s (avg 86.0s) | Best so far: epoch 71	train_loss: 0.0987 train_auc: 0.8874	val_loss: 0.0691 val_auc: 0.8115	test_loss: 0.1166 test_auc: 0.7568
2025-07-04 22:47:40,826 - INFO - Avg time per epoch: 86.02s
2025-07-04 22:47:40,826 - INFO - Total train loop time: 2.39h
2025-07-04 22:47:40,843 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-45
2025-07-04 22:47:40,844 - INFO - Total time: 9158.08s (2.54h)
2025-07-04 22:47:40,861 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-45/agg
2025-07-04 22:47:40,861 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-07-04 22:47:40,861 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-45
2025-07-04 22:47:40,861 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-45/test_results/
Completed seed 45. Results saved in results/molhiv/molhiv-Vanilla-45
----------------------------------------
Running experiment with seed: 47
Starting training for seed 47...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/confignas.yaml
Using device: cuda
2025-07-04 22:47:50,661 - INFO - GPU Mem: 34.1GB
2025-07-04 22:47:50,661 - INFO - Run directory: results/molhiv/molhiv-Vanilla-47
2025-07-04 22:47:50,661 - INFO - Seed: 47
2025-07-04 22:47:50,661 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-07-04 22:47:50,661 - INFO - Routing mode: none
2025-07-04 22:47:50,661 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-07-04 22:47:50,661 - INFO - Number of layers: 15
2025-07-04 22:47:50,662 - INFO - Uncertainty enabled: False
2025-07-04 22:47:50,662 - INFO - Training mode: custom
2025-07-04 22:47:50,662 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-07-04 22:47:50,662 - INFO - Additional features: Router weights logging + JSON export
2025-07-04 22:47:57,562 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-04 22:47:57,564 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-07-04 22:47:57,566 - INFO -   undirected: True
2025-07-04 22:47:57,566 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-04 22:47:57,566 - INFO -   avg num_nodes/graph: 25
2025-07-04 22:47:57,567 - INFO -   num node features: 9
2025-07-04 22:47:57,567 - INFO -   num edge features: 3
2025-07-04 22:47:57,567 - INFO -   num tasks: 1
2025-07-04 22:47:57,567 - INFO -   num classes: 2
2025-07-04 22:47:57,567 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-07-04 22:47:57,567 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-07-04 22:47:57,571 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  5%|▍         | 2056/41127 [00:13<04:10, 155.98it/s]  5%|▍         | 2056/41127 [00:23<04:10, 155.98it/s] 10%|▉         | 3947/41127 [00:23<03:38, 170.04it/s] 12%|█▏        | 5038/41127 [00:33<04:11, 143.33it/s] 14%|█▎        | 5597/41127 [00:44<05:28, 108.32it/s] 15%|█▍        | 6008/41127 [00:54<06:52, 85.04it/s]  16%|█▌        | 6415/41127 [01:04<08:12, 70.46it/s] 16%|█▌        | 6535/41127 [01:14<11:18, 51.00it/s] 17%|█▋        | 7164/41127 [01:25<10:31, 53.75it/s] 20%|██        | 8355/41127 [01:35<07:28, 73.14it/s] 24%|██▍       | 9902/41127 [01:46<05:24, 96.23it/s] 26%|██▌       | 10636/41127 [01:56<05:43, 88.81it/s] 29%|██▊       | 11806/41127 [02:06<05:05, 95.94it/s] 33%|███▎      | 13492/41127 [02:17<04:00, 114.76it/s] 34%|███▍      | 13921/41127 [02:27<04:53, 92.64it/s]  36%|███▌      | 14740/41127 [02:38<04:57, 88.80it/s] 36%|███▋      | 14927/41127 [02:48<06:27, 67.65it/s] 38%|███▊      | 15512/41127 [02:59<06:40, 63.88it/s] 38%|███▊      | 15702/41127 [03:09<08:25, 50.28it/s] 40%|███▉      | 16418/41127 [03:19<07:22, 55.90it/s] 40%|████      | 16494/41127 [03:30<09:52, 41.58it/s] 44%|████▍     | 18107/41127 [03:40<05:01, 76.31it/s] 46%|████▌     | 18757/41127 [03:50<05:11, 71.88it/s] 48%|████▊     | 19702/41127 [04:01<04:36, 77.48it/s] 51%|█████     | 20900/41127 [04:11<03:45, 89.51it/s] 52%|█████▏    | 21392/41127 [04:21<04:14, 77.67it/s] 55%|█████▍    | 22619/41127 [04:31<03:23, 90.89it/s] 57%|█████▋    | 23613/41127 [04:41<03:09, 92.58it/s] 60%|█████▉    | 24483/41127 [04:52<03:05, 89.89it/s] 63%|██████▎   | 26114/41127 [05:02<02:14, 111.45it/s] 65%|██████▍   | 26728/41127 [05:12<02:30, 95.71it/s]  70%|██████▉   | 28631/41127 [05:22<01:42, 122.47it/s] 71%|███████   | 29266/41127 [05:33<01:53, 104.09it/s] 71%|███████▏  | 29350/41127 [05:43<02:37, 74.91it/s]  74%|███████▎  | 30327/41127 [05:53<02:12, 81.57it/s] 76%|███████▌  | 31089/41127 [06:04<02:08, 78.39it/s] 76%|███████▌  | 31133/41127 [06:14<02:58, 56.10it/s] 79%|███████▉  | 32439/41127 [06:24<01:51, 77.57it/s] 80%|████████  | 32906/41127 [06:35<02:01, 67.54it/s] 83%|████████▎ | 34218/41127 [06:45<01:20, 85.74it/s] 84%|████████▍ | 34581/41127 [06:56<01:33, 69.69it/s] 85%|████████▌ | 35156/41127 [07:06<01:30, 65.66it/s] 86%|████████▋ | 35485/41127 [07:16<01:40, 56.09it/s] 89%|████████▊ | 36478/41127 [07:26<01:08, 67.73it/s] 92%|█████████▏| 37957/41127 [07:37<00:35, 90.50it/s] 93%|█████████▎| 38405/41127 [07:47<00:35, 77.06it/s] 95%|█████████▍| 38997/41127 [07:57<00:30, 70.43it/s] 96%|█████████▌| 39582/41127 [08:07<00:23, 66.94it/s] 97%|█████████▋| 40066/41127 [08:18<00:17, 60.80it/s] 98%|█████████▊| 40348/41127 [08:28<00:15, 50.79it/s] 99%|█████████▉| 40746/41127 [08:39<00:08, 46.65it/s]100%|█████████▉| 40986/41127 [08:49<00:03, 40.00it/s]100%|██████████| 41127/41127 [08:58<00:00, 76.35it/s]
2025-07-04 22:56:57,525 - INFO - Done! Took 00:08:59.96
2025-07-04 22:56:57,695 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-07-04 22:56:57,825 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-07-04 22:56:57,825 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-07-04 22:56:57,825 - INFO - Inner model has get_darts_model: False
2025-07-04 22:56:57,829 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-07-04 22:56:57,832 - INFO - Number of parameters: 451,793
2025-07-04 22:56:57,832 - INFO - Starting optimized training: 2025-07-04 22:56:57.832950
2025-07-04 22:57:04,186 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-04 22:57:04,187 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-07-04 22:57:04,188 - INFO -   undirected: True
2025-07-04 22:57:04,188 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-04 22:57:04,188 - INFO -   avg num_nodes/graph: 25
2025-07-04 22:57:04,189 - INFO -   num node features: 9
2025-07-04 22:57:04,189 - INFO -   num edge features: 3
2025-07-04 22:57:04,189 - INFO -   num tasks: 1
2025-07-04 22:57:04,189 - INFO -   num classes: 2
2025-07-04 22:57:04,189 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-07-04 22:57:04,189 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-07-04 22:57:04,193 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  5%|▍         | 2056/41127 [00:13<04:20, 150.20it/s] 10%|▉         | 4112/41127 [00:26<03:52, 159.02it/s] 10%|▉         | 4112/41127 [00:36<03:52, 159.02it/s] 12%|█▏        | 5066/41127 [00:37<04:42, 127.62it/s] 14%|█▎        | 5601/41127 [00:47<05:53, 100.45it/s] 15%|█▍        | 6025/41127 [00:58<07:17, 80.26it/s]  16%|█▌        | 6449/41127 [01:08<08:32, 67.62it/s] 16%|█▌        | 6563/41127 [01:18<11:28, 50.18it/s] 18%|█▊        | 7572/41127 [01:28<08:30, 65.75it/s] 21%|██▏       | 8832/41127 [01:38<06:24, 84.08it/s] 24%|██▍       | 10073/41127 [01:48<05:28, 94.65it/s] 26%|██▋       | 10834/41127 [01:59<05:46, 87.42it/s] 30%|███       | 12374/41127 [02:10<04:31, 105.75it/s] 34%|███▎      | 13798/41127 [02:20<03:56, 115.53it/s] 35%|███▍      | 14339/41127 [02:31<04:40, 95.57it/s]  36%|███▌      | 14751/41127 [02:41<05:36, 78.49it/s] 37%|███▋      | 15309/41127 [02:51<05:59, 71.88it/s] 38%|███▊      | 15515/41127 [03:01<07:34, 56.30it/s] 39%|███▉      | 15954/41127 [03:11<07:58, 52.66it/s] 40%|███▉      | 16424/41127 [03:22<08:14, 49.91it/s] 40%|████      | 16538/41127 [03:33<10:49, 37.83it/s] 45%|████▍     | 18465/41127 [03:43<04:34, 82.47it/s] 47%|████▋     | 19175/41127 [03:53<04:38, 78.70it/s] 49%|████▊     | 20008/41127 [04:04<04:27, 78.90it/s] 51%|█████▏    | 21125/41127 [04:14<03:47, 88.01it/s] 53%|█████▎    | 21985/41127 [04:24<03:39, 87.13it/s] 56%|█████▌    | 23131/41127 [04:34<03:08, 95.22it/s] 58%|█████▊    | 23731/41127 [04:44<03:25, 84.68it/s] 61%|██████    | 24916/41127 [04:55<02:55, 92.45it/s] 64%|██████▍   | 26387/41127 [05:05<02:16, 107.88it/s] 66%|██████▌   | 27029/41127 [05:15<02:28, 95.04it/s]  71%|███████   | 29118/41127 [05:25<01:33, 128.71it/s] 71%|███████   | 29273/41127 [05:35<02:04, 94.88it/s]  72%|███████▏  | 29419/41127 [05:46<02:47, 69.78it/s] 75%|███████▍  | 30685/41127 [05:56<02:01, 85.99it/s] 76%|███████▌  | 31116/41127 [06:07<02:19, 71.98it/s] 77%|███████▋  | 31587/41127 [06:17<02:28, 64.43it/s] 79%|███████▉  | 32535/41127 [06:27<01:58, 72.54it/s] 81%|████████  | 33287/41127 [06:37<01:47, 73.11it/s] 84%|████████▍ | 34478/41127 [06:48<01:17, 85.38it/s] 85%|████████▍ | 34759/41127 [06:58<01:33, 68.17it/s] 86%|████████▌ | 35433/41127 [07:08<01:24, 67.46it/s] 87%|████████▋ | 35613/41127 [07:19<01:46, 51.76it/s] 90%|████████▉ | 36857/41127 [07:29<00:59, 71.63it/s] 93%|█████████▎| 38375/41127 [07:40<00:29, 93.66it/s] 94%|█████████▍| 38730/41127 [07:50<00:31, 76.60it/s] 95%|█████████▌| 39265/41127 [08:00<00:26, 69.50it/s] 97%|█████████▋| 39748/41127 [08:10<00:21, 62.78it/s] 97%|█████████▋| 40071/41127 [08:21<00:19, 53.10it/s] 98%|█████████▊| 40478/41127 [08:31<00:13, 48.71it/s] 99%|█████████▉| 40848/41127 [08:42<00:06, 44.54it/s]100%|█████████▉| 41019/41127 [08:53<00:02, 36.03it/s]100%|██████████| 41127/41127 [08:59<00:00, 76.18it/s]
2025-07-04 23:06:05,347 - INFO - Done! Took 00:09:01.16
2025-07-04 23:06:05,517 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-07-04 23:06:05,522 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-07-04 23:06:05,522 - INFO - Start from epoch 0
2025-07-04 23:07:28,845 - INFO - train: {'epoch': 0, 'time_epoch': 83.09712, 'eta': 8226.61453, 'eta_hours': 2.28517, 'loss': 0.71941173, 'lr': 0.0, 'params': 451793, 'time_iter': 0.08076, 'accuracy': 0.05574, 'precision': 0.03786, 'recall': 0.99188, 'f1': 0.07293, 'auc': 0.51739}
2025-07-04 23:07:28,858 - INFO - ...computing epoch stats took: 0.20s
2025-07-04 23:07:34,402 - INFO - val: {'epoch': 0, 'time_epoch': 5.52549, 'loss': 0.71477122, 'lr': 0, 'params': 451793, 'time_iter': 0.04283, 'accuracy': 0.0231, 'precision': 0.01976, 'recall': 1.0, 'f1': 0.03876, 'auc': 0.56404}
2025-07-04 23:07:34,405 - INFO - ...computing epoch stats took: 0.02s
2025-07-04 23:07:39,467 - INFO - test: {'epoch': 0, 'time_epoch': 5.04415, 'loss': 0.71682137, 'lr': 0, 'params': 451793, 'time_iter': 0.0391, 'accuracy': 0.04012, 'precision': 0.03165, 'recall': 0.99231, 'f1': 0.06134, 'auc': 0.5408}
2025-07-04 23:07:39,506 - INFO - ...computing epoch stats took: 0.05s
2025-07-04 23:07:39,506 - INFO - > Epoch 0: took 94.0s (avg 94.0s) | Best so far: epoch 0	train_loss: 0.7194 train_auc: 0.5174	val_loss: 0.7148 val_auc: 0.5640	test_loss: 0.7168 test_auc: 0.5408
2025-07-04 23:08:57,660 - INFO - train: {'epoch': 1, 'time_epoch': 77.92342, 'eta': 7890.00627, 'eta_hours': 2.19167, 'loss': 0.51561157, 'lr': 2e-05, 'params': 451793, 'time_iter': 0.07573, 'accuracy': 0.85602, 'precision': 0.04398, 'recall': 0.13718, 'f1': 0.0666, 'auc': 0.54184}
2025-07-04 23:08:57,670 - INFO - ...computing epoch stats took: 0.21s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:09:02,254 - INFO - val: {'epoch': 1, 'time_epoch': 4.56287, 'loss': 0.3012461, 'lr': 0, 'params': 451793, 'time_iter': 0.03537, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.48875}
2025-07-04 23:09:02,256 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:09:06,834 - INFO - test: {'epoch': 1, 'time_epoch': 4.56019, 'loss': 0.29558936, 'lr': 0, 'params': 451793, 'time_iter': 0.03535, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.5965}
2025-07-04 23:09:06,837 - INFO - ...computing epoch stats took: 0.02s
2025-07-04 23:09:06,838 - INFO - > Epoch 1: took 87.3s (avg 90.7s) | Best so far: epoch 0	train_loss: 0.7194 train_auc: 0.5174	val_loss: 0.7148 val_auc: 0.5640	test_loss: 0.7168 test_auc: 0.5408
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:10:26,124 - INFO - train: {'epoch': 2, 'time_epoch': 79.1117, 'eta': 7764.27577, 'eta_hours': 2.15674, 'loss': 0.21241879, 'lr': 4e-05, 'params': 451793, 'time_iter': 0.07688, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.57968}
2025-07-04 23:10:26,135 - INFO - ...computing epoch stats took: 0.15s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:10:30,745 - INFO - val: {'epoch': 2, 'time_epoch': 4.59177, 'loss': 0.11376574, 'lr': 0, 'params': 451793, 'time_iter': 0.0356, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.5507}
2025-07-04 23:10:30,748 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:10:35,383 - INFO - test: {'epoch': 2, 'time_epoch': 4.61718, 'loss': 0.14660282, 'lr': 0, 'params': 451793, 'time_iter': 0.03579, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.60266}
2025-07-04 23:10:35,385 - INFO - ...computing epoch stats took: 0.02s
2025-07-04 23:10:35,386 - INFO - > Epoch 2: took 88.5s (avg 90.0s) | Best so far: epoch 0	train_loss: 0.7194 train_auc: 0.5174	val_loss: 0.7148 val_auc: 0.5640	test_loss: 0.7168 test_auc: 0.5408
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:11:55,055 - INFO - train: {'epoch': 3, 'time_epoch': 79.46809, 'eta': 7670.40784, 'eta_hours': 2.13067, 'loss': 0.16380582, 'lr': 6e-05, 'params': 451793, 'time_iter': 0.07723, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.59286}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:11:59,746 - INFO - val: {'epoch': 3, 'time_epoch': 4.66516, 'loss': 0.10189375, 'lr': 0, 'params': 451793, 'time_iter': 0.03616, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.5867}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:12:04,323 - INFO - test: {'epoch': 3, 'time_epoch': 4.55726, 'loss': 0.13918429, 'lr': 0, 'params': 451793, 'time_iter': 0.03533, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.63422}
2025-07-04 23:12:04,326 - INFO - > Epoch 3: took 88.9s (avg 89.7s) | Best so far: epoch 3	train_loss: 0.1638 train_auc: 0.5929	val_loss: 0.1019 val_auc: 0.5867	test_loss: 0.1392 test_auc: 0.6342
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:13:26,168 - INFO - train: {'epoch': 4, 'time_epoch': 81.62218, 'eta': 7623.22754, 'eta_hours': 2.11756, 'loss': 0.15910378, 'lr': 8e-05, 'params': 451793, 'time_iter': 0.07932, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.61753}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:13:30,776 - INFO - val: {'epoch': 4, 'time_epoch': 4.57944, 'loss': 0.09785282, 'lr': 0, 'params': 451793, 'time_iter': 0.0355, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.64392}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:13:35,536 - INFO - test: {'epoch': 4, 'time_epoch': 4.73917, 'loss': 0.14008756, 'lr': 0, 'params': 451793, 'time_iter': 0.03674, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.63445}
2025-07-04 23:13:35,538 - INFO - > Epoch 4: took 91.2s (avg 90.0s) | Best so far: epoch 4	train_loss: 0.1591 train_auc: 0.6175	val_loss: 0.0979 val_auc: 0.6439	test_loss: 0.1401 test_auc: 0.6344
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:14:59,468 - INFO - train: {'epoch': 5, 'time_epoch': 83.75, 'eta': 7597.90261, 'eta_hours': 2.11053, 'loss': 0.15537568, 'lr': 0.0001, 'params': 451793, 'time_iter': 0.08139, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.65099}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:15:04,125 - INFO - val: {'epoch': 5, 'time_epoch': 4.62748, 'loss': 0.09734649, 'lr': 0, 'params': 451793, 'time_iter': 0.03587, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.63329}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:15:08,736 - INFO - test: {'epoch': 5, 'time_epoch': 4.58669, 'loss': 0.13475124, 'lr': 0, 'params': 451793, 'time_iter': 0.03556, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6652}
2025-07-04 23:15:08,742 - INFO - > Epoch 5: took 93.2s (avg 90.5s) | Best so far: epoch 4	train_loss: 0.1591 train_auc: 0.6175	val_loss: 0.0979 val_auc: 0.6439	test_loss: 0.1401 test_auc: 0.6344
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:16:28,045 - INFO - train: {'epoch': 6, 'time_epoch': 79.10743, 'eta': 7494.20484, 'eta_hours': 2.08172, 'loss': 0.1499289, 'lr': 9.997e-05, 'params': 451793, 'time_iter': 0.07688, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69314}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:16:32,721 - INFO - val: {'epoch': 6, 'time_epoch': 4.64868, 'loss': 0.09258127, 'lr': 0, 'params': 451793, 'time_iter': 0.03604, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69375}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:16:37,378 - INFO - test: {'epoch': 6, 'time_epoch': 4.63655, 'loss': 0.13458578, 'lr': 0, 'params': 451793, 'time_iter': 0.03594, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69907}
2025-07-04 23:16:37,381 - INFO - > Epoch 6: took 88.6s (avg 90.3s) | Best so far: epoch 6	train_loss: 0.1499 train_auc: 0.6931	val_loss: 0.0926 val_auc: 0.6937	test_loss: 0.1346 test_auc: 0.6991
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:17:57,175 - INFO - train: {'epoch': 7, 'time_epoch': 79.60983, 'eta': 7402.43225, 'eta_hours': 2.05623, 'loss': 0.14642409, 'lr': 9.989e-05, 'params': 451793, 'time_iter': 0.07737, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71522}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:18:01,904 - INFO - val: {'epoch': 7, 'time_epoch': 4.70249, 'loss': 0.0889621, 'lr': 0, 'params': 451793, 'time_iter': 0.03645, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71456}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:18:06,600 - INFO - test: {'epoch': 7, 'time_epoch': 4.67563, 'loss': 0.12836499, 'lr': 0, 'params': 451793, 'time_iter': 0.03625, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71878}
2025-07-04 23:18:06,603 - INFO - > Epoch 7: took 89.2s (avg 90.1s) | Best so far: epoch 7	train_loss: 0.1464 train_auc: 0.7152	val_loss: 0.0890 val_auc: 0.7146	test_loss: 0.1284 test_auc: 0.7188
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:19:28,693 - INFO - train: {'epoch': 8, 'time_epoch': 81.88582, 'eta': 7336.37528, 'eta_hours': 2.03788, 'loss': 0.14226724, 'lr': 9.975e-05, 'params': 451793, 'time_iter': 0.07958, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72885}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:19:33,574 - INFO - val: {'epoch': 8, 'time_epoch': 4.85376, 'loss': 0.08637433, 'lr': 0, 'params': 451793, 'time_iter': 0.03763, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74005}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:19:38,401 - INFO - test: {'epoch': 8, 'time_epoch': 4.80626, 'loss': 0.12382721, 'lr': 0, 'params': 451793, 'time_iter': 0.03726, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73706}
2025-07-04 23:19:38,404 - INFO - > Epoch 8: took 91.8s (avg 90.3s) | Best so far: epoch 8	train_loss: 0.1423 train_auc: 0.7288	val_loss: 0.0864 val_auc: 0.7400	test_loss: 0.1238 test_auc: 0.7371
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:21:01,608 - INFO - train: {'epoch': 9, 'time_epoch': 83.00166, 'eta': 7277.19514, 'eta_hours': 2.02144, 'loss': 0.13984344, 'lr': 9.956e-05, 'params': 451793, 'time_iter': 0.08066, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74134}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:21:06,485 - INFO - val: {'epoch': 9, 'time_epoch': 4.8488, 'loss': 0.08712622, 'lr': 0, 'params': 451793, 'time_iter': 0.03759, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6941}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:21:11,319 - INFO - test: {'epoch': 9, 'time_epoch': 4.81278, 'loss': 0.12386328, 'lr': 0, 'params': 451793, 'time_iter': 0.03731, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73875}
2025-07-04 23:21:11,322 - INFO - > Epoch 9: took 92.9s (avg 90.6s) | Best so far: epoch 8	train_loss: 0.1423 train_auc: 0.7288	val_loss: 0.0864 val_auc: 0.7400	test_loss: 0.1238 test_auc: 0.7371
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:22:30,917 - INFO - train: {'epoch': 10, 'time_epoch': 79.40025, 'eta': 7184.54509, 'eta_hours': 1.99571, 'loss': 0.13851846, 'lr': 9.932e-05, 'params': 451793, 'time_iter': 0.07716, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74829}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:22:35,562 - INFO - val: {'epoch': 10, 'time_epoch': 4.61835, 'loss': 0.08911378, 'lr': 0, 'params': 451793, 'time_iter': 0.0358, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69876}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:22:40,141 - INFO - test: {'epoch': 10, 'time_epoch': 4.5564, 'loss': 0.12549796, 'lr': 0, 'params': 451793, 'time_iter': 0.03532, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73409}
2025-07-04 23:22:40,145 - INFO - > Epoch 10: took 88.8s (avg 90.4s) | Best so far: epoch 8	train_loss: 0.1423 train_auc: 0.7288	val_loss: 0.0864 val_auc: 0.7400	test_loss: 0.1238 test_auc: 0.7371
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:24:01,847 - INFO - train: {'epoch': 11, 'time_epoch': 81.50903, 'eta': 7109.56775, 'eta_hours': 1.97488, 'loss': 0.13749532, 'lr': 9.902e-05, 'params': 451793, 'time_iter': 0.07921, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74968}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:24:06,600 - INFO - val: {'epoch': 11, 'time_epoch': 4.71284, 'loss': 0.08856488, 'lr': 0, 'params': 451793, 'time_iter': 0.03653, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72697}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:24:11,268 - INFO - test: {'epoch': 11, 'time_epoch': 4.64781, 'loss': 0.12581134, 'lr': 0, 'params': 451793, 'time_iter': 0.03603, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72094}
2025-07-04 23:24:11,271 - INFO - > Epoch 11: took 91.1s (avg 90.5s) | Best so far: epoch 8	train_loss: 0.1423 train_auc: 0.7288	val_loss: 0.0864 val_auc: 0.7400	test_loss: 0.1238 test_auc: 0.7371
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:25:30,660 - INFO - train: {'epoch': 12, 'time_epoch': 79.17648, 'eta': 7017.97539, 'eta_hours': 1.94944, 'loss': 0.13541771, 'lr': 9.867e-05, 'params': 451793, 'time_iter': 0.07695, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75599}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:25:35,233 - INFO - val: {'epoch': 12, 'time_epoch': 4.54672, 'loss': 0.08288019, 'lr': 0, 'params': 451793, 'time_iter': 0.03525, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72906}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:25:39,792 - INFO - test: {'epoch': 12, 'time_epoch': 4.53731, 'loss': 0.12194757, 'lr': 0, 'params': 451793, 'time_iter': 0.03517, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73899}
2025-07-04 23:25:39,795 - INFO - > Epoch 12: took 88.5s (avg 90.3s) | Best so far: epoch 8	train_loss: 0.1423 train_auc: 0.7288	val_loss: 0.0864 val_auc: 0.7400	test_loss: 0.1238 test_auc: 0.7371
2025-07-04 23:26:58,053 - INFO - train: {'epoch': 13, 'time_epoch': 78.07053, 'eta': 6921.36302, 'eta_hours': 1.9226, 'loss': 0.1351102, 'lr': 9.826e-05, 'params': 451793, 'time_iter': 0.07587, 'accuracy': 0.96252, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75993}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:27:02,662 - INFO - val: {'epoch': 13, 'time_epoch': 4.58241, 'loss': 0.08328562, 'lr': 0, 'params': 451793, 'time_iter': 0.03552, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73362}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:27:07,243 - INFO - test: {'epoch': 13, 'time_epoch': 4.56093, 'loss': 0.1165281, 'lr': 0, 'params': 451793, 'time_iter': 0.03536, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76601}
2025-07-04 23:27:07,246 - INFO - > Epoch 13: took 87.5s (avg 90.1s) | Best so far: epoch 8	train_loss: 0.1423 train_auc: 0.7288	val_loss: 0.0864 val_auc: 0.7400	test_loss: 0.1238 test_auc: 0.7371
2025-07-04 23:28:26,473 - INFO - train: {'epoch': 14, 'time_epoch': 79.02657, 'eta': 6832.64046, 'eta_hours': 1.89796, 'loss': 0.13385939, 'lr': 9.78e-05, 'params': 451793, 'time_iter': 0.0768, 'accuracy': 0.96252, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76294}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:28:31,126 - INFO - val: {'epoch': 14, 'time_epoch': 4.6249, 'loss': 0.08373561, 'lr': 0, 'params': 451793, 'time_iter': 0.03585, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7401}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:28:35,785 - INFO - test: {'epoch': 14, 'time_epoch': 4.63858, 'loss': 0.12353066, 'lr': 0, 'params': 451793, 'time_iter': 0.03596, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73925}
2025-07-04 23:28:35,788 - INFO - > Epoch 14: took 88.5s (avg 90.0s) | Best so far: epoch 14	train_loss: 0.1339 train_auc: 0.7629	val_loss: 0.0837 val_auc: 0.7401	test_loss: 0.1235 test_auc: 0.7392
2025-07-04 23:29:55,845 - INFO - train: {'epoch': 15, 'time_epoch': 79.84916, 'eta': 6749.44851, 'eta_hours': 1.87485, 'loss': 0.1325115, 'lr': 9.729e-05, 'params': 451793, 'time_iter': 0.0776, 'accuracy': 0.96246, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76758}
2025-07-04 23:30:00,527 - INFO - val: {'epoch': 15, 'time_epoch': 4.6526, 'loss': 0.0836153, 'lr': 0, 'params': 451793, 'time_iter': 0.03607, 'accuracy': 0.98079, 'precision': 1.0, 'recall': 0.02469, 'f1': 0.04819, 'auc': 0.72753}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-07-04 23:30:05,270 - INFO - test: {'epoch': 15, 'time_epoch': 4.72183, 'loss': 0.12186255, 'lr': 0, 'params': 451793, 'time_iter': 0.0366, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73116}
2025-07-04 23:30:05,272 - INFO - > Epoch 15: took 89.5s (avg 90.0s) | Best so far: epoch 14	train_loss: 0.1339 train_auc: 0.7629	val_loss: 0.0837 val_auc: 0.7401	test_loss: 0.1235 test_auc: 0.7392
2025-07-04 23:31:27,020 - INFO - train: {'epoch': 16, 'time_epoch': 81.56311, 'eta': 6675.01795, 'eta_hours': 1.85417, 'loss': 0.13149386, 'lr': 9.673e-05, 'params': 451793, 'time_iter': 0.07926, 'accuracy': 0.96268, 'precision': 0.75, 'recall': 0.00487, 'f1': 0.00968, 'auc': 0.76924}
2025-07-04 23:31:31,789 - INFO - val: {'epoch': 16, 'time_epoch': 4.74001, 'loss': 0.08356371, 'lr': 0, 'params': 451793, 'time_iter': 0.03674, 'accuracy': 0.98104, 'precision': 0.6, 'recall': 0.11111, 'f1': 0.1875, 'auc': 0.76061}
2025-07-04 23:31:36,658 - INFO - test: {'epoch': 16, 'time_epoch': 4.84683, 'loss': 0.11908209, 'lr': 0, 'params': 451793, 'time_iter': 0.03757, 'accuracy': 0.96888, 'precision': 0.6, 'recall': 0.04615, 'f1': 0.08571, 'auc': 0.76058}
2025-07-04 23:31:36,661 - INFO - > Epoch 16: took 91.4s (avg 90.1s) | Best so far: epoch 16	train_loss: 0.1315 train_auc: 0.7692	val_loss: 0.0836 val_auc: 0.7606	test_loss: 0.1191 test_auc: 0.7606
2025-07-04 23:33:00,062 - INFO - train: {'epoch': 17, 'time_epoch': 83.18336, 'eta': 6607.17601, 'eta_hours': 1.83533, 'loss': 0.13038769, 'lr': 9.611e-05, 'params': 451793, 'time_iter': 0.08084, 'accuracy': 0.96277, 'precision': 0.64, 'recall': 0.01299, 'f1': 0.02546, 'auc': 0.77619}
2025-07-04 23:33:04,972 - INFO - val: {'epoch': 17, 'time_epoch': 4.88008, 'loss': 0.08145788, 'lr': 0, 'params': 451793, 'time_iter': 0.03783, 'accuracy': 0.98104, 'precision': 0.8, 'recall': 0.04938, 'f1': 0.09302, 'auc': 0.74645}
2025-07-04 23:33:09,737 - INFO - test: {'epoch': 17, 'time_epoch': 4.74305, 'loss': 0.12004074, 'lr': 0, 'params': 451793, 'time_iter': 0.03677, 'accuracy': 0.96888, 'precision': 0.75, 'recall': 0.02308, 'f1': 0.04478, 'auc': 0.75486}
2025-07-04 23:33:09,739 - INFO - > Epoch 17: took 93.1s (avg 90.2s) | Best so far: epoch 16	train_loss: 0.1315 train_auc: 0.7692	val_loss: 0.0836 val_auc: 0.7606	test_loss: 0.1191 test_auc: 0.7606
2025-07-04 23:34:29,336 - INFO - train: {'epoch': 18, 'time_epoch': 79.37893, 'eta': 6521.5003, 'eta_hours': 1.81153, 'loss': 0.12981767, 'lr': 9.545e-05, 'params': 451793, 'time_iter': 0.07714, 'accuracy': 0.96271, 'precision': 0.52688, 'recall': 0.03977, 'f1': 0.07396, 'auc': 0.78043}
2025-07-04 23:34:33,987 - INFO - val: {'epoch': 18, 'time_epoch': 4.61572, 'loss': 0.08169972, 'lr': 0, 'params': 451793, 'time_iter': 0.03578, 'accuracy': 0.98128, 'precision': 1.0, 'recall': 0.04938, 'f1': 0.09412, 'auc': 0.72075}
2025-07-04 23:34:38,621 - INFO - test: {'epoch': 18, 'time_epoch': 4.60774, 'loss': 0.11582355, 'lr': 0, 'params': 451793, 'time_iter': 0.03572, 'accuracy': 0.96815, 'precision': 0.33333, 'recall': 0.00769, 'f1': 0.01504, 'auc': 0.77311}
2025-07-04 23:34:38,625 - INFO - > Epoch 18: took 88.9s (avg 90.2s) | Best so far: epoch 16	train_loss: 0.1315 train_auc: 0.7692	val_loss: 0.0836 val_auc: 0.7606	test_loss: 0.1191 test_auc: 0.7606
2025-07-04 23:35:56,959 - INFO - train: {'epoch': 19, 'time_epoch': 78.13643, 'eta': 6431.48429, 'eta_hours': 1.78652, 'loss': 0.12847422, 'lr': 9.474e-05, 'params': 451793, 'time_iter': 0.07593, 'accuracy': 0.96347, 'precision': 0.61364, 'recall': 0.06575, 'f1': 0.11877, 'auc': 0.7823}
2025-07-04 23:36:01,548 - INFO - val: {'epoch': 19, 'time_epoch': 4.55657, 'loss': 0.07808267, 'lr': 0, 'params': 451793, 'time_iter': 0.03532, 'accuracy': 0.98079, 'precision': 0.6, 'recall': 0.07407, 'f1': 0.13187, 'auc': 0.75829}
2025-07-04 23:36:06,110 - INFO - test: {'epoch': 19, 'time_epoch': 4.53998, 'loss': 0.12017167, 'lr': 0, 'params': 451793, 'time_iter': 0.03519, 'accuracy': 0.96742, 'precision': 0.3, 'recall': 0.02308, 'f1': 0.04286, 'auc': 0.74648}
2025-07-04 23:36:06,113 - INFO - > Epoch 19: took 87.5s (avg 90.0s) | Best so far: epoch 16	train_loss: 0.1315 train_auc: 0.7692	val_loss: 0.0836 val_auc: 0.7606	test_loss: 0.1191 test_auc: 0.7606
2025-07-04 23:37:26,332 - INFO - train: {'epoch': 20, 'time_epoch': 80.05279, 'eta': 6349.8088, 'eta_hours': 1.76384, 'loss': 0.12754038, 'lr': 9.397e-05, 'params': 451793, 'time_iter': 0.0778, 'accuracy': 0.96432, 'precision': 0.69333, 'recall': 0.08442, 'f1': 0.15051, 'auc': 0.78803}
2025-07-04 23:37:30,989 - INFO - val: {'epoch': 20, 'time_epoch': 4.62903, 'loss': 0.07921937, 'lr': 0, 'params': 451793, 'time_iter': 0.03588, 'accuracy': 0.97982, 'precision': 0.42857, 'recall': 0.07407, 'f1': 0.12632, 'auc': 0.77022}
2025-07-04 23:37:35,598 - INFO - test: {'epoch': 20, 'time_epoch': 4.58691, 'loss': 0.11814704, 'lr': 0, 'params': 451793, 'time_iter': 0.03556, 'accuracy': 0.96791, 'precision': 0.45455, 'recall': 0.07692, 'f1': 0.13158, 'auc': 0.75289}
2025-07-04 23:37:35,600 - INFO - > Epoch 20: took 89.5s (avg 90.0s) | Best so far: epoch 20	train_loss: 0.1275 train_auc: 0.7880	val_loss: 0.0792 val_auc: 0.7702	test_loss: 0.1181 test_auc: 0.7529
2025-07-04 23:38:55,478 - INFO - train: {'epoch': 21, 'time_epoch': 79.66166, 'eta': 6266.89411, 'eta_hours': 1.7408, 'loss': 0.12675565, 'lr': 9.316e-05, 'params': 451793, 'time_iter': 0.07742, 'accuracy': 0.96471, 'precision': 0.65639, 'recall': 0.12094, 'f1': 0.20425, 'auc': 0.79246}
2025-07-04 23:39:00,088 - INFO - val: {'epoch': 21, 'time_epoch': 4.58006, 'loss': 0.07637841, 'lr': 0, 'params': 451793, 'time_iter': 0.0355, 'accuracy': 0.98152, 'precision': 0.6, 'recall': 0.18519, 'f1': 0.28302, 'auc': 0.77572}
2025-07-04 23:39:04,765 - INFO - test: {'epoch': 21, 'time_epoch': 4.64262, 'loss': 0.11904091, 'lr': 0, 'params': 451793, 'time_iter': 0.03599, 'accuracy': 0.97009, 'precision': 0.62963, 'recall': 0.13077, 'f1': 0.21656, 'auc': 0.7474}
2025-07-04 23:39:04,801 - INFO - > Epoch 21: took 89.2s (avg 90.0s) | Best so far: epoch 21	train_loss: 0.1268 train_auc: 0.7925	val_loss: 0.0764 val_auc: 0.7757	test_loss: 0.1190 test_auc: 0.7474
2025-07-04 23:40:26,288 - INFO - train: {'epoch': 22, 'time_epoch': 81.278, 'eta': 6189.67351, 'eta_hours': 1.71935, 'loss': 0.12500063, 'lr': 9.23e-05, 'params': 451793, 'time_iter': 0.07899, 'accuracy': 0.96453, 'precision': 0.60726, 'recall': 0.14935, 'f1': 0.23974, 'auc': 0.80097}
2025-07-04 23:40:31,160 - INFO - val: {'epoch': 22, 'time_epoch': 4.84321, 'loss': 0.07598777, 'lr': 0, 'params': 451793, 'time_iter': 0.03754, 'accuracy': 0.98249, 'precision': 0.68, 'recall': 0.20988, 'f1': 0.32075, 'auc': 0.77566}
2025-07-04 23:40:35,877 - INFO - test: {'epoch': 22, 'time_epoch': 4.69469, 'loss': 0.11668511, 'lr': 0, 'params': 451793, 'time_iter': 0.03639, 'accuracy': 0.96985, 'precision': 0.65, 'recall': 0.1, 'f1': 0.17333, 'auc': 0.75407}
2025-07-04 23:40:35,880 - INFO - > Epoch 22: took 91.1s (avg 90.0s) | Best so far: epoch 21	train_loss: 0.1268 train_auc: 0.7925	val_loss: 0.0764 val_auc: 0.7757	test_loss: 0.1190 test_auc: 0.7474
2025-07-04 23:41:58,672 - INFO - train: {'epoch': 23, 'time_epoch': 82.54378, 'eta': 6116.12309, 'eta_hours': 1.69892, 'loss': 0.12456856, 'lr': 9.14e-05, 'params': 451793, 'time_iter': 0.08022, 'accuracy': 0.96511, 'precision': 0.62139, 'recall': 0.17451, 'f1': 0.2725, 'auc': 0.80261}
2025-07-04 23:42:03,295 - INFO - val: {'epoch': 23, 'time_epoch': 4.59517, 'loss': 0.07731083, 'lr': 0, 'params': 451793, 'time_iter': 0.03562, 'accuracy': 0.98006, 'precision': 0.47368, 'recall': 0.11111, 'f1': 0.18, 'auc': 0.76816}
2025-07-04 23:42:07,881 - INFO - test: {'epoch': 23, 'time_epoch': 4.55838, 'loss': 0.12212932, 'lr': 0, 'params': 451793, 'time_iter': 0.03534, 'accuracy': 0.96864, 'precision': 0.54545, 'recall': 0.04615, 'f1': 0.08511, 'auc': 0.74892}
2025-07-04 23:42:07,884 - INFO - > Epoch 23: took 92.0s (avg 90.1s) | Best so far: epoch 21	train_loss: 0.1268 train_auc: 0.7925	val_loss: 0.0764 val_auc: 0.7757	test_loss: 0.1190 test_auc: 0.7474
2025-07-04 23:43:27,312 - INFO - train: {'epoch': 24, 'time_epoch': 79.25254, 'eta': 6031.9795, 'eta_hours': 1.67555, 'loss': 0.12340874, 'lr': 9.045e-05, 'params': 451793, 'time_iter': 0.07702, 'accuracy': 0.96541, 'precision': 0.66906, 'recall': 0.15097, 'f1': 0.24636, 'auc': 0.80785}
2025-07-04 23:43:31,970 - INFO - val: {'epoch': 24, 'time_epoch': 4.62889, 'loss': 0.08125083, 'lr': 0, 'params': 451793, 'time_iter': 0.03588, 'accuracy': 0.97982, 'precision': 0.45, 'recall': 0.11111, 'f1': 0.17822, 'auc': 0.77143}
2025-07-04 23:43:36,566 - INFO - test: {'epoch': 24, 'time_epoch': 4.57545, 'loss': 0.12344987, 'lr': 0, 'params': 451793, 'time_iter': 0.03547, 'accuracy': 0.96815, 'precision': 0.48571, 'recall': 0.13077, 'f1': 0.20606, 'auc': 0.74196}
2025-07-04 23:43:36,569 - INFO - > Epoch 24: took 88.7s (avg 90.0s) | Best so far: epoch 21	train_loss: 0.1268 train_auc: 0.7925	val_loss: 0.0764 val_auc: 0.7757	test_loss: 0.1190 test_auc: 0.7474
2025-07-04 23:44:56,958 - INFO - train: {'epoch': 25, 'time_epoch': 80.1583, 'eta': 5950.79008, 'eta_hours': 1.653, 'loss': 0.12356921, 'lr': 8.946e-05, 'params': 451793, 'time_iter': 0.0779, 'accuracy': 0.96459, 'precision': 0.61279, 'recall': 0.14773, 'f1': 0.23806, 'auc': 0.81047}
2025-07-04 23:45:01,843 - INFO - val: {'epoch': 25, 'time_epoch': 4.85428, 'loss': 0.07631822, 'lr': 0, 'params': 451793, 'time_iter': 0.03763, 'accuracy': 0.98079, 'precision': 0.5625, 'recall': 0.11111, 'f1': 0.18557, 'auc': 0.77684}
2025-07-04 23:45:06,684 - INFO - test: {'epoch': 25, 'time_epoch': 4.81815, 'loss': 0.1185263, 'lr': 0, 'params': 451793, 'time_iter': 0.03735, 'accuracy': 0.96961, 'precision': 0.64706, 'recall': 0.08462, 'f1': 0.14966, 'auc': 0.75578}
2025-07-04 23:45:06,687 - INFO - > Epoch 25: took 90.1s (avg 90.0s) | Best so far: epoch 25	train_loss: 0.1236 train_auc: 0.8105	val_loss: 0.0763 val_auc: 0.7768	test_loss: 0.1185 test_auc: 0.7558
2025-07-04 23:46:29,071 - INFO - train: {'epoch': 26, 'time_epoch': 82.15236, 'eta': 5875.06837, 'eta_hours': 1.63196, 'loss': 0.12286046, 'lr': 8.842e-05, 'params': 451793, 'time_iter': 0.07984, 'accuracy': 0.96471, 'precision': 0.6035, 'recall': 0.16802, 'f1': 0.26286, 'auc': 0.80288}
2025-07-04 23:46:34,020 - INFO - val: {'epoch': 26, 'time_epoch': 4.91972, 'loss': 0.07510768, 'lr': 0, 'params': 451793, 'time_iter': 0.03814, 'accuracy': 0.98225, 'precision': 0.66667, 'recall': 0.19753, 'f1': 0.30476, 'auc': 0.80092}
2025-07-04 23:46:38,923 - INFO - test: {'epoch': 26, 'time_epoch': 4.88057, 'loss': 0.12117868, 'lr': 0, 'params': 451793, 'time_iter': 0.03783, 'accuracy': 0.96766, 'precision': 0.38462, 'recall': 0.03846, 'f1': 0.06993, 'auc': 0.75073}
2025-07-04 23:46:38,925 - INFO - > Epoch 26: took 92.2s (avg 90.1s) | Best so far: epoch 26	train_loss: 0.1229 train_auc: 0.8029	val_loss: 0.0751 val_auc: 0.8009	test_loss: 0.1212 test_auc: 0.7507
2025-07-04 23:47:59,893 - INFO - train: {'epoch': 27, 'time_epoch': 80.74243, 'eta': 5795.2618, 'eta_hours': 1.60979, 'loss': 0.12213166, 'lr': 8.734e-05, 'params': 451793, 'time_iter': 0.07847, 'accuracy': 0.96493, 'precision': 0.60372, 'recall': 0.18425, 'f1': 0.28234, 'auc': 0.80489}
2025-07-04 23:48:04,500 - INFO - val: {'epoch': 27, 'time_epoch': 4.57732, 'loss': 0.07433714, 'lr': 0, 'params': 451793, 'time_iter': 0.03548, 'accuracy': 0.98395, 'precision': 0.71429, 'recall': 0.30864, 'f1': 0.43103, 'auc': 0.78284}
2025-07-04 23:48:09,105 - INFO - test: {'epoch': 27, 'time_epoch': 4.5822, 'loss': 0.11718999, 'lr': 0, 'params': 451793, 'time_iter': 0.03552, 'accuracy': 0.96937, 'precision': 0.54167, 'recall': 0.2, 'f1': 0.29213, 'auc': 0.77252}
2025-07-04 23:48:09,111 - INFO - > Epoch 27: took 90.2s (avg 90.1s) | Best so far: epoch 26	train_loss: 0.1229 train_auc: 0.8029	val_loss: 0.0751 val_auc: 0.8009	test_loss: 0.1212 test_auc: 0.7507
2025-07-04 23:49:29,861 - INFO - train: {'epoch': 28, 'time_epoch': 80.51341, 'eta': 5714.82997, 'eta_hours': 1.58745, 'loss': 0.12098643, 'lr': 8.622e-05, 'params': 451793, 'time_iter': 0.07824, 'accuracy': 0.96523, 'precision': 0.60891, 'recall': 0.19968, 'f1': 0.30073, 'auc': 0.81091}
2025-07-04 23:49:34,734 - INFO - val: {'epoch': 28, 'time_epoch': 4.83867, 'loss': 0.07413202, 'lr': 0, 'params': 451793, 'time_iter': 0.03751, 'accuracy': 0.98225, 'precision': 0.66667, 'recall': 0.19753, 'f1': 0.30476, 'auc': 0.80661}
2025-07-04 23:49:39,498 - INFO - test: {'epoch': 28, 'time_epoch': 4.74264, 'loss': 0.11572119, 'lr': 0, 'params': 451793, 'time_iter': 0.03676, 'accuracy': 0.96985, 'precision': 0.575, 'recall': 0.17692, 'f1': 0.27059, 'auc': 0.75568}
2025-07-04 23:49:39,501 - INFO - > Epoch 28: took 90.4s (avg 90.1s) | Best so far: epoch 28	train_loss: 0.1210 train_auc: 0.8109	val_loss: 0.0741 val_auc: 0.8066	test_loss: 0.1157 test_auc: 0.7557
2025-07-04 23:50:58,568 - INFO - train: {'epoch': 29, 'time_epoch': 78.88283, 'eta': 5630.58803, 'eta_hours': 1.56405, 'loss': 0.12023013, 'lr': 8.506e-05, 'params': 451793, 'time_iter': 0.07666, 'accuracy': 0.96496, 'precision': 0.5985, 'recall': 0.19481, 'f1': 0.29394, 'auc': 0.81589}
2025-07-04 23:51:03,177 - INFO - val: {'epoch': 29, 'time_epoch': 4.58013, 'loss': 0.07415524, 'lr': 0, 'params': 451793, 'time_iter': 0.0355, 'accuracy': 0.98298, 'precision': 0.73913, 'recall': 0.20988, 'f1': 0.32692, 'auc': 0.75982}
2025-07-04 23:51:07,729 - INFO - test: {'epoch': 29, 'time_epoch': 4.53055, 'loss': 0.1155317, 'lr': 0, 'params': 451793, 'time_iter': 0.03512, 'accuracy': 0.97082, 'precision': 0.625, 'recall': 0.19231, 'f1': 0.29412, 'auc': 0.75676}
2025-07-04 23:51:07,732 - INFO - > Epoch 29: took 88.2s (avg 90.1s) | Best so far: epoch 28	train_loss: 0.1210 train_auc: 0.8109	val_loss: 0.0741 val_auc: 0.8066	test_loss: 0.1157 test_auc: 0.7557
2025-07-04 23:52:27,355 - INFO - train: {'epoch': 30, 'time_epoch': 79.3796, 'eta': 5547.79755, 'eta_hours': 1.54105, 'loss': 0.11901166, 'lr': 8.386e-05, 'params': 451793, 'time_iter': 0.07714, 'accuracy': 0.96614, 'precision': 0.6385, 'recall': 0.22078, 'f1': 0.32811, 'auc': 0.82585}
2025-07-04 23:52:31,956 - INFO - val: {'epoch': 30, 'time_epoch': 4.56828, 'loss': 0.07323713, 'lr': 0, 'params': 451793, 'time_iter': 0.03541, 'accuracy': 0.98177, 'precision': 0.65, 'recall': 0.16049, 'f1': 0.25743, 'auc': 0.77773}
2025-07-04 23:52:36,542 - INFO - test: {'epoch': 30, 'time_epoch': 4.56376, 'loss': 0.11938499, 'lr': 0, 'params': 451793, 'time_iter': 0.03538, 'accuracy': 0.96912, 'precision': 0.56, 'recall': 0.10769, 'f1': 0.18065, 'auc': 0.75281}
2025-07-04 23:52:36,545 - INFO - > Epoch 30: took 88.8s (avg 90.0s) | Best so far: epoch 28	train_loss: 0.1210 train_auc: 0.8109	val_loss: 0.0741 val_auc: 0.8066	test_loss: 0.1157 test_auc: 0.7557
2025-07-04 23:53:55,392 - INFO - train: {'epoch': 31, 'time_epoch': 78.60527, 'eta': 5463.57479, 'eta_hours': 1.51766, 'loss': 0.11998028, 'lr': 8.263e-05, 'params': 451793, 'time_iter': 0.07639, 'accuracy': 0.9659, 'precision': 0.63285, 'recall': 0.21266, 'f1': 0.31835, 'auc': 0.81295}
2025-07-04 23:54:00,047 - INFO - val: {'epoch': 31, 'time_epoch': 4.62523, 'loss': 0.0732608, 'lr': 0, 'params': 451793, 'time_iter': 0.03585, 'accuracy': 0.98395, 'precision': 0.75862, 'recall': 0.2716, 'f1': 0.4, 'auc': 0.77656}
2025-07-04 23:54:04,696 - INFO - test: {'epoch': 31, 'time_epoch': 4.62633, 'loss': 0.11706141, 'lr': 0, 'params': 451793, 'time_iter': 0.03586, 'accuracy': 0.96864, 'precision': 0.51351, 'recall': 0.14615, 'f1': 0.22754, 'auc': 0.76268}
2025-07-04 23:54:04,698 - INFO - > Epoch 31: took 88.2s (avg 90.0s) | Best so far: epoch 28	train_loss: 0.1210 train_auc: 0.8109	val_loss: 0.0741 val_auc: 0.8066	test_loss: 0.1157 test_auc: 0.7557
2025-07-04 23:55:24,486 - INFO - train: {'epoch': 32, 'time_epoch': 79.59055, 'eta': 5381.69292, 'eta_hours': 1.49491, 'loss': 0.11847288, 'lr': 8.136e-05, 'params': 451793, 'time_iter': 0.07735, 'accuracy': 0.96663, 'precision': 0.64823, 'recall': 0.23782, 'f1': 0.34798, 'auc': 0.81687}
2025-07-04 23:55:29,149 - INFO - val: {'epoch': 32, 'time_epoch': 4.63392, 'loss': 0.07046013, 'lr': 0, 'params': 451793, 'time_iter': 0.03592, 'accuracy': 0.98347, 'precision': 0.70968, 'recall': 0.2716, 'f1': 0.39286, 'auc': 0.79698}
2025-07-04 23:55:33,823 - INFO - test: {'epoch': 32, 'time_epoch': 4.65202, 'loss': 0.11334015, 'lr': 0, 'params': 451793, 'time_iter': 0.03606, 'accuracy': 0.97204, 'precision': 0.68293, 'recall': 0.21538, 'f1': 0.32749, 'auc': 0.7684}
2025-07-04 23:55:33,826 - INFO - > Epoch 32: took 89.1s (avg 89.9s) | Best so far: epoch 28	train_loss: 0.1210 train_auc: 0.8109	val_loss: 0.0741 val_auc: 0.8066	test_loss: 0.1157 test_auc: 0.7557
2025-07-04 23:56:55,328 - INFO - train: {'epoch': 33, 'time_epoch': 81.29877, 'eta': 5303.26179, 'eta_hours': 1.47313, 'loss': 0.1173896, 'lr': 8.005e-05, 'params': 451793, 'time_iter': 0.07901, 'accuracy': 0.96763, 'precision': 0.68192, 'recall': 0.25406, 'f1': 0.3702, 'auc': 0.82248}
2025-07-04 23:57:00,209 - INFO - val: {'epoch': 33, 'time_epoch': 4.85095, 'loss': 0.06964282, 'lr': 0, 'params': 451793, 'time_iter': 0.0376, 'accuracy': 0.98322, 'precision': 0.73077, 'recall': 0.23457, 'f1': 0.35514, 'auc': 0.81774}
2025-07-04 23:57:05,099 - INFO - test: {'epoch': 33, 'time_epoch': 4.8672, 'loss': 0.11719725, 'lr': 0, 'params': 451793, 'time_iter': 0.03773, 'accuracy': 0.97034, 'precision': 0.63333, 'recall': 0.14615, 'f1': 0.2375, 'auc': 0.75448}
2025-07-04 23:57:05,102 - INFO - > Epoch 33: took 91.3s (avg 90.0s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-04 23:58:26,705 - INFO - train: {'epoch': 34, 'time_epoch': 81.40962, 'eta': 5224.87264, 'eta_hours': 1.45135, 'loss': 0.11718984, 'lr': 7.872e-05, 'params': 451793, 'time_iter': 0.07912, 'accuracy': 0.96602, 'precision': 0.62611, 'recall': 0.22971, 'f1': 0.3361, 'auc': 0.82735}
2025-07-04 23:58:31,570 - INFO - val: {'epoch': 34, 'time_epoch': 4.83373, 'loss': 0.07011677, 'lr': 0, 'params': 451793, 'time_iter': 0.03747, 'accuracy': 0.98347, 'precision': 0.72414, 'recall': 0.25926, 'f1': 0.38182, 'auc': 0.79992}
2025-07-04 23:58:36,471 - INFO - test: {'epoch': 34, 'time_epoch': 4.87429, 'loss': 0.11661091, 'lr': 0, 'params': 451793, 'time_iter': 0.03779, 'accuracy': 0.97131, 'precision': 0.65789, 'recall': 0.19231, 'f1': 0.29762, 'auc': 0.76055}
2025-07-04 23:58:36,476 - INFO - > Epoch 34: took 91.4s (avg 90.0s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-04 23:59:55,460 - INFO - train: {'epoch': 35, 'time_epoch': 78.76746, 'eta': 5141.61853, 'eta_hours': 1.42823, 'loss': 0.11563055, 'lr': 7.735e-05, 'params': 451793, 'time_iter': 0.07655, 'accuracy': 0.96821, 'precision': 0.6898, 'recall': 0.27435, 'f1': 0.39257, 'auc': 0.82548}
2025-07-05 00:00:00,082 - INFO - val: {'epoch': 35, 'time_epoch': 4.59457, 'loss': 0.07165788, 'lr': 0, 'params': 451793, 'time_iter': 0.03562, 'accuracy': 0.98395, 'precision': 0.74194, 'recall': 0.28395, 'f1': 0.41071, 'auc': 0.78317}
2025-07-05 00:00:04,684 - INFO - test: {'epoch': 35, 'time_epoch': 4.58035, 'loss': 0.11549225, 'lr': 0, 'params': 451793, 'time_iter': 0.03551, 'accuracy': 0.9718, 'precision': 0.64583, 'recall': 0.23846, 'f1': 0.34831, 'auc': 0.75319}
2025-07-05 00:00:04,688 - INFO - > Epoch 35: took 88.2s (avg 90.0s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:01:23,431 - INFO - train: {'epoch': 36, 'time_epoch': 78.51848, 'eta': 5058.18299, 'eta_hours': 1.40505, 'loss': 0.11738135, 'lr': 7.595e-05, 'params': 451793, 'time_iter': 0.07631, 'accuracy': 0.9662, 'precision': 0.63158, 'recall': 0.23377, 'f1': 0.34123, 'auc': 0.82584}
2025-07-05 00:01:27,999 - INFO - val: {'epoch': 36, 'time_epoch': 4.54078, 'loss': 0.07515353, 'lr': 0, 'params': 451793, 'time_iter': 0.0352, 'accuracy': 0.98225, 'precision': 0.65385, 'recall': 0.20988, 'f1': 0.31776, 'auc': 0.77992}
2025-07-05 00:01:32,601 - INFO - test: {'epoch': 36, 'time_epoch': 4.57717, 'loss': 0.1176077, 'lr': 0, 'params': 451793, 'time_iter': 0.03548, 'accuracy': 0.96766, 'precision': 0.45714, 'recall': 0.12308, 'f1': 0.19394, 'auc': 0.78342}
2025-07-05 00:01:32,604 - INFO - > Epoch 36: took 87.9s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:02:51,809 - INFO - train: {'epoch': 37, 'time_epoch': 79.01685, 'eta': 4975.81938, 'eta_hours': 1.38217, 'loss': 0.11471708, 'lr': 7.452e-05, 'params': 451793, 'time_iter': 0.07679, 'accuracy': 0.96702, 'precision': 0.65092, 'recall': 0.25731, 'f1': 0.36882, 'auc': 0.83623}
2025-07-05 00:02:56,526 - INFO - val: {'epoch': 37, 'time_epoch': 4.68518, 'loss': 0.06903613, 'lr': 0, 'params': 451793, 'time_iter': 0.03632, 'accuracy': 0.98395, 'precision': 0.82609, 'recall': 0.23457, 'f1': 0.36538, 'auc': 0.79777}
2025-07-05 00:03:01,215 - INFO - test: {'epoch': 37, 'time_epoch': 4.66423, 'loss': 0.11318947, 'lr': 0, 'params': 451793, 'time_iter': 0.03616, 'accuracy': 0.97204, 'precision': 0.65957, 'recall': 0.23846, 'f1': 0.35028, 'auc': 0.76178}
2025-07-05 00:03:01,360 - INFO - > Epoch 37: took 88.8s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:04:22,023 - INFO - train: {'epoch': 38, 'time_epoch': 80.44822, 'eta': 4895.86621, 'eta_hours': 1.35996, 'loss': 0.11504033, 'lr': 7.307e-05, 'params': 451793, 'time_iter': 0.07818, 'accuracy': 0.96711, 'precision': 0.65625, 'recall': 0.25568, 'f1': 0.36799, 'auc': 0.83471}
2025-07-05 00:04:26,744 - INFO - val: {'epoch': 38, 'time_epoch': 4.68819, 'loss': 0.0710674, 'lr': 0, 'params': 451793, 'time_iter': 0.03634, 'accuracy': 0.98347, 'precision': 0.66667, 'recall': 0.32099, 'f1': 0.43333, 'auc': 0.79865}
2025-07-05 00:04:31,430 - INFO - test: {'epoch': 38, 'time_epoch': 4.65882, 'loss': 0.11917815, 'lr': 0, 'params': 451793, 'time_iter': 0.03611, 'accuracy': 0.96669, 'precision': 0.4386, 'recall': 0.19231, 'f1': 0.26738, 'auc': 0.75502}
2025-07-05 00:04:31,435 - INFO - > Epoch 38: took 90.1s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:05:53,606 - INFO - train: {'epoch': 39, 'time_epoch': 81.95617, 'eta': 4818.15021, 'eta_hours': 1.33838, 'loss': 0.11452101, 'lr': 7.159e-05, 'params': 451793, 'time_iter': 0.07965, 'accuracy': 0.96739, 'precision': 0.65805, 'recall': 0.26867, 'f1': 0.38156, 'auc': 0.83356}
2025-07-05 00:05:58,469 - INFO - val: {'epoch': 39, 'time_epoch': 4.83304, 'loss': 0.07395267, 'lr': 0, 'params': 451793, 'time_iter': 0.03747, 'accuracy': 0.98152, 'precision': 0.55814, 'recall': 0.2963, 'f1': 0.3871, 'auc': 0.79943}
2025-07-05 00:06:03,305 - INFO - test: {'epoch': 39, 'time_epoch': 4.81331, 'loss': 0.11792042, 'lr': 0, 'params': 451793, 'time_iter': 0.03731, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.29231, 'f1': 0.36893, 'auc': 0.76073}
2025-07-05 00:06:03,308 - INFO - > Epoch 39: took 91.9s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:07:25,424 - INFO - train: {'epoch': 40, 'time_epoch': 81.88673, 'eta': 4740.12746, 'eta_hours': 1.3167, 'loss': 0.11334114, 'lr': 7.008e-05, 'params': 451793, 'time_iter': 0.07958, 'accuracy': 0.96766, 'precision': 0.66471, 'recall': 0.27516, 'f1': 0.38921, 'auc': 0.83402}
2025-07-05 00:07:30,035 - INFO - val: {'epoch': 40, 'time_epoch': 4.58242, 'loss': 0.07176917, 'lr': 0, 'params': 451793, 'time_iter': 0.03552, 'accuracy': 0.98201, 'precision': 0.6, 'recall': 0.25926, 'f1': 0.36207, 'auc': 0.80494}
2025-07-05 00:07:34,630 - INFO - test: {'epoch': 40, 'time_epoch': 4.5731, 'loss': 0.11678013, 'lr': 0, 'params': 451793, 'time_iter': 0.03545, 'accuracy': 0.96985, 'precision': 0.56, 'recall': 0.21538, 'f1': 0.31111, 'auc': 0.77229}
2025-07-05 00:07:34,633 - INFO - > Epoch 40: took 91.3s (avg 90.0s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:08:53,639 - INFO - train: {'epoch': 41, 'time_epoch': 78.78506, 'eta': 4657.63743, 'eta_hours': 1.29379, 'loss': 0.11311817, 'lr': 6.856e-05, 'params': 451793, 'time_iter': 0.07656, 'accuracy': 0.96796, 'precision': 0.67451, 'recall': 0.27922, 'f1': 0.39495, 'auc': 0.83903}
2025-07-05 00:08:58,411 - INFO - val: {'epoch': 41, 'time_epoch': 4.7434, 'loss': 0.0694803, 'lr': 0, 'params': 451793, 'time_iter': 0.03677, 'accuracy': 0.98249, 'precision': 0.66667, 'recall': 0.22222, 'f1': 0.33333, 'auc': 0.7897}
2025-07-05 00:09:03,112 - INFO - test: {'epoch': 41, 'time_epoch': 4.67448, 'loss': 0.11655278, 'lr': 0, 'params': 451793, 'time_iter': 0.03624, 'accuracy': 0.96864, 'precision': 0.51613, 'recall': 0.12308, 'f1': 0.19876, 'auc': 0.75159}
2025-07-05 00:09:03,123 - INFO - > Epoch 41: took 88.5s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:10:24,247 - INFO - train: {'epoch': 42, 'time_epoch': 80.90019, 'eta': 4578.1235, 'eta_hours': 1.2717, 'loss': 0.11253612, 'lr': 6.701e-05, 'params': 451793, 'time_iter': 0.07862, 'accuracy': 0.96769, 'precision': 0.66219, 'recall': 0.28003, 'f1': 0.39361, 'auc': 0.83929}
2025-07-05 00:10:28,945 - INFO - val: {'epoch': 42, 'time_epoch': 4.66374, 'loss': 0.07015687, 'lr': 0, 'params': 451793, 'time_iter': 0.03615, 'accuracy': 0.98225, 'precision': 0.65385, 'recall': 0.20988, 'f1': 0.31776, 'auc': 0.80153}
2025-07-05 00:10:33,639 - INFO - test: {'epoch': 42, 'time_epoch': 4.65445, 'loss': 0.11977073, 'lr': 0, 'params': 451793, 'time_iter': 0.03608, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.07692, 'f1': 0.13333, 'auc': 0.75996}
2025-07-05 00:10:33,660 - INFO - > Epoch 42: took 90.5s (avg 90.0s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:11:56,040 - INFO - train: {'epoch': 43, 'time_epoch': 82.18209, 'eta': 4500.17808, 'eta_hours': 1.25005, 'loss': 0.11193417, 'lr': 6.545e-05, 'params': 451793, 'time_iter': 0.07987, 'accuracy': 0.96854, 'precision': 0.68906, 'recall': 0.2914, 'f1': 0.40958, 'auc': 0.83827}
2025-07-05 00:12:01,069 - INFO - val: {'epoch': 43, 'time_epoch': 4.99937, 'loss': 0.07300504, 'lr': 0, 'params': 451793, 'time_iter': 0.03875, 'accuracy': 0.98322, 'precision': 0.6875, 'recall': 0.2716, 'f1': 0.38938, 'auc': 0.78204}
2025-07-05 00:12:05,938 - INFO - test: {'epoch': 43, 'time_epoch': 4.84639, 'loss': 0.11519753, 'lr': 0, 'params': 451793, 'time_iter': 0.03757, 'accuracy': 0.96961, 'precision': 0.54098, 'recall': 0.25385, 'f1': 0.34555, 'auc': 0.77265}
2025-07-05 00:12:05,941 - INFO - > Epoch 43: took 92.3s (avg 90.0s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:13:24,362 - INFO - train: {'epoch': 44, 'time_epoch': 78.21444, 'eta': 4417.19501, 'eta_hours': 1.227, 'loss': 0.11260265, 'lr': 6.387e-05, 'params': 451793, 'time_iter': 0.07601, 'accuracy': 0.96778, 'precision': 0.66732, 'recall': 0.27841, 'f1': 0.3929, 'auc': 0.8389}
2025-07-05 00:13:29,012 - INFO - val: {'epoch': 44, 'time_epoch': 4.62111, 'loss': 0.07174203, 'lr': 0, 'params': 451793, 'time_iter': 0.03582, 'accuracy': 0.98201, 'precision': 0.62963, 'recall': 0.20988, 'f1': 0.31481, 'auc': 0.79816}
2025-07-05 00:13:33,651 - INFO - test: {'epoch': 44, 'time_epoch': 4.61808, 'loss': 0.12087665, 'lr': 0, 'params': 451793, 'time_iter': 0.0358, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.10769, 'f1': 0.17722, 'auc': 0.75454}
2025-07-05 00:13:33,654 - INFO - > Epoch 44: took 87.7s (avg 90.0s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:14:55,437 - INFO - train: {'epoch': 45, 'time_epoch': 81.54684, 'eta': 4338.33122, 'eta_hours': 1.20509, 'loss': 0.1110436, 'lr': 6.227e-05, 'params': 451793, 'time_iter': 0.07925, 'accuracy': 0.96848, 'precision': 0.68932, 'recall': 0.28815, 'f1': 0.40641, 'auc': 0.8421}
2025-07-05 00:15:00,063 - INFO - val: {'epoch': 45, 'time_epoch': 4.59043, 'loss': 0.07128921, 'lr': 0, 'params': 451793, 'time_iter': 0.03558, 'accuracy': 0.98347, 'precision': 0.72414, 'recall': 0.25926, 'f1': 0.38182, 'auc': 0.78757}
2025-07-05 00:15:04,714 - INFO - test: {'epoch': 45, 'time_epoch': 4.62744, 'loss': 0.11570184, 'lr': 0, 'params': 451793, 'time_iter': 0.03587, 'accuracy': 0.97034, 'precision': 0.5625, 'recall': 0.27692, 'f1': 0.37113, 'auc': 0.74677}
2025-07-05 00:15:04,717 - INFO - > Epoch 45: took 91.1s (avg 90.0s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:16:23,850 - INFO - train: {'epoch': 46, 'time_epoch': 78.89497, 'eta': 4256.36286, 'eta_hours': 1.18232, 'loss': 0.11082041, 'lr': 6.066e-05, 'params': 451793, 'time_iter': 0.07667, 'accuracy': 0.96888, 'precision': 0.68638, 'recall': 0.31088, 'f1': 0.42793, 'auc': 0.84309}
2025-07-05 00:16:28,460 - INFO - val: {'epoch': 46, 'time_epoch': 4.57625, 'loss': 0.07594377, 'lr': 0, 'params': 451793, 'time_iter': 0.03547, 'accuracy': 0.98079, 'precision': 0.51724, 'recall': 0.37037, 'f1': 0.43165, 'auc': 0.78768}
2025-07-05 00:16:33,031 - INFO - test: {'epoch': 46, 'time_epoch': 4.548, 'loss': 0.11941504, 'lr': 0, 'params': 451793, 'time_iter': 0.03526, 'accuracy': 0.96548, 'precision': 0.43878, 'recall': 0.33077, 'f1': 0.37719, 'auc': 0.76567}
2025-07-05 00:16:33,034 - INFO - > Epoch 46: took 88.3s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:17:52,155 - INFO - train: {'epoch': 47, 'time_epoch': 78.8762, 'eta': 4174.50222, 'eta_hours': 1.15958, 'loss': 0.11083885, 'lr': 5.904e-05, 'params': 451793, 'time_iter': 0.07665, 'accuracy': 0.96836, 'precision': 0.67985, 'recall': 0.29302, 'f1': 0.40953, 'auc': 0.8465}
2025-07-05 00:17:56,801 - INFO - val: {'epoch': 47, 'time_epoch': 4.6178, 'loss': 0.07040892, 'lr': 0, 'params': 451793, 'time_iter': 0.0358, 'accuracy': 0.98322, 'precision': 0.62, 'recall': 0.38272, 'f1': 0.47328, 'auc': 0.79726}
2025-07-05 00:18:01,410 - INFO - test: {'epoch': 47, 'time_epoch': 4.58396, 'loss': 0.11671103, 'lr': 0, 'params': 451793, 'time_iter': 0.03553, 'accuracy': 0.96937, 'precision': 0.53448, 'recall': 0.23846, 'f1': 0.32979, 'auc': 0.76955}
2025-07-05 00:18:01,413 - INFO - > Epoch 47: took 88.4s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:19:21,179 - INFO - train: {'epoch': 48, 'time_epoch': 79.49451, 'eta': 4093.40694, 'eta_hours': 1.13706, 'loss': 0.11097797, 'lr': 5.741e-05, 'params': 451793, 'time_iter': 0.07725, 'accuracy': 0.96891, 'precision': 0.69174, 'recall': 0.30601, 'f1': 0.42431, 'auc': 0.84142}
2025-07-05 00:19:25,861 - INFO - val: {'epoch': 48, 'time_epoch': 4.65153, 'loss': 0.07165602, 'lr': 0, 'params': 451793, 'time_iter': 0.03606, 'accuracy': 0.98395, 'precision': 0.69231, 'recall': 0.33333, 'f1': 0.45, 'auc': 0.8091}
2025-07-05 00:19:30,479 - INFO - test: {'epoch': 48, 'time_epoch': 4.59261, 'loss': 0.11866113, 'lr': 0, 'params': 451793, 'time_iter': 0.0356, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.23077, 'f1': 0.31579, 'auc': 0.76319}
2025-07-05 00:19:30,482 - INFO - > Epoch 48: took 89.1s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:20:50,839 - INFO - train: {'epoch': 49, 'time_epoch': 80.12453, 'eta': 4013.0057, 'eta_hours': 1.11472, 'loss': 0.1096261, 'lr': 5.577e-05, 'params': 451793, 'time_iter': 0.07787, 'accuracy': 0.96903, 'precision': 0.70841, 'recall': 0.29383, 'f1': 0.41538, 'auc': 0.85239}
2025-07-05 00:20:55,551 - INFO - val: {'epoch': 49, 'time_epoch': 4.67999, 'loss': 0.07043824, 'lr': 0, 'params': 451793, 'time_iter': 0.03628, 'accuracy': 0.98371, 'precision': 0.65217, 'recall': 0.37037, 'f1': 0.47244, 'auc': 0.81213}
2025-07-05 00:21:00,335 - INFO - test: {'epoch': 49, 'time_epoch': 4.76056, 'loss': 0.11931482, 'lr': 0, 'params': 451793, 'time_iter': 0.0369, 'accuracy': 0.96669, 'precision': 0.45977, 'recall': 0.30769, 'f1': 0.36866, 'auc': 0.77205}
2025-07-05 00:21:00,338 - INFO - > Epoch 49: took 89.9s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:22:23,014 - INFO - train: {'epoch': 50, 'time_epoch': 82.45413, 'eta': 3934.85356, 'eta_hours': 1.09301, 'loss': 0.1098954, 'lr': 5.413e-05, 'params': 451793, 'time_iter': 0.08013, 'accuracy': 0.96891, 'precision': 0.68366, 'recall': 0.31575, 'f1': 0.43198, 'auc': 0.8488}
2025-07-05 00:22:27,891 - INFO - val: {'epoch': 50, 'time_epoch': 4.83392, 'loss': 0.07031543, 'lr': 0, 'params': 451793, 'time_iter': 0.03747, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.80423}
2025-07-05 00:22:32,821 - INFO - test: {'epoch': 50, 'time_epoch': 4.90789, 'loss': 0.11790402, 'lr': 0, 'params': 451793, 'time_iter': 0.03805, 'accuracy': 0.96693, 'precision': 0.45714, 'recall': 0.24615, 'f1': 0.32, 'auc': 0.76836}
2025-07-05 00:22:32,824 - INFO - > Epoch 50: took 92.5s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:23:55,406 - INFO - train: {'epoch': 51, 'time_epoch': 82.37188, 'eta': 3856.46004, 'eta_hours': 1.07124, 'loss': 0.10847069, 'lr': 5.248e-05, 'params': 451793, 'time_iter': 0.08005, 'accuracy': 0.96921, 'precision': 0.70621, 'recall': 0.30438, 'f1': 0.42541, 'auc': 0.85458}
2025-07-05 00:24:00,109 - INFO - val: {'epoch': 51, 'time_epoch': 4.67364, 'loss': 0.07110609, 'lr': 0, 'params': 451793, 'time_iter': 0.03623, 'accuracy': 0.98395, 'precision': 0.68293, 'recall': 0.34568, 'f1': 0.45902, 'auc': 0.80417}
2025-07-05 00:24:04,775 - INFO - test: {'epoch': 51, 'time_epoch': 4.64477, 'loss': 0.11655395, 'lr': 0, 'params': 451793, 'time_iter': 0.03601, 'accuracy': 0.96864, 'precision': 0.50704, 'recall': 0.27692, 'f1': 0.35821, 'auc': 0.76962}
2025-07-05 00:24:04,778 - INFO - > Epoch 51: took 92.0s (avg 90.0s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:25:23,809 - INFO - train: {'epoch': 52, 'time_epoch': 78.79815, 'eta': 3774.74723, 'eta_hours': 1.04854, 'loss': 0.10852085, 'lr': 5.083e-05, 'params': 451793, 'time_iter': 0.07658, 'accuracy': 0.96888, 'precision': 0.69048, 'recall': 0.30601, 'f1': 0.42407, 'auc': 0.85455}
2025-07-05 00:25:28,398 - INFO - val: {'epoch': 52, 'time_epoch': 4.56067, 'loss': 0.06973079, 'lr': 0, 'params': 451793, 'time_iter': 0.03535, 'accuracy': 0.98322, 'precision': 0.6875, 'recall': 0.2716, 'f1': 0.38938, 'auc': 0.79844}
2025-07-05 00:25:32,968 - INFO - test: {'epoch': 52, 'time_epoch': 4.54861, 'loss': 0.11537076, 'lr': 0, 'params': 451793, 'time_iter': 0.03526, 'accuracy': 0.97009, 'precision': 0.55738, 'recall': 0.26154, 'f1': 0.35602, 'auc': 0.7739}
2025-07-05 00:25:32,971 - INFO - > Epoch 52: took 88.2s (avg 90.0s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:26:51,466 - INFO - train: {'epoch': 53, 'time_epoch': 78.25836, 'eta': 3692.68255, 'eta_hours': 1.02575, 'loss': 0.10847056, 'lr': 4.917e-05, 'params': 451793, 'time_iter': 0.07605, 'accuracy': 0.96933, 'precision': 0.69946, 'recall': 0.31737, 'f1': 0.43663, 'auc': 0.85268}
2025-07-05 00:26:56,056 - INFO - val: {'epoch': 53, 'time_epoch': 4.56204, 'loss': 0.07011809, 'lr': 0, 'params': 451793, 'time_iter': 0.03536, 'accuracy': 0.98274, 'precision': 0.69231, 'recall': 0.22222, 'f1': 0.33645, 'auc': 0.80302}
2025-07-05 00:27:00,670 - INFO - test: {'epoch': 53, 'time_epoch': 4.59327, 'loss': 0.11617327, 'lr': 0, 'params': 451793, 'time_iter': 0.03561, 'accuracy': 0.97082, 'precision': 0.65625, 'recall': 0.16154, 'f1': 0.25926, 'auc': 0.76324}
2025-07-05 00:27:00,673 - INFO - > Epoch 53: took 87.7s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:28:20,249 - INFO - train: {'epoch': 54, 'time_epoch': 79.37615, 'eta': 3611.67085, 'eta_hours': 1.00324, 'loss': 0.10879701, 'lr': 4.752e-05, 'params': 451793, 'time_iter': 0.07714, 'accuracy': 0.96973, 'precision': 0.72433, 'recall': 0.30925, 'f1': 0.43345, 'auc': 0.849}
2025-07-05 00:28:25,013 - INFO - val: {'epoch': 54, 'time_epoch': 4.72957, 'loss': 0.07129953, 'lr': 0, 'params': 451793, 'time_iter': 0.03666, 'accuracy': 0.98225, 'precision': 0.625, 'recall': 0.24691, 'f1': 0.35398, 'auc': 0.7959}
2025-07-05 00:28:29,743 - INFO - test: {'epoch': 54, 'time_epoch': 4.70373, 'loss': 0.11929607, 'lr': 0, 'params': 451793, 'time_iter': 0.03646, 'accuracy': 0.96985, 'precision': 0.56, 'recall': 0.21538, 'f1': 0.31111, 'auc': 0.75956}
2025-07-05 00:28:29,746 - INFO - > Epoch 54: took 89.1s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:29:49,789 - INFO - train: {'epoch': 55, 'time_epoch': 79.83784, 'eta': 3531.08031, 'eta_hours': 0.98086, 'loss': 0.10798462, 'lr': 4.587e-05, 'params': 451793, 'time_iter': 0.07759, 'accuracy': 0.96933, 'precision': 0.69735, 'recall': 0.31981, 'f1': 0.43851, 'auc': 0.86062}
2025-07-05 00:29:54,514 - INFO - val: {'epoch': 55, 'time_epoch': 4.69671, 'loss': 0.07260609, 'lr': 0, 'params': 451793, 'time_iter': 0.03641, 'accuracy': 0.98104, 'precision': 0.54054, 'recall': 0.24691, 'f1': 0.33898, 'auc': 0.79171}
2025-07-05 00:29:59,163 - INFO - test: {'epoch': 55, 'time_epoch': 4.62195, 'loss': 0.12117616, 'lr': 0, 'params': 451793, 'time_iter': 0.03583, 'accuracy': 0.96864, 'precision': 0.5098, 'recall': 0.2, 'f1': 0.28729, 'auc': 0.74585}
2025-07-05 00:29:59,168 - INFO - > Epoch 55: took 89.4s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:31:21,300 - INFO - train: {'epoch': 56, 'time_epoch': 81.92615, 'eta': 3452.09157, 'eta_hours': 0.95891, 'loss': 0.10733618, 'lr': 4.423e-05, 'params': 451793, 'time_iter': 0.07962, 'accuracy': 0.96982, 'precision': 0.70783, 'recall': 0.33036, 'f1': 0.45047, 'auc': 0.8563}
2025-07-05 00:31:26,171 - INFO - val: {'epoch': 56, 'time_epoch': 4.83939, 'loss': 0.07070241, 'lr': 0, 'params': 451793, 'time_iter': 0.03751, 'accuracy': 0.98201, 'precision': 0.60606, 'recall': 0.24691, 'f1': 0.35088, 'auc': 0.79361}
2025-07-05 00:31:31,023 - INFO - test: {'epoch': 56, 'time_epoch': 4.83068, 'loss': 0.11638953, 'lr': 0, 'params': 451793, 'time_iter': 0.03745, 'accuracy': 0.97034, 'precision': 0.57407, 'recall': 0.23846, 'f1': 0.33696, 'auc': 0.7673}
2025-07-05 00:31:31,026 - INFO - > Epoch 56: took 91.9s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:32:52,926 - INFO - train: {'epoch': 57, 'time_epoch': 81.67763, 'eta': 3372.82158, 'eta_hours': 0.93689, 'loss': 0.10645405, 'lr': 4.259e-05, 'params': 451793, 'time_iter': 0.07938, 'accuracy': 0.96976, 'precision': 0.71199, 'recall': 0.32305, 'f1': 0.44444, 'auc': 0.8602}
2025-07-05 00:32:57,544 - INFO - val: {'epoch': 57, 'time_epoch': 4.58929, 'loss': 0.07186499, 'lr': 0, 'params': 451793, 'time_iter': 0.03558, 'accuracy': 0.98298, 'precision': 0.67742, 'recall': 0.25926, 'f1': 0.375, 'auc': 0.79727}
2025-07-05 00:33:02,133 - INFO - test: {'epoch': 57, 'time_epoch': 4.5683, 'loss': 0.1158135, 'lr': 0, 'params': 451793, 'time_iter': 0.03541, 'accuracy': 0.97107, 'precision': 0.59016, 'recall': 0.27692, 'f1': 0.37696, 'auc': 0.76614}
2025-07-05 00:33:02,136 - INFO - > Epoch 57: took 91.1s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:34:22,143 - INFO - train: {'epoch': 58, 'time_epoch': 79.77986, 'eta': 3292.15119, 'eta_hours': 0.91449, 'loss': 0.10567987, 'lr': 4.096e-05, 'params': 451793, 'time_iter': 0.07753, 'accuracy': 0.97061, 'precision': 0.7242, 'recall': 0.3474, 'f1': 0.46956, 'auc': 0.86123}
2025-07-05 00:34:26,854 - INFO - val: {'epoch': 58, 'time_epoch': 4.68145, 'loss': 0.06966792, 'lr': 0, 'params': 451793, 'time_iter': 0.03629, 'accuracy': 0.98371, 'precision': 0.75, 'recall': 0.25926, 'f1': 0.38532, 'auc': 0.78765}
2025-07-05 00:34:31,634 - INFO - test: {'epoch': 58, 'time_epoch': 4.75741, 'loss': 0.1149389, 'lr': 0, 'params': 451793, 'time_iter': 0.03688, 'accuracy': 0.97253, 'precision': 0.71795, 'recall': 0.21538, 'f1': 0.33136, 'auc': 0.75052}
2025-07-05 00:34:31,731 - INFO - > Epoch 58: took 89.6s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:35:53,667 - INFO - train: {'epoch': 59, 'time_epoch': 81.72752, 'eta': 3212.80891, 'eta_hours': 0.89245, 'loss': 0.10566781, 'lr': 3.934e-05, 'params': 451793, 'time_iter': 0.07942, 'accuracy': 0.96988, 'precision': 0.70598, 'recall': 0.33523, 'f1': 0.4546, 'auc': 0.86178}
2025-07-05 00:35:58,506 - INFO - val: {'epoch': 59, 'time_epoch': 4.80831, 'loss': 0.07002004, 'lr': 0, 'params': 451793, 'time_iter': 0.03727, 'accuracy': 0.98347, 'precision': 0.74074, 'recall': 0.24691, 'f1': 0.37037, 'auc': 0.78218}
2025-07-05 00:36:03,341 - INFO - test: {'epoch': 59, 'time_epoch': 4.81231, 'loss': 0.11655453, 'lr': 0, 'params': 451793, 'time_iter': 0.0373, 'accuracy': 0.97228, 'precision': 0.67391, 'recall': 0.23846, 'f1': 0.35227, 'auc': 0.76016}
2025-07-05 00:36:03,344 - INFO - > Epoch 59: took 91.6s (avg 90.0s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:37:24,070 - INFO - train: {'epoch': 60, 'time_epoch': 80.51425, 'eta': 3132.61274, 'eta_hours': 0.87017, 'loss': 0.10547777, 'lr': 3.773e-05, 'params': 451793, 'time_iter': 0.07825, 'accuracy': 0.96964, 'precision': 0.70693, 'recall': 0.32305, 'f1': 0.44345, 'auc': 0.86854}
2025-07-05 00:37:28,651 - INFO - val: {'epoch': 60, 'time_epoch': 4.55292, 'loss': 0.07188625, 'lr': 0, 'params': 451793, 'time_iter': 0.03529, 'accuracy': 0.98298, 'precision': 0.67742, 'recall': 0.25926, 'f1': 0.375, 'auc': 0.78605}
2025-07-05 00:37:33,257 - INFO - test: {'epoch': 60, 'time_epoch': 4.58385, 'loss': 0.11490581, 'lr': 0, 'params': 451793, 'time_iter': 0.03553, 'accuracy': 0.97107, 'precision': 0.62222, 'recall': 0.21538, 'f1': 0.32, 'auc': 0.77044}
2025-07-05 00:37:33,259 - INFO - > Epoch 60: took 89.9s (avg 90.0s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:38:54,038 - INFO - train: {'epoch': 61, 'time_epoch': 80.55347, 'eta': 3052.43035, 'eta_hours': 0.8479, 'loss': 0.10441265, 'lr': 3.613e-05, 'params': 451793, 'time_iter': 0.07828, 'accuracy': 0.97049, 'precision': 0.72007, 'recall': 0.34659, 'f1': 0.46795, 'auc': 0.86513}
2025-07-05 00:38:58,669 - INFO - val: {'epoch': 61, 'time_epoch': 4.60223, 'loss': 0.07237543, 'lr': 0, 'params': 451793, 'time_iter': 0.03568, 'accuracy': 0.98225, 'precision': 0.61111, 'recall': 0.2716, 'f1': 0.37607, 'auc': 0.78662}
2025-07-05 00:39:03,293 - INFO - test: {'epoch': 61, 'time_epoch': 4.59986, 'loss': 0.11753333, 'lr': 0, 'params': 451793, 'time_iter': 0.03566, 'accuracy': 0.97058, 'precision': 0.58824, 'recall': 0.23077, 'f1': 0.33149, 'auc': 0.76832}
2025-07-05 00:39:03,345 - INFO - > Epoch 61: took 90.1s (avg 90.0s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:40:22,396 - INFO - train: {'epoch': 62, 'time_epoch': 78.85594, 'eta': 2971.23921, 'eta_hours': 0.82534, 'loss': 0.10541922, 'lr': 3.455e-05, 'params': 451793, 'time_iter': 0.07663, 'accuracy': 0.97061, 'precision': 0.73619, 'recall': 0.33523, 'f1': 0.46068, 'auc': 0.86255}
2025-07-05 00:40:26,973 - INFO - val: {'epoch': 62, 'time_epoch': 4.54899, 'loss': 0.07145279, 'lr': 0, 'params': 451793, 'time_iter': 0.03526, 'accuracy': 0.98177, 'precision': 0.57895, 'recall': 0.2716, 'f1': 0.36975, 'auc': 0.78021}
2025-07-05 00:40:31,537 - INFO - test: {'epoch': 62, 'time_epoch': 4.54108, 'loss': 0.11718114, 'lr': 0, 'params': 451793, 'time_iter': 0.0352, 'accuracy': 0.96937, 'precision': 0.53448, 'recall': 0.23846, 'f1': 0.32979, 'auc': 0.76416}
2025-07-05 00:40:31,540 - INFO - > Epoch 62: took 88.2s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:41:50,704 - INFO - train: {'epoch': 63, 'time_epoch': 78.9507, 'eta': 2890.17436, 'eta_hours': 0.80283, 'loss': 0.10338211, 'lr': 3.299e-05, 'params': 451793, 'time_iter': 0.07673, 'accuracy': 0.97003, 'precision': 0.70847, 'recall': 0.33929, 'f1': 0.45884, 'auc': 0.87327}
2025-07-05 00:41:55,314 - INFO - val: {'epoch': 63, 'time_epoch': 4.57999, 'loss': 0.0726714, 'lr': 0, 'params': 451793, 'time_iter': 0.0355, 'accuracy': 0.98104, 'precision': 0.53659, 'recall': 0.2716, 'f1': 0.36066, 'auc': 0.77081}
2025-07-05 00:41:59,905 - INFO - test: {'epoch': 63, 'time_epoch': 4.56755, 'loss': 0.11882256, 'lr': 0, 'params': 451793, 'time_iter': 0.03541, 'accuracy': 0.96912, 'precision': 0.52459, 'recall': 0.24615, 'f1': 0.33508, 'auc': 0.75494}
2025-07-05 00:41:59,918 - INFO - > Epoch 63: took 88.4s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:43:19,188 - INFO - train: {'epoch': 64, 'time_epoch': 79.07071, 'eta': 2809.23916, 'eta_hours': 0.78034, 'loss': 0.10484242, 'lr': 3.144e-05, 'params': 451793, 'time_iter': 0.07684, 'accuracy': 0.97061, 'precision': 0.72496, 'recall': 0.34659, 'f1': 0.46897, 'auc': 0.86257}
2025-07-05 00:43:23,806 - INFO - val: {'epoch': 64, 'time_epoch': 4.58545, 'loss': 0.07210896, 'lr': 0, 'params': 451793, 'time_iter': 0.03555, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.77584}
2025-07-05 00:43:28,437 - INFO - test: {'epoch': 64, 'time_epoch': 4.60839, 'loss': 0.11548438, 'lr': 0, 'params': 451793, 'time_iter': 0.03572, 'accuracy': 0.97082, 'precision': 0.58929, 'recall': 0.25385, 'f1': 0.35484, 'auc': 0.76289}
2025-07-05 00:43:28,441 - INFO - > Epoch 64: took 88.5s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:44:48,528 - INFO - train: {'epoch': 65, 'time_epoch': 79.90234, 'eta': 2728.78889, 'eta_hours': 0.758, 'loss': 0.10411467, 'lr': 2.992e-05, 'params': 451793, 'time_iter': 0.07765, 'accuracy': 0.97085, 'precision': 0.74159, 'recall': 0.3401, 'f1': 0.46633, 'auc': 0.86511}
2025-07-05 00:44:53,239 - INFO - val: {'epoch': 65, 'time_epoch': 4.68257, 'loss': 0.07147161, 'lr': 0, 'params': 451793, 'time_iter': 0.0363, 'accuracy': 0.98201, 'precision': 0.59459, 'recall': 0.2716, 'f1': 0.37288, 'auc': 0.79127}
2025-07-05 00:44:57,975 - INFO - test: {'epoch': 65, 'time_epoch': 4.71304, 'loss': 0.11882177, 'lr': 0, 'params': 451793, 'time_iter': 0.03654, 'accuracy': 0.96961, 'precision': 0.54098, 'recall': 0.25385, 'f1': 0.34555, 'auc': 0.77496}
2025-07-05 00:44:57,977 - INFO - > Epoch 65: took 89.5s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:46:21,129 - INFO - train: {'epoch': 66, 'time_epoch': 82.93996, 'eta': 2649.85111, 'eta_hours': 0.73607, 'loss': 0.10340355, 'lr': 2.841e-05, 'params': 451793, 'time_iter': 0.0806, 'accuracy': 0.97055, 'precision': 0.72326, 'recall': 0.34578, 'f1': 0.46787, 'auc': 0.86939}
2025-07-05 00:46:25,967 - INFO - val: {'epoch': 66, 'time_epoch': 4.80982, 'loss': 0.0742506, 'lr': 0, 'params': 451793, 'time_iter': 0.03729, 'accuracy': 0.97982, 'precision': 0.47826, 'recall': 0.2716, 'f1': 0.34646, 'auc': 0.77813}
2025-07-05 00:46:30,847 - INFO - test: {'epoch': 66, 'time_epoch': 4.85434, 'loss': 0.12048125, 'lr': 0, 'params': 451793, 'time_iter': 0.03763, 'accuracy': 0.96572, 'precision': 0.4321, 'recall': 0.26923, 'f1': 0.33175, 'auc': 0.77279}
2025-07-05 00:46:30,852 - INFO - > Epoch 66: took 92.9s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:47:51,197 - INFO - train: {'epoch': 67, 'time_epoch': 80.09373, 'eta': 2569.45622, 'eta_hours': 0.71374, 'loss': 0.10240074, 'lr': 2.693e-05, 'params': 451793, 'time_iter': 0.07784, 'accuracy': 0.97088, 'precision': 0.73951, 'recall': 0.34334, 'f1': 0.46896, 'auc': 0.87342}
2025-07-05 00:47:55,813 - INFO - val: {'epoch': 67, 'time_epoch': 4.58746, 'loss': 0.06990841, 'lr': 0, 'params': 451793, 'time_iter': 0.03556, 'accuracy': 0.98201, 'precision': 0.6129, 'recall': 0.23457, 'f1': 0.33929, 'auc': 0.78831}
2025-07-05 00:48:00,398 - INFO - test: {'epoch': 67, 'time_epoch': 4.56204, 'loss': 0.11719048, 'lr': 0, 'params': 451793, 'time_iter': 0.03536, 'accuracy': 0.97009, 'precision': 0.5814, 'recall': 0.19231, 'f1': 0.28902, 'auc': 0.76428}
2025-07-05 00:48:00,400 - INFO - > Epoch 67: took 89.5s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:49:19,004 - INFO - train: {'epoch': 68, 'time_epoch': 78.38813, 'eta': 2488.30378, 'eta_hours': 0.6912, 'loss': 0.10405688, 'lr': 2.548e-05, 'params': 451793, 'time_iter': 0.07618, 'accuracy': 0.97037, 'precision': 0.72348, 'recall': 0.33766, 'f1': 0.46043, 'auc': 0.86801}
2025-07-05 00:49:23,600 - INFO - val: {'epoch': 68, 'time_epoch': 4.56798, 'loss': 0.07151246, 'lr': 0, 'params': 451793, 'time_iter': 0.03541, 'accuracy': 0.98274, 'precision': 0.66667, 'recall': 0.24691, 'f1': 0.36036, 'auc': 0.78518}
2025-07-05 00:49:28,163 - INFO - test: {'epoch': 68, 'time_epoch': 4.54174, 'loss': 0.11917795, 'lr': 0, 'params': 451793, 'time_iter': 0.03521, 'accuracy': 0.97107, 'precision': 0.62791, 'recall': 0.20769, 'f1': 0.31214, 'auc': 0.76395}
2025-07-05 00:49:28,166 - INFO - > Epoch 68: took 87.8s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:50:47,308 - INFO - train: {'epoch': 69, 'time_epoch': 78.92537, 'eta': 2407.46056, 'eta_hours': 0.66874, 'loss': 0.10157925, 'lr': 2.405e-05, 'params': 451793, 'time_iter': 0.0767, 'accuracy': 0.9714, 'precision': 0.75482, 'recall': 0.34984, 'f1': 0.47809, 'auc': 0.877}
2025-07-05 00:50:51,912 - INFO - val: {'epoch': 69, 'time_epoch': 4.57562, 'loss': 0.07150713, 'lr': 0, 'params': 451793, 'time_iter': 0.03547, 'accuracy': 0.98152, 'precision': 0.56757, 'recall': 0.25926, 'f1': 0.35593, 'auc': 0.78376}
2025-07-05 00:50:56,501 - INFO - test: {'epoch': 69, 'time_epoch': 4.56712, 'loss': 0.11686042, 'lr': 0, 'params': 451793, 'time_iter': 0.0354, 'accuracy': 0.97082, 'precision': 0.59615, 'recall': 0.23846, 'f1': 0.34066, 'auc': 0.7758}
2025-07-05 00:50:56,504 - INFO - > Epoch 69: took 88.3s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:52:17,281 - INFO - train: {'epoch': 70, 'time_epoch': 80.56393, 'eta': 2327.34064, 'eta_hours': 0.64648, 'loss': 0.10272498, 'lr': 2.265e-05, 'params': 451793, 'time_iter': 0.07829, 'accuracy': 0.9711, 'precision': 0.73378, 'recall': 0.35795, 'f1': 0.48118, 'auc': 0.87344}
2025-07-05 00:52:21,957 - INFO - val: {'epoch': 70, 'time_epoch': 4.64708, 'loss': 0.07241417, 'lr': 0, 'params': 451793, 'time_iter': 0.03602, 'accuracy': 0.98249, 'precision': 0.64516, 'recall': 0.24691, 'f1': 0.35714, 'auc': 0.78586}
2025-07-05 00:52:26,629 - INFO - test: {'epoch': 70, 'time_epoch': 4.64849, 'loss': 0.11691443, 'lr': 0, 'params': 451793, 'time_iter': 0.03603, 'accuracy': 0.97058, 'precision': 0.59574, 'recall': 0.21538, 'f1': 0.31638, 'auc': 0.76953}
2025-07-05 00:52:26,634 - INFO - > Epoch 70: took 90.1s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:53:47,638 - INFO - train: {'epoch': 71, 'time_epoch': 80.76668, 'eta': 2247.28723, 'eta_hours': 0.62425, 'loss': 0.10289613, 'lr': 2.128e-05, 'params': 451793, 'time_iter': 0.07849, 'accuracy': 0.97134, 'precision': 0.74701, 'recall': 0.35471, 'f1': 0.48101, 'auc': 0.87002}
2025-07-05 00:53:52,556 - INFO - val: {'epoch': 71, 'time_epoch': 4.88926, 'loss': 0.07224854, 'lr': 0, 'params': 451793, 'time_iter': 0.0379, 'accuracy': 0.98298, 'precision': 0.67742, 'recall': 0.25926, 'f1': 0.375, 'auc': 0.78353}
2025-07-05 00:53:57,376 - INFO - test: {'epoch': 71, 'time_epoch': 4.79831, 'loss': 0.1168997, 'lr': 0, 'params': 451793, 'time_iter': 0.0372, 'accuracy': 0.97131, 'precision': 0.61538, 'recall': 0.24615, 'f1': 0.35165, 'auc': 0.76827}
2025-07-05 00:53:57,379 - INFO - > Epoch 71: took 90.7s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:55:20,786 - INFO - train: {'epoch': 72, 'time_epoch': 83.20708, 'eta': 2168.11689, 'eta_hours': 0.60225, 'loss': 0.10124179, 'lr': 1.995e-05, 'params': 451793, 'time_iter': 0.08086, 'accuracy': 0.97167, 'precision': 0.75597, 'recall': 0.35958, 'f1': 0.48735, 'auc': 0.87678}
2025-07-05 00:55:25,390 - INFO - val: {'epoch': 72, 'time_epoch': 4.57435, 'loss': 0.06941288, 'lr': 0, 'params': 451793, 'time_iter': 0.03546, 'accuracy': 0.98371, 'precision': 0.79167, 'recall': 0.23457, 'f1': 0.3619, 'auc': 0.78586}
2025-07-05 00:55:29,904 - INFO - test: {'epoch': 72, 'time_epoch': 4.49309, 'loss': 0.11652334, 'lr': 0, 'params': 451793, 'time_iter': 0.03483, 'accuracy': 0.9718, 'precision': 0.65909, 'recall': 0.22308, 'f1': 0.33333, 'auc': 0.76948}
2025-07-05 00:55:29,906 - INFO - > Epoch 72: took 92.5s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:56:48,881 - INFO - train: {'epoch': 73, 'time_epoch': 78.74459, 'eta': 2087.26955, 'eta_hours': 0.5798, 'loss': 0.10176133, 'lr': 1.864e-05, 'params': 451793, 'time_iter': 0.07653, 'accuracy': 0.971, 'precision': 0.72787, 'recall': 0.36039, 'f1': 0.48208, 'auc': 0.87661}
2025-07-05 00:56:53,521 - INFO - val: {'epoch': 73, 'time_epoch': 4.61132, 'loss': 0.07145273, 'lr': 0, 'params': 451793, 'time_iter': 0.03575, 'accuracy': 0.98298, 'precision': 0.68966, 'recall': 0.24691, 'f1': 0.36364, 'auc': 0.78092}
2025-07-05 00:56:58,158 - INFO - test: {'epoch': 73, 'time_epoch': 4.61603, 'loss': 0.11862872, 'lr': 0, 'params': 451793, 'time_iter': 0.03578, 'accuracy': 0.97107, 'precision': 0.60377, 'recall': 0.24615, 'f1': 0.34973, 'auc': 0.76717}
2025-07-05 00:56:58,161 - INFO - > Epoch 73: took 88.3s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:58:19,584 - INFO - train: {'epoch': 74, 'time_epoch': 81.18477, 'eta': 2007.29168, 'eta_hours': 0.55758, 'loss': 0.10157576, 'lr': 1.737e-05, 'params': 451793, 'time_iter': 0.0789, 'accuracy': 0.97122, 'precision': 0.7403, 'recall': 0.35633, 'f1': 0.4811, 'auc': 0.87565}
2025-07-05 00:58:24,510 - INFO - val: {'epoch': 74, 'time_epoch': 4.89751, 'loss': 0.07324083, 'lr': 0, 'params': 451793, 'time_iter': 0.03797, 'accuracy': 0.98274, 'precision': 0.69231, 'recall': 0.22222, 'f1': 0.33645, 'auc': 0.7729}
2025-07-05 00:58:29,348 - INFO - test: {'epoch': 74, 'time_epoch': 4.81089, 'loss': 0.11816175, 'lr': 0, 'params': 451793, 'time_iter': 0.03729, 'accuracy': 0.96961, 'precision': 0.55319, 'recall': 0.2, 'f1': 0.29379, 'auc': 0.75965}
2025-07-05 00:58:29,351 - INFO - > Epoch 74: took 91.2s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 00:59:49,097 - INFO - train: {'epoch': 75, 'time_epoch': 79.51497, 'eta': 1926.75474, 'eta_hours': 0.53521, 'loss': 0.10180759, 'lr': 1.614e-05, 'params': 451793, 'time_iter': 0.07727, 'accuracy': 0.97116, 'precision': 0.73544, 'recall': 0.35877, 'f1': 0.48227, 'auc': 0.87514}
2025-07-05 00:59:53,728 - INFO - val: {'epoch': 75, 'time_epoch': 4.60346, 'loss': 0.07176734, 'lr': 0, 'params': 451793, 'time_iter': 0.03569, 'accuracy': 0.98274, 'precision': 0.66667, 'recall': 0.24691, 'f1': 0.36036, 'auc': 0.77031}
2025-07-05 00:59:58,344 - INFO - test: {'epoch': 75, 'time_epoch': 4.5942, 'loss': 0.1191335, 'lr': 0, 'params': 451793, 'time_iter': 0.03561, 'accuracy': 0.97009, 'precision': 0.57447, 'recall': 0.20769, 'f1': 0.30508, 'auc': 0.76668}
2025-07-05 00:59:58,347 - INFO - > Epoch 75: took 89.0s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:01:18,762 - INFO - train: {'epoch': 76, 'time_epoch': 80.1953, 'eta': 1846.44756, 'eta_hours': 0.5129, 'loss': 0.10112008, 'lr': 1.494e-05, 'params': 451793, 'time_iter': 0.07794, 'accuracy': 0.97103, 'precision': 0.73445, 'recall': 0.35471, 'f1': 0.47838, 'auc': 0.88156}
2025-07-05 01:01:23,397 - INFO - val: {'epoch': 76, 'time_epoch': 4.60637, 'loss': 0.07114571, 'lr': 0, 'params': 451793, 'time_iter': 0.03571, 'accuracy': 0.98298, 'precision': 0.68966, 'recall': 0.24691, 'f1': 0.36364, 'auc': 0.7812}
2025-07-05 01:01:28,009 - INFO - test: {'epoch': 76, 'time_epoch': 4.58769, 'loss': 0.11691162, 'lr': 0, 'params': 451793, 'time_iter': 0.03556, 'accuracy': 0.97131, 'precision': 0.65, 'recall': 0.2, 'f1': 0.30588, 'auc': 0.76882}
2025-07-05 01:01:28,012 - INFO - > Epoch 76: took 89.7s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:02:46,674 - INFO - train: {'epoch': 77, 'time_epoch': 78.49297, 'eta': 1765.6631, 'eta_hours': 0.49046, 'loss': 0.10155997, 'lr': 1.378e-05, 'params': 451793, 'time_iter': 0.07628, 'accuracy': 0.97082, 'precision': 0.72819, 'recall': 0.35227, 'f1': 0.47484, 'auc': 0.8757}
2025-07-05 01:02:51,324 - INFO - val: {'epoch': 77, 'time_epoch': 4.55062, 'loss': 0.07049764, 'lr': 0, 'params': 451793, 'time_iter': 0.03528, 'accuracy': 0.98371, 'precision': 0.75, 'recall': 0.25926, 'f1': 0.38532, 'auc': 0.78279}
2025-07-05 01:02:55,897 - INFO - test: {'epoch': 77, 'time_epoch': 4.55169, 'loss': 0.11793839, 'lr': 0, 'params': 451793, 'time_iter': 0.03528, 'accuracy': 0.97082, 'precision': 0.61364, 'recall': 0.20769, 'f1': 0.31034, 'auc': 0.76992}
2025-07-05 01:02:55,900 - INFO - > Epoch 77: took 87.9s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:04:14,962 - INFO - train: {'epoch': 78, 'time_epoch': 78.84429, 'eta': 1685.03005, 'eta_hours': 0.46806, 'loss': 0.10099764, 'lr': 1.266e-05, 'params': 451793, 'time_iter': 0.07662, 'accuracy': 0.97134, 'precision': 0.74286, 'recall': 0.35877, 'f1': 0.48385, 'auc': 0.87394}
2025-07-05 01:04:19,571 - INFO - val: {'epoch': 78, 'time_epoch': 4.55597, 'loss': 0.07200484, 'lr': 0, 'params': 451793, 'time_iter': 0.03532, 'accuracy': 0.98249, 'precision': 0.64516, 'recall': 0.24691, 'f1': 0.35714, 'auc': 0.77454}
2025-07-05 01:04:24,170 - INFO - test: {'epoch': 78, 'time_epoch': 4.57547, 'loss': 0.12193815, 'lr': 0, 'params': 451793, 'time_iter': 0.03547, 'accuracy': 0.96864, 'precision': 0.51064, 'recall': 0.18462, 'f1': 0.27119, 'auc': 0.77074}
2025-07-05 01:04:24,174 - INFO - > Epoch 78: took 88.3s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:05:43,668 - INFO - train: {'epoch': 79, 'time_epoch': 79.09294, 'eta': 1604.50388, 'eta_hours': 0.4457, 'loss': 0.10104741, 'lr': 1.158e-05, 'params': 451793, 'time_iter': 0.07686, 'accuracy': 0.97152, 'precision': 0.74062, 'recall': 0.36851, 'f1': 0.49214, 'auc': 0.87806}
2025-07-05 01:05:48,304 - INFO - val: {'epoch': 79, 'time_epoch': 4.60685, 'loss': 0.07532033, 'lr': 0, 'params': 451793, 'time_iter': 0.03571, 'accuracy': 0.98055, 'precision': 0.51111, 'recall': 0.28395, 'f1': 0.36508, 'auc': 0.77359}
2025-07-05 01:05:52,930 - INFO - test: {'epoch': 79, 'time_epoch': 4.60291, 'loss': 0.11947962, 'lr': 0, 'params': 451793, 'time_iter': 0.03568, 'accuracy': 0.96669, 'precision': 0.45783, 'recall': 0.29231, 'f1': 0.35681, 'auc': 0.77295}
2025-07-05 01:05:52,933 - INFO - > Epoch 79: took 88.8s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:07:13,615 - INFO - train: {'epoch': 80, 'time_epoch': 80.43384, 'eta': 1524.32762, 'eta_hours': 0.42342, 'loss': 0.10120936, 'lr': 1.054e-05, 'params': 451793, 'time_iter': 0.07817, 'accuracy': 0.97149, 'precision': 0.74098, 'recall': 0.36688, 'f1': 0.49077, 'auc': 0.87849}
2025-07-05 01:07:18,350 - INFO - val: {'epoch': 80, 'time_epoch': 4.70189, 'loss': 0.072066, 'lr': 0, 'params': 451793, 'time_iter': 0.03645, 'accuracy': 0.98298, 'precision': 0.68966, 'recall': 0.24691, 'f1': 0.36364, 'auc': 0.77933}
2025-07-05 01:07:23,099 - INFO - test: {'epoch': 80, 'time_epoch': 4.72249, 'loss': 0.11889106, 'lr': 0, 'params': 451793, 'time_iter': 0.03661, 'accuracy': 0.97058, 'precision': 0.60465, 'recall': 0.2, 'f1': 0.30058, 'auc': 0.77274}
2025-07-05 01:07:23,102 - INFO - > Epoch 80: took 90.2s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:08:45,882 - INFO - train: {'epoch': 81, 'time_epoch': 82.54007, 'eta': 1444.60743, 'eta_hours': 0.40128, 'loss': 0.0992634, 'lr': 9.55e-06, 'params': 451793, 'time_iter': 0.08021, 'accuracy': 0.97185, 'precision': 0.74757, 'recall': 0.375, 'f1': 0.49946, 'auc': 0.8829}
2025-07-05 01:08:50,803 - INFO - val: {'epoch': 81, 'time_epoch': 4.89155, 'loss': 0.0733217, 'lr': 0, 'params': 451793, 'time_iter': 0.03792, 'accuracy': 0.98152, 'precision': 0.56098, 'recall': 0.28395, 'f1': 0.37705, 'auc': 0.7776}
2025-07-05 01:08:55,554 - INFO - test: {'epoch': 81, 'time_epoch': 4.72961, 'loss': 0.11812425, 'lr': 0, 'params': 451793, 'time_iter': 0.03666, 'accuracy': 0.97034, 'precision': 0.56897, 'recall': 0.25385, 'f1': 0.35106, 'auc': 0.77424}
2025-07-05 01:08:55,558 - INFO - > Epoch 81: took 92.5s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:10:15,151 - INFO - train: {'epoch': 82, 'time_epoch': 79.37425, 'eta': 1364.17087, 'eta_hours': 0.37894, 'loss': 0.10060941, 'lr': 8.6e-06, 'params': 451793, 'time_iter': 0.07714, 'accuracy': 0.9711, 'precision': 0.72771, 'recall': 0.36445, 'f1': 0.48567, 'auc': 0.88021}
2025-07-05 01:10:19,753 - INFO - val: {'epoch': 82, 'time_epoch': 4.57436, 'loss': 0.07269739, 'lr': 0, 'params': 451793, 'time_iter': 0.03546, 'accuracy': 0.98177, 'precision': 0.59375, 'recall': 0.23457, 'f1': 0.33628, 'auc': 0.77747}
2025-07-05 01:10:24,393 - INFO - test: {'epoch': 82, 'time_epoch': 4.61766, 'loss': 0.11893797, 'lr': 0, 'params': 451793, 'time_iter': 0.0358, 'accuracy': 0.96937, 'precision': 0.53448, 'recall': 0.23846, 'f1': 0.32979, 'auc': 0.76557}
2025-07-05 01:10:24,395 - INFO - > Epoch 82: took 88.8s (avg 89.9s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:11:42,308 - INFO - train: {'epoch': 83, 'time_epoch': 77.71204, 'eta': 1283.44299, 'eta_hours': 0.35651, 'loss': 0.10019076, 'lr': 7.7e-06, 'params': 451793, 'time_iter': 0.07552, 'accuracy': 0.97195, 'precision': 0.75793, 'recall': 0.36851, 'f1': 0.4959, 'auc': 0.88021}
2025-07-05 01:11:46,908 - INFO - val: {'epoch': 83, 'time_epoch': 4.5593, 'loss': 0.07247356, 'lr': 0, 'params': 451793, 'time_iter': 0.03534, 'accuracy': 0.98274, 'precision': 0.66667, 'recall': 0.24691, 'f1': 0.36036, 'auc': 0.7733}
2025-07-05 01:11:51,511 - INFO - test: {'epoch': 83, 'time_epoch': 4.55333, 'loss': 0.118793, 'lr': 0, 'params': 451793, 'time_iter': 0.0353, 'accuracy': 0.97009, 'precision': 0.56604, 'recall': 0.23077, 'f1': 0.32787, 'auc': 0.76202}
2025-07-05 01:11:51,527 - INFO - > Epoch 83: took 87.1s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:13:10,625 - INFO - train: {'epoch': 84, 'time_epoch': 78.86513, 'eta': 1202.98956, 'eta_hours': 0.33416, 'loss': 0.09871285, 'lr': 6.84e-06, 'params': 451793, 'time_iter': 0.07664, 'accuracy': 0.97222, 'precision': 0.76589, 'recall': 0.37175, 'f1': 0.50055, 'auc': 0.88377}
2025-07-05 01:13:15,230 - INFO - val: {'epoch': 84, 'time_epoch': 4.57675, 'loss': 0.07279575, 'lr': 0, 'params': 451793, 'time_iter': 0.03548, 'accuracy': 0.98177, 'precision': 0.58824, 'recall': 0.24691, 'f1': 0.34783, 'auc': 0.77649}
2025-07-05 01:13:19,836 - INFO - test: {'epoch': 84, 'time_epoch': 4.58148, 'loss': 0.11813486, 'lr': 0, 'params': 451793, 'time_iter': 0.03552, 'accuracy': 0.97131, 'precision': 0.61538, 'recall': 0.24615, 'f1': 0.35165, 'auc': 0.76865}
2025-07-05 01:13:19,839 - INFO - > Epoch 84: took 88.3s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:14:39,228 - INFO - train: {'epoch': 85, 'time_epoch': 79.15078, 'eta': 1122.61956, 'eta_hours': 0.31184, 'loss': 0.10098378, 'lr': 6.03e-06, 'params': 451793, 'time_iter': 0.07692, 'accuracy': 0.97152, 'precision': 0.73984, 'recall': 0.36932, 'f1': 0.49269, 'auc': 0.8787}
2025-07-05 01:14:43,864 - INFO - val: {'epoch': 85, 'time_epoch': 4.60639, 'loss': 0.07161705, 'lr': 0, 'params': 451793, 'time_iter': 0.03571, 'accuracy': 0.98298, 'precision': 0.7037, 'recall': 0.23457, 'f1': 0.35185, 'auc': 0.77949}
2025-07-05 01:14:48,538 - INFO - test: {'epoch': 85, 'time_epoch': 4.65059, 'loss': 0.11776409, 'lr': 0, 'params': 451793, 'time_iter': 0.03605, 'accuracy': 0.97131, 'precision': 0.63636, 'recall': 0.21538, 'f1': 0.32184, 'auc': 0.7658}
2025-07-05 01:14:48,541 - INFO - > Epoch 85: took 88.7s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:16:09,148 - INFO - train: {'epoch': 86, 'time_epoch': 80.38289, 'eta': 1042.46171, 'eta_hours': 0.28957, 'loss': 0.09953705, 'lr': 5.26e-06, 'params': 451793, 'time_iter': 0.07812, 'accuracy': 0.97143, 'precision': 0.73101, 'recall': 0.375, 'f1': 0.49571, 'auc': 0.88469}
2025-07-05 01:16:13,812 - INFO - val: {'epoch': 86, 'time_epoch': 4.63467, 'loss': 0.07241006, 'lr': 0, 'params': 451793, 'time_iter': 0.03593, 'accuracy': 0.98201, 'precision': 0.60606, 'recall': 0.24691, 'f1': 0.35088, 'auc': 0.77483}
2025-07-05 01:16:18,687 - INFO - test: {'epoch': 86, 'time_epoch': 4.8534, 'loss': 0.11723355, 'lr': 0, 'params': 451793, 'time_iter': 0.03762, 'accuracy': 0.97009, 'precision': 0.55738, 'recall': 0.26154, 'f1': 0.35602, 'auc': 0.77464}
2025-07-05 01:16:18,690 - INFO - > Epoch 86: took 90.1s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:17:41,240 - INFO - train: {'epoch': 87, 'time_epoch': 82.32586, 'eta': 962.56369, 'eta_hours': 0.26738, 'loss': 0.10052468, 'lr': 4.55e-06, 'params': 451793, 'time_iter': 0.08001, 'accuracy': 0.97234, 'precision': 0.76656, 'recall': 0.37581, 'f1': 0.50436, 'auc': 0.8775}
2025-07-05 01:17:45,819 - INFO - val: {'epoch': 87, 'time_epoch': 4.55091, 'loss': 0.07248741, 'lr': 0, 'params': 451793, 'time_iter': 0.03528, 'accuracy': 0.98225, 'precision': 0.61111, 'recall': 0.2716, 'f1': 0.37607, 'auc': 0.77302}
2025-07-05 01:17:50,406 - INFO - test: {'epoch': 87, 'time_epoch': 4.56507, 'loss': 0.11754428, 'lr': 0, 'params': 451793, 'time_iter': 0.03539, 'accuracy': 0.96961, 'precision': 0.54098, 'recall': 0.25385, 'f1': 0.34555, 'auc': 0.77283}
2025-07-05 01:17:50,409 - INFO - > Epoch 87: took 91.7s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:19:10,654 - INFO - train: {'epoch': 88, 'time_epoch': 80.00921, 'eta': 882.32478, 'eta_hours': 0.24509, 'loss': 0.09922009, 'lr': 3.89e-06, 'params': 451793, 'time_iter': 0.07775, 'accuracy': 0.97182, 'precision': 0.74016, 'recall': 0.38149, 'f1': 0.50348, 'auc': 0.88492}
2025-07-05 01:19:15,385 - INFO - val: {'epoch': 88, 'time_epoch': 4.70208, 'loss': 0.07296611, 'lr': 0, 'params': 451793, 'time_iter': 0.03645, 'accuracy': 0.98104, 'precision': 0.54054, 'recall': 0.24691, 'f1': 0.33898, 'auc': 0.77325}
2025-07-05 01:19:20,188 - INFO - test: {'epoch': 88, 'time_epoch': 4.78128, 'loss': 0.11782707, 'lr': 0, 'params': 451793, 'time_iter': 0.03706, 'accuracy': 0.97058, 'precision': 0.58182, 'recall': 0.24615, 'f1': 0.34595, 'auc': 0.76655}
2025-07-05 01:19:20,191 - INFO - > Epoch 88: took 89.8s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:20:40,528 - INFO - train: {'epoch': 89, 'time_epoch': 80.14783, 'eta': 802.10638, 'eta_hours': 0.22281, 'loss': 0.09996146, 'lr': 3.27e-06, 'params': 451793, 'time_iter': 0.07789, 'accuracy': 0.97143, 'precision': 0.73397, 'recall': 0.37175, 'f1': 0.49353, 'auc': 0.88654}
2025-07-05 01:20:45,136 - INFO - val: {'epoch': 89, 'time_epoch': 4.578, 'loss': 0.07405872, 'lr': 0, 'params': 451793, 'time_iter': 0.03549, 'accuracy': 0.98152, 'precision': 0.56757, 'recall': 0.25926, 'f1': 0.35593, 'auc': 0.7743}
2025-07-05 01:20:49,701 - INFO - test: {'epoch': 89, 'time_epoch': 4.5419, 'loss': 0.11733273, 'lr': 0, 'params': 451793, 'time_iter': 0.03521, 'accuracy': 0.97034, 'precision': 0.56667, 'recall': 0.26154, 'f1': 0.35789, 'auc': 0.76656}
2025-07-05 01:20:49,703 - INFO - > Epoch 89: took 89.5s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:22:11,304 - INFO - train: {'epoch': 90, 'time_epoch': 81.39013, 'eta': 722.01239, 'eta_hours': 0.20056, 'loss': 0.0984601, 'lr': 2.71e-06, 'params': 451793, 'time_iter': 0.0791, 'accuracy': 0.9717, 'precision': 0.74959, 'recall': 0.36688, 'f1': 0.49264, 'auc': 0.88671}
2025-07-05 01:22:15,883 - INFO - val: {'epoch': 90, 'time_epoch': 4.55095, 'loss': 0.07302813, 'lr': 0, 'params': 451793, 'time_iter': 0.03528, 'accuracy': 0.98152, 'precision': 0.57143, 'recall': 0.24691, 'f1': 0.34483, 'auc': 0.77515}
2025-07-05 01:22:20,462 - INFO - test: {'epoch': 90, 'time_epoch': 4.55767, 'loss': 0.1189226, 'lr': 0, 'params': 451793, 'time_iter': 0.03533, 'accuracy': 0.96985, 'precision': 0.55, 'recall': 0.25385, 'f1': 0.34737, 'auc': 0.7687}
2025-07-05 01:22:20,465 - INFO - > Epoch 90: took 90.8s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:23:39,233 - INFO - train: {'epoch': 91, 'time_epoch': 78.58584, 'eta': 641.64638, 'eta_hours': 0.17824, 'loss': 0.09893075, 'lr': 2.2e-06, 'params': 451793, 'time_iter': 0.07637, 'accuracy': 0.97207, 'precision': 0.76661, 'recall': 0.36526, 'f1': 0.49478, 'auc': 0.88383}
2025-07-05 01:23:43,829 - INFO - val: {'epoch': 91, 'time_epoch': 4.56731, 'loss': 0.07295374, 'lr': 0, 'params': 451793, 'time_iter': 0.03541, 'accuracy': 0.98152, 'precision': 0.56757, 'recall': 0.25926, 'f1': 0.35593, 'auc': 0.77646}
2025-07-05 01:23:48,415 - INFO - test: {'epoch': 91, 'time_epoch': 4.56469, 'loss': 0.11849368, 'lr': 0, 'params': 451793, 'time_iter': 0.03539, 'accuracy': 0.96985, 'precision': 0.54839, 'recall': 0.26154, 'f1': 0.35417, 'auc': 0.77192}
2025-07-05 01:23:48,417 - INFO - > Epoch 91: took 88.0s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:25:06,660 - INFO - train: {'epoch': 92, 'time_epoch': 78.05028, 'eta': 561.27834, 'eta_hours': 0.15591, 'loss': 0.09913499, 'lr': 1.74e-06, 'params': 451793, 'time_iter': 0.07585, 'accuracy': 0.97143, 'precision': 0.73175, 'recall': 0.37419, 'f1': 0.49517, 'auc': 0.88463}
2025-07-05 01:25:11,257 - INFO - val: {'epoch': 92, 'time_epoch': 4.568, 'loss': 0.07302218, 'lr': 0, 'params': 451793, 'time_iter': 0.03541, 'accuracy': 0.98104, 'precision': 0.53659, 'recall': 0.2716, 'f1': 0.36066, 'auc': 0.78015}
2025-07-05 01:25:15,839 - INFO - test: {'epoch': 92, 'time_epoch': 4.56001, 'loss': 0.11770483, 'lr': 0, 'params': 451793, 'time_iter': 0.03535, 'accuracy': 0.96985, 'precision': 0.54839, 'recall': 0.26154, 'f1': 0.35417, 'auc': 0.76961}
2025-07-05 01:25:15,842 - INFO - > Epoch 92: took 87.4s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:26:35,736 - INFO - train: {'epoch': 93, 'time_epoch': 79.69294, 'eta': 481.06446, 'eta_hours': 0.13363, 'loss': 0.09991568, 'lr': 1.33e-06, 'params': 451793, 'time_iter': 0.07745, 'accuracy': 0.97161, 'precision': 0.74188, 'recall': 0.37094, 'f1': 0.49459, 'auc': 0.88152}
2025-07-05 01:26:40,338 - INFO - val: {'epoch': 93, 'time_epoch': 4.5747, 'loss': 0.07261419, 'lr': 0, 'params': 451793, 'time_iter': 0.03546, 'accuracy': 0.98201, 'precision': 0.60606, 'recall': 0.24691, 'f1': 0.35088, 'auc': 0.77719}
2025-07-05 01:26:44,952 - INFO - test: {'epoch': 93, 'time_epoch': 4.59063, 'loss': 0.11837569, 'lr': 0, 'params': 451793, 'time_iter': 0.03559, 'accuracy': 0.97107, 'precision': 0.60784, 'recall': 0.23846, 'f1': 0.34254, 'auc': 0.76546}
2025-07-05 01:26:44,959 - INFO - > Epoch 93: took 89.1s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:28:04,808 - INFO - train: {'epoch': 94, 'time_epoch': 79.61403, 'eta': 400.8574, 'eta_hours': 0.11135, 'loss': 0.09777708, 'lr': 9.8e-07, 'params': 451793, 'time_iter': 0.07737, 'accuracy': 0.97189, 'precision': 0.75205, 'recall': 0.37175, 'f1': 0.49756, 'auc': 0.88681}
2025-07-05 01:28:09,544 - INFO - val: {'epoch': 94, 'time_epoch': 4.69933, 'loss': 0.07384609, 'lr': 0, 'params': 451793, 'time_iter': 0.03643, 'accuracy': 0.98055, 'precision': 0.51282, 'recall': 0.24691, 'f1': 0.33333, 'auc': 0.7742}
2025-07-05 01:28:14,233 - INFO - test: {'epoch': 94, 'time_epoch': 4.66809, 'loss': 0.1184523, 'lr': 0, 'params': 451793, 'time_iter': 0.03619, 'accuracy': 0.96864, 'precision': 0.50746, 'recall': 0.26154, 'f1': 0.34518, 'auc': 0.7688}
2025-07-05 01:28:14,236 - INFO - > Epoch 94: took 89.3s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:29:36,570 - INFO - train: {'epoch': 95, 'time_epoch': 82.10187, 'eta': 320.76635, 'eta_hours': 0.0891, 'loss': 0.09807015, 'lr': 6.8e-07, 'params': 451793, 'time_iter': 0.07979, 'accuracy': 0.9721, 'precision': 0.7557, 'recall': 0.37662, 'f1': 0.50271, 'auc': 0.89013}
2025-07-05 01:29:41,460 - INFO - val: {'epoch': 95, 'time_epoch': 4.85972, 'loss': 0.07265394, 'lr': 0, 'params': 451793, 'time_iter': 0.03767, 'accuracy': 0.98152, 'precision': 0.57143, 'recall': 0.24691, 'f1': 0.34483, 'auc': 0.77689}
2025-07-05 01:29:46,325 - INFO - test: {'epoch': 95, 'time_epoch': 4.84327, 'loss': 0.11900184, 'lr': 0, 'params': 451793, 'time_iter': 0.03754, 'accuracy': 0.97082, 'precision': 0.59259, 'recall': 0.24615, 'f1': 0.34783, 'auc': 0.76577}
2025-07-05 01:29:46,328 - INFO - > Epoch 95: took 92.1s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:31:06,542 - INFO - train: {'epoch': 96, 'time_epoch': 79.98434, 'eta': 240.56836, 'eta_hours': 0.06682, 'loss': 0.09881711, 'lr': 4.4e-07, 'params': 451793, 'time_iter': 0.07773, 'accuracy': 0.97201, 'precision': 0.75203, 'recall': 0.37662, 'f1': 0.50189, 'auc': 0.88273}
2025-07-05 01:31:11,178 - INFO - val: {'epoch': 96, 'time_epoch': 4.60773, 'loss': 0.07370239, 'lr': 0, 'params': 451793, 'time_iter': 0.03572, 'accuracy': 0.98152, 'precision': 0.56757, 'recall': 0.25926, 'f1': 0.35593, 'auc': 0.77285}
2025-07-05 01:31:15,748 - INFO - test: {'epoch': 96, 'time_epoch': 4.54617, 'loss': 0.11811425, 'lr': 0, 'params': 451793, 'time_iter': 0.03524, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.26154, 'f1': 0.34343, 'auc': 0.77488}
2025-07-05 01:31:15,751 - INFO - > Epoch 96: took 89.4s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:32:34,217 - INFO - train: {'epoch': 97, 'time_epoch': 78.25916, 'eta': 160.33951, 'eta_hours': 0.04454, 'loss': 0.09899792, 'lr': 2.5e-07, 'params': 451793, 'time_iter': 0.07605, 'accuracy': 0.97225, 'precision': 0.75358, 'recall': 0.38474, 'f1': 0.5094, 'auc': 0.88374}
2025-07-05 01:32:38,913 - INFO - val: {'epoch': 97, 'time_epoch': 4.65734, 'loss': 0.07258506, 'lr': 0, 'params': 451793, 'time_iter': 0.0361, 'accuracy': 0.98104, 'precision': 0.54054, 'recall': 0.24691, 'f1': 0.33898, 'auc': 0.77488}
2025-07-05 01:32:43,517 - INFO - test: {'epoch': 97, 'time_epoch': 4.57815, 'loss': 0.11800132, 'lr': 0, 'params': 451793, 'time_iter': 0.03549, 'accuracy': 0.97034, 'precision': 0.56897, 'recall': 0.25385, 'f1': 0.35106, 'auc': 0.76756}
2025-07-05 01:32:43,522 - INFO - > Epoch 97: took 87.8s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:34:02,677 - INFO - train: {'epoch': 98, 'time_epoch': 78.93799, 'eta': 80.15731, 'eta_hours': 0.02227, 'loss': 0.0989247, 'lr': 1.1e-07, 'params': 451793, 'time_iter': 0.07671, 'accuracy': 0.97149, 'precision': 0.73786, 'recall': 0.37013, 'f1': 0.49297, 'auc': 0.88354}
2025-07-05 01:34:07,294 - INFO - val: {'epoch': 98, 'time_epoch': 4.58584, 'loss': 0.07185617, 'lr': 0, 'params': 451793, 'time_iter': 0.03555, 'accuracy': 0.98177, 'precision': 0.58824, 'recall': 0.24691, 'f1': 0.34783, 'auc': 0.77919}
2025-07-05 01:34:11,901 - INFO - test: {'epoch': 98, 'time_epoch': 4.58468, 'loss': 0.11868723, 'lr': 0, 'params': 451793, 'time_iter': 0.03554, 'accuracy': 0.97082, 'precision': 0.6, 'recall': 0.23077, 'f1': 0.33333, 'auc': 0.7673}
2025-07-05 01:34:11,904 - INFO - > Epoch 98: took 88.4s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:35:31,454 - INFO - train: {'epoch': 99, 'time_epoch': 79.34318, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.09836917, 'lr': 3e-08, 'params': 451793, 'time_iter': 0.07711, 'accuracy': 0.97152, 'precision': 0.73984, 'recall': 0.36932, 'f1': 0.49269, 'auc': 0.89013}
2025-07-05 01:35:36,105 - INFO - val: {'epoch': 99, 'time_epoch': 4.62112, 'loss': 0.0723406, 'lr': 0, 'params': 451793, 'time_iter': 0.03582, 'accuracy': 0.98322, 'precision': 0.73077, 'recall': 0.23457, 'f1': 0.35514, 'auc': 0.78144}
2025-07-05 01:35:40,830 - INFO - test: {'epoch': 99, 'time_epoch': 4.69795, 'loss': 0.11846175, 'lr': 0, 'params': 451793, 'time_iter': 0.03642, 'accuracy': 0.97155, 'precision': 0.64444, 'recall': 0.22308, 'f1': 0.33143, 'auc': 0.76639}
2025-07-05 01:35:41,141 - INFO - > Epoch 99: took 88.9s (avg 89.8s) | Best so far: epoch 33	train_loss: 0.1174 train_auc: 0.8225	val_loss: 0.0696 val_auc: 0.8177	test_loss: 0.1172 test_auc: 0.7545
2025-07-05 01:35:41,142 - INFO - Avg time per epoch: 89.75s
2025-07-05 01:35:41,142 - INFO - Total train loop time: 2.49h
2025-07-05 01:35:41,157 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-47
2025-07-05 01:35:41,158 - INFO - Total time: 9523.33s (2.65h)
2025-07-05 01:35:41,195 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-47/agg
2025-07-05 01:35:41,196 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-07-05 01:35:41,196 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-47
2025-07-05 01:35:41,196 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-47/test_results/
Completed seed 47. Results saved in results/molhiv/molhiv-Vanilla-47
----------------------------------------
All experiments completed!
