Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          251Gi       9.8Gi       166Gi       2.4Gi        74Gi       236Gi
Swap:         1.9Gi        26Mi       1.8Gi
Sun Aug 17 02:30:53 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA TITAN RTX               On  |   00000000:1E:00.0 Off |                  N/A |
| 41%   38C    P8             19W /  280W |       1MiB /  24576MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 45
Starting training for seed 45...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/confignas.yaml
Using device: cuda
2025-08-17 02:31:05,568 - INFO - GPU Mem: 25.2GB
2025-08-17 02:31:05,568 - INFO - Run directory: results/molhiv/molhiv-Vanilla-45
2025-08-17 02:31:05,568 - INFO - Seed: 45
2025-08-17 02:31:05,568 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-17 02:31:05,568 - INFO - Routing mode: none
2025-08-17 02:31:05,568 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-17 02:31:05,568 - INFO - Number of layers: 15
2025-08-17 02:31:05,568 - INFO - Uncertainty enabled: False
2025-08-17 02:31:05,568 - INFO - Training mode: custom
2025-08-17 02:31:05,568 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-17 02:31:05,568 - INFO - Additional features: Router weights logging + JSON export
2025-08-17 02:31:14,101 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 02:31:14,103 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-17 02:31:14,104 - INFO -   undirected: True
2025-08-17 02:31:14,104 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 02:31:14,105 - INFO -   avg num_nodes/graph: 25
2025-08-17 02:31:14,105 - INFO -   num node features: 9
2025-08-17 02:31:14,105 - INFO -   num edge features: 3
2025-08-17 02:31:14,105 - INFO -   num tasks: 1
2025-08-17 02:31:14,105 - INFO -   num classes: 2
2025-08-17 02:31:14,105 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-17 02:31:14,105 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-17 02:31:14,109 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 17%|█▋        | 6911/41127 [00:10<00:49, 691.06it/s] 34%|███▎      | 13800/41127 [00:20<00:39, 689.71it/s] 50%|█████     | 20642/41127 [00:30<00:29, 687.16it/s] 67%|██████▋   | 27443/41127 [00:40<00:19, 684.34it/s] 84%|████████▎ | 34400/41127 [00:50<00:09, 688.42it/s]100%|█████████▉| 41092/41127 [01:00<00:00, 681.88it/s]100%|██████████| 41127/41127 [01:00<00:00, 684.81it/s]
2025-08-17 02:32:15,130 - INFO - Done! Took 00:01:01.02
2025-08-17 02:32:15,277 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-17 02:32:15,466 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-17 02:32:15,466 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-08-17 02:32:15,466 - INFO - Inner model has get_darts_model: False
2025-08-17 02:32:15,469 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-08-17 02:32:15,471 - INFO - Number of parameters: 451,793
2025-08-17 02:32:15,472 - INFO - Starting optimized training: 2025-08-17 02:32:15.472050
2025-08-17 02:32:21,384 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 02:32:21,385 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-17 02:32:21,385 - INFO -   undirected: True
2025-08-17 02:32:21,385 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 02:32:21,386 - INFO -   avg num_nodes/graph: 25
2025-08-17 02:32:21,386 - INFO -   num node features: 9
2025-08-17 02:32:21,386 - INFO -   num edge features: 3
2025-08-17 02:32:21,386 - INFO -   num tasks: 1
2025-08-17 02:32:21,386 - INFO -   num classes: 2
2025-08-17 02:32:21,386 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-17 02:32:21,387 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-17 02:32:21,390 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 17%|█▋        | 6947/41127 [00:10<00:49, 694.67it/s] 34%|███▍      | 13898/41127 [00:20<00:39, 694.90it/s] 50%|█████     | 20696/41127 [00:30<00:29, 688.00it/s] 65%|██████▍   | 26663/41127 [00:40<00:22, 651.93it/s] 80%|███████▉  | 32780/41127 [00:50<00:13, 635.59it/s] 95%|█████████▌| 39218/41127 [01:00<00:02, 638.36it/s]100%|██████████| 41127/41127 [01:03<00:00, 652.09it/s]
2025-08-17 02:33:25,495 - INFO - Done! Took 00:01:04.11
2025-08-17 02:33:25,641 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-17 02:33:25,653 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-17 02:33:25,653 - INFO - Start from epoch 0
2025-08-17 02:34:41,948 - INFO - train: {'epoch': 0, 'time_epoch': 76.19065, 'eta': 7542.87466, 'eta_hours': 2.09524, 'loss': 0.62549572, 'lr': 0.0, 'params': 451793, 'time_iter': 0.07404, 'accuracy': 0.96222, 'precision': 0.07692, 'recall': 0.00081, 'f1': 0.00161, 'auc': 0.4713}
2025-08-17 02:34:41,956 - INFO - ...computing epoch stats took: 0.09s
2025-08-17 02:34:47,365 - INFO - val: {'epoch': 0, 'time_epoch': 5.39187, 'loss': 0.62598024, 'lr': 0, 'params': 451793, 'time_iter': 0.0418, 'accuracy': 0.98006, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.43285}
2025-08-17 02:34:47,367 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 02:34:52,370 - INFO - test: {'epoch': 0, 'time_epoch': 4.98511, 'loss': 0.62910126, 'lr': 0, 'params': 451793, 'time_iter': 0.03864, 'accuracy': 0.96815, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.41876}
2025-08-17 02:34:52,372 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 02:34:52,373 - INFO - > Epoch 0: took 86.7s (avg 86.7s) | Best so far: epoch 0	train_loss: 0.6255 train_auc: 0.4713	val_loss: 0.6260 val_auc: 0.4329	test_loss: 0.6291 test_auc: 0.4188
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:36:04,007 - INFO - train: {'epoch': 1, 'time_epoch': 71.57193, 'eta': 7240.36675, 'eta_hours': 2.01121, 'loss': 0.49406607, 'lr': 2e-05, 'params': 451793, 'time_iter': 0.06955, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.51112}
2025-08-17 02:36:04,014 - INFO - ...computing epoch stats took: 0.05s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:36:08,292 - INFO - val: {'epoch': 1, 'time_epoch': 4.26257, 'loss': 0.31105286, 'lr': 0, 'params': 451793, 'time_iter': 0.03304, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.52197}
2025-08-17 02:36:08,294 - INFO - ...computing epoch stats took: 0.01s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:36:12,572 - INFO - test: {'epoch': 1, 'time_epoch': 4.26387, 'loss': 0.31474314, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.50788}
2025-08-17 02:36:12,583 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 02:36:12,584 - INFO - > Epoch 1: took 80.2s (avg 83.5s) | Best so far: epoch 1	train_loss: 0.4941 train_auc: 0.5111	val_loss: 0.3111 val_auc: 0.5220	test_loss: 0.3147 test_auc: 0.5079
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:37:24,604 - INFO - train: {'epoch': 2, 'time_epoch': 71.96411, 'eta': 7104.49667, 'eta_hours': 1.97347, 'loss': 0.20972317, 'lr': 4e-05, 'params': 451793, 'time_iter': 0.06994, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.55229}
2025-08-17 02:37:24,613 - INFO - ...computing epoch stats took: 0.04s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:37:29,064 - INFO - val: {'epoch': 2, 'time_epoch': 4.43624, 'loss': 0.10757566, 'lr': 0, 'params': 451793, 'time_iter': 0.03439, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.62202}
2025-08-17 02:37:29,066 - INFO - ...computing epoch stats took: 0.01s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:37:33,535 - INFO - test: {'epoch': 2, 'time_epoch': 4.45345, 'loss': 0.14649536, 'lr': 0, 'params': 451793, 'time_iter': 0.03452, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.62557}
2025-08-17 02:37:33,537 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 02:37:33,538 - INFO - > Epoch 2: took 81.0s (avg 82.6s) | Best so far: epoch 2	train_loss: 0.2097 train_auc: 0.5523	val_loss: 0.1076 val_auc: 0.6220	test_loss: 0.1465 test_auc: 0.6256
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:38:45,411 - INFO - train: {'epoch': 3, 'time_epoch': 71.8169, 'eta': 6997.0465, 'eta_hours': 1.94362, 'loss': 0.15934087, 'lr': 6e-05, 'params': 451793, 'time_iter': 0.06979, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.61005}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:38:49,906 - INFO - val: {'epoch': 3, 'time_epoch': 4.47228, 'loss': 0.10142173, 'lr': 0, 'params': 451793, 'time_iter': 0.03467, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.61217}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:38:54,389 - INFO - test: {'epoch': 3, 'time_epoch': 4.46481, 'loss': 0.13775972, 'lr': 0, 'params': 451793, 'time_iter': 0.03461, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.63705}
2025-08-17 02:38:54,392 - INFO - > Epoch 3: took 80.9s (avg 82.2s) | Best so far: epoch 2	train_loss: 0.2097 train_auc: 0.5523	val_loss: 0.1076 val_auc: 0.6220	test_loss: 0.1465 test_auc: 0.6256
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:40:07,680 - INFO - train: {'epoch': 4, 'time_epoch': 73.22975, 'eta': 6930.6937, 'eta_hours': 1.92519, 'loss': 0.15221166, 'lr': 8e-05, 'params': 451793, 'time_iter': 0.07117, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6577}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:40:12,209 - INFO - val: {'epoch': 4, 'time_epoch': 4.50464, 'loss': 0.09298328, 'lr': 0, 'params': 451793, 'time_iter': 0.03492, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66637}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:40:16,764 - INFO - test: {'epoch': 4, 'time_epoch': 4.5355, 'loss': 0.13186215, 'lr': 0, 'params': 451793, 'time_iter': 0.03516, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6774}
2025-08-17 02:40:16,767 - INFO - > Epoch 4: took 82.4s (avg 82.2s) | Best so far: epoch 4	train_loss: 0.1522 train_auc: 0.6577	val_loss: 0.0930 val_auc: 0.6664	test_loss: 0.1319 test_auc: 0.6774
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:41:29,768 - INFO - train: {'epoch': 5, 'time_epoch': 72.94388, 'eta': 6857.57004, 'eta_hours': 1.90488, 'loss': 0.14935438, 'lr': 0.0001, 'params': 451793, 'time_iter': 0.07089, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67854}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:41:34,289 - INFO - val: {'epoch': 5, 'time_epoch': 4.49717, 'loss': 0.09296284, 'lr': 0, 'params': 451793, 'time_iter': 0.03486, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68845}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:41:38,798 - INFO - test: {'epoch': 5, 'time_epoch': 4.49207, 'loss': 0.12899619, 'lr': 0, 'params': 451793, 'time_iter': 0.03482, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71444}
2025-08-17 02:41:38,800 - INFO - > Epoch 5: took 82.0s (avg 82.2s) | Best so far: epoch 5	train_loss: 0.1494 train_auc: 0.6785	val_loss: 0.0930 val_auc: 0.6885	test_loss: 0.1290 test_auc: 0.7144
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:42:50,929 - INFO - train: {'epoch': 6, 'time_epoch': 72.07268, 'eta': 6772.92315, 'eta_hours': 1.88137, 'loss': 0.14508146, 'lr': 9.997e-05, 'params': 451793, 'time_iter': 0.07004, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71234}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:42:55,409 - INFO - val: {'epoch': 6, 'time_epoch': 4.4573, 'loss': 0.09232877, 'lr': 0, 'params': 451793, 'time_iter': 0.03455, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70131}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:42:59,875 - INFO - test: {'epoch': 6, 'time_epoch': 4.44861, 'loss': 0.12890856, 'lr': 0, 'params': 451793, 'time_iter': 0.03449, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73957}
2025-08-17 02:42:59,878 - INFO - > Epoch 6: took 81.1s (avg 82.0s) | Best so far: epoch 6	train_loss: 0.1451 train_auc: 0.7123	val_loss: 0.0923 val_auc: 0.7013	test_loss: 0.1289 test_auc: 0.7396
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:44:11,443 - INFO - train: {'epoch': 7, 'time_epoch': 71.50859, 'eta': 6684.93284, 'eta_hours': 1.85693, 'loss': 0.14297887, 'lr': 9.989e-05, 'params': 451793, 'time_iter': 0.06949, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72352}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:44:15,935 - INFO - val: {'epoch': 7, 'time_epoch': 4.47048, 'loss': 0.09695975, 'lr': 0, 'params': 451793, 'time_iter': 0.03465, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68448}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:44:20,389 - INFO - test: {'epoch': 7, 'time_epoch': 4.43671, 'loss': 0.13188995, 'lr': 0, 'params': 451793, 'time_iter': 0.03439, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70816}
2025-08-17 02:44:20,392 - INFO - > Epoch 7: took 80.5s (avg 81.8s) | Best so far: epoch 6	train_loss: 0.1451 train_auc: 0.7123	val_loss: 0.0923 val_auc: 0.7013	test_loss: 0.1289 test_auc: 0.7396
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:45:32,865 - INFO - train: {'epoch': 8, 'time_epoch': 72.41713, 'eta': 6609.79149, 'eta_hours': 1.83605, 'loss': 0.14072803, 'lr': 9.975e-05, 'params': 451793, 'time_iter': 0.07038, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73408}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:45:37,346 - INFO - val: {'epoch': 8, 'time_epoch': 4.46009, 'loss': 0.09235014, 'lr': 0, 'params': 451793, 'time_iter': 0.03457, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71301}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:45:41,846 - INFO - test: {'epoch': 8, 'time_epoch': 4.43795, 'loss': 0.12099616, 'lr': 0, 'params': 451793, 'time_iter': 0.0344, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75147}
2025-08-17 02:45:41,848 - INFO - > Epoch 8: took 81.5s (avg 81.8s) | Best so far: epoch 8	train_loss: 0.1407 train_auc: 0.7341	val_loss: 0.0924 val_auc: 0.7130	test_loss: 0.1210 test_auc: 0.7515
2025-08-17 02:46:54,170 - INFO - train: {'epoch': 9, 'time_epoch': 72.25059, 'eta': 6533.69608, 'eta_hours': 1.81492, 'loss': 0.1386881, 'lr': 9.956e-05, 'params': 451793, 'time_iter': 0.07021, 'accuracy': 0.96252, 'precision': 0.4, 'recall': 0.00162, 'f1': 0.00323, 'auc': 0.7389}
2025-08-17 02:46:58,710 - INFO - val: {'epoch': 9, 'time_epoch': 4.51492, 'loss': 0.08971138, 'lr': 0, 'params': 451793, 'time_iter': 0.035, 'accuracy': 0.98152, 'precision': 0.85714, 'recall': 0.07407, 'f1': 0.13636, 'auc': 0.70444}
2025-08-17 02:47:03,229 - INFO - test: {'epoch': 9, 'time_epoch': 4.50009, 'loss': 0.12001485, 'lr': 0, 'params': 451793, 'time_iter': 0.03488, 'accuracy': 0.96888, 'precision': 1.0, 'recall': 0.01538, 'f1': 0.0303, 'auc': 0.75192}
2025-08-17 02:47:03,240 - INFO - > Epoch 9: took 81.4s (avg 81.8s) | Best so far: epoch 8	train_loss: 0.1407 train_auc: 0.7341	val_loss: 0.0924 val_auc: 0.7130	test_loss: 0.1210 test_auc: 0.7515
2025-08-17 02:48:15,521 - INFO - train: {'epoch': 10, 'time_epoch': 72.20804, 'eta': 6457.95544, 'eta_hours': 1.79388, 'loss': 0.13732265, 'lr': 9.932e-05, 'params': 451793, 'time_iter': 0.07017, 'accuracy': 0.96268, 'precision': 0.61111, 'recall': 0.00893, 'f1': 0.0176, 'auc': 0.74918}
2025-08-17 02:48:20,041 - INFO - val: {'epoch': 10, 'time_epoch': 4.49545, 'loss': 0.08555375, 'lr': 0, 'params': 451793, 'time_iter': 0.03485, 'accuracy': 0.97958, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74334}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 02:48:24,540 - INFO - test: {'epoch': 10, 'time_epoch': 4.48181, 'loss': 0.12508332, 'lr': 0, 'params': 451793, 'time_iter': 0.03474, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75106}
2025-08-17 02:48:24,542 - INFO - > Epoch 10: took 81.3s (avg 81.7s) | Best so far: epoch 10	train_loss: 0.1373 train_auc: 0.7492	val_loss: 0.0856 val_auc: 0.7433	test_loss: 0.1251 test_auc: 0.7511
2025-08-17 02:49:37,285 - INFO - train: {'epoch': 11, 'time_epoch': 72.6714, 'eta': 6386.20156, 'eta_hours': 1.77394, 'loss': 0.13628168, 'lr': 9.902e-05, 'params': 451793, 'time_iter': 0.07062, 'accuracy': 0.96359, 'precision': 0.6371, 'recall': 0.06412, 'f1': 0.11652, 'auc': 0.74546}
2025-08-17 02:49:41,739 - INFO - val: {'epoch': 11, 'time_epoch': 4.43016, 'loss': 0.08515814, 'lr': 0, 'params': 451793, 'time_iter': 0.03434, 'accuracy': 0.98055, 'precision': 0.53846, 'recall': 0.08642, 'f1': 0.14894, 'auc': 0.73779}
2025-08-17 02:49:46,214 - INFO - test: {'epoch': 11, 'time_epoch': 4.45648, 'loss': 0.11655408, 'lr': 0, 'params': 451793, 'time_iter': 0.03455, 'accuracy': 0.97009, 'precision': 0.68421, 'recall': 0.1, 'f1': 0.1745, 'auc': 0.76192}
2025-08-17 02:49:46,218 - INFO - > Epoch 11: took 81.7s (avg 81.7s) | Best so far: epoch 10	train_loss: 0.1373 train_auc: 0.7492	val_loss: 0.0856 val_auc: 0.7433	test_loss: 0.1251 test_auc: 0.7511
2025-08-17 02:50:58,087 - INFO - train: {'epoch': 12, 'time_epoch': 71.7973, 'eta': 6308.4568, 'eta_hours': 1.75235, 'loss': 0.13288602, 'lr': 9.867e-05, 'params': 451793, 'time_iter': 0.06977, 'accuracy': 0.96359, 'precision': 0.59444, 'recall': 0.08685, 'f1': 0.15156, 'auc': 0.76891}
2025-08-17 02:51:02,640 - INFO - val: {'epoch': 12, 'time_epoch': 4.52826, 'loss': 0.08356953, 'lr': 0, 'params': 451793, 'time_iter': 0.0351, 'accuracy': 0.98055, 'precision': 0.52632, 'recall': 0.12346, 'f1': 0.2, 'auc': 0.75949}
2025-08-17 02:51:07,159 - INFO - test: {'epoch': 12, 'time_epoch': 4.50007, 'loss': 0.12085527, 'lr': 0, 'params': 451793, 'time_iter': 0.03488, 'accuracy': 0.96912, 'precision': 0.57895, 'recall': 0.08462, 'f1': 0.14765, 'auc': 0.73427}
2025-08-17 02:51:07,161 - INFO - > Epoch 12: took 80.9s (avg 81.7s) | Best so far: epoch 12	train_loss: 0.1329 train_auc: 0.7689	val_loss: 0.0836 val_auc: 0.7595	test_loss: 0.1209 test_auc: 0.7343
2025-08-17 02:52:19,302 - INFO - train: {'epoch': 13, 'time_epoch': 72.06913, 'eta': 6233.23149, 'eta_hours': 1.73145, 'loss': 0.13129013, 'lr': 9.826e-05, 'params': 451793, 'time_iter': 0.07004, 'accuracy': 0.96441, 'precision': 0.63203, 'recall': 0.11851, 'f1': 0.19959, 'auc': 0.77654}
2025-08-17 02:52:23,844 - INFO - val: {'epoch': 13, 'time_epoch': 4.5174, 'loss': 0.08974029, 'lr': 0, 'params': 451793, 'time_iter': 0.03502, 'accuracy': 0.98055, 'precision': 0.51724, 'recall': 0.18519, 'f1': 0.27273, 'auc': 0.76452}
2025-08-17 02:52:28,372 - INFO - test: {'epoch': 13, 'time_epoch': 4.50866, 'loss': 0.12095707, 'lr': 0, 'params': 451793, 'time_iter': 0.03495, 'accuracy': 0.96912, 'precision': 0.52941, 'recall': 0.20769, 'f1': 0.29834, 'auc': 0.74233}
2025-08-17 02:52:28,375 - INFO - > Epoch 13: took 81.2s (avg 81.6s) | Best so far: epoch 13	train_loss: 0.1313 train_auc: 0.7765	val_loss: 0.0897 val_auc: 0.7645	test_loss: 0.1210 test_auc: 0.7423
2025-08-17 02:53:41,112 - INFO - train: {'epoch': 14, 'time_epoch': 72.66525, 'eta': 6161.805, 'eta_hours': 1.71161, 'loss': 0.13105323, 'lr': 9.78e-05, 'params': 451793, 'time_iter': 0.07062, 'accuracy': 0.96459, 'precision': 0.63137, 'recall': 0.13068, 'f1': 0.21654, 'auc': 0.77451}
2025-08-17 02:53:45,651 - INFO - val: {'epoch': 14, 'time_epoch': 4.51522, 'loss': 0.08710716, 'lr': 0, 'params': 451793, 'time_iter': 0.035, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.14815, 'f1': 0.22857, 'auc': 0.75856}
2025-08-17 02:53:50,170 - INFO - test: {'epoch': 14, 'time_epoch': 4.49911, 'loss': 0.11816195, 'lr': 0, 'params': 451793, 'time_iter': 0.03488, 'accuracy': 0.96766, 'precision': 0.44444, 'recall': 0.09231, 'f1': 0.15287, 'auc': 0.76417}
2025-08-17 02:53:50,172 - INFO - > Epoch 14: took 81.8s (avg 81.6s) | Best so far: epoch 13	train_loss: 0.1313 train_auc: 0.7765	val_loss: 0.0897 val_auc: 0.7645	test_loss: 0.1210 test_auc: 0.7423
2025-08-17 02:55:03,594 - INFO - train: {'epoch': 15, 'time_epoch': 73.34782, 'eta': 6093.80718, 'eta_hours': 1.69272, 'loss': 0.1293054, 'lr': 9.729e-05, 'params': 451793, 'time_iter': 0.07128, 'accuracy': 0.96453, 'precision': 0.62948, 'recall': 0.12825, 'f1': 0.21308, 'auc': 0.78734}
2025-08-17 02:55:08,094 - INFO - val: {'epoch': 15, 'time_epoch': 4.47216, 'loss': 0.08446512, 'lr': 0, 'params': 451793, 'time_iter': 0.03467, 'accuracy': 0.98104, 'precision': 0.56522, 'recall': 0.16049, 'f1': 0.25, 'auc': 0.71457}
2025-08-17 02:55:12,626 - INFO - test: {'epoch': 15, 'time_epoch': 4.51272, 'loss': 0.1180153, 'lr': 0, 'params': 451793, 'time_iter': 0.03498, 'accuracy': 0.96912, 'precision': 0.52941, 'recall': 0.20769, 'f1': 0.29834, 'auc': 0.75302}
2025-08-17 02:55:12,630 - INFO - > Epoch 15: took 82.5s (avg 81.7s) | Best so far: epoch 13	train_loss: 0.1313 train_auc: 0.7765	val_loss: 0.0897 val_auc: 0.7645	test_loss: 0.1210 test_auc: 0.7423
2025-08-17 02:56:25,205 - INFO - train: {'epoch': 16, 'time_epoch': 72.50179, 'eta': 6021.04931, 'eta_hours': 1.67251, 'loss': 0.12780933, 'lr': 9.673e-05, 'params': 451793, 'time_iter': 0.07046, 'accuracy': 0.96517, 'precision': 0.64333, 'recall': 0.15666, 'f1': 0.25196, 'auc': 0.79188}
2025-08-17 02:56:29,693 - INFO - val: {'epoch': 16, 'time_epoch': 4.45554, 'loss': 0.09045479, 'lr': 0, 'params': 451793, 'time_iter': 0.03454, 'accuracy': 0.98006, 'precision': 0.44444, 'recall': 0.04938, 'f1': 0.08889, 'auc': 0.6968}
2025-08-17 02:56:34,168 - INFO - test: {'epoch': 16, 'time_epoch': 4.45258, 'loss': 0.13514801, 'lr': 0, 'params': 451793, 'time_iter': 0.03452, 'accuracy': 0.96718, 'precision': 0.14286, 'recall': 0.00769, 'f1': 0.0146, 'auc': 0.70728}
2025-08-17 02:56:34,172 - INFO - > Epoch 16: took 81.5s (avg 81.7s) | Best so far: epoch 13	train_loss: 0.1313 train_auc: 0.7765	val_loss: 0.0897 val_auc: 0.7645	test_loss: 0.1210 test_auc: 0.7423
2025-08-17 02:57:46,603 - INFO - train: {'epoch': 17, 'time_epoch': 72.36111, 'eta': 5947.679, 'eta_hours': 1.65213, 'loss': 0.12870077, 'lr': 9.611e-05, 'params': 451793, 'time_iter': 0.07032, 'accuracy': 0.96429, 'precision': 0.59596, 'recall': 0.14367, 'f1': 0.23152, 'auc': 0.78372}
2025-08-17 02:57:51,087 - INFO - val: {'epoch': 17, 'time_epoch': 4.4598, 'loss': 0.08322097, 'lr': 0, 'params': 451793, 'time_iter': 0.03457, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.16049, 'f1': 0.24299, 'auc': 0.77641}
2025-08-17 02:57:55,571 - INFO - test: {'epoch': 17, 'time_epoch': 4.46204, 'loss': 0.11786616, 'lr': 0, 'params': 451793, 'time_iter': 0.03459, 'accuracy': 0.96888, 'precision': 0.52, 'recall': 0.2, 'f1': 0.28889, 'auc': 0.75652}
2025-08-17 02:57:55,574 - INFO - > Epoch 17: took 81.4s (avg 81.7s) | Best so far: epoch 17	train_loss: 0.1287 train_auc: 0.7837	val_loss: 0.0832 val_auc: 0.7764	test_loss: 0.1179 test_auc: 0.7565
2025-08-17 02:59:07,986 - INFO - train: {'epoch': 18, 'time_epoch': 72.33891, 'eta': 5874.32028, 'eta_hours': 1.63176, 'loss': 0.12676092, 'lr': 9.545e-05, 'params': 451793, 'time_iter': 0.0703, 'accuracy': 0.96413, 'precision': 0.58228, 'recall': 0.14935, 'f1': 0.23773, 'auc': 0.79609}
2025-08-17 02:59:12,522 - INFO - val: {'epoch': 18, 'time_epoch': 4.51048, 'loss': 0.08452572, 'lr': 0, 'params': 451793, 'time_iter': 0.03496, 'accuracy': 0.97885, 'precision': 0.4, 'recall': 0.14815, 'f1': 0.21622, 'auc': 0.77655}
2025-08-17 02:59:17,066 - INFO - test: {'epoch': 18, 'time_epoch': 4.52208, 'loss': 0.11946172, 'lr': 0, 'params': 451793, 'time_iter': 0.03505, 'accuracy': 0.96766, 'precision': 0.45161, 'recall': 0.10769, 'f1': 0.17391, 'auc': 0.74713}
2025-08-17 02:59:17,068 - INFO - > Epoch 18: took 81.5s (avg 81.7s) | Best so far: epoch 18	train_loss: 0.1268 train_auc: 0.7961	val_loss: 0.0845 val_auc: 0.7765	test_loss: 0.1195 test_auc: 0.7471
2025-08-17 03:00:29,471 - INFO - train: {'epoch': 19, 'time_epoch': 72.33178, 'eta': 5801.03502, 'eta_hours': 1.6114, 'loss': 0.12582292, 'lr': 9.474e-05, 'params': 451793, 'time_iter': 0.07029, 'accuracy': 0.96468, 'precision': 0.61076, 'recall': 0.15666, 'f1': 0.24935, 'auc': 0.80196}
2025-08-17 03:00:33,960 - INFO - val: {'epoch': 19, 'time_epoch': 4.46495, 'loss': 0.0861916, 'lr': 0, 'params': 451793, 'time_iter': 0.03461, 'accuracy': 0.98152, 'precision': 0.5641, 'recall': 0.2716, 'f1': 0.36667, 'auc': 0.75837}
2025-08-17 03:00:38,448 - INFO - test: {'epoch': 19, 'time_epoch': 4.46843, 'loss': 0.12030206, 'lr': 0, 'params': 451793, 'time_iter': 0.03464, 'accuracy': 0.96864, 'precision': 0.50667, 'recall': 0.29231, 'f1': 0.37073, 'auc': 0.74478}
2025-08-17 03:00:38,450 - INFO - > Epoch 19: took 81.4s (avg 81.6s) | Best so far: epoch 18	train_loss: 0.1268 train_auc: 0.7961	val_loss: 0.0845 val_auc: 0.7765	test_loss: 0.1195 test_auc: 0.7471
2025-08-17 03:01:51,035 - INFO - train: {'epoch': 20, 'time_epoch': 72.51478, 'eta': 5728.529, 'eta_hours': 1.59126, 'loss': 0.12533922, 'lr': 9.397e-05, 'params': 451793, 'time_iter': 0.07047, 'accuracy': 0.96471, 'precision': 0.60856, 'recall': 0.16153, 'f1': 0.25529, 'auc': 0.79545}
2025-08-17 03:01:55,555 - INFO - val: {'epoch': 20, 'time_epoch': 4.49637, 'loss': 0.0772941, 'lr': 0, 'params': 451793, 'time_iter': 0.03486, 'accuracy': 0.98201, 'precision': 0.64, 'recall': 0.19753, 'f1': 0.30189, 'auc': 0.77762}
2025-08-17 03:02:00,083 - INFO - test: {'epoch': 20, 'time_epoch': 4.5084, 'loss': 0.11648886, 'lr': 0, 'params': 451793, 'time_iter': 0.03495, 'accuracy': 0.96985, 'precision': 0.59375, 'recall': 0.14615, 'f1': 0.23457, 'auc': 0.74724}
2025-08-17 03:02:00,086 - INFO - > Epoch 20: took 81.6s (avg 81.6s) | Best so far: epoch 20	train_loss: 0.1253 train_auc: 0.7954	val_loss: 0.0773 val_auc: 0.7776	test_loss: 0.1165 test_auc: 0.7472
2025-08-17 03:03:12,181 - INFO - train: {'epoch': 21, 'time_epoch': 71.98409, 'eta': 5654.14067, 'eta_hours': 1.57059, 'loss': 0.12323857, 'lr': 9.316e-05, 'params': 451793, 'time_iter': 0.06996, 'accuracy': 0.96556, 'precision': 0.65231, 'recall': 0.17208, 'f1': 0.27232, 'auc': 0.80924}
2025-08-17 03:03:16,727 - INFO - val: {'epoch': 21, 'time_epoch': 4.52163, 'loss': 0.08042429, 'lr': 0, 'params': 451793, 'time_iter': 0.03505, 'accuracy': 0.98152, 'precision': 0.57576, 'recall': 0.23457, 'f1': 0.33333, 'auc': 0.7705}
2025-08-17 03:03:21,256 - INFO - test: {'epoch': 21, 'time_epoch': 4.5092, 'loss': 0.11839646, 'lr': 0, 'params': 451793, 'time_iter': 0.03496, 'accuracy': 0.96791, 'precision': 0.48214, 'recall': 0.20769, 'f1': 0.29032, 'auc': 0.75475}
2025-08-17 03:03:21,258 - INFO - > Epoch 21: took 81.2s (avg 81.6s) | Best so far: epoch 20	train_loss: 0.1253 train_auc: 0.7954	val_loss: 0.0773 val_auc: 0.7776	test_loss: 0.1165 test_auc: 0.7472
2025-08-17 03:04:33,382 - INFO - train: {'epoch': 22, 'time_epoch': 72.05211, 'eta': 5580.18909, 'eta_hours': 1.55005, 'loss': 0.12357975, 'lr': 9.23e-05, 'params': 451793, 'time_iter': 0.07002, 'accuracy': 0.96559, 'precision': 0.64045, 'recall': 0.18506, 'f1': 0.28715, 'auc': 0.80501}
2025-08-17 03:04:37,875 - INFO - val: {'epoch': 22, 'time_epoch': 4.46849, 'loss': 0.07746367, 'lr': 0, 'params': 451793, 'time_iter': 0.03464, 'accuracy': 0.98177, 'precision': 0.58824, 'recall': 0.24691, 'f1': 0.34783, 'auc': 0.79681}
2025-08-17 03:04:42,350 - INFO - test: {'epoch': 22, 'time_epoch': 4.45229, 'loss': 0.11415013, 'lr': 0, 'params': 451793, 'time_iter': 0.03451, 'accuracy': 0.97082, 'precision': 0.59259, 'recall': 0.24615, 'f1': 0.34783, 'auc': 0.7738}
2025-08-17 03:04:42,352 - INFO - > Epoch 22: took 81.1s (avg 81.6s) | Best so far: epoch 22	train_loss: 0.1236 train_auc: 0.8050	val_loss: 0.0775 val_auc: 0.7968	test_loss: 0.1142 test_auc: 0.7738
2025-08-17 03:05:54,507 - INFO - train: {'epoch': 23, 'time_epoch': 72.08404, 'eta': 5506.49694, 'eta_hours': 1.52958, 'loss': 0.12282895, 'lr': 9.14e-05, 'params': 451793, 'time_iter': 0.07005, 'accuracy': 0.96547, 'precision': 0.63636, 'recall': 0.18182, 'f1': 0.28283, 'auc': 0.80805}
2025-08-17 03:05:58,993 - INFO - val: {'epoch': 23, 'time_epoch': 4.4612, 'loss': 0.0767413, 'lr': 0, 'params': 451793, 'time_iter': 0.03458, 'accuracy': 0.98249, 'precision': 0.63636, 'recall': 0.25926, 'f1': 0.36842, 'auc': 0.77506}
2025-08-17 03:06:03,468 - INFO - test: {'epoch': 23, 'time_epoch': 4.45631, 'loss': 0.11309957, 'lr': 0, 'params': 451793, 'time_iter': 0.03455, 'accuracy': 0.97131, 'precision': 0.62, 'recall': 0.23846, 'f1': 0.34444, 'auc': 0.75928}
2025-08-17 03:06:03,471 - INFO - > Epoch 23: took 81.1s (avg 81.6s) | Best so far: epoch 22	train_loss: 0.1236 train_auc: 0.8050	val_loss: 0.0775 val_auc: 0.7968	test_loss: 0.1142 test_auc: 0.7738
2025-08-17 03:07:16,228 - INFO - train: {'epoch': 24, 'time_epoch': 72.68552, 'eta': 5434.73788, 'eta_hours': 1.50965, 'loss': 0.12171217, 'lr': 9.045e-05, 'params': 451793, 'time_iter': 0.07064, 'accuracy': 0.96508, 'precision': 0.61126, 'recall': 0.18506, 'f1': 0.28411, 'auc': 0.8175}
2025-08-17 03:07:20,753 - INFO - val: {'epoch': 24, 'time_epoch': 4.50058, 'loss': 0.07594244, 'lr': 0, 'params': 451793, 'time_iter': 0.03489, 'accuracy': 0.98249, 'precision': 0.68, 'recall': 0.20988, 'f1': 0.32075, 'auc': 0.77685}
2025-08-17 03:07:25,271 - INFO - test: {'epoch': 24, 'time_epoch': 4.49842, 'loss': 0.11733942, 'lr': 0, 'params': 451793, 'time_iter': 0.03487, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.08462, 'f1': 0.14474, 'auc': 0.75424}
2025-08-17 03:07:25,273 - INFO - > Epoch 24: took 81.8s (avg 81.6s) | Best so far: epoch 22	train_loss: 0.1236 train_auc: 0.8050	val_loss: 0.0775 val_auc: 0.7968	test_loss: 0.1142 test_auc: 0.7738
2025-08-17 03:08:37,362 - INFO - train: {'epoch': 25, 'time_epoch': 72.01665, 'eta': 5361.00384, 'eta_hours': 1.48917, 'loss': 0.12184401, 'lr': 8.946e-05, 'params': 451793, 'time_iter': 0.06999, 'accuracy': 0.96553, 'precision': 0.62069, 'recall': 0.20455, 'f1': 0.30769, 'auc': 0.80788}
2025-08-17 03:08:41,884 - INFO - val: {'epoch': 25, 'time_epoch': 4.49872, 'loss': 0.07713404, 'lr': 0, 'params': 451793, 'time_iter': 0.03487, 'accuracy': 0.98152, 'precision': 0.57143, 'recall': 0.24691, 'f1': 0.34483, 'auc': 0.7509}
2025-08-17 03:08:46,352 - INFO - test: {'epoch': 25, 'time_epoch': 4.44942, 'loss': 0.11495277, 'lr': 0, 'params': 451793, 'time_iter': 0.03449, 'accuracy': 0.97034, 'precision': 0.58696, 'recall': 0.20769, 'f1': 0.30682, 'auc': 0.74809}
2025-08-17 03:08:46,354 - INFO - > Epoch 25: took 81.1s (avg 81.6s) | Best so far: epoch 22	train_loss: 0.1236 train_auc: 0.8050	val_loss: 0.0775 val_auc: 0.7968	test_loss: 0.1142 test_auc: 0.7738
2025-08-17 03:10:00,668 - INFO - train: {'epoch': 26, 'time_epoch': 74.23811, 'eta': 5293.40319, 'eta_hours': 1.47039, 'loss': 0.12031884, 'lr': 8.842e-05, 'params': 451793, 'time_iter': 0.07215, 'accuracy': 0.96547, 'precision': 0.60959, 'recall': 0.21672, 'f1': 0.31976, 'auc': 0.81506}
2025-08-17 03:10:05,249 - INFO - val: {'epoch': 26, 'time_epoch': 4.55443, 'loss': 0.07611078, 'lr': 0, 'params': 451793, 'time_iter': 0.03531, 'accuracy': 0.98225, 'precision': 0.65385, 'recall': 0.20988, 'f1': 0.31776, 'auc': 0.75601}
2025-08-17 03:10:09,797 - INFO - test: {'epoch': 26, 'time_epoch': 4.52809, 'loss': 0.11272323, 'lr': 0, 'params': 451793, 'time_iter': 0.0351, 'accuracy': 0.97082, 'precision': 0.61364, 'recall': 0.20769, 'f1': 0.31034, 'auc': 0.76398}
2025-08-17 03:10:09,800 - INFO - > Epoch 26: took 83.4s (avg 81.6s) | Best so far: epoch 22	train_loss: 0.1236 train_auc: 0.8050	val_loss: 0.0775 val_auc: 0.7968	test_loss: 0.1142 test_auc: 0.7738
2025-08-17 03:11:22,643 - INFO - train: {'epoch': 27, 'time_epoch': 72.77033, 'eta': 5221.55413, 'eta_hours': 1.45043, 'loss': 0.12150325, 'lr': 8.734e-05, 'params': 451793, 'time_iter': 0.07072, 'accuracy': 0.96584, 'precision': 0.63568, 'recall': 0.20536, 'f1': 0.31043, 'auc': 0.81219}
2025-08-17 03:11:27,144 - INFO - val: {'epoch': 27, 'time_epoch': 4.47678, 'loss': 0.07705665, 'lr': 0, 'params': 451793, 'time_iter': 0.0347, 'accuracy': 0.98395, 'precision': 0.72727, 'recall': 0.2963, 'f1': 0.42105, 'auc': 0.75832}
2025-08-17 03:11:31,636 - INFO - test: {'epoch': 27, 'time_epoch': 4.472, 'loss': 0.11537498, 'lr': 0, 'params': 451793, 'time_iter': 0.03467, 'accuracy': 0.96985, 'precision': 0.56818, 'recall': 0.19231, 'f1': 0.28736, 'auc': 0.76426}
2025-08-17 03:11:31,639 - INFO - > Epoch 27: took 81.8s (avg 81.6s) | Best so far: epoch 22	train_loss: 0.1236 train_auc: 0.8050	val_loss: 0.0775 val_auc: 0.7968	test_loss: 0.1142 test_auc: 0.7738
2025-08-17 03:12:43,749 - INFO - train: {'epoch': 28, 'time_epoch': 72.03826, 'eta': 5147.84923, 'eta_hours': 1.42996, 'loss': 0.11837285, 'lr': 8.622e-05, 'params': 451793, 'time_iter': 0.07001, 'accuracy': 0.96562, 'precision': 0.61882, 'recall': 0.21347, 'f1': 0.31744, 'auc': 0.82835}
2025-08-17 03:12:48,248 - INFO - val: {'epoch': 28, 'time_epoch': 4.47545, 'loss': 0.07812811, 'lr': 0, 'params': 451793, 'time_iter': 0.03469, 'accuracy': 0.98347, 'precision': 0.72414, 'recall': 0.25926, 'f1': 0.38182, 'auc': 0.74197}
2025-08-17 03:12:52,771 - INFO - test: {'epoch': 28, 'time_epoch': 4.50456, 'loss': 0.11655286, 'lr': 0, 'params': 451793, 'time_iter': 0.03492, 'accuracy': 0.96912, 'precision': 0.54545, 'recall': 0.13846, 'f1': 0.22086, 'auc': 0.75456}
2025-08-17 03:12:52,774 - INFO - > Epoch 28: took 81.1s (avg 81.6s) | Best so far: epoch 22	train_loss: 0.1236 train_auc: 0.8050	val_loss: 0.0775 val_auc: 0.7968	test_loss: 0.1142 test_auc: 0.7738
2025-08-17 03:14:04,738 - INFO - train: {'epoch': 29, 'time_epoch': 71.89258, 'eta': 5073.91552, 'eta_hours': 1.40942, 'loss': 0.11800197, 'lr': 8.506e-05, 'params': 451793, 'time_iter': 0.06987, 'accuracy': 0.96599, 'precision': 0.62418, 'recall': 0.23052, 'f1': 0.33669, 'auc': 0.8243}
2025-08-17 03:14:09,276 - INFO - val: {'epoch': 29, 'time_epoch': 4.51357, 'loss': 0.07629637, 'lr': 0, 'params': 451793, 'time_iter': 0.03499, 'accuracy': 0.98322, 'precision': 0.66667, 'recall': 0.2963, 'f1': 0.41026, 'auc': 0.76625}
2025-08-17 03:14:13,822 - INFO - test: {'epoch': 29, 'time_epoch': 4.52226, 'loss': 0.11432904, 'lr': 0, 'params': 451793, 'time_iter': 0.03506, 'accuracy': 0.96888, 'precision': 0.51429, 'recall': 0.27692, 'f1': 0.36, 'auc': 0.75558}
2025-08-17 03:14:13,826 - INFO - > Epoch 29: took 81.1s (avg 81.6s) | Best so far: epoch 22	train_loss: 0.1236 train_auc: 0.8050	val_loss: 0.0775 val_auc: 0.7968	test_loss: 0.1142 test_auc: 0.7738
2025-08-17 03:15:26,406 - INFO - train: {'epoch': 30, 'time_epoch': 72.50818, 'eta': 5001.48369, 'eta_hours': 1.3893, 'loss': 0.11832189, 'lr': 8.386e-05, 'params': 451793, 'time_iter': 0.07046, 'accuracy': 0.96699, 'precision': 0.66977, 'recall': 0.23377, 'f1': 0.34657, 'auc': 0.82838}
2025-08-17 03:15:30,917 - INFO - val: {'epoch': 30, 'time_epoch': 4.48792, 'loss': 0.07465481, 'lr': 0, 'params': 451793, 'time_iter': 0.03479, 'accuracy': 0.98395, 'precision': 0.7027, 'recall': 0.32099, 'f1': 0.44068, 'auc': 0.77682}
2025-08-17 03:15:35,413 - INFO - test: {'epoch': 30, 'time_epoch': 4.47639, 'loss': 0.1161489, 'lr': 0, 'params': 451793, 'time_iter': 0.0347, 'accuracy': 0.96937, 'precision': 0.53448, 'recall': 0.23846, 'f1': 0.32979, 'auc': 0.76261}
2025-08-17 03:15:35,415 - INFO - > Epoch 30: took 81.6s (avg 81.6s) | Best so far: epoch 22	train_loss: 0.1236 train_auc: 0.8050	val_loss: 0.0775 val_auc: 0.7968	test_loss: 0.1142 test_auc: 0.7738
2025-08-17 03:16:47,453 - INFO - train: {'epoch': 31, 'time_epoch': 71.96592, 'eta': 4927.89481, 'eta_hours': 1.36886, 'loss': 0.11662165, 'lr': 8.263e-05, 'params': 451793, 'time_iter': 0.06994, 'accuracy': 0.96629, 'precision': 0.63002, 'recall': 0.24188, 'f1': 0.34956, 'auc': 0.83458}
2025-08-17 03:16:51,980 - INFO - val: {'epoch': 31, 'time_epoch': 4.50235, 'loss': 0.07679002, 'lr': 0, 'params': 451793, 'time_iter': 0.0349, 'accuracy': 0.98225, 'precision': 0.59091, 'recall': 0.32099, 'f1': 0.416, 'auc': 0.77805}
2025-08-17 03:16:56,511 - INFO - test: {'epoch': 31, 'time_epoch': 4.5111, 'loss': 0.12106929, 'lr': 0, 'params': 451793, 'time_iter': 0.03497, 'accuracy': 0.9645, 'precision': 0.42, 'recall': 0.32308, 'f1': 0.36522, 'auc': 0.754}
2025-08-17 03:16:56,513 - INFO - > Epoch 31: took 81.1s (avg 81.6s) | Best so far: epoch 22	train_loss: 0.1236 train_auc: 0.8050	val_loss: 0.0775 val_auc: 0.7968	test_loss: 0.1142 test_auc: 0.7738
2025-08-17 03:18:08,437 - INFO - train: {'epoch': 32, 'time_epoch': 71.85241, 'eta': 4854.17382, 'eta_hours': 1.34838, 'loss': 0.11642134, 'lr': 8.136e-05, 'params': 451793, 'time_iter': 0.06983, 'accuracy': 0.96654, 'precision': 0.63848, 'recall': 0.24513, 'f1': 0.35425, 'auc': 0.83036}
2025-08-17 03:18:12,920 - INFO - val: {'epoch': 32, 'time_epoch': 4.45866, 'loss': 0.07261624, 'lr': 0, 'params': 451793, 'time_iter': 0.03456, 'accuracy': 0.98249, 'precision': 0.62162, 'recall': 0.28395, 'f1': 0.38983, 'auc': 0.78191}
2025-08-17 03:18:17,413 - INFO - test: {'epoch': 32, 'time_epoch': 4.47392, 'loss': 0.11519131, 'lr': 0, 'params': 451793, 'time_iter': 0.03468, 'accuracy': 0.97058, 'precision': 0.56164, 'recall': 0.31538, 'f1': 0.40394, 'auc': 0.74105}
2025-08-17 03:18:17,416 - INFO - > Epoch 32: took 80.9s (avg 81.6s) | Best so far: epoch 22	train_loss: 0.1236 train_auc: 0.8050	val_loss: 0.0775 val_auc: 0.7968	test_loss: 0.1142 test_auc: 0.7738
2025-08-17 03:19:29,679 - INFO - train: {'epoch': 33, 'time_epoch': 72.19078, 'eta': 4781.21958, 'eta_hours': 1.32812, 'loss': 0.1161302, 'lr': 8.005e-05, 'params': 451793, 'time_iter': 0.07016, 'accuracy': 0.96678, 'precision': 0.63984, 'recall': 0.25812, 'f1': 0.36784, 'auc': 0.8304}
2025-08-17 03:19:34,216 - INFO - val: {'epoch': 33, 'time_epoch': 4.5129, 'loss': 0.07337433, 'lr': 0, 'params': 451793, 'time_iter': 0.03498, 'accuracy': 0.98249, 'precision': 0.66667, 'recall': 0.22222, 'f1': 0.33333, 'auc': 0.79051}
2025-08-17 03:19:38,772 - INFO - test: {'epoch': 33, 'time_epoch': 4.53696, 'loss': 0.11691197, 'lr': 0, 'params': 451793, 'time_iter': 0.03517, 'accuracy': 0.96791, 'precision': 0.46154, 'recall': 0.09231, 'f1': 0.15385, 'auc': 0.75596}
2025-08-17 03:19:38,775 - INFO - > Epoch 33: took 81.4s (avg 81.6s) | Best so far: epoch 22	train_loss: 0.1236 train_auc: 0.8050	val_loss: 0.0775 val_auc: 0.7968	test_loss: 0.1142 test_auc: 0.7738
2025-08-17 03:20:50,819 - INFO - train: {'epoch': 34, 'time_epoch': 71.97231, 'eta': 4707.90324, 'eta_hours': 1.30775, 'loss': 0.11546265, 'lr': 7.872e-05, 'params': 451793, 'time_iter': 0.06994, 'accuracy': 0.96769, 'precision': 0.6714, 'recall': 0.26867, 'f1': 0.38377, 'auc': 0.83567}
2025-08-17 03:20:55,299 - INFO - val: {'epoch': 34, 'time_epoch': 4.4554, 'loss': 0.07257208, 'lr': 0, 'params': 451793, 'time_iter': 0.03454, 'accuracy': 0.9842, 'precision': 0.75, 'recall': 0.2963, 'f1': 0.42478, 'auc': 0.78326}
2025-08-17 03:20:59,784 - INFO - test: {'epoch': 34, 'time_epoch': 4.46583, 'loss': 0.11819765, 'lr': 0, 'params': 451793, 'time_iter': 0.03462, 'accuracy': 0.96961, 'precision': 0.56757, 'recall': 0.16154, 'f1': 0.2515, 'auc': 0.7468}
2025-08-17 03:20:59,787 - INFO - > Epoch 34: took 81.0s (avg 81.5s) | Best so far: epoch 22	train_loss: 0.1236 train_auc: 0.8050	val_loss: 0.0775 val_auc: 0.7968	test_loss: 0.1142 test_auc: 0.7738
2025-08-17 03:22:11,518 - INFO - train: {'epoch': 35, 'time_epoch': 71.66002, 'eta': 4634.10638, 'eta_hours': 1.28725, 'loss': 0.11514501, 'lr': 7.735e-05, 'params': 451793, 'time_iter': 0.06964, 'accuracy': 0.96702, 'precision': 0.64054, 'recall': 0.27192, 'f1': 0.38177, 'auc': 0.83802}
2025-08-17 03:22:16,024 - INFO - val: {'epoch': 35, 'time_epoch': 4.48037, 'loss': 0.07564923, 'lr': 0, 'params': 451793, 'time_iter': 0.03473, 'accuracy': 0.98249, 'precision': 0.62857, 'recall': 0.2716, 'f1': 0.37931, 'auc': 0.7913}
2025-08-17 03:22:20,479 - INFO - test: {'epoch': 35, 'time_epoch': 4.43584, 'loss': 0.11461847, 'lr': 0, 'params': 451793, 'time_iter': 0.03439, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.24615, 'f1': 0.3299, 'auc': 0.75275}
2025-08-17 03:22:20,481 - INFO - > Epoch 35: took 80.7s (avg 81.5s) | Best so far: epoch 22	train_loss: 0.1236 train_auc: 0.8050	val_loss: 0.0775 val_auc: 0.7968	test_loss: 0.1142 test_auc: 0.7738
2025-08-17 03:23:32,515 - INFO - train: {'epoch': 36, 'time_epoch': 71.96111, 'eta': 4560.93769, 'eta_hours': 1.26693, 'loss': 0.11361964, 'lr': 7.595e-05, 'params': 451793, 'time_iter': 0.06993, 'accuracy': 0.96778, 'precision': 0.66538, 'recall': 0.28084, 'f1': 0.39498, 'auc': 0.83797}
2025-08-17 03:23:36,991 - INFO - val: {'epoch': 36, 'time_epoch': 4.45079, 'loss': 0.07137179, 'lr': 0, 'params': 451793, 'time_iter': 0.0345, 'accuracy': 0.9842, 'precision': 0.76667, 'recall': 0.28395, 'f1': 0.41441, 'auc': 0.80441}
2025-08-17 03:23:41,447 - INFO - test: {'epoch': 36, 'time_epoch': 4.43766, 'loss': 0.11702064, 'lr': 0, 'params': 451793, 'time_iter': 0.0344, 'accuracy': 0.96888, 'precision': 0.53333, 'recall': 0.12308, 'f1': 0.2, 'auc': 0.75357}
2025-08-17 03:23:41,449 - INFO - > Epoch 36: took 81.0s (avg 81.5s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:24:53,051 - INFO - train: {'epoch': 37, 'time_epoch': 71.52959, 'eta': 4487.12851, 'eta_hours': 1.24642, 'loss': 0.11335402, 'lr': 7.452e-05, 'params': 451793, 'time_iter': 0.06951, 'accuracy': 0.96778, 'precision': 0.65751, 'recall': 0.2914, 'f1': 0.40382, 'auc': 0.83721}
2025-08-17 03:24:57,453 - INFO - val: {'epoch': 37, 'time_epoch': 4.37856, 'loss': 0.07111954, 'lr': 0, 'params': 451793, 'time_iter': 0.03394, 'accuracy': 0.98347, 'precision': 0.66667, 'recall': 0.32099, 'f1': 0.43333, 'auc': 0.8018}
2025-08-17 03:25:01,852 - INFO - test: {'epoch': 37, 'time_epoch': 4.38013, 'loss': 0.11464065, 'lr': 0, 'params': 451793, 'time_iter': 0.03395, 'accuracy': 0.96985, 'precision': 0.54412, 'recall': 0.28462, 'f1': 0.37374, 'auc': 0.75762}
2025-08-17 03:25:01,854 - INFO - > Epoch 37: took 80.4s (avg 81.5s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:26:12,536 - INFO - train: {'epoch': 38, 'time_epoch': 70.61068, 'eta': 4411.99896, 'eta_hours': 1.22556, 'loss': 0.11315637, 'lr': 7.307e-05, 'params': 451793, 'time_iter': 0.06862, 'accuracy': 0.96745, 'precision': 0.65047, 'recall': 0.28247, 'f1': 0.39389, 'auc': 0.83971}
2025-08-17 03:26:16,986 - INFO - val: {'epoch': 38, 'time_epoch': 4.42687, 'loss': 0.07412717, 'lr': 0, 'params': 451793, 'time_iter': 0.03432, 'accuracy': 0.98201, 'precision': 0.6, 'recall': 0.25926, 'f1': 0.36207, 'auc': 0.7855}
2025-08-17 03:26:21,412 - INFO - test: {'epoch': 38, 'time_epoch': 4.40724, 'loss': 0.11333633, 'lr': 0, 'params': 451793, 'time_iter': 0.03416, 'accuracy': 0.97034, 'precision': 0.56667, 'recall': 0.26154, 'f1': 0.35789, 'auc': 0.75489}
2025-08-17 03:26:21,415 - INFO - > Epoch 38: took 79.6s (avg 81.4s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:27:32,361 - INFO - train: {'epoch': 39, 'time_epoch': 70.87498, 'eta': 4337.49181, 'eta_hours': 1.20486, 'loss': 0.11296837, 'lr': 7.159e-05, 'params': 451793, 'time_iter': 0.06888, 'accuracy': 0.96781, 'precision': 0.6629, 'recall': 0.28571, 'f1': 0.39932, 'auc': 0.8393}
2025-08-17 03:27:36,804 - INFO - val: {'epoch': 39, 'time_epoch': 4.41956, 'loss': 0.07398772, 'lr': 0, 'params': 451793, 'time_iter': 0.03426, 'accuracy': 0.98225, 'precision': 0.60526, 'recall': 0.28395, 'f1': 0.38655, 'auc': 0.78777}
2025-08-17 03:27:41,199 - INFO - test: {'epoch': 39, 'time_epoch': 4.37688, 'loss': 0.11614855, 'lr': 0, 'params': 451793, 'time_iter': 0.03393, 'accuracy': 0.96912, 'precision': 0.52459, 'recall': 0.24615, 'f1': 0.33508, 'auc': 0.75806}
2025-08-17 03:27:41,201 - INFO - > Epoch 39: took 79.8s (avg 81.4s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:28:50,384 - INFO - train: {'epoch': 40, 'time_epoch': 69.11423, 'eta': 4260.62807, 'eta_hours': 1.18351, 'loss': 0.11147898, 'lr': 7.008e-05, 'params': 451793, 'time_iter': 0.06717, 'accuracy': 0.96796, 'precision': 0.66421, 'recall': 0.29221, 'f1': 0.40586, 'auc': 0.84889}
2025-08-17 03:28:54,720 - INFO - val: {'epoch': 40, 'time_epoch': 4.31305, 'loss': 0.07326459, 'lr': 0, 'params': 451793, 'time_iter': 0.03343, 'accuracy': 0.98347, 'precision': 0.67568, 'recall': 0.30864, 'f1': 0.42373, 'auc': 0.77442}
2025-08-17 03:28:59,064 - INFO - test: {'epoch': 40, 'time_epoch': 4.32512, 'loss': 0.11625989, 'lr': 0, 'params': 451793, 'time_iter': 0.03353, 'accuracy': 0.96985, 'precision': 0.54839, 'recall': 0.26154, 'f1': 0.35417, 'auc': 0.73927}
2025-08-17 03:28:59,066 - INFO - > Epoch 40: took 77.9s (avg 81.3s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:30:07,897 - INFO - train: {'epoch': 41, 'time_epoch': 68.76371, 'eta': 4183.6493, 'eta_hours': 1.16212, 'loss': 0.11082224, 'lr': 6.856e-05, 'params': 451793, 'time_iter': 0.06683, 'accuracy': 0.96842, 'precision': 0.67706, 'recall': 0.29951, 'f1': 0.41531, 'auc': 0.85002}
2025-08-17 03:30:12,295 - INFO - val: {'epoch': 41, 'time_epoch': 4.37405, 'loss': 0.07208315, 'lr': 0, 'params': 451793, 'time_iter': 0.03391, 'accuracy': 0.98347, 'precision': 0.72414, 'recall': 0.25926, 'f1': 0.38182, 'auc': 0.80098}
2025-08-17 03:30:16,690 - INFO - test: {'epoch': 41, 'time_epoch': 4.37742, 'loss': 0.11635605, 'lr': 0, 'params': 451793, 'time_iter': 0.03393, 'accuracy': 0.96985, 'precision': 0.6, 'recall': 0.13846, 'f1': 0.225, 'auc': 0.75468}
2025-08-17 03:30:16,693 - INFO - > Epoch 41: took 77.6s (avg 81.2s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:31:26,146 - INFO - train: {'epoch': 42, 'time_epoch': 69.38448, 'eta': 4107.87551, 'eta_hours': 1.14108, 'loss': 0.10978706, 'lr': 6.701e-05, 'params': 451793, 'time_iter': 0.06743, 'accuracy': 0.96787, 'precision': 0.66925, 'recall': 0.28084, 'f1': 0.39565, 'auc': 0.85368}
2025-08-17 03:31:30,535 - INFO - val: {'epoch': 42, 'time_epoch': 4.36751, 'loss': 0.07157944, 'lr': 0, 'params': 451793, 'time_iter': 0.03386, 'accuracy': 0.98371, 'precision': 0.675, 'recall': 0.33333, 'f1': 0.44628, 'auc': 0.79225}
2025-08-17 03:31:34,924 - INFO - test: {'epoch': 42, 'time_epoch': 4.3698, 'loss': 0.11707638, 'lr': 0, 'params': 451793, 'time_iter': 0.03387, 'accuracy': 0.96742, 'precision': 0.47619, 'recall': 0.30769, 'f1': 0.37383, 'auc': 0.76841}
2025-08-17 03:31:34,926 - INFO - > Epoch 42: took 78.2s (avg 81.1s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:32:43,748 - INFO - train: {'epoch': 43, 'time_epoch': 68.7532, 'eta': 4031.5887, 'eta_hours': 1.11989, 'loss': 0.11155233, 'lr': 6.545e-05, 'params': 451793, 'time_iter': 0.06682, 'accuracy': 0.96714, 'precision': 0.63555, 'recall': 0.28734, 'f1': 0.39575, 'auc': 0.84726}
2025-08-17 03:32:48,033 - INFO - val: {'epoch': 43, 'time_epoch': 4.26328, 'loss': 0.073253, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.98322, 'precision': 0.66667, 'recall': 0.2963, 'f1': 0.41026, 'auc': 0.78786}
2025-08-17 03:32:52,370 - INFO - test: {'epoch': 43, 'time_epoch': 4.31843, 'loss': 0.11556071, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.96961, 'precision': 0.54098, 'recall': 0.25385, 'f1': 0.34555, 'auc': 0.7475}
2025-08-17 03:32:52,373 - INFO - > Epoch 43: took 77.4s (avg 81.1s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:34:01,051 - INFO - train: {'epoch': 44, 'time_epoch': 68.61082, 'eta': 3955.46268, 'eta_hours': 1.09874, 'loss': 0.11068307, 'lr': 6.387e-05, 'params': 451793, 'time_iter': 0.06668, 'accuracy': 0.96806, 'precision': 0.66916, 'recall': 0.29058, 'f1': 0.40521, 'auc': 0.84941}
2025-08-17 03:34:05,408 - INFO - val: {'epoch': 44, 'time_epoch': 4.3341, 'loss': 0.07470544, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.98249, 'precision': 0.6, 'recall': 0.33333, 'f1': 0.42857, 'auc': 0.79226}
2025-08-17 03:34:09,749 - INFO - test: {'epoch': 44, 'time_epoch': 4.32224, 'loss': 0.12150519, 'lr': 0, 'params': 451793, 'time_iter': 0.03351, 'accuracy': 0.96572, 'precision': 0.44762, 'recall': 0.36154, 'f1': 0.4, 'auc': 0.75768}
2025-08-17 03:34:09,752 - INFO - > Epoch 44: took 77.4s (avg 81.0s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:35:18,828 - INFO - train: {'epoch': 45, 'time_epoch': 69.00786, 'eta': 3880.12951, 'eta_hours': 1.07781, 'loss': 0.10997809, 'lr': 6.227e-05, 'params': 451793, 'time_iter': 0.06706, 'accuracy': 0.96796, 'precision': 0.65893, 'recall': 0.29951, 'f1': 0.41183, 'auc': 0.85725}
2025-08-17 03:35:23,185 - INFO - val: {'epoch': 45, 'time_epoch': 4.3341, 'loss': 0.07238077, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.98347, 'precision': 0.66667, 'recall': 0.32099, 'f1': 0.43333, 'auc': 0.7903}
2025-08-17 03:35:27,547 - INFO - test: {'epoch': 45, 'time_epoch': 4.34321, 'loss': 0.11387183, 'lr': 0, 'params': 451793, 'time_iter': 0.03367, 'accuracy': 0.96961, 'precision': 0.53846, 'recall': 0.26923, 'f1': 0.35897, 'auc': 0.75435}
2025-08-17 03:35:27,549 - INFO - > Epoch 45: took 77.8s (avg 80.9s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:36:35,967 - INFO - train: {'epoch': 46, 'time_epoch': 68.34944, 'eta': 3804.32303, 'eta_hours': 1.05676, 'loss': 0.10942041, 'lr': 6.066e-05, 'params': 451793, 'time_iter': 0.06642, 'accuracy': 0.96842, 'precision': 0.67577, 'recall': 0.30114, 'f1': 0.41662, 'auc': 0.85243}
2025-08-17 03:36:40,305 - INFO - val: {'epoch': 46, 'time_epoch': 4.31534, 'loss': 0.07186615, 'lr': 0, 'params': 451793, 'time_iter': 0.03345, 'accuracy': 0.98468, 'precision': 0.82143, 'recall': 0.28395, 'f1': 0.42202, 'auc': 0.78653}
2025-08-17 03:36:44,627 - INFO - test: {'epoch': 46, 'time_epoch': 4.30462, 'loss': 0.11835457, 'lr': 0, 'params': 451793, 'time_iter': 0.03337, 'accuracy': 0.96888, 'precision': 0.52632, 'recall': 0.15385, 'f1': 0.2381, 'auc': 0.73902}
2025-08-17 03:36:44,629 - INFO - > Epoch 46: took 77.1s (avg 80.8s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:37:53,198 - INFO - train: {'epoch': 47, 'time_epoch': 68.50047, 'eta': 3728.99087, 'eta_hours': 1.03583, 'loss': 0.10945926, 'lr': 5.904e-05, 'params': 451793, 'time_iter': 0.06657, 'accuracy': 0.96812, 'precision': 0.65858, 'recall': 0.30844, 'f1': 0.42012, 'auc': 0.85206}
2025-08-17 03:37:57,554 - INFO - val: {'epoch': 47, 'time_epoch': 4.3339, 'loss': 0.0750098, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.98322, 'precision': 0.65, 'recall': 0.32099, 'f1': 0.42975, 'auc': 0.77478}
2025-08-17 03:38:01,903 - INFO - test: {'epoch': 47, 'time_epoch': 4.33062, 'loss': 0.11950359, 'lr': 0, 'params': 451793, 'time_iter': 0.03357, 'accuracy': 0.96693, 'precision': 0.45312, 'recall': 0.22308, 'f1': 0.29897, 'auc': 0.7447}
2025-08-17 03:38:01,905 - INFO - > Epoch 47: took 77.3s (avg 80.8s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:39:10,761 - INFO - train: {'epoch': 48, 'time_epoch': 68.78886, 'eta': 3654.23772, 'eta_hours': 1.01507, 'loss': 0.10908458, 'lr': 5.741e-05, 'params': 451793, 'time_iter': 0.06685, 'accuracy': 0.96848, 'precision': 0.6661, 'recall': 0.31737, 'f1': 0.42991, 'auc': 0.85744}
2025-08-17 03:39:15,235 - INFO - val: {'epoch': 48, 'time_epoch': 4.45095, 'loss': 0.07293629, 'lr': 0, 'params': 451793, 'time_iter': 0.0345, 'accuracy': 0.9842, 'precision': 0.72222, 'recall': 0.32099, 'f1': 0.44444, 'auc': 0.78229}
2025-08-17 03:39:19,605 - INFO - test: {'epoch': 48, 'time_epoch': 4.35095, 'loss': 0.11615278, 'lr': 0, 'params': 451793, 'time_iter': 0.03373, 'accuracy': 0.96961, 'precision': 0.53968, 'recall': 0.26154, 'f1': 0.35233, 'auc': 0.74867}
2025-08-17 03:39:19,607 - INFO - > Epoch 48: took 77.7s (avg 80.7s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:40:29,043 - INFO - train: {'epoch': 49, 'time_epoch': 69.36643, 'eta': 3580.30071, 'eta_hours': 0.99453, 'loss': 0.10847861, 'lr': 5.577e-05, 'params': 451793, 'time_iter': 0.06741, 'accuracy': 0.96851, 'precision': 0.67254, 'recall': 0.31006, 'f1': 0.42444, 'auc': 0.85792}
2025-08-17 03:40:33,409 - INFO - val: {'epoch': 49, 'time_epoch': 4.34389, 'loss': 0.07018436, 'lr': 0, 'params': 451793, 'time_iter': 0.03367, 'accuracy': 0.98322, 'precision': 0.6875, 'recall': 0.2716, 'f1': 0.38938, 'auc': 0.78859}
2025-08-17 03:40:37,784 - INFO - test: {'epoch': 49, 'time_epoch': 4.35671, 'loss': 0.11766326, 'lr': 0, 'params': 451793, 'time_iter': 0.03377, 'accuracy': 0.96791, 'precision': 0.47059, 'recall': 0.12308, 'f1': 0.19512, 'auc': 0.75326}
2025-08-17 03:40:37,787 - INFO - > Epoch 49: took 78.2s (avg 80.6s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:41:46,692 - INFO - train: {'epoch': 50, 'time_epoch': 68.83708, 'eta': 3506.03435, 'eta_hours': 0.9739, 'loss': 0.10645574, 'lr': 5.413e-05, 'params': 451793, 'time_iter': 0.0669, 'accuracy': 0.96875, 'precision': 0.67057, 'recall': 0.32549, 'f1': 0.43825, 'auc': 0.86579}
2025-08-17 03:41:51,035 - INFO - val: {'epoch': 50, 'time_epoch': 4.3209, 'loss': 0.07359948, 'lr': 0, 'params': 451793, 'time_iter': 0.0335, 'accuracy': 0.98322, 'precision': 0.65, 'recall': 0.32099, 'f1': 0.42975, 'auc': 0.78618}
2025-08-17 03:41:55,379 - INFO - test: {'epoch': 50, 'time_epoch': 4.32513, 'loss': 0.11784167, 'lr': 0, 'params': 451793, 'time_iter': 0.03353, 'accuracy': 0.96815, 'precision': 0.49275, 'recall': 0.26154, 'f1': 0.34171, 'auc': 0.74803}
2025-08-17 03:41:55,381 - INFO - > Epoch 50: took 77.6s (avg 80.6s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:43:04,322 - INFO - train: {'epoch': 51, 'time_epoch': 68.87348, 'eta': 3432.01041, 'eta_hours': 0.95334, 'loss': 0.10727496, 'lr': 5.248e-05, 'params': 451793, 'time_iter': 0.06693, 'accuracy': 0.96875, 'precision': 0.67958, 'recall': 0.31331, 'f1': 0.42889, 'auc': 0.86072}
2025-08-17 03:43:08,671 - INFO - val: {'epoch': 51, 'time_epoch': 4.32687, 'loss': 0.07372976, 'lr': 0, 'params': 451793, 'time_iter': 0.03354, 'accuracy': 0.98298, 'precision': 0.62222, 'recall': 0.34568, 'f1': 0.44444, 'auc': 0.79335}
2025-08-17 03:43:13,014 - INFO - test: {'epoch': 51, 'time_epoch': 4.32486, 'loss': 0.11891268, 'lr': 0, 'params': 451793, 'time_iter': 0.03353, 'accuracy': 0.96888, 'precision': 0.51724, 'recall': 0.23077, 'f1': 0.31915, 'auc': 0.75292}
2025-08-17 03:43:13,017 - INFO - > Epoch 51: took 77.6s (avg 80.5s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:44:21,799 - INFO - train: {'epoch': 52, 'time_epoch': 68.71432, 'eta': 3358.03968, 'eta_hours': 0.93279, 'loss': 0.10778382, 'lr': 5.083e-05, 'params': 451793, 'time_iter': 0.06678, 'accuracy': 0.9683, 'precision': 0.66845, 'recall': 0.30438, 'f1': 0.41829, 'auc': 0.85953}
2025-08-17 03:44:26,140 - INFO - val: {'epoch': 52, 'time_epoch': 4.31879, 'loss': 0.07434907, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.98322, 'precision': 0.65, 'recall': 0.32099, 'f1': 0.42975, 'auc': 0.78945}
2025-08-17 03:44:30,476 - INFO - test: {'epoch': 52, 'time_epoch': 4.31777, 'loss': 0.11773292, 'lr': 0, 'params': 451793, 'time_iter': 0.03347, 'accuracy': 0.96888, 'precision': 0.52, 'recall': 0.2, 'f1': 0.28889, 'auc': 0.746}
2025-08-17 03:44:30,478 - INFO - > Epoch 52: took 77.5s (avg 80.5s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:45:39,343 - INFO - train: {'epoch': 53, 'time_epoch': 68.79642, 'eta': 3284.33357, 'eta_hours': 0.91231, 'loss': 0.10587695, 'lr': 4.917e-05, 'params': 451793, 'time_iter': 0.06686, 'accuracy': 0.96915, 'precision': 0.6962, 'recall': 0.3125, 'f1': 0.43137, 'auc': 0.86879}
2025-08-17 03:45:43,670 - INFO - val: {'epoch': 53, 'time_epoch': 4.30532, 'loss': 0.07487623, 'lr': 0, 'params': 451793, 'time_iter': 0.03337, 'accuracy': 0.98347, 'precision': 0.66667, 'recall': 0.32099, 'f1': 0.43333, 'auc': 0.77195}
2025-08-17 03:45:48,006 - INFO - test: {'epoch': 53, 'time_epoch': 4.31737, 'loss': 0.12051517, 'lr': 0, 'params': 451793, 'time_iter': 0.03347, 'accuracy': 0.96912, 'precision': 0.5283, 'recall': 0.21538, 'f1': 0.30601, 'auc': 0.74466}
2025-08-17 03:45:48,008 - INFO - > Epoch 53: took 77.5s (avg 80.4s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:46:57,057 - INFO - train: {'epoch': 54, 'time_epoch': 68.98095, 'eta': 3210.95697, 'eta_hours': 0.89193, 'loss': 0.10570677, 'lr': 4.752e-05, 'params': 451793, 'time_iter': 0.06704, 'accuracy': 0.96988, 'precision': 0.70884, 'recall': 0.33198, 'f1': 0.45218, 'auc': 0.86343}
2025-08-17 03:47:01,411 - INFO - val: {'epoch': 54, 'time_epoch': 4.33173, 'loss': 0.07073733, 'lr': 0, 'params': 451793, 'time_iter': 0.03358, 'accuracy': 0.98322, 'precision': 0.67647, 'recall': 0.28395, 'f1': 0.4, 'auc': 0.7982}
2025-08-17 03:47:05,755 - INFO - test: {'epoch': 54, 'time_epoch': 4.32618, 'loss': 0.11387329, 'lr': 0, 'params': 451793, 'time_iter': 0.03354, 'accuracy': 0.9718, 'precision': 0.65217, 'recall': 0.23077, 'f1': 0.34091, 'auc': 0.75782}
2025-08-17 03:47:05,758 - INFO - > Epoch 54: took 77.7s (avg 80.4s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:48:14,489 - INFO - train: {'epoch': 55, 'time_epoch': 68.66302, 'eta': 3137.48755, 'eta_hours': 0.87152, 'loss': 0.10597204, 'lr': 4.587e-05, 'params': 451793, 'time_iter': 0.06673, 'accuracy': 0.96939, 'precision': 0.69634, 'recall': 0.32386, 'f1': 0.44211, 'auc': 0.86844}
2025-08-17 03:48:18,846 - INFO - val: {'epoch': 55, 'time_epoch': 4.33403, 'loss': 0.07273609, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.98298, 'precision': 0.65714, 'recall': 0.28395, 'f1': 0.39655, 'auc': 0.79784}
2025-08-17 03:48:23,191 - INFO - test: {'epoch': 55, 'time_epoch': 4.32651, 'loss': 0.11838172, 'lr': 0, 'params': 451793, 'time_iter': 0.03354, 'accuracy': 0.97034, 'precision': 0.58, 'recall': 0.22308, 'f1': 0.32222, 'auc': 0.75707}
2025-08-17 03:48:23,193 - INFO - > Epoch 55: took 77.4s (avg 80.3s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:49:31,883 - INFO - train: {'epoch': 56, 'time_epoch': 68.62188, 'eta': 3064.15575, 'eta_hours': 0.85115, 'loss': 0.10575868, 'lr': 4.423e-05, 'params': 451793, 'time_iter': 0.06669, 'accuracy': 0.96979, 'precision': 0.70169, 'recall': 0.33604, 'f1': 0.45445, 'auc': 0.868}
2025-08-17 03:49:36,276 - INFO - val: {'epoch': 56, 'time_epoch': 4.36997, 'loss': 0.07623167, 'lr': 0, 'params': 451793, 'time_iter': 0.03388, 'accuracy': 0.98274, 'precision': 0.625, 'recall': 0.30864, 'f1': 0.41322, 'auc': 0.76407}
2025-08-17 03:49:40,652 - INFO - test: {'epoch': 56, 'time_epoch': 4.35798, 'loss': 0.1191106, 'lr': 0, 'params': 451793, 'time_iter': 0.03378, 'accuracy': 0.96985, 'precision': 0.56, 'recall': 0.21538, 'f1': 0.31111, 'auc': 0.74354}
2025-08-17 03:49:40,654 - INFO - > Epoch 56: took 77.5s (avg 80.3s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:50:49,785 - INFO - train: {'epoch': 57, 'time_epoch': 69.06343, 'eta': 2991.3061, 'eta_hours': 0.83092, 'loss': 0.10522442, 'lr': 4.259e-05, 'params': 451793, 'time_iter': 0.06712, 'accuracy': 0.96954, 'precision': 0.69965, 'recall': 0.32711, 'f1': 0.4458, 'auc': 0.86807}
2025-08-17 03:50:54,129 - INFO - val: {'epoch': 57, 'time_epoch': 4.32149, 'loss': 0.07194913, 'lr': 0, 'params': 451793, 'time_iter': 0.0335, 'accuracy': 0.98347, 'precision': 0.68571, 'recall': 0.2963, 'f1': 0.41379, 'auc': 0.79325}
2025-08-17 03:50:58,469 - INFO - test: {'epoch': 57, 'time_epoch': 4.32254, 'loss': 0.11874245, 'lr': 0, 'params': 451793, 'time_iter': 0.03351, 'accuracy': 0.96864, 'precision': 0.5122, 'recall': 0.16154, 'f1': 0.24561, 'auc': 0.75057}
2025-08-17 03:50:58,471 - INFO - > Epoch 57: took 77.8s (avg 80.2s) | Best so far: epoch 36	train_loss: 0.1136 train_auc: 0.8380	val_loss: 0.0714 val_auc: 0.8044	test_loss: 0.1170 test_auc: 0.7536
2025-08-17 03:52:07,343 - INFO - train: {'epoch': 58, 'time_epoch': 68.80316, 'eta': 2918.40394, 'eta_hours': 0.81067, 'loss': 0.10345312, 'lr': 4.096e-05, 'params': 451793, 'time_iter': 0.06686, 'accuracy': 0.97049, 'precision': 0.72232, 'recall': 0.34416, 'f1': 0.46619, 'auc': 0.87567}
2025-08-17 03:52:11,733 - INFO - val: {'epoch': 58, 'time_epoch': 4.36712, 'loss': 0.07132276, 'lr': 0, 'params': 451793, 'time_iter': 0.03385, 'accuracy': 0.98274, 'precision': 0.61905, 'recall': 0.32099, 'f1': 0.42276, 'auc': 0.80756}
2025-08-17 03:52:16,126 - INFO - test: {'epoch': 58, 'time_epoch': 4.37445, 'loss': 0.11954278, 'lr': 0, 'params': 451793, 'time_iter': 0.03391, 'accuracy': 0.96815, 'precision': 0.49333, 'recall': 0.28462, 'f1': 0.36098, 'auc': 0.76059}
2025-08-17 03:52:16,128 - INFO - > Epoch 58: took 77.7s (avg 80.2s) | Best so far: epoch 58	train_loss: 0.1035 train_auc: 0.8757	val_loss: 0.0713 val_auc: 0.8076	test_loss: 0.1195 test_auc: 0.7606
2025-08-17 03:53:25,247 - INFO - train: {'epoch': 59, 'time_epoch': 69.05006, 'eta': 2845.80301, 'eta_hours': 0.7905, 'loss': 0.10502641, 'lr': 3.934e-05, 'params': 451793, 'time_iter': 0.0671, 'accuracy': 0.97003, 'precision': 0.71062, 'recall': 0.33685, 'f1': 0.45705, 'auc': 0.8679}
2025-08-17 03:53:29,590 - INFO - val: {'epoch': 59, 'time_epoch': 4.32175, 'loss': 0.0736385, 'lr': 0, 'params': 451793, 'time_iter': 0.0335, 'accuracy': 0.98371, 'precision': 0.73333, 'recall': 0.2716, 'f1': 0.3964, 'auc': 0.78229}
2025-08-17 03:53:33,925 - INFO - test: {'epoch': 59, 'time_epoch': 4.31756, 'loss': 0.11686312, 'lr': 0, 'params': 451793, 'time_iter': 0.03347, 'accuracy': 0.97034, 'precision': 0.61765, 'recall': 0.16154, 'f1': 0.2561, 'auc': 0.75024}
2025-08-17 03:53:33,928 - INFO - > Epoch 59: took 77.8s (avg 80.1s) | Best so far: epoch 58	train_loss: 0.1035 train_auc: 0.8757	val_loss: 0.0713 val_auc: 0.8076	test_loss: 0.1195 test_auc: 0.7606
2025-08-17 03:54:43,934 - INFO - train: {'epoch': 60, 'time_epoch': 69.93591, 'eta': 2773.88486, 'eta_hours': 0.77052, 'loss': 0.10419936, 'lr': 3.773e-05, 'params': 451793, 'time_iter': 0.06796, 'accuracy': 0.96976, 'precision': 0.70187, 'recall': 0.33442, 'f1': 0.453, 'auc': 0.86946}
2025-08-17 03:54:48,336 - INFO - val: {'epoch': 60, 'time_epoch': 4.37959, 'loss': 0.07418971, 'lr': 0, 'params': 451793, 'time_iter': 0.03395, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.78403}
2025-08-17 03:54:52,724 - INFO - test: {'epoch': 60, 'time_epoch': 4.36831, 'loss': 0.11952399, 'lr': 0, 'params': 451793, 'time_iter': 0.03386, 'accuracy': 0.97009, 'precision': 0.59459, 'recall': 0.16923, 'f1': 0.26347, 'auc': 0.75439}
2025-08-17 03:54:52,726 - INFO - > Epoch 60: took 78.8s (avg 80.1s) | Best so far: epoch 58	train_loss: 0.1035 train_auc: 0.8757	val_loss: 0.0713 val_auc: 0.8076	test_loss: 0.1195 test_auc: 0.7606
2025-08-17 03:56:01,587 - INFO - train: {'epoch': 61, 'time_epoch': 68.7916, 'eta': 2701.3293, 'eta_hours': 0.75037, 'loss': 0.10331108, 'lr': 3.613e-05, 'params': 451793, 'time_iter': 0.06685, 'accuracy': 0.97046, 'precision': 0.71886, 'recall': 0.34659, 'f1': 0.46769, 'auc': 0.87508}
2025-08-17 03:56:05,949 - INFO - val: {'epoch': 61, 'time_epoch': 4.34072, 'loss': 0.07431617, 'lr': 0, 'params': 451793, 'time_iter': 0.03365, 'accuracy': 0.98152, 'precision': 0.54717, 'recall': 0.35802, 'f1': 0.43284, 'auc': 0.8078}
2025-08-17 03:56:10,285 - INFO - test: {'epoch': 61, 'time_epoch': 4.31728, 'loss': 0.12487749, 'lr': 0, 'params': 451793, 'time_iter': 0.03347, 'accuracy': 0.96596, 'precision': 0.45455, 'recall': 0.38462, 'f1': 0.41667, 'auc': 0.75732}
2025-08-17 03:56:10,287 - INFO - > Epoch 61: took 77.6s (avg 80.1s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 03:57:18,987 - INFO - train: {'epoch': 62, 'time_epoch': 68.63249, 'eta': 2628.79979, 'eta_hours': 0.73022, 'loss': 0.10347756, 'lr': 3.455e-05, 'params': 451793, 'time_iter': 0.0667, 'accuracy': 0.97064, 'precision': 0.71875, 'recall': 0.35471, 'f1': 0.475, 'auc': 0.87961}
2025-08-17 03:57:23,344 - INFO - val: {'epoch': 62, 'time_epoch': 4.33497, 'loss': 0.07285934, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.98249, 'precision': 0.61538, 'recall': 0.2963, 'f1': 0.4, 'auc': 0.79538}
2025-08-17 03:57:27,689 - INFO - test: {'epoch': 62, 'time_epoch': 4.32727, 'loss': 0.11841728, 'lr': 0, 'params': 451793, 'time_iter': 0.03354, 'accuracy': 0.96912, 'precision': 0.53061, 'recall': 0.2, 'f1': 0.2905, 'auc': 0.76394}
2025-08-17 03:57:27,692 - INFO - > Epoch 62: took 77.4s (avg 80.0s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 03:58:36,819 - INFO - train: {'epoch': 63, 'time_epoch': 69.05941, 'eta': 2556.6322, 'eta_hours': 0.71018, 'loss': 0.10333022, 'lr': 3.299e-05, 'params': 451793, 'time_iter': 0.06711, 'accuracy': 0.96985, 'precision': 0.69802, 'recall': 0.34334, 'f1': 0.46028, 'auc': 0.87865}
2025-08-17 03:58:41,172 - INFO - val: {'epoch': 63, 'time_epoch': 4.33064, 'loss': 0.07436248, 'lr': 0, 'params': 451793, 'time_iter': 0.03357, 'accuracy': 0.98347, 'precision': 0.67568, 'recall': 0.30864, 'f1': 0.42373, 'auc': 0.77377}
2025-08-17 03:58:45,515 - INFO - test: {'epoch': 63, 'time_epoch': 4.32563, 'loss': 0.12002744, 'lr': 0, 'params': 451793, 'time_iter': 0.03353, 'accuracy': 0.96937, 'precision': 0.55, 'recall': 0.16923, 'f1': 0.25882, 'auc': 0.75347}
2025-08-17 03:58:45,518 - INFO - > Epoch 63: took 77.8s (avg 80.0s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 03:59:54,503 - INFO - train: {'epoch': 64, 'time_epoch': 68.91765, 'eta': 2484.48392, 'eta_hours': 0.69013, 'loss': 0.10280413, 'lr': 3.144e-05, 'params': 451793, 'time_iter': 0.06698, 'accuracy': 0.97049, 'precision': 0.72308, 'recall': 0.34334, 'f1': 0.4656, 'auc': 0.87562}
2025-08-17 03:59:58,856 - INFO - val: {'epoch': 64, 'time_epoch': 4.32972, 'loss': 0.0711054, 'lr': 0, 'params': 451793, 'time_iter': 0.03356, 'accuracy': 0.98274, 'precision': 0.63158, 'recall': 0.2963, 'f1': 0.40336, 'auc': 0.79857}
2025-08-17 04:00:03,237 - INFO - test: {'epoch': 64, 'time_epoch': 4.3623, 'loss': 0.11773277, 'lr': 0, 'params': 451793, 'time_iter': 0.03382, 'accuracy': 0.97009, 'precision': 0.57778, 'recall': 0.2, 'f1': 0.29714, 'auc': 0.76142}
2025-08-17 04:00:03,239 - INFO - > Epoch 64: took 77.7s (avg 80.0s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:01:12,172 - INFO - train: {'epoch': 65, 'time_epoch': 68.86492, 'eta': 2412.40637, 'eta_hours': 0.67011, 'loss': 0.10220841, 'lr': 2.992e-05, 'params': 451793, 'time_iter': 0.06692, 'accuracy': 0.97097, 'precision': 0.73122, 'recall': 0.35552, 'f1': 0.47843, 'auc': 0.87884}
2025-08-17 04:01:16,567 - INFO - val: {'epoch': 65, 'time_epoch': 4.37197, 'loss': 0.07240504, 'lr': 0, 'params': 451793, 'time_iter': 0.03389, 'accuracy': 0.98371, 'precision': 0.68421, 'recall': 0.32099, 'f1': 0.43697, 'auc': 0.78189}
2025-08-17 04:01:20,955 - INFO - test: {'epoch': 65, 'time_epoch': 4.36938, 'loss': 0.11649971, 'lr': 0, 'params': 451793, 'time_iter': 0.03387, 'accuracy': 0.97082, 'precision': 0.61905, 'recall': 0.2, 'f1': 0.30233, 'auc': 0.75937}
2025-08-17 04:01:20,957 - INFO - > Epoch 65: took 77.7s (avg 79.9s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:02:30,126 - INFO - train: {'epoch': 66, 'time_epoch': 69.1012, 'eta': 2340.5411, 'eta_hours': 0.65015, 'loss': 0.10318271, 'lr': 2.841e-05, 'params': 451793, 'time_iter': 0.06715, 'accuracy': 0.97055, 'precision': 0.71452, 'recall': 0.35552, 'f1': 0.4748, 'auc': 0.87628}
2025-08-17 04:02:34,516 - INFO - val: {'epoch': 66, 'time_epoch': 4.36662, 'loss': 0.07335702, 'lr': 0, 'params': 451793, 'time_iter': 0.03385, 'accuracy': 0.98298, 'precision': 0.63415, 'recall': 0.32099, 'f1': 0.42623, 'auc': 0.78359}
2025-08-17 04:02:38,901 - INFO - test: {'epoch': 66, 'time_epoch': 4.36724, 'loss': 0.12003794, 'lr': 0, 'params': 451793, 'time_iter': 0.03385, 'accuracy': 0.96912, 'precision': 0.5283, 'recall': 0.21538, 'f1': 0.30601, 'auc': 0.76063}
2025-08-17 04:02:38,903 - INFO - > Epoch 66: took 77.9s (avg 79.9s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:03:47,504 - INFO - train: {'epoch': 67, 'time_epoch': 68.53505, 'eta': 2268.4907, 'eta_hours': 0.63014, 'loss': 0.10191424, 'lr': 2.693e-05, 'params': 451793, 'time_iter': 0.0666, 'accuracy': 0.97079, 'precision': 0.71272, 'recall': 0.36851, 'f1': 0.48582, 'auc': 0.88079}
2025-08-17 04:03:51,794 - INFO - val: {'epoch': 67, 'time_epoch': 4.26669, 'loss': 0.07300407, 'lr': 0, 'params': 451793, 'time_iter': 0.03308, 'accuracy': 0.98274, 'precision': 0.63889, 'recall': 0.28395, 'f1': 0.39316, 'auc': 0.77938}
2025-08-17 04:03:56,093 - INFO - test: {'epoch': 67, 'time_epoch': 4.28104, 'loss': 0.11578648, 'lr': 0, 'params': 451793, 'time_iter': 0.03319, 'accuracy': 0.97082, 'precision': 0.61905, 'recall': 0.2, 'f1': 0.30233, 'auc': 0.75649}
2025-08-17 04:03:56,096 - INFO - > Epoch 67: took 77.2s (avg 79.9s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:05:06,016 - INFO - train: {'epoch': 68, 'time_epoch': 69.8515, 'eta': 2197.13364, 'eta_hours': 0.61031, 'loss': 0.10212656, 'lr': 2.548e-05, 'params': 451793, 'time_iter': 0.06788, 'accuracy': 0.97055, 'precision': 0.72479, 'recall': 0.34416, 'f1': 0.4667, 'auc': 0.87823}
2025-08-17 04:05:10,362 - INFO - val: {'epoch': 68, 'time_epoch': 4.3242, 'loss': 0.07136691, 'lr': 0, 'params': 451793, 'time_iter': 0.03352, 'accuracy': 0.98347, 'precision': 0.66667, 'recall': 0.32099, 'f1': 0.43333, 'auc': 0.79713}
2025-08-17 04:05:14,718 - INFO - test: {'epoch': 68, 'time_epoch': 4.33838, 'loss': 0.11682011, 'lr': 0, 'params': 451793, 'time_iter': 0.03363, 'accuracy': 0.97058, 'precision': 0.58824, 'recall': 0.23077, 'f1': 0.33149, 'auc': 0.76103}
2025-08-17 04:05:14,720 - INFO - > Epoch 68: took 78.6s (avg 79.8s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:06:23,343 - INFO - train: {'epoch': 69, 'time_epoch': 68.55723, 'eta': 2125.26491, 'eta_hours': 0.59035, 'loss': 0.10007142, 'lr': 2.405e-05, 'params': 451793, 'time_iter': 0.06663, 'accuracy': 0.97073, 'precision': 0.70661, 'recall': 0.37338, 'f1': 0.48858, 'auc': 0.88728}
2025-08-17 04:06:27,634 - INFO - val: {'epoch': 69, 'time_epoch': 4.26922, 'loss': 0.0732657, 'lr': 0, 'params': 451793, 'time_iter': 0.03309, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.77867}
2025-08-17 04:06:31,908 - INFO - test: {'epoch': 69, 'time_epoch': 4.25548, 'loss': 0.1176322, 'lr': 0, 'params': 451793, 'time_iter': 0.03299, 'accuracy': 0.97058, 'precision': 0.60465, 'recall': 0.2, 'f1': 0.30058, 'auc': 0.7632}
2025-08-17 04:06:31,910 - INFO - > Epoch 69: took 77.2s (avg 79.8s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:07:40,188 - INFO - train: {'epoch': 70, 'time_epoch': 68.20952, 'eta': 2053.34744, 'eta_hours': 0.57037, 'loss': 0.10141234, 'lr': 2.265e-05, 'params': 451793, 'time_iter': 0.06629, 'accuracy': 0.97073, 'precision': 0.71799, 'recall': 0.35958, 'f1': 0.47918, 'auc': 0.88026}
2025-08-17 04:07:44,518 - INFO - val: {'epoch': 70, 'time_epoch': 4.30859, 'loss': 0.07339297, 'lr': 0, 'params': 451793, 'time_iter': 0.0334, 'accuracy': 0.98225, 'precision': 0.60526, 'recall': 0.28395, 'f1': 0.38655, 'auc': 0.78315}
2025-08-17 04:07:48,833 - INFO - test: {'epoch': 70, 'time_epoch': 4.29686, 'loss': 0.11816057, 'lr': 0, 'params': 451793, 'time_iter': 0.03331, 'accuracy': 0.97034, 'precision': 0.56897, 'recall': 0.25385, 'f1': 0.35106, 'auc': 0.76687}
2025-08-17 04:07:48,836 - INFO - > Epoch 70: took 76.9s (avg 79.8s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:08:57,421 - INFO - train: {'epoch': 71, 'time_epoch': 68.51707, 'eta': 1981.65257, 'eta_hours': 0.55046, 'loss': 0.10047247, 'lr': 2.128e-05, 'params': 451793, 'time_iter': 0.06659, 'accuracy': 0.97094, 'precision': 0.71698, 'recall': 0.37013, 'f1': 0.48822, 'auc': 0.88262}
2025-08-17 04:09:01,801 - INFO - val: {'epoch': 71, 'time_epoch': 4.35666, 'loss': 0.07259819, 'lr': 0, 'params': 451793, 'time_iter': 0.03377, 'accuracy': 0.98322, 'precision': 0.65, 'recall': 0.32099, 'f1': 0.42975, 'auc': 0.79413}
2025-08-17 04:09:06,156 - INFO - test: {'epoch': 71, 'time_epoch': 4.33635, 'loss': 0.11695832, 'lr': 0, 'params': 451793, 'time_iter': 0.03362, 'accuracy': 0.9718, 'precision': 0.62069, 'recall': 0.27692, 'f1': 0.38298, 'auc': 0.76647}
2025-08-17 04:09:06,159 - INFO - > Epoch 71: took 77.3s (avg 79.7s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:10:15,549 - INFO - train: {'epoch': 72, 'time_epoch': 69.32121, 'eta': 1910.34219, 'eta_hours': 0.53065, 'loss': 0.10191759, 'lr': 1.995e-05, 'params': 451793, 'time_iter': 0.06737, 'accuracy': 0.97043, 'precision': 0.69954, 'recall': 0.36851, 'f1': 0.48272, 'auc': 0.88284}
2025-08-17 04:10:19,902 - INFO - val: {'epoch': 72, 'time_epoch': 4.33082, 'loss': 0.07230075, 'lr': 0, 'params': 451793, 'time_iter': 0.03357, 'accuracy': 0.98322, 'precision': 0.67647, 'recall': 0.28395, 'f1': 0.4, 'auc': 0.7907}
2025-08-17 04:10:24,238 - INFO - test: {'epoch': 72, 'time_epoch': 4.31842, 'loss': 0.11887602, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.97034, 'precision': 0.59091, 'recall': 0.2, 'f1': 0.29885, 'auc': 0.76256}
2025-08-17 04:10:24,241 - INFO - > Epoch 72: took 78.1s (avg 79.7s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:11:32,674 - INFO - train: {'epoch': 73, 'time_epoch': 68.36536, 'eta': 1838.74973, 'eta_hours': 0.51076, 'loss': 0.09998359, 'lr': 1.864e-05, 'params': 451793, 'time_iter': 0.06644, 'accuracy': 0.97113, 'precision': 0.7224, 'recall': 0.37175, 'f1': 0.49089, 'auc': 0.88391}
2025-08-17 04:11:37,015 - INFO - val: {'epoch': 73, 'time_epoch': 4.31905, 'loss': 0.07243693, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.98347, 'precision': 0.67568, 'recall': 0.30864, 'f1': 0.42373, 'auc': 0.79545}
2025-08-17 04:11:41,324 - INFO - test: {'epoch': 73, 'time_epoch': 4.29144, 'loss': 0.11647941, 'lr': 0, 'params': 451793, 'time_iter': 0.03327, 'accuracy': 0.97107, 'precision': 0.59649, 'recall': 0.26154, 'f1': 0.36364, 'auc': 0.76822}
2025-08-17 04:11:41,327 - INFO - > Epoch 73: took 77.1s (avg 79.7s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:12:49,461 - INFO - train: {'epoch': 74, 'time_epoch': 68.06691, 'eta': 1767.14384, 'eta_hours': 0.49087, 'loss': 0.09925446, 'lr': 1.737e-05, 'params': 451793, 'time_iter': 0.06615, 'accuracy': 0.97146, 'precision': 0.73217, 'recall': 0.375, 'f1': 0.49597, 'auc': 0.88696}
2025-08-17 04:12:53,798 - INFO - val: {'epoch': 74, 'time_epoch': 4.31439, 'loss': 0.07353916, 'lr': 0, 'params': 451793, 'time_iter': 0.03344, 'accuracy': 0.98249, 'precision': 0.60465, 'recall': 0.32099, 'f1': 0.41935, 'auc': 0.78672}
2025-08-17 04:12:58,112 - INFO - test: {'epoch': 74, 'time_epoch': 4.29587, 'loss': 0.11862801, 'lr': 0, 'params': 451793, 'time_iter': 0.0333, 'accuracy': 0.96985, 'precision': 0.54167, 'recall': 0.3, 'f1': 0.38614, 'auc': 0.75906}
2025-08-17 04:12:58,115 - INFO - > Epoch 74: took 76.8s (avg 79.6s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:14:06,637 - INFO - train: {'epoch': 75, 'time_epoch': 68.45515, 'eta': 1695.75369, 'eta_hours': 0.47104, 'loss': 0.10065487, 'lr': 1.614e-05, 'params': 451793, 'time_iter': 0.06653, 'accuracy': 0.97152, 'precision': 0.736, 'recall': 0.37338, 'f1': 0.49542, 'auc': 0.8803}
2025-08-17 04:14:10,979 - INFO - val: {'epoch': 75, 'time_epoch': 4.3209, 'loss': 0.07189285, 'lr': 0, 'params': 451793, 'time_iter': 0.0335, 'accuracy': 0.98225, 'precision': 0.59091, 'recall': 0.32099, 'f1': 0.416, 'auc': 0.79527}
2025-08-17 04:14:15,320 - INFO - test: {'epoch': 75, 'time_epoch': 4.32218, 'loss': 0.11800639, 'lr': 0, 'params': 451793, 'time_iter': 0.03351, 'accuracy': 0.96937, 'precision': 0.52857, 'recall': 0.28462, 'f1': 0.37, 'auc': 0.76043}
2025-08-17 04:14:15,322 - INFO - > Epoch 75: took 77.2s (avg 79.6s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:15:24,034 - INFO - train: {'epoch': 76, 'time_epoch': 68.64303, 'eta': 1624.49589, 'eta_hours': 0.45125, 'loss': 0.09929001, 'lr': 1.494e-05, 'params': 451793, 'time_iter': 0.06671, 'accuracy': 0.97097, 'precision': 0.71406, 'recall': 0.375, 'f1': 0.49175, 'auc': 0.89076}
2025-08-17 04:15:28,420 - INFO - val: {'epoch': 76, 'time_epoch': 4.36334, 'loss': 0.07310664, 'lr': 0, 'params': 451793, 'time_iter': 0.03382, 'accuracy': 0.98177, 'precision': 0.575, 'recall': 0.28395, 'f1': 0.38017, 'auc': 0.78712}
2025-08-17 04:15:32,803 - INFO - test: {'epoch': 76, 'time_epoch': 4.36539, 'loss': 0.11968033, 'lr': 0, 'params': 451793, 'time_iter': 0.03384, 'accuracy': 0.97009, 'precision': 0.56604, 'recall': 0.23077, 'f1': 0.32787, 'auc': 0.75497}
2025-08-17 04:15:32,806 - INFO - > Epoch 76: took 77.5s (avg 79.6s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:16:41,394 - INFO - train: {'epoch': 77, 'time_epoch': 68.5197, 'eta': 1553.27035, 'eta_hours': 0.43146, 'loss': 0.09934566, 'lr': 1.378e-05, 'params': 451793, 'time_iter': 0.06659, 'accuracy': 0.97179, 'precision': 0.74051, 'recall': 0.37987, 'f1': 0.50215, 'auc': 0.88806}
2025-08-17 04:16:45,727 - INFO - val: {'epoch': 77, 'time_epoch': 4.31119, 'loss': 0.07353873, 'lr': 0, 'params': 451793, 'time_iter': 0.03342, 'accuracy': 0.98298, 'precision': 0.64865, 'recall': 0.2963, 'f1': 0.40678, 'auc': 0.7897}
2025-08-17 04:16:50,099 - INFO - test: {'epoch': 77, 'time_epoch': 4.35399, 'loss': 0.12183099, 'lr': 0, 'params': 451793, 'time_iter': 0.03375, 'accuracy': 0.97034, 'precision': 0.58696, 'recall': 0.20769, 'f1': 0.30682, 'auc': 0.75946}
2025-08-17 04:16:50,102 - INFO - > Epoch 77: took 77.3s (avg 79.5s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:17:59,232 - INFO - train: {'epoch': 78, 'time_epoch': 69.06255, 'eta': 1482.25761, 'eta_hours': 0.41174, 'loss': 0.09802099, 'lr': 1.266e-05, 'params': 451793, 'time_iter': 0.06712, 'accuracy': 0.97164, 'precision': 0.73396, 'recall': 0.38068, 'f1': 0.50134, 'auc': 0.88911}
2025-08-17 04:18:03,575 - INFO - val: {'epoch': 78, 'time_epoch': 4.32036, 'loss': 0.07346135, 'lr': 0, 'params': 451793, 'time_iter': 0.03349, 'accuracy': 0.98249, 'precision': 0.60976, 'recall': 0.30864, 'f1': 0.40984, 'auc': 0.78959}
2025-08-17 04:18:07,902 - INFO - test: {'epoch': 78, 'time_epoch': 4.30962, 'loss': 0.11927736, 'lr': 0, 'params': 451793, 'time_iter': 0.03341, 'accuracy': 0.96912, 'precision': 0.52459, 'recall': 0.24615, 'f1': 0.33508, 'auc': 0.76269}
2025-08-17 04:18:07,904 - INFO - > Epoch 78: took 77.8s (avg 79.5s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:19:16,216 - INFO - train: {'epoch': 79, 'time_epoch': 68.24583, 'eta': 1411.08945, 'eta_hours': 0.39197, 'loss': 0.09871227, 'lr': 1.158e-05, 'params': 451793, 'time_iter': 0.06632, 'accuracy': 0.97103, 'precision': 0.72831, 'recall': 0.3612, 'f1': 0.48291, 'auc': 0.89109}
2025-08-17 04:19:20,507 - INFO - val: {'epoch': 79, 'time_epoch': 4.26826, 'loss': 0.07290304, 'lr': 0, 'params': 451793, 'time_iter': 0.03309, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.79053}
2025-08-17 04:19:24,838 - INFO - test: {'epoch': 79, 'time_epoch': 4.3132, 'loss': 0.11972289, 'lr': 0, 'params': 451793, 'time_iter': 0.03344, 'accuracy': 0.97058, 'precision': 0.60976, 'recall': 0.19231, 'f1': 0.2924, 'auc': 0.75957}
2025-08-17 04:19:24,840 - INFO - > Epoch 79: took 76.9s (avg 79.5s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:20:33,125 - INFO - train: {'epoch': 80, 'time_epoch': 68.21612, 'eta': 1339.98648, 'eta_hours': 0.37222, 'loss': 0.09956165, 'lr': 1.054e-05, 'params': 451793, 'time_iter': 0.06629, 'accuracy': 0.97076, 'precision': 0.72131, 'recall': 0.35714, 'f1': 0.47774, 'auc': 0.88919}
2025-08-17 04:20:37,479 - INFO - val: {'epoch': 80, 'time_epoch': 4.33162, 'loss': 0.07182875, 'lr': 0, 'params': 451793, 'time_iter': 0.03358, 'accuracy': 0.98347, 'precision': 0.67568, 'recall': 0.30864, 'f1': 0.42373, 'auc': 0.80173}
2025-08-17 04:20:41,806 - INFO - test: {'epoch': 80, 'time_epoch': 4.30856, 'loss': 0.12048258, 'lr': 0, 'params': 451793, 'time_iter': 0.0334, 'accuracy': 0.97009, 'precision': 0.57143, 'recall': 0.21538, 'f1': 0.31285, 'auc': 0.76581}
2025-08-17 04:20:41,809 - INFO - > Epoch 80: took 77.0s (avg 79.5s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:21:50,744 - INFO - train: {'epoch': 81, 'time_epoch': 68.86949, 'eta': 1269.09734, 'eta_hours': 0.35253, 'loss': 0.10007362, 'lr': 9.55e-06, 'params': 451793, 'time_iter': 0.06693, 'accuracy': 0.97055, 'precision': 0.70388, 'recall': 0.36851, 'f1': 0.48375, 'auc': 0.88997}
2025-08-17 04:21:55,026 - INFO - val: {'epoch': 81, 'time_epoch': 4.26027, 'loss': 0.07259462, 'lr': 0, 'params': 451793, 'time_iter': 0.03303, 'accuracy': 0.98322, 'precision': 0.65789, 'recall': 0.30864, 'f1': 0.42017, 'auc': 0.79629}
2025-08-17 04:21:59,368 - INFO - test: {'epoch': 81, 'time_epoch': 4.32373, 'loss': 0.11911923, 'lr': 0, 'params': 451793, 'time_iter': 0.03352, 'accuracy': 0.96937, 'precision': 0.5303, 'recall': 0.26923, 'f1': 0.35714, 'auc': 0.76265}
2025-08-17 04:21:59,370 - INFO - > Epoch 81: took 77.6s (avg 79.4s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:23:08,341 - INFO - train: {'epoch': 82, 'time_epoch': 68.90231, 'eta': 1198.26358, 'eta_hours': 0.33285, 'loss': 0.09921822, 'lr': 8.6e-06, 'params': 451793, 'time_iter': 0.06696, 'accuracy': 0.97067, 'precision': 0.7136, 'recall': 0.36201, 'f1': 0.48034, 'auc': 0.89233}
2025-08-17 04:23:12,739 - INFO - val: {'epoch': 82, 'time_epoch': 4.36768, 'loss': 0.07381181, 'lr': 0, 'params': 451793, 'time_iter': 0.03386, 'accuracy': 0.98225, 'precision': 0.59091, 'recall': 0.32099, 'f1': 0.416, 'auc': 0.79117}
2025-08-17 04:23:17,135 - INFO - test: {'epoch': 82, 'time_epoch': 4.37824, 'loss': 0.11999034, 'lr': 0, 'params': 451793, 'time_iter': 0.03394, 'accuracy': 0.96985, 'precision': 0.54054, 'recall': 0.30769, 'f1': 0.39216, 'auc': 0.7618}
2025-08-17 04:23:17,137 - INFO - > Epoch 82: took 77.8s (avg 79.4s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:24:27,112 - INFO - train: {'epoch': 83, 'time_epoch': 69.9048, 'eta': 1127.66677, 'eta_hours': 0.31324, 'loss': 0.09890209, 'lr': 7.7e-06, 'params': 451793, 'time_iter': 0.06793, 'accuracy': 0.97094, 'precision': 0.71495, 'recall': 0.37256, 'f1': 0.48986, 'auc': 0.89073}
2025-08-17 04:24:31,472 - INFO - val: {'epoch': 83, 'time_epoch': 4.33616, 'loss': 0.07345007, 'lr': 0, 'params': 451793, 'time_iter': 0.03361, 'accuracy': 0.98274, 'precision': 0.625, 'recall': 0.30864, 'f1': 0.41322, 'auc': 0.78756}
2025-08-17 04:24:35,825 - INFO - test: {'epoch': 83, 'time_epoch': 4.33432, 'loss': 0.11940372, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.96985, 'precision': 0.55, 'recall': 0.25385, 'f1': 0.34737, 'auc': 0.76407}
2025-08-17 04:24:35,829 - INFO - > Epoch 83: took 78.7s (avg 79.4s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:25:45,341 - INFO - train: {'epoch': 84, 'time_epoch': 69.44435, 'eta': 1057.00498, 'eta_hours': 0.29361, 'loss': 0.0979069, 'lr': 6.84e-06, 'params': 451793, 'time_iter': 0.06749, 'accuracy': 0.97149, 'precision': 0.72072, 'recall': 0.38961, 'f1': 0.5058, 'auc': 0.89136}
2025-08-17 04:25:49,714 - INFO - val: {'epoch': 84, 'time_epoch': 4.35087, 'loss': 0.07287294, 'lr': 0, 'params': 451793, 'time_iter': 0.03373, 'accuracy': 0.98274, 'precision': 0.61905, 'recall': 0.32099, 'f1': 0.42276, 'auc': 0.79475}
2025-08-17 04:25:54,091 - INFO - test: {'epoch': 84, 'time_epoch': 4.35812, 'loss': 0.11888989, 'lr': 0, 'params': 451793, 'time_iter': 0.03378, 'accuracy': 0.96985, 'precision': 0.54167, 'recall': 0.3, 'f1': 0.38614, 'auc': 0.76417}
2025-08-17 04:25:54,093 - INFO - > Epoch 84: took 78.3s (avg 79.4s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:27:02,590 - INFO - train: {'epoch': 85, 'time_epoch': 68.42904, 'eta': 986.20622, 'eta_hours': 0.27395, 'loss': 0.09838573, 'lr': 6.03e-06, 'params': 451793, 'time_iter': 0.0665, 'accuracy': 0.9717, 'precision': 0.72907, 'recall': 0.3888, 'f1': 0.50715, 'auc': 0.89461}
2025-08-17 04:27:06,961 - INFO - val: {'epoch': 85, 'time_epoch': 4.34638, 'loss': 0.0735602, 'lr': 0, 'params': 451793, 'time_iter': 0.03369, 'accuracy': 0.98274, 'precision': 0.61905, 'recall': 0.32099, 'f1': 0.42276, 'auc': 0.79273}
2025-08-17 04:27:11,324 - INFO - test: {'epoch': 85, 'time_epoch': 4.34529, 'loss': 0.11878009, 'lr': 0, 'params': 451793, 'time_iter': 0.03368, 'accuracy': 0.96985, 'precision': 0.54054, 'recall': 0.30769, 'f1': 0.39216, 'auc': 0.76218}
2025-08-17 04:27:11,326 - INFO - > Epoch 85: took 77.2s (avg 79.4s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:28:20,192 - INFO - train: {'epoch': 86, 'time_epoch': 68.79737, 'eta': 915.51697, 'eta_hours': 0.25431, 'loss': 0.09852441, 'lr': 5.26e-06, 'params': 451793, 'time_iter': 0.06686, 'accuracy': 0.97116, 'precision': 0.73466, 'recall': 0.35958, 'f1': 0.48283, 'auc': 0.89231}
2025-08-17 04:28:24,531 - INFO - val: {'epoch': 86, 'time_epoch': 4.31717, 'loss': 0.07334983, 'lr': 0, 'params': 451793, 'time_iter': 0.03347, 'accuracy': 0.98298, 'precision': 0.63415, 'recall': 0.32099, 'f1': 0.42623, 'auc': 0.7909}
2025-08-17 04:28:28,869 - INFO - test: {'epoch': 86, 'time_epoch': 4.31991, 'loss': 0.12102804, 'lr': 0, 'params': 451793, 'time_iter': 0.03349, 'accuracy': 0.96864, 'precision': 0.50667, 'recall': 0.29231, 'f1': 0.37073, 'auc': 0.76332}
2025-08-17 04:28:28,891 - INFO - > Epoch 86: took 77.6s (avg 79.3s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:29:37,887 - INFO - train: {'epoch': 87, 'time_epoch': 68.92968, 'eta': 844.88877, 'eta_hours': 0.23469, 'loss': 0.09911702, 'lr': 4.55e-06, 'params': 451793, 'time_iter': 0.06699, 'accuracy': 0.97088, 'precision': 0.71142, 'recall': 0.37419, 'f1': 0.49043, 'auc': 0.89118}
2025-08-17 04:29:42,244 - INFO - val: {'epoch': 87, 'time_epoch': 4.33432, 'loss': 0.07296248, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.98249, 'precision': 0.63636, 'recall': 0.25926, 'f1': 0.36842, 'auc': 0.78486}
2025-08-17 04:29:46,599 - INFO - test: {'epoch': 87, 'time_epoch': 4.33675, 'loss': 0.11917986, 'lr': 0, 'params': 451793, 'time_iter': 0.03362, 'accuracy': 0.97034, 'precision': 0.60526, 'recall': 0.17692, 'f1': 0.27381, 'auc': 0.76621}
2025-08-17 04:29:46,602 - INFO - > Epoch 87: took 77.7s (avg 79.3s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:30:55,527 - INFO - train: {'epoch': 88, 'time_epoch': 68.85689, 'eta': 774.28974, 'eta_hours': 0.21508, 'loss': 0.09848132, 'lr': 3.89e-06, 'params': 451793, 'time_iter': 0.06692, 'accuracy': 0.97176, 'precision': 0.73783, 'recall': 0.38149, 'f1': 0.50294, 'auc': 0.89369}
2025-08-17 04:30:59,897 - INFO - val: {'epoch': 88, 'time_epoch': 4.34733, 'loss': 0.07290299, 'lr': 0, 'params': 451793, 'time_iter': 0.0337, 'accuracy': 0.98322, 'precision': 0.65789, 'recall': 0.30864, 'f1': 0.42017, 'auc': 0.79024}
2025-08-17 04:31:04,225 - INFO - test: {'epoch': 88, 'time_epoch': 4.30991, 'loss': 0.11964731, 'lr': 0, 'params': 451793, 'time_iter': 0.03341, 'accuracy': 0.96961, 'precision': 0.55102, 'recall': 0.20769, 'f1': 0.30168, 'auc': 0.76113}
2025-08-17 04:31:04,227 - INFO - > Epoch 88: took 77.6s (avg 79.3s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:32:12,563 - INFO - train: {'epoch': 89, 'time_epoch': 68.26778, 'eta': 703.66396, 'eta_hours': 0.19546, 'loss': 0.09796456, 'lr': 3.27e-06, 'params': 451793, 'time_iter': 0.06634, 'accuracy': 0.97164, 'precision': 0.74152, 'recall': 0.37256, 'f1': 0.49595, 'auc': 0.89261}
2025-08-17 04:32:16,907 - INFO - val: {'epoch': 89, 'time_epoch': 4.3181, 'loss': 0.0736029, 'lr': 0, 'params': 451793, 'time_iter': 0.03347, 'accuracy': 0.98322, 'precision': 0.65, 'recall': 0.32099, 'f1': 0.42975, 'auc': 0.79332}
2025-08-17 04:32:21,356 - INFO - test: {'epoch': 89, 'time_epoch': 4.29048, 'loss': 0.1193075, 'lr': 0, 'params': 451793, 'time_iter': 0.03326, 'accuracy': 0.96961, 'precision': 0.53731, 'recall': 0.27692, 'f1': 0.36548, 'auc': 0.76473}
2025-08-17 04:32:21,359 - INFO - > Epoch 89: took 77.1s (avg 79.3s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:33:29,719 - INFO - train: {'epoch': 90, 'time_epoch': 68.29342, 'eta': 633.09254, 'eta_hours': 0.17586, 'loss': 0.09845452, 'lr': 2.71e-06, 'params': 451793, 'time_iter': 0.06637, 'accuracy': 0.9717, 'precision': 0.73626, 'recall': 0.38068, 'f1': 0.50187, 'auc': 0.89095}
2025-08-17 04:33:34,043 - INFO - val: {'epoch': 90, 'time_epoch': 4.30192, 'loss': 0.07372213, 'lr': 0, 'params': 451793, 'time_iter': 0.03335, 'accuracy': 0.98322, 'precision': 0.65, 'recall': 0.32099, 'f1': 0.42975, 'auc': 0.79271}
2025-08-17 04:33:38,405 - INFO - test: {'epoch': 90, 'time_epoch': 4.34401, 'loss': 0.12028452, 'lr': 0, 'params': 451793, 'time_iter': 0.03367, 'accuracy': 0.97009, 'precision': 0.54795, 'recall': 0.30769, 'f1': 0.39409, 'auc': 0.76301}
2025-08-17 04:33:38,408 - INFO - > Epoch 90: took 77.0s (avg 79.3s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:34:47,305 - INFO - train: {'epoch': 91, 'time_epoch': 68.82944, 'eta': 562.61726, 'eta_hours': 0.15628, 'loss': 0.09796203, 'lr': 2.2e-06, 'params': 451793, 'time_iter': 0.06689, 'accuracy': 0.97204, 'precision': 0.73636, 'recall': 0.39448, 'f1': 0.51374, 'auc': 0.89332}
2025-08-17 04:34:51,638 - INFO - val: {'epoch': 91, 'time_epoch': 4.31092, 'loss': 0.07278861, 'lr': 0, 'params': 451793, 'time_iter': 0.03342, 'accuracy': 0.98347, 'precision': 0.66667, 'recall': 0.32099, 'f1': 0.43333, 'auc': 0.79711}
2025-08-17 04:34:55,975 - INFO - test: {'epoch': 91, 'time_epoch': 4.3192, 'loss': 0.11850477, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.97009, 'precision': 0.55932, 'recall': 0.25385, 'f1': 0.34921, 'auc': 0.76276}
2025-08-17 04:34:55,994 - INFO - > Epoch 91: took 77.6s (avg 79.2s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:36:04,384 - INFO - train: {'epoch': 92, 'time_epoch': 68.32412, 'eta': 492.13934, 'eta_hours': 0.13671, 'loss': 0.09757846, 'lr': 1.74e-06, 'params': 451793, 'time_iter': 0.0664, 'accuracy': 0.97216, 'precision': 0.75566, 'recall': 0.37906, 'f1': 0.50486, 'auc': 0.89509}
2025-08-17 04:36:08,679 - INFO - val: {'epoch': 92, 'time_epoch': 4.2735, 'loss': 0.07316097, 'lr': 0, 'params': 451793, 'time_iter': 0.03313, 'accuracy': 0.98322, 'precision': 0.65789, 'recall': 0.30864, 'f1': 0.42017, 'auc': 0.79449}
2025-08-17 04:36:12,987 - INFO - test: {'epoch': 92, 'time_epoch': 4.27371, 'loss': 0.11975714, 'lr': 0, 'params': 451793, 'time_iter': 0.03313, 'accuracy': 0.97009, 'precision': 0.55738, 'recall': 0.26154, 'f1': 0.35602, 'auc': 0.76344}
2025-08-17 04:36:12,989 - INFO - > Epoch 92: took 77.0s (avg 79.2s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:37:21,611 - INFO - train: {'epoch': 93, 'time_epoch': 68.55403, 'eta': 421.72191, 'eta_hours': 0.11714, 'loss': 0.09734268, 'lr': 1.33e-06, 'params': 451793, 'time_iter': 0.06662, 'accuracy': 0.97252, 'precision': 0.75868, 'recall': 0.39042, 'f1': 0.51554, 'auc': 0.89352}
2025-08-17 04:37:25,948 - INFO - val: {'epoch': 93, 'time_epoch': 4.31409, 'loss': 0.07333562, 'lr': 0, 'params': 451793, 'time_iter': 0.03344, 'accuracy': 0.98322, 'precision': 0.65, 'recall': 0.32099, 'f1': 0.42975, 'auc': 0.79868}
2025-08-17 04:37:30,274 - INFO - test: {'epoch': 93, 'time_epoch': 4.30782, 'loss': 0.12051632, 'lr': 0, 'params': 451793, 'time_iter': 0.03339, 'accuracy': 0.96937, 'precision': 0.52703, 'recall': 0.3, 'f1': 0.38235, 'auc': 0.76168}
2025-08-17 04:37:30,276 - INFO - > Epoch 93: took 77.3s (avg 79.2s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:38:38,830 - INFO - train: {'epoch': 94, 'time_epoch': 68.48638, 'eta': 351.34016, 'eta_hours': 0.09759, 'loss': 0.09886107, 'lr': 9.8e-07, 'params': 451793, 'time_iter': 0.06656, 'accuracy': 0.9711, 'precision': 0.72266, 'recall': 0.37013, 'f1': 0.48953, 'auc': 0.89267}
2025-08-17 04:38:43,157 - INFO - val: {'epoch': 94, 'time_epoch': 4.30501, 'loss': 0.07299824, 'lr': 0, 'params': 451793, 'time_iter': 0.03337, 'accuracy': 0.98322, 'precision': 0.65789, 'recall': 0.30864, 'f1': 0.42017, 'auc': 0.79353}
2025-08-17 04:38:47,492 - INFO - test: {'epoch': 94, 'time_epoch': 4.31678, 'loss': 0.12017008, 'lr': 0, 'params': 451793, 'time_iter': 0.03346, 'accuracy': 0.96961, 'precision': 0.54902, 'recall': 0.21538, 'f1': 0.30939, 'auc': 0.76314}
2025-08-17 04:38:47,495 - INFO - > Epoch 94: took 77.2s (avg 79.2s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:39:55,957 - INFO - train: {'epoch': 95, 'time_epoch': 68.39346, 'eta': 280.99402, 'eta_hours': 0.07805, 'loss': 0.09796238, 'lr': 6.8e-07, 'params': 451793, 'time_iter': 0.06647, 'accuracy': 0.97176, 'precision': 0.72444, 'recall': 0.39692, 'f1': 0.51285, 'auc': 0.89559}
2025-08-17 04:40:00,286 - INFO - val: {'epoch': 95, 'time_epoch': 4.30666, 'loss': 0.07280097, 'lr': 0, 'params': 451793, 'time_iter': 0.03338, 'accuracy': 0.98347, 'precision': 0.66667, 'recall': 0.32099, 'f1': 0.43333, 'auc': 0.79828}
2025-08-17 04:40:04,665 - INFO - test: {'epoch': 95, 'time_epoch': 4.36152, 'loss': 0.11868211, 'lr': 0, 'params': 451793, 'time_iter': 0.03381, 'accuracy': 0.96985, 'precision': 0.54545, 'recall': 0.27692, 'f1': 0.36735, 'auc': 0.76283}
2025-08-17 04:40:04,668 - INFO - > Epoch 95: took 77.2s (avg 79.2s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:41:13,778 - INFO - train: {'epoch': 96, 'time_epoch': 69.04166, 'eta': 210.70819, 'eta_hours': 0.05853, 'loss': 0.09683012, 'lr': 4.4e-07, 'params': 451793, 'time_iter': 0.0671, 'accuracy': 0.97216, 'precision': 0.74233, 'recall': 0.39286, 'f1': 0.5138, 'auc': 0.89495}
2025-08-17 04:41:18,135 - INFO - val: {'epoch': 96, 'time_epoch': 4.33415, 'loss': 0.07339019, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.78969}
2025-08-17 04:41:22,476 - INFO - test: {'epoch': 96, 'time_epoch': 4.32309, 'loss': 0.1199288, 'lr': 0, 'params': 451793, 'time_iter': 0.03351, 'accuracy': 0.96985, 'precision': 0.56, 'recall': 0.21538, 'f1': 0.31111, 'auc': 0.76097}
2025-08-17 04:41:22,479 - INFO - > Epoch 96: took 77.8s (avg 79.1s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:42:30,410 - INFO - train: {'epoch': 97, 'time_epoch': 67.86345, 'eta': 140.42371, 'eta_hours': 0.03901, 'loss': 0.098316, 'lr': 2.5e-07, 'params': 451793, 'time_iter': 0.06595, 'accuracy': 0.97164, 'precision': 0.73618, 'recall': 0.37825, 'f1': 0.49973, 'auc': 0.89104}
2025-08-17 04:42:34,658 - INFO - val: {'epoch': 97, 'time_epoch': 4.22563, 'loss': 0.07313802, 'lr': 0, 'params': 451793, 'time_iter': 0.03276, 'accuracy': 0.98322, 'precision': 0.65789, 'recall': 0.30864, 'f1': 0.42017, 'auc': 0.79176}
2025-08-17 04:42:38,972 - INFO - test: {'epoch': 97, 'time_epoch': 4.29668, 'loss': 0.12091704, 'lr': 0, 'params': 451793, 'time_iter': 0.03331, 'accuracy': 0.97009, 'precision': 0.57447, 'recall': 0.20769, 'f1': 0.30508, 'auc': 0.76364}
2025-08-17 04:42:38,974 - INFO - > Epoch 97: took 76.5s (avg 79.1s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:43:47,218 - INFO - train: {'epoch': 98, 'time_epoch': 68.17588, 'eta': 70.19129, 'eta_hours': 0.0195, 'loss': 0.09754499, 'lr': 1.1e-07, 'params': 451793, 'time_iter': 0.06625, 'accuracy': 0.9717, 'precision': 0.72838, 'recall': 0.38961, 'f1': 0.50767, 'auc': 0.89661}
2025-08-17 04:43:51,563 - INFO - val: {'epoch': 98, 'time_epoch': 4.3228, 'loss': 0.07287807, 'lr': 0, 'params': 451793, 'time_iter': 0.03351, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.79128}
2025-08-17 04:43:55,900 - INFO - test: {'epoch': 98, 'time_epoch': 4.3186, 'loss': 0.11929303, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.96985, 'precision': 0.55172, 'recall': 0.24615, 'f1': 0.34043, 'auc': 0.76432}
2025-08-17 04:43:55,902 - INFO - > Epoch 98: took 76.9s (avg 79.1s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:45:04,674 - INFO - train: {'epoch': 99, 'time_epoch': 68.70121, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.09597336, 'lr': 3e-08, 'params': 451793, 'time_iter': 0.06677, 'accuracy': 0.97277, 'precision': 0.77184, 'recall': 0.38718, 'f1': 0.51568, 'auc': 0.89819}
2025-08-17 04:45:09,069 - INFO - val: {'epoch': 99, 'time_epoch': 4.3726, 'loss': 0.07379419, 'lr': 0, 'params': 451793, 'time_iter': 0.0339, 'accuracy': 0.98298, 'precision': 0.63415, 'recall': 0.32099, 'f1': 0.42623, 'auc': 0.78915}
2025-08-17 04:45:13,411 - INFO - test: {'epoch': 99, 'time_epoch': 4.32356, 'loss': 0.11945446, 'lr': 0, 'params': 451793, 'time_iter': 0.03352, 'accuracy': 0.97034, 'precision': 0.5625, 'recall': 0.27692, 'f1': 0.37113, 'auc': 0.76381}
2025-08-17 04:45:13,637 - INFO - > Epoch 99: took 77.5s (avg 79.1s) | Best so far: epoch 61	train_loss: 0.1033 train_auc: 0.8751	val_loss: 0.0743 val_auc: 0.8078	test_loss: 0.1249 test_auc: 0.7573
2025-08-17 04:45:13,637 - INFO - Avg time per epoch: 79.08s
2025-08-17 04:45:13,637 - INFO - Total train loop time: 2.20h
2025-08-17 04:45:13,836 - INFO - ============================================================
2025-08-17 04:45:13,836 - INFO - Starting PK-Explainer Analysis (Enhanced Version)
2025-08-17 04:45:13,836 - INFO - ============================================================
2025-08-17 04:45:13,836 - INFO - Dataset: ogbg-molhiv
2025-08-17 04:45:13,836 - INFO - Model type: VanillaModel
2025-08-17 04:45:13,836 - INFO - GNN types available: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-17 04:45:13,906 - INFO - Saved model state to results/molhiv/molhiv-Vanilla-45/model_for_ablation.pt
2025-08-17 04:45:13,906 - INFO - 
Performing ablation study...
2025-08-17 04:45:13,995 - INFO - Getting baseline performance...
2025-08-17 04:45:14,030 - WARNING - Could not extract GNN mapping from optimal weights, attempting to infer from layers...
2025-08-17 04:45:14,030 - INFO - Final GNN mapping: {}
2025-08-17 04:45:18,804 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.75829, 'loss': 0.11945446, 'lr': 0, 'params': 451793, 'time_iter': 0.03689, 'accuracy': 0.97034, 'precision': 0.5625, 'recall': 0.27692, 'f1': 0.37113, 'auc': 0.76381}
2025-08-17 04:45:18,806 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:45:18,806 - INFO - Baseline auc: 0.7638
2025-08-17 04:45:23,194 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33809, 'loss': 0.11945444, 'lr': 0, 'params': 451793, 'time_iter': 0.03363, 'accuracy': 0.96937, 'precision': 0.53125, 'recall': 0.26154, 'f1': 0.35052, 'auc': 0.76388}
2025-08-17 04:45:23,233 - INFO - ...computing epoch stats took: 0.05s
2025-08-17 04:45:23,234 - INFO - Layer 0 (Layer_0), Head 0: drop=-0.0001
2025-08-17 04:45:27,619 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33195, 'loss': 0.11950286, 'lr': 0, 'params': 451793, 'time_iter': 0.03358, 'accuracy': 0.96937, 'precision': 0.53448, 'recall': 0.23846, 'f1': 0.32979, 'auc': 0.76171}
2025-08-17 04:45:27,621 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:45:27,621 - INFO - Layer 0 (Layer_0), Head 1: drop=0.0027
2025-08-17 04:45:31,999 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32807, 'loss': 0.12001405, 'lr': 0, 'params': 451793, 'time_iter': 0.03355, 'accuracy': 0.97058, 'precision': 0.57143, 'recall': 0.27692, 'f1': 0.37306, 'auc': 0.76403}
2025-08-17 04:45:32,001 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:45:32,001 - INFO - Layer 0 (Layer_0), Head 2: drop=-0.0003
2025-08-17 04:45:36,395 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34338, 'loss': 0.1201277, 'lr': 0, 'params': 451793, 'time_iter': 0.03367, 'accuracy': 0.97034, 'precision': 0.56897, 'recall': 0.25385, 'f1': 0.35106, 'auc': 0.765}
2025-08-17 04:45:36,396 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:45:36,397 - INFO - Layer 0 (Layer_0), Head 3: drop=-0.0016
2025-08-17 04:45:40,780 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33363, 'loss': 0.11976579, 'lr': 0, 'params': 451793, 'time_iter': 0.03359, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.22308, 'f1': 0.30851, 'auc': 0.76528}
2025-08-17 04:45:40,783 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:45:40,783 - INFO - Layer 1 (Layer_1), Head 0: drop=-0.0019
2025-08-17 04:45:45,167 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33414, 'loss': 0.11839734, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.97082, 'precision': 0.58065, 'recall': 0.27692, 'f1': 0.375, 'auc': 0.76349}
2025-08-17 04:45:45,169 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:45:45,169 - INFO - Layer 1 (Layer_1), Head 1: drop=0.0004
2025-08-17 04:45:49,547 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32739, 'loss': 0.12017697, 'lr': 0, 'params': 451793, 'time_iter': 0.03355, 'accuracy': 0.96985, 'precision': 0.55, 'recall': 0.25385, 'f1': 0.34737, 'auc': 0.76771}
2025-08-17 04:45:49,550 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:45:49,550 - INFO - Layer 1 (Layer_1), Head 2: drop=-0.0051
2025-08-17 04:45:53,927 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32808, 'loss': 0.11942938, 'lr': 0, 'params': 451793, 'time_iter': 0.03355, 'accuracy': 0.97131, 'precision': 0.59375, 'recall': 0.29231, 'f1': 0.39175, 'auc': 0.76182}
2025-08-17 04:45:53,929 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:45:53,929 - INFO - Layer 1 (Layer_1), Head 3: drop=0.0026
2025-08-17 04:45:58,316 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33723, 'loss': 0.12008773, 'lr': 0, 'params': 451793, 'time_iter': 0.03362, 'accuracy': 0.96888, 'precision': 0.51429, 'recall': 0.27692, 'f1': 0.36, 'auc': 0.76098}
2025-08-17 04:45:58,318 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:45:58,318 - INFO - Layer 2 (Layer_2), Head 0: drop=0.0037
2025-08-17 04:46:02,707 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33828, 'loss': 0.11930828, 'lr': 0, 'params': 451793, 'time_iter': 0.03363, 'accuracy': 0.96961, 'precision': 0.53846, 'recall': 0.26923, 'f1': 0.35897, 'auc': 0.75867}
2025-08-17 04:46:02,709 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:46:02,709 - INFO - Layer 2 (Layer_2), Head 1: drop=0.0067
2025-08-17 04:46:07,087 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32837, 'loss': 0.11874861, 'lr': 0, 'params': 451793, 'time_iter': 0.03355, 'accuracy': 0.96961, 'precision': 0.53846, 'recall': 0.26923, 'f1': 0.35897, 'auc': 0.76404}
2025-08-17 04:46:07,089 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:07,089 - INFO - Layer 2 (Layer_2), Head 2: drop=-0.0003
2025-08-17 04:46:11,455 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.31596, 'loss': 0.12030046, 'lr': 0, 'params': 451793, 'time_iter': 0.03346, 'accuracy': 0.96912, 'precision': 0.52632, 'recall': 0.23077, 'f1': 0.32086, 'auc': 0.76175}
2025-08-17 04:46:11,456 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:11,457 - INFO - Layer 2 (Layer_2), Head 3: drop=0.0027
2025-08-17 04:46:15,844 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33792, 'loss': 0.11978676, 'lr': 0, 'params': 451793, 'time_iter': 0.03363, 'accuracy': 0.96888, 'precision': 0.51667, 'recall': 0.23846, 'f1': 0.32632, 'auc': 0.76271}
2025-08-17 04:46:15,847 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:46:15,847 - INFO - Layer 3 (Layer_3), Head 0: drop=0.0014
2025-08-17 04:46:20,234 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33653, 'loss': 0.11834951, 'lr': 0, 'params': 451793, 'time_iter': 0.03362, 'accuracy': 0.97058, 'precision': 0.57627, 'recall': 0.26154, 'f1': 0.35979, 'auc': 0.76592}
2025-08-17 04:46:20,237 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:46:20,237 - INFO - Layer 3 (Layer_3), Head 1: drop=-0.0028
2025-08-17 04:46:24,616 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32825, 'loss': 0.11825471, 'lr': 0, 'params': 451793, 'time_iter': 0.03355, 'accuracy': 0.97082, 'precision': 0.58333, 'recall': 0.26923, 'f1': 0.36842, 'auc': 0.76536}
2025-08-17 04:46:24,618 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:46:24,618 - INFO - Layer 3 (Layer_3), Head 2: drop=-0.0020
2025-08-17 04:46:28,993 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32512, 'loss': 0.11808694, 'lr': 0, 'params': 451793, 'time_iter': 0.03353, 'accuracy': 0.96961, 'precision': 0.53731, 'recall': 0.27692, 'f1': 0.36548, 'auc': 0.76281}
2025-08-17 04:46:28,995 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:46:28,995 - INFO - Layer 3 (Layer_3), Head 3: drop=0.0013
2025-08-17 04:46:33,371 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32619, 'loss': 0.11911308, 'lr': 0, 'params': 451793, 'time_iter': 0.03354, 'accuracy': 0.96985, 'precision': 0.54839, 'recall': 0.26154, 'f1': 0.35417, 'auc': 0.76073}
2025-08-17 04:46:33,373 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:33,373 - INFO - Layer 4 (Layer_4), Head 0: drop=0.0040
2025-08-17 04:46:37,755 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33224, 'loss': 0.11976835, 'lr': 0, 'params': 451793, 'time_iter': 0.03358, 'accuracy': 0.96985, 'precision': 0.55172, 'recall': 0.24615, 'f1': 0.34043, 'auc': 0.76281}
2025-08-17 04:46:37,757 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:46:37,757 - INFO - Layer 4 (Layer_4), Head 1: drop=0.0013
2025-08-17 04:46:42,138 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33047, 'loss': 0.11787616, 'lr': 0, 'params': 451793, 'time_iter': 0.03357, 'accuracy': 0.97058, 'precision': 0.56716, 'recall': 0.29231, 'f1': 0.38579, 'auc': 0.76556}
2025-08-17 04:46:42,140 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:46:42,140 - INFO - Layer 4 (Layer_4), Head 2: drop=-0.0023
2025-08-17 04:46:46,521 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33127, 'loss': 0.11835348, 'lr': 0, 'params': 451793, 'time_iter': 0.03358, 'accuracy': 0.97082, 'precision': 0.58065, 'recall': 0.27692, 'f1': 0.375, 'auc': 0.76366}
2025-08-17 04:46:46,523 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:46,523 - INFO - Layer 4 (Layer_4), Head 3: drop=0.0002
2025-08-17 04:46:50,909 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33518, 'loss': 0.11812689, 'lr': 0, 'params': 451793, 'time_iter': 0.03361, 'accuracy': 0.97034, 'precision': 0.56061, 'recall': 0.28462, 'f1': 0.37755, 'auc': 0.76488}
2025-08-17 04:46:50,911 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:46:50,912 - INFO - Layer 5 (Layer_5), Head 0: drop=-0.0014
2025-08-17 04:46:55,289 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32771, 'loss': 0.11949675, 'lr': 0, 'params': 451793, 'time_iter': 0.03355, 'accuracy': 0.96937, 'precision': 0.53448, 'recall': 0.23846, 'f1': 0.32979, 'auc': 0.76383}
2025-08-17 04:46:55,291 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:55,291 - INFO - Layer 5 (Layer_5), Head 1: drop=-0.0000
2025-08-17 04:46:59,673 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33208, 'loss': 0.11826956, 'lr': 0, 'params': 451793, 'time_iter': 0.03358, 'accuracy': 0.96985, 'precision': 0.55, 'recall': 0.25385, 'f1': 0.34737, 'auc': 0.76127}
2025-08-17 04:46:59,675 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:46:59,675 - INFO - Layer 5 (Layer_5), Head 2: drop=0.0033
2025-08-17 04:47:04,055 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33031, 'loss': 0.11897854, 'lr': 0, 'params': 451793, 'time_iter': 0.03357, 'accuracy': 0.97058, 'precision': 0.57895, 'recall': 0.25385, 'f1': 0.35294, 'auc': 0.76312}
2025-08-17 04:47:04,057 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:47:04,057 - INFO - Layer 5 (Layer_5), Head 3: drop=0.0009
2025-08-17 04:47:08,427 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32079, 'loss': 0.11872303, 'lr': 0, 'params': 451793, 'time_iter': 0.03349, 'accuracy': 0.97082, 'precision': 0.58621, 'recall': 0.26154, 'f1': 0.3617, 'auc': 0.7606}
2025-08-17 04:47:08,430 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:47:08,430 - INFO - Layer 6 (Layer_6), Head 0: drop=0.0042
2025-08-17 04:47:12,810 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3287, 'loss': 0.11825055, 'lr': 0, 'params': 451793, 'time_iter': 0.03356, 'accuracy': 0.97082, 'precision': 0.58333, 'recall': 0.26923, 'f1': 0.36842, 'auc': 0.7663}
2025-08-17 04:47:12,812 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:47:12,812 - INFO - Layer 6 (Layer_6), Head 1: drop=-0.0033
2025-08-17 04:47:17,205 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34235, 'loss': 0.11881247, 'lr': 0, 'params': 451793, 'time_iter': 0.03366, 'accuracy': 0.96985, 'precision': 0.54839, 'recall': 0.26154, 'f1': 0.35417, 'auc': 0.76288}
2025-08-17 04:47:17,207 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:47:17,207 - INFO - Layer 6 (Layer_6), Head 2: drop=0.0012
2025-08-17 04:47:21,591 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3337, 'loss': 0.11911443, 'lr': 0, 'params': 451793, 'time_iter': 0.03359, 'accuracy': 0.96985, 'precision': 0.54688, 'recall': 0.26923, 'f1': 0.36082, 'auc': 0.76292}
2025-08-17 04:47:21,593 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:47:21,593 - INFO - Layer 6 (Layer_6), Head 3: drop=0.0012
2025-08-17 04:47:25,982 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33937, 'loss': 0.11819047, 'lr': 0, 'params': 451793, 'time_iter': 0.03364, 'accuracy': 0.97082, 'precision': 0.59259, 'recall': 0.24615, 'f1': 0.34783, 'auc': 0.76327}
2025-08-17 04:47:25,984 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:47:25,984 - INFO - Layer 7 (Layer_7), Head 0: drop=0.0007
2025-08-17 04:47:30,371 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.33646, 'loss': 0.11881507, 'lr': 0, 'params': 451793, 'time_iter': 0.03362, 'accuracy': 0.96937, 'precision': 0.53125, 'recall': 0.26154, 'f1': 0.35052, 'auc': 0.76299}
2025-08-17 04:47:30,650 - INFO - ...computing epoch stats took: 0.29s
2025-08-17 04:47:30,650 - INFO - Layer 7 (Layer_7), Head 1: drop=0.0011
2025-08-17 04:47:35,045 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3443, 'loss': 0.11939308, 'lr': 0, 'params': 451793, 'time_iter': 0.03368, 'accuracy': 0.97058, 'precision': 0.57627, 'recall': 0.26154, 'f1': 0.35979, 'auc': 0.76048}
2025-08-17 04:47:35,047 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:47:35,047 - INFO - Layer 7 (Layer_7), Head 2: drop=0.0044
2025-08-17 04:47:39,321 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.22237, 'loss': 0.11918424, 'lr': 0, 'params': 451793, 'time_iter': 0.03273, 'accuracy': 0.96937, 'precision': 0.5303, 'recall': 0.26923, 'f1': 0.35714, 'auc': 0.76377}
2025-08-17 04:47:39,323 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:47:39,324 - INFO - Layer 7 (Layer_7), Head 3: drop=0.0001
2025-08-17 04:47:43,743 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3662, 'loss': 0.11857933, 'lr': 0, 'params': 451793, 'time_iter': 0.03385, 'accuracy': 0.96985, 'precision': 0.54839, 'recall': 0.26154, 'f1': 0.35417, 'auc': 0.76411}
2025-08-17 04:47:43,744 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:47:43,744 - INFO - Layer 8 (Layer_8), Head 0: drop=-0.0004
2025-08-17 04:47:48,231 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43311, 'loss': 0.11912174, 'lr': 0, 'params': 451793, 'time_iter': 0.03437, 'accuracy': 0.97009, 'precision': 0.57143, 'recall': 0.21538, 'f1': 0.31285, 'auc': 0.759}
2025-08-17 04:47:48,233 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:47:48,233 - INFO - Layer 8 (Layer_8), Head 1: drop=0.0063
2025-08-17 04:47:52,626 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34157, 'loss': 0.11874647, 'lr': 0, 'params': 451793, 'time_iter': 0.03366, 'accuracy': 0.96985, 'precision': 0.54688, 'recall': 0.26923, 'f1': 0.36082, 'auc': 0.76007}
2025-08-17 04:47:52,628 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:47:52,628 - INFO - Layer 8 (Layer_8), Head 2: drop=0.0049
2025-08-17 04:47:57,091 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.41021, 'loss': 0.11882754, 'lr': 0, 'params': 451793, 'time_iter': 0.03419, 'accuracy': 0.97107, 'precision': 0.6, 'recall': 0.25385, 'f1': 0.35676, 'auc': 0.76183}
2025-08-17 04:47:57,092 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:47:57,093 - INFO - Layer 8 (Layer_8), Head 3: drop=0.0026
2025-08-17 04:48:01,458 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.31208, 'loss': 0.11952293, 'lr': 0, 'params': 451793, 'time_iter': 0.03343, 'accuracy': 0.97009, 'precision': 0.55738, 'recall': 0.26154, 'f1': 0.35602, 'auc': 0.76266}
2025-08-17 04:48:01,512 - INFO - ...computing epoch stats took: 0.07s
2025-08-17 04:48:01,512 - INFO - Layer 9 (Layer_9), Head 0: drop=0.0015
2025-08-17 04:48:05,966 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40243, 'loss': 0.1190528, 'lr': 0, 'params': 451793, 'time_iter': 0.03413, 'accuracy': 0.96961, 'precision': 0.53846, 'recall': 0.26923, 'f1': 0.35897, 'auc': 0.76114}
2025-08-17 04:48:05,972 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:48:05,973 - INFO - Layer 9 (Layer_9), Head 1: drop=0.0035
2025-08-17 04:48:10,480 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.45594, 'loss': 0.1188215, 'lr': 0, 'params': 451793, 'time_iter': 0.03454, 'accuracy': 0.97034, 'precision': 0.56452, 'recall': 0.26923, 'f1': 0.36458, 'auc': 0.76328}
2025-08-17 04:48:10,482 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:48:10,482 - INFO - Layer 9 (Layer_9), Head 2: drop=0.0007
2025-08-17 04:48:15,028 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.49318, 'loss': 0.11902153, 'lr': 0, 'params': 451793, 'time_iter': 0.03483, 'accuracy': 0.97034, 'precision': 0.56452, 'recall': 0.26923, 'f1': 0.36458, 'auc': 0.763}
2025-08-17 04:48:15,031 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:48:15,031 - INFO - Layer 9 (Layer_9), Head 3: drop=0.0011
2025-08-17 04:48:19,483 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40051, 'loss': 0.11863184, 'lr': 0, 'params': 451793, 'time_iter': 0.03411, 'accuracy': 0.96985, 'precision': 0.54839, 'recall': 0.26154, 'f1': 0.35417, 'auc': 0.76593}
2025-08-17 04:48:19,485 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:48:19,486 - INFO - Layer 10 (Layer_10), Head 0: drop=-0.0028
2025-08-17 04:48:23,918 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3788, 'loss': 0.11876628, 'lr': 0, 'params': 451793, 'time_iter': 0.03394, 'accuracy': 0.97058, 'precision': 0.58182, 'recall': 0.24615, 'f1': 0.34595, 'auc': 0.76311}
2025-08-17 04:48:23,920 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:48:23,920 - INFO - Layer 10 (Layer_10), Head 1: drop=0.0009
2025-08-17 04:48:28,400 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.42729, 'loss': 0.11910863, 'lr': 0, 'params': 451793, 'time_iter': 0.03432, 'accuracy': 0.97009, 'precision': 0.55738, 'recall': 0.26154, 'f1': 0.35602, 'auc': 0.76312}
2025-08-17 04:48:28,402 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:48:28,402 - INFO - Layer 10 (Layer_10), Head 2: drop=0.0009
2025-08-17 04:48:32,755 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.30306, 'loss': 0.11877252, 'lr': 0, 'params': 451793, 'time_iter': 0.03336, 'accuracy': 0.97058, 'precision': 0.57377, 'recall': 0.26923, 'f1': 0.36649, 'auc': 0.76606}
2025-08-17 04:48:32,757 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:48:32,757 - INFO - Layer 10 (Layer_10), Head 3: drop=-0.0029
2025-08-17 04:48:37,247 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43995, 'loss': 0.11928022, 'lr': 0, 'params': 451793, 'time_iter': 0.03442, 'accuracy': 0.97009, 'precision': 0.56364, 'recall': 0.23846, 'f1': 0.33514, 'auc': 0.7624}
2025-08-17 04:48:37,249 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:48:37,249 - INFO - Layer 11 (Layer_11), Head 0: drop=0.0018
2025-08-17 04:48:41,733 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43416, 'loss': 0.1190379, 'lr': 0, 'params': 451793, 'time_iter': 0.03437, 'accuracy': 0.96961, 'precision': 0.53846, 'recall': 0.26923, 'f1': 0.35897, 'auc': 0.76493}
2025-08-17 04:48:41,735 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:48:41,735 - INFO - Layer 11 (Layer_11), Head 1: drop=-0.0015
2025-08-17 04:48:46,273 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.48487, 'loss': 0.11874176, 'lr': 0, 'params': 451793, 'time_iter': 0.03477, 'accuracy': 0.97058, 'precision': 0.57377, 'recall': 0.26923, 'f1': 0.36649, 'auc': 0.76457}
2025-08-17 04:48:46,280 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:48:46,280 - INFO - Layer 11 (Layer_11), Head 2: drop=-0.0010
2025-08-17 04:48:50,782 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.45072, 'loss': 0.1188747, 'lr': 0, 'params': 451793, 'time_iter': 0.0345, 'accuracy': 0.97034, 'precision': 0.56452, 'recall': 0.26923, 'f1': 0.36458, 'auc': 0.76399}
2025-08-17 04:48:50,788 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:48:50,789 - INFO - Layer 11 (Layer_11), Head 3: drop=-0.0002
2025-08-17 04:48:55,251 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40919, 'loss': 0.11889042, 'lr': 0, 'params': 451793, 'time_iter': 0.03418, 'accuracy': 0.97058, 'precision': 0.57895, 'recall': 0.25385, 'f1': 0.35294, 'auc': 0.76394}
2025-08-17 04:48:55,253 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:48:55,253 - INFO - Layer 12 (Layer_12), Head 0: drop=-0.0002
2025-08-17 04:48:59,715 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.41112, 'loss': 0.11920277, 'lr': 0, 'params': 451793, 'time_iter': 0.03419, 'accuracy': 0.97009, 'precision': 0.55932, 'recall': 0.25385, 'f1': 0.34921, 'auc': 0.76318}
2025-08-17 04:48:59,717 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:48:59,717 - INFO - Layer 12 (Layer_12), Head 1: drop=0.0008
2025-08-17 04:49:04,193 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.42512, 'loss': 0.11888037, 'lr': 0, 'params': 451793, 'time_iter': 0.0343, 'accuracy': 0.96985, 'precision': 0.55357, 'recall': 0.23846, 'f1': 0.33333, 'auc': 0.76444}
2025-08-17 04:49:04,195 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:49:04,195 - INFO - Layer 12 (Layer_12), Head 2: drop=-0.0008
2025-08-17 04:49:08,660 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.41209, 'loss': 0.1194557, 'lr': 0, 'params': 451793, 'time_iter': 0.0342, 'accuracy': 0.96985, 'precision': 0.54688, 'recall': 0.26923, 'f1': 0.36082, 'auc': 0.76357}
2025-08-17 04:49:08,667 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:49:08,667 - INFO - Layer 12 (Layer_12), Head 3: drop=0.0003
2025-08-17 04:49:13,130 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.41151, 'loss': 0.11946791, 'lr': 0, 'params': 451793, 'time_iter': 0.0342, 'accuracy': 0.96985, 'precision': 0.54688, 'recall': 0.26923, 'f1': 0.36082, 'auc': 0.76147}
2025-08-17 04:49:13,132 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:49:13,132 - INFO - Layer 13 (Layer_13), Head 0: drop=0.0031
2025-08-17 04:49:17,605 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.42095, 'loss': 0.11963677, 'lr': 0, 'params': 451793, 'time_iter': 0.03427, 'accuracy': 0.96961, 'precision': 0.53846, 'recall': 0.26923, 'f1': 0.35897, 'auc': 0.76469}
2025-08-17 04:49:17,607 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:49:17,607 - INFO - Layer 13 (Layer_13), Head 1: drop=-0.0012
2025-08-17 04:49:22,071 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.4132, 'loss': 0.11875637, 'lr': 0, 'params': 451793, 'time_iter': 0.03421, 'accuracy': 0.97034, 'precision': 0.56452, 'recall': 0.26923, 'f1': 0.36458, 'auc': 0.76595}
2025-08-17 04:49:22,073 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:49:22,073 - INFO - Layer 13 (Layer_13), Head 2: drop=-0.0028
2025-08-17 04:49:26,480 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35458, 'loss': 0.11945571, 'lr': 0, 'params': 451793, 'time_iter': 0.03376, 'accuracy': 0.97009, 'precision': 0.55556, 'recall': 0.26923, 'f1': 0.36269, 'auc': 0.76482}
2025-08-17 04:49:26,487 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:49:26,487 - INFO - Layer 13 (Layer_13), Head 3: drop=-0.0013
2025-08-17 04:49:31,001 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.46384, 'loss': 0.11965017, 'lr': 0, 'params': 451793, 'time_iter': 0.0346, 'accuracy': 0.97009, 'precision': 0.55556, 'recall': 0.26923, 'f1': 0.36269, 'auc': 0.76334}
2025-08-17 04:49:31,003 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:49:31,004 - INFO - Layer 14 (Layer_14), Head 0: drop=0.0006
2025-08-17 04:49:35,451 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.39411, 'loss': 0.11931184, 'lr': 0, 'params': 451793, 'time_iter': 0.03406, 'accuracy': 0.96985, 'precision': 0.54688, 'recall': 0.26923, 'f1': 0.36082, 'auc': 0.76379}
2025-08-17 04:49:35,452 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:49:35,453 - INFO - Layer 14 (Layer_14), Head 1: drop=0.0000
2025-08-17 04:49:39,966 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.46079, 'loss': 0.11947463, 'lr': 0, 'params': 451793, 'time_iter': 0.03458, 'accuracy': 0.96961, 'precision': 0.53846, 'recall': 0.26923, 'f1': 0.35897, 'auc': 0.76401}
2025-08-17 04:49:39,968 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:49:39,968 - INFO - Layer 14 (Layer_14), Head 2: drop=-0.0003
2025-08-17 04:49:44,465 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44536, 'loss': 0.119899, 'lr': 0, 'params': 451793, 'time_iter': 0.03446, 'accuracy': 0.97058, 'precision': 0.57377, 'recall': 0.26923, 'f1': 0.36649, 'auc': 0.762}
2025-08-17 04:49:44,473 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:49:44,473 - INFO - Layer 14 (Layer_14), Head 3: drop=0.0024
2025-08-17 04:49:44,476 - INFO - 
FIDELITY METRICS:
2025-08-17 04:49:44,476 - INFO - Fidelity (top 30 heads): 0.0025
2025-08-17 04:49:44,476 - INFO - Fidelity- (bottom 30 heads): -0.0012
2025-08-17 04:49:44,476 - INFO - 
GNN distribution in important heads:
2025-08-17 04:49:44,476 - INFO -   Layer_9: 4 heads
2025-08-17 04:49:44,476 - INFO -   Layer_2: 3 heads
2025-08-17 04:49:44,476 - INFO -   Layer_8: 3 heads
2025-08-17 04:49:44,476 - INFO -   Layer_7: 3 heads
2025-08-17 04:49:44,476 - INFO -   Layer_6: 3 heads
2025-08-17 04:49:44,477 - INFO -   Layer_4: 2 heads
2025-08-17 04:49:44,477 - INFO -   Layer_5: 2 heads
2025-08-17 04:49:44,477 - INFO -   Layer_3: 2 heads
2025-08-17 04:49:44,477 - INFO -   Layer_10: 2 heads
2025-08-17 04:49:44,477 - INFO -   Layer_13: 1 heads
2025-08-17 04:49:44,477 - INFO -   Layer_0: 1 heads
2025-08-17 04:49:44,477 - INFO -   Layer_1: 1 heads
2025-08-17 04:49:44,477 - INFO -   Layer_14: 1 heads
2025-08-17 04:49:44,477 - INFO -   Layer_11: 1 heads
2025-08-17 04:49:44,477 - INFO -   Layer_12: 1 heads
2025-08-17 04:49:44,477 - INFO - 
Interpretability Analysis:
2025-08-17 04:49:44,477 - INFO -   Fidelity: 0.0025
2025-08-17 04:49:44,477 - INFO -   Fidelity-: -0.0012
2025-08-17 04:49:44,477 - INFO -   Total heads tested: 60
2025-08-17 04:49:44,735 - INFO - Excel results saved to results/molhiv/molhiv-Vanilla-45/pk_explainer_results.xlsx
2025-08-17 04:49:46,025 - INFO - Saved visualizations to results/molhiv/molhiv-Vanilla-45/pk_explainer_results
2025-08-17 04:49:46,029 - INFO - 
PK-Explainer results saved to:
2025-08-17 04:49:46,029 - INFO -   - Excel: results/molhiv/molhiv-Vanilla-45/pk_explainer_results.xlsx
2025-08-17 04:49:46,029 - INFO -   - JSON: results/molhiv/molhiv-Vanilla-45/pk_explainer_results.json
2025-08-17 04:49:46,029 - INFO -   - Visualizations: results/molhiv/molhiv-Vanilla-45/pk_explainer_results
2025-08-17 04:49:46,044 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-45
2025-08-17 04:49:46,044 - INFO - Total time: 8250.57s (2.29h)
2025-08-17 04:49:46,059 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-45/agg
2025-08-17 04:49:46,059 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-17 04:49:46,059 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-45
2025-08-17 04:49:46,059 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-45/test_results/
Completed seed 45. Results saved in results/molhiv/molhiv-Vanilla-45
----------------------------------------
Running experiment with seed: 47
Starting training for seed 47...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/confignas.yaml
Using device: cuda
2025-08-17 04:49:56,921 - INFO - GPU Mem: 25.2GB
2025-08-17 04:49:56,921 - INFO - Run directory: results/molhiv/molhiv-Vanilla-47
2025-08-17 04:49:56,921 - INFO - Seed: 47
2025-08-17 04:49:56,921 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-17 04:49:56,921 - INFO - Routing mode: none
2025-08-17 04:49:56,921 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-17 04:49:56,921 - INFO - Number of layers: 15
2025-08-17 04:49:56,921 - INFO - Uncertainty enabled: False
2025-08-17 04:49:56,921 - INFO - Training mode: custom
2025-08-17 04:49:56,921 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-17 04:49:56,921 - INFO - Additional features: Router weights logging + JSON export
2025-08-17 04:50:03,739 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 04:50:03,741 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-17 04:50:03,742 - INFO -   undirected: True
2025-08-17 04:50:03,742 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 04:50:03,742 - INFO -   avg num_nodes/graph: 25
2025-08-17 04:50:03,743 - INFO -   num node features: 9
2025-08-17 04:50:03,743 - INFO -   num edge features: 3
2025-08-17 04:50:03,743 - INFO -   num tasks: 1
2025-08-17 04:50:03,743 - INFO -   num classes: 2
2025-08-17 04:50:03,743 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-17 04:50:03,743 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-17 04:50:03,746 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  8%|▊         | 3365/41127 [00:10<01:52, 336.48it/s] 15%|█▍        | 5984/41127 [00:20<02:00, 292.05it/s] 20%|█▉        | 8040/41127 [00:32<02:25, 226.95it/s] 26%|██▌       | 10670/41127 [00:42<02:06, 240.25it/s] 33%|███▎      | 13590/41127 [00:52<01:46, 258.12it/s] 33%|███▎      | 13590/41127 [01:03<01:46, 258.12it/s] 37%|███▋      | 15311/41127 [01:03<01:56, 221.92it/s] 40%|████      | 16466/41127 [01:13<02:10, 188.38it/s] 45%|████▌     | 18666/41127 [01:23<01:53, 198.14it/s] 51%|█████     | 21045/41127 [01:33<01:35, 210.31it/s] 57%|█████▋    | 23388/41127 [01:43<01:21, 217.37it/s] 64%|██████▎   | 26173/41127 [01:53<01:03, 235.86it/s] 71%|███████   | 29257/41127 [02:03<00:46, 257.36it/s] 74%|███████▍  | 30594/41127 [02:13<00:47, 220.13it/s] 79%|███████▉  | 32535/41127 [02:23<00:40, 210.84it/s] 84%|████████▍ | 34582/41127 [02:34<00:31, 208.28it/s] 88%|████████▊ | 36148/41127 [02:44<00:26, 191.44it/s] 94%|█████████▍| 38725/41127 [02:54<00:11, 210.32it/s] 97%|█████████▋| 40066/41127 [03:04<00:05, 187.39it/s]100%|█████████▉| 40976/41127 [03:14<00:00, 158.60it/s]100%|██████████| 41127/41127 [03:17<00:00, 207.90it/s]
2025-08-17 04:53:22,755 - INFO - Done! Took 00:03:19.01
2025-08-17 04:53:22,900 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-17 04:53:23,099 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-17 04:53:23,099 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-08-17 04:53:23,100 - INFO - Inner model has get_darts_model: False
2025-08-17 04:53:23,110 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-08-17 04:53:23,113 - INFO - Number of parameters: 451,793
2025-08-17 04:53:23,113 - INFO - Starting optimized training: 2025-08-17 04:53:23.113547
2025-08-17 04:53:29,631 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 04:53:29,631 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-17 04:53:29,632 - INFO -   undirected: True
2025-08-17 04:53:29,632 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 04:53:29,632 - INFO -   avg num_nodes/graph: 25
2025-08-17 04:53:29,633 - INFO -   num node features: 9
2025-08-17 04:53:29,633 - INFO -   num edge features: 3
2025-08-17 04:53:29,633 - INFO -   num tasks: 1
2025-08-17 04:53:29,633 - INFO -   num classes: 2
2025-08-17 04:53:29,633 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-17 04:53:29,633 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-17 04:53:29,637 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s]  8%|▊         | 3362/41127 [00:10<01:53, 334.16it/s] 14%|█▍        | 5838/41127 [00:20<02:04, 283.37it/s] 19%|█▉        | 7894/41127 [00:30<02:18, 239.37it/s] 27%|██▋       | 10988/41127 [00:40<01:53, 266.23it/s] 35%|███▌      | 14540/41127 [00:50<01:29, 296.51it/s] 40%|████      | 16596/41127 [01:05<01:46, 229.83it/s] 49%|████▊     | 20008/41127 [01:15<01:20, 262.23it/s] 56%|█████▌    | 22918/41127 [01:25<01:07, 269.98it/s] 63%|██████▎   | 25901/41127 [01:35<00:54, 278.36it/s] 71%|███████   | 29260/41127 [01:45<00:40, 294.43it/s] 76%|███████▌  | 31316/41127 [01:57<00:38, 254.85it/s] 84%|████████▎ | 34421/41127 [02:07<00:24, 270.84it/s] 84%|████████▎ | 34421/41127 [02:17<00:24, 270.84it/s] 88%|████████▊ | 36184/41127 [02:17<00:20, 242.68it/s] 95%|█████████▍| 39014/41127 [02:27<00:08, 254.50it/s] 99%|█████████▉| 40746/41127 [02:37<00:01, 229.61it/s]100%|██████████| 41127/41127 [02:42<00:00, 253.00it/s]
2025-08-17 04:56:13,356 - INFO - Done! Took 00:02:43.72
2025-08-17 04:56:13,494 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-17 04:56:13,511 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-17 04:56:13,512 - INFO - Start from epoch 0
2025-08-17 04:57:28,942 - INFO - train: {'epoch': 0, 'time_epoch': 75.32253, 'eta': 7456.93012, 'eta_hours': 2.07137, 'loss': 0.71941173, 'lr': 0.0, 'params': 451793, 'time_iter': 0.0732, 'accuracy': 0.05574, 'precision': 0.03786, 'recall': 0.99188, 'f1': 0.07293, 'auc': 0.51739}
2025-08-17 04:57:28,996 - INFO - ...computing epoch stats took: 0.14s
2025-08-17 04:57:34,426 - INFO - val: {'epoch': 0, 'time_epoch': 5.41142, 'loss': 0.71477123, 'lr': 0, 'params': 451793, 'time_iter': 0.04195, 'accuracy': 0.0231, 'precision': 0.01976, 'recall': 1.0, 'f1': 0.03876, 'auc': 0.56404}
2025-08-17 04:57:34,429 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 04:57:39,383 - INFO - test: {'epoch': 0, 'time_epoch': 4.93754, 'loss': 0.71682137, 'lr': 0, 'params': 451793, 'time_iter': 0.03828, 'accuracy': 0.04012, 'precision': 0.03165, 'recall': 0.99231, 'f1': 0.06134, 'auc': 0.5408}
2025-08-17 04:57:39,407 - INFO - ...computing epoch stats took: 0.04s
2025-08-17 04:57:39,408 - INFO - > Epoch 0: took 85.9s (avg 85.9s) | Best so far: epoch 0	train_loss: 0.7194 train_auc: 0.5174	val_loss: 0.7148 val_auc: 0.5640	test_loss: 0.7168 test_auc: 0.5408
2025-08-17 04:58:49,975 - INFO - train: {'epoch': 1, 'time_epoch': 70.47429, 'eta': 7144.04413, 'eta_hours': 1.98446, 'loss': 0.51562847, 'lr': 2e-05, 'params': 451793, 'time_iter': 0.06849, 'accuracy': 0.85593, 'precision': 0.04418, 'recall': 0.13799, 'f1': 0.06693, 'auc': 0.54207}
2025-08-17 04:58:49,982 - INFO - ...computing epoch stats took: 0.08s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 04:58:54,429 - INFO - val: {'epoch': 1, 'time_epoch': 4.42861, 'loss': 0.30145146, 'lr': 0, 'params': 451793, 'time_iter': 0.03433, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.48979}
2025-08-17 04:58:54,431 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 04:58:58,889 - INFO - test: {'epoch': 1, 'time_epoch': 4.4429, 'loss': 0.29578809, 'lr': 0, 'params': 451793, 'time_iter': 0.03444, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.59624}
2025-08-17 04:58:58,891 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 04:58:58,891 - INFO - > Epoch 1: took 79.5s (avg 82.7s) | Best so far: epoch 0	train_loss: 0.7194 train_auc: 0.5174	val_loss: 0.7148 val_auc: 0.5640	test_loss: 0.7168 test_auc: 0.5408
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:00:10,113 - INFO - train: {'epoch': 2, 'time_epoch': 71.14642, 'eta': 7014.49798, 'eta_hours': 1.94847, 'loss': 0.21246478, 'lr': 4e-05, 'params': 451793, 'time_iter': 0.06914, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.57422}
2025-08-17 05:00:10,120 - INFO - ...computing epoch stats took: 0.06s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:00:14,262 - INFO - val: {'epoch': 2, 'time_epoch': 4.12717, 'loss': 0.1108758, 'lr': 0, 'params': 451793, 'time_iter': 0.03199, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.55705}
2025-08-17 05:00:14,265 - INFO - ...computing epoch stats took: 0.01s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:00:18,529 - INFO - test: {'epoch': 2, 'time_epoch': 4.25026, 'loss': 0.14627707, 'lr': 0, 'params': 451793, 'time_iter': 0.03295, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.59966}
2025-08-17 05:00:18,531 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 05:00:18,532 - INFO - > Epoch 2: took 79.6s (avg 81.7s) | Best so far: epoch 0	train_loss: 0.7194 train_auc: 0.5174	val_loss: 0.7148 val_auc: 0.5640	test_loss: 0.7168 test_auc: 0.5408
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:01:29,571 - INFO - train: {'epoch': 3, 'time_epoch': 70.97291, 'eta': 6909.98748, 'eta_hours': 1.91944, 'loss': 0.16313554, 'lr': 6e-05, 'params': 451793, 'time_iter': 0.06897, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.60253}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:01:33,956 - INFO - val: {'epoch': 3, 'time_epoch': 4.36315, 'loss': 0.10156152, 'lr': 0, 'params': 451793, 'time_iter': 0.03382, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.58713}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:01:38,344 - INFO - test: {'epoch': 3, 'time_epoch': 4.37098, 'loss': 0.13857773, 'lr': 0, 'params': 451793, 'time_iter': 0.03388, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.62392}
2025-08-17 05:01:38,348 - INFO - > Epoch 3: took 79.8s (avg 81.2s) | Best so far: epoch 3	train_loss: 0.1631 train_auc: 0.6025	val_loss: 0.1016 val_auc: 0.5871	test_loss: 0.1386 test_auc: 0.6239
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:02:49,323 - INFO - train: {'epoch': 4, 'time_epoch': 70.90339, 'eta': 6817.57118, 'eta_hours': 1.89377, 'loss': 0.15820662, 'lr': 8e-05, 'params': 451793, 'time_iter': 0.06891, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.62534}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:02:53,710 - INFO - val: {'epoch': 4, 'time_epoch': 4.36541, 'loss': 0.09972088, 'lr': 0, 'params': 451793, 'time_iter': 0.03384, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.61756}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:02:58,068 - INFO - test: {'epoch': 4, 'time_epoch': 4.34233, 'loss': 0.14282461, 'lr': 0, 'params': 451793, 'time_iter': 0.03366, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.59046}
2025-08-17 05:02:58,071 - INFO - > Epoch 4: took 79.7s (avg 80.9s) | Best so far: epoch 4	train_loss: 0.1582 train_auc: 0.6253	val_loss: 0.0997 val_auc: 0.6176	test_loss: 0.1428 test_auc: 0.5905
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:04:09,677 - INFO - train: {'epoch': 5, 'time_epoch': 71.53215, 'eta': 6742.17649, 'eta_hours': 1.87283, 'loss': 0.15484302, 'lr': 0.0001, 'params': 451793, 'time_iter': 0.06952, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66245}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:04:14,229 - INFO - val: {'epoch': 5, 'time_epoch': 4.5251, 'loss': 0.09694711, 'lr': 0, 'params': 451793, 'time_iter': 0.03508, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.65114}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:04:18,776 - INFO - test: {'epoch': 5, 'time_epoch': 4.52649, 'loss': 0.12914462, 'lr': 0, 'params': 451793, 'time_iter': 0.03509, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71217}
2025-08-17 05:04:18,781 - INFO - > Epoch 5: took 80.7s (avg 80.9s) | Best so far: epoch 5	train_loss: 0.1548 train_auc: 0.6624	val_loss: 0.0969 val_auc: 0.6511	test_loss: 0.1291 test_auc: 0.7122
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:05:29,814 - INFO - train: {'epoch': 6, 'time_epoch': 70.96028, 'eta': 6660.28756, 'eta_hours': 1.85008, 'loss': 0.14900522, 'lr': 9.997e-05, 'params': 451793, 'time_iter': 0.06896, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70113}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:05:34,271 - INFO - val: {'epoch': 6, 'time_epoch': 4.43455, 'loss': 0.09726701, 'lr': 0, 'params': 451793, 'time_iter': 0.03438, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68396}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:05:38,723 - INFO - test: {'epoch': 6, 'time_epoch': 4.43609, 'loss': 0.1357488, 'lr': 0, 'params': 451793, 'time_iter': 0.03439, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.68151}
2025-08-17 05:05:38,726 - INFO - > Epoch 6: took 79.9s (avg 80.7s) | Best so far: epoch 6	train_loss: 0.1490 train_auc: 0.7011	val_loss: 0.0973 val_auc: 0.6840	test_loss: 0.1357 test_auc: 0.6815
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:06:49,813 - INFO - train: {'epoch': 7, 'time_epoch': 71.01069, 'eta': 6581.71054, 'eta_hours': 1.82825, 'loss': 0.14669388, 'lr': 9.989e-05, 'params': 451793, 'time_iter': 0.06901, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71528}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:06:54,360 - INFO - val: {'epoch': 7, 'time_epoch': 4.52181, 'loss': 0.0892113, 'lr': 0, 'params': 451793, 'time_iter': 0.03505, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70845}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:06:58,910 - INFO - test: {'epoch': 7, 'time_epoch': 4.52916, 'loss': 0.12589028, 'lr': 0, 'params': 451793, 'time_iter': 0.03511, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72524}
2025-08-17 05:06:58,914 - INFO - > Epoch 7: took 80.2s (avg 80.7s) | Best so far: epoch 7	train_loss: 0.1467 train_auc: 0.7153	val_loss: 0.0892 val_auc: 0.7085	test_loss: 0.1259 test_auc: 0.7252
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:08:10,700 - INFO - train: {'epoch': 8, 'time_epoch': 71.71098, 'eta': 6511.8956, 'eta_hours': 1.80886, 'loss': 0.14216351, 'lr': 9.975e-05, 'params': 451793, 'time_iter': 0.06969, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73262}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:08:15,184 - INFO - val: {'epoch': 8, 'time_epoch': 4.4619, 'loss': 0.09146569, 'lr': 0, 'params': 451793, 'time_iter': 0.03459, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6983}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:08:19,648 - INFO - test: {'epoch': 8, 'time_epoch': 4.44649, 'loss': 0.12408545, 'lr': 0, 'params': 451793, 'time_iter': 0.03447, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73724}
2025-08-17 05:08:19,650 - INFO - > Epoch 8: took 80.7s (avg 80.7s) | Best so far: epoch 7	train_loss: 0.1467 train_auc: 0.7153	val_loss: 0.0892 val_auc: 0.7085	test_loss: 0.1259 test_auc: 0.7252
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:09:30,849 - INFO - train: {'epoch': 9, 'time_epoch': 71.11875, 'eta': 6436.37143, 'eta_hours': 1.78788, 'loss': 0.13975762, 'lr': 9.956e-05, 'params': 451793, 'time_iter': 0.06911, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74139}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:09:35,343 - INFO - val: {'epoch': 9, 'time_epoch': 4.46787, 'loss': 0.08637052, 'lr': 0, 'params': 451793, 'time_iter': 0.03463, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72864}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:09:39,875 - INFO - test: {'epoch': 9, 'time_epoch': 4.51497, 'loss': 0.12239554, 'lr': 0, 'params': 451793, 'time_iter': 0.035, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74927}
2025-08-17 05:09:39,912 - INFO - > Epoch 9: took 80.3s (avg 80.6s) | Best so far: epoch 9	train_loss: 0.1398 train_auc: 0.7414	val_loss: 0.0864 val_auc: 0.7286	test_loss: 0.1224 test_auc: 0.7493
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:10:52,378 - INFO - train: {'epoch': 10, 'time_epoch': 72.39114, 'eta': 6371.94301, 'eta_hours': 1.76998, 'loss': 0.13840306, 'lr': 9.932e-05, 'params': 451793, 'time_iter': 0.07035, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75368}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:10:56,844 - INFO - val: {'epoch': 10, 'time_epoch': 4.44305, 'loss': 0.09262607, 'lr': 0, 'params': 451793, 'time_iter': 0.03444, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72182}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:11:01,297 - INFO - test: {'epoch': 10, 'time_epoch': 4.43591, 'loss': 0.12639175, 'lr': 0, 'params': 451793, 'time_iter': 0.03439, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71688}
2025-08-17 05:11:01,299 - INFO - > Epoch 10: took 81.4s (avg 80.7s) | Best so far: epoch 9	train_loss: 0.1398 train_auc: 0.7414	val_loss: 0.0864 val_auc: 0.7286	test_loss: 0.1224 test_auc: 0.7493
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:12:13,138 - INFO - train: {'epoch': 11, 'time_epoch': 71.76459, 'eta': 6301.59278, 'eta_hours': 1.75044, 'loss': 0.1376819, 'lr': 9.902e-05, 'params': 451793, 'time_iter': 0.06974, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74901}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:12:17,604 - INFO - val: {'epoch': 11, 'time_epoch': 4.44448, 'loss': 0.08591441, 'lr': 0, 'params': 451793, 'time_iter': 0.03445, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72961}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:12:22,053 - INFO - test: {'epoch': 11, 'time_epoch': 4.43211, 'loss': 0.12229547, 'lr': 0, 'params': 451793, 'time_iter': 0.03436, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74384}
2025-08-17 05:12:22,055 - INFO - > Epoch 11: took 80.8s (avg 80.7s) | Best so far: epoch 11	train_loss: 0.1377 train_auc: 0.7490	val_loss: 0.0859 val_auc: 0.7296	test_loss: 0.1223 test_auc: 0.7438
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:13:33,283 - INFO - train: {'epoch': 12, 'time_epoch': 71.15143, 'eta': 6226.92148, 'eta_hours': 1.7297, 'loss': 0.13423519, 'lr': 9.867e-05, 'params': 451793, 'time_iter': 0.06915, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76085}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:13:37,843 - INFO - val: {'epoch': 12, 'time_epoch': 4.53406, 'loss': 0.08411142, 'lr': 0, 'params': 451793, 'time_iter': 0.03515, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75002}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:13:42,348 - INFO - test: {'epoch': 12, 'time_epoch': 4.48418, 'loss': 0.11808153, 'lr': 0, 'params': 451793, 'time_iter': 0.03476, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74034}
2025-08-17 05:13:42,351 - INFO - > Epoch 12: took 80.3s (avg 80.7s) | Best so far: epoch 12	train_loss: 0.1342 train_auc: 0.7609	val_loss: 0.0841 val_auc: 0.7500	test_loss: 0.1181 test_auc: 0.7403
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:14:53,098 - INFO - train: {'epoch': 13, 'time_epoch': 70.67342, 'eta': 6149.81667, 'eta_hours': 1.70828, 'loss': 0.13443939, 'lr': 9.826e-05, 'params': 451793, 'time_iter': 0.06868, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76128}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:14:57,458 - INFO - val: {'epoch': 13, 'time_epoch': 4.33488, 'loss': 0.08315064, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76221}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:15:01,852 - INFO - test: {'epoch': 13, 'time_epoch': 4.37352, 'loss': 0.11583502, 'lr': 0, 'params': 451793, 'time_iter': 0.0339, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.77089}
2025-08-17 05:15:01,856 - INFO - > Epoch 13: took 79.5s (avg 80.6s) | Best so far: epoch 13	train_loss: 0.1344 train_auc: 0.7613	val_loss: 0.0832 val_auc: 0.7622	test_loss: 0.1158 test_auc: 0.7709
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:16:12,930 - INFO - train: {'epoch': 14, 'time_epoch': 70.99751, 'eta': 6075.40592, 'eta_hours': 1.68761, 'loss': 0.133028, 'lr': 9.78e-05, 'params': 451793, 'time_iter': 0.069, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76867}
2025-08-17 05:16:17,358 - INFO - val: {'epoch': 14, 'time_epoch': 4.4045, 'loss': 0.08343768, 'lr': 0, 'params': 451793, 'time_iter': 0.03414, 'accuracy': 0.98152, 'precision': 1.0, 'recall': 0.06173, 'f1': 0.11628, 'auc': 0.77329}
2025-08-17 05:16:21,772 - INFO - test: {'epoch': 14, 'time_epoch': 4.39625, 'loss': 0.11811172, 'lr': 0, 'params': 451793, 'time_iter': 0.03408, 'accuracy': 0.96815, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76574}
2025-08-17 05:16:21,774 - INFO - > Epoch 14: took 79.9s (avg 80.6s) | Best so far: epoch 14	train_loss: 0.1330 train_auc: 0.7687	val_loss: 0.0834 val_auc: 0.7733	test_loss: 0.1181 test_auc: 0.7657
2025-08-17 05:17:32,542 - INFO - train: {'epoch': 15, 'time_epoch': 70.67832, 'eta': 5999.74609, 'eta_hours': 1.6666, 'loss': 0.1317772, 'lr': 9.729e-05, 'params': 451793, 'time_iter': 0.06869, 'accuracy': 0.96252, 'precision': 0.33333, 'recall': 0.00081, 'f1': 0.00162, 'auc': 0.7691}
2025-08-17 05:17:36,951 - INFO - val: {'epoch': 15, 'time_epoch': 4.38478, 'loss': 0.08381059, 'lr': 0, 'params': 451793, 'time_iter': 0.03399, 'accuracy': 0.98152, 'precision': 1.0, 'recall': 0.06173, 'f1': 0.11628, 'auc': 0.73261}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 05:17:41,364 - INFO - test: {'epoch': 15, 'time_epoch': 4.39639, 'loss': 0.11917124, 'lr': 0, 'params': 451793, 'time_iter': 0.03408, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75246}
2025-08-17 05:17:41,366 - INFO - > Epoch 15: took 79.6s (avg 80.5s) | Best so far: epoch 14	train_loss: 0.1330 train_auc: 0.7687	val_loss: 0.0834 val_auc: 0.7733	test_loss: 0.1181 test_auc: 0.7657
2025-08-17 05:18:52,346 - INFO - train: {'epoch': 16, 'time_epoch': 70.89459, 'eta': 5925.72821, 'eta_hours': 1.64604, 'loss': 0.12920392, 'lr': 9.673e-05, 'params': 451793, 'time_iter': 0.0689, 'accuracy': 0.96255, 'precision': 0.5, 'recall': 0.00081, 'f1': 0.00162, 'auc': 0.78655}
2025-08-17 05:18:56,916 - INFO - val: {'epoch': 16, 'time_epoch': 4.54151, 'loss': 0.08198676, 'lr': 0, 'params': 451793, 'time_iter': 0.03521, 'accuracy': 0.98079, 'precision': 0.5625, 'recall': 0.11111, 'f1': 0.18557, 'auc': 0.77164}
2025-08-17 05:19:01,452 - INFO - test: {'epoch': 16, 'time_epoch': 4.51359, 'loss': 0.11596799, 'lr': 0, 'params': 451793, 'time_iter': 0.03499, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.01538, 'f1': 0.02985, 'auc': 0.75472}
2025-08-17 05:19:01,456 - INFO - > Epoch 16: took 80.1s (avg 80.5s) | Best so far: epoch 14	train_loss: 0.1330 train_auc: 0.7687	val_loss: 0.0834 val_auc: 0.7733	test_loss: 0.1181 test_auc: 0.7657
2025-08-17 05:20:11,977 - INFO - train: {'epoch': 17, 'time_epoch': 70.43764, 'eta': 5849.9757, 'eta_hours': 1.62499, 'loss': 0.12875727, 'lr': 9.611e-05, 'params': 451793, 'time_iter': 0.06845, 'accuracy': 0.96295, 'precision': 0.64444, 'recall': 0.02354, 'f1': 0.04542, 'auc': 0.78255}
2025-08-17 05:20:16,172 - INFO - val: {'epoch': 17, 'time_epoch': 4.17114, 'loss': 0.0803777, 'lr': 0, 'params': 451793, 'time_iter': 0.03233, 'accuracy': 0.98006, 'precision': 0.46667, 'recall': 0.08642, 'f1': 0.14583, 'auc': 0.75967}
2025-08-17 05:20:20,307 - INFO - test: {'epoch': 17, 'time_epoch': 4.11845, 'loss': 0.11466314, 'lr': 0, 'params': 451793, 'time_iter': 0.03193, 'accuracy': 0.96815, 'precision': 0.42857, 'recall': 0.02308, 'f1': 0.0438, 'auc': 0.76999}
2025-08-17 05:20:20,309 - INFO - > Epoch 17: took 78.9s (avg 80.4s) | Best so far: epoch 14	train_loss: 0.1330 train_auc: 0.7687	val_loss: 0.0834 val_auc: 0.7733	test_loss: 0.1181 test_auc: 0.7657
2025-08-17 05:21:29,839 - INFO - train: {'epoch': 18, 'time_epoch': 69.44588, 'eta': 5770.55462, 'eta_hours': 1.60293, 'loss': 0.12814473, 'lr': 9.545e-05, 'params': 451793, 'time_iter': 0.06749, 'accuracy': 0.96377, 'precision': 0.71739, 'recall': 0.05357, 'f1': 0.0997, 'auc': 0.79353}
2025-08-17 05:21:33,995 - INFO - val: {'epoch': 18, 'time_epoch': 4.13239, 'loss': 0.08406433, 'lr': 0, 'params': 451793, 'time_iter': 0.03203, 'accuracy': 0.98055, 'precision': 0.57143, 'recall': 0.04938, 'f1': 0.09091, 'auc': 0.71938}
2025-08-17 05:21:38,165 - INFO - test: {'epoch': 18, 'time_epoch': 4.15393, 'loss': 0.11682666, 'lr': 0, 'params': 451793, 'time_iter': 0.0322, 'accuracy': 0.96937, 'precision': 0.7, 'recall': 0.05385, 'f1': 0.1, 'auc': 0.76997}
2025-08-17 05:21:38,167 - INFO - > Epoch 18: took 77.9s (avg 80.2s) | Best so far: epoch 14	train_loss: 0.1330 train_auc: 0.7687	val_loss: 0.0834 val_auc: 0.7733	test_loss: 0.1181 test_auc: 0.7657
2025-08-17 05:22:47,249 - INFO - train: {'epoch': 19, 'time_epoch': 68.9915, 'eta': 5690.31355, 'eta_hours': 1.58064, 'loss': 0.1268471, 'lr': 9.474e-05, 'params': 451793, 'time_iter': 0.06705, 'accuracy': 0.96347, 'precision': 0.59868, 'recall': 0.07386, 'f1': 0.1315, 'auc': 0.79753}
2025-08-17 05:22:51,645 - INFO - val: {'epoch': 19, 'time_epoch': 4.37175, 'loss': 0.08211263, 'lr': 0, 'params': 451793, 'time_iter': 0.03389, 'accuracy': 0.98104, 'precision': 0.58824, 'recall': 0.12346, 'f1': 0.20408, 'auc': 0.73759}
2025-08-17 05:22:56,070 - INFO - test: {'epoch': 19, 'time_epoch': 4.40575, 'loss': 0.11326507, 'lr': 0, 'params': 451793, 'time_iter': 0.03415, 'accuracy': 0.96815, 'precision': 0.47059, 'recall': 0.06154, 'f1': 0.10884, 'auc': 0.76015}
2025-08-17 05:22:56,074 - INFO - > Epoch 19: took 77.9s (avg 80.1s) | Best so far: epoch 14	train_loss: 0.1330 train_auc: 0.7687	val_loss: 0.0834 val_auc: 0.7733	test_loss: 0.1181 test_auc: 0.7657
2025-08-17 05:24:06,891 - INFO - train: {'epoch': 20, 'time_epoch': 70.72814, 'eta': 5617.67692, 'eta_hours': 1.56047, 'loss': 0.12589535, 'lr': 9.397e-05, 'params': 451793, 'time_iter': 0.06873, 'accuracy': 0.9638, 'precision': 0.6, 'recall': 0.09984, 'f1': 0.17119, 'auc': 0.79841}
2025-08-17 05:24:11,329 - INFO - val: {'epoch': 20, 'time_epoch': 4.41681, 'loss': 0.07905193, 'lr': 0, 'params': 451793, 'time_iter': 0.03424, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.09877, 'f1': 0.16495, 'auc': 0.77584}
2025-08-17 05:24:15,738 - INFO - test: {'epoch': 20, 'time_epoch': 4.39142, 'loss': 0.11460405, 'lr': 0, 'params': 451793, 'time_iter': 0.03404, 'accuracy': 0.96693, 'precision': 0.28571, 'recall': 0.03077, 'f1': 0.05556, 'auc': 0.76551}
2025-08-17 05:24:15,740 - INFO - > Epoch 20: took 79.7s (avg 80.1s) | Best so far: epoch 20	train_loss: 0.1259 train_auc: 0.7984	val_loss: 0.0791 val_auc: 0.7758	test_loss: 0.1146 test_auc: 0.7655
2025-08-17 05:25:27,587 - INFO - train: {'epoch': 21, 'time_epoch': 71.75904, 'eta': 5548.86882, 'eta_hours': 1.54135, 'loss': 0.12549944, 'lr': 9.316e-05, 'params': 451793, 'time_iter': 0.06974, 'accuracy': 0.96471, 'precision': 0.65639, 'recall': 0.12094, 'f1': 0.20425, 'auc': 0.79609}
2025-08-17 05:25:31,933 - INFO - val: {'epoch': 21, 'time_epoch': 4.32059, 'loss': 0.07936347, 'lr': 0, 'params': 451793, 'time_iter': 0.03349, 'accuracy': 0.98298, 'precision': 0.66667, 'recall': 0.2716, 'f1': 0.38596, 'auc': 0.73748}
2025-08-17 05:25:36,269 - INFO - test: {'epoch': 21, 'time_epoch': 4.31569, 'loss': 0.11827497, 'lr': 0, 'params': 451793, 'time_iter': 0.03345, 'accuracy': 0.96864, 'precision': 0.51613, 'recall': 0.12308, 'f1': 0.19876, 'auc': 0.74834}
2025-08-17 05:25:36,273 - INFO - > Epoch 21: took 80.5s (avg 80.1s) | Best so far: epoch 20	train_loss: 0.1259 train_auc: 0.7984	val_loss: 0.0791 val_auc: 0.7758	test_loss: 0.1146 test_auc: 0.7655
2025-08-17 05:26:46,606 - INFO - train: {'epoch': 22, 'time_epoch': 70.24855, 'eta': 5474.74726, 'eta_hours': 1.52076, 'loss': 0.12381517, 'lr': 9.23e-05, 'params': 451793, 'time_iter': 0.06827, 'accuracy': 0.96486, 'precision': 0.63014, 'recall': 0.14935, 'f1': 0.24147, 'auc': 0.80548}
2025-08-17 05:26:50,762 - INFO - val: {'epoch': 22, 'time_epoch': 4.13481, 'loss': 0.07978047, 'lr': 0, 'params': 451793, 'time_iter': 0.03205, 'accuracy': 0.98104, 'precision': 0.56522, 'recall': 0.16049, 'f1': 0.25, 'auc': 0.75785}
2025-08-17 05:26:54,959 - INFO - test: {'epoch': 22, 'time_epoch': 4.179, 'loss': 0.11382433, 'lr': 0, 'params': 451793, 'time_iter': 0.0324, 'accuracy': 0.96937, 'precision': 0.57143, 'recall': 0.12308, 'f1': 0.20253, 'auc': 0.76017}
2025-08-17 05:26:54,962 - INFO - > Epoch 22: took 78.7s (avg 80.1s) | Best so far: epoch 20	train_loss: 0.1259 train_auc: 0.7984	val_loss: 0.0791 val_auc: 0.7758	test_loss: 0.1146 test_auc: 0.7655
2025-08-17 05:28:05,978 - INFO - train: {'epoch': 23, 'time_epoch': 70.93132, 'eta': 5403.11055, 'eta_hours': 1.50086, 'loss': 0.12303017, 'lr': 9.14e-05, 'params': 451793, 'time_iter': 0.06893, 'accuracy': 0.96502, 'precision': 0.6209, 'recall': 0.16883, 'f1': 0.26548, 'auc': 0.80813}
2025-08-17 05:28:10,242 - INFO - val: {'epoch': 23, 'time_epoch': 4.24038, 'loss': 0.08071566, 'lr': 0, 'params': 451793, 'time_iter': 0.03287, 'accuracy': 0.98079, 'precision': 0.54545, 'recall': 0.14815, 'f1': 0.23301, 'auc': 0.7208}
2025-08-17 05:28:14,551 - INFO - test: {'epoch': 23, 'time_epoch': 4.29142, 'loss': 0.12288567, 'lr': 0, 'params': 451793, 'time_iter': 0.03327, 'accuracy': 0.96742, 'precision': 0.4, 'recall': 0.06154, 'f1': 0.10667, 'auc': 0.73854}
2025-08-17 05:28:14,554 - INFO - > Epoch 23: took 79.6s (avg 80.0s) | Best so far: epoch 20	train_loss: 0.1259 train_auc: 0.7984	val_loss: 0.0791 val_auc: 0.7758	test_loss: 0.1146 test_auc: 0.7655
2025-08-17 05:29:25,919 - INFO - train: {'epoch': 24, 'time_epoch': 71.27651, 'eta': 5332.56584, 'eta_hours': 1.48127, 'loss': 0.12327165, 'lr': 9.045e-05, 'params': 451793, 'time_iter': 0.06927, 'accuracy': 0.96499, 'precision': 0.62422, 'recall': 0.16315, 'f1': 0.25869, 'auc': 0.80909}
2025-08-17 05:29:30,384 - INFO - val: {'epoch': 24, 'time_epoch': 4.44215, 'loss': 0.08011998, 'lr': 0, 'params': 451793, 'time_iter': 0.03444, 'accuracy': 0.98006, 'precision': 0.48, 'recall': 0.14815, 'f1': 0.22642, 'auc': 0.76655}
2025-08-17 05:29:34,880 - INFO - test: {'epoch': 24, 'time_epoch': 4.47743, 'loss': 0.11938215, 'lr': 0, 'params': 451793, 'time_iter': 0.03471, 'accuracy': 0.96864, 'precision': 0.51429, 'recall': 0.13846, 'f1': 0.21818, 'auc': 0.74926}
2025-08-17 05:29:34,883 - INFO - > Epoch 24: took 80.3s (avg 80.1s) | Best so far: epoch 20	train_loss: 0.1259 train_auc: 0.7984	val_loss: 0.0791 val_auc: 0.7758	test_loss: 0.1146 test_auc: 0.7655
2025-08-17 05:30:46,545 - INFO - train: {'epoch': 25, 'time_epoch': 71.58003, 'eta': 5262.82869, 'eta_hours': 1.4619, 'loss': 0.12262357, 'lr': 8.946e-05, 'params': 451793, 'time_iter': 0.06956, 'accuracy': 0.96489, 'precision': 0.60907, 'recall': 0.17451, 'f1': 0.27129, 'auc': 0.81616}
2025-08-17 05:30:50,931 - INFO - val: {'epoch': 25, 'time_epoch': 4.36227, 'loss': 0.08359412, 'lr': 0, 'params': 451793, 'time_iter': 0.03382, 'accuracy': 0.98177, 'precision': 0.61538, 'recall': 0.19753, 'f1': 0.29907, 'auc': 0.72422}
2025-08-17 05:30:55,322 - INFO - test: {'epoch': 25, 'time_epoch': 4.37302, 'loss': 0.11611099, 'lr': 0, 'params': 451793, 'time_iter': 0.0339, 'accuracy': 0.96961, 'precision': 0.57143, 'recall': 0.15385, 'f1': 0.24242, 'auc': 0.75766}
2025-08-17 05:30:55,325 - INFO - > Epoch 25: took 80.4s (avg 80.1s) | Best so far: epoch 20	train_loss: 0.1259 train_auc: 0.7984	val_loss: 0.0791 val_auc: 0.7758	test_loss: 0.1146 test_auc: 0.7655
2025-08-17 05:32:06,712 - INFO - train: {'epoch': 26, 'time_epoch': 71.29597, 'eta': 5192.18703, 'eta_hours': 1.44227, 'loss': 0.12040761, 'lr': 8.842e-05, 'params': 451793, 'time_iter': 0.06929, 'accuracy': 0.96578, 'precision': 0.64972, 'recall': 0.18669, 'f1': 0.29004, 'auc': 0.81398}
2025-08-17 05:32:11,132 - INFO - val: {'epoch': 26, 'time_epoch': 4.39391, 'loss': 0.0793428, 'lr': 0, 'params': 451793, 'time_iter': 0.03406, 'accuracy': 0.98055, 'precision': 0.51613, 'recall': 0.19753, 'f1': 0.28571, 'auc': 0.77472}
2025-08-17 05:32:15,561 - INFO - test: {'epoch': 26, 'time_epoch': 4.40741, 'loss': 0.11923511, 'lr': 0, 'params': 451793, 'time_iter': 0.03417, 'accuracy': 0.96791, 'precision': 0.47826, 'recall': 0.16923, 'f1': 0.25, 'auc': 0.76067}
2025-08-17 05:32:15,564 - INFO - > Epoch 26: took 80.2s (avg 80.1s) | Best so far: epoch 20	train_loss: 0.1259 train_auc: 0.7984	val_loss: 0.0791 val_auc: 0.7758	test_loss: 0.1146 test_auc: 0.7655
2025-08-17 05:33:27,076 - INFO - train: {'epoch': 27, 'time_epoch': 71.42749, 'eta': 5121.83682, 'eta_hours': 1.42273, 'loss': 0.12085728, 'lr': 8.734e-05, 'params': 451793, 'time_iter': 0.06941, 'accuracy': 0.96562, 'precision': 0.63467, 'recall': 0.19318, 'f1': 0.2962, 'auc': 0.81411}
2025-08-17 05:33:31,367 - INFO - val: {'epoch': 27, 'time_epoch': 4.26541, 'loss': 0.07667568, 'lr': 0, 'params': 451793, 'time_iter': 0.03307, 'accuracy': 0.98298, 'precision': 0.67742, 'recall': 0.25926, 'f1': 0.375, 'auc': 0.77112}
2025-08-17 05:33:35,674 - INFO - test: {'epoch': 27, 'time_epoch': 4.2856, 'loss': 0.11762909, 'lr': 0, 'params': 451793, 'time_iter': 0.03322, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.16923, 'f1': 0.25287, 'auc': 0.77339}
2025-08-17 05:33:35,678 - INFO - > Epoch 27: took 80.1s (avg 80.1s) | Best so far: epoch 20	train_loss: 0.1259 train_auc: 0.7984	val_loss: 0.0791 val_auc: 0.7758	test_loss: 0.1146 test_auc: 0.7655
2025-08-17 05:34:46,842 - INFO - train: {'epoch': 28, 'time_epoch': 71.07142, 'eta': 5050.54056, 'eta_hours': 1.40293, 'loss': 0.11976286, 'lr': 8.622e-05, 'params': 451793, 'time_iter': 0.06907, 'accuracy': 0.96541, 'precision': 0.62051, 'recall': 0.19643, 'f1': 0.2984, 'auc': 0.81985}
2025-08-17 05:34:51,306 - INFO - val: {'epoch': 28, 'time_epoch': 4.43756, 'loss': 0.07906965, 'lr': 0, 'params': 451793, 'time_iter': 0.0344, 'accuracy': 0.98006, 'precision': 0.48889, 'recall': 0.2716, 'f1': 0.34921, 'auc': 0.80498}
2025-08-17 05:34:55,815 - INFO - test: {'epoch': 28, 'time_epoch': 4.48953, 'loss': 0.11639938, 'lr': 0, 'params': 451793, 'time_iter': 0.0348, 'accuracy': 0.96961, 'precision': 0.55319, 'recall': 0.2, 'f1': 0.29379, 'auc': 0.76421}
2025-08-17 05:34:55,818 - INFO - > Epoch 28: took 80.1s (avg 80.1s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:36:07,217 - INFO - train: {'epoch': 29, 'time_epoch': 71.31021, 'eta': 4979.81648, 'eta_hours': 1.38328, 'loss': 0.11956264, 'lr': 8.506e-05, 'params': 451793, 'time_iter': 0.0693, 'accuracy': 0.96562, 'precision': 0.62531, 'recall': 0.20455, 'f1': 0.30826, 'auc': 0.81915}
2025-08-17 05:36:11,602 - INFO - val: {'epoch': 29, 'time_epoch': 4.36127, 'loss': 0.07719918, 'lr': 0, 'params': 451793, 'time_iter': 0.03381, 'accuracy': 0.98201, 'precision': 0.6129, 'recall': 0.23457, 'f1': 0.33929, 'auc': 0.76391}
2025-08-17 05:36:16,069 - INFO - test: {'epoch': 29, 'time_epoch': 4.44842, 'loss': 0.11595906, 'lr': 0, 'params': 451793, 'time_iter': 0.03448, 'accuracy': 0.96742, 'precision': 0.46429, 'recall': 0.2, 'f1': 0.27957, 'auc': 0.78252}
2025-08-17 05:36:16,072 - INFO - > Epoch 29: took 80.3s (avg 80.1s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:37:27,471 - INFO - train: {'epoch': 30, 'time_epoch': 71.31155, 'eta': 4909.05757, 'eta_hours': 1.36363, 'loss': 0.11823373, 'lr': 8.386e-05, 'params': 451793, 'time_iter': 0.0693, 'accuracy': 0.96648, 'precision': 0.65176, 'recall': 0.22484, 'f1': 0.33434, 'auc': 0.82914}
2025-08-17 05:37:31,922 - INFO - val: {'epoch': 30, 'time_epoch': 4.42602, 'loss': 0.07530884, 'lr': 0, 'params': 451793, 'time_iter': 0.03431, 'accuracy': 0.98225, 'precision': 0.68182, 'recall': 0.18519, 'f1': 0.29126, 'auc': 0.75877}
2025-08-17 05:37:36,374 - INFO - test: {'epoch': 30, 'time_epoch': 4.43421, 'loss': 0.12186588, 'lr': 0, 'params': 451793, 'time_iter': 0.03437, 'accuracy': 0.96766, 'precision': 0.38462, 'recall': 0.03846, 'f1': 0.06993, 'auc': 0.75425}
2025-08-17 05:37:36,377 - INFO - > Epoch 30: took 80.3s (avg 80.1s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:38:47,194 - INFO - train: {'epoch': 31, 'time_epoch': 70.72955, 'eta': 4837.02735, 'eta_hours': 1.34362, 'loss': 0.11837707, 'lr': 8.263e-05, 'params': 451793, 'time_iter': 0.06874, 'accuracy': 0.96575, 'precision': 0.62411, 'recall': 0.21429, 'f1': 0.31903, 'auc': 0.82438}
2025-08-17 05:38:51,732 - INFO - val: {'epoch': 31, 'time_epoch': 4.5117, 'loss': 0.07606224, 'lr': 0, 'params': 451793, 'time_iter': 0.03497, 'accuracy': 0.98225, 'precision': 0.625, 'recall': 0.24691, 'f1': 0.35398, 'auc': 0.76649}
2025-08-17 05:38:56,259 - INFO - test: {'epoch': 31, 'time_epoch': 4.50449, 'loss': 0.11453037, 'lr': 0, 'params': 451793, 'time_iter': 0.03492, 'accuracy': 0.97058, 'precision': 0.58491, 'recall': 0.23846, 'f1': 0.3388, 'auc': 0.77959}
2025-08-17 05:38:56,262 - INFO - > Epoch 31: took 79.9s (avg 80.1s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:40:07,511 - INFO - train: {'epoch': 32, 'time_epoch': 71.15854, 'eta': 4765.94695, 'eta_hours': 1.32387, 'loss': 0.11775519, 'lr': 8.136e-05, 'params': 451793, 'time_iter': 0.06915, 'accuracy': 0.96581, 'precision': 0.62529, 'recall': 0.21672, 'f1': 0.32188, 'auc': 0.8259}
2025-08-17 05:40:11,908 - INFO - val: {'epoch': 32, 'time_epoch': 4.37199, 'loss': 0.07669527, 'lr': 0, 'params': 451793, 'time_iter': 0.03389, 'accuracy': 0.98225, 'precision': 0.6, 'recall': 0.2963, 'f1': 0.39669, 'auc': 0.74491}
2025-08-17 05:40:16,346 - INFO - test: {'epoch': 32, 'time_epoch': 4.42014, 'loss': 0.11592727, 'lr': 0, 'params': 451793, 'time_iter': 0.03426, 'accuracy': 0.96815, 'precision': 0.49231, 'recall': 0.24615, 'f1': 0.32821, 'auc': 0.77709}
2025-08-17 05:40:16,350 - INFO - > Epoch 32: took 80.1s (avg 80.1s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:41:26,712 - INFO - train: {'epoch': 33, 'time_epoch': 70.27532, 'eta': 4693.14746, 'eta_hours': 1.30365, 'loss': 0.11610335, 'lr': 8.005e-05, 'params': 451793, 'time_iter': 0.06829, 'accuracy': 0.9669, 'precision': 0.65646, 'recall': 0.24351, 'f1': 0.35524, 'auc': 0.83093}
2025-08-17 05:41:30,936 - INFO - val: {'epoch': 33, 'time_epoch': 4.20175, 'loss': 0.07545127, 'lr': 0, 'params': 451793, 'time_iter': 0.03257, 'accuracy': 0.98104, 'precision': 0.54286, 'recall': 0.23457, 'f1': 0.32759, 'auc': 0.76683}
2025-08-17 05:41:35,155 - INFO - test: {'epoch': 33, 'time_epoch': 4.20083, 'loss': 0.11764416, 'lr': 0, 'params': 451793, 'time_iter': 0.03256, 'accuracy': 0.97009, 'precision': 0.5814, 'recall': 0.19231, 'f1': 0.28902, 'auc': 0.7644}
2025-08-17 05:41:35,157 - INFO - > Epoch 33: took 78.8s (avg 80.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:42:44,294 - INFO - train: {'epoch': 34, 'time_epoch': 69.05136, 'eta': 4618.21914, 'eta_hours': 1.28284, 'loss': 0.11646839, 'lr': 7.872e-05, 'params': 451793, 'time_iter': 0.06711, 'accuracy': 0.96681, 'precision': 0.65217, 'recall': 0.24351, 'f1': 0.35461, 'auc': 0.82873}
2025-08-17 05:42:48,761 - INFO - val: {'epoch': 34, 'time_epoch': 4.43916, 'loss': 0.07521266, 'lr': 0, 'params': 451793, 'time_iter': 0.03441, 'accuracy': 0.98079, 'precision': 0.53571, 'recall': 0.18519, 'f1': 0.27523, 'auc': 0.76926}
2025-08-17 05:42:53,212 - INFO - test: {'epoch': 34, 'time_epoch': 4.4303, 'loss': 0.11814702, 'lr': 0, 'params': 451793, 'time_iter': 0.03434, 'accuracy': 0.97034, 'precision': 0.58333, 'recall': 0.21538, 'f1': 0.31461, 'auc': 0.76145}
2025-08-17 05:42:53,215 - INFO - > Epoch 34: took 78.1s (avg 80.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:44:03,618 - INFO - train: {'epoch': 35, 'time_epoch': 70.31585, 'eta': 4545.8653, 'eta_hours': 1.26274, 'loss': 0.11532204, 'lr': 7.735e-05, 'params': 451793, 'time_iter': 0.06833, 'accuracy': 0.96742, 'precision': 0.6581, 'recall': 0.27029, 'f1': 0.3832, 'auc': 0.82908}
2025-08-17 05:44:07,908 - INFO - val: {'epoch': 35, 'time_epoch': 4.26664, 'loss': 0.07698047, 'lr': 0, 'params': 451793, 'time_iter': 0.03307, 'accuracy': 0.98249, 'precision': 0.64516, 'recall': 0.24691, 'f1': 0.35714, 'auc': 0.75709}
2025-08-17 05:44:12,185 - INFO - test: {'epoch': 35, 'time_epoch': 4.25972, 'loss': 0.11957836, 'lr': 0, 'params': 451793, 'time_iter': 0.03302, 'accuracy': 0.96937, 'precision': 0.53846, 'recall': 0.21538, 'f1': 0.30769, 'auc': 0.7482}
2025-08-17 05:44:12,188 - INFO - > Epoch 35: took 79.0s (avg 80.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:45:21,687 - INFO - train: {'epoch': 36, 'time_epoch': 69.41041, 'eta': 4472.07993, 'eta_hours': 1.24224, 'loss': 0.11638864, 'lr': 7.595e-05, 'params': 451793, 'time_iter': 0.06745, 'accuracy': 0.96684, 'precision': 0.65563, 'recall': 0.24107, 'f1': 0.35252, 'auc': 0.83002}
2025-08-17 05:45:25,975 - INFO - val: {'epoch': 36, 'time_epoch': 4.2639, 'loss': 0.07924581, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.98104, 'precision': 0.53659, 'recall': 0.2716, 'f1': 0.36066, 'auc': 0.76789}
2025-08-17 05:45:30,309 - INFO - test: {'epoch': 36, 'time_epoch': 4.3139, 'loss': 0.12056024, 'lr': 0, 'params': 451793, 'time_iter': 0.03344, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.19231, 'f1': 0.27778, 'auc': 0.75894}
2025-08-17 05:45:30,312 - INFO - > Epoch 36: took 78.1s (avg 79.9s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:46:37,847 - INFO - train: {'epoch': 37, 'time_epoch': 67.45424, 'eta': 4395.33317, 'eta_hours': 1.22093, 'loss': 0.11445881, 'lr': 7.452e-05, 'params': 451793, 'time_iter': 0.06555, 'accuracy': 0.9672, 'precision': 0.65971, 'recall': 0.25649, 'f1': 0.36937, 'auc': 0.83491}
2025-08-17 05:46:42,185 - INFO - val: {'epoch': 37, 'time_epoch': 4.31634, 'loss': 0.07314114, 'lr': 0, 'params': 451793, 'time_iter': 0.03346, 'accuracy': 0.98322, 'precision': 0.66667, 'recall': 0.2963, 'f1': 0.41026, 'auc': 0.7767}
2025-08-17 05:46:46,514 - INFO - test: {'epoch': 37, 'time_epoch': 4.31088, 'loss': 0.11460415, 'lr': 0, 'params': 451793, 'time_iter': 0.03342, 'accuracy': 0.97009, 'precision': 0.55932, 'recall': 0.25385, 'f1': 0.34921, 'auc': 0.77758}
2025-08-17 05:46:46,517 - INFO - > Epoch 37: took 76.2s (avg 79.8s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:47:54,656 - INFO - train: {'epoch': 38, 'time_epoch': 68.05225, 'eta': 4319.99831, 'eta_hours': 1.2, 'loss': 0.11449699, 'lr': 7.307e-05, 'params': 451793, 'time_iter': 0.06613, 'accuracy': 0.96702, 'precision': 0.65474, 'recall': 0.25244, 'f1': 0.36438, 'auc': 0.83624}
2025-08-17 05:47:58,892 - INFO - val: {'epoch': 38, 'time_epoch': 4.21341, 'loss': 0.07430443, 'lr': 0, 'params': 451793, 'time_iter': 0.03266, 'accuracy': 0.98322, 'precision': 0.65789, 'recall': 0.30864, 'f1': 0.42017, 'auc': 0.76493}
2025-08-17 05:48:03,101 - INFO - test: {'epoch': 38, 'time_epoch': 4.19109, 'loss': 0.11781315, 'lr': 0, 'params': 451793, 'time_iter': 0.03249, 'accuracy': 0.96864, 'precision': 0.5082, 'recall': 0.23846, 'f1': 0.32461, 'auc': 0.77152}
2025-08-17 05:48:03,104 - INFO - > Epoch 38: took 76.6s (avg 79.7s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:49:11,723 - INFO - train: {'epoch': 39, 'time_epoch': 68.53389, 'eta': 4245.75003, 'eta_hours': 1.17938, 'loss': 0.11421087, 'lr': 7.159e-05, 'params': 451793, 'time_iter': 0.0666, 'accuracy': 0.96763, 'precision': 0.66869, 'recall': 0.26867, 'f1': 0.38332, 'auc': 0.83559}
2025-08-17 05:49:16,030 - INFO - val: {'epoch': 39, 'time_epoch': 4.28561, 'loss': 0.07887839, 'lr': 0, 'params': 451793, 'time_iter': 0.03322, 'accuracy': 0.98006, 'precision': 0.4902, 'recall': 0.30864, 'f1': 0.37879, 'auc': 0.76529}
2025-08-17 05:49:20,357 - INFO - test: {'epoch': 39, 'time_epoch': 4.30913, 'loss': 0.1200511, 'lr': 0, 'params': 451793, 'time_iter': 0.0334, 'accuracy': 0.96718, 'precision': 0.45902, 'recall': 0.21538, 'f1': 0.29319, 'auc': 0.76228}
2025-08-17 05:49:20,359 - INFO - > Epoch 39: took 77.3s (avg 79.7s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:50:28,354 - INFO - train: {'epoch': 40, 'time_epoch': 67.90516, 'eta': 4170.87575, 'eta_hours': 1.15858, 'loss': 0.11277641, 'lr': 7.008e-05, 'params': 451793, 'time_iter': 0.06599, 'accuracy': 0.96714, 'precision': 0.64833, 'recall': 0.26786, 'f1': 0.37909, 'auc': 0.84312}
2025-08-17 05:50:32,649 - INFO - val: {'epoch': 40, 'time_epoch': 4.2733, 'loss': 0.07379201, 'lr': 0, 'params': 451793, 'time_iter': 0.03313, 'accuracy': 0.98249, 'precision': 0.62162, 'recall': 0.28395, 'f1': 0.38983, 'auc': 0.77962}
2025-08-17 05:50:36,932 - INFO - test: {'epoch': 40, 'time_epoch': 4.26649, 'loss': 0.11739274, 'lr': 0, 'params': 451793, 'time_iter': 0.03307, 'accuracy': 0.96937, 'precision': 0.53846, 'recall': 0.21538, 'f1': 0.30769, 'auc': 0.76566}
2025-08-17 05:50:36,934 - INFO - > Epoch 40: took 76.6s (avg 79.6s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:51:44,961 - INFO - train: {'epoch': 41, 'time_epoch': 67.93976, 'eta': 4096.38111, 'eta_hours': 1.13788, 'loss': 0.11286996, 'lr': 6.856e-05, 'params': 451793, 'time_iter': 0.06603, 'accuracy': 0.96763, 'precision': 0.65966, 'recall': 0.28003, 'f1': 0.39316, 'auc': 0.84259}
2025-08-17 05:51:49,349 - INFO - val: {'epoch': 41, 'time_epoch': 4.36467, 'loss': 0.07469729, 'lr': 0, 'params': 451793, 'time_iter': 0.03383, 'accuracy': 0.98322, 'precision': 0.66667, 'recall': 0.2963, 'f1': 0.41026, 'auc': 0.7533}
2025-08-17 05:51:53,719 - INFO - test: {'epoch': 41, 'time_epoch': 4.3529, 'loss': 0.11730413, 'lr': 0, 'params': 451793, 'time_iter': 0.03374, 'accuracy': 0.96985, 'precision': 0.55172, 'recall': 0.24615, 'f1': 0.34043, 'auc': 0.75443}
2025-08-17 05:51:53,722 - INFO - > Epoch 41: took 76.8s (avg 79.5s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:53:02,875 - INFO - train: {'epoch': 42, 'time_epoch': 69.06428, 'eta': 4023.68198, 'eta_hours': 1.11769, 'loss': 0.11149546, 'lr': 6.701e-05, 'params': 451793, 'time_iter': 0.06712, 'accuracy': 0.96818, 'precision': 0.68612, 'recall': 0.27679, 'f1': 0.39445, 'auc': 0.84426}
2025-08-17 05:53:07,221 - INFO - val: {'epoch': 42, 'time_epoch': 4.32031, 'loss': 0.0758857, 'lr': 0, 'params': 451793, 'time_iter': 0.03349, 'accuracy': 0.98225, 'precision': 0.61111, 'recall': 0.2716, 'f1': 0.37607, 'auc': 0.76301}
2025-08-17 05:53:11,579 - INFO - test: {'epoch': 42, 'time_epoch': 4.33925, 'loss': 0.11790895, 'lr': 0, 'params': 451793, 'time_iter': 0.03364, 'accuracy': 0.96985, 'precision': 0.55769, 'recall': 0.22308, 'f1': 0.31868, 'auc': 0.76083}
2025-08-17 05:53:11,583 - INFO - > Epoch 42: took 77.9s (avg 79.5s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:54:20,053 - INFO - train: {'epoch': 43, 'time_epoch': 68.3829, 'eta': 3950.28088, 'eta_hours': 1.0973, 'loss': 0.11185102, 'lr': 6.545e-05, 'params': 451793, 'time_iter': 0.06646, 'accuracy': 0.96815, 'precision': 0.68254, 'recall': 0.27922, 'f1': 0.39631, 'auc': 0.84268}
2025-08-17 05:54:24,422 - INFO - val: {'epoch': 43, 'time_epoch': 4.34611, 'loss': 0.07650622, 'lr': 0, 'params': 451793, 'time_iter': 0.03369, 'accuracy': 0.98152, 'precision': 0.5641, 'recall': 0.2716, 'f1': 0.36667, 'auc': 0.74257}
2025-08-17 05:54:28,791 - INFO - test: {'epoch': 43, 'time_epoch': 4.35162, 'loss': 0.11828458, 'lr': 0, 'params': 451793, 'time_iter': 0.03373, 'accuracy': 0.96888, 'precision': 0.51667, 'recall': 0.23846, 'f1': 0.32632, 'auc': 0.76933}
2025-08-17 05:54:28,793 - INFO - > Epoch 43: took 77.2s (avg 79.4s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:55:37,409 - INFO - train: {'epoch': 44, 'time_epoch': 68.52408, 'eta': 3877.27536, 'eta_hours': 1.07702, 'loss': 0.11181555, 'lr': 6.387e-05, 'params': 451793, 'time_iter': 0.06659, 'accuracy': 0.96796, 'precision': 0.67181, 'recall': 0.28247, 'f1': 0.39771, 'auc': 0.84544}
2025-08-17 05:55:41,768 - INFO - val: {'epoch': 44, 'time_epoch': 4.33731, 'loss': 0.07683973, 'lr': 0, 'params': 451793, 'time_iter': 0.03362, 'accuracy': 0.98371, 'precision': 0.69444, 'recall': 0.30864, 'f1': 0.42735, 'auc': 0.73565}
2025-08-17 05:55:46,142 - INFO - test: {'epoch': 44, 'time_epoch': 4.35491, 'loss': 0.1230628, 'lr': 0, 'params': 451793, 'time_iter': 0.03376, 'accuracy': 0.96766, 'precision': 0.46809, 'recall': 0.16923, 'f1': 0.24859, 'auc': 0.756}
2025-08-17 05:55:46,144 - INFO - > Epoch 44: took 77.3s (avg 79.4s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:56:54,815 - INFO - train: {'epoch': 45, 'time_epoch': 68.58547, 'eta': 3804.53675, 'eta_hours': 1.05682, 'loss': 0.11021041, 'lr': 6.227e-05, 'params': 451793, 'time_iter': 0.06665, 'accuracy': 0.96863, 'precision': 0.69841, 'recall': 0.28571, 'f1': 0.40553, 'auc': 0.84753}
2025-08-17 05:56:59,198 - INFO - val: {'epoch': 45, 'time_epoch': 4.35834, 'loss': 0.07345863, 'lr': 0, 'params': 451793, 'time_iter': 0.03379, 'accuracy': 0.98274, 'precision': 0.63158, 'recall': 0.2963, 'f1': 0.40336, 'auc': 0.77884}
2025-08-17 05:57:03,536 - INFO - test: {'epoch': 45, 'time_epoch': 4.31813, 'loss': 0.11618721, 'lr': 0, 'params': 451793, 'time_iter': 0.03347, 'accuracy': 0.96937, 'precision': 0.52564, 'recall': 0.31538, 'f1': 0.39423, 'auc': 0.77147}
2025-08-17 05:57:03,539 - INFO - > Epoch 45: took 77.4s (avg 79.3s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:58:11,819 - INFO - train: {'epoch': 46, 'time_epoch': 68.19454, 'eta': 3731.53403, 'eta_hours': 1.03654, 'loss': 0.11037272, 'lr': 6.066e-05, 'params': 451793, 'time_iter': 0.06627, 'accuracy': 0.96863, 'precision': 0.68248, 'recall': 0.30357, 'f1': 0.42022, 'auc': 0.84879}
2025-08-17 05:58:16,139 - INFO - val: {'epoch': 46, 'time_epoch': 4.29812, 'loss': 0.08086789, 'lr': 0, 'params': 451793, 'time_iter': 0.03332, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.41975, 'f1': 0.45638, 'auc': 0.74597}
2025-08-17 05:58:20,457 - INFO - test: {'epoch': 46, 'time_epoch': 4.30089, 'loss': 0.12084553, 'lr': 0, 'params': 451793, 'time_iter': 0.03334, 'accuracy': 0.96669, 'precision': 0.46067, 'recall': 0.31538, 'f1': 0.37443, 'auc': 0.77348}
2025-08-17 05:58:20,459 - INFO - > Epoch 46: took 76.9s (avg 79.3s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 05:59:28,809 - INFO - train: {'epoch': 47, 'time_epoch': 68.26201, 'eta': 3658.80474, 'eta_hours': 1.01633, 'loss': 0.11058125, 'lr': 5.904e-05, 'params': 451793, 'time_iter': 0.06634, 'accuracy': 0.96818, 'precision': 0.67486, 'recall': 0.28977, 'f1': 0.40545, 'auc': 0.85052}
2025-08-17 05:59:33,126 - INFO - val: {'epoch': 47, 'time_epoch': 4.29198, 'loss': 0.07386476, 'lr': 0, 'params': 451793, 'time_iter': 0.03327, 'accuracy': 0.98298, 'precision': 0.61702, 'recall': 0.35802, 'f1': 0.45312, 'auc': 0.78423}
2025-08-17 05:59:37,443 - INFO - test: {'epoch': 47, 'time_epoch': 4.29834, 'loss': 0.11447497, 'lr': 0, 'params': 451793, 'time_iter': 0.03332, 'accuracy': 0.97009, 'precision': 0.55385, 'recall': 0.27692, 'f1': 0.36923, 'auc': 0.77546}
2025-08-17 05:59:37,446 - INFO - > Epoch 47: took 77.0s (avg 79.2s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:00:46,145 - INFO - train: {'epoch': 48, 'time_epoch': 68.60927, 'eta': 3586.61923, 'eta_hours': 0.99628, 'loss': 0.10951539, 'lr': 5.741e-05, 'params': 451793, 'time_iter': 0.06668, 'accuracy': 0.96875, 'precision': 0.69392, 'recall': 0.29627, 'f1': 0.41524, 'auc': 0.85246}
2025-08-17 06:00:50,398 - INFO - val: {'epoch': 48, 'time_epoch': 4.22823, 'loss': 0.0759619, 'lr': 0, 'params': 451793, 'time_iter': 0.03278, 'accuracy': 0.98371, 'precision': 0.64, 'recall': 0.39506, 'f1': 0.48855, 'auc': 0.78273}
2025-08-17 06:00:54,684 - INFO - test: {'epoch': 48, 'time_epoch': 4.26645, 'loss': 0.12038319, 'lr': 0, 'params': 451793, 'time_iter': 0.03307, 'accuracy': 0.96864, 'precision': 0.50769, 'recall': 0.25385, 'f1': 0.33846, 'auc': 0.77247}
2025-08-17 06:00:54,688 - INFO - > Epoch 48: took 77.2s (avg 79.2s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:02:02,963 - INFO - train: {'epoch': 49, 'time_epoch': 68.18915, 'eta': 3514.15665, 'eta_hours': 0.97615, 'loss': 0.10956684, 'lr': 5.577e-05, 'params': 451793, 'time_iter': 0.06627, 'accuracy': 0.96833, 'precision': 0.68411, 'recall': 0.28653, 'f1': 0.40389, 'auc': 0.85557}
2025-08-17 06:02:07,243 - INFO - val: {'epoch': 49, 'time_epoch': 4.25615, 'loss': 0.07442914, 'lr': 0, 'params': 451793, 'time_iter': 0.03299, 'accuracy': 0.98322, 'precision': 0.625, 'recall': 0.37037, 'f1': 0.46512, 'auc': 0.78073}
2025-08-17 06:02:11,501 - INFO - test: {'epoch': 49, 'time_epoch': 4.24127, 'loss': 0.11794632, 'lr': 0, 'params': 451793, 'time_iter': 0.03288, 'accuracy': 0.96888, 'precision': 0.5125, 'recall': 0.31538, 'f1': 0.39048, 'auc': 0.77669}
2025-08-17 06:02:11,503 - INFO - > Epoch 49: took 76.8s (avg 79.2s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:03:19,688 - INFO - train: {'epoch': 50, 'time_epoch': 68.09599, 'eta': 3441.77215, 'eta_hours': 0.95605, 'loss': 0.10870914, 'lr': 5.413e-05, 'params': 451793, 'time_iter': 0.06618, 'accuracy': 0.96933, 'precision': 0.70384, 'recall': 0.3125, 'f1': 0.43283, 'auc': 0.85497}
2025-08-17 06:03:23,902 - INFO - val: {'epoch': 50, 'time_epoch': 4.18999, 'loss': 0.07501017, 'lr': 0, 'params': 451793, 'time_iter': 0.03248, 'accuracy': 0.98177, 'precision': 0.57895, 'recall': 0.2716, 'f1': 0.36975, 'auc': 0.77192}
2025-08-17 06:03:28,210 - INFO - test: {'epoch': 50, 'time_epoch': 4.28828, 'loss': 0.11739064, 'lr': 0, 'params': 451793, 'time_iter': 0.03324, 'accuracy': 0.96888, 'precision': 0.52, 'recall': 0.2, 'f1': 0.28889, 'auc': 0.77294}
2025-08-17 06:03:28,213 - INFO - > Epoch 50: took 76.7s (avg 79.1s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:04:36,898 - INFO - train: {'epoch': 51, 'time_epoch': 68.59959, 'eta': 3370.01745, 'eta_hours': 0.93612, 'loss': 0.10870614, 'lr': 5.248e-05, 'params': 451793, 'time_iter': 0.06667, 'accuracy': 0.96879, 'precision': 0.68271, 'recall': 0.31088, 'f1': 0.42722, 'auc': 0.8561}
2025-08-17 06:04:41,199 - INFO - val: {'epoch': 51, 'time_epoch': 4.27876, 'loss': 0.07147455, 'lr': 0, 'params': 451793, 'time_iter': 0.03317, 'accuracy': 0.98298, 'precision': 0.66667, 'recall': 0.2716, 'f1': 0.38596, 'auc': 0.79022}
2025-08-17 06:04:45,534 - INFO - test: {'epoch': 51, 'time_epoch': 4.31616, 'loss': 0.11480455, 'lr': 0, 'params': 451793, 'time_iter': 0.03346, 'accuracy': 0.97204, 'precision': 0.63158, 'recall': 0.27692, 'f1': 0.38503, 'auc': 0.77231}
2025-08-17 06:04:45,537 - INFO - > Epoch 51: took 77.3s (avg 79.1s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:05:53,524 - INFO - train: {'epoch': 52, 'time_epoch': 67.9038, 'eta': 3297.76478, 'eta_hours': 0.91605, 'loss': 0.10751189, 'lr': 5.083e-05, 'params': 451793, 'time_iter': 0.06599, 'accuracy': 0.96891, 'precision': 0.68966, 'recall': 0.30844, 'f1': 0.42625, 'auc': 0.85691}
2025-08-17 06:05:57,822 - INFO - val: {'epoch': 52, 'time_epoch': 4.27397, 'loss': 0.07215767, 'lr': 0, 'params': 451793, 'time_iter': 0.03313, 'accuracy': 0.98322, 'precision': 0.65, 'recall': 0.32099, 'f1': 0.42975, 'auc': 0.79462}
2025-08-17 06:06:02,104 - INFO - test: {'epoch': 52, 'time_epoch': 4.26309, 'loss': 0.1182816, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.96888, 'precision': 0.51515, 'recall': 0.26154, 'f1': 0.34694, 'auc': 0.78015}
2025-08-17 06:06:02,107 - INFO - > Epoch 52: took 76.6s (avg 79.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:07:10,401 - INFO - train: {'epoch': 53, 'time_epoch': 68.20712, 'eta': 3225.93157, 'eta_hours': 0.89609, 'loss': 0.10692241, 'lr': 4.917e-05, 'params': 451793, 'time_iter': 0.06628, 'accuracy': 0.96994, 'precision': 0.72212, 'recall': 0.32062, 'f1': 0.44407, 'auc': 0.8579}
2025-08-17 06:07:14,729 - INFO - val: {'epoch': 53, 'time_epoch': 4.30665, 'loss': 0.07395421, 'lr': 0, 'params': 451793, 'time_iter': 0.03338, 'accuracy': 0.98249, 'precision': 0.62857, 'recall': 0.2716, 'f1': 0.37931, 'auc': 0.79194}
2025-08-17 06:07:19,053 - INFO - test: {'epoch': 53, 'time_epoch': 4.3061, 'loss': 0.11811194, 'lr': 0, 'params': 451793, 'time_iter': 0.03338, 'accuracy': 0.97009, 'precision': 0.56364, 'recall': 0.23846, 'f1': 0.33514, 'auc': 0.76618}
2025-08-17 06:07:19,056 - INFO - > Epoch 53: took 76.9s (avg 79.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:08:27,248 - INFO - train: {'epoch': 54, 'time_epoch': 68.10456, 'eta': 3154.14631, 'eta_hours': 0.87615, 'loss': 0.10700213, 'lr': 4.752e-05, 'params': 451793, 'time_iter': 0.06619, 'accuracy': 0.96979, 'precision': 0.72453, 'recall': 0.31169, 'f1': 0.43587, 'auc': 0.85663}
2025-08-17 06:08:31,406 - INFO - val: {'epoch': 54, 'time_epoch': 4.13648, 'loss': 0.07708334, 'lr': 0, 'params': 451793, 'time_iter': 0.03207, 'accuracy': 0.98225, 'precision': 0.625, 'recall': 0.24691, 'f1': 0.35398, 'auc': 0.76053}
2025-08-17 06:08:35,672 - INFO - test: {'epoch': 54, 'time_epoch': 4.24742, 'loss': 0.11903499, 'lr': 0, 'params': 451793, 'time_iter': 0.03293, 'accuracy': 0.96888, 'precision': 0.51724, 'recall': 0.23077, 'f1': 0.31915, 'auc': 0.76066}
2025-08-17 06:08:35,674 - INFO - > Epoch 54: took 76.6s (avg 78.9s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:09:43,915 - INFO - train: {'epoch': 55, 'time_epoch': 68.14637, 'eta': 3082.52534, 'eta_hours': 0.85626, 'loss': 0.10619002, 'lr': 4.587e-05, 'params': 451793, 'time_iter': 0.06623, 'accuracy': 0.97037, 'precision': 0.73665, 'recall': 0.32468, 'f1': 0.4507, 'auc': 0.86348}
2025-08-17 06:09:48,239 - INFO - val: {'epoch': 55, 'time_epoch': 4.3013, 'loss': 0.07043554, 'lr': 0, 'params': 451793, 'time_iter': 0.03334, 'accuracy': 0.98298, 'precision': 0.67742, 'recall': 0.25926, 'f1': 0.375, 'auc': 0.8032}
2025-08-17 06:09:52,569 - INFO - test: {'epoch': 55, 'time_epoch': 4.31184, 'loss': 0.11885944, 'lr': 0, 'params': 451793, 'time_iter': 0.03343, 'accuracy': 0.96937, 'precision': 0.54545, 'recall': 0.18462, 'f1': 0.27586, 'auc': 0.75374}
2025-08-17 06:09:52,571 - INFO - > Epoch 55: took 76.9s (avg 78.9s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:11:00,663 - INFO - train: {'epoch': 56, 'time_epoch': 68.01293, 'eta': 3010.92563, 'eta_hours': 0.83637, 'loss': 0.10732268, 'lr': 4.423e-05, 'params': 451793, 'time_iter': 0.0661, 'accuracy': 0.96854, 'precision': 0.67012, 'recall': 0.31494, 'f1': 0.42849, 'auc': 0.86259}
2025-08-17 06:11:04,939 - INFO - val: {'epoch': 56, 'time_epoch': 4.2529, 'loss': 0.07201734, 'lr': 0, 'params': 451793, 'time_iter': 0.03297, 'accuracy': 0.98249, 'precision': 0.63636, 'recall': 0.25926, 'f1': 0.36842, 'auc': 0.79012}
2025-08-17 06:11:09,257 - INFO - test: {'epoch': 56, 'time_epoch': 4.29971, 'loss': 0.11709018, 'lr': 0, 'params': 451793, 'time_iter': 0.03333, 'accuracy': 0.97082, 'precision': 0.58929, 'recall': 0.25385, 'f1': 0.35484, 'auc': 0.76352}
2025-08-17 06:11:09,259 - INFO - > Epoch 56: took 76.7s (avg 78.9s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:12:18,173 - INFO - train: {'epoch': 57, 'time_epoch': 68.82497, 'eta': 2940.03763, 'eta_hours': 0.81668, 'loss': 0.10653045, 'lr': 4.259e-05, 'params': 451793, 'time_iter': 0.06689, 'accuracy': 0.96976, 'precision': 0.71048, 'recall': 0.32468, 'f1': 0.44568, 'auc': 0.85974}
2025-08-17 06:12:22,525 - INFO - val: {'epoch': 57, 'time_epoch': 4.32515, 'loss': 0.07233433, 'lr': 0, 'params': 451793, 'time_iter': 0.03353, 'accuracy': 0.98249, 'precision': 0.60465, 'recall': 0.32099, 'f1': 0.41935, 'auc': 0.79331}
2025-08-17 06:12:26,871 - INFO - test: {'epoch': 57, 'time_epoch': 4.32502, 'loss': 0.11671714, 'lr': 0, 'params': 451793, 'time_iter': 0.03353, 'accuracy': 0.97034, 'precision': 0.55405, 'recall': 0.31538, 'f1': 0.40196, 'auc': 0.7758}
2025-08-17 06:12:26,873 - INFO - > Epoch 57: took 77.6s (avg 78.9s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:13:34,417 - INFO - train: {'epoch': 58, 'time_epoch': 67.45996, 'eta': 2868.271, 'eta_hours': 0.79674, 'loss': 0.10516192, 'lr': 4.096e-05, 'params': 451793, 'time_iter': 0.06556, 'accuracy': 0.97037, 'precision': 0.7307, 'recall': 0.33036, 'f1': 0.455, 'auc': 0.86569}
2025-08-17 06:13:38,793 - INFO - val: {'epoch': 58, 'time_epoch': 4.35422, 'loss': 0.07096354, 'lr': 0, 'params': 451793, 'time_iter': 0.03375, 'accuracy': 0.98298, 'precision': 0.65714, 'recall': 0.28395, 'f1': 0.39655, 'auc': 0.78318}
2025-08-17 06:13:43,174 - INFO - test: {'epoch': 58, 'time_epoch': 4.36358, 'loss': 0.11790329, 'lr': 0, 'params': 451793, 'time_iter': 0.03383, 'accuracy': 0.96937, 'precision': 0.53704, 'recall': 0.22308, 'f1': 0.31522, 'auc': 0.75451}
2025-08-17 06:13:43,177 - INFO - > Epoch 58: took 76.3s (avg 78.8s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:14:51,411 - INFO - train: {'epoch': 59, 'time_epoch': 68.14923, 'eta': 2797.10744, 'eta_hours': 0.77697, 'loss': 0.10473341, 'lr': 3.934e-05, 'params': 451793, 'time_iter': 0.06623, 'accuracy': 0.96988, 'precision': 0.70957, 'recall': 0.33117, 'f1': 0.45158, 'auc': 0.86585}
2025-08-17 06:14:55,816 - INFO - val: {'epoch': 59, 'time_epoch': 4.3796, 'loss': 0.07093889, 'lr': 0, 'params': 451793, 'time_iter': 0.03395, 'accuracy': 0.98298, 'precision': 0.63415, 'recall': 0.32099, 'f1': 0.42623, 'auc': 0.78905}
2025-08-17 06:15:00,207 - INFO - test: {'epoch': 59, 'time_epoch': 4.37141, 'loss': 0.11884384, 'lr': 0, 'params': 451793, 'time_iter': 0.03389, 'accuracy': 0.96985, 'precision': 0.55, 'recall': 0.25385, 'f1': 0.34737, 'auc': 0.77421}
2025-08-17 06:15:00,209 - INFO - > Epoch 59: took 77.0s (avg 78.8s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:16:08,469 - INFO - train: {'epoch': 60, 'time_epoch': 68.17683, 'eta': 2726.06035, 'eta_hours': 0.75724, 'loss': 0.10462385, 'lr': 3.773e-05, 'params': 451793, 'time_iter': 0.06626, 'accuracy': 0.97049, 'precision': 0.72308, 'recall': 0.34334, 'f1': 0.4656, 'auc': 0.86598}
2025-08-17 06:16:12,635 - INFO - val: {'epoch': 60, 'time_epoch': 4.14437, 'loss': 0.07323939, 'lr': 0, 'params': 451793, 'time_iter': 0.03213, 'accuracy': 0.98322, 'precision': 0.66667, 'recall': 0.2963, 'f1': 0.41026, 'auc': 0.78127}
2025-08-17 06:16:16,850 - INFO - test: {'epoch': 60, 'time_epoch': 4.19732, 'loss': 0.1197065, 'lr': 0, 'params': 451793, 'time_iter': 0.03254, 'accuracy': 0.96888, 'precision': 0.51852, 'recall': 0.21538, 'f1': 0.30435, 'auc': 0.76959}
2025-08-17 06:16:16,852 - INFO - > Epoch 60: took 76.6s (avg 78.7s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:17:24,552 - INFO - train: {'epoch': 61, 'time_epoch': 67.61513, 'eta': 2654.76159, 'eta_hours': 0.73743, 'loss': 0.10322781, 'lr': 3.613e-05, 'params': 451793, 'time_iter': 0.06571, 'accuracy': 0.97073, 'precision': 0.72605, 'recall': 0.35065, 'f1': 0.47291, 'auc': 0.86819}
2025-08-17 06:17:28,931 - INFO - val: {'epoch': 61, 'time_epoch': 4.35652, 'loss': 0.07123509, 'lr': 0, 'params': 451793, 'time_iter': 0.03377, 'accuracy': 0.98371, 'precision': 0.70588, 'recall': 0.2963, 'f1': 0.41739, 'auc': 0.79387}
2025-08-17 06:17:33,277 - INFO - test: {'epoch': 61, 'time_epoch': 4.32803, 'loss': 0.11911253, 'lr': 0, 'params': 451793, 'time_iter': 0.03355, 'accuracy': 0.96888, 'precision': 0.52273, 'recall': 0.17692, 'f1': 0.26437, 'auc': 0.76684}
2025-08-17 06:17:33,279 - INFO - > Epoch 61: took 76.4s (avg 78.7s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:18:41,708 - INFO - train: {'epoch': 62, 'time_epoch': 68.33896, 'eta': 2584.00487, 'eta_hours': 0.71778, 'loss': 0.10466577, 'lr': 3.455e-05, 'params': 451793, 'time_iter': 0.06641, 'accuracy': 0.96945, 'precision': 0.69535, 'recall': 0.32792, 'f1': 0.44567, 'auc': 0.87034}
2025-08-17 06:18:45,999 - INFO - val: {'epoch': 62, 'time_epoch': 4.26663, 'loss': 0.07281023, 'lr': 0, 'params': 451793, 'time_iter': 0.03307, 'accuracy': 0.98177, 'precision': 0.5625, 'recall': 0.33333, 'f1': 0.4186, 'auc': 0.79147}
2025-08-17 06:18:50,288 - INFO - test: {'epoch': 62, 'time_epoch': 4.27024, 'loss': 0.11950407, 'lr': 0, 'params': 451793, 'time_iter': 0.0331, 'accuracy': 0.96937, 'precision': 0.5303, 'recall': 0.26923, 'f1': 0.35714, 'auc': 0.76919}
2025-08-17 06:18:50,291 - INFO - > Epoch 62: took 77.0s (avg 78.7s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:19:58,534 - INFO - train: {'epoch': 63, 'time_epoch': 68.15615, 'eta': 2513.22088, 'eta_hours': 0.69812, 'loss': 0.10399361, 'lr': 3.299e-05, 'params': 451793, 'time_iter': 0.06624, 'accuracy': 0.97003, 'precision': 0.70432, 'recall': 0.34416, 'f1': 0.46238, 'auc': 0.87297}
2025-08-17 06:20:02,797 - INFO - val: {'epoch': 63, 'time_epoch': 4.23872, 'loss': 0.07279539, 'lr': 0, 'params': 451793, 'time_iter': 0.03286, 'accuracy': 0.98347, 'precision': 0.67568, 'recall': 0.30864, 'f1': 0.42373, 'auc': 0.79047}
2025-08-17 06:20:07,071 - INFO - test: {'epoch': 63, 'time_epoch': 4.25521, 'loss': 0.11968445, 'lr': 0, 'params': 451793, 'time_iter': 0.03299, 'accuracy': 0.96888, 'precision': 0.51389, 'recall': 0.28462, 'f1': 0.36634, 'auc': 0.76017}
2025-08-17 06:20:07,073 - INFO - > Epoch 63: took 76.8s (avg 78.6s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:21:15,607 - INFO - train: {'epoch': 64, 'time_epoch': 68.44847, 'eta': 2442.67515, 'eta_hours': 0.67852, 'loss': 0.10380191, 'lr': 3.144e-05, 'params': 451793, 'time_iter': 0.06652, 'accuracy': 0.97058, 'precision': 0.72526, 'recall': 0.34497, 'f1': 0.46755, 'auc': 0.86879}
2025-08-17 06:21:19,879 - INFO - val: {'epoch': 64, 'time_epoch': 4.25002, 'loss': 0.07149207, 'lr': 0, 'params': 451793, 'time_iter': 0.03295, 'accuracy': 0.98322, 'precision': 0.64286, 'recall': 0.33333, 'f1': 0.43902, 'auc': 0.79774}
2025-08-17 06:21:24,117 - INFO - test: {'epoch': 64, 'time_epoch': 4.2215, 'loss': 0.11944915, 'lr': 0, 'params': 451793, 'time_iter': 0.03272, 'accuracy': 0.96961, 'precision': 0.53623, 'recall': 0.28462, 'f1': 0.37186, 'auc': 0.77236}
2025-08-17 06:21:24,120 - INFO - > Epoch 64: took 77.0s (avg 78.6s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:22:31,294 - INFO - train: {'epoch': 65, 'time_epoch': 67.0909, 'eta': 2371.49361, 'eta_hours': 0.65875, 'loss': 0.10294321, 'lr': 2.992e-05, 'params': 451793, 'time_iter': 0.0652, 'accuracy': 0.97064, 'precision': 0.7309, 'recall': 0.34172, 'f1': 0.46571, 'auc': 0.87178}
2025-08-17 06:22:35,565 - INFO - val: {'epoch': 65, 'time_epoch': 4.24881, 'loss': 0.07187206, 'lr': 0, 'params': 451793, 'time_iter': 0.03294, 'accuracy': 0.98249, 'precision': 0.6, 'recall': 0.33333, 'f1': 0.42857, 'auc': 0.79755}
2025-08-17 06:22:39,826 - INFO - test: {'epoch': 65, 'time_epoch': 4.24485, 'loss': 0.12231157, 'lr': 0, 'params': 451793, 'time_iter': 0.03291, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.30769, 'f1': 0.38095, 'auc': 0.77397}
2025-08-17 06:22:39,829 - INFO - > Epoch 65: took 75.7s (avg 78.6s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:23:47,822 - INFO - train: {'epoch': 66, 'time_epoch': 67.9114, 'eta': 2300.83831, 'eta_hours': 0.63912, 'loss': 0.10173226, 'lr': 2.841e-05, 'params': 451793, 'time_iter': 0.066, 'accuracy': 0.97185, 'precision': 0.75758, 'recall': 0.36526, 'f1': 0.49288, 'auc': 0.87167}
2025-08-17 06:23:52,024 - INFO - val: {'epoch': 66, 'time_epoch': 4.18142, 'loss': 0.07286232, 'lr': 0, 'params': 451793, 'time_iter': 0.03241, 'accuracy': 0.98201, 'precision': 0.5814, 'recall': 0.30864, 'f1': 0.40323, 'auc': 0.79687}
2025-08-17 06:23:56,255 - INFO - test: {'epoch': 66, 'time_epoch': 4.21418, 'loss': 0.12361785, 'lr': 0, 'params': 451793, 'time_iter': 0.03267, 'accuracy': 0.96693, 'precision': 0.45714, 'recall': 0.24615, 'f1': 0.32, 'auc': 0.77583}
2025-08-17 06:23:56,257 - INFO - > Epoch 66: took 76.4s (avg 78.5s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:25:04,783 - INFO - train: {'epoch': 67, 'time_epoch': 68.43971, 'eta': 2230.51233, 'eta_hours': 0.61959, 'loss': 0.10327777, 'lr': 2.693e-05, 'params': 451793, 'time_iter': 0.06651, 'accuracy': 0.97021, 'precision': 0.71799, 'recall': 0.33685, 'f1': 0.45856, 'auc': 0.87418}
2025-08-17 06:25:08,934 - INFO - val: {'epoch': 67, 'time_epoch': 4.12787, 'loss': 0.06969344, 'lr': 0, 'params': 451793, 'time_iter': 0.032, 'accuracy': 0.98347, 'precision': 0.70968, 'recall': 0.2716, 'f1': 0.39286, 'auc': 0.79385}
2025-08-17 06:25:12,998 - INFO - test: {'epoch': 67, 'time_epoch': 4.04619, 'loss': 0.11904928, 'lr': 0, 'params': 451793, 'time_iter': 0.03137, 'accuracy': 0.97034, 'precision': 0.59091, 'recall': 0.2, 'f1': 0.29885, 'auc': 0.76992}
2025-08-17 06:25:13,001 - INFO - > Epoch 67: took 76.7s (avg 78.5s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:26:20,742 - INFO - train: {'epoch': 68, 'time_epoch': 67.65167, 'eta': 2159.88698, 'eta_hours': 0.59997, 'loss': 0.10268788, 'lr': 2.548e-05, 'params': 451793, 'time_iter': 0.06575, 'accuracy': 0.9707, 'precision': 0.73103, 'recall': 0.34416, 'f1': 0.46799, 'auc': 0.87336}
2025-08-17 06:26:24,930 - INFO - val: {'epoch': 68, 'time_epoch': 4.16421, 'loss': 0.07058314, 'lr': 0, 'params': 451793, 'time_iter': 0.03228, 'accuracy': 0.98347, 'precision': 0.68571, 'recall': 0.2963, 'f1': 0.41379, 'auc': 0.79506}
2025-08-17 06:26:29,071 - INFO - test: {'epoch': 68, 'time_epoch': 4.12379, 'loss': 0.12357185, 'lr': 0, 'params': 451793, 'time_iter': 0.03197, 'accuracy': 0.96937, 'precision': 0.54167, 'recall': 0.2, 'f1': 0.29213, 'auc': 0.75856}
2025-08-17 06:26:29,074 - INFO - > Epoch 68: took 76.1s (avg 78.5s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:27:36,048 - INFO - train: {'epoch': 69, 'time_epoch': 66.88576, 'eta': 2089.01834, 'eta_hours': 0.58028, 'loss': 0.10158994, 'lr': 2.405e-05, 'params': 451793, 'time_iter': 0.065, 'accuracy': 0.97143, 'precision': 0.75524, 'recall': 0.35065, 'f1': 0.47894, 'auc': 0.87512}
2025-08-17 06:27:40,352 - INFO - val: {'epoch': 69, 'time_epoch': 4.28018, 'loss': 0.07185462, 'lr': 0, 'params': 451793, 'time_iter': 0.03318, 'accuracy': 0.98347, 'precision': 0.65854, 'recall': 0.33333, 'f1': 0.44262, 'auc': 0.7946}
2025-08-17 06:27:44,619 - INFO - test: {'epoch': 69, 'time_epoch': 4.24916, 'loss': 0.12169157, 'lr': 0, 'params': 451793, 'time_iter': 0.03294, 'accuracy': 0.96888, 'precision': 0.51471, 'recall': 0.26923, 'f1': 0.35354, 'auc': 0.76622}
2025-08-17 06:27:44,622 - INFO - > Epoch 69: took 75.5s (avg 78.4s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:28:52,741 - INFO - train: {'epoch': 70, 'time_epoch': 68.03525, 'eta': 2018.73141, 'eta_hours': 0.56076, 'loss': 0.10165602, 'lr': 2.265e-05, 'params': 451793, 'time_iter': 0.06612, 'accuracy': 0.97122, 'precision': 0.73554, 'recall': 0.3612, 'f1': 0.48449, 'auc': 0.87812}
2025-08-17 06:28:57,057 - INFO - val: {'epoch': 70, 'time_epoch': 4.29383, 'loss': 0.07197644, 'lr': 0, 'params': 451793, 'time_iter': 0.03329, 'accuracy': 0.98347, 'precision': 0.67568, 'recall': 0.30864, 'f1': 0.42373, 'auc': 0.79381}
2025-08-17 06:29:01,381 - INFO - test: {'epoch': 70, 'time_epoch': 4.30646, 'loss': 0.1210511, 'lr': 0, 'params': 451793, 'time_iter': 0.03338, 'accuracy': 0.97131, 'precision': 0.625, 'recall': 0.23077, 'f1': 0.33708, 'auc': 0.7672}
2025-08-17 06:29:01,384 - INFO - > Epoch 70: took 76.8s (avg 78.4s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:30:07,887 - INFO - train: {'epoch': 71, 'time_epoch': 66.41904, 'eta': 1947.8785, 'eta_hours': 0.54108, 'loss': 0.1015875, 'lr': 2.128e-05, 'params': 451793, 'time_iter': 0.06455, 'accuracy': 0.9711, 'precision': 0.73378, 'recall': 0.35795, 'f1': 0.48118, 'auc': 0.8765}
2025-08-17 06:30:12,208 - INFO - val: {'epoch': 71, 'time_epoch': 4.29851, 'loss': 0.07327177, 'lr': 0, 'params': 451793, 'time_iter': 0.03332, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.78535}
2025-08-17 06:30:16,475 - INFO - test: {'epoch': 71, 'time_epoch': 4.24749, 'loss': 0.12067974, 'lr': 0, 'params': 451793, 'time_iter': 0.03293, 'accuracy': 0.96912, 'precision': 0.52174, 'recall': 0.27692, 'f1': 0.36181, 'auc': 0.76756}
2025-08-17 06:30:16,477 - INFO - > Epoch 71: took 75.1s (avg 78.4s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:31:23,555 - INFO - train: {'epoch': 72, 'time_epoch': 66.99077, 'eta': 1877.35852, 'eta_hours': 0.52149, 'loss': 0.10120851, 'lr': 1.995e-05, 'params': 451793, 'time_iter': 0.0651, 'accuracy': 0.97137, 'precision': 0.74914, 'recall': 0.3539, 'f1': 0.48071, 'auc': 0.8756}
2025-08-17 06:31:27,809 - INFO - val: {'epoch': 72, 'time_epoch': 4.23077, 'loss': 0.07038086, 'lr': 0, 'params': 451793, 'time_iter': 0.0328, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.7927}
2025-08-17 06:31:32,031 - INFO - test: {'epoch': 72, 'time_epoch': 4.20363, 'loss': 0.12066975, 'lr': 0, 'params': 451793, 'time_iter': 0.03259, 'accuracy': 0.96937, 'precision': 0.54348, 'recall': 0.19231, 'f1': 0.28409, 'auc': 0.76812}
2025-08-17 06:31:32,035 - INFO - > Epoch 72: took 75.6s (avg 78.3s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:32:39,163 - INFO - train: {'epoch': 73, 'time_epoch': 67.05139, 'eta': 1806.95523, 'eta_hours': 0.50193, 'loss': 0.1012271, 'lr': 1.864e-05, 'params': 451793, 'time_iter': 0.06516, 'accuracy': 0.97094, 'precision': 0.7363, 'recall': 0.34903, 'f1': 0.47357, 'auc': 0.87549}
2025-08-17 06:32:43,279 - INFO - val: {'epoch': 73, 'time_epoch': 4.09461, 'loss': 0.07179235, 'lr': 0, 'params': 451793, 'time_iter': 0.03174, 'accuracy': 0.98298, 'precision': 0.65714, 'recall': 0.28395, 'f1': 0.39655, 'auc': 0.78676}
2025-08-17 06:32:47,450 - INFO - test: {'epoch': 73, 'time_epoch': 4.15273, 'loss': 0.12272123, 'lr': 0, 'params': 451793, 'time_iter': 0.03219, 'accuracy': 0.96864, 'precision': 0.50769, 'recall': 0.25385, 'f1': 0.33846, 'auc': 0.76839}
2025-08-17 06:32:47,453 - INFO - > Epoch 73: took 75.4s (avg 78.3s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:33:53,779 - INFO - train: {'epoch': 74, 'time_epoch': 66.24569, 'eta': 1736.37276, 'eta_hours': 0.48233, 'loss': 0.10123653, 'lr': 1.737e-05, 'params': 451793, 'time_iter': 0.06438, 'accuracy': 0.97061, 'precision': 0.72194, 'recall': 0.34984, 'f1': 0.4713, 'auc': 0.87729}
2025-08-17 06:33:58,090 - INFO - val: {'epoch': 74, 'time_epoch': 4.2891, 'loss': 0.07254628, 'lr': 0, 'params': 451793, 'time_iter': 0.03325, 'accuracy': 0.98298, 'precision': 0.67742, 'recall': 0.25926, 'f1': 0.375, 'auc': 0.78752}
2025-08-17 06:34:02,427 - INFO - test: {'epoch': 74, 'time_epoch': 4.31989, 'loss': 0.12207876, 'lr': 0, 'params': 451793, 'time_iter': 0.03349, 'accuracy': 0.96912, 'precision': 0.52727, 'recall': 0.22308, 'f1': 0.31351, 'auc': 0.75447}
2025-08-17 06:34:02,429 - INFO - > Epoch 74: took 75.0s (avg 78.3s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:35:10,242 - INFO - train: {'epoch': 75, 'time_epoch': 67.73148, 'eta': 1666.37361, 'eta_hours': 0.46288, 'loss': 0.10145767, 'lr': 1.614e-05, 'params': 451793, 'time_iter': 0.06582, 'accuracy': 0.97088, 'precision': 0.72833, 'recall': 0.35471, 'f1': 0.47707, 'auc': 0.87699}
2025-08-17 06:35:14,283 - INFO - val: {'epoch': 75, 'time_epoch': 4.02146, 'loss': 0.07213161, 'lr': 0, 'params': 451793, 'time_iter': 0.03117, 'accuracy': 0.98322, 'precision': 0.67647, 'recall': 0.28395, 'f1': 0.4, 'auc': 0.78685}
2025-08-17 06:35:18,338 - INFO - test: {'epoch': 75, 'time_epoch': 4.03908, 'loss': 0.12228391, 'lr': 0, 'params': 451793, 'time_iter': 0.03131, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.21538, 'f1': 0.30108, 'auc': 0.76176}
2025-08-17 06:35:18,341 - INFO - > Epoch 75: took 75.9s (avg 78.2s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:36:24,727 - INFO - train: {'epoch': 76, 'time_epoch': 66.30047, 'eta': 1596.00591, 'eta_hours': 0.44333, 'loss': 0.0990176, 'lr': 1.494e-05, 'params': 451793, 'time_iter': 0.06443, 'accuracy': 0.97155, 'precision': 0.74262, 'recall': 0.36769, 'f1': 0.49186, 'auc': 0.8844}
2025-08-17 06:36:29,015 - INFO - val: {'epoch': 76, 'time_epoch': 4.26781, 'loss': 0.07188885, 'lr': 0, 'params': 451793, 'time_iter': 0.03308, 'accuracy': 0.98298, 'precision': 0.66667, 'recall': 0.2716, 'f1': 0.38596, 'auc': 0.78778}
2025-08-17 06:36:33,300 - INFO - test: {'epoch': 76, 'time_epoch': 4.26801, 'loss': 0.12154003, 'lr': 0, 'params': 451793, 'time_iter': 0.03309, 'accuracy': 0.96888, 'precision': 0.52083, 'recall': 0.19231, 'f1': 0.2809, 'auc': 0.76391}
2025-08-17 06:36:33,302 - INFO - > Epoch 76: took 75.0s (avg 78.2s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:37:39,767 - INFO - train: {'epoch': 77, 'time_epoch': 66.37992, 'eta': 1525.76491, 'eta_hours': 0.42382, 'loss': 0.10014107, 'lr': 1.378e-05, 'params': 451793, 'time_iter': 0.06451, 'accuracy': 0.97152, 'precision': 0.74461, 'recall': 0.36445, 'f1': 0.48937, 'auc': 0.88271}
2025-08-17 06:37:44,023 - INFO - val: {'epoch': 77, 'time_epoch': 4.2349, 'loss': 0.07038659, 'lr': 0, 'params': 451793, 'time_iter': 0.03283, 'accuracy': 0.98322, 'precision': 0.7, 'recall': 0.25926, 'f1': 0.37838, 'auc': 0.79278}
2025-08-17 06:37:48,327 - INFO - test: {'epoch': 77, 'time_epoch': 4.28768, 'loss': 0.12066709, 'lr': 0, 'params': 451793, 'time_iter': 0.03324, 'accuracy': 0.97034, 'precision': 0.58696, 'recall': 0.20769, 'f1': 0.30682, 'auc': 0.76634}
2025-08-17 06:37:48,330 - INFO - > Epoch 77: took 75.0s (avg 78.1s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:38:56,759 - INFO - train: {'epoch': 78, 'time_epoch': 68.3521, 'eta': 1456.14591, 'eta_hours': 0.40448, 'loss': 0.09808065, 'lr': 1.266e-05, 'params': 451793, 'time_iter': 0.06643, 'accuracy': 0.97182, 'precision': 0.75041, 'recall': 0.37094, 'f1': 0.49647, 'auc': 0.88573}
2025-08-17 06:39:01,128 - INFO - val: {'epoch': 78, 'time_epoch': 4.34658, 'loss': 0.07161397, 'lr': 0, 'params': 451793, 'time_iter': 0.03369, 'accuracy': 0.98395, 'precision': 0.68293, 'recall': 0.34568, 'f1': 0.45902, 'auc': 0.7955}
2025-08-17 06:39:05,511 - INFO - test: {'epoch': 78, 'time_epoch': 4.36569, 'loss': 0.12192763, 'lr': 0, 'params': 451793, 'time_iter': 0.03384, 'accuracy': 0.96864, 'precision': 0.50725, 'recall': 0.26923, 'f1': 0.35176, 'auc': 0.76881}
2025-08-17 06:39:05,513 - INFO - > Epoch 78: took 77.2s (avg 78.1s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:40:14,169 - INFO - train: {'epoch': 79, 'time_epoch': 68.53741, 'eta': 1386.60491, 'eta_hours': 0.38517, 'loss': 0.10048549, 'lr': 1.158e-05, 'params': 451793, 'time_iter': 0.06661, 'accuracy': 0.97113, 'precision': 0.73344, 'recall': 0.35958, 'f1': 0.48257, 'auc': 0.87949}
2025-08-17 06:40:18,498 - INFO - val: {'epoch': 79, 'time_epoch': 4.30726, 'loss': 0.0730589, 'lr': 0, 'params': 451793, 'time_iter': 0.03339, 'accuracy': 0.98274, 'precision': 0.61905, 'recall': 0.32099, 'f1': 0.42276, 'auc': 0.79366}
2025-08-17 06:40:22,798 - INFO - test: {'epoch': 79, 'time_epoch': 4.28262, 'loss': 0.12422594, 'lr': 0, 'params': 451793, 'time_iter': 0.0332, 'accuracy': 0.96596, 'precision': 0.44444, 'recall': 0.30769, 'f1': 0.36364, 'auc': 0.77231}
2025-08-17 06:40:22,901 - INFO - > Epoch 79: took 77.4s (avg 78.1s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:41:29,880 - INFO - train: {'epoch': 80, 'time_epoch': 66.88966, 'eta': 1316.70218, 'eta_hours': 0.36575, 'loss': 0.10070381, 'lr': 1.054e-05, 'params': 451793, 'time_iter': 0.065, 'accuracy': 0.97173, 'precision': 0.75167, 'recall': 0.36607, 'f1': 0.49236, 'auc': 0.87673}
2025-08-17 06:41:34,215 - INFO - val: {'epoch': 80, 'time_epoch': 4.31378, 'loss': 0.07077597, 'lr': 0, 'params': 451793, 'time_iter': 0.03344, 'accuracy': 0.98322, 'precision': 0.6875, 'recall': 0.2716, 'f1': 0.38938, 'auc': 0.79308}
2025-08-17 06:41:38,550 - INFO - test: {'epoch': 80, 'time_epoch': 4.31744, 'loss': 0.12177516, 'lr': 0, 'params': 451793, 'time_iter': 0.03347, 'accuracy': 0.96912, 'precision': 0.52459, 'recall': 0.24615, 'f1': 0.33508, 'auc': 0.76846}
2025-08-17 06:41:38,553 - INFO - > Epoch 80: took 75.7s (avg 78.1s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:42:46,842 - INFO - train: {'epoch': 81, 'time_epoch': 68.20714, 'eta': 1247.16215, 'eta_hours': 0.34643, 'loss': 0.09824286, 'lr': 9.55e-06, 'params': 451793, 'time_iter': 0.06628, 'accuracy': 0.97201, 'precision': 0.75285, 'recall': 0.37581, 'f1': 0.50135, 'auc': 0.88897}
2025-08-17 06:42:51,049 - INFO - val: {'epoch': 81, 'time_epoch': 4.18625, 'loss': 0.07237149, 'lr': 0, 'params': 451793, 'time_iter': 0.03245, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.79277}
2025-08-17 06:42:55,246 - INFO - test: {'epoch': 81, 'time_epoch': 4.17954, 'loss': 0.12212376, 'lr': 0, 'params': 451793, 'time_iter': 0.0324, 'accuracy': 0.96693, 'precision': 0.46512, 'recall': 0.30769, 'f1': 0.37037, 'auc': 0.76983}
2025-08-17 06:42:55,248 - INFO - > Epoch 81: took 76.7s (avg 78.1s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:44:03,341 - INFO - train: {'epoch': 82, 'time_epoch': 68.00411, 'eta': 1177.61265, 'eta_hours': 0.32711, 'loss': 0.09927347, 'lr': 8.6e-06, 'params': 451793, 'time_iter': 0.06609, 'accuracy': 0.97146, 'precision': 0.7344, 'recall': 0.37256, 'f1': 0.49435, 'auc': 0.88466}
2025-08-17 06:44:07,480 - INFO - val: {'epoch': 82, 'time_epoch': 4.11442, 'loss': 0.07108215, 'lr': 0, 'params': 451793, 'time_iter': 0.03189, 'accuracy': 0.98298, 'precision': 0.67742, 'recall': 0.25926, 'f1': 0.375, 'auc': 0.79167}
2025-08-17 06:44:11,651 - INFO - test: {'epoch': 82, 'time_epoch': 4.15211, 'loss': 0.12108189, 'lr': 0, 'params': 451793, 'time_iter': 0.03219, 'accuracy': 0.97058, 'precision': 0.59574, 'recall': 0.21538, 'f1': 0.31638, 'auc': 0.76292}
2025-08-17 06:44:11,654 - INFO - > Epoch 82: took 76.4s (avg 78.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:45:20,499 - INFO - train: {'epoch': 83, 'time_epoch': 68.7603, 'eta': 1108.24397, 'eta_hours': 0.30785, 'loss': 0.09883338, 'lr': 7.7e-06, 'params': 451793, 'time_iter': 0.06682, 'accuracy': 0.9721, 'precision': 0.7557, 'recall': 0.37662, 'f1': 0.50271, 'auc': 0.88628}
2025-08-17 06:45:24,837 - INFO - val: {'epoch': 83, 'time_epoch': 4.31477, 'loss': 0.07088462, 'lr': 0, 'params': 451793, 'time_iter': 0.03345, 'accuracy': 0.98298, 'precision': 0.65714, 'recall': 0.28395, 'f1': 0.39655, 'auc': 0.79134}
2025-08-17 06:45:29,177 - INFO - test: {'epoch': 83, 'time_epoch': 4.32109, 'loss': 0.1214476, 'lr': 0, 'params': 451793, 'time_iter': 0.0335, 'accuracy': 0.96961, 'precision': 0.54098, 'recall': 0.25385, 'f1': 0.34555, 'auc': 0.76135}
2025-08-17 06:45:29,179 - INFO - > Epoch 83: took 77.5s (avg 78.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:46:37,234 - INFO - train: {'epoch': 84, 'time_epoch': 67.96747, 'eta': 1038.74971, 'eta_hours': 0.28854, 'loss': 0.09909537, 'lr': 6.84e-06, 'params': 451793, 'time_iter': 0.06605, 'accuracy': 0.97167, 'precision': 0.7451, 'recall': 0.37013, 'f1': 0.49458, 'auc': 0.88539}
2025-08-17 06:46:41,574 - INFO - val: {'epoch': 84, 'time_epoch': 4.31854, 'loss': 0.07151574, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.98322, 'precision': 0.65789, 'recall': 0.30864, 'f1': 0.42017, 'auc': 0.79134}
2025-08-17 06:46:45,905 - INFO - test: {'epoch': 84, 'time_epoch': 4.31334, 'loss': 0.12035447, 'lr': 0, 'params': 451793, 'time_iter': 0.03344, 'accuracy': 0.96888, 'precision': 0.51471, 'recall': 0.26923, 'f1': 0.35354, 'auc': 0.7721}
2025-08-17 06:46:45,907 - INFO - > Epoch 84: took 76.7s (avg 78.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:47:54,221 - INFO - train: {'epoch': 85, 'time_epoch': 68.224, 'eta': 969.33271, 'eta_hours': 0.26926, 'loss': 0.09923924, 'lr': 6.03e-06, 'params': 451793, 'time_iter': 0.0663, 'accuracy': 0.97219, 'precision': 0.75523, 'recall': 0.38068, 'f1': 0.50621, 'auc': 0.88556}
2025-08-17 06:47:58,568 - INFO - val: {'epoch': 85, 'time_epoch': 4.32552, 'loss': 0.07115829, 'lr': 0, 'params': 451793, 'time_iter': 0.03353, 'accuracy': 0.98347, 'precision': 0.69697, 'recall': 0.28395, 'f1': 0.40351, 'auc': 0.78818}
2025-08-17 06:48:02,900 - INFO - test: {'epoch': 85, 'time_epoch': 4.3142, 'loss': 0.11969258, 'lr': 0, 'params': 451793, 'time_iter': 0.03344, 'accuracy': 0.97009, 'precision': 0.55738, 'recall': 0.26154, 'f1': 0.35602, 'auc': 0.76898}
2025-08-17 06:48:02,902 - INFO - > Epoch 85: took 77.0s (avg 78.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:49:11,256 - INFO - train: {'epoch': 86, 'time_epoch': 68.27127, 'eta': 899.95019, 'eta_hours': 0.24999, 'loss': 0.09977085, 'lr': 5.26e-06, 'params': 451793, 'time_iter': 0.06635, 'accuracy': 0.97198, 'precision': 0.76541, 'recall': 0.36282, 'f1': 0.49229, 'auc': 0.88219}
2025-08-17 06:49:15,536 - INFO - val: {'epoch': 86, 'time_epoch': 4.25888, 'loss': 0.07180609, 'lr': 0, 'params': 451793, 'time_iter': 0.03301, 'accuracy': 0.98371, 'precision': 0.68421, 'recall': 0.32099, 'f1': 0.43697, 'auc': 0.78833}
2025-08-17 06:49:19,824 - INFO - test: {'epoch': 86, 'time_epoch': 4.271, 'loss': 0.12092955, 'lr': 0, 'params': 451793, 'time_iter': 0.03311, 'accuracy': 0.96864, 'precision': 0.50794, 'recall': 0.24615, 'f1': 0.33161, 'auc': 0.77249}
2025-08-17 06:49:19,827 - INFO - > Epoch 86: took 76.9s (avg 78.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:50:28,436 - INFO - train: {'epoch': 87, 'time_epoch': 68.53076, 'eta': 830.62832, 'eta_hours': 0.23073, 'loss': 0.09891218, 'lr': 4.55e-06, 'params': 451793, 'time_iter': 0.0666, 'accuracy': 0.97237, 'precision': 0.7609, 'recall': 0.38231, 'f1': 0.50891, 'auc': 0.88438}
2025-08-17 06:50:32,827 - INFO - val: {'epoch': 87, 'time_epoch': 4.3649, 'loss': 0.07073444, 'lr': 0, 'params': 451793, 'time_iter': 0.03384, 'accuracy': 0.98444, 'precision': 0.72973, 'recall': 0.33333, 'f1': 0.45763, 'auc': 0.78939}
2025-08-17 06:50:37,207 - INFO - test: {'epoch': 87, 'time_epoch': 4.36149, 'loss': 0.12098055, 'lr': 0, 'params': 451793, 'time_iter': 0.03381, 'accuracy': 0.96961, 'precision': 0.53731, 'recall': 0.27692, 'f1': 0.36548, 'auc': 0.77304}
2025-08-17 06:50:37,210 - INFO - > Epoch 87: took 77.4s (avg 78.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:51:45,408 - INFO - train: {'epoch': 88, 'time_epoch': 68.11398, 'eta': 761.27272, 'eta_hours': 0.21146, 'loss': 0.09802153, 'lr': 3.89e-06, 'params': 451793, 'time_iter': 0.06619, 'accuracy': 0.97161, 'precision': 0.74032, 'recall': 0.37256, 'f1': 0.49568, 'auc': 0.88902}
2025-08-17 06:51:49,676 - INFO - val: {'epoch': 88, 'time_epoch': 4.24577, 'loss': 0.07105566, 'lr': 0, 'params': 451793, 'time_iter': 0.03291, 'accuracy': 0.98371, 'precision': 0.675, 'recall': 0.33333, 'f1': 0.44628, 'auc': 0.7935}
2025-08-17 06:51:53,938 - INFO - test: {'epoch': 88, 'time_epoch': 4.24442, 'loss': 0.12209429, 'lr': 0, 'params': 451793, 'time_iter': 0.0329, 'accuracy': 0.96815, 'precision': 0.49315, 'recall': 0.27692, 'f1': 0.35468, 'auc': 0.76466}
2025-08-17 06:51:53,940 - INFO - > Epoch 88: took 76.7s (avg 78.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:53:02,131 - INFO - train: {'epoch': 89, 'time_epoch': 68.10177, 'eta': 691.94335, 'eta_hours': 0.19221, 'loss': 0.09851791, 'lr': 3.27e-06, 'params': 451793, 'time_iter': 0.06618, 'accuracy': 0.97119, 'precision': 0.72397, 'recall': 0.37256, 'f1': 0.49196, 'auc': 0.88827}
2025-08-17 06:53:06,424 - INFO - val: {'epoch': 89, 'time_epoch': 4.26788, 'loss': 0.07247909, 'lr': 0, 'params': 451793, 'time_iter': 0.03308, 'accuracy': 0.98274, 'precision': 0.63889, 'recall': 0.28395, 'f1': 0.39316, 'auc': 0.78685}
2025-08-17 06:53:10,806 - INFO - test: {'epoch': 89, 'time_epoch': 4.36244, 'loss': 0.1200273, 'lr': 0, 'params': 451793, 'time_iter': 0.03382, 'accuracy': 0.96742, 'precision': 0.47368, 'recall': 0.27692, 'f1': 0.34951, 'auc': 0.77141}
2025-08-17 06:53:10,808 - INFO - > Epoch 89: took 76.9s (avg 78.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:54:19,572 - INFO - train: {'epoch': 90, 'time_epoch': 68.65278, 'eta': 622.69545, 'eta_hours': 0.17297, 'loss': 0.09864704, 'lr': 2.71e-06, 'params': 451793, 'time_iter': 0.06672, 'accuracy': 0.9721, 'precision': 0.75822, 'recall': 0.37419, 'f1': 0.50109, 'auc': 0.88721}
2025-08-17 06:54:23,925 - INFO - val: {'epoch': 90, 'time_epoch': 4.32987, 'loss': 0.07159078, 'lr': 0, 'params': 451793, 'time_iter': 0.03356, 'accuracy': 0.98371, 'precision': 0.65909, 'recall': 0.35802, 'f1': 0.464, 'auc': 0.79271}
2025-08-17 06:54:28,252 - INFO - test: {'epoch': 90, 'time_epoch': 4.30972, 'loss': 0.12293829, 'lr': 0, 'params': 451793, 'time_iter': 0.03341, 'accuracy': 0.96791, 'precision': 0.48684, 'recall': 0.28462, 'f1': 0.35922, 'auc': 0.77217}
2025-08-17 06:54:28,255 - INFO - > Epoch 90: took 77.4s (avg 78.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:55:37,694 - INFO - train: {'epoch': 91, 'time_epoch': 69.34977, 'eta': 553.5211, 'eta_hours': 0.15376, 'loss': 0.09835288, 'lr': 2.2e-06, 'params': 451793, 'time_iter': 0.0674, 'accuracy': 0.97176, 'precision': 0.74318, 'recall': 0.37581, 'f1': 0.49919, 'auc': 0.8849}
2025-08-17 06:55:42,059 - INFO - val: {'epoch': 91, 'time_epoch': 4.33983, 'loss': 0.07113712, 'lr': 0, 'params': 451793, 'time_iter': 0.03364, 'accuracy': 0.98395, 'precision': 0.69231, 'recall': 0.33333, 'f1': 0.45, 'auc': 0.79004}
2025-08-17 06:55:46,407 - INFO - test: {'epoch': 91, 'time_epoch': 4.32786, 'loss': 0.12179671, 'lr': 0, 'params': 451793, 'time_iter': 0.03355, 'accuracy': 0.96864, 'precision': 0.50725, 'recall': 0.26923, 'f1': 0.35176, 'auc': 0.77285}
2025-08-17 06:55:46,409 - INFO - > Epoch 91: took 78.2s (avg 78.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:56:54,591 - INFO - train: {'epoch': 92, 'time_epoch': 68.0966, 'eta': 484.24866, 'eta_hours': 0.13451, 'loss': 0.09846835, 'lr': 1.74e-06, 'params': 451793, 'time_iter': 0.06618, 'accuracy': 0.97192, 'precision': 0.75246, 'recall': 0.37256, 'f1': 0.49837, 'auc': 0.88552}
2025-08-17 06:56:58,867 - INFO - val: {'epoch': 92, 'time_epoch': 4.2542, 'loss': 0.07202638, 'lr': 0, 'params': 451793, 'time_iter': 0.03298, 'accuracy': 0.98395, 'precision': 0.69231, 'recall': 0.33333, 'f1': 0.45, 'auc': 0.79063}
2025-08-17 06:57:03,122 - INFO - test: {'epoch': 92, 'time_epoch': 4.23598, 'loss': 0.12225451, 'lr': 0, 'params': 451793, 'time_iter': 0.03284, 'accuracy': 0.96791, 'precision': 0.48684, 'recall': 0.28462, 'f1': 0.35922, 'auc': 0.77012}
2025-08-17 06:57:03,124 - INFO - > Epoch 92: took 76.7s (avg 78.0s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:58:11,541 - INFO - train: {'epoch': 93, 'time_epoch': 68.3281, 'eta': 415.016, 'eta_hours': 0.11528, 'loss': 0.10019531, 'lr': 1.33e-06, 'params': 451793, 'time_iter': 0.0664, 'accuracy': 0.97082, 'precision': 0.71384, 'recall': 0.36851, 'f1': 0.48608, 'auc': 0.88225}
2025-08-17 06:58:15,923 - INFO - val: {'epoch': 93, 'time_epoch': 4.35756, 'loss': 0.07086273, 'lr': 0, 'params': 451793, 'time_iter': 0.03378, 'accuracy': 0.98249, 'precision': 0.63636, 'recall': 0.25926, 'f1': 0.36842, 'auc': 0.79413}
2025-08-17 06:58:20,266 - INFO - test: {'epoch': 93, 'time_epoch': 4.32479, 'loss': 0.12163207, 'lr': 0, 'params': 451793, 'time_iter': 0.03353, 'accuracy': 0.96961, 'precision': 0.54237, 'recall': 0.24615, 'f1': 0.33862, 'auc': 0.76304}
2025-08-17 06:58:20,269 - INFO - > Epoch 93: took 77.1s (avg 77.9s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 06:59:28,763 - INFO - train: {'epoch': 94, 'time_epoch': 68.40659, 'eta': 345.80652, 'eta_hours': 0.09606, 'loss': 0.09727843, 'lr': 9.8e-07, 'params': 451793, 'time_iter': 0.06648, 'accuracy': 0.97189, 'precision': 0.75541, 'recall': 0.36851, 'f1': 0.49536, 'auc': 0.89123}
2025-08-17 06:59:33,103 - INFO - val: {'epoch': 94, 'time_epoch': 4.31855, 'loss': 0.07322222, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.98347, 'precision': 0.65116, 'recall': 0.34568, 'f1': 0.45161, 'auc': 0.78998}
2025-08-17 06:59:37,447 - INFO - test: {'epoch': 94, 'time_epoch': 4.32659, 'loss': 0.12247394, 'lr': 0, 'params': 451793, 'time_iter': 0.03354, 'accuracy': 0.96718, 'precision': 0.46988, 'recall': 0.3, 'f1': 0.3662, 'auc': 0.77172}
2025-08-17 06:59:37,449 - INFO - > Epoch 94: took 77.2s (avg 77.9s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 07:00:46,435 - INFO - train: {'epoch': 95, 'time_epoch': 68.90312, 'eta': 276.63446, 'eta_hours': 0.07684, 'loss': 0.09858009, 'lr': 6.8e-07, 'params': 451793, 'time_iter': 0.06696, 'accuracy': 0.97192, 'precision': 0.75329, 'recall': 0.37175, 'f1': 0.49783, 'auc': 0.8876}
2025-08-17 07:00:50,457 - INFO - val: {'epoch': 95, 'time_epoch': 4.00137, 'loss': 0.07075531, 'lr': 0, 'params': 451793, 'time_iter': 0.03102, 'accuracy': 0.98274, 'precision': 0.64706, 'recall': 0.2716, 'f1': 0.38261, 'auc': 0.79084}
2025-08-17 07:00:54,699 - INFO - test: {'epoch': 95, 'time_epoch': 4.22396, 'loss': 0.12168731, 'lr': 0, 'params': 451793, 'time_iter': 0.03274, 'accuracy': 0.96937, 'precision': 0.5303, 'recall': 0.26923, 'f1': 0.35714, 'auc': 0.76893}
2025-08-17 07:00:54,701 - INFO - > Epoch 95: took 77.3s (avg 77.9s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 07:02:02,122 - INFO - train: {'epoch': 96, 'time_epoch': 67.33953, 'eta': 207.41959, 'eta_hours': 0.05762, 'loss': 0.09874003, 'lr': 4.4e-07, 'params': 451793, 'time_iter': 0.06544, 'accuracy': 0.97161, 'precision': 0.74916, 'recall': 0.36364, 'f1': 0.48962, 'auc': 0.88945}
2025-08-17 07:02:06,458 - INFO - val: {'epoch': 96, 'time_epoch': 4.31409, 'loss': 0.07215511, 'lr': 0, 'params': 451793, 'time_iter': 0.03344, 'accuracy': 0.98371, 'precision': 0.68421, 'recall': 0.32099, 'f1': 0.43697, 'auc': 0.7906}
2025-08-17 07:02:10,779 - INFO - test: {'epoch': 96, 'time_epoch': 4.30341, 'loss': 0.1221798, 'lr': 0, 'params': 451793, 'time_iter': 0.03336, 'accuracy': 0.96742, 'precision': 0.47368, 'recall': 0.27692, 'f1': 0.34951, 'auc': 0.77438}
2025-08-17 07:02:10,781 - INFO - > Epoch 96: took 76.1s (avg 77.9s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 07:03:19,518 - INFO - train: {'epoch': 97, 'time_epoch': 68.64929, 'eta': 138.26971, 'eta_hours': 0.03841, 'loss': 0.09816638, 'lr': 2.5e-07, 'params': 451793, 'time_iter': 0.06671, 'accuracy': 0.97237, 'precision': 0.7584, 'recall': 0.38474, 'f1': 0.5105, 'auc': 0.88778}
2025-08-17 07:03:23,861 - INFO - val: {'epoch': 97, 'time_epoch': 4.32126, 'loss': 0.07191323, 'lr': 0, 'params': 451793, 'time_iter': 0.0335, 'accuracy': 0.9842, 'precision': 0.7, 'recall': 0.34568, 'f1': 0.46281, 'auc': 0.79188}
2025-08-17 07:03:28,196 - INFO - test: {'epoch': 97, 'time_epoch': 4.31824, 'loss': 0.12204748, 'lr': 0, 'params': 451793, 'time_iter': 0.03347, 'accuracy': 0.96912, 'precision': 0.52174, 'recall': 0.27692, 'f1': 0.36181, 'auc': 0.76886}
2025-08-17 07:03:28,198 - INFO - > Epoch 97: took 77.4s (avg 77.9s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 07:04:36,235 - INFO - train: {'epoch': 98, 'time_epoch': 67.94783, 'eta': 69.12287, 'eta_hours': 0.0192, 'loss': 0.09759235, 'lr': 1.1e-07, 'params': 451793, 'time_iter': 0.06603, 'accuracy': 0.9721, 'precision': 0.7608, 'recall': 0.37175, 'f1': 0.49945, 'auc': 0.89146}
2025-08-17 07:04:40,576 - INFO - val: {'epoch': 98, 'time_epoch': 4.31891, 'loss': 0.07072293, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.9842, 'precision': 0.72222, 'recall': 0.32099, 'f1': 0.44444, 'auc': 0.7932}
2025-08-17 07:04:44,908 - INFO - test: {'epoch': 98, 'time_epoch': 4.31407, 'loss': 0.12235835, 'lr': 0, 'params': 451793, 'time_iter': 0.03344, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.23846, 'f1': 0.32292, 'auc': 0.76867}
2025-08-17 07:04:44,910 - INFO - > Epoch 98: took 76.7s (avg 77.9s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 07:05:55,499 - INFO - train: {'epoch': 99, 'time_epoch': 70.50195, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.09866926, 'lr': 3e-08, 'params': 451793, 'time_iter': 0.06852, 'accuracy': 0.97134, 'precision': 0.73964, 'recall': 0.36201, 'f1': 0.4861, 'auc': 0.88992}
2025-08-17 07:05:59,950 - INFO - val: {'epoch': 99, 'time_epoch': 4.42703, 'loss': 0.07130596, 'lr': 0, 'params': 451793, 'time_iter': 0.03432, 'accuracy': 0.98322, 'precision': 0.7, 'recall': 0.25926, 'f1': 0.37838, 'auc': 0.79048}
2025-08-17 07:06:04,449 - INFO - test: {'epoch': 99, 'time_epoch': 4.47963, 'loss': 0.12298613, 'lr': 0, 'params': 451793, 'time_iter': 0.03473, 'accuracy': 0.97009, 'precision': 0.56863, 'recall': 0.22308, 'f1': 0.32044, 'auc': 0.76305}
2025-08-17 07:06:04,702 - INFO - > Epoch 99: took 79.5s (avg 77.9s) | Best so far: epoch 28	train_loss: 0.1198 train_auc: 0.8198	val_loss: 0.0791 val_auc: 0.8050	test_loss: 0.1164 test_auc: 0.7642
2025-08-17 07:06:04,702 - INFO - Avg time per epoch: 77.91s
2025-08-17 07:06:04,702 - INFO - Total train loop time: 2.16h
2025-08-17 07:06:04,833 - INFO - ============================================================
2025-08-17 07:06:04,833 - INFO - Starting PK-Explainer Analysis (Enhanced Version)
2025-08-17 07:06:04,833 - INFO - ============================================================
2025-08-17 07:06:04,833 - INFO - Dataset: ogbg-molhiv
2025-08-17 07:06:04,833 - INFO - Model type: VanillaModel
2025-08-17 07:06:04,834 - INFO - GNN types available: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-17 07:06:05,308 - INFO - Saved model state to results/molhiv/molhiv-Vanilla-47/model_for_ablation.pt
2025-08-17 07:06:05,308 - INFO - 
Performing ablation study...
2025-08-17 07:06:05,365 - INFO - Getting baseline performance...
2025-08-17 07:06:05,404 - WARNING - Could not extract GNN mapping from optimal weights, attempting to infer from layers...
2025-08-17 07:06:05,404 - INFO - Final GNN mapping: {}
2025-08-17 07:06:09,949 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.52825, 'loss': 0.12298613, 'lr': 0, 'params': 451793, 'time_iter': 0.0351, 'accuracy': 0.97009, 'precision': 0.56863, 'recall': 0.22308, 'f1': 0.32044, 'auc': 0.76305}
2025-08-17 07:06:09,956 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:06:09,957 - INFO - Baseline auc: 0.7631
2025-08-17 07:06:14,536 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.52602, 'loss': 0.12242483, 'lr': 0, 'params': 451793, 'time_iter': 0.03509, 'accuracy': 0.96985, 'precision': 0.56, 'recall': 0.21538, 'f1': 0.31111, 'auc': 0.76633}
2025-08-17 07:06:14,541 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:06:14,542 - INFO - Layer 0 (Layer_0), Head 0: drop=-0.0043
2025-08-17 07:06:18,998 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40174, 'loss': 0.12304323, 'lr': 0, 'params': 451793, 'time_iter': 0.03412, 'accuracy': 0.96985, 'precision': 0.56522, 'recall': 0.2, 'f1': 0.29545, 'auc': 0.7643}
2025-08-17 07:06:18,999 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:06:19,000 - INFO - Layer 0 (Layer_0), Head 1: drop=-0.0016
2025-08-17 07:06:23,482 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43023, 'loss': 0.12252093, 'lr': 0, 'params': 451793, 'time_iter': 0.03434, 'accuracy': 0.96937, 'precision': 0.53846, 'recall': 0.21538, 'f1': 0.30769, 'auc': 0.7661}
2025-08-17 07:06:23,483 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:06:23,484 - INFO - Layer 0 (Layer_0), Head 2: drop=-0.0040
2025-08-17 07:06:27,926 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.38925, 'loss': 0.12296686, 'lr': 0, 'params': 451793, 'time_iter': 0.03403, 'accuracy': 0.96937, 'precision': 0.54545, 'recall': 0.18462, 'f1': 0.27586, 'auc': 0.76429}
2025-08-17 07:06:27,934 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:06:27,934 - INFO - Layer 0 (Layer_0), Head 3: drop=-0.0016
2025-08-17 07:06:32,429 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44299, 'loss': 0.12339282, 'lr': 0, 'params': 451793, 'time_iter': 0.03444, 'accuracy': 0.96912, 'precision': 0.53191, 'recall': 0.19231, 'f1': 0.28249, 'auc': 0.76602}
2025-08-17 07:06:32,436 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:06:32,436 - INFO - Layer 1 (Layer_1), Head 0: drop=-0.0039
2025-08-17 07:06:36,924 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43689, 'loss': 0.12355371, 'lr': 0, 'params': 451793, 'time_iter': 0.03439, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.15385, 'f1': 0.23529, 'auc': 0.76954}
2025-08-17 07:06:36,931 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:06:36,931 - INFO - Layer 1 (Layer_1), Head 1: drop=-0.0085
2025-08-17 07:06:41,390 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.4079, 'loss': 0.12469535, 'lr': 0, 'params': 451793, 'time_iter': 0.03417, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.17692, 'f1': 0.26136, 'auc': 0.76426}
2025-08-17 07:06:41,392 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:06:41,392 - INFO - Layer 1 (Layer_1), Head 2: drop=-0.0016
2025-08-17 07:06:45,831 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.39006, 'loss': 0.12047976, 'lr': 0, 'params': 451793, 'time_iter': 0.03403, 'accuracy': 0.97058, 'precision': 0.58491, 'recall': 0.23846, 'f1': 0.3388, 'auc': 0.77033}
2025-08-17 07:06:45,833 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:06:45,833 - INFO - Layer 1 (Layer_1), Head 3: drop=-0.0095
2025-08-17 07:06:50,242 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35849, 'loss': 0.12071708, 'lr': 0, 'params': 451793, 'time_iter': 0.03379, 'accuracy': 0.97058, 'precision': 0.58182, 'recall': 0.24615, 'f1': 0.34595, 'auc': 0.76396}
2025-08-17 07:06:50,248 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:06:50,248 - INFO - Layer 2 (Layer_2), Head 0: drop=-0.0012
2025-08-17 07:06:54,813 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.51155, 'loss': 0.1240521, 'lr': 0, 'params': 451793, 'time_iter': 0.03497, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.18462, 'f1': 0.26966, 'auc': 0.76441}
2025-08-17 07:06:54,814 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:06:54,815 - INFO - Layer 2 (Layer_2), Head 1: drop=-0.0018
2025-08-17 07:06:59,216 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.34816, 'loss': 0.12148247, 'lr': 0, 'params': 451793, 'time_iter': 0.03371, 'accuracy': 0.96937, 'precision': 0.54167, 'recall': 0.2, 'f1': 0.29213, 'auc': 0.76201}
2025-08-17 07:06:59,226 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:06:59,226 - INFO - Layer 2 (Layer_2), Head 2: drop=0.0014
2025-08-17 07:07:03,700 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.42028, 'loss': 0.12221048, 'lr': 0, 'params': 451793, 'time_iter': 0.03427, 'accuracy': 0.96912, 'precision': 0.53191, 'recall': 0.19231, 'f1': 0.28249, 'auc': 0.76059}
2025-08-17 07:07:03,701 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:07:03,701 - INFO - Layer 2 (Layer_2), Head 3: drop=0.0032
2025-08-17 07:07:08,199 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44545, 'loss': 0.12347494, 'lr': 0, 'params': 451793, 'time_iter': 0.03446, 'accuracy': 0.96888, 'precision': 0.51852, 'recall': 0.21538, 'f1': 0.30435, 'auc': 0.76016}
2025-08-17 07:07:08,201 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:07:08,202 - INFO - Layer 3 (Layer_3), Head 0: drop=0.0038
2025-08-17 07:07:12,659 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40793, 'loss': 0.12190088, 'lr': 0, 'params': 451793, 'time_iter': 0.03417, 'accuracy': 0.96961, 'precision': 0.54717, 'recall': 0.22308, 'f1': 0.31694, 'auc': 0.76878}
2025-08-17 07:07:12,667 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:07:12,667 - INFO - Layer 3 (Layer_3), Head 1: drop=-0.0075
2025-08-17 07:07:17,162 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44243, 'loss': 0.12347134, 'lr': 0, 'params': 451793, 'time_iter': 0.03444, 'accuracy': 0.96961, 'precision': 0.55102, 'recall': 0.20769, 'f1': 0.30168, 'auc': 0.76144}
2025-08-17 07:07:17,164 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:07:17,165 - INFO - Layer 3 (Layer_3), Head 2: drop=0.0021
2025-08-17 07:07:21,624 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40853, 'loss': 0.12328798, 'lr': 0, 'params': 451793, 'time_iter': 0.03417, 'accuracy': 0.96912, 'precision': 0.52941, 'recall': 0.20769, 'f1': 0.29834, 'auc': 0.76695}
2025-08-17 07:07:21,626 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:07:21,626 - INFO - Layer 3 (Layer_3), Head 3: drop=-0.0051
2025-08-17 07:07:26,031 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35394, 'loss': 0.12157243, 'lr': 0, 'params': 451793, 'time_iter': 0.03375, 'accuracy': 0.96985, 'precision': 0.56522, 'recall': 0.2, 'f1': 0.29545, 'auc': 0.76398}
2025-08-17 07:07:26,037 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:07:26,038 - INFO - Layer 4 (Layer_4), Head 0: drop=-0.0012
2025-08-17 07:07:30,527 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43613, 'loss': 0.12219837, 'lr': 0, 'params': 451793, 'time_iter': 0.03439, 'accuracy': 0.97058, 'precision': 0.58182, 'recall': 0.24615, 'f1': 0.34595, 'auc': 0.76378}
2025-08-17 07:07:30,528 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:07:30,528 - INFO - Layer 4 (Layer_4), Head 1: drop=-0.0010
2025-08-17 07:07:35,034 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.45104, 'loss': 0.12161183, 'lr': 0, 'params': 451793, 'time_iter': 0.0345, 'accuracy': 0.96985, 'precision': 0.5625, 'recall': 0.20769, 'f1': 0.30337, 'auc': 0.76746}
2025-08-17 07:07:35,036 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:07:35,037 - INFO - Layer 4 (Layer_4), Head 2: drop=-0.0058
2025-08-17 07:07:39,572 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.48252, 'loss': 0.12163759, 'lr': 0, 'params': 451793, 'time_iter': 0.03475, 'accuracy': 0.96985, 'precision': 0.55769, 'recall': 0.22308, 'f1': 0.31868, 'auc': 0.76575}
2025-08-17 07:07:39,574 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:07:39,574 - INFO - Layer 4 (Layer_4), Head 3: drop=-0.0035
2025-08-17 07:07:44,118 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.49313, 'loss': 0.12171155, 'lr': 0, 'params': 451793, 'time_iter': 0.03483, 'accuracy': 0.97058, 'precision': 0.6, 'recall': 0.20769, 'f1': 0.30857, 'auc': 0.76417}
2025-08-17 07:07:44,123 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:07:44,124 - INFO - Layer 5 (Layer_5), Head 0: drop=-0.0015
2025-08-17 07:07:48,545 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.36757, 'loss': 0.12203816, 'lr': 0, 'params': 451793, 'time_iter': 0.03386, 'accuracy': 0.96912, 'precision': 0.52941, 'recall': 0.20769, 'f1': 0.29834, 'auc': 0.7664}
2025-08-17 07:07:48,547 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:07:48,547 - INFO - Layer 5 (Layer_5), Head 1: drop=-0.0044
2025-08-17 07:07:52,921 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.32361, 'loss': 0.12190201, 'lr': 0, 'params': 451793, 'time_iter': 0.03352, 'accuracy': 0.97034, 'precision': 0.59091, 'recall': 0.2, 'f1': 0.29885, 'auc': 0.76763}
2025-08-17 07:07:52,923 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:07:52,923 - INFO - Layer 5 (Layer_5), Head 2: drop=-0.0060
2025-08-17 07:07:57,393 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.41752, 'loss': 0.12329923, 'lr': 0, 'params': 451793, 'time_iter': 0.03424, 'accuracy': 0.96961, 'precision': 0.54717, 'recall': 0.22308, 'f1': 0.31694, 'auc': 0.76464}
2025-08-17 07:07:57,395 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:07:57,395 - INFO - Layer 5 (Layer_5), Head 3: drop=-0.0021
2025-08-17 07:08:01,841 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3955, 'loss': 0.12373428, 'lr': 0, 'params': 451793, 'time_iter': 0.03407, 'accuracy': 0.96961, 'precision': 0.55556, 'recall': 0.19231, 'f1': 0.28571, 'auc': 0.76148}
2025-08-17 07:08:01,844 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:08:01,844 - INFO - Layer 6 (Layer_6), Head 0: drop=0.0021
2025-08-17 07:08:06,351 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.45552, 'loss': 0.12067495, 'lr': 0, 'params': 451793, 'time_iter': 0.03454, 'accuracy': 0.97034, 'precision': 0.57692, 'recall': 0.23077, 'f1': 0.32967, 'auc': 0.76947}
2025-08-17 07:08:06,352 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:08:06,353 - INFO - Layer 6 (Layer_6), Head 1: drop=-0.0084
2025-08-17 07:08:10,867 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.46112, 'loss': 0.12116455, 'lr': 0, 'params': 451793, 'time_iter': 0.03458, 'accuracy': 0.97058, 'precision': 0.59184, 'recall': 0.22308, 'f1': 0.32402, 'auc': 0.76413}
2025-08-17 07:08:10,869 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:08:10,869 - INFO - Layer 6 (Layer_6), Head 2: drop=-0.0014
2025-08-17 07:08:15,423 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.50014, 'loss': 0.12159238, 'lr': 0, 'params': 451793, 'time_iter': 0.03488, 'accuracy': 0.96961, 'precision': 0.55102, 'recall': 0.20769, 'f1': 0.30168, 'auc': 0.76803}
2025-08-17 07:08:15,432 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:08:15,433 - INFO - Layer 6 (Layer_6), Head 3: drop=-0.0065
2025-08-17 07:08:19,919 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43303, 'loss': 0.12133157, 'lr': 0, 'params': 451793, 'time_iter': 0.03436, 'accuracy': 0.96985, 'precision': 0.56522, 'recall': 0.2, 'f1': 0.29545, 'auc': 0.76826}
2025-08-17 07:08:19,924 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:08:19,925 - INFO - Layer 7 (Layer_7), Head 0: drop=-0.0068
2025-08-17 07:08:24,358 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.38342, 'loss': 0.12254371, 'lr': 0, 'params': 451793, 'time_iter': 0.03398, 'accuracy': 0.97034, 'precision': 0.58333, 'recall': 0.21538, 'f1': 0.31461, 'auc': 0.76212}
2025-08-17 07:08:24,360 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:08:24,360 - INFO - Layer 7 (Layer_7), Head 1: drop=0.0012
2025-08-17 07:08:28,852 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44094, 'loss': 0.12175619, 'lr': 0, 'params': 451793, 'time_iter': 0.03443, 'accuracy': 0.97058, 'precision': 0.6, 'recall': 0.20769, 'f1': 0.30857, 'auc': 0.76512}
2025-08-17 07:08:28,854 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:08:28,854 - INFO - Layer 7 (Layer_7), Head 2: drop=-0.0027
2025-08-17 07:08:33,311 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.40423, 'loss': 0.12143583, 'lr': 0, 'params': 451793, 'time_iter': 0.03414, 'accuracy': 0.96961, 'precision': 0.55319, 'recall': 0.2, 'f1': 0.29379, 'auc': 0.76522}
2025-08-17 07:08:33,313 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:08:33,313 - INFO - Layer 7 (Layer_7), Head 3: drop=-0.0028
2025-08-17 07:08:37,813 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44979, 'loss': 0.12144326, 'lr': 0, 'params': 451793, 'time_iter': 0.03449, 'accuracy': 0.97009, 'precision': 0.57143, 'recall': 0.21538, 'f1': 0.31285, 'auc': 0.76916}
2025-08-17 07:08:37,815 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:08:37,815 - INFO - Layer 8 (Layer_8), Head 0: drop=-0.0080
2025-08-17 07:08:42,336 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.47022, 'loss': 0.12178666, 'lr': 0, 'params': 451793, 'time_iter': 0.03465, 'accuracy': 0.96961, 'precision': 0.55556, 'recall': 0.19231, 'f1': 0.28571, 'auc': 0.76777}
2025-08-17 07:08:42,341 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:08:42,341 - INFO - Layer 8 (Layer_8), Head 1: drop=-0.0062
2025-08-17 07:08:46,876 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.48112, 'loss': 0.120934, 'lr': 0, 'params': 451793, 'time_iter': 0.03474, 'accuracy': 0.97082, 'precision': 0.6087, 'recall': 0.21538, 'f1': 0.31818, 'auc': 0.76726}
2025-08-17 07:08:46,877 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:08:46,878 - INFO - Layer 8 (Layer_8), Head 2: drop=-0.0055
2025-08-17 07:08:51,426 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.49644, 'loss': 0.12146199, 'lr': 0, 'params': 451793, 'time_iter': 0.03486, 'accuracy': 0.97009, 'precision': 0.57778, 'recall': 0.2, 'f1': 0.29714, 'auc': 0.76664}
2025-08-17 07:08:51,429 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:08:51,429 - INFO - Layer 8 (Layer_8), Head 3: drop=-0.0047
2025-08-17 07:08:56,023 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.54377, 'loss': 0.12232303, 'lr': 0, 'params': 451793, 'time_iter': 0.03522, 'accuracy': 0.96985, 'precision': 0.56522, 'recall': 0.2, 'f1': 0.29545, 'auc': 0.76465}
2025-08-17 07:08:56,025 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:08:56,025 - INFO - Layer 9 (Layer_9), Head 0: drop=-0.0021
2025-08-17 07:09:00,520 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44319, 'loss': 0.12202996, 'lr': 0, 'params': 451793, 'time_iter': 0.03444, 'accuracy': 0.97034, 'precision': 0.58696, 'recall': 0.20769, 'f1': 0.30682, 'auc': 0.76368}
2025-08-17 07:09:00,522 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:09:00,522 - INFO - Layer 9 (Layer_9), Head 1: drop=-0.0008
2025-08-17 07:09:05,061 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.48699, 'loss': 0.12219806, 'lr': 0, 'params': 451793, 'time_iter': 0.03478, 'accuracy': 0.96961, 'precision': 0.55556, 'recall': 0.19231, 'f1': 0.28571, 'auc': 0.76672}
2025-08-17 07:09:05,064 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:09:05,064 - INFO - Layer 9 (Layer_9), Head 2: drop=-0.0048
2025-08-17 07:09:09,577 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.46137, 'loss': 0.12182299, 'lr': 0, 'params': 451793, 'time_iter': 0.03458, 'accuracy': 0.97058, 'precision': 0.59184, 'recall': 0.22308, 'f1': 0.32402, 'auc': 0.76657}
2025-08-17 07:09:09,578 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:09:09,579 - INFO - Layer 9 (Layer_9), Head 3: drop=-0.0046
2025-08-17 07:09:14,084 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.45181, 'loss': 0.12272562, 'lr': 0, 'params': 451793, 'time_iter': 0.03451, 'accuracy': 0.96912, 'precision': 0.53333, 'recall': 0.18462, 'f1': 0.27429, 'auc': 0.7637}
2025-08-17 07:09:14,087 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:09:14,088 - INFO - Layer 10 (Layer_10), Head 0: drop=-0.0009
2025-08-17 07:09:18,611 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.46149, 'loss': 0.12259486, 'lr': 0, 'params': 451793, 'time_iter': 0.03459, 'accuracy': 0.96985, 'precision': 0.56522, 'recall': 0.2, 'f1': 0.29545, 'auc': 0.7633}
2025-08-17 07:09:18,618 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:09:18,618 - INFO - Layer 10 (Layer_10), Head 1: drop=-0.0003
2025-08-17 07:09:23,126 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.45655, 'loss': 0.12254534, 'lr': 0, 'params': 451793, 'time_iter': 0.03455, 'accuracy': 0.96912, 'precision': 0.53488, 'recall': 0.17692, 'f1': 0.2659, 'auc': 0.76566}
2025-08-17 07:09:23,128 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:09:23,128 - INFO - Layer 10 (Layer_10), Head 2: drop=-0.0034
2025-08-17 07:09:27,644 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.46539, 'loss': 0.12240168, 'lr': 0, 'params': 451793, 'time_iter': 0.03462, 'accuracy': 0.97009, 'precision': 0.57447, 'recall': 0.20769, 'f1': 0.30508, 'auc': 0.76515}
2025-08-17 07:09:27,647 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:09:27,647 - INFO - Layer 10 (Layer_10), Head 3: drop=-0.0028
2025-08-17 07:09:32,109 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.4113, 'loss': 0.12224704, 'lr': 0, 'params': 451793, 'time_iter': 0.0342, 'accuracy': 0.96985, 'precision': 0.5625, 'recall': 0.20769, 'f1': 0.30337, 'auc': 0.76532}
2025-08-17 07:09:32,115 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:09:32,116 - INFO - Layer 11 (Layer_11), Head 0: drop=-0.0030
2025-08-17 07:09:36,703 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.53431, 'loss': 0.12184812, 'lr': 0, 'params': 451793, 'time_iter': 0.03515, 'accuracy': 0.96961, 'precision': 0.55102, 'recall': 0.20769, 'f1': 0.30168, 'auc': 0.76397}
2025-08-17 07:09:36,709 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:09:36,710 - INFO - Layer 11 (Layer_11), Head 1: drop=-0.0012
2025-08-17 07:09:41,202 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.43931, 'loss': 0.12236132, 'lr': 0, 'params': 451793, 'time_iter': 0.03441, 'accuracy': 0.96912, 'precision': 0.53191, 'recall': 0.19231, 'f1': 0.28249, 'auc': 0.76413}
2025-08-17 07:09:41,204 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:09:41,204 - INFO - Layer 11 (Layer_11), Head 2: drop=-0.0014
2025-08-17 07:09:45,784 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.52558, 'loss': 0.12265936, 'lr': 0, 'params': 451793, 'time_iter': 0.03508, 'accuracy': 0.97009, 'precision': 0.57143, 'recall': 0.21538, 'f1': 0.31285, 'auc': 0.76443}
2025-08-17 07:09:45,786 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:09:45,786 - INFO - Layer 11 (Layer_11), Head 3: drop=-0.0018
2025-08-17 07:09:50,358 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.5188, 'loss': 0.12206172, 'lr': 0, 'params': 451793, 'time_iter': 0.03503, 'accuracy': 0.96985, 'precision': 0.5625, 'recall': 0.20769, 'f1': 0.30337, 'auc': 0.76361}
2025-08-17 07:09:50,360 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:09:50,361 - INFO - Layer 12 (Layer_12), Head 0: drop=-0.0007
2025-08-17 07:09:54,901 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.4884, 'loss': 0.12235628, 'lr': 0, 'params': 451793, 'time_iter': 0.03479, 'accuracy': 0.96961, 'precision': 0.54717, 'recall': 0.22308, 'f1': 0.31694, 'auc': 0.76463}
2025-08-17 07:09:54,904 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:09:54,905 - INFO - Layer 12 (Layer_12), Head 1: drop=-0.0021
2025-08-17 07:09:59,469 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.50426, 'loss': 0.12220711, 'lr': 0, 'params': 451793, 'time_iter': 0.03492, 'accuracy': 0.97009, 'precision': 0.57143, 'recall': 0.21538, 'f1': 0.31285, 'auc': 0.76474}
2025-08-17 07:09:59,475 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:09:59,476 - INFO - Layer 12 (Layer_12), Head 2: drop=-0.0022
2025-08-17 07:10:04,025 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.49619, 'loss': 0.12312537, 'lr': 0, 'params': 451793, 'time_iter': 0.03485, 'accuracy': 0.97009, 'precision': 0.57447, 'recall': 0.20769, 'f1': 0.30508, 'auc': 0.7648}
2025-08-17 07:10:04,027 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:10:04,027 - INFO - Layer 12 (Layer_12), Head 3: drop=-0.0023
2025-08-17 07:10:08,560 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.47897, 'loss': 0.1233208, 'lr': 0, 'params': 451793, 'time_iter': 0.03472, 'accuracy': 0.96888, 'precision': 0.52, 'recall': 0.2, 'f1': 0.28889, 'auc': 0.75963}
2025-08-17 07:10:08,562 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:10:08,562 - INFO - Layer 13 (Layer_13), Head 0: drop=0.0045
2025-08-17 07:10:13,084 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.47094, 'loss': 0.12363131, 'lr': 0, 'params': 451793, 'time_iter': 0.03466, 'accuracy': 0.96888, 'precision': 0.51852, 'recall': 0.21538, 'f1': 0.30435, 'auc': 0.76159}
2025-08-17 07:10:13,085 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:10:13,086 - INFO - Layer 13 (Layer_13), Head 1: drop=0.0019
2025-08-17 07:10:17,698 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.5563, 'loss': 0.12268281, 'lr': 0, 'params': 451793, 'time_iter': 0.03532, 'accuracy': 0.96961, 'precision': 0.54902, 'recall': 0.21538, 'f1': 0.30939, 'auc': 0.76414}
2025-08-17 07:10:17,700 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:10:17,700 - INFO - Layer 13 (Layer_13), Head 2: drop=-0.0014
2025-08-17 07:10:22,200 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.44592, 'loss': 0.12295929, 'lr': 0, 'params': 451793, 'time_iter': 0.03446, 'accuracy': 0.96961, 'precision': 0.54902, 'recall': 0.21538, 'f1': 0.30939, 'auc': 0.76173}
2025-08-17 07:10:22,202 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:10:22,202 - INFO - Layer 13 (Layer_13), Head 3: drop=0.0017
2025-08-17 07:10:26,754 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.49733, 'loss': 0.1225082, 'lr': 0, 'params': 451793, 'time_iter': 0.03486, 'accuracy': 0.96961, 'precision': 0.54902, 'recall': 0.21538, 'f1': 0.30939, 'auc': 0.75843}
2025-08-17 07:10:26,756 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:10:26,756 - INFO - Layer 14 (Layer_14), Head 0: drop=0.0061
2025-08-17 07:10:31,297 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.48988, 'loss': 0.12240373, 'lr': 0, 'params': 451793, 'time_iter': 0.03481, 'accuracy': 0.96985, 'precision': 0.55357, 'recall': 0.23846, 'f1': 0.33333, 'auc': 0.75992}
2025-08-17 07:10:31,299 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:10:31,300 - INFO - Layer 14 (Layer_14), Head 1: drop=0.0041
2025-08-17 07:10:35,707 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.35362, 'loss': 0.12258954, 'lr': 0, 'params': 451793, 'time_iter': 0.03375, 'accuracy': 0.96912, 'precision': 0.53061, 'recall': 0.2, 'f1': 0.2905, 'auc': 0.76141}
2025-08-17 07:10:35,709 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:10:35,709 - INFO - Layer 14 (Layer_14), Head 2: drop=0.0021
2025-08-17 07:10:40,068 - INFO - pk_ablation: {'epoch': 0, 'time_epoch': 4.3076, 'loss': 0.1236357, 'lr': 0, 'params': 451793, 'time_iter': 0.03339, 'accuracy': 0.96912, 'precision': 0.53191, 'recall': 0.19231, 'f1': 0.28249, 'auc': 0.76092}
2025-08-17 07:10:40,076 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:10:40,077 - INFO - Layer 14 (Layer_14), Head 3: drop=0.0028
2025-08-17 07:10:40,079 - INFO - 
FIDELITY METRICS:
2025-08-17 07:10:40,080 - INFO - Fidelity (top 30 heads): 0.0005
2025-08-17 07:10:40,080 - INFO - Fidelity- (bottom 30 heads): -0.0048
2025-08-17 07:10:40,080 - INFO - 
GNN distribution in important heads:
2025-08-17 07:10:40,080 - INFO -   Layer_14: 4 heads
2025-08-17 07:10:40,080 - INFO -   Layer_13: 4 heads
2025-08-17 07:10:40,080 - INFO -   Layer_2: 4 heads
2025-08-17 07:10:40,080 - INFO -   Layer_11: 3 heads
2025-08-17 07:10:40,080 - INFO -   Layer_3: 2 heads
2025-08-17 07:10:40,080 - INFO -   Layer_6: 2 heads
2025-08-17 07:10:40,080 - INFO -   Layer_10: 2 heads
2025-08-17 07:10:40,081 - INFO -   Layer_4: 2 heads
2025-08-17 07:10:40,081 - INFO -   Layer_0: 2 heads
2025-08-17 07:10:40,081 - INFO -   Layer_7: 1 heads
2025-08-17 07:10:40,081 - INFO -   Layer_12: 1 heads
2025-08-17 07:10:40,081 - INFO -   Layer_9: 1 heads
2025-08-17 07:10:40,081 - INFO -   Layer_5: 1 heads
2025-08-17 07:10:40,081 - INFO -   Layer_1: 1 heads
2025-08-17 07:10:40,081 - INFO - 
Interpretability Analysis:
2025-08-17 07:10:40,081 - INFO -   Fidelity: 0.0005
2025-08-17 07:10:40,081 - INFO -   Fidelity-: -0.0048
2025-08-17 07:10:40,081 - INFO -   Total heads tested: 60
2025-08-17 07:10:40,525 - INFO - Excel results saved to results/molhiv/molhiv-Vanilla-47/pk_explainer_results.xlsx
2025-08-17 07:10:41,876 - INFO - Saved visualizations to results/molhiv/molhiv-Vanilla-47/pk_explainer_results
2025-08-17 07:10:41,879 - INFO - 
PK-Explainer results saved to:
2025-08-17 07:10:41,879 - INFO -   - Excel: results/molhiv/molhiv-Vanilla-47/pk_explainer_results.xlsx
2025-08-17 07:10:41,879 - INFO -   - JSON: results/molhiv/molhiv-Vanilla-47/pk_explainer_results.json
2025-08-17 07:10:41,879 - INFO -   - Visualizations: results/molhiv/molhiv-Vanilla-47/pk_explainer_results
2025-08-17 07:10:42,007 - INFO - Task done, results saved in results/molhiv/molhiv-Vanilla-47
2025-08-17 07:10:42,008 - INFO - Total time: 8238.89s (2.29h)
2025-08-17 07:10:42,054 - INFO - Results aggregated across runs saved in results/molhiv/molhiv-Vanilla-47/agg
2025-08-17 07:10:42,054 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-08-17 07:10:42,054 - INFO - Results saved in: results/molhiv/molhiv-Vanilla-47
2025-08-17 07:10:42,054 - INFO - Test results JSON files saved in: results/molhiv/molhiv-Vanilla-47/test_results/
Completed seed 47. Results saved in results/molhiv/molhiv-Vanilla-47
----------------------------------------
Running experiment with seed: 49
Starting training for seed 49...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/GET_VANILLA/MOLHIV/confignas.yaml
Using device: cuda
2025-08-17 07:11:02,062 - INFO - GPU Mem: 25.2GB
2025-08-17 07:11:02,062 - INFO - Run directory: results/molhiv/molhiv-Vanilla-49
2025-08-17 07:11:02,062 - INFO - Seed: 49
2025-08-17 07:11:02,062 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-17 07:11:02,062 - INFO - Routing mode: none
2025-08-17 07:11:02,062 - INFO - Expert types: ['GIN', 'GCN', 'GAT', 'SAGE']
2025-08-17 07:11:02,062 - INFO - Number of layers: 15
2025-08-17 07:11:02,063 - INFO - Uncertainty enabled: False
2025-08-17 07:11:02,063 - INFO - Training mode: custom
2025-08-17 07:11:02,063 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-17 07:11:02,063 - INFO - Additional features: Router weights logging + JSON export
2025-08-17 07:11:08,617 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 07:11:08,618 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-17 07:11:08,619 - INFO -   undirected: True
2025-08-17 07:11:08,620 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 07:11:08,620 - INFO -   avg num_nodes/graph: 25
2025-08-17 07:11:08,620 - INFO -   num node features: 9
2025-08-17 07:11:08,620 - INFO -   num edge features: 3
2025-08-17 07:11:08,620 - INFO -   num tasks: 1
2025-08-17 07:11:08,620 - INFO -   num classes: 2
2025-08-17 07:11:08,621 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-17 07:11:08,621 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-17 07:11:08,624 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 10%|█         | 4245/41127 [00:10<01:26, 424.48it/s] 15%|█▌        | 6319/41127 [00:20<01:57, 296.09it/s] 23%|██▎       | 9297/41127 [00:30<01:47, 296.51it/s] 31%|███       | 12798/41127 [00:40<01:29, 315.87it/s] 38%|███▊      | 15506/41127 [00:50<01:25, 299.17it/s] 43%|████▎     | 17562/41127 [01:01<01:32, 255.20it/s] 51%|█████     | 20899/41127 [01:11<01:12, 279.85it/s] 59%|█████▉    | 24368/41127 [01:21<00:55, 300.67it/s] 68%|██████▊   | 27806/41127 [01:31<00:42, 313.92it/s] 74%|███████▍  | 30370/41127 [01:41<00:36, 296.36it/s] 80%|████████  | 32906/41127 [01:51<00:29, 283.13it/s] 86%|████████▌ | 35434/41127 [02:01<00:20, 273.37it/s] 93%|█████████▎| 38400/41127 [02:11<00:09, 279.24it/s] 93%|█████████▎| 38400/41127 [02:23<00:09, 279.24it/s] 98%|█████████▊| 40352/41127 [02:23<00:03, 242.05it/s]100%|██████████| 41127/41127 [02:29<00:00, 274.76it/s]
2025-08-17 07:13:39,508 - INFO - Done! Took 00:02:30.89
2025-08-17 07:13:39,649 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-17 07:13:39,841 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-17 07:13:39,841 - INFO - Inner model type: <class 'graphgps.network.vanilla_model.VanillaModel'>
2025-08-17 07:13:39,841 - INFO - Inner model has get_darts_model: False
2025-08-17 07:13:39,844 - INFO - GraphGymModule(
  (model): VanillaModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): AtomEncoder(
          (atom_embedding_list): ModuleList(
            (0): Embedding(119, 48)
            (1): Embedding(5, 48)
            (2-3): 2 x Embedding(12, 48)
            (4): Embedding(10, 48)
            (5-6): 2 x Embedding(6, 48)
            (7-8): 2 x Embedding(2, 48)
          )
        )
        (encoder2): RWSENodeEncoder(
          (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pe_encoder): Linear(in_features=16, out_features=16, bias=True)
        )
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 64)
          (1): Embedding(6, 64)
          (2): Embedding(2, 64)
        )
      )
    )
    (layers): Sequential(
      (0): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (1): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (2): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (3): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (4): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (5): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (6): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (7): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (8): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (9): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (10): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (11): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (12): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (13): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
      (14): VANLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, heads=4
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_attn): Dropout(p=0.05, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.05, inplace=False)
        (ff_dropout2): Dropout(p=0.05, inplace=False)
      )
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
2025-08-17 07:13:39,847 - INFO - Number of parameters: 451,793
2025-08-17 07:13:39,847 - INFO - Starting optimized training: 2025-08-17 07:13:39.847264
2025-08-17 07:13:46,001 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 07:13:46,002 - INFO -   Data(edge_index=[2, 2259376], edge_attr=[2259376, 3], x=[1049163, 9], y=[41127, 1], num_nodes=1049163)
2025-08-17 07:13:46,003 - INFO -   undirected: True
2025-08-17 07:13:46,003 - INFO -   num graphs: 41127
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-17 07:13:46,003 - INFO -   avg num_nodes/graph: 25
2025-08-17 07:13:46,004 - INFO -   num node features: 9
2025-08-17 07:13:46,004 - INFO -   num edge features: 3
2025-08-17 07:13:46,004 - INFO -   num tasks: 1
2025-08-17 07:13:46,004 - INFO -   num classes: 2
2025-08-17 07:13:46,004 - INFO - Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2025-08-17 07:13:46,004 - INFO - Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...
2025-08-17 07:13:46,007 - INFO -   ...estimated to be undirected: True
  0%|          | 0/41127 [00:00<?, ?it/s] 10%|█         | 4296/41127 [00:10<01:25, 429.55it/s] 16%|█▌        | 6446/41127 [00:20<01:54, 302.56it/s] 23%|██▎       | 9298/41127 [00:30<01:48, 292.73it/s] 31%|███       | 12798/41127 [00:40<01:30, 313.79it/s] 36%|███▋      | 14942/41127 [00:50<01:34, 278.15it/s] 41%|████▏     | 16998/41127 [01:02<01:42, 234.51it/s] 50%|█████     | 20614/41127 [01:12<01:15, 273.31it/s] 57%|█████▋    | 23587/41127 [01:22<01:02, 280.23it/s] 65%|██████▍   | 26729/41127 [01:32<00:49, 290.38it/s] 72%|███████▏  | 29544/41127 [01:42<00:40, 287.69it/s] 79%|███████▉  | 32457/41127 [01:52<00:30, 288.77it/s] 85%|████████▍ | 34908/41127 [02:02<00:22, 275.16it/s] 91%|█████████ | 37312/41127 [02:12<00:14, 264.71it/s] 97%|█████████▋| 39868/41127 [02:22<00:04, 261.97it/s]100%|██████████| 41127/41127 [02:32<00:00, 269.82it/s]
2025-08-17 07:16:19,546 - INFO - Done! Took 00:02:33.54
2025-08-17 07:16:19,687 - INFO - [*] Loaded dataset 'ogbg-molhiv' from 'OGB'
2025-08-17 07:16:19,722 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-17 07:16:19,722 - INFO - Start from epoch 0
2025-08-17 07:17:34,968 - INFO - train: {'epoch': 0, 'time_epoch': 75.1428, 'eta': 7439.1373, 'eta_hours': 2.06643, 'loss': 0.71854297, 'lr': 0.0, 'params': 451793, 'time_iter': 0.07303, 'accuracy': 0.04185, 'precision': 0.03747, 'recall': 0.99594, 'f1': 0.07222, 'auc': 0.45872}
2025-08-17 07:17:35,009 - INFO - ...computing epoch stats took: 0.12s
2025-08-17 07:17:40,250 - INFO - val: {'epoch': 0, 'time_epoch': 5.22634, 'loss': 0.71709819, 'lr': 0, 'params': 451793, 'time_iter': 0.04051, 'accuracy': 0.01994, 'precision': 0.0197, 'recall': 1.0, 'f1': 0.03864, 'auc': 0.49204}
2025-08-17 07:17:40,253 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:17:45,099 - INFO - test: {'epoch': 0, 'time_epoch': 4.83091, 'loss': 0.71892876, 'lr': 0, 'params': 451793, 'time_iter': 0.03745, 'accuracy': 0.03258, 'precision': 0.03164, 'recall': 1.0, 'f1': 0.06134, 'auc': 0.40686}
2025-08-17 07:17:45,102 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:17:45,102 - INFO - > Epoch 0: took 85.4s (avg 85.4s) | Best so far: epoch 0	train_loss: 0.7185 train_auc: 0.4587	val_loss: 0.7171 val_auc: 0.4920	test_loss: 0.7189 test_auc: 0.4069
2025-08-17 07:18:54,789 - INFO - train: {'epoch': 1, 'time_epoch': 69.59718, 'eta': 7092.25886, 'eta_hours': 1.97007, 'loss': 0.48477871, 'lr': 2e-05, 'params': 451793, 'time_iter': 0.06764, 'accuracy': 0.87842, 'precision': 0.03805, 'recall': 0.09253, 'f1': 0.05393, 'auc': 0.51795}
2025-08-17 07:18:54,797 - INFO - ...computing epoch stats took: 0.08s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:18:59,307 - INFO - val: {'epoch': 1, 'time_epoch': 4.49106, 'loss': 0.24043629, 'lr': 0, 'params': 451793, 'time_iter': 0.03481, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.5517}
2025-08-17 07:18:59,310 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:19:03,810 - INFO - test: {'epoch': 1, 'time_epoch': 4.48442, 'loss': 0.25168469, 'lr': 0, 'params': 451793, 'time_iter': 0.03476, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.57855}
2025-08-17 07:19:03,812 - INFO - ...computing epoch stats took: 0.01s
2025-08-17 07:19:03,812 - INFO - > Epoch 1: took 78.7s (avg 82.0s) | Best so far: epoch 1	train_loss: 0.4848 train_auc: 0.5180	val_loss: 0.2404 val_auc: 0.5517	test_loss: 0.2517 test_auc: 0.5786
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:20:14,613 - INFO - train: {'epoch': 2, 'time_epoch': 70.73055, 'eta': 6966.88033, 'eta_hours': 1.93524, 'loss': 0.20166454, 'lr': 4e-05, 'params': 451793, 'time_iter': 0.06874, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.57935}
2025-08-17 07:20:14,620 - INFO - ...computing epoch stats took: 0.06s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:20:19,128 - INFO - val: {'epoch': 2, 'time_epoch': 4.49097, 'loss': 0.11561699, 'lr': 0, 'params': 451793, 'time_iter': 0.03481, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.60984}
2025-08-17 07:20:19,130 - INFO - ...computing epoch stats took: 0.02s
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:20:23,633 - INFO - test: {'epoch': 2, 'time_epoch': 4.48732, 'loss': 0.14563867, 'lr': 0, 'params': 451793, 'time_iter': 0.03479, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.65799}
2025-08-17 07:20:23,636 - INFO - ...computing epoch stats took: 0.02s
2025-08-17 07:20:23,637 - INFO - > Epoch 2: took 79.8s (avg 81.3s) | Best so far: epoch 2	train_loss: 0.2017 train_auc: 0.5794	val_loss: 0.1156 val_auc: 0.6098	test_loss: 0.1456 test_auc: 0.6580
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:21:34,567 - INFO - train: {'epoch': 3, 'time_epoch': 70.85755, 'eta': 6871.87382, 'eta_hours': 1.90885, 'loss': 0.15858032, 'lr': 6e-05, 'params': 451793, 'time_iter': 0.06886, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.64108}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:21:38,903 - INFO - val: {'epoch': 3, 'time_epoch': 4.31331, 'loss': 0.10222877, 'lr': 0, 'params': 451793, 'time_iter': 0.03344, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.58902}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:21:43,285 - INFO - test: {'epoch': 3, 'time_epoch': 4.36483, 'loss': 0.13021167, 'lr': 0, 'params': 451793, 'time_iter': 0.03384, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71028}
2025-08-17 07:21:43,287 - INFO - > Epoch 3: took 79.6s (avg 80.9s) | Best so far: epoch 2	train_loss: 0.2017 train_auc: 0.5794	val_loss: 0.1156 val_auc: 0.6098	test_loss: 0.1456 test_auc: 0.6580
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:22:54,222 - INFO - train: {'epoch': 4, 'time_epoch': 70.86039, 'eta': 6786.58078, 'eta_hours': 1.88516, 'loss': 0.15276063, 'lr': 8e-05, 'params': 451793, 'time_iter': 0.06886, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.66583}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:22:58,609 - INFO - val: {'epoch': 4, 'time_epoch': 4.36542, 'loss': 0.10003237, 'lr': 0, 'params': 451793, 'time_iter': 0.03384, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.65277}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:23:02,994 - INFO - test: {'epoch': 4, 'time_epoch': 4.35188, 'loss': 0.12907367, 'lr': 0, 'params': 451793, 'time_iter': 0.03374, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71156}
2025-08-17 07:23:02,998 - INFO - > Epoch 4: took 79.7s (avg 80.7s) | Best so far: epoch 4	train_loss: 0.1528 train_auc: 0.6658	val_loss: 0.1000 val_auc: 0.6528	test_loss: 0.1291 test_auc: 0.7116
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:24:13,831 - INFO - train: {'epoch': 5, 'time_epoch': 70.76145, 'eta': 6704.5486, 'eta_hours': 1.86237, 'loss': 0.14774281, 'lr': 0.0001, 'params': 451793, 'time_iter': 0.06877, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.69839}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:24:18,035 - INFO - val: {'epoch': 5, 'time_epoch': 4.18189, 'loss': 0.09559577, 'lr': 0, 'params': 451793, 'time_iter': 0.03242, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.70023}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:24:22,231 - INFO - test: {'epoch': 5, 'time_epoch': 4.17982, 'loss': 0.12120114, 'lr': 0, 'params': 451793, 'time_iter': 0.0324, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72908}
2025-08-17 07:24:22,233 - INFO - > Epoch 5: took 79.2s (avg 80.4s) | Best so far: epoch 5	train_loss: 0.1477 train_auc: 0.6984	val_loss: 0.0956 val_auc: 0.7002	test_loss: 0.1212 test_auc: 0.7291
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:25:34,111 - INFO - train: {'epoch': 6, 'time_epoch': 71.80286, 'eta': 6639.57252, 'eta_hours': 1.84433, 'loss': 0.14350231, 'lr': 9.997e-05, 'params': 451793, 'time_iter': 0.06978, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71651}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:25:38,578 - INFO - val: {'epoch': 6, 'time_epoch': 4.44472, 'loss': 0.09540776, 'lr': 0, 'params': 451793, 'time_iter': 0.03446, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.71085}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:25:43,103 - INFO - test: {'epoch': 6, 'time_epoch': 4.50688, 'loss': 0.1266778, 'lr': 0, 'params': 451793, 'time_iter': 0.03494, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.72371}
2025-08-17 07:25:43,105 - INFO - > Epoch 6: took 80.9s (avg 80.5s) | Best so far: epoch 6	train_loss: 0.1435 train_auc: 0.7165	val_loss: 0.0954 val_auc: 0.7108	test_loss: 0.1267 test_auc: 0.7237
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:26:52,232 - INFO - train: {'epoch': 7, 'time_epoch': 69.05508, 'eta': 6541.2903, 'eta_hours': 1.81703, 'loss': 0.13948845, 'lr': 9.989e-05, 'params': 451793, 'time_iter': 0.06711, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74482}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:26:56,615 - INFO - val: {'epoch': 7, 'time_epoch': 4.3595, 'loss': 0.08879943, 'lr': 0, 'params': 451793, 'time_iter': 0.03379, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7216}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:27:01,000 - INFO - test: {'epoch': 7, 'time_epoch': 4.36885, 'loss': 0.11767663, 'lr': 0, 'params': 451793, 'time_iter': 0.03387, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75595}
2025-08-17 07:27:01,003 - INFO - > Epoch 7: took 77.9s (avg 80.2s) | Best so far: epoch 7	train_loss: 0.1395 train_auc: 0.7448	val_loss: 0.0888 val_auc: 0.7216	test_loss: 0.1177 test_auc: 0.7560
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:28:10,956 - INFO - train: {'epoch': 8, 'time_epoch': 69.88092, 'eta': 6457.85311, 'eta_hours': 1.79385, 'loss': 0.13731021, 'lr': 9.975e-05, 'params': 451793, 'time_iter': 0.06791, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75262}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:28:15,350 - INFO - val: {'epoch': 8, 'time_epoch': 4.37204, 'loss': 0.08854338, 'lr': 0, 'params': 451793, 'time_iter': 0.03389, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75464}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:28:19,828 - INFO - test: {'epoch': 8, 'time_epoch': 4.46041, 'loss': 0.12089283, 'lr': 0, 'params': 451793, 'time_iter': 0.03458, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73625}
2025-08-17 07:28:19,830 - INFO - > Epoch 8: took 78.8s (avg 80.0s) | Best so far: epoch 8	train_loss: 0.1373 train_auc: 0.7526	val_loss: 0.0885 val_auc: 0.7546	test_loss: 0.1209 test_auc: 0.7362
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:29:28,935 - INFO - train: {'epoch': 9, 'time_epoch': 69.03441, 'eta': 6369.50859, 'eta_hours': 1.76931, 'loss': 0.13629923, 'lr': 9.956e-05, 'params': 451793, 'time_iter': 0.06709, 'accuracy': 0.96255, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75759}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:29:33,285 - INFO - val: {'epoch': 9, 'time_epoch': 4.32809, 'loss': 0.09090769, 'lr': 0, 'params': 451793, 'time_iter': 0.03355, 'accuracy': 0.98031, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73979}
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-08-17 07:29:37,681 - INFO - test: {'epoch': 9, 'time_epoch': 4.37949, 'loss': 0.11863929, 'lr': 0, 'params': 451793, 'time_iter': 0.03395, 'accuracy': 0.96839, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.74845}
2025-08-17 07:29:37,683 - INFO - > Epoch 9: took 77.9s (avg 79.8s) | Best so far: epoch 8	train_loss: 0.1373 train_auc: 0.7526	val_loss: 0.0885 val_auc: 0.7546	test_loss: 0.1209 test_auc: 0.7362
2025-08-17 07:30:48,333 - INFO - train: {'epoch': 10, 'time_epoch': 70.56388, 'eta': 6297.0498, 'eta_hours': 1.74918, 'loss': 0.13393408, 'lr': 9.932e-05, 'params': 451793, 'time_iter': 0.06858, 'accuracy': 0.96262, 'precision': 1.0, 'recall': 0.00162, 'f1': 0.00324, 'auc': 0.76569}
2025-08-17 07:30:52,596 - INFO - val: {'epoch': 10, 'time_epoch': 4.24017, 'loss': 0.09195334, 'lr': 0, 'params': 451793, 'time_iter': 0.03287, 'accuracy': 0.97958, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75024}
2025-08-17 07:30:56,975 - INFO - test: {'epoch': 10, 'time_epoch': 4.36165, 'loss': 0.1222005, 'lr': 0, 'params': 451793, 'time_iter': 0.03381, 'accuracy': 0.96888, 'precision': 1.0, 'recall': 0.01538, 'f1': 0.0303, 'auc': 0.74947}
2025-08-17 07:30:56,978 - INFO - > Epoch 10: took 79.3s (avg 79.8s) | Best so far: epoch 8	train_loss: 0.1373 train_auc: 0.7526	val_loss: 0.0885 val_auc: 0.7546	test_loss: 0.1209 test_auc: 0.7362
2025-08-17 07:32:07,283 - INFO - train: {'epoch': 11, 'time_epoch': 70.22, 'eta': 6222.38508, 'eta_hours': 1.72844, 'loss': 0.13326312, 'lr': 9.902e-05, 'params': 451793, 'time_iter': 0.06824, 'accuracy': 0.96262, 'precision': 0.55, 'recall': 0.00893, 'f1': 0.01757, 'auc': 0.77099}
2025-08-17 07:32:11,646 - INFO - val: {'epoch': 11, 'time_epoch': 4.34002, 'loss': 0.09407167, 'lr': 0, 'params': 451793, 'time_iter': 0.03364, 'accuracy': 0.97885, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76552}
2025-08-17 07:32:16,063 - INFO - test: {'epoch': 11, 'time_epoch': 4.39797, 'loss': 0.12056161, 'lr': 0, 'params': 451793, 'time_iter': 0.03409, 'accuracy': 0.96742, 'precision': 0.25, 'recall': 0.01538, 'f1': 0.02899, 'auc': 0.77435}
2025-08-17 07:32:16,065 - INFO - > Epoch 11: took 79.1s (avg 79.7s) | Best so far: epoch 11	train_loss: 0.1333 train_auc: 0.7710	val_loss: 0.0941 val_auc: 0.7655	test_loss: 0.1206 test_auc: 0.7743
2025-08-17 07:33:25,564 - INFO - train: {'epoch': 12, 'time_epoch': 69.41142, 'eta': 6142.99287, 'eta_hours': 1.70639, 'loss': 0.13175255, 'lr': 9.867e-05, 'params': 451793, 'time_iter': 0.06746, 'accuracy': 0.9628, 'precision': 0.55882, 'recall': 0.03084, 'f1': 0.05846, 'auc': 0.77215}
2025-08-17 07:33:29,979 - INFO - val: {'epoch': 12, 'time_epoch': 4.3911, 'loss': 0.08877736, 'lr': 0, 'params': 451793, 'time_iter': 0.03404, 'accuracy': 0.97909, 'precision': 0.38095, 'recall': 0.09877, 'f1': 0.15686, 'auc': 0.77866}
2025-08-17 07:33:34,398 - INFO - test: {'epoch': 12, 'time_epoch': 4.40154, 'loss': 0.12023157, 'lr': 0, 'params': 451793, 'time_iter': 0.03412, 'accuracy': 0.96669, 'precision': 0.4186, 'recall': 0.13846, 'f1': 0.20809, 'auc': 0.76965}
2025-08-17 07:33:34,401 - INFO - > Epoch 12: took 78.3s (avg 79.6s) | Best so far: epoch 12	train_loss: 0.1318 train_auc: 0.7722	val_loss: 0.0888 val_auc: 0.7787	test_loss: 0.1202 test_auc: 0.7696
2025-08-17 07:34:44,363 - INFO - train: {'epoch': 13, 'time_epoch': 69.88098, 'eta': 6067.91091, 'eta_hours': 1.68553, 'loss': 0.13089469, 'lr': 9.826e-05, 'params': 451793, 'time_iter': 0.06791, 'accuracy': 0.96301, 'precision': 0.57426, 'recall': 0.04708, 'f1': 0.08702, 'auc': 0.78225}
2025-08-17 07:34:48,769 - INFO - val: {'epoch': 13, 'time_epoch': 4.38243, 'loss': 0.08504416, 'lr': 0, 'params': 451793, 'time_iter': 0.03397, 'accuracy': 0.97958, 'precision': 0.4, 'recall': 0.07407, 'f1': 0.125, 'auc': 0.76141}
2025-08-17 07:34:53,274 - INFO - test: {'epoch': 13, 'time_epoch': 4.48577, 'loss': 0.11881563, 'lr': 0, 'params': 451793, 'time_iter': 0.03477, 'accuracy': 0.96815, 'precision': 0.46154, 'recall': 0.04615, 'f1': 0.08392, 'auc': 0.74908}
2025-08-17 07:34:53,276 - INFO - > Epoch 13: took 78.9s (avg 79.5s) | Best so far: epoch 12	train_loss: 0.1318 train_auc: 0.7722	val_loss: 0.0888 val_auc: 0.7787	test_loss: 0.1202 test_auc: 0.7696
2025-08-17 07:36:04,404 - INFO - train: {'epoch': 14, 'time_epoch': 71.04405, 'eta': 6000.11318, 'eta_hours': 1.6667, 'loss': 0.12991853, 'lr': 9.78e-05, 'params': 451793, 'time_iter': 0.06904, 'accuracy': 0.96322, 'precision': 0.58088, 'recall': 0.06412, 'f1': 0.1155, 'auc': 0.78662}
2025-08-17 07:36:08,899 - INFO - val: {'epoch': 14, 'time_epoch': 4.46916, 'loss': 0.08324589, 'lr': 0, 'params': 451793, 'time_iter': 0.03464, 'accuracy': 0.98006, 'precision': 0.47368, 'recall': 0.11111, 'f1': 0.18, 'auc': 0.77849}
2025-08-17 07:36:13,424 - INFO - test: {'epoch': 14, 'time_epoch': 4.50614, 'loss': 0.11658822, 'lr': 0, 'params': 451793, 'time_iter': 0.03493, 'accuracy': 0.96766, 'precision': 0.44828, 'recall': 0.1, 'f1': 0.16352, 'auc': 0.76337}
2025-08-17 07:36:13,427 - INFO - > Epoch 14: took 80.2s (avg 79.6s) | Best so far: epoch 12	train_loss: 0.1318 train_auc: 0.7722	val_loss: 0.0888 val_auc: 0.7787	test_loss: 0.1202 test_auc: 0.7696
2025-08-17 07:37:24,774 - INFO - train: {'epoch': 15, 'time_epoch': 71.26006, 'eta': 5933.04369, 'eta_hours': 1.64807, 'loss': 0.12795439, 'lr': 9.729e-05, 'params': 451793, 'time_iter': 0.06925, 'accuracy': 0.96319, 'precision': 0.56364, 'recall': 0.07549, 'f1': 0.13314, 'auc': 0.79257}
2025-08-17 07:37:29,165 - INFO - val: {'epoch': 15, 'time_epoch': 4.36095, 'loss': 0.08253775, 'lr': 0, 'params': 451793, 'time_iter': 0.03381, 'accuracy': 0.98055, 'precision': 0.52632, 'recall': 0.12346, 'f1': 0.2, 'auc': 0.77356}
2025-08-17 07:37:33,540 - INFO - test: {'epoch': 15, 'time_epoch': 4.35742, 'loss': 0.11361421, 'lr': 0, 'params': 451793, 'time_iter': 0.03378, 'accuracy': 0.96937, 'precision': 0.61111, 'recall': 0.08462, 'f1': 0.14865, 'auc': 0.7696}
2025-08-17 07:37:33,542 - INFO - > Epoch 15: took 80.1s (avg 79.6s) | Best so far: epoch 12	train_loss: 0.1318 train_auc: 0.7722	val_loss: 0.0888 val_auc: 0.7787	test_loss: 0.1202 test_auc: 0.7696
2025-08-17 07:38:43,615 - INFO - train: {'epoch': 16, 'time_epoch': 69.98765, 'eta': 5859.26886, 'eta_hours': 1.62757, 'loss': 0.12781179, 'lr': 9.673e-05, 'params': 451793, 'time_iter': 0.06802, 'accuracy': 0.96371, 'precision': 0.59694, 'recall': 0.09497, 'f1': 0.16387, 'auc': 0.78979}
2025-08-17 07:38:48,059 - INFO - val: {'epoch': 16, 'time_epoch': 4.42101, 'loss': 0.08515873, 'lr': 0, 'params': 451793, 'time_iter': 0.03427, 'accuracy': 0.97958, 'precision': 0.41176, 'recall': 0.08642, 'f1': 0.14286, 'auc': 0.76156}
2025-08-17 07:38:52,532 - INFO - test: {'epoch': 16, 'time_epoch': 4.45439, 'loss': 0.11666324, 'lr': 0, 'params': 451793, 'time_iter': 0.03453, 'accuracy': 0.96912, 'precision': 0.58824, 'recall': 0.07692, 'f1': 0.13605, 'auc': 0.75703}
2025-08-17 07:38:52,535 - INFO - > Epoch 16: took 79.0s (avg 79.6s) | Best so far: epoch 12	train_loss: 0.1318 train_auc: 0.7722	val_loss: 0.0888 val_auc: 0.7787	test_loss: 0.1202 test_auc: 0.7696
2025-08-17 07:40:04,566 - INFO - train: {'epoch': 17, 'time_epoch': 71.94604, 'eta': 5794.83636, 'eta_hours': 1.60968, 'loss': 0.1260803, 'lr': 9.611e-05, 'params': 451793, 'time_iter': 0.06992, 'accuracy': 0.96462, 'precision': 0.63178, 'recall': 0.13231, 'f1': 0.21879, 'auc': 0.80022}
2025-08-17 07:40:08,891 - INFO - val: {'epoch': 17, 'time_epoch': 4.30203, 'loss': 0.08175444, 'lr': 0, 'params': 451793, 'time_iter': 0.03335, 'accuracy': 0.98104, 'precision': 0.57143, 'recall': 0.14815, 'f1': 0.23529, 'auc': 0.78136}
2025-08-17 07:40:13,226 - INFO - test: {'epoch': 17, 'time_epoch': 4.31566, 'loss': 0.12045298, 'lr': 0, 'params': 451793, 'time_iter': 0.03345, 'accuracy': 0.9662, 'precision': 0.33333, 'recall': 0.06923, 'f1': 0.11465, 'auc': 0.74825}
2025-08-17 07:40:13,229 - INFO - > Epoch 17: took 80.7s (avg 79.6s) | Best so far: epoch 17	train_loss: 0.1261 train_auc: 0.8002	val_loss: 0.0818 val_auc: 0.7814	test_loss: 0.1205 test_auc: 0.7482
2025-08-17 07:41:24,777 - INFO - train: {'epoch': 18, 'time_epoch': 71.45574, 'eta': 5727.52277, 'eta_hours': 1.59098, 'loss': 0.12453624, 'lr': 9.545e-05, 'params': 451793, 'time_iter': 0.06944, 'accuracy': 0.9638, 'precision': 0.57915, 'recall': 0.12175, 'f1': 0.20121, 'auc': 0.80764}
2025-08-17 07:41:29,228 - INFO - val: {'epoch': 18, 'time_epoch': 4.42325, 'loss': 0.08003307, 'lr': 0, 'params': 451793, 'time_iter': 0.03429, 'accuracy': 0.98055, 'precision': 0.52381, 'recall': 0.1358, 'f1': 0.21569, 'auc': 0.77727}
2025-08-17 07:41:33,701 - INFO - test: {'epoch': 18, 'time_epoch': 4.45134, 'loss': 0.11303089, 'lr': 0, 'params': 451793, 'time_iter': 0.03451, 'accuracy': 0.97009, 'precision': 0.59459, 'recall': 0.16923, 'f1': 0.26347, 'auc': 0.7721}
2025-08-17 07:41:33,704 - INFO - > Epoch 18: took 80.5s (avg 79.7s) | Best so far: epoch 17	train_loss: 0.1261 train_auc: 0.8002	val_loss: 0.0818 val_auc: 0.7814	test_loss: 0.1205 test_auc: 0.7482
2025-08-17 07:42:43,342 - INFO - train: {'epoch': 19, 'time_epoch': 69.55128, 'eta': 5652.17708, 'eta_hours': 1.57005, 'loss': 0.12386745, 'lr': 9.474e-05, 'params': 451793, 'time_iter': 0.06759, 'accuracy': 0.96523, 'precision': 0.64194, 'recall': 0.16153, 'f1': 0.25811, 'auc': 0.80557}
2025-08-17 07:42:47,706 - INFO - val: {'epoch': 19, 'time_epoch': 4.34034, 'loss': 0.08094234, 'lr': 0, 'params': 451793, 'time_iter': 0.03365, 'accuracy': 0.97958, 'precision': 0.44444, 'recall': 0.14815, 'f1': 0.22222, 'auc': 0.79083}
2025-08-17 07:42:52,079 - INFO - test: {'epoch': 19, 'time_epoch': 4.35479, 'loss': 0.11516184, 'lr': 0, 'params': 451793, 'time_iter': 0.03376, 'accuracy': 0.96937, 'precision': 0.53333, 'recall': 0.24615, 'f1': 0.33684, 'auc': 0.76279}
2025-08-17 07:42:52,082 - INFO - > Epoch 19: took 78.4s (avg 79.6s) | Best so far: epoch 19	train_loss: 0.1239 train_auc: 0.8056	val_loss: 0.0809 val_auc: 0.7908	test_loss: 0.1152 test_auc: 0.7628
2025-08-17 07:44:02,334 - INFO - train: {'epoch': 20, 'time_epoch': 70.1669, 'eta': 5579.69916, 'eta_hours': 1.54992, 'loss': 0.12338272, 'lr': 9.397e-05, 'params': 451793, 'time_iter': 0.06819, 'accuracy': 0.96493, 'precision': 0.61677, 'recall': 0.16721, 'f1': 0.26309, 'auc': 0.80599}
2025-08-17 07:44:06,650 - INFO - val: {'epoch': 20, 'time_epoch': 4.29329, 'loss': 0.08209772, 'lr': 0, 'params': 451793, 'time_iter': 0.03328, 'accuracy': 0.97982, 'precision': 0.45833, 'recall': 0.1358, 'f1': 0.20952, 'auc': 0.78592}
2025-08-17 07:44:10,919 - INFO - test: {'epoch': 20, 'time_epoch': 4.25212, 'loss': 0.1150203, 'lr': 0, 'params': 451793, 'time_iter': 0.03296, 'accuracy': 0.96815, 'precision': 0.48276, 'recall': 0.10769, 'f1': 0.1761, 'auc': 0.76521}
2025-08-17 07:44:10,922 - INFO - > Epoch 20: took 78.8s (avg 79.6s) | Best so far: epoch 19	train_loss: 0.1239 train_auc: 0.8056	val_loss: 0.0809 val_auc: 0.7908	test_loss: 0.1152 test_auc: 0.7628
2025-08-17 07:45:21,701 - INFO - train: {'epoch': 21, 'time_epoch': 70.67671, 'eta': 5509.23885, 'eta_hours': 1.53034, 'loss': 0.12170663, 'lr': 9.316e-05, 'params': 451793, 'time_iter': 0.06868, 'accuracy': 0.96517, 'precision': 0.61026, 'recall': 0.19318, 'f1': 0.29346, 'auc': 0.81813}
2025-08-17 07:45:26,083 - INFO - val: {'epoch': 21, 'time_epoch': 4.35832, 'loss': 0.07909297, 'lr': 0, 'params': 451793, 'time_iter': 0.03379, 'accuracy': 0.98055, 'precision': 0.52174, 'recall': 0.14815, 'f1': 0.23077, 'auc': 0.79153}
2025-08-17 07:45:30,431 - INFO - test: {'epoch': 21, 'time_epoch': 4.33115, 'loss': 0.11241511, 'lr': 0, 'params': 451793, 'time_iter': 0.03357, 'accuracy': 0.97082, 'precision': 0.61905, 'recall': 0.2, 'f1': 0.30233, 'auc': 0.7622}
2025-08-17 07:45:30,434 - INFO - > Epoch 21: took 79.5s (avg 79.6s) | Best so far: epoch 21	train_loss: 0.1217 train_auc: 0.8181	val_loss: 0.0791 val_auc: 0.7915	test_loss: 0.1124 test_auc: 0.7622
2025-08-17 07:46:42,041 - INFO - train: {'epoch': 22, 'time_epoch': 71.52107, 'eta': 5441.5865, 'eta_hours': 1.51155, 'loss': 0.12160799, 'lr': 9.23e-05, 'params': 451793, 'time_iter': 0.06951, 'accuracy': 0.96572, 'precision': 0.63978, 'recall': 0.19318, 'f1': 0.29676, 'auc': 0.81119}
2025-08-17 07:46:46,334 - INFO - val: {'epoch': 22, 'time_epoch': 4.27018, 'loss': 0.08324909, 'lr': 0, 'params': 451793, 'time_iter': 0.0331, 'accuracy': 0.97933, 'precision': 0.44118, 'recall': 0.18519, 'f1': 0.26087, 'auc': 0.75878}
2025-08-17 07:46:50,671 - INFO - test: {'epoch': 22, 'time_epoch': 4.3185, 'loss': 0.11580596, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.31538, 'f1': 0.38679, 'auc': 0.75572}
2025-08-17 07:46:50,673 - INFO - > Epoch 22: took 80.2s (avg 79.6s) | Best so far: epoch 21	train_loss: 0.1217 train_auc: 0.8181	val_loss: 0.0791 val_auc: 0.7915	test_loss: 0.1124 test_auc: 0.7622
2025-08-17 07:48:00,996 - INFO - train: {'epoch': 23, 'time_epoch': 70.24288, 'eta': 5369.56416, 'eta_hours': 1.49155, 'loss': 0.12101053, 'lr': 9.14e-05, 'params': 451793, 'time_iter': 0.06826, 'accuracy': 0.96514, 'precision': 0.60341, 'recall': 0.2013, 'f1': 0.30189, 'auc': 0.81706}
2025-08-17 07:48:05,288 - INFO - val: {'epoch': 23, 'time_epoch': 4.26959, 'loss': 0.08991067, 'lr': 0, 'params': 451793, 'time_iter': 0.0331, 'accuracy': 0.97982, 'precision': 0.46429, 'recall': 0.16049, 'f1': 0.23853, 'auc': 0.75364}
2025-08-17 07:48:09,625 - INFO - test: {'epoch': 23, 'time_epoch': 4.31866, 'loss': 0.11878346, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.21538, 'f1': 0.30108, 'auc': 0.76335}
2025-08-17 07:48:09,627 - INFO - > Epoch 23: took 79.0s (avg 79.6s) | Best so far: epoch 21	train_loss: 0.1217 train_auc: 0.8181	val_loss: 0.0791 val_auc: 0.7915	test_loss: 0.1124 test_auc: 0.7622
2025-08-17 07:49:20,444 - INFO - train: {'epoch': 24, 'time_epoch': 70.73237, 'eta': 5299.15261, 'eta_hours': 1.47199, 'loss': 0.12099508, 'lr': 9.045e-05, 'params': 451793, 'time_iter': 0.06874, 'accuracy': 0.9659, 'precision': 0.64103, 'recall': 0.20292, 'f1': 0.30826, 'auc': 0.81461}
2025-08-17 07:49:24,695 - INFO - val: {'epoch': 24, 'time_epoch': 4.22811, 'loss': 0.07484483, 'lr': 0, 'params': 451793, 'time_iter': 0.03278, 'accuracy': 0.98201, 'precision': 0.62963, 'recall': 0.20988, 'f1': 0.31481, 'auc': 0.79844}
2025-08-17 07:49:29,145 - INFO - test: {'epoch': 24, 'time_epoch': 4.43196, 'loss': 0.11240951, 'lr': 0, 'params': 451793, 'time_iter': 0.03436, 'accuracy': 0.97131, 'precision': 0.6, 'recall': 0.27692, 'f1': 0.37895, 'auc': 0.75712}
2025-08-17 07:49:29,147 - INFO - > Epoch 24: took 79.5s (avg 79.6s) | Best so far: epoch 24	train_loss: 0.1210 train_auc: 0.8146	val_loss: 0.0748 val_auc: 0.7984	test_loss: 0.1124 test_auc: 0.7571
2025-08-17 07:50:40,386 - INFO - train: {'epoch': 25, 'time_epoch': 71.14921, 'eta': 5229.90279, 'eta_hours': 1.45275, 'loss': 0.12104235, 'lr': 8.946e-05, 'params': 451793, 'time_iter': 0.06914, 'accuracy': 0.9659, 'precision': 0.63415, 'recall': 0.21104, 'f1': 0.31669, 'auc': 0.81672}
2025-08-17 07:50:44,859 - INFO - val: {'epoch': 25, 'time_epoch': 4.44898, 'loss': 0.07676255, 'lr': 0, 'params': 451793, 'time_iter': 0.03449, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.17284, 'f1': 0.25688, 'auc': 0.79359}
2025-08-17 07:50:49,327 - INFO - test: {'epoch': 25, 'time_epoch': 4.44856, 'loss': 0.11212754, 'lr': 0, 'params': 451793, 'time_iter': 0.03448, 'accuracy': 0.97155, 'precision': 0.5942, 'recall': 0.31538, 'f1': 0.41206, 'auc': 0.76017}
2025-08-17 07:50:49,330 - INFO - > Epoch 25: took 80.2s (avg 79.6s) | Best so far: epoch 24	train_loss: 0.1210 train_auc: 0.8146	val_loss: 0.0748 val_auc: 0.7984	test_loss: 0.1124 test_auc: 0.7571
2025-08-17 07:52:00,692 - INFO - train: {'epoch': 26, 'time_epoch': 71.27628, 'eta': 5160.85585, 'eta_hours': 1.43357, 'loss': 0.11902845, 'lr': 8.842e-05, 'params': 451793, 'time_iter': 0.06927, 'accuracy': 0.96602, 'precision': 0.62955, 'recall': 0.22484, 'f1': 0.33134, 'auc': 0.82166}
2025-08-17 07:52:04,880 - INFO - val: {'epoch': 26, 'time_epoch': 4.16524, 'loss': 0.08153436, 'lr': 0, 'params': 451793, 'time_iter': 0.03229, 'accuracy': 0.97909, 'precision': 0.42424, 'recall': 0.17284, 'f1': 0.24561, 'auc': 0.7681}
2025-08-17 07:52:09,076 - INFO - test: {'epoch': 26, 'time_epoch': 4.17802, 'loss': 0.11392107, 'lr': 0, 'params': 451793, 'time_iter': 0.03239, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.28462, 'f1': 0.36275, 'auc': 0.76916}
2025-08-17 07:52:09,079 - INFO - > Epoch 26: took 79.7s (avg 79.6s) | Best so far: epoch 24	train_loss: 0.1210 train_auc: 0.8146	val_loss: 0.0748 val_auc: 0.7984	test_loss: 0.1124 test_auc: 0.7571
2025-08-17 07:53:20,793 - INFO - train: {'epoch': 27, 'time_epoch': 71.61189, 'eta': 5092.51265, 'eta_hours': 1.41459, 'loss': 0.11777575, 'lr': 8.734e-05, 'params': 451793, 'time_iter': 0.06959, 'accuracy': 0.96648, 'precision': 0.65248, 'recall': 0.22403, 'f1': 0.33353, 'auc': 0.82838}
2025-08-17 07:53:25,189 - INFO - val: {'epoch': 27, 'time_epoch': 4.36857, 'loss': 0.07945437, 'lr': 0, 'params': 451793, 'time_iter': 0.03386, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.23457, 'f1': 0.31933, 'auc': 0.78354}
2025-08-17 07:53:29,608 - INFO - test: {'epoch': 27, 'time_epoch': 4.39877, 'loss': 0.11676371, 'lr': 0, 'params': 451793, 'time_iter': 0.0341, 'accuracy': 0.96815, 'precision': 0.49351, 'recall': 0.29231, 'f1': 0.36715, 'auc': 0.75676}
2025-08-17 07:53:29,610 - INFO - > Epoch 27: took 80.5s (avg 79.6s) | Best so far: epoch 24	train_loss: 0.1210 train_auc: 0.8146	val_loss: 0.0748 val_auc: 0.7984	test_loss: 0.1124 test_auc: 0.7571
2025-08-17 07:54:39,814 - INFO - train: {'epoch': 28, 'time_epoch': 70.1165, 'eta': 5020.28289, 'eta_hours': 1.39452, 'loss': 0.11694065, 'lr': 8.622e-05, 'params': 451793, 'time_iter': 0.06814, 'accuracy': 0.9669, 'precision': 0.66362, 'recall': 0.23539, 'f1': 0.34751, 'auc': 0.82779}
2025-08-17 07:54:44,164 - INFO - val: {'epoch': 28, 'time_epoch': 4.32652, 'loss': 0.0793357, 'lr': 0, 'params': 451793, 'time_iter': 0.03354, 'accuracy': 0.97982, 'precision': 0.47727, 'recall': 0.25926, 'f1': 0.336, 'auc': 0.77189}
2025-08-17 07:54:48,612 - INFO - test: {'epoch': 28, 'time_epoch': 4.42954, 'loss': 0.11642645, 'lr': 0, 'params': 451793, 'time_iter': 0.03434, 'accuracy': 0.96791, 'precision': 0.4898, 'recall': 0.36923, 'f1': 0.42105, 'auc': 0.77236}
2025-08-17 07:54:48,622 - INFO - > Epoch 28: took 79.0s (avg 79.6s) | Best so far: epoch 24	train_loss: 0.1210 train_auc: 0.8146	val_loss: 0.0748 val_auc: 0.7984	test_loss: 0.1124 test_auc: 0.7571
2025-08-17 07:55:58,754 - INFO - train: {'epoch': 29, 'time_epoch': 70.03357, 'eta': 4948.00054, 'eta_hours': 1.37444, 'loss': 0.11642106, 'lr': 8.506e-05, 'params': 451793, 'time_iter': 0.06806, 'accuracy': 0.96717, 'precision': 0.65966, 'recall': 0.25487, 'f1': 0.36768, 'auc': 0.82926}
2025-08-17 07:56:03,174 - INFO - val: {'epoch': 29, 'time_epoch': 4.39304, 'loss': 0.08405831, 'lr': 0, 'params': 451793, 'time_iter': 0.03405, 'accuracy': 0.97909, 'precision': 0.43902, 'recall': 0.22222, 'f1': 0.29508, 'auc': 0.79697}
2025-08-17 07:56:07,574 - INFO - test: {'epoch': 29, 'time_epoch': 4.38094, 'loss': 0.12086075, 'lr': 0, 'params': 451793, 'time_iter': 0.03396, 'accuracy': 0.96961, 'precision': 0.53086, 'recall': 0.33077, 'f1': 0.40758, 'auc': 0.76291}
2025-08-17 07:56:07,590 - INFO - > Epoch 29: took 79.0s (avg 79.6s) | Best so far: epoch 24	train_loss: 0.1210 train_auc: 0.8146	val_loss: 0.0748 val_auc: 0.7984	test_loss: 0.1124 test_auc: 0.7571
2025-08-17 07:57:15,806 - INFO - train: {'epoch': 30, 'time_epoch': 68.12767, 'eta': 4871.62109, 'eta_hours': 1.35323, 'loss': 0.11694222, 'lr': 8.386e-05, 'params': 451793, 'time_iter': 0.06621, 'accuracy': 0.96705, 'precision': 0.65948, 'recall': 0.24838, 'f1': 0.36085, 'auc': 0.83058}
2025-08-17 07:57:20,136 - INFO - val: {'epoch': 30, 'time_epoch': 4.30627, 'loss': 0.07577918, 'lr': 0, 'params': 451793, 'time_iter': 0.03338, 'accuracy': 0.98104, 'precision': 0.54839, 'recall': 0.20988, 'f1': 0.30357, 'auc': 0.79966}
2025-08-17 07:57:24,414 - INFO - test: {'epoch': 30, 'time_epoch': 4.26094, 'loss': 0.11192036, 'lr': 0, 'params': 451793, 'time_iter': 0.03303, 'accuracy': 0.97155, 'precision': 0.58904, 'recall': 0.33077, 'f1': 0.42365, 'auc': 0.76409}
2025-08-17 07:57:24,417 - INFO - > Epoch 30: took 76.8s (avg 79.5s) | Best so far: epoch 30	train_loss: 0.1169 train_auc: 0.8306	val_loss: 0.0758 val_auc: 0.7997	test_loss: 0.1119 test_auc: 0.7641
2025-08-17 07:58:33,116 - INFO - train: {'epoch': 31, 'time_epoch': 68.60375, 'eta': 4796.76905, 'eta_hours': 1.33244, 'loss': 0.11543981, 'lr': 8.263e-05, 'params': 451793, 'time_iter': 0.06667, 'accuracy': 0.96699, 'precision': 0.65939, 'recall': 0.24513, 'f1': 0.3574, 'auc': 0.83187}
2025-08-17 07:58:37,334 - INFO - val: {'epoch': 31, 'time_epoch': 4.19235, 'loss': 0.07919482, 'lr': 0, 'params': 451793, 'time_iter': 0.0325, 'accuracy': 0.98152, 'precision': 0.6087, 'recall': 0.17284, 'f1': 0.26923, 'auc': 0.77822}
2025-08-17 07:58:41,532 - INFO - test: {'epoch': 31, 'time_epoch': 4.18041, 'loss': 0.11388118, 'lr': 0, 'params': 451793, 'time_iter': 0.03241, 'accuracy': 0.96937, 'precision': 0.53704, 'recall': 0.22308, 'f1': 0.31522, 'auc': 0.7601}
2025-08-17 07:58:41,535 - INFO - > Epoch 31: took 77.1s (avg 79.4s) | Best so far: epoch 30	train_loss: 0.1169 train_auc: 0.8306	val_loss: 0.0758 val_auc: 0.7997	test_loss: 0.1119 test_auc: 0.7641
2025-08-17 07:59:48,474 - INFO - train: {'epoch': 32, 'time_epoch': 66.84749, 'eta': 4718.72994, 'eta_hours': 1.31076, 'loss': 0.11534937, 'lr': 8.136e-05, 'params': 451793, 'time_iter': 0.06496, 'accuracy': 0.96742, 'precision': 0.6626, 'recall': 0.26461, 'f1': 0.37819, 'auc': 0.83603}
2025-08-17 07:59:52,827 - INFO - val: {'epoch': 32, 'time_epoch': 4.32774, 'loss': 0.08305694, 'lr': 0, 'params': 451793, 'time_iter': 0.03355, 'accuracy': 0.98006, 'precision': 0.49057, 'recall': 0.32099, 'f1': 0.38806, 'auc': 0.78315}
2025-08-17 07:59:57,086 - INFO - test: {'epoch': 32, 'time_epoch': 4.24113, 'loss': 0.12208428, 'lr': 0, 'params': 451793, 'time_iter': 0.03288, 'accuracy': 0.96742, 'precision': 0.48182, 'recall': 0.40769, 'f1': 0.44167, 'auc': 0.75858}
2025-08-17 07:59:57,089 - INFO - > Epoch 32: took 75.6s (avg 79.3s) | Best so far: epoch 30	train_loss: 0.1169 train_auc: 0.8306	val_loss: 0.0758 val_auc: 0.7997	test_loss: 0.1119 test_auc: 0.7641
2025-08-17 08:01:06,786 - INFO - train: {'epoch': 33, 'time_epoch': 69.608, 'eta': 4646.70782, 'eta_hours': 1.29075, 'loss': 0.11309472, 'lr': 8.005e-05, 'params': 451793, 'time_iter': 0.06765, 'accuracy': 0.96772, 'precision': 0.67137, 'recall': 0.27029, 'f1': 0.38542, 'auc': 0.84323}
2025-08-17 08:01:10,900 - INFO - val: {'epoch': 33, 'time_epoch': 4.08969, 'loss': 0.07761181, 'lr': 0, 'params': 451793, 'time_iter': 0.0317, 'accuracy': 0.9786, 'precision': 0.40541, 'recall': 0.18519, 'f1': 0.25424, 'auc': 0.78951}
2025-08-17 08:01:15,052 - INFO - test: {'epoch': 33, 'time_epoch': 4.13415, 'loss': 0.11614285, 'lr': 0, 'params': 451793, 'time_iter': 0.03205, 'accuracy': 0.96864, 'precision': 0.50667, 'recall': 0.29231, 'f1': 0.37073, 'auc': 0.75578}
2025-08-17 08:01:15,055 - INFO - > Epoch 33: took 78.0s (avg 79.3s) | Best so far: epoch 30	train_loss: 0.1169 train_auc: 0.8306	val_loss: 0.0758 val_auc: 0.7997	test_loss: 0.1119 test_auc: 0.7641
2025-08-17 08:02:22,640 - INFO - train: {'epoch': 34, 'time_epoch': 67.50257, 'eta': 4570.91354, 'eta_hours': 1.2697, 'loss': 0.11494847, 'lr': 7.872e-05, 'params': 451793, 'time_iter': 0.0656, 'accuracy': 0.96699, 'precision': 0.65021, 'recall': 0.25649, 'f1': 0.36787, 'auc': 0.83541}
2025-08-17 08:02:27,011 - INFO - val: {'epoch': 34, 'time_epoch': 4.34759, 'loss': 0.07609915, 'lr': 0, 'params': 451793, 'time_iter': 0.0337, 'accuracy': 0.98104, 'precision': 0.54054, 'recall': 0.24691, 'f1': 0.33898, 'auc': 0.78687}
2025-08-17 08:02:31,359 - INFO - test: {'epoch': 34, 'time_epoch': 4.3302, 'loss': 0.11295736, 'lr': 0, 'params': 451793, 'time_iter': 0.03357, 'accuracy': 0.97131, 'precision': 0.58824, 'recall': 0.30769, 'f1': 0.40404, 'auc': 0.75795}
2025-08-17 08:02:31,362 - INFO - > Epoch 34: took 76.3s (avg 79.2s) | Best so far: epoch 30	train_loss: 0.1169 train_auc: 0.8306	val_loss: 0.0758 val_auc: 0.7997	test_loss: 0.1119 test_auc: 0.7641
2025-08-17 08:03:38,890 - INFO - train: {'epoch': 35, 'time_epoch': 67.44364, 'eta': 4495.47517, 'eta_hours': 1.24874, 'loss': 0.11317279, 'lr': 7.735e-05, 'params': 451793, 'time_iter': 0.06554, 'accuracy': 0.96778, 'precision': 0.66797, 'recall': 0.2776, 'f1': 0.3922, 'auc': 0.84264}
2025-08-17 08:03:43,210 - INFO - val: {'epoch': 35, 'time_epoch': 4.29832, 'loss': 0.07312545, 'lr': 0, 'params': 451793, 'time_iter': 0.03332, 'accuracy': 0.98152, 'precision': 0.58065, 'recall': 0.22222, 'f1': 0.32143, 'auc': 0.81636}
2025-08-17 08:03:47,521 - INFO - test: {'epoch': 35, 'time_epoch': 4.29393, 'loss': 0.11243419, 'lr': 0, 'params': 451793, 'time_iter': 0.03329, 'accuracy': 0.96985, 'precision': 0.55, 'recall': 0.25385, 'f1': 0.34737, 'auc': 0.7611}
2025-08-17 08:03:47,523 - INFO - > Epoch 35: took 76.2s (avg 79.1s) | Best so far: epoch 35	train_loss: 0.1132 train_auc: 0.8426	val_loss: 0.0731 val_auc: 0.8164	test_loss: 0.1124 test_auc: 0.7611
2025-08-17 08:04:55,348 - INFO - train: {'epoch': 36, 'time_epoch': 67.74327, 'eta': 4420.97912, 'eta_hours': 1.22805, 'loss': 0.11239079, 'lr': 7.595e-05, 'params': 451793, 'time_iter': 0.06583, 'accuracy': 0.96806, 'precision': 0.68283, 'recall': 0.27435, 'f1': 0.39143, 'auc': 0.84695}
2025-08-17 08:04:59,460 - INFO - val: {'epoch': 36, 'time_epoch': 4.09144, 'loss': 0.07744131, 'lr': 0, 'params': 451793, 'time_iter': 0.03172, 'accuracy': 0.98128, 'precision': 0.54545, 'recall': 0.2963, 'f1': 0.384, 'auc': 0.79757}
2025-08-17 08:05:03,594 - INFO - test: {'epoch': 36, 'time_epoch': 4.11749, 'loss': 0.1146078, 'lr': 0, 'params': 451793, 'time_iter': 0.03192, 'accuracy': 0.97034, 'precision': 0.56061, 'recall': 0.28462, 'f1': 0.37755, 'auc': 0.7498}
2025-08-17 08:05:03,596 - INFO - > Epoch 36: took 76.1s (avg 79.0s) | Best so far: epoch 35	train_loss: 0.1132 train_auc: 0.8426	val_loss: 0.0731 val_auc: 0.8164	test_loss: 0.1124 test_auc: 0.7611
2025-08-17 08:06:09,468 - INFO - train: {'epoch': 37, 'time_epoch': 65.78659, 'eta': 4343.646, 'eta_hours': 1.20657, 'loss': 0.11180984, 'lr': 7.452e-05, 'params': 451793, 'time_iter': 0.06393, 'accuracy': 0.96842, 'precision': 0.69897, 'recall': 0.27516, 'f1': 0.39487, 'auc': 0.84511}
2025-08-17 08:06:13,809 - INFO - val: {'epoch': 37, 'time_epoch': 4.31857, 'loss': 0.07600771, 'lr': 0, 'params': 451793, 'time_iter': 0.03348, 'accuracy': 0.98079, 'precision': 0.53125, 'recall': 0.20988, 'f1': 0.30088, 'auc': 0.78594}
2025-08-17 08:06:18,160 - INFO - test: {'epoch': 37, 'time_epoch': 4.33387, 'loss': 0.11571146, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.96985, 'precision': 0.54167, 'recall': 0.3, 'f1': 0.38614, 'auc': 0.73974}
2025-08-17 08:06:18,163 - INFO - > Epoch 37: took 74.6s (avg 78.9s) | Best so far: epoch 35	train_loss: 0.1132 train_auc: 0.8426	val_loss: 0.0731 val_auc: 0.8164	test_loss: 0.1124 test_auc: 0.7611
2025-08-17 08:07:25,830 - INFO - train: {'epoch': 38, 'time_epoch': 67.58517, 'eta': 4269.71816, 'eta_hours': 1.18603, 'loss': 0.11063622, 'lr': 7.307e-05, 'params': 451793, 'time_iter': 0.06568, 'accuracy': 0.96833, 'precision': 0.69, 'recall': 0.28003, 'f1': 0.39838, 'auc': 0.84851}
2025-08-17 08:07:30,128 - INFO - val: {'epoch': 38, 'time_epoch': 4.27607, 'loss': 0.08386559, 'lr': 0, 'params': 451793, 'time_iter': 0.03315, 'accuracy': 0.97885, 'precision': 0.44643, 'recall': 0.30864, 'f1': 0.36496, 'auc': 0.79195}
2025-08-17 08:07:34,443 - INFO - test: {'epoch': 38, 'time_epoch': 4.29634, 'loss': 0.12154524, 'lr': 0, 'params': 451793, 'time_iter': 0.0333, 'accuracy': 0.9662, 'precision': 0.45714, 'recall': 0.36923, 'f1': 0.40851, 'auc': 0.75596}
2025-08-17 08:07:34,445 - INFO - > Epoch 38: took 76.3s (avg 78.8s) | Best so far: epoch 35	train_loss: 0.1132 train_auc: 0.8426	val_loss: 0.0731 val_auc: 0.8164	test_loss: 0.1124 test_auc: 0.7611
2025-08-17 08:08:42,805 - INFO - train: {'epoch': 39, 'time_epoch': 68.27568, 'eta': 4197.14323, 'eta_hours': 1.16587, 'loss': 0.11116591, 'lr': 7.159e-05, 'params': 451793, 'time_iter': 0.06635, 'accuracy': 0.96857, 'precision': 0.6875, 'recall': 0.29464, 'f1': 0.4125, 'auc': 0.85041}
2025-08-17 08:08:47,099 - INFO - val: {'epoch': 39, 'time_epoch': 4.271, 'loss': 0.07286505, 'lr': 0, 'params': 451793, 'time_iter': 0.03311, 'accuracy': 0.98249, 'precision': 0.64516, 'recall': 0.24691, 'f1': 0.35714, 'auc': 0.80838}
2025-08-17 08:08:51,419 - INFO - test: {'epoch': 39, 'time_epoch': 4.30197, 'loss': 0.11164435, 'lr': 0, 'params': 451793, 'time_iter': 0.03335, 'accuracy': 0.97155, 'precision': 0.6, 'recall': 0.3, 'f1': 0.4, 'auc': 0.7513}
2025-08-17 08:08:51,421 - INFO - > Epoch 39: took 77.0s (avg 78.8s) | Best so far: epoch 35	train_loss: 0.1132 train_auc: 0.8426	val_loss: 0.0731 val_auc: 0.8164	test_loss: 0.1124 test_auc: 0.7611
2025-08-17 08:09:59,587 - INFO - train: {'epoch': 40, 'time_epoch': 68.08091, 'eta': 4124.49775, 'eta_hours': 1.14569, 'loss': 0.11002615, 'lr': 7.008e-05, 'params': 451793, 'time_iter': 0.06616, 'accuracy': 0.96869, 'precision': 0.69804, 'recall': 0.28896, 'f1': 0.40873, 'auc': 0.85143}
2025-08-17 08:10:03,914 - INFO - val: {'epoch': 40, 'time_epoch': 4.30437, 'loss': 0.07676581, 'lr': 0, 'params': 451793, 'time_iter': 0.03337, 'accuracy': 0.98201, 'precision': 0.57778, 'recall': 0.32099, 'f1': 0.4127, 'auc': 0.79241}
2025-08-17 08:10:08,195 - INFO - test: {'epoch': 40, 'time_epoch': 4.26359, 'loss': 0.11634842, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.97082, 'precision': 0.55814, 'recall': 0.36923, 'f1': 0.44444, 'auc': 0.7497}
2025-08-17 08:10:08,197 - INFO - > Epoch 40: took 76.8s (avg 78.7s) | Best so far: epoch 35	train_loss: 0.1132 train_auc: 0.8426	val_loss: 0.0731 val_auc: 0.8164	test_loss: 0.1124 test_auc: 0.7611
2025-08-17 08:11:15,953 - INFO - train: {'epoch': 41, 'time_epoch': 67.67495, 'eta': 4051.50901, 'eta_hours': 1.12542, 'loss': 0.10974616, 'lr': 6.856e-05, 'params': 451793, 'time_iter': 0.06577, 'accuracy': 0.96787, 'precision': 0.67606, 'recall': 0.27273, 'f1': 0.38866, 'auc': 0.85305}
2025-08-17 08:11:20,116 - INFO - val: {'epoch': 41, 'time_epoch': 4.14043, 'loss': 0.07180986, 'lr': 0, 'params': 451793, 'time_iter': 0.0321, 'accuracy': 0.98274, 'precision': 0.66667, 'recall': 0.24691, 'f1': 0.36036, 'auc': 0.8088}
2025-08-17 08:11:24,399 - INFO - test: {'epoch': 41, 'time_epoch': 4.26562, 'loss': 0.1163142, 'lr': 0, 'params': 451793, 'time_iter': 0.03307, 'accuracy': 0.97058, 'precision': 0.56338, 'recall': 0.30769, 'f1': 0.39801, 'auc': 0.74425}
2025-08-17 08:11:24,401 - INFO - > Epoch 41: took 76.2s (avg 78.7s) | Best so far: epoch 35	train_loss: 0.1132 train_auc: 0.8426	val_loss: 0.0731 val_auc: 0.8164	test_loss: 0.1124 test_auc: 0.7611
2025-08-17 08:12:31,185 - INFO - train: {'epoch': 42, 'time_epoch': 66.70167, 'eta': 3977.47726, 'eta_hours': 1.10485, 'loss': 0.10874987, 'lr': 6.701e-05, 'params': 451793, 'time_iter': 0.06482, 'accuracy': 0.96882, 'precision': 0.68934, 'recall': 0.30438, 'f1': 0.4223, 'auc': 0.8534}
2025-08-17 08:12:35,480 - INFO - val: {'epoch': 42, 'time_epoch': 4.2703, 'loss': 0.07254512, 'lr': 0, 'params': 451793, 'time_iter': 0.0331, 'accuracy': 0.98104, 'precision': 0.54054, 'recall': 0.24691, 'f1': 0.33898, 'auc': 0.82731}
2025-08-17 08:12:39,761 - INFO - test: {'epoch': 42, 'time_epoch': 4.26374, 'loss': 0.11710997, 'lr': 0, 'params': 451793, 'time_iter': 0.03305, 'accuracy': 0.96791, 'precision': 0.48387, 'recall': 0.23077, 'f1': 0.3125, 'auc': 0.7535}
2025-08-17 08:12:39,764 - INFO - > Epoch 42: took 75.4s (avg 78.6s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:13:47,470 - INFO - train: {'epoch': 43, 'time_epoch': 67.62392, 'eta': 3904.95247, 'eta_hours': 1.08471, 'loss': 0.10808174, 'lr': 6.545e-05, 'params': 451793, 'time_iter': 0.06572, 'accuracy': 0.96897, 'precision': 0.69358, 'recall': 0.30682, 'f1': 0.42544, 'auc': 0.85742}
2025-08-17 08:13:51,781 - INFO - val: {'epoch': 43, 'time_epoch': 4.29, 'loss': 0.0736181, 'lr': 0, 'params': 451793, 'time_iter': 0.03326, 'accuracy': 0.98298, 'precision': 0.67742, 'recall': 0.25926, 'f1': 0.375, 'auc': 0.80609}
2025-08-17 08:13:56,094 - INFO - test: {'epoch': 43, 'time_epoch': 4.29478, 'loss': 0.11375121, 'lr': 0, 'params': 451793, 'time_iter': 0.03329, 'accuracy': 0.97082, 'precision': 0.57143, 'recall': 0.30769, 'f1': 0.4, 'auc': 0.7445}
2025-08-17 08:13:56,096 - INFO - > Epoch 43: took 76.3s (avg 78.6s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:15:03,792 - INFO - train: {'epoch': 44, 'time_epoch': 67.61005, 'eta': 3832.62854, 'eta_hours': 1.06462, 'loss': 0.10808372, 'lr': 6.387e-05, 'params': 451793, 'time_iter': 0.0657, 'accuracy': 0.96979, 'precision': 0.72119, 'recall': 0.31494, 'f1': 0.43842, 'auc': 0.85284}
2025-08-17 08:15:08,227 - INFO - val: {'epoch': 44, 'time_epoch': 4.41287, 'loss': 0.07342022, 'lr': 0, 'params': 451793, 'time_iter': 0.03421, 'accuracy': 0.98322, 'precision': 0.65, 'recall': 0.32099, 'f1': 0.42975, 'auc': 0.8049}
2025-08-17 08:15:12,515 - INFO - test: {'epoch': 44, 'time_epoch': 4.27079, 'loss': 0.1145141, 'lr': 0, 'params': 451793, 'time_iter': 0.03311, 'accuracy': 0.97058, 'precision': 0.55844, 'recall': 0.33077, 'f1': 0.41546, 'auc': 0.75078}
2025-08-17 08:15:12,517 - INFO - > Epoch 44: took 76.4s (avg 78.5s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:16:19,679 - INFO - train: {'epoch': 45, 'time_epoch': 67.08053, 'eta': 3759.88795, 'eta_hours': 1.04441, 'loss': 0.10862301, 'lr': 6.227e-05, 'params': 451793, 'time_iter': 0.06519, 'accuracy': 0.96927, 'precision': 0.71624, 'recall': 0.29708, 'f1': 0.41997, 'auc': 0.85671}
2025-08-17 08:16:23,847 - INFO - val: {'epoch': 45, 'time_epoch': 4.14602, 'loss': 0.07820588, 'lr': 0, 'params': 451793, 'time_iter': 0.03214, 'accuracy': 0.97909, 'precision': 0.44186, 'recall': 0.23457, 'f1': 0.30645, 'auc': 0.78752}
2025-08-17 08:16:28,079 - INFO - test: {'epoch': 45, 'time_epoch': 4.21595, 'loss': 0.12271248, 'lr': 0, 'params': 451793, 'time_iter': 0.03268, 'accuracy': 0.96645, 'precision': 0.45349, 'recall': 0.3, 'f1': 0.36111, 'auc': 0.74707}
2025-08-17 08:16:28,082 - INFO - > Epoch 45: took 75.6s (avg 78.4s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:17:35,789 - INFO - train: {'epoch': 46, 'time_epoch': 67.6244, 'eta': 3688.00152, 'eta_hours': 1.02444, 'loss': 0.10835226, 'lr': 6.066e-05, 'params': 451793, 'time_iter': 0.06572, 'accuracy': 0.96903, 'precision': 0.70209, 'recall': 0.30032, 'f1': 0.42069, 'auc': 0.86013}
2025-08-17 08:17:40,052 - INFO - val: {'epoch': 46, 'time_epoch': 4.24048, 'loss': 0.07334539, 'lr': 0, 'params': 451793, 'time_iter': 0.03287, 'accuracy': 0.98249, 'precision': 0.60465, 'recall': 0.32099, 'f1': 0.41935, 'auc': 0.81121}
2025-08-17 08:17:44,308 - INFO - test: {'epoch': 46, 'time_epoch': 4.23837, 'loss': 0.11735621, 'lr': 0, 'params': 451793, 'time_iter': 0.03286, 'accuracy': 0.96961, 'precision': 0.53086, 'recall': 0.33077, 'f1': 0.40758, 'auc': 0.75137}
2025-08-17 08:17:44,311 - INFO - > Epoch 46: took 76.2s (avg 78.4s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:18:51,821 - INFO - train: {'epoch': 47, 'time_epoch': 67.42715, 'eta': 3616.079, 'eta_hours': 1.00447, 'loss': 0.10696661, 'lr': 5.904e-05, 'params': 451793, 'time_iter': 0.06553, 'accuracy': 0.96915, 'precision': 0.69835, 'recall': 0.31006, 'f1': 0.42945, 'auc': 0.86397}
2025-08-17 08:18:56,159 - INFO - val: {'epoch': 47, 'time_epoch': 4.31605, 'loss': 0.07764934, 'lr': 0, 'params': 451793, 'time_iter': 0.03346, 'accuracy': 0.98201, 'precision': 0.60606, 'recall': 0.24691, 'f1': 0.35088, 'auc': 0.79053}
2025-08-17 08:19:00,483 - INFO - test: {'epoch': 47, 'time_epoch': 4.30564, 'loss': 0.11512417, 'lr': 0, 'params': 451793, 'time_iter': 0.03338, 'accuracy': 0.96888, 'precision': 0.51429, 'recall': 0.27692, 'f1': 0.36, 'auc': 0.75866}
2025-08-17 08:19:00,485 - INFO - > Epoch 47: took 76.2s (avg 78.3s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:20:08,464 - INFO - train: {'epoch': 48, 'time_epoch': 67.89632, 'eta': 3544.82826, 'eta_hours': 0.98467, 'loss': 0.10584879, 'lr': 5.741e-05, 'params': 451793, 'time_iter': 0.06598, 'accuracy': 0.96933, 'precision': 0.69191, 'recall': 0.3263, 'f1': 0.44346, 'auc': 0.86589}
2025-08-17 08:20:12,839 - INFO - val: {'epoch': 48, 'time_epoch': 4.3526, 'loss': 0.07713001, 'lr': 0, 'params': 451793, 'time_iter': 0.03374, 'accuracy': 0.98055, 'precision': 0.51064, 'recall': 0.2963, 'f1': 0.375, 'auc': 0.79483}
2025-08-17 08:20:17,197 - INFO - test: {'epoch': 48, 'time_epoch': 4.34084, 'loss': 0.11926889, 'lr': 0, 'params': 451793, 'time_iter': 0.03365, 'accuracy': 0.96912, 'precision': 0.51648, 'recall': 0.36154, 'f1': 0.42534, 'auc': 0.75827}
2025-08-17 08:20:17,199 - INFO - > Epoch 48: took 76.7s (avg 78.3s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:21:25,049 - INFO - train: {'epoch': 49, 'time_epoch': 67.76355, 'eta': 3473.57893, 'eta_hours': 0.96488, 'loss': 0.1055443, 'lr': 5.577e-05, 'params': 451793, 'time_iter': 0.06585, 'accuracy': 0.97027, 'precision': 0.71672, 'recall': 0.34091, 'f1': 0.46205, 'auc': 0.86639}
2025-08-17 08:21:29,416 - INFO - val: {'epoch': 49, 'time_epoch': 4.3427, 'loss': 0.07240565, 'lr': 0, 'params': 451793, 'time_iter': 0.03366, 'accuracy': 0.98347, 'precision': 0.69697, 'recall': 0.28395, 'f1': 0.40351, 'auc': 0.80283}
2025-08-17 08:21:33,775 - INFO - test: {'epoch': 49, 'time_epoch': 4.3415, 'loss': 0.11514437, 'lr': 0, 'params': 451793, 'time_iter': 0.03366, 'accuracy': 0.97034, 'precision': 0.55714, 'recall': 0.3, 'f1': 0.39, 'auc': 0.75855}
2025-08-17 08:21:33,778 - INFO - > Epoch 49: took 76.6s (avg 78.3s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:22:40,168 - INFO - train: {'epoch': 50, 'time_epoch': 66.30002, 'eta': 3401.06018, 'eta_hours': 0.94474, 'loss': 0.10595549, 'lr': 5.413e-05, 'params': 451793, 'time_iter': 0.06443, 'accuracy': 0.9693, 'precision': 0.69072, 'recall': 0.3263, 'f1': 0.44322, 'auc': 0.86434}
2025-08-17 08:22:44,409 - INFO - val: {'epoch': 50, 'time_epoch': 4.20875, 'loss': 0.07321895, 'lr': 0, 'params': 451793, 'time_iter': 0.03263, 'accuracy': 0.98128, 'precision': 0.55263, 'recall': 0.25926, 'f1': 0.35294, 'auc': 0.81021}
2025-08-17 08:22:48,706 - INFO - test: {'epoch': 50, 'time_epoch': 4.27914, 'loss': 0.11417409, 'lr': 0, 'params': 451793, 'time_iter': 0.03317, 'accuracy': 0.97107, 'precision': 0.57971, 'recall': 0.30769, 'f1': 0.40201, 'auc': 0.77115}
2025-08-17 08:22:48,708 - INFO - > Epoch 50: took 74.9s (avg 78.2s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:23:56,960 - INFO - train: {'epoch': 51, 'time_epoch': 68.15842, 'eta': 3330.49604, 'eta_hours': 0.92514, 'loss': 0.10550275, 'lr': 5.248e-05, 'params': 451793, 'time_iter': 0.06624, 'accuracy': 0.96942, 'precision': 0.70696, 'recall': 0.31331, 'f1': 0.4342, 'auc': 0.86669}
2025-08-17 08:24:01,263 - INFO - val: {'epoch': 51, 'time_epoch': 4.27938, 'loss': 0.07726263, 'lr': 0, 'params': 451793, 'time_iter': 0.03317, 'accuracy': 0.98201, 'precision': 0.5814, 'recall': 0.30864, 'f1': 0.40323, 'auc': 0.7805}
2025-08-17 08:24:05,515 - INFO - test: {'epoch': 51, 'time_epoch': 4.23478, 'loss': 0.12175607, 'lr': 0, 'params': 451793, 'time_iter': 0.03283, 'accuracy': 0.96791, 'precision': 0.4878, 'recall': 0.30769, 'f1': 0.37736, 'auc': 0.74807}
2025-08-17 08:24:05,519 - INFO - > Epoch 51: took 76.8s (avg 78.2s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:25:13,396 - INFO - train: {'epoch': 52, 'time_epoch': 67.74907, 'eta': 3259.65968, 'eta_hours': 0.90546, 'loss': 0.10385312, 'lr': 5.083e-05, 'params': 451793, 'time_iter': 0.06584, 'accuracy': 0.96985, 'precision': 0.70134, 'recall': 0.33929, 'f1': 0.45733, 'auc': 0.87325}
2025-08-17 08:25:17,732 - INFO - val: {'epoch': 52, 'time_epoch': 4.31335, 'loss': 0.0745754, 'lr': 0, 'params': 451793, 'time_iter': 0.03344, 'accuracy': 0.97982, 'precision': 0.47222, 'recall': 0.20988, 'f1': 0.2906, 'auc': 0.7979}
2025-08-17 08:25:22,095 - INFO - test: {'epoch': 52, 'time_epoch': 4.34534, 'loss': 0.11764942, 'lr': 0, 'params': 451793, 'time_iter': 0.03368, 'accuracy': 0.96742, 'precision': 0.46154, 'recall': 0.18462, 'f1': 0.26374, 'auc': 0.75613}
2025-08-17 08:25:22,097 - INFO - > Epoch 52: took 76.6s (avg 78.2s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:26:29,712 - INFO - train: {'epoch': 53, 'time_epoch': 67.53154, 'eta': 3188.75237, 'eta_hours': 0.88576, 'loss': 0.10418607, 'lr': 4.917e-05, 'params': 451793, 'time_iter': 0.06563, 'accuracy': 0.96973, 'precision': 0.70068, 'recall': 0.33442, 'f1': 0.45275, 'auc': 0.86772}
2025-08-17 08:26:33,924 - INFO - val: {'epoch': 53, 'time_epoch': 4.18724, 'loss': 0.06906069, 'lr': 0, 'params': 451793, 'time_iter': 0.03246, 'accuracy': 0.98298, 'precision': 0.7037, 'recall': 0.23457, 'f1': 0.35185, 'auc': 0.80961}
2025-08-17 08:26:38,225 - INFO - test: {'epoch': 53, 'time_epoch': 4.28326, 'loss': 0.11503537, 'lr': 0, 'params': 451793, 'time_iter': 0.0332, 'accuracy': 0.97155, 'precision': 0.60656, 'recall': 0.28462, 'f1': 0.38743, 'auc': 0.75434}
2025-08-17 08:26:38,227 - INFO - > Epoch 53: took 76.1s (avg 78.1s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:27:46,322 - INFO - train: {'epoch': 54, 'time_epoch': 68.01098, 'eta': 3118.36007, 'eta_hours': 0.86621, 'loss': 0.10365909, 'lr': 4.752e-05, 'params': 451793, 'time_iter': 0.06609, 'accuracy': 0.96976, 'precision': 0.69916, 'recall': 0.33766, 'f1': 0.45539, 'auc': 0.87358}
2025-08-17 08:27:50,656 - INFO - val: {'epoch': 54, 'time_epoch': 4.31074, 'loss': 0.07494395, 'lr': 0, 'params': 451793, 'time_iter': 0.03342, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.2963, 'f1': 0.37209, 'auc': 0.79841}
2025-08-17 08:27:54,958 - INFO - test: {'epoch': 54, 'time_epoch': 4.28341, 'loss': 0.11936399, 'lr': 0, 'params': 451793, 'time_iter': 0.0332, 'accuracy': 0.96766, 'precision': 0.48352, 'recall': 0.33846, 'f1': 0.39819, 'auc': 0.7559}
2025-08-17 08:27:54,961 - INFO - > Epoch 54: took 76.7s (avg 78.1s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:29:02,664 - INFO - train: {'epoch': 55, 'time_epoch': 67.61921, 'eta': 3047.745, 'eta_hours': 0.8466, 'loss': 0.10309616, 'lr': 4.587e-05, 'params': 451793, 'time_iter': 0.06571, 'accuracy': 0.96991, 'precision': 0.69329, 'recall': 0.35227, 'f1': 0.46717, 'auc': 0.87769}
2025-08-17 08:29:07,035 - INFO - val: {'epoch': 55, 'time_epoch': 4.34734, 'loss': 0.07349181, 'lr': 0, 'params': 451793, 'time_iter': 0.0337, 'accuracy': 0.98201, 'precision': 0.6, 'recall': 0.25926, 'f1': 0.36207, 'auc': 0.7974}
2025-08-17 08:29:11,395 - INFO - test: {'epoch': 55, 'time_epoch': 4.34064, 'loss': 0.11886979, 'lr': 0, 'params': 451793, 'time_iter': 0.03365, 'accuracy': 0.96961, 'precision': 0.53333, 'recall': 0.30769, 'f1': 0.39024, 'auc': 0.7477}
2025-08-17 08:29:11,398 - INFO - > Epoch 55: took 76.4s (avg 78.1s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:30:19,949 - INFO - train: {'epoch': 56, 'time_epoch': 68.46224, 'eta': 2977.87102, 'eta_hours': 0.82719, 'loss': 0.10362906, 'lr': 4.423e-05, 'params': 451793, 'time_iter': 0.06653, 'accuracy': 0.97021, 'precision': 0.72183, 'recall': 0.33279, 'f1': 0.45556, 'auc': 0.87109}
2025-08-17 08:30:24,296 - INFO - val: {'epoch': 56, 'time_epoch': 4.32158, 'loss': 0.07173559, 'lr': 0, 'params': 451793, 'time_iter': 0.0335, 'accuracy': 0.98322, 'precision': 0.64286, 'recall': 0.33333, 'f1': 0.43902, 'auc': 0.79785}
2025-08-17 08:30:28,613 - INFO - test: {'epoch': 56, 'time_epoch': 4.29989, 'loss': 0.11943961, 'lr': 0, 'params': 451793, 'time_iter': 0.03333, 'accuracy': 0.96912, 'precision': 0.51948, 'recall': 0.30769, 'f1': 0.38647, 'auc': 0.74738}
2025-08-17 08:30:28,616 - INFO - > Epoch 56: took 77.2s (avg 78.1s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:31:37,191 - INFO - train: {'epoch': 57, 'time_epoch': 68.48976, 'eta': 2908.06565, 'eta_hours': 0.8078, 'loss': 0.10398856, 'lr': 4.259e-05, 'params': 451793, 'time_iter': 0.06656, 'accuracy': 0.9703, 'precision': 0.71721, 'recall': 0.34172, 'f1': 0.46289, 'auc': 0.86884}
2025-08-17 08:31:41,417 - INFO - val: {'epoch': 57, 'time_epoch': 4.20319, 'loss': 0.07400601, 'lr': 0, 'params': 451793, 'time_iter': 0.03258, 'accuracy': 0.98128, 'precision': 0.54545, 'recall': 0.2963, 'f1': 0.384, 'auc': 0.80609}
2025-08-17 08:31:45,611 - INFO - test: {'epoch': 57, 'time_epoch': 4.17698, 'loss': 0.1201638, 'lr': 0, 'params': 451793, 'time_iter': 0.03238, 'accuracy': 0.96864, 'precision': 0.50562, 'recall': 0.34615, 'f1': 0.41096, 'auc': 0.75984}
2025-08-17 08:31:45,614 - INFO - > Epoch 57: took 77.0s (avg 78.0s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:32:53,112 - INFO - train: {'epoch': 58, 'time_epoch': 67.41553, 'eta': 2837.55838, 'eta_hours': 0.78821, 'loss': 0.10229909, 'lr': 4.096e-05, 'params': 451793, 'time_iter': 0.06552, 'accuracy': 0.9707, 'precision': 0.73183, 'recall': 0.34334, 'f1': 0.4674, 'auc': 0.87615}
2025-08-17 08:32:57,230 - INFO - val: {'epoch': 58, 'time_epoch': 4.09487, 'loss': 0.07065554, 'lr': 0, 'params': 451793, 'time_iter': 0.03174, 'accuracy': 0.98249, 'precision': 0.62162, 'recall': 0.28395, 'f1': 0.38983, 'auc': 0.8094}
2025-08-17 08:33:01,383 - INFO - test: {'epoch': 58, 'time_epoch': 4.13509, 'loss': 0.11706114, 'lr': 0, 'params': 451793, 'time_iter': 0.03205, 'accuracy': 0.96912, 'precision': 0.52055, 'recall': 0.29231, 'f1': 0.37438, 'auc': 0.75921}
2025-08-17 08:33:01,385 - INFO - > Epoch 58: took 75.8s (avg 78.0s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:34:09,459 - INFO - train: {'epoch': 59, 'time_epoch': 67.99235, 'eta': 2767.53871, 'eta_hours': 0.76876, 'loss': 0.10284764, 'lr': 3.934e-05, 'params': 451793, 'time_iter': 0.06608, 'accuracy': 0.97018, 'precision': 0.71092, 'recall': 0.34334, 'f1': 0.46305, 'auc': 0.87524}
2025-08-17 08:34:13,730 - INFO - val: {'epoch': 59, 'time_epoch': 4.24907, 'loss': 0.07834182, 'lr': 0, 'params': 451793, 'time_iter': 0.03294, 'accuracy': 0.98031, 'precision': 0.5, 'recall': 0.24691, 'f1': 0.33058, 'auc': 0.77586}
2025-08-17 08:34:18,056 - INFO - test: {'epoch': 59, 'time_epoch': 4.30791, 'loss': 0.1196441, 'lr': 0, 'params': 451793, 'time_iter': 0.03339, 'accuracy': 0.96888, 'precision': 0.51316, 'recall': 0.3, 'f1': 0.37864, 'auc': 0.7597}
2025-08-17 08:34:18,059 - INFO - > Epoch 59: took 76.7s (avg 78.0s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:35:26,090 - INFO - train: {'epoch': 60, 'time_epoch': 67.94771, 'eta': 2697.55697, 'eta_hours': 0.74932, 'loss': 0.10124561, 'lr': 3.773e-05, 'params': 451793, 'time_iter': 0.06603, 'accuracy': 0.97055, 'precision': 0.72027, 'recall': 0.34903, 'f1': 0.4702, 'auc': 0.88181}
2025-08-17 08:35:30,455 - INFO - val: {'epoch': 60, 'time_epoch': 4.34025, 'loss': 0.07348673, 'lr': 0, 'params': 451793, 'time_iter': 0.03365, 'accuracy': 0.98152, 'precision': 0.55814, 'recall': 0.2963, 'f1': 0.3871, 'auc': 0.79713}
2025-08-17 08:35:34,808 - INFO - test: {'epoch': 60, 'time_epoch': 4.33487, 'loss': 0.11908684, 'lr': 0, 'params': 451793, 'time_iter': 0.0336, 'accuracy': 0.97009, 'precision': 0.54217, 'recall': 0.34615, 'f1': 0.42254, 'auc': 0.75758}
2025-08-17 08:35:34,810 - INFO - > Epoch 60: took 76.8s (avg 78.0s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:36:42,296 - INFO - train: {'epoch': 61, 'time_epoch': 67.40261, 'eta': 2627.30675, 'eta_hours': 0.72981, 'loss': 0.10173382, 'lr': 3.613e-05, 'params': 451793, 'time_iter': 0.0655, 'accuracy': 0.97079, 'precision': 0.72927, 'recall': 0.34984, 'f1': 0.47285, 'auc': 0.87902}
2025-08-17 08:36:46,649 - INFO - val: {'epoch': 61, 'time_epoch': 4.33, 'loss': 0.07300013, 'lr': 0, 'params': 451793, 'time_iter': 0.03357, 'accuracy': 0.98201, 'precision': 0.6129, 'recall': 0.23457, 'f1': 0.33929, 'auc': 0.79487}
2025-08-17 08:36:51,003 - INFO - test: {'epoch': 61, 'time_epoch': 4.33515, 'loss': 0.11812961, 'lr': 0, 'params': 451793, 'time_iter': 0.03361, 'accuracy': 0.96985, 'precision': 0.54839, 'recall': 0.26154, 'f1': 0.35417, 'auc': 0.75404}
2025-08-17 08:36:51,005 - INFO - > Epoch 61: took 76.2s (avg 77.9s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:37:58,541 - INFO - train: {'epoch': 62, 'time_epoch': 67.44923, 'eta': 2557.17431, 'eta_hours': 0.71033, 'loss': 0.1014734, 'lr': 3.455e-05, 'params': 451793, 'time_iter': 0.06555, 'accuracy': 0.97012, 'precision': 0.70785, 'recall': 0.34416, 'f1': 0.46313, 'auc': 0.87981}
2025-08-17 08:38:02,791 - INFO - val: {'epoch': 62, 'time_epoch': 4.22914, 'loss': 0.07104161, 'lr': 0, 'params': 451793, 'time_iter': 0.03278, 'accuracy': 0.98322, 'precision': 0.7, 'recall': 0.25926, 'f1': 0.37838, 'auc': 0.81121}
2025-08-17 08:38:07,036 - INFO - test: {'epoch': 62, 'time_epoch': 4.22671, 'loss': 0.11985991, 'lr': 0, 'params': 451793, 'time_iter': 0.03277, 'accuracy': 0.96937, 'precision': 0.52703, 'recall': 0.3, 'f1': 0.38235, 'auc': 0.7471}
2025-08-17 08:38:07,038 - INFO - > Epoch 62: took 76.0s (avg 77.9s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:39:14,171 - INFO - train: {'epoch': 63, 'time_epoch': 67.0455, 'eta': 2486.89862, 'eta_hours': 0.69081, 'loss': 0.10082661, 'lr': 3.299e-05, 'params': 451793, 'time_iter': 0.06516, 'accuracy': 0.97073, 'precision': 0.72379, 'recall': 0.35308, 'f1': 0.47463, 'auc': 0.87989}
2025-08-17 08:39:18,401 - INFO - val: {'epoch': 63, 'time_epoch': 4.20688, 'loss': 0.07292184, 'lr': 0, 'params': 451793, 'time_iter': 0.03261, 'accuracy': 0.98201, 'precision': 0.58537, 'recall': 0.2963, 'f1': 0.39344, 'auc': 0.80848}
2025-08-17 08:39:22,729 - INFO - test: {'epoch': 63, 'time_epoch': 4.3099, 'loss': 0.11820122, 'lr': 0, 'params': 451793, 'time_iter': 0.03341, 'accuracy': 0.96912, 'precision': 0.51852, 'recall': 0.32308, 'f1': 0.3981, 'auc': 0.76159}
2025-08-17 08:39:22,731 - INFO - > Epoch 63: took 75.7s (avg 77.9s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:40:30,599 - INFO - train: {'epoch': 64, 'time_epoch': 67.77908, 'eta': 2417.11733, 'eta_hours': 0.67142, 'loss': 0.09965897, 'lr': 3.144e-05, 'params': 451793, 'time_iter': 0.06587, 'accuracy': 0.97182, 'precision': 0.75124, 'recall': 0.37013, 'f1': 0.49592, 'auc': 0.87973}
2025-08-17 08:40:34,863 - INFO - val: {'epoch': 64, 'time_epoch': 4.24043, 'loss': 0.07218758, 'lr': 0, 'params': 451793, 'time_iter': 0.03287, 'accuracy': 0.98055, 'precision': 0.5098, 'recall': 0.32099, 'f1': 0.39394, 'auc': 0.81713}
2025-08-17 08:40:39,134 - INFO - test: {'epoch': 64, 'time_epoch': 4.25431, 'loss': 0.1180755, 'lr': 0, 'params': 451793, 'time_iter': 0.03298, 'accuracy': 0.96888, 'precision': 0.51111, 'recall': 0.35385, 'f1': 0.41818, 'auc': 0.76104}
2025-08-17 08:40:39,137 - INFO - > Epoch 64: took 76.4s (avg 77.8s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:41:46,111 - INFO - train: {'epoch': 65, 'time_epoch': 66.8952, 'eta': 2346.94138, 'eta_hours': 0.65193, 'loss': 0.10073489, 'lr': 2.992e-05, 'params': 451793, 'time_iter': 0.06501, 'accuracy': 0.97049, 'precision': 0.71429, 'recall': 0.35308, 'f1': 0.47257, 'auc': 0.88174}
2025-08-17 08:41:50,254 - INFO - val: {'epoch': 65, 'time_epoch': 4.12166, 'loss': 0.0715941, 'lr': 0, 'params': 451793, 'time_iter': 0.03195, 'accuracy': 0.98225, 'precision': 0.6, 'recall': 0.2963, 'f1': 0.39669, 'auc': 0.8046}
2025-08-17 08:41:54,424 - INFO - test: {'epoch': 65, 'time_epoch': 4.15284, 'loss': 0.11722401, 'lr': 0, 'params': 451793, 'time_iter': 0.03219, 'accuracy': 0.97034, 'precision': 0.55263, 'recall': 0.32308, 'f1': 0.40777, 'auc': 0.75956}
2025-08-17 08:41:54,427 - INFO - > Epoch 65: took 75.3s (avg 77.8s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:43:02,860 - INFO - train: {'epoch': 66, 'time_epoch': 68.34714, 'eta': 2277.5785, 'eta_hours': 0.63266, 'loss': 0.09987716, 'lr': 2.841e-05, 'params': 451793, 'time_iter': 0.06642, 'accuracy': 0.97052, 'precision': 0.71475, 'recall': 0.3539, 'f1': 0.4734, 'auc': 0.88767}
2025-08-17 08:43:06,912 - INFO - val: {'epoch': 66, 'time_epoch': 4.02954, 'loss': 0.0744308, 'lr': 0, 'params': 451793, 'time_iter': 0.03124, 'accuracy': 0.98152, 'precision': 0.55814, 'recall': 0.2963, 'f1': 0.3871, 'auc': 0.80627}
2025-08-17 08:43:10,995 - INFO - test: {'epoch': 66, 'time_epoch': 4.06597, 'loss': 0.11983495, 'lr': 0, 'params': 451793, 'time_iter': 0.03152, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.33077, 'f1': 0.39815, 'auc': 0.76001}
2025-08-17 08:43:10,998 - INFO - > Epoch 66: took 76.6s (avg 77.8s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:44:17,483 - INFO - train: {'epoch': 67, 'time_epoch': 66.39762, 'eta': 2207.32808, 'eta_hours': 0.61315, 'loss': 0.09921145, 'lr': 2.693e-05, 'params': 451793, 'time_iter': 0.06453, 'accuracy': 0.9717, 'precision': 0.73626, 'recall': 0.38068, 'f1': 0.50187, 'auc': 0.88911}
2025-08-17 08:44:21,759 - INFO - val: {'epoch': 67, 'time_epoch': 4.2512, 'loss': 0.07332259, 'lr': 0, 'params': 451793, 'time_iter': 0.03296, 'accuracy': 0.98201, 'precision': 0.58537, 'recall': 0.2963, 'f1': 0.39344, 'auc': 0.80368}
2025-08-17 08:44:26,008 - INFO - test: {'epoch': 67, 'time_epoch': 4.23083, 'loss': 0.11822306, 'lr': 0, 'params': 451793, 'time_iter': 0.0328, 'accuracy': 0.96864, 'precision': 0.50602, 'recall': 0.32308, 'f1': 0.39437, 'auc': 0.7654}
2025-08-17 08:44:26,010 - INFO - > Epoch 67: took 75.0s (avg 77.7s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:45:33,302 - INFO - train: {'epoch': 68, 'time_epoch': 67.21058, 'eta': 2137.55456, 'eta_hours': 0.59377, 'loss': 0.09935361, 'lr': 2.548e-05, 'params': 451793, 'time_iter': 0.06532, 'accuracy': 0.97176, 'precision': 0.74163, 'recall': 0.37744, 'f1': 0.50027, 'auc': 0.88365}
2025-08-17 08:45:37,400 - INFO - val: {'epoch': 68, 'time_epoch': 4.07691, 'loss': 0.07038656, 'lr': 0, 'params': 451793, 'time_iter': 0.0316, 'accuracy': 0.98249, 'precision': 0.61538, 'recall': 0.2963, 'f1': 0.4, 'auc': 0.81098}
2025-08-17 08:45:41,527 - INFO - test: {'epoch': 68, 'time_epoch': 4.10961, 'loss': 0.11646198, 'lr': 0, 'params': 451793, 'time_iter': 0.03186, 'accuracy': 0.97009, 'precision': 0.55224, 'recall': 0.28462, 'f1': 0.37563, 'auc': 0.75672}
2025-08-17 08:45:41,530 - INFO - > Epoch 68: took 75.5s (avg 77.7s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:46:49,683 - INFO - train: {'epoch': 69, 'time_epoch': 68.0689, 'eta': 2068.22213, 'eta_hours': 0.57451, 'loss': 0.1003794, 'lr': 2.405e-05, 'params': 451793, 'time_iter': 0.06615, 'accuracy': 0.97088, 'precision': 0.72459, 'recall': 0.35877, 'f1': 0.47991, 'auc': 0.88242}
2025-08-17 08:46:53,947 - INFO - val: {'epoch': 69, 'time_epoch': 4.24153, 'loss': 0.07095094, 'lr': 0, 'params': 451793, 'time_iter': 0.03288, 'accuracy': 0.98201, 'precision': 0.58537, 'recall': 0.2963, 'f1': 0.39344, 'auc': 0.81805}
2025-08-17 08:46:58,196 - INFO - test: {'epoch': 69, 'time_epoch': 4.23152, 'loss': 0.11762906, 'lr': 0, 'params': 451793, 'time_iter': 0.0328, 'accuracy': 0.96937, 'precision': 0.52778, 'recall': 0.29231, 'f1': 0.37624, 'auc': 0.76102}
2025-08-17 08:46:58,199 - INFO - > Epoch 69: took 76.7s (avg 77.7s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:48:05,361 - INFO - train: {'epoch': 70, 'time_epoch': 67.0749, 'eta': 1998.51929, 'eta_hours': 0.55514, 'loss': 0.09818016, 'lr': 2.265e-05, 'params': 451793, 'time_iter': 0.06518, 'accuracy': 0.97152, 'precision': 0.72939, 'recall': 0.38068, 'f1': 0.50027, 'auc': 0.88848}
2025-08-17 08:48:09,599 - INFO - val: {'epoch': 70, 'time_epoch': 4.21486, 'loss': 0.07680732, 'lr': 0, 'params': 451793, 'time_iter': 0.03267, 'accuracy': 0.98104, 'precision': 0.53333, 'recall': 0.2963, 'f1': 0.38095, 'auc': 0.78735}
2025-08-17 08:48:13,844 - INFO - test: {'epoch': 70, 'time_epoch': 4.22673, 'loss': 0.12127246, 'lr': 0, 'params': 451793, 'time_iter': 0.03277, 'accuracy': 0.96815, 'precision': 0.49438, 'recall': 0.33846, 'f1': 0.40183, 'auc': 0.74736}
2025-08-17 08:48:13,847 - INFO - > Epoch 70: took 75.6s (avg 77.7s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:49:21,225 - INFO - train: {'epoch': 71, 'time_epoch': 67.29317, 'eta': 1928.97433, 'eta_hours': 0.53583, 'loss': 0.098762, 'lr': 2.128e-05, 'params': 451793, 'time_iter': 0.0654, 'accuracy': 0.97122, 'precision': 0.73322, 'recall': 0.36364, 'f1': 0.48616, 'auc': 0.88569}
2025-08-17 08:49:25,362 - INFO - val: {'epoch': 71, 'time_epoch': 4.11484, 'loss': 0.07171099, 'lr': 0, 'params': 451793, 'time_iter': 0.0319, 'accuracy': 0.98322, 'precision': 0.66667, 'recall': 0.2963, 'f1': 0.41026, 'auc': 0.80011}
2025-08-17 08:49:29,464 - INFO - test: {'epoch': 71, 'time_epoch': 4.08515, 'loss': 0.11645318, 'lr': 0, 'params': 451793, 'time_iter': 0.03167, 'accuracy': 0.97107, 'precision': 0.58209, 'recall': 0.3, 'f1': 0.39594, 'auc': 0.76262}
2025-08-17 08:49:29,466 - INFO - > Epoch 71: took 75.6s (avg 77.6s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:50:37,887 - INFO - train: {'epoch': 72, 'time_epoch': 68.33705, 'eta': 1859.87716, 'eta_hours': 0.51663, 'loss': 0.09749309, 'lr': 1.995e-05, 'params': 451793, 'time_iter': 0.06641, 'accuracy': 0.97161, 'precision': 0.72783, 'recall': 0.38636, 'f1': 0.50477, 'auc': 0.89139}
2025-08-17 08:50:42,262 - INFO - val: {'epoch': 72, 'time_epoch': 4.35327, 'loss': 0.07054471, 'lr': 0, 'params': 451793, 'time_iter': 0.03375, 'accuracy': 0.98347, 'precision': 0.67568, 'recall': 0.30864, 'f1': 0.42373, 'auc': 0.79848}
2025-08-17 08:50:46,630 - INFO - test: {'epoch': 72, 'time_epoch': 4.3496, 'loss': 0.11688455, 'lr': 0, 'params': 451793, 'time_iter': 0.03372, 'accuracy': 0.96985, 'precision': 0.54545, 'recall': 0.27692, 'f1': 0.36735, 'auc': 0.76322}
2025-08-17 08:50:46,632 - INFO - > Epoch 72: took 77.2s (avg 77.6s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:51:53,999 - INFO - train: {'epoch': 73, 'time_epoch': 67.27867, 'eta': 1790.42866, 'eta_hours': 0.49734, 'loss': 0.09708546, 'lr': 1.864e-05, 'params': 451793, 'time_iter': 0.06538, 'accuracy': 0.97198, 'precision': 0.74448, 'recall': 0.38312, 'f1': 0.50589, 'auc': 0.89099}
2025-08-17 08:51:58,150 - INFO - val: {'epoch': 73, 'time_epoch': 4.12836, 'loss': 0.07427015, 'lr': 0, 'params': 451793, 'time_iter': 0.032, 'accuracy': 0.98201, 'precision': 0.58974, 'recall': 0.28395, 'f1': 0.38333, 'auc': 0.79877}
2025-08-17 08:52:02,297 - INFO - test: {'epoch': 73, 'time_epoch': 4.13015, 'loss': 0.11869792, 'lr': 0, 'params': 451793, 'time_iter': 0.03202, 'accuracy': 0.96888, 'precision': 0.51351, 'recall': 0.29231, 'f1': 0.37255, 'auc': 0.76431}
2025-08-17 08:52:02,299 - INFO - > Epoch 73: took 75.7s (avg 77.6s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:53:09,475 - INFO - train: {'epoch': 74, 'time_epoch': 67.09258, 'eta': 1720.976, 'eta_hours': 0.47805, 'loss': 0.0983395, 'lr': 1.737e-05, 'params': 451793, 'time_iter': 0.0652, 'accuracy': 0.97176, 'precision': 0.75548, 'recall': 0.36364, 'f1': 0.49096, 'auc': 0.89039}
2025-08-17 08:53:13,568 - INFO - val: {'epoch': 74, 'time_epoch': 4.06991, 'loss': 0.07563925, 'lr': 0, 'params': 451793, 'time_iter': 0.03155, 'accuracy': 0.98055, 'precision': 0.51064, 'recall': 0.2963, 'f1': 0.375, 'auc': 0.80082}
2025-08-17 08:53:17,650 - INFO - test: {'epoch': 74, 'time_epoch': 4.06594, 'loss': 0.12245924, 'lr': 0, 'params': 451793, 'time_iter': 0.03152, 'accuracy': 0.9662, 'precision': 0.45631, 'recall': 0.36154, 'f1': 0.40343, 'auc': 0.7614}
2025-08-17 08:53:17,653 - INFO - > Epoch 74: took 75.4s (avg 77.6s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:54:26,443 - INFO - train: {'epoch': 75, 'time_epoch': 68.69835, 'eta': 1652.09254, 'eta_hours': 0.45891, 'loss': 0.09889455, 'lr': 1.614e-05, 'params': 451793, 'time_iter': 0.06676, 'accuracy': 0.97122, 'precision': 0.72231, 'recall': 0.37581, 'f1': 0.49439, 'auc': 0.88876}
2025-08-17 08:54:30,698 - INFO - val: {'epoch': 75, 'time_epoch': 4.23187, 'loss': 0.07094491, 'lr': 0, 'params': 451793, 'time_iter': 0.03281, 'accuracy': 0.98201, 'precision': 0.6129, 'recall': 0.23457, 'f1': 0.33929, 'auc': 0.7962}
2025-08-17 08:54:34,893 - INFO - test: {'epoch': 75, 'time_epoch': 4.17704, 'loss': 0.11919034, 'lr': 0, 'params': 451793, 'time_iter': 0.03238, 'accuracy': 0.97034, 'precision': 0.58, 'recall': 0.22308, 'f1': 0.32222, 'auc': 0.76155}
2025-08-17 08:54:34,895 - INFO - > Epoch 75: took 77.2s (avg 77.6s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:55:42,402 - INFO - train: {'epoch': 76, 'time_epoch': 67.42287, 'eta': 1582.83289, 'eta_hours': 0.43968, 'loss': 0.09756028, 'lr': 1.494e-05, 'params': 451793, 'time_iter': 0.06552, 'accuracy': 0.97134, 'precision': 0.72828, 'recall': 0.37419, 'f1': 0.49437, 'auc': 0.8963}
2025-08-17 08:55:46,548 - INFO - val: {'epoch': 76, 'time_epoch': 4.12242, 'loss': 0.07455235, 'lr': 0, 'params': 451793, 'time_iter': 0.03196, 'accuracy': 0.98104, 'precision': 0.53333, 'recall': 0.2963, 'f1': 0.38095, 'auc': 0.79173}
2025-08-17 08:55:50,675 - INFO - test: {'epoch': 76, 'time_epoch': 4.10912, 'loss': 0.12159692, 'lr': 0, 'params': 451793, 'time_iter': 0.03185, 'accuracy': 0.9662, 'precision': 0.45361, 'recall': 0.33846, 'f1': 0.38767, 'auc': 0.75794}
2025-08-17 08:55:50,677 - INFO - > Epoch 76: took 75.8s (avg 77.5s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:56:58,373 - INFO - train: {'epoch': 77, 'time_epoch': 67.61282, 'eta': 1513.67391, 'eta_hours': 0.42046, 'loss': 0.0967215, 'lr': 1.378e-05, 'params': 451793, 'time_iter': 0.06571, 'accuracy': 0.97192, 'precision': 0.73123, 'recall': 0.39529, 'f1': 0.51317, 'auc': 0.89263}
2025-08-17 08:57:02,571 - INFO - val: {'epoch': 77, 'time_epoch': 4.17734, 'loss': 0.07267927, 'lr': 0, 'params': 451793, 'time_iter': 0.03238, 'accuracy': 0.98249, 'precision': 0.62162, 'recall': 0.28395, 'f1': 0.38983, 'auc': 0.79742}
2025-08-17 08:57:06,754 - INFO - test: {'epoch': 77, 'time_epoch': 4.16478, 'loss': 0.11859154, 'lr': 0, 'params': 451793, 'time_iter': 0.03229, 'accuracy': 0.96937, 'precision': 0.52439, 'recall': 0.33077, 'f1': 0.40566, 'auc': 0.76635}
2025-08-17 08:57:06,756 - INFO - > Epoch 77: took 76.1s (avg 77.5s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:58:14,108 - INFO - train: {'epoch': 78, 'time_epoch': 67.26782, 'eta': 1444.46237, 'eta_hours': 0.40124, 'loss': 0.09658332, 'lr': 1.266e-05, 'params': 451793, 'time_iter': 0.06537, 'accuracy': 0.97219, 'precision': 0.75279, 'recall': 0.38312, 'f1': 0.5078, 'auc': 0.89328}
2025-08-17 08:58:18,373 - INFO - val: {'epoch': 78, 'time_epoch': 4.24355, 'loss': 0.07035382, 'lr': 0, 'params': 451793, 'time_iter': 0.0329, 'accuracy': 0.98201, 'precision': 0.58537, 'recall': 0.2963, 'f1': 0.39344, 'auc': 0.81121}
2025-08-17 08:58:22,626 - INFO - test: {'epoch': 78, 'time_epoch': 4.23563, 'loss': 0.11926483, 'lr': 0, 'params': 451793, 'time_iter': 0.03283, 'accuracy': 0.96961, 'precision': 0.53165, 'recall': 0.32308, 'f1': 0.40191, 'auc': 0.76081}
2025-08-17 08:58:22,628 - INFO - > Epoch 78: took 75.9s (avg 77.5s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 08:59:29,812 - INFO - train: {'epoch': 79, 'time_epoch': 67.10345, 'eta': 1375.25833, 'eta_hours': 0.38202, 'loss': 0.09747033, 'lr': 1.158e-05, 'params': 451793, 'time_iter': 0.06521, 'accuracy': 0.97176, 'precision': 0.73201, 'recall': 0.38799, 'f1': 0.50716, 'auc': 0.89157}
2025-08-17 08:59:33,865 - INFO - val: {'epoch': 79, 'time_epoch': 4.03222, 'loss': 0.0751095, 'lr': 0, 'params': 451793, 'time_iter': 0.03126, 'accuracy': 0.98152, 'precision': 0.55814, 'recall': 0.2963, 'f1': 0.3871, 'auc': 0.78916}
2025-08-17 08:59:37,933 - INFO - test: {'epoch': 79, 'time_epoch': 4.05194, 'loss': 0.12138251, 'lr': 0, 'params': 451793, 'time_iter': 0.03141, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.33846, 'f1': 0.40367, 'auc': 0.7626}
2025-08-17 08:59:37,936 - INFO - > Epoch 79: took 75.3s (avg 77.5s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:00:45,790 - INFO - train: {'epoch': 80, 'time_epoch': 67.76887, 'eta': 1306.26224, 'eta_hours': 0.36285, 'loss': 0.09678321, 'lr': 1.054e-05, 'params': 451793, 'time_iter': 0.06586, 'accuracy': 0.97204, 'precision': 0.74224, 'recall': 0.38799, 'f1': 0.50959, 'auc': 0.8953}
2025-08-17 09:00:50,138 - INFO - val: {'epoch': 80, 'time_epoch': 4.32555, 'loss': 0.07102718, 'lr': 0, 'params': 451793, 'time_iter': 0.03353, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.80195}
2025-08-17 09:00:54,479 - INFO - test: {'epoch': 80, 'time_epoch': 4.3229, 'loss': 0.11959926, 'lr': 0, 'params': 451793, 'time_iter': 0.03351, 'accuracy': 0.96937, 'precision': 0.52941, 'recall': 0.27692, 'f1': 0.36364, 'auc': 0.76111}
2025-08-17 09:00:54,481 - INFO - > Epoch 80: took 76.5s (avg 77.5s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:02:01,804 - INFO - train: {'epoch': 81, 'time_epoch': 67.20825, 'eta': 1237.17303, 'eta_hours': 0.34366, 'loss': 0.09617169, 'lr': 9.55e-06, 'params': 451793, 'time_iter': 0.06531, 'accuracy': 0.97189, 'precision': 0.74326, 'recall': 0.38068, 'f1': 0.50349, 'auc': 0.8931}
2025-08-17 09:02:06,086 - INFO - val: {'epoch': 81, 'time_epoch': 4.25965, 'loss': 0.07274131, 'lr': 0, 'params': 451793, 'time_iter': 0.03302, 'accuracy': 0.98274, 'precision': 0.61905, 'recall': 0.32099, 'f1': 0.42276, 'auc': 0.79583}
2025-08-17 09:02:10,320 - INFO - test: {'epoch': 81, 'time_epoch': 4.21678, 'loss': 0.12079039, 'lr': 0, 'params': 451793, 'time_iter': 0.03269, 'accuracy': 0.96815, 'precision': 0.49412, 'recall': 0.32308, 'f1': 0.3907, 'auc': 0.75963}
2025-08-17 09:02:10,323 - INFO - > Epoch 81: took 75.8s (avg 77.4s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:03:18,143 - INFO - train: {'epoch': 82, 'time_epoch': 67.73275, 'eta': 1168.23656, 'eta_hours': 0.32451, 'loss': 0.09656073, 'lr': 8.6e-06, 'params': 451793, 'time_iter': 0.06582, 'accuracy': 0.97201, 'precision': 0.74034, 'recall': 0.3888, 'f1': 0.50985, 'auc': 0.89304}
2025-08-17 09:03:22,483 - INFO - val: {'epoch': 82, 'time_epoch': 4.31568, 'loss': 0.07002107, 'lr': 0, 'params': 451793, 'time_iter': 0.03345, 'accuracy': 0.98298, 'precision': 0.65714, 'recall': 0.28395, 'f1': 0.39655, 'auc': 0.81405}
2025-08-17 09:03:26,790 - INFO - test: {'epoch': 82, 'time_epoch': 4.29041, 'loss': 0.1182382, 'lr': 0, 'params': 451793, 'time_iter': 0.03326, 'accuracy': 0.97034, 'precision': 0.55882, 'recall': 0.29231, 'f1': 0.38384, 'auc': 0.76427}
2025-08-17 09:03:26,792 - INFO - > Epoch 82: took 76.5s (avg 77.4s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:04:34,151 - INFO - train: {'epoch': 83, 'time_epoch': 67.27255, 'eta': 1099.24109, 'eta_hours': 0.30534, 'loss': 0.09637042, 'lr': 7.7e-06, 'params': 451793, 'time_iter': 0.06538, 'accuracy': 0.97234, 'precision': 0.75314, 'recall': 0.3888, 'f1': 0.51285, 'auc': 0.89382}
2025-08-17 09:04:38,363 - INFO - val: {'epoch': 83, 'time_epoch': 4.18734, 'loss': 0.07203006, 'lr': 0, 'params': 451793, 'time_iter': 0.03246, 'accuracy': 0.98298, 'precision': 0.65714, 'recall': 0.28395, 'f1': 0.39655, 'auc': 0.79803}
2025-08-17 09:04:42,553 - INFO - test: {'epoch': 83, 'time_epoch': 4.17357, 'loss': 0.11826688, 'lr': 0, 'params': 451793, 'time_iter': 0.03235, 'accuracy': 0.97131, 'precision': 0.59375, 'recall': 0.29231, 'f1': 0.39175, 'auc': 0.76323}
2025-08-17 09:04:42,556 - INFO - > Epoch 83: took 75.8s (avg 77.4s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:05:50,357 - INFO - train: {'epoch': 84, 'time_epoch': 67.71588, 'eta': 1030.3644, 'eta_hours': 0.28621, 'loss': 0.09613069, 'lr': 6.84e-06, 'params': 451793, 'time_iter': 0.06581, 'accuracy': 0.97289, 'precision': 0.77157, 'recall': 0.39205, 'f1': 0.51991, 'auc': 0.89247}
2025-08-17 09:05:54,715 - INFO - val: {'epoch': 84, 'time_epoch': 4.33587, 'loss': 0.07403246, 'lr': 0, 'params': 451793, 'time_iter': 0.03361, 'accuracy': 0.98152, 'precision': 0.55814, 'recall': 0.2963, 'f1': 0.3871, 'auc': 0.7953}
2025-08-17 09:05:59,041 - INFO - test: {'epoch': 84, 'time_epoch': 4.30756, 'loss': 0.12070687, 'lr': 0, 'params': 451793, 'time_iter': 0.03339, 'accuracy': 0.96961, 'precision': 0.53012, 'recall': 0.33846, 'f1': 0.41315, 'auc': 0.76354}
2025-08-17 09:05:59,043 - INFO - > Epoch 84: took 76.5s (avg 77.4s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:07:06,054 - INFO - train: {'epoch': 85, 'time_epoch': 66.9321, 'eta': 961.38712, 'eta_hours': 0.26705, 'loss': 0.09570612, 'lr': 6.03e-06, 'params': 451793, 'time_iter': 0.06505, 'accuracy': 0.97198, 'precision': 0.74219, 'recall': 0.38555, 'f1': 0.50748, 'auc': 0.89772}
2025-08-17 09:07:10,281 - INFO - val: {'epoch': 85, 'time_epoch': 4.20563, 'loss': 0.07228228, 'lr': 0, 'params': 451793, 'time_iter': 0.0326, 'accuracy': 0.98225, 'precision': 0.59524, 'recall': 0.30864, 'f1': 0.4065, 'auc': 0.80295}
2025-08-17 09:07:14,514 - INFO - test: {'epoch': 85, 'time_epoch': 4.21523, 'loss': 0.12047975, 'lr': 0, 'params': 451793, 'time_iter': 0.03268, 'accuracy': 0.96961, 'precision': 0.53012, 'recall': 0.33846, 'f1': 0.41315, 'auc': 0.76261}
2025-08-17 09:07:14,516 - INFO - > Epoch 85: took 75.5s (avg 77.4s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:08:21,773 - INFO - train: {'epoch': 86, 'time_epoch': 67.17561, 'eta': 892.49323, 'eta_hours': 0.24791, 'loss': 0.09701769, 'lr': 5.26e-06, 'params': 451793, 'time_iter': 0.06528, 'accuracy': 0.97198, 'precision': 0.74219, 'recall': 0.38555, 'f1': 0.50748, 'auc': 0.8949}
2025-08-17 09:08:25,911 - INFO - val: {'epoch': 86, 'time_epoch': 4.11655, 'loss': 0.07391844, 'lr': 0, 'params': 451793, 'time_iter': 0.03191, 'accuracy': 0.98201, 'precision': 0.5814, 'recall': 0.30864, 'f1': 0.40323, 'auc': 0.79659}
2025-08-17 09:08:30,038 - INFO - test: {'epoch': 86, 'time_epoch': 4.10954, 'loss': 0.12182646, 'lr': 0, 'params': 451793, 'time_iter': 0.03186, 'accuracy': 0.96864, 'precision': 0.50588, 'recall': 0.33077, 'f1': 0.4, 'auc': 0.76329}
2025-08-17 09:08:30,040 - INFO - > Epoch 86: took 75.5s (avg 77.4s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:09:38,554 - INFO - train: {'epoch': 87, 'time_epoch': 68.42703, 'eta': 823.80905, 'eta_hours': 0.22884, 'loss': 0.09488435, 'lr': 4.55e-06, 'params': 451793, 'time_iter': 0.0665, 'accuracy': 0.97243, 'precision': 0.74809, 'recall': 0.39773, 'f1': 0.51934, 'auc': 0.89938}
2025-08-17 09:09:42,817 - INFO - val: {'epoch': 87, 'time_epoch': 4.23858, 'loss': 0.07335086, 'lr': 0, 'params': 451793, 'time_iter': 0.03286, 'accuracy': 0.98225, 'precision': 0.6, 'recall': 0.2963, 'f1': 0.39669, 'auc': 0.79909}
2025-08-17 09:09:47,078 - INFO - test: {'epoch': 87, 'time_epoch': 4.24353, 'loss': 0.12082363, 'lr': 0, 'params': 451793, 'time_iter': 0.0329, 'accuracy': 0.96985, 'precision': 0.53659, 'recall': 0.33846, 'f1': 0.41509, 'auc': 0.7616}
2025-08-17 09:09:47,081 - INFO - > Epoch 87: took 77.0s (avg 77.4s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:10:54,802 - INFO - train: {'epoch': 88, 'time_epoch': 67.63937, 'eta': 755.03329, 'eta_hours': 0.20973, 'loss': 0.09612371, 'lr': 3.89e-06, 'params': 451793, 'time_iter': 0.06573, 'accuracy': 0.97246, 'precision': 0.75873, 'recall': 0.38799, 'f1': 0.51343, 'auc': 0.89506}
2025-08-17 09:10:58,856 - INFO - val: {'epoch': 88, 'time_epoch': 4.03129, 'loss': 0.07251089, 'lr': 0, 'params': 451793, 'time_iter': 0.03125, 'accuracy': 0.98225, 'precision': 0.6, 'recall': 0.2963, 'f1': 0.39669, 'auc': 0.80534}
2025-08-17 09:11:02,947 - INFO - test: {'epoch': 88, 'time_epoch': 4.07486, 'loss': 0.12015485, 'lr': 0, 'params': 451793, 'time_iter': 0.03159, 'accuracy': 0.96888, 'precision': 0.51163, 'recall': 0.33846, 'f1': 0.40741, 'auc': 0.76505}
2025-08-17 09:11:02,950 - INFO - > Epoch 88: took 75.9s (avg 77.3s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:12:09,760 - INFO - train: {'epoch': 89, 'time_epoch': 66.72927, 'eta': 686.18167, 'eta_hours': 0.19061, 'loss': 0.09461465, 'lr': 3.27e-06, 'params': 451793, 'time_iter': 0.06485, 'accuracy': 0.97249, 'precision': 0.75911, 'recall': 0.3888, 'f1': 0.51422, 'auc': 0.8988}
2025-08-17 09:12:13,981 - INFO - val: {'epoch': 89, 'time_epoch': 4.19296, 'loss': 0.0744922, 'lr': 0, 'params': 451793, 'time_iter': 0.0325, 'accuracy': 0.98128, 'precision': 0.54545, 'recall': 0.2963, 'f1': 0.384, 'auc': 0.80123}
2025-08-17 09:12:18,173 - INFO - test: {'epoch': 89, 'time_epoch': 4.17499, 'loss': 0.12282697, 'lr': 0, 'params': 451793, 'time_iter': 0.03236, 'accuracy': 0.96742, 'precision': 0.47917, 'recall': 0.35385, 'f1': 0.40708, 'auc': 0.76295}
2025-08-17 09:12:18,178 - INFO - > Epoch 89: took 75.2s (avg 77.3s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:13:24,804 - INFO - train: {'epoch': 90, 'time_epoch': 66.54389, 'eta': 617.35835, 'eta_hours': 0.17149, 'loss': 0.09475816, 'lr': 2.71e-06, 'params': 451793, 'time_iter': 0.06467, 'accuracy': 0.97243, 'precision': 0.74146, 'recall': 0.40503, 'f1': 0.52388, 'auc': 0.89741}
2025-08-17 09:13:29,026 - INFO - val: {'epoch': 90, 'time_epoch': 4.19989, 'loss': 0.07226644, 'lr': 0, 'params': 451793, 'time_iter': 0.03256, 'accuracy': 0.98298, 'precision': 0.64103, 'recall': 0.30864, 'f1': 0.41667, 'auc': 0.8007}
2025-08-17 09:13:33,270 - INFO - test: {'epoch': 90, 'time_epoch': 4.22618, 'loss': 0.119851, 'lr': 0, 'params': 451793, 'time_iter': 0.03276, 'accuracy': 0.97034, 'precision': 0.55128, 'recall': 0.33077, 'f1': 0.41346, 'auc': 0.76533}
2025-08-17 09:13:33,272 - INFO - > Epoch 90: took 75.1s (avg 77.3s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:14:41,328 - INFO - train: {'epoch': 91, 'time_epoch': 67.97323, 'eta': 548.70888, 'eta_hours': 0.15242, 'loss': 0.09626727, 'lr': 2.2e-06, 'params': 451793, 'time_iter': 0.06606, 'accuracy': 0.97179, 'precision': 0.73242, 'recall': 0.3888, 'f1': 0.50795, 'auc': 0.89492}
2025-08-17 09:14:45,592 - INFO - val: {'epoch': 91, 'time_epoch': 4.24206, 'loss': 0.07129775, 'lr': 0, 'params': 451793, 'time_iter': 0.03288, 'accuracy': 0.98274, 'precision': 0.63889, 'recall': 0.28395, 'f1': 0.39316, 'auc': 0.80819}
2025-08-17 09:14:49,845 - INFO - test: {'epoch': 91, 'time_epoch': 4.23489, 'loss': 0.11888079, 'lr': 0, 'params': 451793, 'time_iter': 0.03283, 'accuracy': 0.96961, 'precision': 0.53425, 'recall': 0.3, 'f1': 0.38424, 'auc': 0.7662}
2025-08-17 09:14:49,847 - INFO - > Epoch 91: took 76.6s (avg 77.3s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:15:57,896 - INFO - train: {'epoch': 92, 'time_epoch': 67.96484, 'eta': 480.07332, 'eta_hours': 0.13335, 'loss': 0.09522998, 'lr': 1.74e-06, 'params': 451793, 'time_iter': 0.06605, 'accuracy': 0.97182, 'precision': 0.75041, 'recall': 0.37094, 'f1': 0.49647, 'auc': 0.90227}
2025-08-17 09:16:02,132 - INFO - val: {'epoch': 92, 'time_epoch': 4.21205, 'loss': 0.07161572, 'lr': 0, 'params': 451793, 'time_iter': 0.03265, 'accuracy': 0.98249, 'precision': 0.60976, 'recall': 0.30864, 'f1': 0.40984, 'auc': 0.80307}
2025-08-17 09:16:06,340 - INFO - test: {'epoch': 92, 'time_epoch': 4.19047, 'loss': 0.11869852, 'lr': 0, 'params': 451793, 'time_iter': 0.03248, 'accuracy': 0.97058, 'precision': 0.56, 'recall': 0.32308, 'f1': 0.40976, 'auc': 0.76198}
2025-08-17 09:16:06,343 - INFO - > Epoch 92: took 76.5s (avg 77.3s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:17:13,719 - INFO - train: {'epoch': 93, 'time_epoch': 67.28841, 'eta': 411.40885, 'eta_hours': 0.11428, 'loss': 0.09514274, 'lr': 1.33e-06, 'params': 451793, 'time_iter': 0.06539, 'accuracy': 0.97265, 'precision': 0.75076, 'recall': 0.40341, 'f1': 0.52482, 'auc': 0.89421}
2025-08-17 09:17:17,898 - INFO - val: {'epoch': 93, 'time_epoch': 4.15738, 'loss': 0.07276461, 'lr': 0, 'params': 451793, 'time_iter': 0.03223, 'accuracy': 0.98249, 'precision': 0.61538, 'recall': 0.2963, 'f1': 0.4, 'auc': 0.79894}
2025-08-17 09:17:22,081 - INFO - test: {'epoch': 93, 'time_epoch': 4.16647, 'loss': 0.11977677, 'lr': 0, 'params': 451793, 'time_iter': 0.0323, 'accuracy': 0.96912, 'precision': 0.51948, 'recall': 0.30769, 'f1': 0.38647, 'auc': 0.76613}
2025-08-17 09:17:22,084 - INFO - > Epoch 93: took 75.7s (avg 77.3s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:18:28,366 - INFO - train: {'epoch': 94, 'time_epoch': 66.20042, 'eta': 342.71609, 'eta_hours': 0.0952, 'loss': 0.09390623, 'lr': 9.8e-07, 'params': 451793, 'time_iter': 0.06433, 'accuracy': 0.97304, 'precision': 0.76018, 'recall': 0.40909, 'f1': 0.53193, 'auc': 0.90153}
2025-08-17 09:18:32,436 - INFO - val: {'epoch': 94, 'time_epoch': 4.04867, 'loss': 0.07369225, 'lr': 0, 'params': 451793, 'time_iter': 0.03139, 'accuracy': 0.98225, 'precision': 0.59524, 'recall': 0.30864, 'f1': 0.4065, 'auc': 0.79967}
2025-08-17 09:18:36,550 - INFO - test: {'epoch': 94, 'time_epoch': 4.09643, 'loss': 0.12037657, 'lr': 0, 'params': 451793, 'time_iter': 0.03176, 'accuracy': 0.96937, 'precision': 0.52439, 'recall': 0.33077, 'f1': 0.40566, 'auc': 0.76498}
2025-08-17 09:18:36,552 - INFO - > Epoch 94: took 74.5s (avg 77.2s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:19:43,303 - INFO - train: {'epoch': 95, 'time_epoch': 66.67083, 'eta': 274.09486, 'eta_hours': 0.07614, 'loss': 0.09607113, 'lr': 6.8e-07, 'params': 451793, 'time_iter': 0.06479, 'accuracy': 0.97243, 'precision': 0.74962, 'recall': 0.3961, 'f1': 0.51832, 'auc': 0.89318}
2025-08-17 09:19:47,327 - INFO - val: {'epoch': 95, 'time_epoch': 4.00391, 'loss': 0.07246744, 'lr': 0, 'params': 451793, 'time_iter': 0.03104, 'accuracy': 0.98201, 'precision': 0.58537, 'recall': 0.2963, 'f1': 0.39344, 'auc': 0.80301}
2025-08-17 09:19:51,346 - INFO - test: {'epoch': 95, 'time_epoch': 4.00203, 'loss': 0.1203579, 'lr': 0, 'params': 451793, 'time_iter': 0.03102, 'accuracy': 0.96961, 'precision': 0.52941, 'recall': 0.34615, 'f1': 0.4186, 'auc': 0.76182}
2025-08-17 09:19:51,348 - INFO - > Epoch 95: took 74.8s (avg 77.2s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:20:56,220 - INFO - train: {'epoch': 96, 'time_epoch': 64.78769, 'eta': 205.4556, 'eta_hours': 0.05707, 'loss': 0.09584674, 'lr': 4.4e-07, 'params': 451793, 'time_iter': 0.06296, 'accuracy': 0.97237, 'precision': 0.74732, 'recall': 0.3961, 'f1': 0.51777, 'auc': 0.89505}
2025-08-17 09:21:00,283 - INFO - val: {'epoch': 96, 'time_epoch': 4.04115, 'loss': 0.07353782, 'lr': 0, 'params': 451793, 'time_iter': 0.03133, 'accuracy': 0.98201, 'precision': 0.58537, 'recall': 0.2963, 'f1': 0.39344, 'auc': 0.79966}
2025-08-17 09:21:04,406 - INFO - test: {'epoch': 96, 'time_epoch': 4.1058, 'loss': 0.12038427, 'lr': 0, 'params': 451793, 'time_iter': 0.03183, 'accuracy': 0.96912, 'precision': 0.51765, 'recall': 0.33846, 'f1': 0.4093, 'auc': 0.76544}
2025-08-17 09:21:04,408 - INFO - > Epoch 96: took 73.1s (avg 77.2s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:22:10,234 - INFO - train: {'epoch': 97, 'time_epoch': 65.74485, 'eta': 136.91447, 'eta_hours': 0.03803, 'loss': 0.09642313, 'lr': 2.5e-07, 'params': 451793, 'time_iter': 0.06389, 'accuracy': 0.97246, 'precision': 0.75232, 'recall': 0.39448, 'f1': 0.51757, 'auc': 0.89457}
2025-08-17 09:22:14,355 - INFO - val: {'epoch': 97, 'time_epoch': 4.10074, 'loss': 0.07333898, 'lr': 0, 'params': 451793, 'time_iter': 0.03179, 'accuracy': 0.98274, 'precision': 0.63158, 'recall': 0.2963, 'f1': 0.40336, 'auc': 0.79907}
2025-08-17 09:22:18,469 - INFO - test: {'epoch': 97, 'time_epoch': 4.09686, 'loss': 0.11994168, 'lr': 0, 'params': 451793, 'time_iter': 0.03176, 'accuracy': 0.96961, 'precision': 0.53086, 'recall': 0.33077, 'f1': 0.40758, 'auc': 0.76712}
2025-08-17 09:22:18,471 - INFO - > Epoch 97: took 74.1s (avg 77.1s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:23:25,823 - INFO - train: {'epoch': 98, 'time_epoch': 67.27194, 'eta': 68.44526, 'eta_hours': 0.01901, 'loss': 0.09533901, 'lr': 1.1e-07, 'params': 451793, 'time_iter': 0.06538, 'accuracy': 0.97234, 'precision': 0.74693, 'recall': 0.39529, 'f1': 0.51699, 'auc': 0.89642}
2025-08-17 09:23:29,920 - INFO - val: {'epoch': 98, 'time_epoch': 4.07689, 'loss': 0.07266123, 'lr': 0, 'params': 451793, 'time_iter': 0.0316, 'accuracy': 0.98177, 'precision': 0.56818, 'recall': 0.30864, 'f1': 0.4, 'auc': 0.80736}
2025-08-17 09:23:34,029 - INFO - test: {'epoch': 98, 'time_epoch': 4.09316, 'loss': 0.11986763, 'lr': 0, 'params': 451793, 'time_iter': 0.03173, 'accuracy': 0.96839, 'precision': 0.5, 'recall': 0.34615, 'f1': 0.40909, 'auc': 0.76508}
2025-08-17 09:23:34,032 - INFO - > Epoch 98: took 75.6s (avg 77.1s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:24:40,848 - INFO - train: {'epoch': 99, 'time_epoch': 66.74021, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.09367837, 'lr': 3e-08, 'params': 451793, 'time_iter': 0.06486, 'accuracy': 0.97304, 'precision': 0.76097, 'recall': 0.40828, 'f1': 0.53143, 'auc': 0.90033}
2025-08-17 09:24:45,103 - INFO - val: {'epoch': 99, 'time_epoch': 4.23328, 'loss': 0.07181665, 'lr': 0, 'params': 451793, 'time_iter': 0.03282, 'accuracy': 0.98274, 'precision': 0.625, 'recall': 0.30864, 'f1': 0.41322, 'auc': 0.80522}
2025-08-17 09:24:49,423 - INFO - test: {'epoch': 99, 'time_epoch': 4.30113, 'loss': 0.1188891, 'lr': 0, 'params': 451793, 'time_iter': 0.03334, 'accuracy': 0.97082, 'precision': 0.56757, 'recall': 0.32308, 'f1': 0.41176, 'auc': 0.7663}
2025-08-17 09:24:49,590 - INFO - > Epoch 99: took 75.4s (avg 77.1s) | Best so far: epoch 42	train_loss: 0.1087 train_auc: 0.8534	val_loss: 0.0725 val_auc: 0.8273	test_loss: 0.1171 test_auc: 0.7535
2025-08-17 09:24:49,590 - INFO - Avg time per epoch: 77.10s
2025-08-17 09:24:49,590 - INFO - Total train loop time: 2.14h

----------------------------------------
All experiments completed!
