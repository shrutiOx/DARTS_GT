Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          251Gi       9.6Gi       231Gi       789Mi       9.9Gi       238Gi
Swap:         1.9Gi       1.0Mi       1.9Gi
Sat Jul  5 09:33:42 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA TITAN RTX               On  |   00000000:89:00.0 Off |                  N/A |
| 41%   36C    P8             30W /  280W |       1MiB /  24576MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 47
Starting training for seed 47...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/PATTERN/FINAL_SINGLE/SPARSE_E
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/PATTERN/FINAL_SINGLE/SPARSE_E/confignas.yaml
Using device: cuda
2025-07-05 09:34:54,609 - INFO - GPU Mem: 25.2GB
2025-07-05 09:34:54,610 - INFO - Run directory: results/pattern/pattern-SPARSE-47
2025-07-05 09:34:54,610 - INFO - Seed: 47
2025-07-05 09:34:54,610 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-07-05 09:34:54,610 - INFO - Routing mode: nas
2025-07-05 09:34:54,610 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-07-05 09:34:54,610 - INFO - Number of layers: 6
2025-07-05 09:34:54,610 - INFO - Uncertainty enabled: False
2025-07-05 09:34:54,610 - INFO - Training mode: NoMixNas_uncertainty_train
2025-07-05 09:34:54,610 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-07-05 09:34:54,610 - INFO - Additional features: Router weights logging + JSON export
2025-07-05 09:35:14,373 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-05 09:35:14,376 - INFO -   Data(x=[1664491, 3], edge_index=[2, 85099952], y=[1664491])
2025-07-05 09:35:14,467 - INFO -   undirected: True
2025-07-05 09:35:14,467 - INFO -   num graphs: 14000
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-05 09:35:14,467 - INFO -   avg num_nodes/graph: 118
2025-07-05 09:35:14,467 - INFO -   num node features: 3
2025-07-05 09:35:14,467 - INFO -   num edge features: 0
2025-07-05 09:35:14,469 - INFO -   num classes: 2
2025-07-05 09:35:14,469 - INFO - Precomputing Positional Encoding statistics: ['LapPE'] for all graphs...
2025-07-05 09:35:14,479 - INFO -   ...estimated to be undirected: True
  0%|          | 0/14000 [00:00<?, ?it/s] 17%|█▋        | 2370/14000 [00:10<00:49, 236.91it/s] 34%|███▍      | 4824/14000 [00:20<00:37, 241.83it/s] 52%|█████▏    | 7227/14000 [00:30<00:28, 241.13it/s] 69%|██████▉   | 9690/14000 [00:40<00:17, 243.14it/s] 88%|████████▊ | 12294/14000 [00:50<00:06, 249.36it/s]100%|██████████| 14000/14000 [00:56<00:00, 247.38it/s]
2025-07-05 09:36:12,079 - INFO - Done! Took 00:00:57.61
2025-07-05 09:36:12,106 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset'
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/nni/nas/nn/pytorch/choice.py:252: UserWarning: "key" is deprecated. Assuming label.
  warnings.warn(f'"key" is deprecated. Assuming label.')
2025-07-05 09:36:12,729 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-07-05 09:36:12,729 - INFO - Inner model type: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-07-05 09:36:12,729 - INFO - Inner model has get_darts_model: True
2025-07-05 09:36:12,733 - INFO - GraphGymModule(
  (model): NASModelEdge(
    (encoder): FeatureEncoder(
      (node_encoder): LapPENodeEncoder(
        (linear_x): Linear(in_features=3, out_features=48, bias=True)
        (linear_A): Linear(in_features=2, out_features=32, bias=True)
        (pe_encoder): Sequential(
          (0): ReLU()
          (1): Linear(in_features=32, out_features=16, bias=True)
          (2): ReLU()
        )
      )
      (edge_encoder): DummyEdgeEncoder(
        (encoder): Embedding(1, 64)
      )
    )
    (darts_layers): ModuleList(
      (0): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (darts_sequential): Sequential(
      (0): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(64, 1, bias=True)
          )
        )
      )
    )
  )
)
2025-07-05 09:36:12,738 - INFO - Number of parameters: 487,351
2025-07-05 09:36:12,738 - INFO - Starting optimized training: 2025-07-05 09:36:12.738311
2025-07-05 09:36:20,290 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset':
2025-07-05 09:36:20,291 - INFO -   Data(x=[1664491, 3], edge_index=[2, 85099952], y=[1664491])
2025-07-05 09:36:20,292 - INFO -   undirected: True
2025-07-05 09:36:20,292 - INFO -   num graphs: 14000
2025-07-05 09:36:20,293 - INFO -   avg num_nodes/graph: 118
2025-07-05 09:36:20,293 - INFO -   num node features: 3
2025-07-05 09:36:20,293 - INFO -   num edge features: 0
2025-07-05 09:36:20,294 - INFO -   num classes: 2
2025-07-05 09:36:20,295 - INFO - Precomputing Positional Encoding statistics: ['LapPE'] for all graphs...
2025-07-05 09:36:20,305 - INFO -   ...estimated to be undirected: True
  0%|          | 0/14000 [00:00<?, ?it/s] 17%|█▋        | 2345/14000 [00:10<00:49, 234.45it/s] 34%|███▍      | 4814/14000 [00:20<00:37, 241.76it/s] 51%|█████     | 7156/14000 [00:30<00:28, 238.28it/s] 70%|██████▉   | 9736/14000 [00:40<00:17, 246.04it/s] 87%|████████▋ | 12124/14000 [00:50<00:07, 243.41it/s]100%|██████████| 14000/14000 [00:57<00:00, 243.38it/s]
2025-07-05 09:37:18,843 - INFO - Done! Took 00:00:58.55
2025-07-05 09:37:18,874 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset'
2025-07-05 09:37:18,894 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-07-05 09:37:18,895 - INFO - Start from epoch 0
2025-07-05 09:37:18,895 - INFO - ================================================================================
2025-07-05 09:37:18,895 - INFO - STARTING TWO-PHASE NAS TRAINING
2025-07-05 09:37:18,895 - INFO - ================================================================================
2025-07-05 09:37:18,895 - INFO - Routing mode: nas
2025-07-05 09:37:18,895 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-07-05 09:37:18,895 - INFO - Phase 1: Architecture search/initialization
2025-07-05 09:37:18,895 - INFO - Phase 2: Discrete training with uncertainty (NO variance)
2025-07-05 09:37:18,895 - INFO - ============================================================
2025-07-05 09:37:18,895 - INFO - PHASE 1: ARCHITECTURE SEARCH/INITIALIZATION
2025-07-05 09:37:18,895 - INFO - ============================================================
2025-07-05 09:37:18,895 - INFO - Splitting dataset for DARTS:
2025-07-05 09:37:18,895 - INFO -   Original train size: 10000
2025-07-05 09:37:18,896 - INFO -   DARTS train size: 6000 (60.0%)
2025-07-05 09:37:18,896 - INFO -   DARTS val size: 4000 (40.0%)
2025-07-05 09:37:18,897 - INFO - Found GraphGym wrapper, using inner model: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-07-05 09:37:18,897 - INFO - Successfully configured model for DARTS training
2025-07-05 09:37:18,897 - INFO - NAS MODE: Running 20 epochs with DARTS
2025-07-05 09:37:18,897 - INFO - DARTS Configuration:
2025-07-05 09:37:18,897 - INFO -   Epochs: 20
2025-07-05 09:37:18,897 - INFO -   Architecture LR: 0.0004
2025-07-05 09:37:18,897 - INFO -   Grad clip: 5.0
2025-07-05 09:37:18,901 - INFO - Starting DARTS architecture search
2025-07-05 09:37:23,749 - WARNING - Epoch [1/20] Step [1/125]  acc 0.790451 (0.790451)  loss 0.673522 (0.673522)
GPU memory consumption  GPU Memory: Allocated: 130.8 MB, Reserved: 4276.0 MB
2025-07-05 09:37:27,203 - WARNING - Epoch [1/20] Step [11/125]  acc 0.817152 (0.822238)  loss 0.532357 (0.576705)
GPU memory consumption  GPU Memory: Allocated: 123.9 MB, Reserved: 4282.0 MB
2025-07-05 09:37:30,485 - WARNING - Epoch [1/20] Step [21/125]  acc 0.873632 (0.827974)  loss 0.486025 (0.541911)
GPU memory consumption  GPU Memory: Allocated: 120.3 MB, Reserved: 4336.0 MB
2025-07-05 09:37:33,773 - WARNING - Epoch [1/20] Step [31/125]  acc 0.886482 (0.846808)  loss 0.439742 (0.514786)
GPU memory consumption  GPU Memory: Allocated: 120.2 MB, Reserved: 4390.0 MB
2025-07-05 09:37:37,141 - WARNING - Epoch [1/20] Step [41/125]  acc 0.898111 (0.858775)  loss 0.404980 (0.492593)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 8462.0 MB
2025-07-05 09:37:40,600 - WARNING - Epoch [1/20] Step [51/125]  acc 0.900486 (0.865578)  loss 0.386849 (0.474897)
GPU memory consumption  GPU Memory: Allocated: 130.1 MB, Reserved: 8462.0 MB
2025-07-05 09:37:43,977 - WARNING - Epoch [1/20] Step [61/125]  acc 0.885479 (0.869643)  loss 0.377829 (0.460022)
GPU memory consumption  GPU Memory: Allocated: 122.2 MB, Reserved: 8462.0 MB
2025-07-05 09:37:47,185 - WARNING - Epoch [1/20] Step [71/125]  acc 0.891298 (0.872457)  loss 0.370930 (0.447593)
GPU memory consumption  GPU Memory: Allocated: 120.6 MB, Reserved: 8462.0 MB
2025-07-05 09:37:50,502 - WARNING - Epoch [1/20] Step [81/125]  acc 0.896534 (0.875524)  loss 0.341377 (0.435605)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 8462.0 MB
2025-07-05 09:37:53,738 - WARNING - Epoch [1/20] Step [91/125]  acc 0.876831 (0.877240)  loss 0.361745 (0.425676)
GPU memory consumption  GPU Memory: Allocated: 124.9 MB, Reserved: 8462.0 MB
2025-07-05 09:37:57,226 - WARNING - Epoch [1/20] Step [101/125]  acc 0.889927 (0.879167)  loss 0.326819 (0.416140)
GPU memory consumption  GPU Memory: Allocated: 123.3 MB, Reserved: 8462.0 MB
2025-07-05 09:38:00,615 - WARNING - Epoch [1/20] Step [111/125]  acc 0.908865 (0.880328)  loss 0.311976 (0.408234)
GPU memory consumption  GPU Memory: Allocated: 135.7 MB, Reserved: 8462.0 MB
2025-07-05 09:38:04,118 - WARNING - Epoch [1/20] Step [121/125]  acc 0.905537 (0.881618)  loss 0.302465 (0.400533)
GPU memory consumption  GPU Memory: Allocated: 130.1 MB, Reserved: 8462.0 MB
Epoch 1 completed in 0:00:46.589262
2025-07-05 09:38:16,069 - WARNING - Epoch [2/20] Step [1/125]  acc 0.888167 (0.888167)  loss 0.310707 (0.310707)
GPU memory consumption  GPU Memory: Allocated: 128.4 MB, Reserved: 8462.0 MB
2025-07-05 09:38:19,258 - WARNING - Epoch [2/20] Step [11/125]  acc 0.908577 (0.898687)  loss 0.281157 (0.305128)
GPU memory consumption  GPU Memory: Allocated: 128.0 MB, Reserved: 8462.0 MB
2025-07-05 09:38:22,505 - WARNING - Epoch [2/20] Step [21/125]  acc 0.902264 (0.898370)  loss 0.292031 (0.302939)
GPU memory consumption  GPU Memory: Allocated: 122.6 MB, Reserved: 8462.0 MB
2025-07-05 09:38:25,787 - WARNING - Epoch [2/20] Step [31/125]  acc 0.900258 (0.898752)  loss 0.284573 (0.298707)
GPU memory consumption  GPU Memory: Allocated: 126.6 MB, Reserved: 8462.0 MB
2025-07-05 09:38:29,145 - WARNING - Epoch [2/20] Step [41/125]  acc 0.905423 (0.899054)  loss 0.276911 (0.296109)
GPU memory consumption  GPU Memory: Allocated: 122.2 MB, Reserved: 8462.0 MB
2025-07-05 09:38:32,457 - WARNING - Epoch [2/20] Step [51/125]  acc 0.884707 (0.899205)  loss 0.312197 (0.293909)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 10144.0 MB
2025-07-05 09:38:35,730 - WARNING - Epoch [2/20] Step [61/125]  acc 0.912679 (0.899232)  loss 0.261240 (0.291742)
GPU memory consumption  GPU Memory: Allocated: 136.3 MB, Reserved: 10144.0 MB
2025-07-05 09:38:39,008 - WARNING - Epoch [2/20] Step [71/125]  acc 0.883708 (0.899045)  loss 0.300234 (0.290179)
GPU memory consumption  GPU Memory: Allocated: 123.1 MB, Reserved: 10144.0 MB
2025-07-05 09:38:42,334 - WARNING - Epoch [2/20] Step [81/125]  acc 0.908833 (0.899039)  loss 0.257412 (0.288271)
GPU memory consumption  GPU Memory: Allocated: 126.2 MB, Reserved: 10144.0 MB
2025-07-05 09:38:45,745 - WARNING - Epoch [2/20] Step [91/125]  acc 0.895045 (0.898624)  loss 0.273385 (0.287249)
GPU memory consumption  GPU Memory: Allocated: 122.8 MB, Reserved: 10144.0 MB
2025-07-05 09:38:48,921 - WARNING - Epoch [2/20] Step [101/125]  acc 0.901578 (0.898432)  loss 0.262785 (0.285749)
GPU memory consumption  GPU Memory: Allocated: 117.9 MB, Reserved: 10144.0 MB
2025-07-05 09:38:52,174 - WARNING - Epoch [2/20] Step [111/125]  acc 0.905956 (0.898696)  loss 0.261923 (0.284133)
GPU memory consumption  GPU Memory: Allocated: 129.7 MB, Reserved: 10144.0 MB
2025-07-05 09:38:55,489 - WARNING - Epoch [2/20] Step [121/125]  acc 0.897985 (0.898466)  loss 0.265787 (0.283315)
GPU memory consumption  GPU Memory: Allocated: 135.9 MB, Reserved: 10144.0 MB
Epoch 2 completed in 0:00:41.106177
2025-07-05 09:39:07,284 - WARNING - Epoch [3/20] Step [1/125]  acc 0.905024 (0.905024)  loss 0.266367 (0.266367)
GPU memory consumption  GPU Memory: Allocated: 132.2 MB, Reserved: 10158.0 MB
2025-07-05 09:39:10,818 - WARNING - Epoch [3/20] Step [11/125]  acc 0.906930 (0.899776)  loss 0.254660 (0.265954)
GPU memory consumption  GPU Memory: Allocated: 130.3 MB, Reserved: 10158.0 MB
2025-07-05 09:39:14,185 - WARNING - Epoch [3/20] Step [21/125]  acc 0.887965 (0.899940)  loss 0.282803 (0.265816)
GPU memory consumption  GPU Memory: Allocated: 124.8 MB, Reserved: 10158.0 MB
2025-07-05 09:39:17,547 - WARNING - Epoch [3/20] Step [31/125]  acc 0.915584 (0.901711)  loss 0.234211 (0.262261)
GPU memory consumption  GPU Memory: Allocated: 121.1 MB, Reserved: 10158.0 MB
2025-07-05 09:39:20,784 - WARNING - Epoch [3/20] Step [41/125]  acc 0.887004 (0.900782)  loss 0.292602 (0.262540)
GPU memory consumption  GPU Memory: Allocated: 118.2 MB, Reserved: 10158.0 MB
2025-07-05 09:39:24,016 - WARNING - Epoch [3/20] Step [51/125]  acc 0.903085 (0.899717)  loss 0.267932 (0.263799)
GPU memory consumption  GPU Memory: Allocated: 124.1 MB, Reserved: 10158.0 MB
2025-07-05 09:39:27,251 - WARNING - Epoch [3/20] Step [61/125]  acc 0.903182 (0.900454)  loss 0.248847 (0.261975)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 10158.0 MB
2025-07-05 09:39:30,455 - WARNING - Epoch [3/20] Step [71/125]  acc 0.896496 (0.899889)  loss 0.259485 (0.262046)
GPU memory consumption  GPU Memory: Allocated: 125.2 MB, Reserved: 10158.0 MB
2025-07-05 09:39:33,675 - WARNING - Epoch [3/20] Step [81/125]  acc 0.926489 (0.900336)  loss 0.216549 (0.260979)
GPU memory consumption  GPU Memory: Allocated: 131.2 MB, Reserved: 10158.0 MB
2025-07-05 09:39:36,875 - WARNING - Epoch [3/20] Step [91/125]  acc 0.889500 (0.899583)  loss 0.268876 (0.261900)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 10158.0 MB
2025-07-05 09:39:40,123 - WARNING - Epoch [3/20] Step [101/125]  acc 0.912168 (0.899489)  loss 0.239841 (0.261603)
GPU memory consumption  GPU Memory: Allocated: 116.5 MB, Reserved: 10158.0 MB
2025-07-05 09:39:43,543 - WARNING - Epoch [3/20] Step [111/125]  acc 0.903542 (0.899873)  loss 0.245232 (0.260673)
GPU memory consumption  GPU Memory: Allocated: 125.1 MB, Reserved: 10158.0 MB
2025-07-05 09:39:46,981 - WARNING - Epoch [3/20] Step [121/125]  acc 0.901552 (0.899970)  loss 0.256343 (0.260312)
GPU memory consumption  GPU Memory: Allocated: 128.6 MB, Reserved: 10158.0 MB
Epoch 3 completed in 0:00:41.342538
2025-07-05 09:39:58,728 - WARNING - Epoch [4/20] Step [1/125]  acc 0.911653 (0.911653)  loss 0.228109 (0.228109)
GPU memory consumption  GPU Memory: Allocated: 134.9 MB, Reserved: 10158.0 MB
2025-07-05 09:40:02,100 - WARNING - Epoch [4/20] Step [11/125]  acc 0.899658 (0.902258)  loss 0.252473 (0.249490)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 10158.0 MB
2025-07-05 09:40:05,523 - WARNING - Epoch [4/20] Step [21/125]  acc 0.899166 (0.902172)  loss 0.257142 (0.251086)
GPU memory consumption  GPU Memory: Allocated: 121.4 MB, Reserved: 10158.0 MB
2025-07-05 09:40:09,004 - WARNING - Epoch [4/20] Step [31/125]  acc 0.912281 (0.902165)  loss 0.229737 (0.250791)
GPU memory consumption  GPU Memory: Allocated: 127.3 MB, Reserved: 10158.0 MB
2025-07-05 09:40:12,245 - WARNING - Epoch [4/20] Step [41/125]  acc 0.908364 (0.902291)  loss 0.235069 (0.249774)
GPU memory consumption  GPU Memory: Allocated: 120.1 MB, Reserved: 10158.0 MB
2025-07-05 09:40:15,459 - WARNING - Epoch [4/20] Step [51/125]  acc 0.909356 (0.901905)  loss 0.226882 (0.250594)
GPU memory consumption  GPU Memory: Allocated: 126.3 MB, Reserved: 10158.0 MB
2025-07-05 09:40:18,697 - WARNING - Epoch [4/20] Step [61/125]  acc 0.899435 (0.901206)  loss 0.257025 (0.251841)
GPU memory consumption  GPU Memory: Allocated: 127.2 MB, Reserved: 10158.0 MB
2025-07-05 09:40:21,997 - WARNING - Epoch [4/20] Step [71/125]  acc 0.895580 (0.901417)  loss 0.259313 (0.251334)
GPU memory consumption  GPU Memory: Allocated: 122.7 MB, Reserved: 10158.0 MB
2025-07-05 09:40:25,314 - WARNING - Epoch [4/20] Step [81/125]  acc 0.909729 (0.901490)  loss 0.229824 (0.250839)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 10158.0 MB
2025-07-05 09:40:28,766 - WARNING - Epoch [4/20] Step [91/125]  acc 0.904026 (0.901424)  loss 0.239177 (0.250777)
GPU memory consumption  GPU Memory: Allocated: 122.6 MB, Reserved: 10158.0 MB
2025-07-05 09:40:31,956 - WARNING - Epoch [4/20] Step [101/125]  acc 0.895589 (0.901048)  loss 0.264985 (0.251433)
GPU memory consumption  GPU Memory: Allocated: 120.4 MB, Reserved: 10158.0 MB
2025-07-05 09:40:35,289 - WARNING - Epoch [4/20] Step [111/125]  acc 0.890386 (0.901235)  loss 0.268923 (0.250910)
GPU memory consumption  GPU Memory: Allocated: 130.7 MB, Reserved: 10158.0 MB
2025-07-05 09:40:38,571 - WARNING - Epoch [4/20] Step [121/125]  acc 0.891667 (0.901128)  loss 0.266063 (0.251038)
GPU memory consumption  GPU Memory: Allocated: 128.1 MB, Reserved: 10158.0 MB
Epoch 4 completed in 0:00:41.532952
2025-07-05 09:40:50,452 - WARNING - Epoch [5/20] Step [1/125]  acc 0.906753 (0.906753)  loss 0.240672 (0.240672)
GPU memory consumption  GPU Memory: Allocated: 132.7 MB, Reserved: 10158.0 MB
2025-07-05 09:40:53,712 - WARNING - Epoch [5/20] Step [11/125]  acc 0.908280 (0.905871)  loss 0.234267 (0.241558)
GPU memory consumption  GPU Memory: Allocated: 128.3 MB, Reserved: 10158.0 MB
2025-07-05 09:40:56,944 - WARNING - Epoch [5/20] Step [21/125]  acc 0.901096 (0.902507)  loss 0.246029 (0.246185)
GPU memory consumption  GPU Memory: Allocated: 127.5 MB, Reserved: 10158.0 MB
2025-07-05 09:41:00,262 - WARNING - Epoch [5/20] Step [31/125]  acc 0.906327 (0.901074)  loss 0.238075 (0.248396)
GPU memory consumption  GPU Memory: Allocated: 120.1 MB, Reserved: 10158.0 MB
2025-07-05 09:41:03,572 - WARNING - Epoch [5/20] Step [41/125]  acc 0.902378 (0.901068)  loss 0.247047 (0.247758)
GPU memory consumption  GPU Memory: Allocated: 127.1 MB, Reserved: 10158.0 MB
2025-07-05 09:41:06,811 - WARNING - Epoch [5/20] Step [51/125]  acc 0.889181 (0.900645)  loss 0.270203 (0.248589)
GPU memory consumption  GPU Memory: Allocated: 127.3 MB, Reserved: 10158.0 MB
2025-07-05 09:41:10,079 - WARNING - Epoch [5/20] Step [61/125]  acc 0.914930 (0.900579)  loss 0.220147 (0.248128)
GPU memory consumption  GPU Memory: Allocated: 136.4 MB, Reserved: 10158.0 MB
2025-07-05 09:41:13,316 - WARNING - Epoch [5/20] Step [71/125]  acc 0.903851 (0.900844)  loss 0.251649 (0.247677)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 10158.0 MB
2025-07-05 09:41:16,678 - WARNING - Epoch [5/20] Step [81/125]  acc 0.897920 (0.900795)  loss 0.251547 (0.247761)
GPU memory consumption  GPU Memory: Allocated: 120.3 MB, Reserved: 10158.0 MB
2025-07-05 09:41:19,948 - WARNING - Epoch [5/20] Step [91/125]  acc 0.908001 (0.901432)  loss 0.229044 (0.246479)
GPU memory consumption  GPU Memory: Allocated: 124.2 MB, Reserved: 10158.0 MB
2025-07-05 09:41:23,174 - WARNING - Epoch [5/20] Step [101/125]  acc 0.891829 (0.901037)  loss 0.255533 (0.247126)
GPU memory consumption  GPU Memory: Allocated: 121.4 MB, Reserved: 10158.0 MB
2025-07-05 09:41:26,463 - WARNING - Epoch [5/20] Step [111/125]  acc 0.927636 (0.901196)  loss 0.197500 (0.246810)
GPU memory consumption  GPU Memory: Allocated: 134.2 MB, Reserved: 10158.0 MB
2025-07-05 09:41:29,717 - WARNING - Epoch [5/20] Step [121/125]  acc 0.900623 (0.901041)  loss 0.243641 (0.246774)
GPU memory consumption  GPU Memory: Allocated: 130.9 MB, Reserved: 10158.0 MB
Epoch 5 completed in 0:00:40.968942
2025-07-05 09:41:41,519 - WARNING - Epoch [6/20] Step [1/125]  acc 0.906042 (0.906042)  loss 0.236459 (0.236459)
GPU memory consumption  GPU Memory: Allocated: 133.7 MB, Reserved: 10158.0 MB
2025-07-05 09:41:44,764 - WARNING - Epoch [6/20] Step [11/125]  acc 0.889547 (0.903529)  loss 0.272450 (0.239696)
GPU memory consumption  GPU Memory: Allocated: 124.4 MB, Reserved: 10158.0 MB
2025-07-05 09:41:48,126 - WARNING - Epoch [6/20] Step [21/125]  acc 0.898382 (0.903608)  loss 0.247522 (0.240423)
GPU memory consumption  GPU Memory: Allocated: 128.4 MB, Reserved: 10158.0 MB
2025-07-05 09:41:51,415 - WARNING - Epoch [6/20] Step [31/125]  acc 0.903072 (0.902373)  loss 0.241726 (0.242461)
GPU memory consumption  GPU Memory: Allocated: 123.7 MB, Reserved: 10158.0 MB
2025-07-05 09:41:54,633 - WARNING - Epoch [6/20] Step [41/125]  acc 0.893526 (0.901531)  loss 0.250207 (0.244051)
GPU memory consumption  GPU Memory: Allocated: 120.6 MB, Reserved: 10158.0 MB
2025-07-05 09:41:57,940 - WARNING - Epoch [6/20] Step [51/125]  acc 0.912553 (0.902055)  loss 0.219519 (0.243012)
GPU memory consumption  GPU Memory: Allocated: 132.7 MB, Reserved: 10158.0 MB
2025-07-05 09:42:01,254 - WARNING - Epoch [6/20] Step [61/125]  acc 0.890436 (0.901946)  loss 0.262439 (0.243306)
GPU memory consumption  GPU Memory: Allocated: 130.4 MB, Reserved: 10158.0 MB
2025-07-05 09:42:04,656 - WARNING - Epoch [6/20] Step [71/125]  acc 0.897700 (0.901750)  loss 0.247589 (0.243680)
GPU memory consumption  GPU Memory: Allocated: 124.5 MB, Reserved: 10158.0 MB
2025-07-05 09:42:07,861 - WARNING - Epoch [6/20] Step [81/125]  acc 0.897410 (0.901337)  loss 0.257773 (0.244369)
GPU memory consumption  GPU Memory: Allocated: 127.1 MB, Reserved: 10158.0 MB
2025-07-05 09:42:11,102 - WARNING - Epoch [6/20] Step [91/125]  acc 0.908710 (0.901633)  loss 0.232843 (0.243981)
GPU memory consumption  GPU Memory: Allocated: 124.5 MB, Reserved: 10158.0 MB
2025-07-05 09:42:14,362 - WARNING - Epoch [6/20] Step [101/125]  acc 0.901903 (0.901844)  loss 0.234818 (0.243409)
GPU memory consumption  GPU Memory: Allocated: 126.1 MB, Reserved: 10158.0 MB
2025-07-05 09:42:17,777 - WARNING - Epoch [6/20] Step [111/125]  acc 0.913557 (0.901947)  loss 0.223418 (0.242980)
GPU memory consumption  GPU Memory: Allocated: 124.5 MB, Reserved: 10158.0 MB
2025-07-05 09:42:21,155 - WARNING - Epoch [6/20] Step [121/125]  acc 0.888536 (0.901641)  loss 0.265610 (0.243340)
GPU memory consumption  GPU Memory: Allocated: 128.9 MB, Reserved: 10158.0 MB
Epoch 6 completed in 0:00:41.277673
2025-07-05 09:42:32,884 - WARNING - Epoch [7/20] Step [1/125]  acc 0.904222 (0.904222)  loss 0.246654 (0.246654)
GPU memory consumption  GPU Memory: Allocated: 131.2 MB, Reserved: 10158.0 MB
2025-07-05 09:42:36,137 - WARNING - Epoch [7/20] Step [11/125]  acc 0.903763 (0.904145)  loss 0.238177 (0.239102)
GPU memory consumption  GPU Memory: Allocated: 124.5 MB, Reserved: 10158.0 MB
2025-07-05 09:42:39,294 - WARNING - Epoch [7/20] Step [21/125]  acc 0.896107 (0.903038)  loss 0.253491 (0.241155)
GPU memory consumption  GPU Memory: Allocated: 120.5 MB, Reserved: 10158.0 MB
2025-07-05 09:42:42,498 - WARNING - Epoch [7/20] Step [31/125]  acc 0.903836 (0.902491)  loss 0.232799 (0.241278)
GPU memory consumption  GPU Memory: Allocated: 123.7 MB, Reserved: 10158.0 MB
2025-07-05 09:42:45,719 - WARNING - Epoch [7/20] Step [41/125]  acc 0.892436 (0.902691)  loss 0.258628 (0.240815)
GPU memory consumption  GPU Memory: Allocated: 120.5 MB, Reserved: 10158.0 MB
2025-07-05 09:42:48,929 - WARNING - Epoch [7/20] Step [51/125]  acc 0.895336 (0.903021)  loss 0.246249 (0.240742)
GPU memory consumption  GPU Memory: Allocated: 124.5 MB, Reserved: 10158.0 MB
2025-07-05 09:42:52,207 - WARNING - Epoch [7/20] Step [61/125]  acc 0.913836 (0.902578)  loss 0.219382 (0.241376)
GPU memory consumption  GPU Memory: Allocated: 136.6 MB, Reserved: 10158.0 MB
2025-07-05 09:42:55,493 - WARNING - Epoch [7/20] Step [71/125]  acc 0.899318 (0.902272)  loss 0.250274 (0.242645)
GPU memory consumption  GPU Memory: Allocated: 123.1 MB, Reserved: 10158.0 MB
2025-07-05 09:42:58,717 - WARNING - Epoch [7/20] Step [81/125]  acc 0.896885 (0.902838)  loss 0.247912 (0.241591)
GPU memory consumption  GPU Memory: Allocated: 122.8 MB, Reserved: 10158.0 MB
2025-07-05 09:43:02,012 - WARNING - Epoch [7/20] Step [91/125]  acc 0.896916 (0.902578)  loss 0.253329 (0.241831)
GPU memory consumption  GPU Memory: Allocated: 118.7 MB, Reserved: 10158.0 MB
2025-07-05 09:43:05,385 - WARNING - Epoch [7/20] Step [101/125]  acc 0.903024 (0.902628)  loss 0.242348 (0.241707)
GPU memory consumption  GPU Memory: Allocated: 116.0 MB, Reserved: 10158.0 MB
2025-07-05 09:43:08,679 - WARNING - Epoch [7/20] Step [111/125]  acc 0.903651 (0.902727)  loss 0.233947 (0.241180)
GPU memory consumption  GPU Memory: Allocated: 132.1 MB, Reserved: 10158.0 MB
2025-07-05 09:43:11,977 - WARNING - Epoch [7/20] Step [121/125]  acc 0.899508 (0.902426)  loss 0.242091 (0.241858)
GPU memory consumption  GPU Memory: Allocated: 130.7 MB, Reserved: 10158.0 MB
Epoch 7 completed in 0:00:40.754011
2025-07-05 09:43:23,987 - WARNING - Epoch [8/20] Step [1/125]  acc 0.908331 (0.908331)  loss 0.229098 (0.229098)
GPU memory consumption  GPU Memory: Allocated: 136.9 MB, Reserved: 10158.0 MB
2025-07-05 09:43:27,201 - WARNING - Epoch [8/20] Step [11/125]  acc 0.901675 (0.899117)  loss 0.244400 (0.249811)
GPU memory consumption  GPU Memory: Allocated: 122.2 MB, Reserved: 10158.0 MB
2025-07-05 09:43:30,391 - WARNING - Epoch [8/20] Step [21/125]  acc 0.899817 (0.898260)  loss 0.254658 (0.249295)
GPU memory consumption  GPU Memory: Allocated: 124.6 MB, Reserved: 10158.0 MB
2025-07-05 09:43:33,659 - WARNING - Epoch [8/20] Step [31/125]  acc 0.911992 (0.901065)  loss 0.215616 (0.244046)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 10158.0 MB
2025-07-05 09:43:36,926 - WARNING - Epoch [8/20] Step [41/125]  acc 0.895710 (0.901218)  loss 0.247907 (0.242803)
GPU memory consumption  GPU Memory: Allocated: 120.3 MB, Reserved: 10158.0 MB
2025-07-05 09:43:40,181 - WARNING - Epoch [8/20] Step [51/125]  acc 0.902627 (0.900788)  loss 0.240971 (0.243508)
GPU memory consumption  GPU Memory: Allocated: 129.4 MB, Reserved: 10158.0 MB
2025-07-05 09:43:43,606 - WARNING - Epoch [8/20] Step [61/125]  acc 0.918974 (0.901271)  loss 0.215809 (0.242479)
GPU memory consumption  GPU Memory: Allocated: 132.3 MB, Reserved: 10158.0 MB
2025-07-05 09:43:46,950 - WARNING - Epoch [8/20] Step [71/125]  acc 0.903209 (0.901329)  loss 0.238081 (0.242572)
GPU memory consumption  GPU Memory: Allocated: 130.2 MB, Reserved: 10158.0 MB
2025-07-05 09:43:50,199 - WARNING - Epoch [8/20] Step [81/125]  acc 0.914958 (0.901971)  loss 0.226226 (0.241518)
GPU memory consumption  GPU Memory: Allocated: 129.5 MB, Reserved: 10158.0 MB
2025-07-05 09:43:53,440 - WARNING - Epoch [8/20] Step [91/125]  acc 0.885076 (0.902090)  loss 0.270469 (0.241154)
GPU memory consumption  GPU Memory: Allocated: 120.3 MB, Reserved: 10158.0 MB
2025-07-05 09:43:56,720 - WARNING - Epoch [8/20] Step [101/125]  acc 0.875485 (0.901928)  loss 0.299822 (0.241562)
GPU memory consumption  GPU Memory: Allocated: 114.4 MB, Reserved: 10158.0 MB
2025-07-05 09:44:00,132 - WARNING - Epoch [8/20] Step [111/125]  acc 0.901818 (0.902178)  loss 0.239246 (0.241174)
GPU memory consumption  GPU Memory: Allocated: 130.1 MB, Reserved: 10158.0 MB
2025-07-05 09:44:03,456 - WARNING - Epoch [8/20] Step [121/125]  acc 0.896597 (0.902216)  loss 0.250404 (0.241036)
GPU memory consumption  GPU Memory: Allocated: 129.9 MB, Reserved: 10158.0 MB
Epoch 8 completed in 0:00:41.150102
2025-07-05 09:44:15,293 - WARNING - Epoch [9/20] Step [1/125]  acc 0.902857 (0.902857)  loss 0.230921 (0.230921)
GPU memory consumption  GPU Memory: Allocated: 132.6 MB, Reserved: 10158.0 MB
2025-07-05 09:44:18,612 - WARNING - Epoch [9/20] Step [11/125]  acc 0.915759 (0.903044)  loss 0.207486 (0.237921)
GPU memory consumption  GPU Memory: Allocated: 127.6 MB, Reserved: 10158.0 MB
2025-07-05 09:44:21,790 - WARNING - Epoch [9/20] Step [21/125]  acc 0.897216 (0.902765)  loss 0.242825 (0.239092)
GPU memory consumption  GPU Memory: Allocated: 122.0 MB, Reserved: 10158.0 MB
2025-07-05 09:44:25,015 - WARNING - Epoch [9/20] Step [31/125]  acc 0.894124 (0.902725)  loss 0.253278 (0.239040)
GPU memory consumption  GPU Memory: Allocated: 119.8 MB, Reserved: 10158.0 MB
2025-07-05 09:44:28,227 - WARNING - Epoch [9/20] Step [41/125]  acc 0.910517 (0.902303)  loss 0.218364 (0.240559)
GPU memory consumption  GPU Memory: Allocated: 124.4 MB, Reserved: 10158.0 MB
2025-07-05 09:44:31,596 - WARNING - Epoch [9/20] Step [51/125]  acc 0.894978 (0.902691)  loss 0.243618 (0.239672)
GPU memory consumption  GPU Memory: Allocated: 131.6 MB, Reserved: 10158.0 MB
2025-07-05 09:44:34,881 - WARNING - Epoch [9/20] Step [61/125]  acc 0.896869 (0.902994)  loss 0.243860 (0.238797)
GPU memory consumption  GPU Memory: Allocated: 129.4 MB, Reserved: 10158.0 MB
2025-07-05 09:44:38,173 - WARNING - Epoch [9/20] Step [71/125]  acc 0.900576 (0.902904)  loss 0.243160 (0.239069)
GPU memory consumption  GPU Memory: Allocated: 127.2 MB, Reserved: 10158.0 MB
2025-07-05 09:44:41,435 - WARNING - Epoch [9/20] Step [81/125]  acc 0.908233 (0.903502)  loss 0.218727 (0.238009)
GPU memory consumption  GPU Memory: Allocated: 124.3 MB, Reserved: 14418.0 MB
2025-07-05 09:44:44,720 - WARNING - Epoch [9/20] Step [91/125]  acc 0.911825 (0.903516)  loss 0.223244 (0.237612)
GPU memory consumption  GPU Memory: Allocated: 126.4 MB, Reserved: 14418.0 MB
2025-07-05 09:44:48,112 - WARNING - Epoch [9/20] Step [101/125]  acc 0.902537 (0.903848)  loss 0.241556 (0.237112)
GPU memory consumption  GPU Memory: Allocated: 117.5 MB, Reserved: 14418.0 MB
2025-07-05 09:44:51,376 - WARNING - Epoch [9/20] Step [111/125]  acc 0.918170 (0.904074)  loss 0.211935 (0.236873)
GPU memory consumption  GPU Memory: Allocated: 131.6 MB, Reserved: 14418.0 MB
2025-07-05 09:44:54,665 - WARNING - Epoch [9/20] Step [121/125]  acc 0.892781 (0.903857)  loss 0.268838 (0.237272)
GPU memory consumption  GPU Memory: Allocated: 129.2 MB, Reserved: 14418.0 MB
Epoch 9 completed in 0:00:41.053331
2025-07-05 09:45:06,552 - WARNING - Epoch [10/20] Step [1/125]  acc 0.886394 (0.886394)  loss 0.270649 (0.270649)
GPU memory consumption  GPU Memory: Allocated: 129.4 MB, Reserved: 14418.0 MB
2025-07-05 09:45:09,734 - WARNING - Epoch [10/20] Step [11/125]  acc 0.918734 (0.904233)  loss 0.215651 (0.238720)
GPU memory consumption  GPU Memory: Allocated: 129.7 MB, Reserved: 14418.0 MB
2025-07-05 09:45:13,024 - WARNING - Epoch [10/20] Step [21/125]  acc 0.908112 (0.904894)  loss 0.244042 (0.235543)
GPU memory consumption  GPU Memory: Allocated: 124.6 MB, Reserved: 14418.0 MB
2025-07-05 09:45:16,304 - WARNING - Epoch [10/20] Step [31/125]  acc 0.897249 (0.904525)  loss 0.249368 (0.235861)
GPU memory consumption  GPU Memory: Allocated: 118.5 MB, Reserved: 14418.0 MB
2025-07-05 09:45:19,556 - WARNING - Epoch [10/20] Step [41/125]  acc 0.899870 (0.904441)  loss 0.245969 (0.235345)
GPU memory consumption  GPU Memory: Allocated: 123.6 MB, Reserved: 14418.0 MB
2025-07-05 09:45:22,747 - WARNING - Epoch [10/20] Step [51/125]  acc 0.902003 (0.903200)  loss 0.239402 (0.237731)
GPU memory consumption  GPU Memory: Allocated: 124.5 MB, Reserved: 14418.0 MB
2025-07-05 09:45:25,939 - WARNING - Epoch [10/20] Step [61/125]  acc 0.897219 (0.902783)  loss 0.240746 (0.237962)
GPU memory consumption  GPU Memory: Allocated: 126.3 MB, Reserved: 14418.0 MB
2025-07-05 09:45:29,127 - WARNING - Epoch [10/20] Step [71/125]  acc 0.897266 (0.902756)  loss 0.242201 (0.238457)
GPU memory consumption  GPU Memory: Allocated: 122.9 MB, Reserved: 14418.0 MB
2025-07-05 09:45:32,410 - WARNING - Epoch [10/20] Step [81/125]  acc 0.906954 (0.902791)  loss 0.230475 (0.238777)
GPU memory consumption  GPU Memory: Allocated: 133.3 MB, Reserved: 14418.0 MB
2025-07-05 09:45:35,647 - WARNING - Epoch [10/20] Step [91/125]  acc 0.915446 (0.903011)  loss 0.223206 (0.238631)
GPU memory consumption  GPU Memory: Allocated: 125.7 MB, Reserved: 14418.0 MB
2025-07-05 09:45:39,045 - WARNING - Epoch [10/20] Step [101/125]  acc 0.888195 (0.902821)  loss 0.263833 (0.239064)
GPU memory consumption  GPU Memory: Allocated: 116.6 MB, Reserved: 14418.0 MB
2025-07-05 09:45:42,263 - WARNING - Epoch [10/20] Step [111/125]  acc 0.899017 (0.902581)  loss 0.250508 (0.239308)
GPU memory consumption  GPU Memory: Allocated: 124.9 MB, Reserved: 14418.0 MB
2025-07-05 09:45:45,585 - WARNING - Epoch [10/20] Step [121/125]  acc 0.918869 (0.902863)  loss 0.217776 (0.238790)
GPU memory consumption  GPU Memory: Allocated: 130.2 MB, Reserved: 14418.0 MB
Epoch 10 completed in 0:00:40.724137
2025-07-05 09:45:57,343 - WARNING - Epoch [11/20] Step [1/125]  acc 0.904416 (0.904416)  loss 0.238097 (0.238097)
GPU memory consumption  GPU Memory: Allocated: 132.3 MB, Reserved: 14418.0 MB
2025-07-05 09:46:00,584 - WARNING - Epoch [11/20] Step [11/125]  acc 0.904284 (0.901408)  loss 0.240166 (0.243555)
GPU memory consumption  GPU Memory: Allocated: 122.6 MB, Reserved: 14418.0 MB
2025-07-05 09:46:03,802 - WARNING - Epoch [11/20] Step [21/125]  acc 0.898061 (0.904373)  loss 0.242715 (0.236540)
GPU memory consumption  GPU Memory: Allocated: 130.7 MB, Reserved: 14418.0 MB
2025-07-05 09:46:07,133 - WARNING - Epoch [11/20] Step [31/125]  acc 0.906959 (0.904791)  loss 0.225499 (0.235490)
GPU memory consumption  GPU Memory: Allocated: 125.3 MB, Reserved: 14418.0 MB
2025-07-05 09:46:10,437 - WARNING - Epoch [11/20] Step [41/125]  acc 0.892479 (0.904514)  loss 0.255403 (0.234958)
GPU memory consumption  GPU Memory: Allocated: 123.8 MB, Reserved: 14418.0 MB
2025-07-05 09:46:13,633 - WARNING - Epoch [11/20] Step [51/125]  acc 0.906782 (0.904617)  loss 0.222483 (0.234871)
GPU memory consumption  GPU Memory: Allocated: 131.6 MB, Reserved: 14418.0 MB
2025-07-05 09:46:16,866 - WARNING - Epoch [11/20] Step [61/125]  acc 0.904672 (0.903945)  loss 0.238722 (0.236084)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 14418.0 MB
2025-07-05 09:46:20,173 - WARNING - Epoch [11/20] Step [71/125]  acc 0.913110 (0.904109)  loss 0.214495 (0.235578)
GPU memory consumption  GPU Memory: Allocated: 130.2 MB, Reserved: 14418.0 MB
2025-07-05 09:46:23,372 - WARNING - Epoch [11/20] Step [81/125]  acc 0.906321 (0.903933)  loss 0.228487 (0.235964)
GPU memory consumption  GPU Memory: Allocated: 128.7 MB, Reserved: 14418.0 MB
2025-07-05 09:46:26,693 - WARNING - Epoch [11/20] Step [91/125]  acc 0.891114 (0.903865)  loss 0.255676 (0.236080)
GPU memory consumption  GPU Memory: Allocated: 120.0 MB, Reserved: 14418.0 MB
2025-07-05 09:46:29,996 - WARNING - Epoch [11/20] Step [101/125]  acc 0.904460 (0.903772)  loss 0.231498 (0.236294)
GPU memory consumption  GPU Memory: Allocated: 118.2 MB, Reserved: 14418.0 MB
2025-07-05 09:46:33,213 - WARNING - Epoch [11/20] Step [111/125]  acc 0.904963 (0.903683)  loss 0.236092 (0.236707)
GPU memory consumption  GPU Memory: Allocated: 128.5 MB, Reserved: 14418.0 MB
2025-07-05 09:46:36,487 - WARNING - Epoch [11/20] Step [121/125]  acc 0.904372 (0.903835)  loss 0.233129 (0.236360)
GPU memory consumption  GPU Memory: Allocated: 132.7 MB, Reserved: 14418.0 MB
Epoch 11 completed in 0:00:40.842092
2025-07-05 09:46:48,356 - WARNING - Epoch [12/20] Step [1/125]  acc 0.894482 (0.894482)  loss 0.253619 (0.253619)
GPU memory consumption  GPU Memory: Allocated: 129.5 MB, Reserved: 14418.0 MB
2025-07-05 09:46:51,579 - WARNING - Epoch [12/20] Step [11/125]  acc 0.894538 (0.899825)  loss 0.248866 (0.241528)
GPU memory consumption  GPU Memory: Allocated: 123.9 MB, Reserved: 14418.0 MB
2025-07-05 09:46:54,799 - WARNING - Epoch [12/20] Step [21/125]  acc 0.903583 (0.900005)  loss 0.241643 (0.241812)
GPU memory consumption  GPU Memory: Allocated: 123.2 MB, Reserved: 14418.0 MB
2025-07-05 09:46:58,146 - WARNING - Epoch [12/20] Step [31/125]  acc 0.908799 (0.902527)  loss 0.226880 (0.237044)
GPU memory consumption  GPU Memory: Allocated: 122.7 MB, Reserved: 14418.0 MB
2025-07-05 09:47:01,493 - WARNING - Epoch [12/20] Step [41/125]  acc 0.900293 (0.901512)  loss 0.244847 (0.239291)
GPU memory consumption  GPU Memory: Allocated: 120.5 MB, Reserved: 14418.0 MB
2025-07-05 09:47:04,779 - WARNING - Epoch [12/20] Step [51/125]  acc 0.904008 (0.902433)  loss 0.235291 (0.238019)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 14418.0 MB
2025-07-05 09:47:08,040 - WARNING - Epoch [12/20] Step [61/125]  acc 0.909091 (0.902495)  loss 0.236786 (0.238363)
GPU memory consumption  GPU Memory: Allocated: 128.4 MB, Reserved: 14418.0 MB
2025-07-05 09:47:11,323 - WARNING - Epoch [12/20] Step [71/125]  acc 0.906480 (0.903091)  loss 0.224880 (0.236995)
GPU memory consumption  GPU Memory: Allocated: 131.0 MB, Reserved: 14418.0 MB
2025-07-05 09:47:14,647 - WARNING - Epoch [12/20] Step [81/125]  acc 0.910392 (0.903416)  loss 0.218229 (0.236751)
GPU memory consumption  GPU Memory: Allocated: 129.1 MB, Reserved: 14418.0 MB
2025-07-05 09:47:17,916 - WARNING - Epoch [12/20] Step [91/125]  acc 0.903851 (0.903161)  loss 0.236590 (0.237157)
GPU memory consumption  GPU Memory: Allocated: 122.7 MB, Reserved: 14418.0 MB
2025-07-05 09:47:21,122 - WARNING - Epoch [12/20] Step [101/125]  acc 0.899838 (0.903492)  loss 0.235210 (0.236806)
GPU memory consumption  GPU Memory: Allocated: 116.2 MB, Reserved: 14418.0 MB
2025-07-05 09:47:24,412 - WARNING - Epoch [12/20] Step [111/125]  acc 0.907201 (0.903565)  loss 0.229244 (0.236536)
GPU memory consumption  GPU Memory: Allocated: 132.8 MB, Reserved: 14418.0 MB
2025-07-05 09:47:27,664 - WARNING - Epoch [12/20] Step [121/125]  acc 0.913807 (0.903593)  loss 0.210632 (0.236700)
GPU memory consumption  GPU Memory: Allocated: 130.3 MB, Reserved: 14418.0 MB
Epoch 12 completed in 0:00:41.013646
2025-07-05 09:47:39,487 - WARNING - Epoch [13/20] Step [1/125]  acc 0.901277 (0.901277)  loss 0.236309 (0.236309)
GPU memory consumption  GPU Memory: Allocated: 129.8 MB, Reserved: 14418.0 MB
2025-07-05 09:47:42,764 - WARNING - Epoch [13/20] Step [11/125]  acc 0.909067 (0.904080)  loss 0.228419 (0.233990)
GPU memory consumption  GPU Memory: Allocated: 128.0 MB, Reserved: 14418.0 MB
2025-07-05 09:47:46,145 - WARNING - Epoch [13/20] Step [21/125]  acc 0.906954 (0.904233)  loss 0.220751 (0.233278)
GPU memory consumption  GPU Memory: Allocated: 128.6 MB, Reserved: 14418.0 MB
2025-07-05 09:47:49,388 - WARNING - Epoch [13/20] Step [31/125]  acc 0.910696 (0.903115)  loss 0.224921 (0.235796)
GPU memory consumption  GPU Memory: Allocated: 127.5 MB, Reserved: 14418.0 MB
2025-07-05 09:47:52,592 - WARNING - Epoch [13/20] Step [41/125]  acc 0.908599 (0.903406)  loss 0.230739 (0.235963)
GPU memory consumption  GPU Memory: Allocated: 119.6 MB, Reserved: 14418.0 MB
2025-07-05 09:47:55,980 - WARNING - Epoch [13/20] Step [51/125]  acc 0.903415 (0.903227)  loss 0.244110 (0.236688)
GPU memory consumption  GPU Memory: Allocated: 126.1 MB, Reserved: 14418.0 MB
2025-07-05 09:47:59,347 - WARNING - Epoch [13/20] Step [61/125]  acc 0.902813 (0.903249)  loss 0.244146 (0.236536)
GPU memory consumption  GPU Memory: Allocated: 134.2 MB, Reserved: 14418.0 MB
2025-07-05 09:48:02,660 - WARNING - Epoch [13/20] Step [71/125]  acc 0.917818 (0.903517)  loss 0.212002 (0.236083)
GPU memory consumption  GPU Memory: Allocated: 133.9 MB, Reserved: 14418.0 MB
2025-07-05 09:48:05,840 - WARNING - Epoch [13/20] Step [81/125]  acc 0.904600 (0.903476)  loss 0.240478 (0.236364)
GPU memory consumption  GPU Memory: Allocated: 124.4 MB, Reserved: 14418.0 MB
2025-07-05 09:48:09,032 - WARNING - Epoch [13/20] Step [91/125]  acc 0.895924 (0.903333)  loss 0.255317 (0.236242)
GPU memory consumption  GPU Memory: Allocated: 126.8 MB, Reserved: 14418.0 MB
2025-07-05 09:48:12,201 - WARNING - Epoch [13/20] Step [101/125]  acc 0.913872 (0.903672)  loss 0.211070 (0.235752)
GPU memory consumption  GPU Memory: Allocated: 122.2 MB, Reserved: 14418.0 MB
2025-07-05 09:48:15,448 - WARNING - Epoch [13/20] Step [111/125]  acc 0.905225 (0.904081)  loss 0.232865 (0.234918)
GPU memory consumption  GPU Memory: Allocated: 131.4 MB, Reserved: 14418.0 MB
2025-07-05 09:48:18,684 - WARNING - Epoch [13/20] Step [121/125]  acc 0.914510 (0.904277)  loss 0.214325 (0.234588)
GPU memory consumption  GPU Memory: Allocated: 133.4 MB, Reserved: 14418.0 MB
Epoch 13 completed in 0:00:40.838576
2025-07-05 09:48:30,467 - WARNING - Epoch [14/20] Step [1/125]  acc 0.899138 (0.899138)  loss 0.252199 (0.252199)
GPU memory consumption  GPU Memory: Allocated: 136.0 MB, Reserved: 14418.0 MB
2025-07-05 09:48:33,827 - WARNING - Epoch [14/20] Step [11/125]  acc 0.891899 (0.902065)  loss 0.256114 (0.238505)
GPU memory consumption  GPU Memory: Allocated: 126.2 MB, Reserved: 14418.0 MB
2025-07-05 09:48:37,060 - WARNING - Epoch [14/20] Step [21/125]  acc 0.906862 (0.903306)  loss 0.230311 (0.237340)
GPU memory consumption  GPU Memory: Allocated: 130.7 MB, Reserved: 14418.0 MB
2025-07-05 09:48:40,272 - WARNING - Epoch [14/20] Step [31/125]  acc 0.895822 (0.902912)  loss 0.252935 (0.237086)
GPU memory consumption  GPU Memory: Allocated: 123.3 MB, Reserved: 14418.0 MB
2025-07-05 09:48:43,615 - WARNING - Epoch [14/20] Step [41/125]  acc 0.893181 (0.903286)  loss 0.264851 (0.237410)
GPU memory consumption  GPU Memory: Allocated: 120.9 MB, Reserved: 14418.0 MB
2025-07-05 09:48:46,930 - WARNING - Epoch [14/20] Step [51/125]  acc 0.914457 (0.904868)  loss 0.216070 (0.234457)
GPU memory consumption  GPU Memory: Allocated: 132.6 MB, Reserved: 14418.0 MB
2025-07-05 09:48:50,383 - WARNING - Epoch [14/20] Step [61/125]  acc 0.908137 (0.904917)  loss 0.226925 (0.234371)
GPU memory consumption  GPU Memory: Allocated: 123.0 MB, Reserved: 14418.0 MB
2025-07-05 09:48:53,788 - WARNING - Epoch [14/20] Step [71/125]  acc 0.911151 (0.905023)  loss 0.219006 (0.233624)
GPU memory consumption  GPU Memory: Allocated: 129.2 MB, Reserved: 14418.0 MB
2025-07-05 09:48:57,331 - WARNING - Epoch [14/20] Step [81/125]  acc 0.904940 (0.905417)  loss 0.235189 (0.232797)
GPU memory consumption  GPU Memory: Allocated: 122.9 MB, Reserved: 14418.0 MB
2025-07-05 09:49:00,856 - WARNING - Epoch [14/20] Step [91/125]  acc 0.918220 (0.905824)  loss 0.200380 (0.231803)
GPU memory consumption  GPU Memory: Allocated: 129.3 MB, Reserved: 14418.0 MB
2025-07-05 09:49:04,175 - WARNING - Epoch [14/20] Step [101/125]  acc 0.901635 (0.905672)  loss 0.235088 (0.231950)
GPU memory consumption  GPU Memory: Allocated: 117.5 MB, Reserved: 14418.0 MB
2025-07-05 09:49:07,526 - WARNING - Epoch [14/20] Step [111/125]  acc 0.905208 (0.905782)  loss 0.226518 (0.231583)
GPU memory consumption  GPU Memory: Allocated: 129.5 MB, Reserved: 14418.0 MB
2025-07-05 09:49:10,941 - WARNING - Epoch [14/20] Step [121/125]  acc 0.901283 (0.905750)  loss 0.235019 (0.231745)
GPU memory consumption  GPU Memory: Allocated: 130.2 MB, Reserved: 14418.0 MB
Epoch 14 completed in 0:00:42.198247
2025-07-05 09:49:22,667 - WARNING - Epoch [15/20] Step [1/125]  acc 0.915694 (0.915694)  loss 0.220093 (0.220093)
GPU memory consumption  GPU Memory: Allocated: 133.0 MB, Reserved: 14418.0 MB
2025-07-05 09:49:26,053 - WARNING - Epoch [15/20] Step [11/125]  acc 0.907118 (0.902467)  loss 0.232330 (0.240511)
GPU memory consumption  GPU Memory: Allocated: 118.0 MB, Reserved: 14418.0 MB
2025-07-05 09:49:29,364 - WARNING - Epoch [15/20] Step [21/125]  acc 0.895467 (0.903887)  loss 0.253989 (0.235745)
GPU memory consumption  GPU Memory: Allocated: 123.4 MB, Reserved: 14418.0 MB
2025-07-05 09:49:32,585 - WARNING - Epoch [15/20] Step [31/125]  acc 0.874793 (0.904053)  loss 0.284204 (0.234994)
GPU memory consumption  GPU Memory: Allocated: 120.2 MB, Reserved: 14418.0 MB
2025-07-05 09:49:35,851 - WARNING - Epoch [15/20] Step [41/125]  acc 0.918863 (0.905815)  loss 0.200237 (0.231058)
GPU memory consumption  GPU Memory: Allocated: 122.8 MB, Reserved: 14418.0 MB
2025-07-05 09:49:39,145 - WARNING - Epoch [15/20] Step [51/125]  acc 0.904573 (0.905118)  loss 0.234292 (0.232344)
GPU memory consumption  GPU Memory: Allocated: 126.4 MB, Reserved: 14418.0 MB
2025-07-05 09:49:42,584 - WARNING - Epoch [15/20] Step [61/125]  acc 0.909044 (0.905372)  loss 0.223085 (0.232062)
GPU memory consumption  GPU Memory: Allocated: 132.0 MB, Reserved: 14418.0 MB
2025-07-05 09:49:45,836 - WARNING - Epoch [15/20] Step [71/125]  acc 0.891529 (0.904830)  loss 0.259242 (0.232635)
GPU memory consumption  GPU Memory: Allocated: 121.2 MB, Reserved: 14418.0 MB
2025-07-05 09:49:49,041 - WARNING - Epoch [15/20] Step [81/125]  acc 0.907031 (0.905009)  loss 0.244973 (0.232239)
GPU memory consumption  GPU Memory: Allocated: 126.5 MB, Reserved: 14418.0 MB
2025-07-05 09:49:52,309 - WARNING - Epoch [15/20] Step [91/125]  acc 0.907374 (0.904892)  loss 0.226590 (0.232408)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 14418.0 MB
2025-07-05 09:49:55,629 - WARNING - Epoch [15/20] Step [101/125]  acc 0.901189 (0.904829)  loss 0.238842 (0.232448)
GPU memory consumption  GPU Memory: Allocated: 126.1 MB, Reserved: 14418.0 MB
2025-07-05 09:49:59,054 - WARNING - Epoch [15/20] Step [111/125]  acc 0.914212 (0.904674)  loss 0.216172 (0.232553)
GPU memory consumption  GPU Memory: Allocated: 130.1 MB, Reserved: 14418.0 MB
2025-07-05 09:50:02,311 - WARNING - Epoch [15/20] Step [121/125]  acc 0.899134 (0.904924)  loss 0.235929 (0.232145)
GPU memory consumption  GPU Memory: Allocated: 133.6 MB, Reserved: 14418.0 MB
Epoch 15 completed in 0:00:41.329270
2025-07-05 09:50:14,338 - WARNING - Epoch [16/20] Step [1/125]  acc 0.909206 (0.909206)  loss 0.228942 (0.228942)
GPU memory consumption  GPU Memory: Allocated: 135.9 MB, Reserved: 14418.0 MB
2025-07-05 09:50:17,595 - WARNING - Epoch [16/20] Step [11/125]  acc 0.907057 (0.904911)  loss 0.232102 (0.234111)
GPU memory consumption  GPU Memory: Allocated: 133.6 MB, Reserved: 14418.0 MB
2025-07-05 09:50:20,828 - WARNING - Epoch [16/20] Step [21/125]  acc 0.903595 (0.904725)  loss 0.232748 (0.234921)
GPU memory consumption  GPU Memory: Allocated: 123.8 MB, Reserved: 14418.0 MB
2025-07-05 09:50:24,055 - WARNING - Epoch [16/20] Step [31/125]  acc 0.916512 (0.905186)  loss 0.210724 (0.233213)
GPU memory consumption  GPU Memory: Allocated: 124.5 MB, Reserved: 14418.0 MB
2025-07-05 09:50:27,438 - WARNING - Epoch [16/20] Step [41/125]  acc 0.908778 (0.905494)  loss 0.221046 (0.232656)
GPU memory consumption  GPU Memory: Allocated: 120.5 MB, Reserved: 14418.0 MB
2025-07-05 09:50:30,819 - WARNING - Epoch [16/20] Step [51/125]  acc 0.907196 (0.905256)  loss 0.225955 (0.232588)
GPU memory consumption  GPU Memory: Allocated: 131.0 MB, Reserved: 14418.0 MB
2025-07-05 09:50:33,953 - WARNING - Epoch [16/20] Step [61/125]  acc 0.903104 (0.905097)  loss 0.246635 (0.232975)
GPU memory consumption  GPU Memory: Allocated: 127.1 MB, Reserved: 14418.0 MB
2025-07-05 09:50:37,180 - WARNING - Epoch [16/20] Step [71/125]  acc 0.899561 (0.905036)  loss 0.246755 (0.233227)
GPU memory consumption  GPU Memory: Allocated: 129.0 MB, Reserved: 14418.0 MB
2025-07-05 09:50:40,642 - WARNING - Epoch [16/20] Step [81/125]  acc 0.890422 (0.904950)  loss 0.264104 (0.233667)
GPU memory consumption  GPU Memory: Allocated: 121.7 MB, Reserved: 14418.0 MB
2025-07-05 09:50:43,921 - WARNING - Epoch [16/20] Step [91/125]  acc 0.892771 (0.904790)  loss 0.254766 (0.233979)
GPU memory consumption  GPU Memory: Allocated: 122.3 MB, Reserved: 14418.0 MB
2025-07-05 09:50:47,151 - WARNING - Epoch [16/20] Step [101/125]  acc 0.902763 (0.904715)  loss 0.241662 (0.234015)
GPU memory consumption  GPU Memory: Allocated: 120.7 MB, Reserved: 14418.0 MB
2025-07-05 09:50:50,376 - WARNING - Epoch [16/20] Step [111/125]  acc 0.910343 (0.904699)  loss 0.220681 (0.234046)
GPU memory consumption  GPU Memory: Allocated: 138.0 MB, Reserved: 14418.0 MB
2025-07-05 09:50:53,567 - WARNING - Epoch [16/20] Step [121/125]  acc 0.897169 (0.904558)  loss 0.249327 (0.234528)
GPU memory consumption  GPU Memory: Allocated: 128.6 MB, Reserved: 14418.0 MB
Epoch 16 completed in 0:00:40.901539
2025-07-05 09:51:05,122 - WARNING - Epoch [17/20] Step [1/125]  acc 0.910580 (0.910580)  loss 0.219732 (0.219732)
GPU memory consumption  GPU Memory: Allocated: 132.5 MB, Reserved: 14418.0 MB
2025-07-05 09:51:08,400 - WARNING - Epoch [17/20] Step [11/125]  acc 0.897194 (0.908598)  loss 0.252492 (0.226603)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 14418.0 MB
2025-07-05 09:51:11,707 - WARNING - Epoch [17/20] Step [21/125]  acc 0.911749 (0.906103)  loss 0.235711 (0.232235)
GPU memory consumption  GPU Memory: Allocated: 126.1 MB, Reserved: 14418.0 MB
2025-07-05 09:51:15,145 - WARNING - Epoch [17/20] Step [31/125]  acc 0.908976 (0.905418)  loss 0.225239 (0.233985)
GPU memory consumption  GPU Memory: Allocated: 128.5 MB, Reserved: 14418.0 MB
2025-07-05 09:51:18,325 - WARNING - Epoch [17/20] Step [41/125]  acc 0.902674 (0.905195)  loss 0.236652 (0.233898)
GPU memory consumption  GPU Memory: Allocated: 120.3 MB, Reserved: 14418.0 MB
2025-07-05 09:51:21,540 - WARNING - Epoch [17/20] Step [51/125]  acc 0.905837 (0.905475)  loss 0.218617 (0.233358)
GPU memory consumption  GPU Memory: Allocated: 127.8 MB, Reserved: 14418.0 MB
2025-07-05 09:51:24,831 - WARNING - Epoch [17/20] Step [61/125]  acc 0.904797 (0.905888)  loss 0.224329 (0.232251)
GPU memory consumption  GPU Memory: Allocated: 135.3 MB, Reserved: 14418.0 MB
2025-07-05 09:51:28,133 - WARNING - Epoch [17/20] Step [71/125]  acc 0.895539 (0.905055)  loss 0.243795 (0.232973)
GPU memory consumption  GPU Memory: Allocated: 122.6 MB, Reserved: 14418.0 MB
2025-07-05 09:51:31,387 - WARNING - Epoch [17/20] Step [81/125]  acc 0.910859 (0.905093)  loss 0.231871 (0.232838)
GPU memory consumption  GPU Memory: Allocated: 121.3 MB, Reserved: 14418.0 MB
2025-07-05 09:51:34,792 - WARNING - Epoch [17/20] Step [91/125]  acc 0.909778 (0.905188)  loss 0.219809 (0.232369)
GPU memory consumption  GPU Memory: Allocated: 128.2 MB, Reserved: 14418.0 MB
2025-07-05 09:51:38,063 - WARNING - Epoch [17/20] Step [101/125]  acc 0.914938 (0.905096)  loss 0.217607 (0.232755)
GPU memory consumption  GPU Memory: Allocated: 118.9 MB, Reserved: 14418.0 MB
2025-07-05 09:51:41,232 - WARNING - Epoch [17/20] Step [111/125]  acc 0.907403 (0.904702)  loss 0.223287 (0.233386)
GPU memory consumption  GPU Memory: Allocated: 129.2 MB, Reserved: 14418.0 MB
2025-07-05 09:51:44,434 - WARNING - Epoch [17/20] Step [121/125]  acc 0.912132 (0.904593)  loss 0.224826 (0.233827)
GPU memory consumption  GPU Memory: Allocated: 129.0 MB, Reserved: 14418.0 MB
Epoch 17 completed in 0:00:40.934177
2025-07-05 09:51:56,524 - WARNING - Epoch [18/20] Step [1/125]  acc 0.904586 (0.904586)  loss 0.236316 (0.236316)
GPU memory consumption  GPU Memory: Allocated: 131.3 MB, Reserved: 14418.0 MB
2025-07-05 09:51:59,793 - WARNING - Epoch [18/20] Step [11/125]  acc 0.907458 (0.900504)  loss 0.226919 (0.240489)
GPU memory consumption  GPU Memory: Allocated: 123.3 MB, Reserved: 14418.0 MB
2025-07-05 09:52:03,091 - WARNING - Epoch [18/20] Step [21/125]  acc 0.901055 (0.901950)  loss 0.237124 (0.238739)
GPU memory consumption  GPU Memory: Allocated: 128.9 MB, Reserved: 14418.0 MB
2025-07-05 09:52:06,384 - WARNING - Epoch [18/20] Step [31/125]  acc 0.913555 (0.902661)  loss 0.219099 (0.237254)
GPU memory consumption  GPU Memory: Allocated: 127.6 MB, Reserved: 14418.0 MB
2025-07-05 09:52:09,623 - WARNING - Epoch [18/20] Step [41/125]  acc 0.924488 (0.903940)  loss 0.202247 (0.234620)
GPU memory consumption  GPU Memory: Allocated: 118.7 MB, Reserved: 14418.0 MB
2025-07-05 09:52:12,840 - WARNING - Epoch [18/20] Step [51/125]  acc 0.905765 (0.904086)  loss 0.223921 (0.234006)
GPU memory consumption  GPU Memory: Allocated: 126.6 MB, Reserved: 14418.0 MB
2025-07-05 09:52:16,109 - WARNING - Epoch [18/20] Step [61/125]  acc 0.912500 (0.904266)  loss 0.221365 (0.233682)
GPU memory consumption  GPU Memory: Allocated: 133.8 MB, Reserved: 14418.0 MB
2025-07-05 09:52:19,352 - WARNING - Epoch [18/20] Step [71/125]  acc 0.905941 (0.903809)  loss 0.236072 (0.234695)
GPU memory consumption  GPU Memory: Allocated: 127.6 MB, Reserved: 14418.0 MB
2025-07-05 09:52:22,606 - WARNING - Epoch [18/20] Step [81/125]  acc 0.909350 (0.903916)  loss 0.215324 (0.234917)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 14418.0 MB
2025-07-05 09:52:25,861 - WARNING - Epoch [18/20] Step [91/125]  acc 0.896652 (0.904070)  loss 0.246896 (0.234327)
GPU memory consumption  GPU Memory: Allocated: 122.7 MB, Reserved: 14418.0 MB
2025-07-05 09:52:29,187 - WARNING - Epoch [18/20] Step [101/125]  acc 0.906691 (0.904240)  loss 0.224718 (0.234022)
GPU memory consumption  GPU Memory: Allocated: 121.8 MB, Reserved: 14418.0 MB
2025-07-05 09:52:32,481 - WARNING - Epoch [18/20] Step [111/125]  acc 0.914806 (0.904324)  loss 0.210023 (0.233541)
GPU memory consumption  GPU Memory: Allocated: 130.7 MB, Reserved: 14418.0 MB
2025-07-05 09:52:35,791 - WARNING - Epoch [18/20] Step [121/125]  acc 0.893116 (0.904642)  loss 0.256497 (0.233028)
GPU memory consumption  GPU Memory: Allocated: 131.4 MB, Reserved: 14418.0 MB
Epoch 18 completed in 0:00:40.952512
2025-07-05 09:52:47,700 - WARNING - Epoch [19/20] Step [1/125]  acc 0.904343 (0.904343)  loss 0.226924 (0.226924)
GPU memory consumption  GPU Memory: Allocated: 130.9 MB, Reserved: 14418.0 MB
2025-07-05 09:52:50,991 - WARNING - Epoch [19/20] Step [11/125]  acc 0.914865 (0.905460)  loss 0.210144 (0.233136)
GPU memory consumption  GPU Memory: Allocated: 124.2 MB, Reserved: 14418.0 MB
2025-07-05 09:52:54,266 - WARNING - Epoch [19/20] Step [21/125]  acc 0.911441 (0.905673)  loss 0.221203 (0.231961)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 14418.0 MB
2025-07-05 09:52:57,595 - WARNING - Epoch [19/20] Step [31/125]  acc 0.905845 (0.905737)  loss 0.235613 (0.232440)
GPU memory consumption  GPU Memory: Allocated: 124.3 MB, Reserved: 14418.0 MB
2025-07-05 09:53:00,930 - WARNING - Epoch [19/20] Step [41/125]  acc 0.893267 (0.905676)  loss 0.255491 (0.232408)
GPU memory consumption  GPU Memory: Allocated: 122.2 MB, Reserved: 14418.0 MB
2025-07-05 09:53:04,331 - WARNING - Epoch [19/20] Step [51/125]  acc 0.909798 (0.904859)  loss 0.217680 (0.233966)
GPU memory consumption  GPU Memory: Allocated: 129.7 MB, Reserved: 14418.0 MB
2025-07-05 09:53:07,696 - WARNING - Epoch [19/20] Step [61/125]  acc 0.894908 (0.904884)  loss 0.253109 (0.233656)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 14418.0 MB
2025-07-05 09:53:11,107 - WARNING - Epoch [19/20] Step [71/125]  acc 0.916792 (0.905055)  loss 0.207347 (0.232994)
GPU memory consumption  GPU Memory: Allocated: 131.2 MB, Reserved: 14418.0 MB
2025-07-05 09:53:14,476 - WARNING - Epoch [19/20] Step [81/125]  acc 0.907440 (0.905018)  loss 0.223270 (0.232906)
GPU memory consumption  GPU Memory: Allocated: 127.9 MB, Reserved: 14418.0 MB
2025-07-05 09:53:17,856 - WARNING - Epoch [19/20] Step [91/125]  acc 0.905754 (0.904920)  loss 0.227534 (0.233122)
GPU memory consumption  GPU Memory: Allocated: 123.9 MB, Reserved: 14418.0 MB
2025-07-05 09:53:21,207 - WARNING - Epoch [19/20] Step [101/125]  acc 0.907652 (0.904441)  loss 0.224787 (0.233831)
GPU memory consumption  GPU Memory: Allocated: 118.8 MB, Reserved: 14418.0 MB
2025-07-05 09:53:24,627 - WARNING - Epoch [19/20] Step [111/125]  acc 0.897531 (0.904595)  loss 0.241040 (0.233442)
GPU memory consumption  GPU Memory: Allocated: 127.2 MB, Reserved: 14418.0 MB
2025-07-05 09:53:28,008 - WARNING - Epoch [19/20] Step [121/125]  acc 0.900267 (0.904595)  loss 0.231746 (0.233371)
GPU memory consumption  GPU Memory: Allocated: 128.6 MB, Reserved: 14418.0 MB
Epoch 19 completed in 0:00:42.009956
2025-07-05 09:53:40,203 - WARNING - Epoch [20/20] Step [1/125]  acc 0.905235 (0.905235)  loss 0.231817 (0.231817)
GPU memory consumption  GPU Memory: Allocated: 129.9 MB, Reserved: 14418.0 MB
2025-07-05 09:53:43,624 - WARNING - Epoch [20/20] Step [11/125]  acc 0.898961 (0.903407)  loss 0.245607 (0.236182)
GPU memory consumption  GPU Memory: Allocated: 127.4 MB, Reserved: 14418.0 MB
2025-07-05 09:53:46,998 - WARNING - Epoch [20/20] Step [21/125]  acc 0.913943 (0.904355)  loss 0.206850 (0.231494)
GPU memory consumption  GPU Memory: Allocated: 126.4 MB, Reserved: 14418.0 MB
2025-07-05 09:53:50,406 - WARNING - Epoch [20/20] Step [31/125]  acc 0.908433 (0.904857)  loss 0.228996 (0.231646)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 14418.0 MB
2025-07-05 09:53:53,795 - WARNING - Epoch [20/20] Step [41/125]  acc 0.903805 (0.904668)  loss 0.243178 (0.231952)
GPU memory consumption  GPU Memory: Allocated: 120.5 MB, Reserved: 14418.0 MB
2025-07-05 09:53:57,199 - WARNING - Epoch [20/20] Step [51/125]  acc 0.899047 (0.904563)  loss 0.240084 (0.232254)
GPU memory consumption  GPU Memory: Allocated: 129.9 MB, Reserved: 14418.0 MB
2025-07-05 09:54:00,617 - WARNING - Epoch [20/20] Step [61/125]  acc 0.906374 (0.904125)  loss 0.230891 (0.233115)
GPU memory consumption  GPU Memory: Allocated: 128.4 MB, Reserved: 14418.0 MB
2025-07-05 09:54:03,995 - WARNING - Epoch [20/20] Step [71/125]  acc 0.913984 (0.904060)  loss 0.211859 (0.232705)
GPU memory consumption  GPU Memory: Allocated: 131.3 MB, Reserved: 14418.0 MB
2025-07-05 09:54:07,388 - WARNING - Epoch [20/20] Step [81/125]  acc 0.903797 (0.904566)  loss 0.239587 (0.231926)
GPU memory consumption  GPU Memory: Allocated: 128.7 MB, Reserved: 14418.0 MB
2025-07-05 09:54:10,780 - WARNING - Epoch [20/20] Step [91/125]  acc 0.903861 (0.904770)  loss 0.230639 (0.231507)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 14418.0 MB
2025-07-05 09:54:14,147 - WARNING - Epoch [20/20] Step [101/125]  acc 0.905439 (0.904744)  loss 0.230471 (0.231468)
GPU memory consumption  GPU Memory: Allocated: 116.0 MB, Reserved: 14418.0 MB
2025-07-05 09:54:17,563 - WARNING - Epoch [20/20] Step [111/125]  acc 0.909068 (0.904646)  loss 0.225579 (0.231823)
GPU memory consumption  GPU Memory: Allocated: 133.8 MB, Reserved: 14418.0 MB
2025-07-05 09:54:20,964 - WARNING - Epoch [20/20] Step [121/125]  acc 0.917259 (0.904556)  loss 0.211067 (0.232429)
GPU memory consumption  GPU Memory: Allocated: 134.2 MB, Reserved: 14418.0 MB
Epoch 20 completed in 0:00:42.466328
2025-07-05 09:54:32,839 - INFO - DARTS search completed in 1033.94s
2025-07-05 09:54:32,839 - INFO - 
============================================================
2025-07-05 09:54:32,839 - INFO - Layer layer_0 Expert Selection:
2025-07-05 09:54:32,839 - INFO -   Expert 0: GINE (α=0.3337)
2025-07-05 09:54:32,839 - INFO -   Expert 1: CustomGatedGCN (α=0.3309)
2025-07-05 09:54:32,839 - INFO -   Expert 2: GATV2 (α=0.3353) ← SELECTED
2025-07-05 09:54:32,839 - INFO - Selected Expert Index: 2 (GATV2)
2025-07-05 09:54:32,839 - INFO - ============================================================

2025-07-05 09:54:32,840 - INFO - 
============================================================
2025-07-05 09:54:32,840 - INFO - Layer layer_1 Expert Selection:
2025-07-05 09:54:32,840 - INFO -   Expert 0: GINE (α=0.3262)
2025-07-05 09:54:32,840 - INFO -   Expert 1: CustomGatedGCN (α=0.3444) ← SELECTED
2025-07-05 09:54:32,840 - INFO -   Expert 2: GATV2 (α=0.3293)
2025-07-05 09:54:32,840 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 09:54:32,840 - INFO - ============================================================

2025-07-05 09:54:32,840 - INFO - 
============================================================
2025-07-05 09:54:32,840 - INFO - Layer layer_2 Expert Selection:
2025-07-05 09:54:32,840 - INFO -   Expert 0: GINE (α=0.3475)
2025-07-05 09:54:32,840 - INFO -   Expert 1: CustomGatedGCN (α=0.3704) ← SELECTED
2025-07-05 09:54:32,840 - INFO -   Expert 2: GATV2 (α=0.2820)
2025-07-05 09:54:32,840 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 09:54:32,840 - INFO - ============================================================

2025-07-05 09:54:32,840 - INFO - 
============================================================
2025-07-05 09:54:32,840 - INFO - Layer layer_3 Expert Selection:
2025-07-05 09:54:32,840 - INFO -   Expert 0: GINE (α=0.3129)
2025-07-05 09:54:32,840 - INFO -   Expert 1: CustomGatedGCN (α=0.3806) ← SELECTED
2025-07-05 09:54:32,840 - INFO -   Expert 2: GATV2 (α=0.3065)
2025-07-05 09:54:32,840 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 09:54:32,840 - INFO - ============================================================

2025-07-05 09:54:32,841 - INFO - 
============================================================
2025-07-05 09:54:32,841 - INFO - Layer layer_4 Expert Selection:
2025-07-05 09:54:32,841 - INFO -   Expert 0: GINE (α=0.3177)
2025-07-05 09:54:32,841 - INFO -   Expert 1: CustomGatedGCN (α=0.3738) ← SELECTED
2025-07-05 09:54:32,841 - INFO -   Expert 2: GATV2 (α=0.3085)
2025-07-05 09:54:32,841 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 09:54:32,841 - INFO - ============================================================

2025-07-05 09:54:32,841 - INFO - 
============================================================
2025-07-05 09:54:32,841 - INFO - Layer layer_5 Expert Selection:
2025-07-05 09:54:32,841 - INFO -   Expert 0: GINE (α=0.3186)
2025-07-05 09:54:32,841 - INFO -   Expert 1: CustomGatedGCN (α=0.3160)
2025-07-05 09:54:32,841 - INFO -   Expert 2: GATV2 (α=0.3654) ← SELECTED
2025-07-05 09:54:32,841 - INFO - Selected Expert Index: 2 (GATV2)
2025-07-05 09:54:32,841 - INFO - ============================================================

=== MODEL PARAMETER COMPARISON ===
Original DARTS model parameters: 487,369
2025-07-05 09:54:32,885 - INFO - Layer 0: Using ONLY Expert 2 (GATV2)
2025-07-05 09:54:32,886 - INFO - DiscreteNASLayer 0: Using ONLY Expert 2 (GATV2)
2025-07-05 09:54:32,890 - INFO - Layer 1: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 09:54:32,890 - INFO - DiscreteNASLayer 1: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 09:54:32,893 - INFO - Layer 2: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 09:54:32,893 - INFO - DiscreteNASLayer 2: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 09:54:32,897 - INFO - Layer 3: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 09:54:32,897 - INFO - DiscreteNASLayer 3: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 09:54:32,900 - INFO - Layer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 09:54:32,900 - INFO - DiscreteNASLayer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 09:54:32,903 - INFO - Layer 5: Using ONLY Expert 2 (GATV2)
2025-07-05 09:54:32,904 - INFO - DiscreteNASLayer 5: Using ONLY Expert 2 (GATV2)
Fresh discrete model parameters: 345,143
Parameter difference: -142,226
✓ Used cfg.share.dim_in (raw input) instead of self.encoder.dim_in (processed)
✓ Fresh discrete model with correct input dimensions
2025-07-05 09:54:32,917 - INFO - Replaced inner model with discrete version
2025-07-05 09:54:32,919 - INFO - Creating fresh optimizer/scheduler for discrete model...
2025-07-05 09:54:32,921 - INFO - Fresh optimizer created: AdamW
2025-07-05 09:54:32,921 - INFO - Fresh scheduler created: LambdaLR
2025-07-05 09:54:32,921 - INFO - Discrete model parameters: 345,143
2025-07-05 09:54:32,921 - INFO - ============================================================
2025-07-05 09:54:32,921 - INFO - PHASE 2: DISCRETE TRAINING WITH UNCERTAINTY
2025-07-05 09:54:32,921 - INFO - ============================================================
2025-07-05 09:54:32,921 - INFO - === Epoch 0 ===
2025-07-05 09:55:13,179 - INFO - train: {'epoch': 0, 'time_epoch': 37.83784, 'eta': 3745.94572, 'eta_hours': 1.04054, 'loss': 0.20113507, 'lr': 0.0, 'params': 345143, 'time_iter': 0.12089, 'accuracy': 0.25669, 'precision': 0.18546, 'recall': 0.9466, 'f1': 0.31015, 'auc': 0.54684, 'accuracy-SBM': 0.52771}
2025-07-05 09:55:13,183 - INFO - ...computing epoch stats took: 2.41s
2025-07-05 09:55:17,951 - INFO - val: {'epoch': 0, 'time_epoch': 4.48226, 'loss': 0.19945317, 'lr': 0, 'params': 345143, 'time_iter': 0.07115, 'accuracy': 0.25325, 'precision': 0.18658, 'recall': 0.958, 'f1': 0.31234, 'auc': 0.55539, 'accuracy-SBM': 0.52983}
2025-07-05 09:55:17,953 - INFO - ...computing epoch stats took: 0.28s
2025-07-05 09:55:23,972 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 09:55:24,264 - INFO - test: {'epoch': 0, 'time_epoch': 4.1932, 'loss': 0.19875532, 'lr': 0, 'params': 345143, 'time_iter': 0.06656, 'accuracy': 0.25063, 'precision': 0.18519, 'recall': 0.95662, 'f1': 0.3103, 'auc': 0.55481, 'accuracy-SBM': 0.52811}
2025-07-05 09:55:24,267 - INFO - ...computing epoch stats took: 0.29s
2025-07-05 09:55:24,267 - INFO - > Epoch 0: took 51.3s (avg 51.3s) | Best so far: epoch 0	train_loss: 0.2011 train_accuracy-SBM: 0.5277	val_loss: 0.1995 val_accuracy-SBM: 0.5298	test_loss: 0.1988 test_accuracy-SBM: 0.5281
2025-07-05 09:55:24,267 - INFO - === Epoch 1 ===
2025-07-05 09:56:03,931 - INFO - train: {'epoch': 1, 'time_epoch': 37.63294, 'eta': 3698.0679, 'eta_hours': 1.02724, 'loss': 0.16647833, 'lr': 0.0001, 'params': 345143, 'time_iter': 0.12023, 'accuracy': 0.81904, 'precision': 0.49281, 'recall': 0.86291, 'f1': 0.62734, 'auc': 0.87969, 'accuracy-SBM': 0.83627}
2025-07-05 09:56:03,935 - INFO - ...computing epoch stats took: 2.02s
2025-07-05 09:56:08,061 - INFO - val: {'epoch': 1, 'time_epoch': 3.82334, 'loss': 0.17736809, 'lr': 0, 'params': 345143, 'time_iter': 0.06069, 'accuracy': 0.50228, 'precision': 0.26055, 'recall': 0.98561, 'f1': 0.41214, 'auc': 0.91189, 'accuracy-SBM': 0.69196}
2025-07-05 09:56:08,063 - INFO - ...computing epoch stats took: 0.30s
2025-07-05 09:56:14,061 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 09:56:14,368 - INFO - test: {'epoch': 1, 'time_epoch': 3.85294, 'loss': 0.17644056, 'lr': 0, 'params': 345143, 'time_iter': 0.06116, 'accuracy': 0.50491, 'precision': 0.26057, 'recall': 0.98461, 'f1': 0.41208, 'auc': 0.91203, 'accuracy-SBM': 0.69345}
2025-07-05 09:56:14,370 - INFO - ...computing epoch stats took: 0.31s
2025-07-05 09:56:14,371 - INFO - > Epoch 1: took 50.1s (avg 50.7s) | Best so far: epoch 1	train_loss: 0.1665 train_accuracy-SBM: 0.8363	val_loss: 0.1774 val_accuracy-SBM: 0.6920	test_loss: 0.1764 test_accuracy-SBM: 0.6935
2025-07-05 09:56:14,371 - INFO - === Epoch 2 ===
2025-07-05 09:56:54,026 - INFO - train: {'epoch': 2, 'time_epoch': 37.51904, 'eta': 3653.33718, 'eta_hours': 1.01482, 'loss': 0.14400449, 'lr': 0.0002, 'params': 345143, 'time_iter': 0.11987, 'accuracy': 0.85172, 'precision': 0.55133, 'recall': 0.85898, 'f1': 0.6716, 'auc': 0.89669, 'accuracy-SBM': 0.85457}
2025-07-05 09:56:54,029 - INFO - ...computing epoch stats took: 2.13s
2025-07-05 09:56:58,353 - INFO - val: {'epoch': 2, 'time_epoch': 3.83425, 'loss': 0.18453457, 'lr': 0, 'params': 345143, 'time_iter': 0.06086, 'accuracy': 0.86795, 'precision': 0.92938, 'recall': 0.27492, 'f1': 0.42432, 'auc': 0.92545, 'accuracy-SBM': 0.63521}
2025-07-05 09:56:58,354 - INFO - ...computing epoch stats took: 0.49s
2025-07-05 09:57:04,382 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 09:57:04,838 - INFO - test: {'epoch': 2, 'time_epoch': 3.85476, 'loss': 0.18330987, 'lr': 0, 'params': 345143, 'time_iter': 0.06119, 'accuracy': 0.86961, 'precision': 0.93216, 'recall': 0.28049, 'f1': 0.43122, 'auc': 0.92547, 'accuracy-SBM': 0.63806}
2025-07-05 09:57:04,840 - INFO - ...computing epoch stats took: 0.45s
2025-07-05 09:57:04,840 - INFO - > Epoch 2: took 50.5s (avg 50.6s) | Best so far: epoch 1	train_loss: 0.1665 train_accuracy-SBM: 0.8363	val_loss: 0.1774 val_accuracy-SBM: 0.6920	test_loss: 0.1764 test_accuracy-SBM: 0.6935
2025-07-05 09:57:04,840 - INFO - === Epoch 3 ===
2025-07-05 09:57:46,013 - INFO - train: {'epoch': 3, 'time_epoch': 37.62901, 'eta': 3614.8517, 'eta_hours': 1.00413, 'loss': 0.12718187, 'lr': 0.0003, 'params': 345143, 'time_iter': 0.12022, 'accuracy': 0.85521, 'precision': 0.55827, 'recall': 0.86097, 'f1': 0.67734, 'auc': 0.91222, 'accuracy-SBM': 0.85747}
2025-07-05 09:57:50,185 - INFO - val: {'epoch': 3, 'time_epoch': 3.85972, 'loss': 0.15720973, 'lr': 0, 'params': 345143, 'time_iter': 0.06127, 'accuracy': 0.58285, 'precision': 0.29509, 'recall': 0.97675, 'f1': 0.45325, 'auc': 0.89497, 'accuracy-SBM': 0.73744}
2025-07-05 09:57:56,182 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 09:57:56,489 - INFO - test: {'epoch': 3, 'time_epoch': 3.85007, 'loss': 0.15530752, 'lr': 0, 'params': 345143, 'time_iter': 0.06111, 'accuracy': 0.5903, 'precision': 0.29756, 'recall': 0.97373, 'f1': 0.45582, 'auc': 0.89328, 'accuracy-SBM': 0.741}
2025-07-05 09:57:56,491 - INFO - > Epoch 3: took 51.7s (avg 50.9s) | Best so far: epoch 3	train_loss: 0.1272 train_accuracy-SBM: 0.8575	val_loss: 0.1572 val_accuracy-SBM: 0.7374	test_loss: 0.1553 test_accuracy-SBM: 0.7410
2025-07-05 09:57:56,491 - INFO - === Epoch 4 ===
2025-07-05 09:58:37,216 - INFO - train: {'epoch': 4, 'time_epoch': 37.39274, 'eta': 3572.21965, 'eta_hours': 0.99228, 'loss': 0.11467282, 'lr': 0.0004, 'params': 345143, 'time_iter': 0.11947, 'accuracy': 0.85815, 'precision': 0.56454, 'recall': 0.85899, 'f1': 0.68131, 'auc': 0.9222, 'accuracy-SBM': 0.85848}
2025-07-05 09:58:41,520 - INFO - val: {'epoch': 4, 'time_epoch': 3.84143, 'loss': 0.2842016, 'lr': 0, 'params': 345143, 'time_iter': 0.06098, 'accuracy': 0.82308, 'precision': 0.79487, 'recall': 0.00074, 'f1': 0.00148, 'auc': 0.9069, 'accuracy-SBM': 0.50035}
2025-07-05 09:58:47,441 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 09:58:47,883 - INFO - test: {'epoch': 4, 'time_epoch': 3.83554, 'loss': 0.28328116, 'lr': 0, 'params': 345143, 'time_iter': 0.06088, 'accuracy': 0.82386, 'precision': 0.73684, 'recall': 0.00067, 'f1': 0.00133, 'auc': 0.90636, 'accuracy-SBM': 0.50031}
2025-07-05 09:58:47,885 - INFO - > Epoch 4: took 51.4s (avg 51.0s) | Best so far: epoch 3	train_loss: 0.1272 train_accuracy-SBM: 0.8575	val_loss: 0.1572 val_accuracy-SBM: 0.7374	test_loss: 0.1553 test_accuracy-SBM: 0.7410
2025-07-05 09:58:47,885 - INFO - === Epoch 5 ===
2025-07-05 09:59:27,383 - INFO - train: {'epoch': 5, 'time_epoch': 37.49859, 'eta': 3532.99235, 'eta_hours': 0.98139, 'loss': 0.10596005, 'lr': 0.0005, 'params': 345143, 'time_iter': 0.1198, 'accuracy': 0.86061, 'precision': 0.56984, 'recall': 0.85808, 'f1': 0.68487, 'auc': 0.92912, 'accuracy-SBM': 0.85962}
2025-07-05 09:59:31,690 - INFO - val: {'epoch': 5, 'time_epoch': 3.82873, 'loss': 0.21072122, 'lr': 0, 'params': 345143, 'time_iter': 0.06077, 'accuracy': 0.86898, 'precision': 0.94349, 'recall': 0.27642, 'f1': 0.42757, 'auc': 0.91873, 'accuracy-SBM': 0.63643}
2025-07-05 09:59:37,644 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 09:59:38,118 - INFO - test: {'epoch': 5, 'time_epoch': 3.85657, 'loss': 0.20975089, 'lr': 0, 'params': 345143, 'time_iter': 0.06122, 'accuracy': 0.87014, 'precision': 0.94626, 'recall': 0.27892, 'f1': 0.43084, 'auc': 0.91873, 'accuracy-SBM': 0.63776}
2025-07-05 09:59:38,120 - INFO - > Epoch 5: took 50.2s (avg 50.9s) | Best so far: epoch 3	train_loss: 0.1272 train_accuracy-SBM: 0.8575	val_loss: 0.1572 val_accuracy-SBM: 0.7374	test_loss: 0.1553 test_accuracy-SBM: 0.7410
2025-07-05 09:59:38,121 - INFO - === Epoch 6 ===
2025-07-05 10:00:16,235 - INFO - train: {'epoch': 6, 'time_epoch': 37.48292, 'eta': 3494.05074, 'eta_hours': 0.97057, 'loss': 0.10080109, 'lr': 0.00049986, 'params': 345143, 'time_iter': 0.11975, 'accuracy': 0.86089, 'precision': 0.57021, 'recall': 0.86064, 'f1': 0.68595, 'auc': 0.93312, 'accuracy-SBM': 0.86079}
2025-07-05 10:00:20,355 - INFO - val: {'epoch': 6, 'time_epoch': 3.81571, 'loss': 0.11823908, 'lr': 0, 'params': 345143, 'time_iter': 0.06057, 'accuracy': 0.73602, 'precision': 0.39647, 'recall': 0.94059, 'f1': 0.55781, 'auc': 0.92516, 'accuracy-SBM': 0.8163}
2025-07-05 10:00:26,347 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:00:26,849 - INFO - test: {'epoch': 6, 'time_epoch': 3.88224, 'loss': 0.11709763, 'lr': 0, 'params': 345143, 'time_iter': 0.06162, 'accuracy': 0.73987, 'precision': 0.39876, 'recall': 0.93776, 'f1': 0.55958, 'auc': 0.92486, 'accuracy-SBM': 0.81765}
2025-07-05 10:00:26,851 - INFO - > Epoch 6: took 48.7s (avg 50.6s) | Best so far: epoch 6	train_loss: 0.1008 train_accuracy-SBM: 0.8608	val_loss: 0.1182 val_accuracy-SBM: 0.8163	test_loss: 0.1171 test_accuracy-SBM: 0.8176
2025-07-05 10:00:26,851 - INFO - === Epoch 7 ===
2025-07-05 10:01:05,691 - INFO - train: {'epoch': 7, 'time_epoch': 35.75692, 'eta': 3435.62488, 'eta_hours': 0.95434, 'loss': 0.09791436, 'lr': 0.00049945, 'params': 345143, 'time_iter': 0.11424, 'accuracy': 0.86046, 'precision': 0.56913, 'recall': 0.86232, 'f1': 0.6857, 'auc': 0.93548, 'accuracy-SBM': 0.86119}
2025-07-05 10:01:09,715 - INFO - val: {'epoch': 7, 'time_epoch': 3.72716, 'loss': 0.25864002, 'lr': 0, 'params': 345143, 'time_iter': 0.05916, 'accuracy': 0.21406, 'precision': 0.18379, 'recall': 0.99964, 'f1': 0.31049, 'auc': 0.92619, 'accuracy-SBM': 0.52236}
2025-07-05 10:01:15,705 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:01:15,987 - INFO - test: {'epoch': 7, 'time_epoch': 3.81141, 'loss': 0.25736068, 'lr': 0, 'params': 345143, 'time_iter': 0.0605, 'accuracy': 0.21371, 'precision': 0.18305, 'recall': 0.99974, 'f1': 0.30945, 'auc': 0.92639, 'accuracy-SBM': 0.52265}
2025-07-05 10:01:15,989 - INFO - > Epoch 7: took 49.1s (avg 50.4s) | Best so far: epoch 6	train_loss: 0.1008 train_accuracy-SBM: 0.8608	val_loss: 0.1182 val_accuracy-SBM: 0.8163	test_loss: 0.1171 test_accuracy-SBM: 0.8176
2025-07-05 10:01:15,990 - INFO - === Epoch 8 ===
2025-07-05 10:01:57,738 - INFO - train: {'epoch': 8, 'time_epoch': 37.90806, 'eta': 3403.98695, 'eta_hours': 0.94555, 'loss': 0.09620749, 'lr': 0.00049877, 'params': 345143, 'time_iter': 0.12111, 'accuracy': 0.86002, 'precision': 0.56797, 'recall': 0.86472, 'f1': 0.68561, 'auc': 0.93649, 'accuracy-SBM': 0.86186}
2025-07-05 10:02:02,078 - INFO - val: {'epoch': 8, 'time_epoch': 4.02095, 'loss': 0.14193716, 'lr': 0, 'params': 345143, 'time_iter': 0.06382, 'accuracy': 0.63737, 'precision': 0.32546, 'recall': 0.97754, 'f1': 0.48833, 'auc': 0.92988, 'accuracy-SBM': 0.77087}
2025-07-05 10:02:08,185 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:02:08,493 - INFO - test: {'epoch': 8, 'time_epoch': 3.92475, 'loss': 0.14048776, 'lr': 0, 'params': 345143, 'time_iter': 0.0623, 'accuracy': 0.64138, 'precision': 0.32681, 'recall': 0.97661, 'f1': 0.48974, 'auc': 0.9296, 'accuracy-SBM': 0.77314}
2025-07-05 10:02:08,495 - INFO - > Epoch 8: took 52.5s (avg 50.6s) | Best so far: epoch 6	train_loss: 0.1008 train_accuracy-SBM: 0.8608	val_loss: 0.1182 val_accuracy-SBM: 0.8163	test_loss: 0.1171 test_accuracy-SBM: 0.8176
2025-07-05 10:02:08,495 - INFO - === Epoch 9 ===
2025-07-05 10:02:51,772 - INFO - train: {'epoch': 9, 'time_epoch': 39.33263, 'eta': 3383.91614, 'eta_hours': 0.93998, 'loss': 0.09512458, 'lr': 0.00049782, 'params': 345143, 'time_iter': 0.12566, 'accuracy': 0.85974, 'precision': 0.56747, 'recall': 0.86374, 'f1': 0.68494, 'auc': 0.93709, 'accuracy-SBM': 0.86131}
2025-07-05 10:02:55,942 - INFO - val: {'epoch': 9, 'time_epoch': 3.87779, 'loss': 0.31046703, 'lr': 0, 'params': 345143, 'time_iter': 0.06155, 'accuracy': 0.1774, 'precision': 0.17709, 'recall': 0.99998, 'f1': 0.30089, 'auc': 0.92271, 'accuracy-SBM': 0.50022}
2025-07-05 10:03:02,115 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:03:02,401 - INFO - test: {'epoch': 9, 'time_epoch': 3.765, 'loss': 0.30933666, 'lr': 0, 'params': 345143, 'time_iter': 0.05976, 'accuracy': 0.17656, 'precision': 0.17628, 'recall': 1.0, 'f1': 0.29973, 'auc': 0.9227, 'accuracy-SBM': 0.50021}
2025-07-05 10:03:02,403 - INFO - > Epoch 9: took 53.9s (avg 50.9s) | Best so far: epoch 6	train_loss: 0.1008 train_accuracy-SBM: 0.8608	val_loss: 0.1182 val_accuracy-SBM: 0.8163	test_loss: 0.1171 test_accuracy-SBM: 0.8176
2025-07-05 10:03:02,403 - INFO - === Epoch 10 ===
2025-07-05 10:03:41,232 - INFO - train: {'epoch': 10, 'time_epoch': 38.33405, 'eta': 3352.26379, 'eta_hours': 0.93118, 'loss': 0.09415758, 'lr': 0.00049659, 'params': 345143, 'time_iter': 0.12247, 'accuracy': 0.86049, 'precision': 0.56904, 'recall': 0.8639, 'f1': 0.68613, 'auc': 0.93773, 'accuracy-SBM': 0.86183}
2025-07-05 10:03:45,468 - INFO - val: {'epoch': 10, 'time_epoch': 3.92144, 'loss': 0.17956866, 'lr': 0, 'params': 345143, 'time_iter': 0.06225, 'accuracy': 0.42199, 'precision': 0.23394, 'recall': 0.99586, 'f1': 0.37888, 'auc': 0.92647, 'accuracy-SBM': 0.64721}
2025-07-05 10:03:51,739 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:03:52,049 - INFO - test: {'epoch': 10, 'time_epoch': 3.95428, 'loss': 0.17781822, 'lr': 0, 'params': 345143, 'time_iter': 0.06277, 'accuracy': 0.42638, 'precision': 0.23443, 'recall': 0.99531, 'f1': 0.37947, 'auc': 0.92672, 'accuracy-SBM': 0.64999}
2025-07-05 10:03:52,051 - INFO - > Epoch 10: took 49.6s (avg 50.8s) | Best so far: epoch 6	train_loss: 0.1008 train_accuracy-SBM: 0.8608	val_loss: 0.1182 val_accuracy-SBM: 0.8163	test_loss: 0.1171 test_accuracy-SBM: 0.8176
2025-07-05 10:03:52,052 - INFO - === Epoch 11 ===
2025-07-05 10:04:30,906 - INFO - train: {'epoch': 11, 'time_epoch': 37.34087, 'eta': 3312.21449, 'eta_hours': 0.92006, 'loss': 0.09350139, 'lr': 0.00049509, 'params': 345143, 'time_iter': 0.1193, 'accuracy': 0.85968, 'precision': 0.56724, 'recall': 0.86491, 'f1': 0.68514, 'auc': 0.93813, 'accuracy-SBM': 0.86173}
2025-07-05 10:04:34,855 - INFO - val: {'epoch': 11, 'time_epoch': 3.66108, 'loss': 0.11848153, 'lr': 0, 'params': 345143, 'time_iter': 0.05811, 'accuracy': 0.72799, 'precision': 0.38949, 'recall': 0.94555, 'f1': 0.55171, 'auc': 0.92614, 'accuracy-SBM': 0.81337}
2025-07-05 10:04:41,332 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:04:41,869 - INFO - test: {'epoch': 11, 'time_epoch': 3.62274, 'loss': 0.11733813, 'lr': 0, 'params': 345143, 'time_iter': 0.0575, 'accuracy': 0.73051, 'precision': 0.39052, 'recall': 0.94407, 'f1': 0.5525, 'auc': 0.9267, 'accuracy-SBM': 0.81445}
2025-07-05 10:04:41,882 - INFO - > Epoch 11: took 49.8s (avg 50.7s) | Best so far: epoch 6	train_loss: 0.1008 train_accuracy-SBM: 0.8608	val_loss: 0.1182 val_accuracy-SBM: 0.8163	test_loss: 0.1171 test_accuracy-SBM: 0.8176
2025-07-05 10:04:41,883 - INFO - === Epoch 12 ===
2025-07-05 10:05:23,066 - INFO - train: {'epoch': 12, 'time_epoch': 37.55448, 'eta': 3274.01141, 'eta_hours': 0.90945, 'loss': 0.09319626, 'lr': 0.00049333, 'params': 345143, 'time_iter': 0.11998, 'accuracy': 0.85951, 'precision': 0.5668, 'recall': 0.86583, 'f1': 0.6851, 'auc': 0.93822, 'accuracy-SBM': 0.86199}
2025-07-05 10:05:27,407 - INFO - val: {'epoch': 12, 'time_epoch': 4.01941, 'loss': 0.22920209, 'lr': 0, 'params': 345143, 'time_iter': 0.0638, 'accuracy': 0.19714, 'precision': 0.18062, 'recall': 0.99971, 'f1': 0.30597, 'auc': 0.92367, 'accuracy-SBM': 0.51211}
2025-07-05 10:05:34,396 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:05:34,698 - INFO - test: {'epoch': 12, 'time_epoch': 4.08697, 'loss': 0.22859244, 'lr': 0, 'params': 345143, 'time_iter': 0.06487, 'accuracy': 0.19613, 'precision': 0.17978, 'recall': 0.99983, 'f1': 0.30476, 'auc': 0.92344, 'accuracy-SBM': 0.51202}
2025-07-05 10:05:34,700 - INFO - > Epoch 12: took 52.8s (avg 50.9s) | Best so far: epoch 6	train_loss: 0.1008 train_accuracy-SBM: 0.8608	val_loss: 0.1182 val_accuracy-SBM: 0.8163	test_loss: 0.1171 test_accuracy-SBM: 0.8176
2025-07-05 10:05:34,700 - INFO - === Epoch 13 ===
2025-07-05 10:06:15,890 - INFO - train: {'epoch': 13, 'time_epoch': 39.02194, 'eta': 3244.91538, 'eta_hours': 0.90137, 'loss': 0.09278164, 'lr': 0.0004913, 'params': 345143, 'time_iter': 0.12467, 'accuracy': 0.85961, 'precision': 0.56703, 'recall': 0.86552, 'f1': 0.68518, 'auc': 0.9385, 'accuracy-SBM': 0.86193}
2025-07-05 10:06:20,574 - INFO - val: {'epoch': 13, 'time_epoch': 4.12753, 'loss': 0.09356655, 'lr': 0, 'params': 345143, 'time_iter': 0.06552, 'accuracy': 0.86337, 'precision': 0.57721, 'recall': 0.85295, 'f1': 0.6885, 'auc': 0.93707, 'accuracy-SBM': 0.85928}
2025-07-05 10:06:27,426 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:06:27,961 - INFO - test: {'epoch': 13, 'time_epoch': 4.05006, 'loss': 0.09259309, 'lr': 0, 'params': 345143, 'time_iter': 0.06429, 'accuracy': 0.86465, 'precision': 0.57834, 'recall': 0.85615, 'f1': 0.69034, 'auc': 0.93789, 'accuracy-SBM': 0.86131}
2025-07-05 10:06:27,963 - INFO - > Epoch 13: took 53.3s (avg 51.1s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:06:27,963 - INFO - === Epoch 14 ===
2025-07-05 10:07:08,373 - INFO - train: {'epoch': 14, 'time_epoch': 38.25766, 'eta': 3210.16497, 'eta_hours': 0.89171, 'loss': 0.09252723, 'lr': 0.00048901, 'params': 345143, 'time_iter': 0.12223, 'accuracy': 0.85988, 'precision': 0.56758, 'recall': 0.86586, 'f1': 0.68568, 'auc': 0.93865, 'accuracy-SBM': 0.86223}
2025-07-05 10:07:12,829 - INFO - val: {'epoch': 14, 'time_epoch': 3.95512, 'loss': 0.3792632, 'lr': 0, 'params': 345143, 'time_iter': 0.06278, 'accuracy': 0.83996, 'precision': 0.84914, 'recall': 0.11665, 'f1': 0.20512, 'auc': 0.87122, 'accuracy-SBM': 0.5561}
2025-07-05 10:07:19,403 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:07:19,890 - INFO - test: {'epoch': 14, 'time_epoch': 3.95125, 'loss': 0.37685083, 'lr': 0, 'params': 345143, 'time_iter': 0.06272, 'accuracy': 0.84081, 'precision': 0.85284, 'recall': 0.11679, 'f1': 0.20545, 'auc': 0.87224, 'accuracy-SBM': 0.55624}
2025-07-05 10:07:19,892 - INFO - > Epoch 14: took 51.9s (avg 51.1s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:07:19,892 - INFO - === Epoch 15 ===
2025-07-05 10:08:02,220 - INFO - train: {'epoch': 15, 'time_epoch': 38.40503, 'eta': 3175.74983, 'eta_hours': 0.88215, 'loss': 0.09223354, 'lr': 0.00048645, 'params': 345143, 'time_iter': 0.1227, 'accuracy': 0.8604, 'precision': 0.56877, 'recall': 0.86474, 'f1': 0.6862, 'auc': 0.93881, 'accuracy-SBM': 0.8621}
2025-07-05 10:08:06,642 - INFO - val: {'epoch': 15, 'time_epoch': 3.90925, 'loss': 0.10195133, 'lr': 0, 'params': 345143, 'time_iter': 0.06205, 'accuracy': 0.78838, 'precision': 0.45198, 'recall': 0.91963, 'f1': 0.60608, 'auc': 0.93221, 'accuracy-SBM': 0.83989}
2025-07-05 10:08:12,741 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:08:13,239 - INFO - test: {'epoch': 15, 'time_epoch': 3.67432, 'loss': 0.10097921, 'lr': 0, 'params': 345143, 'time_iter': 0.05832, 'accuracy': 0.79014, 'precision': 0.45281, 'recall': 0.91584, 'f1': 0.606, 'auc': 0.93247, 'accuracy-SBM': 0.83955}
2025-07-05 10:08:13,241 - INFO - > Epoch 15: took 53.3s (avg 51.3s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:08:13,241 - INFO - === Epoch 16 ===
2025-07-05 10:08:53,429 - INFO - train: {'epoch': 16, 'time_epoch': 36.42364, 'eta': 3131.19143, 'eta_hours': 0.86978, 'loss': 0.09216497, 'lr': 0.00048364, 'params': 345143, 'time_iter': 0.11637, 'accuracy': 0.86037, 'precision': 0.56869, 'recall': 0.86501, 'f1': 0.68623, 'auc': 0.93875, 'accuracy-SBM': 0.86219}
2025-07-05 10:08:57,678 - INFO - val: {'epoch': 16, 'time_epoch': 3.9414, 'loss': 0.10877853, 'lr': 0, 'params': 345143, 'time_iter': 0.06256, 'accuracy': 0.74581, 'precision': 0.40707, 'recall': 0.95484, 'f1': 0.5708, 'auc': 0.93972, 'accuracy-SBM': 0.82784}
2025-07-05 10:09:03,970 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:09:04,489 - INFO - test: {'epoch': 16, 'time_epoch': 3.93468, 'loss': 0.10718886, 'lr': 0, 'params': 345143, 'time_iter': 0.06246, 'accuracy': 0.74929, 'precision': 0.40925, 'recall': 0.95322, 'f1': 0.57265, 'auc': 0.94055, 'accuracy-SBM': 0.82944}
2025-07-05 10:09:04,491 - INFO - > Epoch 16: took 51.2s (avg 51.3s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:09:04,491 - INFO - === Epoch 17 ===
2025-07-05 10:09:45,449 - INFO - train: {'epoch': 17, 'time_epoch': 38.53203, 'eta': 3097.14179, 'eta_hours': 0.86032, 'loss': 0.0918146, 'lr': 0.00048057, 'params': 345143, 'time_iter': 0.12311, 'accuracy': 0.86139, 'precision': 0.57088, 'recall': 0.8649, 'f1': 0.68779, 'auc': 0.93916, 'accuracy-SBM': 0.86277}
2025-07-05 10:09:49,807 - INFO - val: {'epoch': 17, 'time_epoch': 4.05864, 'loss': 0.2102363, 'lr': 0, 'params': 345143, 'time_iter': 0.06442, 'accuracy': 0.27878, 'precision': 0.19702, 'recall': 0.9995, 'f1': 0.32915, 'auc': 0.92917, 'accuracy-SBM': 0.56163}
2025-07-05 10:09:57,138 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:09:57,502 - INFO - test: {'epoch': 17, 'time_epoch': 3.9951, 'loss': 0.20821113, 'lr': 0, 'params': 345143, 'time_iter': 0.06341, 'accuracy': 0.28294, 'precision': 0.19721, 'recall': 0.9995, 'f1': 0.32943, 'auc': 0.92951, 'accuracy-SBM': 0.56458}
2025-07-05 10:09:57,504 - INFO - > Epoch 17: took 53.0s (avg 51.4s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:09:57,504 - INFO - === Epoch 18 ===
2025-07-05 10:10:40,251 - INFO - train: {'epoch': 18, 'time_epoch': 38.71152, 'eta': 3063.38552, 'eta_hours': 0.85094, 'loss': 0.09163801, 'lr': 0.00047725, 'params': 345143, 'time_iter': 0.12368, 'accuracy': 0.86064, 'precision': 0.56919, 'recall': 0.86585, 'f1': 0.68685, 'auc': 0.93926, 'accuracy-SBM': 0.86268}
2025-07-05 10:10:44,664 - INFO - val: {'epoch': 18, 'time_epoch': 3.92112, 'loss': 0.28282923, 'lr': 0, 'params': 345143, 'time_iter': 0.06224, 'accuracy': 0.85594, 'precision': 0.76763, 'recall': 0.26701, 'f1': 0.3962, 'auc': 0.88311, 'accuracy-SBM': 0.62481}
2025-07-05 10:10:51,570 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:10:52,056 - INFO - test: {'epoch': 18, 'time_epoch': 3.95781, 'loss': 0.2817748, 'lr': 0, 'params': 345143, 'time_iter': 0.06282, 'accuracy': 0.85741, 'precision': 0.77163, 'recall': 0.27108, 'f1': 0.40121, 'auc': 0.88304, 'accuracy-SBM': 0.62696}
2025-07-05 10:10:52,089 - INFO - > Epoch 18: took 54.6s (avg 51.5s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:10:52,090 - INFO - === Epoch 19 ===
2025-07-05 10:11:34,421 - INFO - train: {'epoch': 19, 'time_epoch': 38.27057, 'eta': 3027.3699, 'eta_hours': 0.84094, 'loss': 0.09151951, 'lr': 0.00047368, 'params': 345143, 'time_iter': 0.12227, 'accuracy': 0.86068, 'precision': 0.56925, 'recall': 0.86597, 'f1': 0.68694, 'auc': 0.93933, 'accuracy-SBM': 0.86276}
2025-07-05 10:11:38,818 - INFO - val: {'epoch': 19, 'time_epoch': 3.92962, 'loss': 0.46278871, 'lr': 0, 'params': 345143, 'time_iter': 0.06237, 'accuracy': 0.8286, 'precision': 0.88593, 'recall': 0.03645, 'f1': 0.07001, 'auc': 0.90147, 'accuracy-SBM': 0.51772}
2025-07-05 10:11:45,545 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:11:46,043 - INFO - test: {'epoch': 19, 'time_epoch': 3.95343, 'loss': 0.46050933, 'lr': 0, 'params': 345143, 'time_iter': 0.06275, 'accuracy': 0.82926, 'precision': 0.89714, 'recall': 0.03511, 'f1': 0.06758, 'auc': 0.90243, 'accuracy-SBM': 0.51713}
2025-07-05 10:11:46,048 - INFO - > Epoch 19: took 54.0s (avg 51.7s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:11:46,048 - INFO - === Epoch 20 ===
2025-07-05 10:12:23,044 - INFO - train: {'epoch': 20, 'time_epoch': 36.34118, 'eta': 2983.88137, 'eta_hours': 0.82886, 'loss': 0.09151293, 'lr': 0.00046987, 'params': 345143, 'time_iter': 0.11611, 'accuracy': 0.86163, 'precision': 0.57136, 'recall': 0.86515, 'f1': 0.68821, 'auc': 0.93932, 'accuracy-SBM': 0.86301}
2025-07-05 10:12:27,224 - INFO - val: {'epoch': 20, 'time_epoch': 3.68547, 'loss': 0.32476094, 'lr': 0, 'params': 345143, 'time_iter': 0.0585, 'accuracy': 0.85428, 'precision': 0.92607, 'recall': 0.19216, 'f1': 0.31828, 'auc': 0.91099, 'accuracy-SBM': 0.59443}
2025-07-05 10:12:33,423 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:12:33,889 - INFO - test: {'epoch': 20, 'time_epoch': 3.84425, 'loss': 0.32347604, 'lr': 0, 'params': 345143, 'time_iter': 0.06102, 'accuracy': 0.85515, 'precision': 0.92387, 'recall': 0.19397, 'f1': 0.32063, 'auc': 0.91134, 'accuracy-SBM': 0.59528}
2025-07-05 10:12:33,891 - INFO - > Epoch 20: took 47.8s (avg 51.5s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:12:33,891 - INFO - === Epoch 21 ===
2025-07-05 10:13:15,724 - INFO - train: {'epoch': 21, 'time_epoch': 38.00248, 'eta': 2946.93265, 'eta_hours': 0.81859, 'loss': 0.09145105, 'lr': 0.00046581, 'params': 345143, 'time_iter': 0.12141, 'accuracy': 0.86164, 'precision': 0.57147, 'recall': 0.86425, 'f1': 0.68801, 'auc': 0.93931, 'accuracy-SBM': 0.86267}
2025-07-05 10:13:20,206 - INFO - val: {'epoch': 21, 'time_epoch': 4.00037, 'loss': 0.15236704, 'lr': 0, 'params': 345143, 'time_iter': 0.0635, 'accuracy': 0.8964, 'precision': 0.77738, 'recall': 0.58121, 'f1': 0.66513, 'auc': 0.9208, 'accuracy-SBM': 0.7727}
2025-07-05 10:13:26,767 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:13:27,295 - INFO - test: {'epoch': 21, 'time_epoch': 3.90809, 'loss': 0.15240034, 'lr': 0, 'params': 345143, 'time_iter': 0.06203, 'accuracy': 0.89745, 'precision': 0.7799, 'recall': 0.5824, 'f1': 0.66683, 'auc': 0.92082, 'accuracy-SBM': 0.77362}
2025-07-05 10:13:27,304 - INFO - > Epoch 21: took 53.4s (avg 51.6s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:13:27,304 - INFO - === Epoch 22 ===
2025-07-05 10:14:10,451 - INFO - train: {'epoch': 22, 'time_epoch': 39.36414, 'eta': 2914.45091, 'eta_hours': 0.80957, 'loss': 0.09143095, 'lr': 0.00046152, 'params': 345143, 'time_iter': 0.12576, 'accuracy': 0.86076, 'precision': 0.56949, 'recall': 0.8653, 'f1': 0.6869, 'auc': 0.93927, 'accuracy-SBM': 0.86254}
2025-07-05 10:14:14,491 - INFO - val: {'epoch': 22, 'time_epoch': 3.72662, 'loss': 0.12596957, 'lr': 0, 'params': 345143, 'time_iter': 0.05915, 'accuracy': 0.67433, 'precision': 0.34853, 'recall': 0.96608, 'f1': 0.51226, 'auc': 0.92986, 'accuracy-SBM': 0.78883}
2025-07-05 10:14:20,805 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:14:21,322 - INFO - test: {'epoch': 22, 'time_epoch': 3.95197, 'loss': 0.12466801, 'lr': 0, 'params': 345143, 'time_iter': 0.06273, 'accuracy': 0.67829, 'precision': 0.35012, 'recall': 0.96432, 'f1': 0.51372, 'auc': 0.93016, 'accuracy-SBM': 0.79071}
2025-07-05 10:14:21,324 - INFO - > Epoch 22: took 54.0s (avg 51.7s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:14:21,324 - INFO - === Epoch 23 ===
2025-07-05 10:15:04,143 - INFO - train: {'epoch': 23, 'time_epoch': 38.78662, 'eta': 2879.56683, 'eta_hours': 0.79988, 'loss': 0.09137549, 'lr': 0.000457, 'params': 345143, 'time_iter': 0.12392, 'accuracy': 0.86068, 'precision': 0.56932, 'recall': 0.86528, 'f1': 0.68678, 'auc': 0.93931, 'accuracy-SBM': 0.86249}
2025-07-05 10:15:08,597 - INFO - val: {'epoch': 23, 'time_epoch': 3.96662, 'loss': 0.18099898, 'lr': 0, 'params': 345143, 'time_iter': 0.06296, 'accuracy': 0.89376, 'precision': 0.83551, 'recall': 0.49788, 'f1': 0.62395, 'auc': 0.92031, 'accuracy-SBM': 0.7384}
2025-07-05 10:15:15,407 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:15:15,900 - INFO - test: {'epoch': 23, 'time_epoch': 3.97097, 'loss': 0.17819445, 'lr': 0, 'params': 345143, 'time_iter': 0.06303, 'accuracy': 0.89559, 'precision': 0.83721, 'recall': 0.50584, 'f1': 0.63064, 'auc': 0.92145, 'accuracy-SBM': 0.7424}
2025-07-05 10:15:15,902 - INFO - > Epoch 23: took 54.6s (avg 51.8s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:15:15,902 - INFO - === Epoch 24 ===
2025-07-05 10:15:54,297 - INFO - train: {'epoch': 24, 'time_epoch': 36.86714, 'eta': 2838.61211, 'eta_hours': 0.7885, 'loss': 0.09112567, 'lr': 0.00045225, 'params': 345143, 'time_iter': 0.11779, 'accuracy': 0.86171, 'precision': 0.57154, 'recall': 0.86503, 'f1': 0.68831, 'auc': 0.93965, 'accuracy-SBM': 0.86301}
2025-07-05 10:15:58,273 - INFO - val: {'epoch': 24, 'time_epoch': 3.68595, 'loss': 0.14502735, 'lr': 0, 'params': 345143, 'time_iter': 0.05851, 'accuracy': 0.61187, 'precision': 0.31073, 'recall': 0.97894, 'f1': 0.47173, 'auc': 0.92923, 'accuracy-SBM': 0.75593}
2025-07-05 10:16:04,492 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:16:04,790 - INFO - test: {'epoch': 24, 'time_epoch': 3.74028, 'loss': 0.14378445, 'lr': 0, 'params': 345143, 'time_iter': 0.05937, 'accuracy': 0.61453, 'precision': 0.3112, 'recall': 0.97861, 'f1': 0.47223, 'auc': 0.92977, 'accuracy-SBM': 0.75763}
2025-07-05 10:16:04,794 - INFO - > Epoch 24: took 48.9s (avg 51.7s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:16:04,794 - INFO - === Epoch 25 ===
2025-07-05 10:16:42,998 - INFO - train: {'epoch': 25, 'time_epoch': 37.56073, 'eta': 2799.94588, 'eta_hours': 0.77776, 'loss': 0.09116993, 'lr': 0.00044729, 'params': 345143, 'time_iter': 0.12, 'accuracy': 0.8615, 'precision': 0.57111, 'recall': 0.86488, 'f1': 0.68794, 'auc': 0.93949, 'accuracy-SBM': 0.86283}
2025-07-05 10:16:47,532 - INFO - val: {'epoch': 25, 'time_epoch': 4.02428, 'loss': 0.29658097, 'lr': 0, 'params': 345143, 'time_iter': 0.06388, 'accuracy': 0.85241, 'precision': 0.75585, 'recall': 0.24557, 'f1': 0.3707, 'auc': 0.88388, 'accuracy-SBM': 0.61425}
2025-07-05 10:16:54,089 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:16:54,596 - INFO - test: {'epoch': 25, 'time_epoch': 3.9621, 'loss': 0.29488687, 'lr': 0, 'params': 345143, 'time_iter': 0.06289, 'accuracy': 0.8544, 'precision': 0.7657, 'recall': 0.25036, 'f1': 0.37734, 'auc': 0.88381, 'accuracy-SBM': 0.61698}
2025-07-05 10:16:54,598 - INFO - > Epoch 25: took 49.8s (avg 51.6s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:16:54,599 - INFO - === Epoch 26 ===
2025-07-05 10:17:37,512 - INFO - train: {'epoch': 26, 'time_epoch': 39.14894, 'eta': 2765.65558, 'eta_hours': 0.76824, 'loss': 0.09101034, 'lr': 0.0004421, 'params': 345143, 'time_iter': 0.12508, 'accuracy': 0.86185, 'precision': 0.57177, 'recall': 0.86579, 'f1': 0.68871, 'auc': 0.93975, 'accuracy-SBM': 0.8634}
2025-07-05 10:17:42,056 - INFO - val: {'epoch': 26, 'time_epoch': 4.03046, 'loss': 0.17820124, 'lr': 0, 'params': 345143, 'time_iter': 0.06398, 'accuracy': 0.89465, 'precision': 0.83053, 'recall': 0.50865, 'f1': 0.63091, 'auc': 0.92198, 'accuracy-SBM': 0.74316}
2025-07-05 10:17:48,241 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:17:48,692 - INFO - test: {'epoch': 26, 'time_epoch': 4.03018, 'loss': 0.17705179, 'lr': 0, 'params': 345143, 'time_iter': 0.06397, 'accuracy': 0.89607, 'precision': 0.8318, 'recall': 0.5142, 'f1': 0.63553, 'auc': 0.92234, 'accuracy-SBM': 0.74598}
2025-07-05 10:17:48,693 - INFO - > Epoch 26: took 54.1s (avg 51.7s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:17:48,694 - INFO - === Epoch 27 ===
2025-07-05 10:18:30,905 - INFO - train: {'epoch': 27, 'time_epoch': 38.29085, 'eta': 2728.81173, 'eta_hours': 0.758, 'loss': 0.09095616, 'lr': 0.00043671, 'params': 345143, 'time_iter': 0.12233, 'accuracy': 0.86177, 'precision': 0.57162, 'recall': 0.86565, 'f1': 0.68856, 'auc': 0.93977, 'accuracy-SBM': 0.86329}
2025-07-05 10:18:35,319 - INFO - val: {'epoch': 27, 'time_epoch': 3.92369, 'loss': 0.1840943, 'lr': 0, 'params': 345143, 'time_iter': 0.06228, 'accuracy': 0.89039, 'precision': 0.79805, 'recall': 0.50981, 'f1': 0.62217, 'auc': 0.91721, 'accuracy-SBM': 0.74103}
2025-07-05 10:18:41,541 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:18:42,015 - INFO - test: {'epoch': 27, 'time_epoch': 3.96379, 'loss': 0.18221734, 'lr': 0, 'params': 345143, 'time_iter': 0.06292, 'accuracy': 0.89164, 'precision': 0.79756, 'recall': 0.51606, 'f1': 0.62664, 'auc': 0.91788, 'accuracy-SBM': 0.74402}
2025-07-05 10:18:42,017 - INFO - > Epoch 27: took 53.3s (avg 51.8s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:18:42,017 - INFO - === Epoch 28 ===
2025-07-05 10:19:21,711 - INFO - train: {'epoch': 28, 'time_epoch': 37.07782, 'eta': 2688.89824, 'eta_hours': 0.74692, 'loss': 0.0909189, 'lr': 0.00043111, 'params': 345143, 'time_iter': 0.11846, 'accuracy': 0.86174, 'precision': 0.57157, 'recall': 0.86552, 'f1': 0.68848, 'auc': 0.93978, 'accuracy-SBM': 0.86323}
2025-07-05 10:19:25,805 - INFO - val: {'epoch': 28, 'time_epoch': 3.62767, 'loss': 0.30157976, 'lr': 0, 'params': 345143, 'time_iter': 0.05758, 'accuracy': 0.85325, 'precision': 0.91197, 'recall': 0.18928, 'f1': 0.31349, 'auc': 0.91251, 'accuracy-SBM': 0.59268}
2025-07-05 10:19:31,849 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:19:32,309 - INFO - test: {'epoch': 28, 'time_epoch': 3.73259, 'loss': 0.29880304, 'lr': 0, 'params': 345143, 'time_iter': 0.05925, 'accuracy': 0.85445, 'precision': 0.90935, 'recall': 0.19331, 'f1': 0.31884, 'auc': 0.91345, 'accuracy-SBM': 0.59459}
2025-07-05 10:19:32,311 - INFO - > Epoch 28: took 50.3s (avg 51.7s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:19:32,312 - INFO - === Epoch 29 ===
2025-07-05 10:20:13,891 - INFO - train: {'epoch': 29, 'time_epoch': 37.65386, 'eta': 2650.51789, 'eta_hours': 0.73625, 'loss': 0.09101275, 'lr': 0.00042531, 'params': 345143, 'time_iter': 0.1203, 'accuracy': 0.86169, 'precision': 0.57148, 'recall': 0.86518, 'f1': 0.68831, 'auc': 0.93968, 'accuracy-SBM': 0.86306}
2025-07-05 10:20:18,439 - INFO - val: {'epoch': 29, 'time_epoch': 4.03853, 'loss': 0.13228273, 'lr': 0, 'params': 345143, 'time_iter': 0.0641, 'accuracy': 0.88638, 'precision': 0.68043, 'recall': 0.67537, 'f1': 0.67789, 'auc': 0.91643, 'accuracy-SBM': 0.80357}
2025-07-05 10:20:25,079 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:20:25,569 - INFO - test: {'epoch': 29, 'time_epoch': 4.02119, 'loss': 0.13185055, 'lr': 0, 'params': 345143, 'time_iter': 0.06383, 'accuracy': 0.88725, 'precision': 0.68104, 'recall': 0.67739, 'f1': 0.67921, 'auc': 0.91672, 'accuracy-SBM': 0.80476}
2025-07-05 10:20:25,571 - INFO - > Epoch 29: took 53.3s (avg 51.8s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:20:25,571 - INFO - === Epoch 30 ===
2025-07-05 10:21:08,364 - INFO - train: {'epoch': 30, 'time_epoch': 39.15603, 'eta': 2615.52794, 'eta_hours': 0.72654, 'loss': 0.09090768, 'lr': 0.00041932, 'params': 345143, 'time_iter': 0.1251, 'accuracy': 0.86189, 'precision': 0.57188, 'recall': 0.86563, 'f1': 0.68874, 'auc': 0.93977, 'accuracy-SBM': 0.86336}
2025-07-05 10:21:12,901 - INFO - val: {'epoch': 30, 'time_epoch': 3.99751, 'loss': 0.26994722, 'lr': 0, 'params': 345143, 'time_iter': 0.06345, 'accuracy': 0.86068, 'precision': 0.77771, 'recall': 0.29819, 'f1': 0.43109, 'auc': 0.89023, 'accuracy-SBM': 0.63993}
2025-07-05 10:21:18,918 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:21:19,386 - INFO - test: {'epoch': 30, 'time_epoch': 3.9106, 'loss': 0.27016791, 'lr': 0, 'params': 345143, 'time_iter': 0.06207, 'accuracy': 0.86219, 'precision': 0.78237, 'recall': 0.30195, 'f1': 0.43574, 'auc': 0.88976, 'accuracy-SBM': 0.64199}
2025-07-05 10:21:19,388 - INFO - > Epoch 30: took 53.8s (avg 51.8s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:21:19,388 - INFO - === Epoch 31 ===
2025-07-05 10:21:58,345 - INFO - train: {'epoch': 31, 'time_epoch': 38.39461, 'eta': 2578.6596, 'eta_hours': 0.71629, 'loss': 0.09087151, 'lr': 0.00041315, 'params': 345143, 'time_iter': 0.12267, 'accuracy': 0.86208, 'precision': 0.57238, 'recall': 0.86456, 'f1': 0.68876, 'auc': 0.93982, 'accuracy-SBM': 0.86306}
2025-07-05 10:22:02,793 - INFO - val: {'epoch': 31, 'time_epoch': 3.91867, 'loss': 0.23032695, 'lr': 0, 'params': 345143, 'time_iter': 0.0622, 'accuracy': 0.87446, 'precision': 0.7615, 'recall': 0.42342, 'f1': 0.54423, 'auc': 0.89439, 'accuracy-SBM': 0.69745}
2025-07-05 10:22:09,209 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:22:09,714 - INFO - test: {'epoch': 31, 'time_epoch': 3.98538, 'loss': 0.23099031, 'lr': 0, 'params': 345143, 'time_iter': 0.06326, 'accuracy': 0.87529, 'precision': 0.76115, 'recall': 0.42601, 'f1': 0.54628, 'auc': 0.89333, 'accuracy-SBM': 0.69871}
2025-07-05 10:22:09,716 - INFO - > Epoch 31: took 50.3s (avg 51.8s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:22:09,716 - INFO - === Epoch 32 ===
2025-07-05 10:22:48,280 - INFO - train: {'epoch': 32, 'time_epoch': 36.58134, 'eta': 2538.01728, 'eta_hours': 0.705, 'loss': 0.09075735, 'lr': 0.00040679, 'params': 345143, 'time_iter': 0.11687, 'accuracy': 0.86108, 'precision': 0.57001, 'recall': 0.86719, 'f1': 0.68787, 'auc': 0.93995, 'accuracy-SBM': 0.86348}
2025-07-05 10:22:52,544 - INFO - val: {'epoch': 32, 'time_epoch': 3.73637, 'loss': 0.09952244, 'lr': 0, 'params': 345143, 'time_iter': 0.05931, 'accuracy': 0.82943, 'precision': 0.51077, 'recall': 0.86374, 'f1': 0.64193, 'auc': 0.92469, 'accuracy-SBM': 0.84289}
2025-07-05 10:22:58,689 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:22:59,204 - INFO - test: {'epoch': 32, 'time_epoch': 3.82681, 'loss': 0.09910417, 'lr': 0, 'params': 345143, 'time_iter': 0.06074, 'accuracy': 0.82997, 'precision': 0.51041, 'recall': 0.86162, 'f1': 0.64106, 'auc': 0.92483, 'accuracy-SBM': 0.84241}
2025-07-05 10:22:59,206 - INFO - > Epoch 32: took 49.5s (avg 51.7s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:22:59,207 - INFO - === Epoch 33 ===
2025-07-05 10:23:39,355 - INFO - train: {'epoch': 33, 'time_epoch': 38.00517, 'eta': 2500.37774, 'eta_hours': 0.69455, 'loss': 0.09077569, 'lr': 0.00040027, 'params': 345143, 'time_iter': 0.12142, 'accuracy': 0.86051, 'precision': 0.56881, 'recall': 0.86707, 'f1': 0.68696, 'auc': 0.9399, 'accuracy-SBM': 0.86309}
2025-07-05 10:23:43,929 - INFO - val: {'epoch': 33, 'time_epoch': 4.02787, 'loss': 0.38324499, 'lr': 0, 'params': 345143, 'time_iter': 0.06393, 'accuracy': 0.84591, 'precision': 0.91236, 'recall': 0.14333, 'f1': 0.24774, 'auc': 0.89708, 'accuracy-SBM': 0.57018}
2025-07-05 10:23:50,131 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:23:50,644 - INFO - test: {'epoch': 33, 'time_epoch': 3.96896, 'loss': 0.38082252, 'lr': 0, 'params': 345143, 'time_iter': 0.063, 'accuracy': 0.84653, 'precision': 0.90924, 'recall': 0.14343, 'f1': 0.24777, 'auc': 0.89779, 'accuracy-SBM': 0.57018}
2025-07-05 10:23:50,646 - INFO - > Epoch 33: took 51.4s (avg 51.7s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:23:50,647 - INFO - === Epoch 34 ===
2025-07-05 10:24:33,971 - INFO - train: {'epoch': 34, 'time_epoch': 39.38255, 'eta': 2465.27531, 'eta_hours': 0.6848, 'loss': 0.09077827, 'lr': 0.00039358, 'params': 345143, 'time_iter': 0.12582, 'accuracy': 0.86125, 'precision': 0.5704, 'recall': 0.86685, 'f1': 0.68805, 'auc': 0.93992, 'accuracy-SBM': 0.86345}
2025-07-05 10:24:38,115 - INFO - val: {'epoch': 34, 'time_epoch': 3.84853, 'loss': 0.1129867, 'lr': 0, 'params': 345143, 'time_iter': 0.06109, 'accuracy': 0.73319, 'precision': 0.39528, 'recall': 0.95729, 'f1': 0.55952, 'auc': 0.93806, 'accuracy-SBM': 0.82114}
2025-07-05 10:24:46,527 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:24:47,138 - INFO - test: {'epoch': 34, 'time_epoch': 3.77949, 'loss': 0.11143352, 'lr': 0, 'params': 345143, 'time_iter': 0.05999, 'accuracy': 0.73699, 'precision': 0.39751, 'recall': 0.95512, 'f1': 0.56138, 'auc': 0.93878, 'accuracy-SBM': 0.82272}
2025-07-05 10:24:47,140 - INFO - > Epoch 34: took 56.5s (avg 51.8s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:24:47,140 - INFO - === Epoch 35 ===
2025-07-05 10:25:27,742 - INFO - train: {'epoch': 35, 'time_epoch': 38.41465, 'eta': 2428.21437, 'eta_hours': 0.6745, 'loss': 0.09068259, 'lr': 0.00038674, 'params': 345143, 'time_iter': 0.12273, 'accuracy': 0.86085, 'precision': 0.56949, 'recall': 0.86741, 'f1': 0.68757, 'auc': 0.94005, 'accuracy-SBM': 0.86343}
2025-07-05 10:25:32,205 - INFO - val: {'epoch': 35, 'time_epoch': 3.94328, 'loss': 0.09932556, 'lr': 0, 'params': 345143, 'time_iter': 0.06259, 'accuracy': 0.8145, 'precision': 0.48688, 'recall': 0.88888, 'f1': 0.62915, 'auc': 0.928, 'accuracy-SBM': 0.84369}
2025-07-05 10:25:38,299 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:25:38,790 - INFO - test: {'epoch': 35, 'time_epoch': 3.89161, 'loss': 0.0985703, 'lr': 0, 'params': 345143, 'time_iter': 0.06177, 'accuracy': 0.81591, 'precision': 0.48773, 'recall': 0.88759, 'f1': 0.62954, 'auc': 0.9283, 'accuracy-SBM': 0.84409}
2025-07-05 10:25:38,793 - INFO - > Epoch 35: took 51.7s (avg 51.8s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:25:38,793 - INFO - === Epoch 36 ===
2025-07-05 10:26:18,216 - INFO - train: {'epoch': 36, 'time_epoch': 36.05189, 'eta': 2387.05719, 'eta_hours': 0.66307, 'loss': 0.09069322, 'lr': 0.00037974, 'params': 345143, 'time_iter': 0.11518, 'accuracy': 0.86142, 'precision': 0.57079, 'recall': 0.8664, 'f1': 0.68819, 'auc': 0.93998, 'accuracy-SBM': 0.86338}
2025-07-05 10:26:22,516 - INFO - val: {'epoch': 36, 'time_epoch': 3.77938, 'loss': 0.10658151, 'lr': 0, 'params': 345143, 'time_iter': 0.05999, 'accuracy': 0.8995, 'precision': 0.70583, 'recall': 0.74119, 'f1': 0.72307, 'auc': 0.93775, 'accuracy-SBM': 0.83737}
2025-07-05 10:26:28,465 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:26:28,982 - INFO - test: {'epoch': 36, 'time_epoch': 3.77594, 'loss': 0.10576918, 'lr': 0, 'params': 345143, 'time_iter': 0.05994, 'accuracy': 0.90062, 'precision': 0.70787, 'recall': 0.74247, 'f1': 0.72476, 'auc': 0.9383, 'accuracy-SBM': 0.83846}
2025-07-05 10:26:29,009 - INFO - > Epoch 36: took 50.2s (avg 51.8s) | Best so far: epoch 13	train_loss: 0.0928 train_accuracy-SBM: 0.8619	val_loss: 0.0936 val_accuracy-SBM: 0.8593	test_loss: 0.0926 test_accuracy-SBM: 0.8613
2025-07-05 10:26:29,009 - INFO - === Epoch 37 ===
2025-07-05 10:27:10,326 - INFO - train: {'epoch': 37, 'time_epoch': 37.7425, 'eta': 2348.92706, 'eta_hours': 0.65248, 'loss': 0.09060269, 'lr': 0.00037261, 'params': 345143, 'time_iter': 0.12058, 'accuracy': 0.8627, 'precision': 0.57359, 'recall': 0.86582, 'f1': 0.69004, 'auc': 0.94017, 'accuracy-SBM': 0.86393}
2025-07-05 10:27:14,745 - INFO - val: {'epoch': 37, 'time_epoch': 3.86676, 'loss': 0.09289478, 'lr': 0, 'params': 345143, 'time_iter': 0.06138, 'accuracy': 0.8321, 'precision': 0.51469, 'recall': 0.90291, 'f1': 0.65564, 'auc': 0.94036, 'accuracy-SBM': 0.85989}
2025-07-05 10:27:21,005 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:27:21,536 - INFO - test: {'epoch': 37, 'time_epoch': 3.83916, 'loss': 0.09158118, 'lr': 0, 'params': 345143, 'time_iter': 0.06094, 'accuracy': 0.83499, 'precision': 0.51825, 'recall': 0.90319, 'f1': 0.6586, 'auc': 0.94131, 'accuracy-SBM': 0.8618}
2025-07-05 10:27:21,538 - INFO - > Epoch 37: took 52.5s (avg 51.8s) | Best so far: epoch 37	train_loss: 0.0906 train_accuracy-SBM: 0.8639	val_loss: 0.0929 val_accuracy-SBM: 0.8599	test_loss: 0.0916 test_accuracy-SBM: 0.8618
2025-07-05 10:27:21,538 - INFO - === Epoch 38 ===
2025-07-05 10:28:02,324 - INFO - train: {'epoch': 38, 'time_epoch': 37.93618, 'eta': 2311.11975, 'eta_hours': 0.64198, 'loss': 0.09052609, 'lr': 0.00036534, 'params': 345143, 'time_iter': 0.1212, 'accuracy': 0.86201, 'precision': 0.57205, 'recall': 0.86633, 'f1': 0.68909, 'auc': 0.94022, 'accuracy-SBM': 0.8637}
2025-07-05 10:28:06,241 - INFO - val: {'epoch': 38, 'time_epoch': 3.61884, 'loss': 0.13858188, 'lr': 0, 'params': 345143, 'time_iter': 0.05744, 'accuracy': 0.62897, 'precision': 0.32007, 'recall': 0.97482, 'f1': 0.48191, 'auc': 0.92974, 'accuracy-SBM': 0.7647}
2025-07-05 10:28:12,063 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:28:12,368 - INFO - test: {'epoch': 38, 'time_epoch': 3.70487, 'loss': 0.1370218, 'lr': 0, 'params': 345143, 'time_iter': 0.05881, 'accuracy': 0.63255, 'precision': 0.32109, 'recall': 0.9738, 'f1': 0.48294, 'auc': 0.93027, 'accuracy-SBM': 0.76668}
2025-07-05 10:28:12,369 - INFO - > Epoch 38: took 50.8s (avg 51.8s) | Best so far: epoch 37	train_loss: 0.0906 train_accuracy-SBM: 0.8639	val_loss: 0.0929 val_accuracy-SBM: 0.8599	test_loss: 0.0916 test_accuracy-SBM: 0.8618
2025-07-05 10:28:12,370 - INFO - === Epoch 39 ===
2025-07-05 10:28:52,001 - INFO - train: {'epoch': 39, 'time_epoch': 36.43881, 'eta': 2271.05994, 'eta_hours': 0.63085, 'loss': 0.09056702, 'lr': 0.00035794, 'params': 345143, 'time_iter': 0.11642, 'accuracy': 0.86206, 'precision': 0.57217, 'recall': 0.86633, 'f1': 0.68918, 'auc': 0.94016, 'accuracy-SBM': 0.86374}
2025-07-05 10:28:56,271 - INFO - val: {'epoch': 39, 'time_epoch': 3.74429, 'loss': 0.09275028, 'lr': 0, 'params': 345143, 'time_iter': 0.05943, 'accuracy': 0.86562, 'precision': 0.5821, 'recall': 0.85395, 'f1': 0.69229, 'auc': 0.93811, 'accuracy-SBM': 0.86104}
2025-07-05 10:29:02,305 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:29:02,845 - INFO - test: {'epoch': 39, 'time_epoch': 3.79728, 'loss': 0.0915717, 'lr': 0, 'params': 345143, 'time_iter': 0.06027, 'accuracy': 0.86791, 'precision': 0.58601, 'recall': 0.85312, 'f1': 0.69478, 'auc': 0.93899, 'accuracy-SBM': 0.8621}
2025-07-05 10:29:02,848 - INFO - > Epoch 39: took 50.5s (avg 51.7s) | Best so far: epoch 39	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0928 val_accuracy-SBM: 0.8610	test_loss: 0.0916 test_accuracy-SBM: 0.8621
2025-07-05 10:29:02,849 - INFO - === Epoch 40 ===
2025-07-05 10:29:46,973 - INFO - train: {'epoch': 40, 'time_epoch': 38.85943, 'eta': 2234.6601, 'eta_hours': 0.62074, 'loss': 0.09057195, 'lr': 0.00035042, 'params': 345143, 'time_iter': 0.12415, 'accuracy': 0.86234, 'precision': 0.5728, 'recall': 0.86589, 'f1': 0.6895, 'auc': 0.94011, 'accuracy-SBM': 0.86373}
2025-07-05 10:29:51,891 - INFO - val: {'epoch': 40, 'time_epoch': 4.36829, 'loss': 0.12968636, 'lr': 0, 'params': 345143, 'time_iter': 0.06934, 'accuracy': 0.89935, 'precision': 0.75508, 'recall': 0.63854, 'f1': 0.69194, 'auc': 0.92968, 'accuracy-SBM': 0.797}
2025-07-05 10:29:58,799 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:29:59,366 - INFO - test: {'epoch': 40, 'time_epoch': 4.37859, 'loss': 0.12882043, 'lr': 0, 'params': 345143, 'time_iter': 0.0695, 'accuracy': 0.90061, 'precision': 0.75901, 'recall': 0.63883, 'f1': 0.69375, 'auc': 0.93072, 'accuracy-SBM': 0.79772}
2025-07-05 10:29:59,368 - INFO - > Epoch 40: took 56.5s (avg 51.9s) | Best so far: epoch 39	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0928 val_accuracy-SBM: 0.8610	test_loss: 0.0916 test_accuracy-SBM: 0.8621
2025-07-05 10:29:59,368 - INFO - === Epoch 41 ===
2025-07-05 10:30:46,108 - INFO - train: {'epoch': 41, 'time_epoch': 41.80916, 'eta': 2202.21657, 'eta_hours': 0.61173, 'loss': 0.09050485, 'lr': 0.0003428, 'params': 345143, 'time_iter': 0.13358, 'accuracy': 0.8624, 'precision': 0.57292, 'recall': 0.86611, 'f1': 0.68965, 'auc': 0.9402, 'accuracy-SBM': 0.86386}
2025-07-05 10:30:50,797 - INFO - val: {'epoch': 41, 'time_epoch': 4.34071, 'loss': 0.11232047, 'lr': 0, 'params': 345143, 'time_iter': 0.0689, 'accuracy': 0.72387, 'precision': 0.3863, 'recall': 0.951, 'f1': 0.54942, 'auc': 0.93147, 'accuracy-SBM': 0.81301}
2025-07-05 10:30:57,735 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:30:58,234 - INFO - test: {'epoch': 41, 'time_epoch': 4.42244, 'loss': 0.11095865, 'lr': 0, 'params': 345143, 'time_iter': 0.0702, 'accuracy': 0.72758, 'precision': 0.38834, 'recall': 0.94931, 'f1': 0.5512, 'auc': 0.93224, 'accuracy-SBM': 0.81473}
2025-07-05 10:30:58,236 - INFO - > Epoch 41: took 58.9s (avg 52.0s) | Best so far: epoch 39	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0928 val_accuracy-SBM: 0.8610	test_loss: 0.0916 test_accuracy-SBM: 0.8621
2025-07-05 10:30:58,236 - INFO - === Epoch 42 ===
2025-07-05 10:31:37,791 - INFO - train: {'epoch': 42, 'time_epoch': 36.77913, 'eta': 2162.66971, 'eta_hours': 0.60074, 'loss': 0.09045128, 'lr': 0.00033507, 'params': 345143, 'time_iter': 0.11751, 'accuracy': 0.8619, 'precision': 0.57181, 'recall': 0.86646, 'f1': 0.68896, 'auc': 0.94034, 'accuracy-SBM': 0.86369}
2025-07-05 10:31:41,842 - INFO - val: {'epoch': 42, 'time_epoch': 3.57488, 'loss': 0.23849097, 'lr': 0, 'params': 345143, 'time_iter': 0.05674, 'accuracy': 0.88436, 'precision': 0.89641, 'recall': 0.39207, 'f1': 0.54553, 'auc': 0.92076, 'accuracy-SBM': 0.69116}
2025-07-05 10:31:47,587 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:31:48,079 - INFO - test: {'epoch': 42, 'time_epoch': 3.72753, 'loss': 0.23681567, 'lr': 0, 'params': 345143, 'time_iter': 0.05917, 'accuracy': 0.88507, 'precision': 0.89486, 'recall': 0.39412, 'f1': 0.54722, 'auc': 0.92108, 'accuracy-SBM': 0.69211}
2025-07-05 10:31:48,081 - INFO - > Epoch 42: took 49.8s (avg 52.0s) | Best so far: epoch 39	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0928 val_accuracy-SBM: 0.8610	test_loss: 0.0916 test_accuracy-SBM: 0.8621
2025-07-05 10:31:48,081 - INFO - === Epoch 43 ===
2025-07-05 10:32:25,030 - INFO - train: {'epoch': 43, 'time_epoch': 35.28523, 'eta': 2121.34734, 'eta_hours': 0.58926, 'loss': 0.0904358, 'lr': 0.00032725, 'params': 345143, 'time_iter': 0.11273, 'accuracy': 0.86239, 'precision': 0.5729, 'recall': 0.86616, 'f1': 0.68965, 'auc': 0.94028, 'accuracy-SBM': 0.86388}
2025-07-05 10:32:29,161 - INFO - val: {'epoch': 43, 'time_epoch': 3.62002, 'loss': 0.09250619, 'lr': 0, 'params': 345143, 'time_iter': 0.05746, 'accuracy': 0.87392, 'precision': 0.60307, 'recall': 0.8419, 'f1': 0.70275, 'auc': 0.93914, 'accuracy-SBM': 0.86136}
2025-07-05 10:32:34,896 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:32:35,409 - INFO - test: {'epoch': 43, 'time_epoch': 3.63283, 'loss': 0.09139685, 'lr': 0, 'params': 345143, 'time_iter': 0.05766, 'accuracy': 0.8761, 'precision': 0.60698, 'recall': 0.84223, 'f1': 0.70551, 'auc': 0.94012, 'accuracy-SBM': 0.86279}
2025-07-05 10:32:35,413 - INFO - > Epoch 43: took 47.3s (avg 51.9s) | Best so far: epoch 43	train_loss: 0.0904 train_accuracy-SBM: 0.8639	val_loss: 0.0925 val_accuracy-SBM: 0.8614	test_loss: 0.0914 test_accuracy-SBM: 0.8628
2025-07-05 10:32:35,413 - INFO - === Epoch 44 ===
2025-07-05 10:33:13,478 - INFO - train: {'epoch': 44, 'time_epoch': 35.36178, 'eta': 2080.38684, 'eta_hours': 0.57789, 'loss': 0.09033642, 'lr': 0.00031935, 'params': 345143, 'time_iter': 0.11298, 'accuracy': 0.86271, 'precision': 0.57362, 'recall': 0.86578, 'f1': 0.69005, 'auc': 0.94048, 'accuracy-SBM': 0.86392}
2025-07-05 10:33:17,587 - INFO - val: {'epoch': 44, 'time_epoch': 3.60219, 'loss': 0.13933866, 'lr': 0, 'params': 345143, 'time_iter': 0.05718, 'accuracy': 0.88264, 'precision': 0.66668, 'recall': 0.67404, 'f1': 0.67034, 'auc': 0.91161, 'accuracy-SBM': 0.80077}
2025-07-05 10:33:23,265 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:33:23,771 - INFO - test: {'epoch': 44, 'time_epoch': 3.60915, 'loss': 0.13946711, 'lr': 0, 'params': 345143, 'time_iter': 0.05729, 'accuracy': 0.88372, 'precision': 0.66839, 'recall': 0.67511, 'f1': 0.67173, 'auc': 0.91173, 'accuracy-SBM': 0.80173}
2025-07-05 10:33:23,773 - INFO - > Epoch 44: took 48.4s (avg 51.8s) | Best so far: epoch 43	train_loss: 0.0904 train_accuracy-SBM: 0.8639	val_loss: 0.0925 val_accuracy-SBM: 0.8614	test_loss: 0.0914 test_accuracy-SBM: 0.8628
2025-07-05 10:33:23,773 - INFO - === Epoch 45 ===
2025-07-05 10:34:00,655 - INFO - train: {'epoch': 45, 'time_epoch': 35.44562, 'eta': 2039.76819, 'eta_hours': 0.5666, 'loss': 0.09038691, 'lr': 0.00031137, 'params': 345143, 'time_iter': 0.11324, 'accuracy': 0.86216, 'precision': 0.57233, 'recall': 0.86694, 'f1': 0.68948, 'auc': 0.9404, 'accuracy-SBM': 0.86404}
2025-07-05 10:34:04,701 - INFO - val: {'epoch': 45, 'time_epoch': 3.55345, 'loss': 0.09152896, 'lr': 0, 'params': 345143, 'time_iter': 0.0564, 'accuracy': 0.86723, 'precision': 0.58551, 'recall': 0.85579, 'f1': 0.69531, 'auc': 0.93953, 'accuracy-SBM': 0.86274}
2025-07-05 10:34:10,371 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:34:10,863 - INFO - test: {'epoch': 45, 'time_epoch': 3.60103, 'loss': 0.09046839, 'lr': 0, 'params': 345143, 'time_iter': 0.05716, 'accuracy': 0.87003, 'precision': 0.59042, 'recall': 0.85691, 'f1': 0.69913, 'auc': 0.94042, 'accuracy-SBM': 0.86487}
2025-07-05 10:34:10,865 - INFO - > Epoch 45: took 47.1s (avg 51.7s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:34:10,865 - INFO - === Epoch 46 ===
2025-07-05 10:34:48,994 - INFO - train: {'epoch': 46, 'time_epoch': 35.48886, 'eta': 1999.41842, 'eta_hours': 0.55539, 'loss': 0.09044587, 'lr': 0.00030332, 'params': 345143, 'time_iter': 0.11338, 'accuracy': 0.8617, 'precision': 0.57133, 'recall': 0.86697, 'f1': 0.68877, 'auc': 0.94029, 'accuracy-SBM': 0.86377}
2025-07-05 10:34:52,872 - INFO - val: {'epoch': 46, 'time_epoch': 3.5806, 'loss': 0.18413462, 'lr': 0, 'params': 345143, 'time_iter': 0.05683, 'accuracy': 0.41042, 'precision': 0.23033, 'recall': 0.99528, 'f1': 0.37409, 'auc': 0.9265, 'accuracy-SBM': 0.63995}
2025-07-05 10:34:58,548 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:34:58,836 - INFO - test: {'epoch': 46, 'time_epoch': 3.61408, 'loss': 0.18349718, 'lr': 0, 'params': 345143, 'time_iter': 0.05737, 'accuracy': 0.40963, 'precision': 0.22923, 'recall': 0.99485, 'f1': 0.37261, 'auc': 0.92634, 'accuracy-SBM': 0.63964}
2025-07-05 10:34:58,838 - INFO - > Epoch 46: took 48.0s (avg 51.6s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:34:58,838 - INFO - === Epoch 47 ===
2025-07-05 10:35:36,867 - INFO - train: {'epoch': 47, 'time_epoch': 35.37988, 'eta': 1959.15312, 'eta_hours': 0.54421, 'loss': 0.09041085, 'lr': 0.00029522, 'params': 345143, 'time_iter': 0.11303, 'accuracy': 0.86195, 'precision': 0.5719, 'recall': 0.86672, 'f1': 0.6891, 'auc': 0.94031, 'accuracy-SBM': 0.86383}
2025-07-05 10:35:40,914 - INFO - val: {'epoch': 47, 'time_epoch': 3.58186, 'loss': 0.31244084, 'lr': 0, 'params': 345143, 'time_iter': 0.05685, 'accuracy': 0.84371, 'precision': 0.9209, 'recall': 0.12813, 'f1': 0.22496, 'auc': 0.89036, 'accuracy-SBM': 0.56288}
2025-07-05 10:35:46,551 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:35:47,016 - INFO - test: {'epoch': 47, 'time_epoch': 3.61558, 'loss': 0.31220957, 'lr': 0, 'params': 345143, 'time_iter': 0.05739, 'accuracy': 0.84466, 'precision': 0.92354, 'recall': 0.12918, 'f1': 0.22666, 'auc': 0.88971, 'accuracy-SBM': 0.56345}
2025-07-05 10:35:47,018 - INFO - > Epoch 47: took 48.2s (avg 51.5s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:35:47,018 - INFO - === Epoch 48 ===
2025-07-05 10:36:25,151 - INFO - train: {'epoch': 48, 'time_epoch': 35.45677, 'eta': 1919.16727, 'eta_hours': 0.5331, 'loss': 0.0903028, 'lr': 0.00028707, 'params': 345143, 'time_iter': 0.11328, 'accuracy': 0.86213, 'precision': 0.57226, 'recall': 0.86694, 'f1': 0.68943, 'auc': 0.94052, 'accuracy-SBM': 0.86402}
2025-07-05 10:36:29,237 - INFO - val: {'epoch': 48, 'time_epoch': 3.59614, 'loss': 0.11285587, 'lr': 0, 'params': 345143, 'time_iter': 0.05708, 'accuracy': 0.89771, 'precision': 0.71098, 'recall': 0.71131, 'f1': 0.71115, 'auc': 0.93278, 'accuracy-SBM': 0.82456}
2025-07-05 10:36:34,913 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:36:35,368 - INFO - test: {'epoch': 48, 'time_epoch': 3.60579, 'loss': 0.11191096, 'lr': 0, 'params': 345143, 'time_iter': 0.05723, 'accuracy': 0.89877, 'precision': 0.71376, 'recall': 0.71046, 'f1': 0.7121, 'auc': 0.93391, 'accuracy-SBM': 0.82475}
2025-07-05 10:36:35,370 - INFO - > Epoch 48: took 48.4s (avg 51.5s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:36:35,370 - INFO - === Epoch 49 ===
2025-07-05 10:37:13,534 - INFO - train: {'epoch': 49, 'time_epoch': 35.46054, 'eta': 1879.36635, 'eta_hours': 0.52205, 'loss': 0.09036924, 'lr': 0.00027887, 'params': 345143, 'time_iter': 0.11329, 'accuracy': 0.86215, 'precision': 0.5723, 'recall': 0.86695, 'f1': 0.68947, 'auc': 0.94043, 'accuracy-SBM': 0.86404}
2025-07-05 10:37:17,574 - INFO - val: {'epoch': 49, 'time_epoch': 3.57416, 'loss': 0.1295841, 'lr': 0, 'params': 345143, 'time_iter': 0.05673, 'accuracy': 0.90051, 'precision': 0.75893, 'recall': 0.64185, 'f1': 0.6955, 'auc': 0.93157, 'accuracy-SBM': 0.799}
2025-07-05 10:37:23,563 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:37:24,028 - INFO - test: {'epoch': 49, 'time_epoch': 3.59677, 'loss': 0.1288915, 'lr': 0, 'params': 345143, 'time_iter': 0.05709, 'accuracy': 0.90196, 'precision': 0.76334, 'recall': 0.64302, 'f1': 0.69803, 'auc': 0.93256, 'accuracy-SBM': 0.80019}
2025-07-05 10:37:24,030 - INFO - > Epoch 49: took 48.7s (avg 51.4s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:37:24,030 - INFO - === Epoch 50 ===
2025-07-05 10:38:02,073 - INFO - train: {'epoch': 50, 'time_epoch': 35.4366, 'eta': 1839.71264, 'eta_hours': 0.51103, 'loss': 0.09030536, 'lr': 0.00027064, 'params': 345143, 'time_iter': 0.11322, 'accuracy': 0.86289, 'precision': 0.57396, 'recall': 0.86616, 'f1': 0.69042, 'auc': 0.94052, 'accuracy-SBM': 0.86417}
2025-07-05 10:38:06,142 - INFO - val: {'epoch': 50, 'time_epoch': 3.58673, 'loss': 0.14996186, 'lr': 0, 'params': 345143, 'time_iter': 0.05693, 'accuracy': 0.90056, 'precision': 0.78169, 'recall': 0.60808, 'f1': 0.68404, 'auc': 0.92821, 'accuracy-SBM': 0.78577}
2025-07-05 10:38:11,837 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:38:12,319 - INFO - test: {'epoch': 50, 'time_epoch': 3.60727, 'loss': 0.14891223, 'lr': 0, 'params': 345143, 'time_iter': 0.05726, 'accuracy': 0.90174, 'precision': 0.784, 'recall': 0.61067, 'f1': 0.68657, 'auc': 0.9292, 'accuracy-SBM': 0.78734}
2025-07-05 10:38:12,323 - INFO - > Epoch 50: took 48.3s (avg 51.4s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:38:12,323 - INFO - === Epoch 51 ===
2025-07-05 10:38:49,244 - INFO - train: {'epoch': 51, 'time_epoch': 35.43352, 'eta': 1800.21829, 'eta_hours': 0.50006, 'loss': 0.09021038, 'lr': 0.0002624, 'params': 345143, 'time_iter': 0.11321, 'accuracy': 0.86251, 'precision': 0.57307, 'recall': 0.86706, 'f1': 0.69006, 'auc': 0.94059, 'accuracy-SBM': 0.8643}
2025-07-05 10:38:53,289 - INFO - val: {'epoch': 51, 'time_epoch': 3.5745, 'loss': 0.39817691, 'lr': 0, 'params': 345143, 'time_iter': 0.05674, 'accuracy': 0.84644, 'precision': 0.8892, 'recall': 0.15141, 'f1': 0.25875, 'auc': 0.88118, 'accuracy-SBM': 0.57367}
2025-07-05 10:38:58,979 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:38:59,431 - INFO - test: {'epoch': 51, 'time_epoch': 3.61487, 'loss': 0.39649255, 'lr': 0, 'params': 345143, 'time_iter': 0.05738, 'accuracy': 0.84731, 'precision': 0.8878, 'recall': 0.15286, 'f1': 0.26081, 'auc': 0.88131, 'accuracy-SBM': 0.57436}
2025-07-05 10:38:59,433 - INFO - > Epoch 51: took 47.1s (avg 51.3s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:38:59,433 - INFO - === Epoch 52 ===
2025-07-05 10:39:35,116 - INFO - train: {'epoch': 52, 'time_epoch': 35.28131, 'eta': 1760.74219, 'eta_hours': 0.4891, 'loss': 0.09025671, 'lr': 0.00025413, 'params': 345143, 'time_iter': 0.11272, 'accuracy': 0.86247, 'precision': 0.57302, 'recall': 0.86659, 'f1': 0.68987, 'auc': 0.94054, 'accuracy-SBM': 0.86409}
2025-07-05 10:39:38,819 - INFO - val: {'epoch': 52, 'time_epoch': 3.44675, 'loss': 0.10644955, 'lr': 0, 'params': 345143, 'time_iter': 0.05471, 'accuracy': 0.75622, 'precision': 0.41639, 'recall': 0.93909, 'f1': 0.57696, 'auc': 0.93281, 'accuracy-SBM': 0.82799}
2025-07-05 10:39:45,128 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:39:45,591 - INFO - test: {'epoch': 52, 'time_epoch': 3.48519, 'loss': 0.10555705, 'lr': 0, 'params': 345143, 'time_iter': 0.05532, 'accuracy': 0.75815, 'precision': 0.41725, 'recall': 0.93904, 'f1': 0.57778, 'auc': 0.93347, 'accuracy-SBM': 0.82925}
2025-07-05 10:39:45,608 - INFO - > Epoch 52: took 46.2s (avg 51.2s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:39:45,608 - INFO - === Epoch 53 ===
2025-07-05 10:40:25,796 - INFO - train: {'epoch': 53, 'time_epoch': 37.0106, 'eta': 1722.89455, 'eta_hours': 0.47858, 'loss': 0.09014952, 'lr': 0.00024587, 'params': 345143, 'time_iter': 0.11824, 'accuracy': 0.86286, 'precision': 0.57389, 'recall': 0.86645, 'f1': 0.69045, 'auc': 0.9407, 'accuracy-SBM': 0.86427}
2025-07-05 10:40:30,095 - INFO - val: {'epoch': 53, 'time_epoch': 3.81648, 'loss': 0.17176725, 'lr': 0, 'params': 345143, 'time_iter': 0.06058, 'accuracy': 0.89296, 'precision': 0.78698, 'recall': 0.54209, 'f1': 0.64197, 'auc': 0.91633, 'accuracy-SBM': 0.75526}
2025-07-05 10:40:35,777 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:40:36,243 - INFO - test: {'epoch': 53, 'time_epoch': 3.63113, 'loss': 0.17118517, 'lr': 0, 'params': 345143, 'time_iter': 0.05764, 'accuracy': 0.89412, 'precision': 0.78976, 'recall': 0.54397, 'f1': 0.64422, 'auc': 0.91698, 'accuracy-SBM': 0.7565}
2025-07-05 10:40:36,244 - INFO - > Epoch 53: took 50.6s (avg 51.2s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:40:36,245 - INFO - === Epoch 54 ===
2025-07-05 10:41:14,959 - INFO - train: {'epoch': 54, 'time_epoch': 35.71644, 'eta': 1684.0185, 'eta_hours': 0.46778, 'loss': 0.09022493, 'lr': 0.0002376, 'params': 345143, 'time_iter': 0.11411, 'accuracy': 0.86192, 'precision': 0.57175, 'recall': 0.86772, 'f1': 0.68931, 'auc': 0.94062, 'accuracy-SBM': 0.8642}
2025-07-05 10:41:18,948 - INFO - val: {'epoch': 54, 'time_epoch': 3.69566, 'loss': 0.13066347, 'lr': 0, 'params': 345143, 'time_iter': 0.05866, 'accuracy': 0.65428, 'precision': 0.33563, 'recall': 0.97294, 'f1': 0.49909, 'auc': 0.93293, 'accuracy-SBM': 0.77934}
2025-07-05 10:41:24,825 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:41:25,303 - INFO - test: {'epoch': 54, 'time_epoch': 3.87945, 'loss': 0.12951413, 'lr': 0, 'params': 345143, 'time_iter': 0.06158, 'accuracy': 0.65726, 'precision': 0.33646, 'recall': 0.97203, 'f1': 0.49988, 'auc': 0.93345, 'accuracy-SBM': 0.78098}
2025-07-05 10:41:25,304 - INFO - > Epoch 54: took 49.1s (avg 51.1s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:41:25,304 - INFO - === Epoch 55 ===
2025-07-05 10:42:02,711 - INFO - train: {'epoch': 55, 'time_epoch': 35.77555, 'eta': 1645.30173, 'eta_hours': 0.45703, 'loss': 0.09016451, 'lr': 0.00022936, 'params': 345143, 'time_iter': 0.1143, 'accuracy': 0.86231, 'precision': 0.5726, 'recall': 0.86742, 'f1': 0.68983, 'auc': 0.94066, 'accuracy-SBM': 0.86432}
2025-07-05 10:42:06,623 - INFO - val: {'epoch': 55, 'time_epoch': 3.62246, 'loss': 0.1002837, 'lr': 0, 'params': 345143, 'time_iter': 0.0575, 'accuracy': 0.78746, 'precision': 0.45157, 'recall': 0.93533, 'f1': 0.60908, 'auc': 0.93959, 'accuracy-SBM': 0.84549}
2025-07-05 10:42:12,511 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:42:13,022 - INFO - test: {'epoch': 55, 'time_epoch': 3.71099, 'loss': 0.09905547, 'lr': 0, 'params': 345143, 'time_iter': 0.0589, 'accuracy': 0.78954, 'precision': 0.45288, 'recall': 0.93383, 'f1': 0.60995, 'auc': 0.94035, 'accuracy-SBM': 0.84625}
2025-07-05 10:42:13,025 - INFO - > Epoch 55: took 47.7s (avg 51.1s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:42:13,025 - INFO - === Epoch 56 ===
2025-07-05 10:42:52,102 - INFO - train: {'epoch': 56, 'time_epoch': 36.10237, 'eta': 1606.93471, 'eta_hours': 0.44637, 'loss': 0.0900429, 'lr': 0.00022113, 'params': 345143, 'time_iter': 0.11534, 'accuracy': 0.86266, 'precision': 0.57335, 'recall': 0.86745, 'f1': 0.69038, 'auc': 0.94085, 'accuracy-SBM': 0.86454}
2025-07-05 10:42:56,226 - INFO - val: {'epoch': 56, 'time_epoch': 3.65322, 'loss': 0.09402103, 'lr': 0, 'params': 345143, 'time_iter': 0.05799, 'accuracy': 0.88333, 'precision': 0.63108, 'recall': 0.82063, 'f1': 0.71348, 'auc': 0.93944, 'accuracy-SBM': 0.85872}
2025-07-05 10:43:02,334 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:43:02,815 - INFO - test: {'epoch': 56, 'time_epoch': 3.8169, 'loss': 0.09307254, 'lr': 0, 'params': 345143, 'time_iter': 0.06059, 'accuracy': 0.88532, 'precision': 0.63531, 'recall': 0.81982, 'f1': 0.71587, 'auc': 0.94039, 'accuracy-SBM': 0.85957}
2025-07-05 10:43:02,817 - INFO - > Epoch 56: took 49.8s (avg 51.1s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:43:02,818 - INFO - === Epoch 57 ===
2025-07-05 10:43:42,344 - INFO - train: {'epoch': 57, 'time_epoch': 35.99002, 'eta': 1568.56442, 'eta_hours': 0.43571, 'loss': 0.09011569, 'lr': 0.00021293, 'params': 345143, 'time_iter': 0.11498, 'accuracy': 0.86254, 'precision': 0.57314, 'recall': 0.86697, 'f1': 0.69008, 'auc': 0.94076, 'accuracy-SBM': 0.86428}
2025-07-05 10:43:46,610 - INFO - val: {'epoch': 57, 'time_epoch': 3.7758, 'loss': 0.09409859, 'lr': 0, 'params': 345143, 'time_iter': 0.05993, 'accuracy': 0.86103, 'precision': 0.57219, 'recall': 0.85198, 'f1': 0.6846, 'auc': 0.93522, 'accuracy-SBM': 0.85748}
2025-07-05 10:43:52,283 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:43:52,755 - INFO - test: {'epoch': 57, 'time_epoch': 3.66129, 'loss': 0.09309696, 'lr': 0, 'params': 345143, 'time_iter': 0.05812, 'accuracy': 0.86286, 'precision': 0.57483, 'recall': 0.85179, 'f1': 0.68643, 'auc': 0.93607, 'accuracy-SBM': 0.85851}
2025-07-05 10:43:52,757 - INFO - > Epoch 57: took 49.9s (avg 51.0s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:43:52,757 - INFO - === Epoch 58 ===
2025-07-05 10:44:31,837 - INFO - train: {'epoch': 58, 'time_epoch': 37.1962, 'eta': 1531.11302, 'eta_hours': 0.42531, 'loss': 0.0900432, 'lr': 0.00020478, 'params': 345143, 'time_iter': 0.11884, 'accuracy': 0.86259, 'precision': 0.57323, 'recall': 0.86711, 'f1': 0.69019, 'auc': 0.94085, 'accuracy-SBM': 0.86437}
2025-07-05 10:44:35,822 - INFO - val: {'epoch': 58, 'time_epoch': 3.67425, 'loss': 0.1239113, 'lr': 0, 'params': 345143, 'time_iter': 0.05832, 'accuracy': 0.67262, 'precision': 0.34784, 'recall': 0.97089, 'f1': 0.51219, 'auc': 0.93507, 'accuracy-SBM': 0.78968}
2025-07-05 10:44:42,010 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:44:42,472 - INFO - test: {'epoch': 58, 'time_epoch': 3.84699, 'loss': 0.12262521, 'lr': 0, 'params': 345143, 'time_iter': 0.06106, 'accuracy': 0.67621, 'precision': 0.34924, 'recall': 0.97001, 'f1': 0.51358, 'auc': 0.9356, 'accuracy-SBM': 0.79168}
2025-07-05 10:44:42,474 - INFO - > Epoch 58: took 49.7s (avg 51.0s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:44:42,474 - INFO - === Epoch 59 ===
2025-07-05 10:45:20,153 - INFO - train: {'epoch': 59, 'time_epoch': 36.18754, 'eta': 1492.99768, 'eta_hours': 0.41472, 'loss': 0.08999667, 'lr': 0.00019668, 'params': 345143, 'time_iter': 0.11562, 'accuracy': 0.86262, 'precision': 0.57326, 'recall': 0.86744, 'f1': 0.69032, 'auc': 0.94093, 'accuracy-SBM': 0.86451}
2025-07-05 10:45:24,218 - INFO - val: {'epoch': 59, 'time_epoch': 3.58657, 'loss': 0.09732157, 'lr': 0, 'params': 345143, 'time_iter': 0.05693, 'accuracy': 0.88432, 'precision': 0.63783, 'recall': 0.80186, 'f1': 0.7105, 'auc': 0.93587, 'accuracy-SBM': 0.85196}
2025-07-05 10:45:30,077 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:45:30,567 - INFO - test: {'epoch': 59, 'time_epoch': 3.67299, 'loss': 0.09640683, 'lr': 0, 'params': 345143, 'time_iter': 0.0583, 'accuracy': 0.88586, 'precision': 0.64098, 'recall': 0.80081, 'f1': 0.71203, 'auc': 0.93677, 'accuracy-SBM': 0.85243}
2025-07-05 10:45:30,569 - INFO - > Epoch 59: took 48.1s (avg 51.0s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:45:30,569 - INFO - === Epoch 60 ===
2025-07-05 10:46:08,199 - INFO - train: {'epoch': 60, 'time_epoch': 36.12907, 'eta': 1454.90816, 'eta_hours': 0.40414, 'loss': 0.08998333, 'lr': 0.00018863, 'params': 345143, 'time_iter': 0.11543, 'accuracy': 0.86285, 'precision': 0.5738, 'recall': 0.86692, 'f1': 0.69054, 'auc': 0.94092, 'accuracy-SBM': 0.86445}
2025-07-05 10:46:12,088 - INFO - val: {'epoch': 60, 'time_epoch': 3.59225, 'loss': 0.1055856, 'lr': 0, 'params': 345143, 'time_iter': 0.05702, 'accuracy': 0.7604, 'precision': 0.42077, 'recall': 0.93859, 'f1': 0.58105, 'auc': 0.93372, 'accuracy-SBM': 0.83033}
2025-07-05 10:46:26,898 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:46:27,393 - INFO - test: {'epoch': 60, 'time_epoch': 3.6731, 'loss': 0.10449855, 'lr': 0, 'params': 345143, 'time_iter': 0.0583, 'accuracy': 0.76315, 'precision': 0.42248, 'recall': 0.93757, 'f1': 0.58249, 'auc': 0.93459, 'accuracy-SBM': 0.8317}
2025-07-05 10:46:27,397 - INFO - > Epoch 60: took 56.8s (avg 51.1s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:46:27,398 - INFO - === Epoch 61 ===
2025-07-05 10:47:05,592 - INFO - train: {'epoch': 61, 'time_epoch': 36.12904, 'eta': 1416.88187, 'eta_hours': 0.39358, 'loss': 0.08988388, 'lr': 0.00018065, 'params': 345143, 'time_iter': 0.11543, 'accuracy': 0.86328, 'precision': 0.57464, 'recall': 0.86784, 'f1': 0.69144, 'auc': 0.94109, 'accuracy-SBM': 0.86507}
2025-07-05 10:47:09,708 - INFO - val: {'epoch': 61, 'time_epoch': 3.65537, 'loss': 0.16692892, 'lr': 0, 'params': 345143, 'time_iter': 0.05802, 'accuracy': 0.89431, 'precision': 0.77577, 'recall': 0.56677, 'f1': 0.655, 'auc': 0.918, 'accuracy-SBM': 0.76577}
2025-07-05 10:47:15,519 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:47:15,972 - INFO - test: {'epoch': 61, 'time_epoch': 3.63733, 'loss': 0.1665368, 'lr': 0, 'params': 345143, 'time_iter': 0.05774, 'accuracy': 0.89556, 'precision': 0.77845, 'recall': 0.56939, 'f1': 0.65771, 'auc': 0.91875, 'accuracy-SBM': 0.76736}
2025-07-05 10:47:15,974 - INFO - > Epoch 61: took 48.6s (avg 51.0s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:47:15,974 - INFO - === Epoch 62 ===
2025-07-05 10:47:54,389 - INFO - train: {'epoch': 62, 'time_epoch': 35.60692, 'eta': 1378.60916, 'eta_hours': 0.38295, 'loss': 0.0899818, 'lr': 0.00017275, 'params': 345143, 'time_iter': 0.11376, 'accuracy': 0.86287, 'precision': 0.57382, 'recall': 0.86712, 'f1': 0.69062, 'auc': 0.94091, 'accuracy-SBM': 0.86454}
2025-07-05 10:47:58,501 - INFO - val: {'epoch': 62, 'time_epoch': 3.61568, 'loss': 0.09686894, 'lr': 0, 'params': 345143, 'time_iter': 0.05739, 'accuracy': 0.87877, 'precision': 0.62036, 'recall': 0.81222, 'f1': 0.70344, 'auc': 0.93519, 'accuracy-SBM': 0.85265}
2025-07-05 10:48:04,633 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:48:05,141 - INFO - test: {'epoch': 62, 'time_epoch': 3.75064, 'loss': 0.09606844, 'lr': 0, 'params': 345143, 'time_iter': 0.05953, 'accuracy': 0.88099, 'precision': 0.62506, 'recall': 0.81131, 'f1': 0.70611, 'auc': 0.93605, 'accuracy-SBM': 0.85361}
2025-07-05 10:48:05,143 - INFO - > Epoch 62: took 49.2s (avg 51.0s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:48:05,143 - INFO - === Epoch 63 ===
2025-07-05 10:48:44,144 - INFO - train: {'epoch': 63, 'time_epoch': 35.79007, 'eta': 1340.52278, 'eta_hours': 0.37237, 'loss': 0.09003097, 'lr': 0.00016493, 'params': 345143, 'time_iter': 0.11435, 'accuracy': 0.86278, 'precision': 0.57362, 'recall': 0.86732, 'f1': 0.69054, 'auc': 0.94082, 'accuracy-SBM': 0.86457}
2025-07-05 10:48:48,407 - INFO - val: {'epoch': 63, 'time_epoch': 3.77807, 'loss': 0.09957023, 'lr': 0, 'params': 345143, 'time_iter': 0.05997, 'accuracy': 0.89498, 'precision': 0.67757, 'recall': 0.77599, 'f1': 0.72344, 'auc': 0.93888, 'accuracy-SBM': 0.84828}
2025-07-05 10:48:54,052 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:48:54,545 - INFO - test: {'epoch': 63, 'time_epoch': 3.5854, 'loss': 0.0987584, 'lr': 0, 'params': 345143, 'time_iter': 0.05691, 'accuracy': 0.89712, 'precision': 0.68319, 'recall': 0.77604, 'f1': 0.72666, 'auc': 0.93987, 'accuracy-SBM': 0.84953}
2025-07-05 10:48:54,547 - INFO - > Epoch 63: took 49.4s (avg 51.0s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:48:54,547 - INFO - === Epoch 64 ===
2025-07-05 10:49:31,051 - INFO - train: {'epoch': 64, 'time_epoch': 36.01646, 'eta': 1302.62896, 'eta_hours': 0.36184, 'loss': 0.08998393, 'lr': 0.0001572, 'params': 345143, 'time_iter': 0.11507, 'accuracy': 0.86244, 'precision': 0.57281, 'recall': 0.86804, 'f1': 0.69018, 'auc': 0.94092, 'accuracy-SBM': 0.86464}
2025-07-05 10:49:35,198 - INFO - val: {'epoch': 64, 'time_epoch': 3.65422, 'loss': 0.09468946, 'lr': 0, 'params': 345143, 'time_iter': 0.058, 'accuracy': 0.88605, 'precision': 0.64068, 'recall': 0.81131, 'f1': 0.71597, 'auc': 0.93895, 'accuracy-SBM': 0.85672}
2025-07-05 10:49:40,964 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:49:41,420 - INFO - test: {'epoch': 64, 'time_epoch': 3.79772, 'loss': 0.09376008, 'lr': 0, 'params': 345143, 'time_iter': 0.06028, 'accuracy': 0.88794, 'precision': 0.64469, 'recall': 0.8111, 'f1': 0.71838, 'auc': 0.93986, 'accuracy-SBM': 0.85774}
2025-07-05 10:49:41,422 - INFO - > Epoch 64: took 46.9s (avg 50.9s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:49:41,422 - INFO - === Epoch 65 ===
2025-07-05 10:50:19,321 - INFO - train: {'epoch': 65, 'time_epoch': 36.03488, 'eta': 1264.80152, 'eta_hours': 0.35133, 'loss': 0.08988139, 'lr': 0.00014958, 'params': 345143, 'time_iter': 0.11513, 'accuracy': 0.86313, 'precision': 0.57438, 'recall': 0.86726, 'f1': 0.69107, 'auc': 0.94105, 'accuracy-SBM': 0.86475}
2025-07-05 10:50:23,330 - INFO - val: {'epoch': 65, 'time_epoch': 3.7029, 'loss': 0.10606308, 'lr': 0, 'params': 345143, 'time_iter': 0.05878, 'accuracy': 0.75716, 'precision': 0.41781, 'recall': 0.94502, 'f1': 0.57944, 'auc': 0.93701, 'accuracy-SBM': 0.83089}
2025-07-05 10:50:29,407 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:50:29,897 - INFO - test: {'epoch': 65, 'time_epoch': 3.81421, 'loss': 0.10472906, 'lr': 0, 'params': 345143, 'time_iter': 0.06054, 'accuracy': 0.76056, 'precision': 0.42016, 'recall': 0.94395, 'f1': 0.58149, 'auc': 0.93774, 'accuracy-SBM': 0.83264}
2025-07-05 10:50:29,899 - INFO - > Epoch 65: took 48.5s (avg 50.9s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:50:29,900 - INFO - === Epoch 66 ===
2025-07-05 10:51:09,400 - INFO - train: {'epoch': 66, 'time_epoch': 36.16384, 'eta': 1227.09111, 'eta_hours': 0.34086, 'loss': 0.08985734, 'lr': 0.00014206, 'params': 345143, 'time_iter': 0.11554, 'accuracy': 0.8628, 'precision': 0.57358, 'recall': 0.86805, 'f1': 0.69074, 'auc': 0.9411, 'accuracy-SBM': 0.86486}
2025-07-05 10:51:13,607 - INFO - val: {'epoch': 66, 'time_epoch': 3.75772, 'loss': 0.2129191, 'lr': 0, 'params': 345143, 'time_iter': 0.05965, 'accuracy': 0.88927, 'precision': 0.85971, 'recall': 0.44755, 'f1': 0.58865, 'auc': 0.9186, 'accuracy-SBM': 0.71592}
2025-07-05 10:51:19,170 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:51:19,615 - INFO - test: {'epoch': 66, 'time_epoch': 3.5582, 'loss': 0.21186917, 'lr': 0, 'params': 345143, 'time_iter': 0.05648, 'accuracy': 0.88986, 'precision': 0.86027, 'recall': 0.44774, 'f1': 0.58895, 'auc': 0.91935, 'accuracy-SBM': 0.71609}
2025-07-05 10:51:19,618 - INFO - > Epoch 66: took 49.7s (avg 50.8s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:51:19,618 - INFO - === Epoch 67 ===
2025-07-05 10:51:55,879 - INFO - train: {'epoch': 67, 'time_epoch': 35.75994, 'eta': 1189.23611, 'eta_hours': 0.33034, 'loss': 0.08988909, 'lr': 0.00013466, 'params': 345143, 'time_iter': 0.11425, 'accuracy': 0.8626, 'precision': 0.57315, 'recall': 0.86814, 'f1': 0.69046, 'auc': 0.941, 'accuracy-SBM': 0.86477}
2025-07-05 10:51:59,956 - INFO - val: {'epoch': 67, 'time_epoch': 3.63391, 'loss': 0.19779322, 'lr': 0, 'params': 345143, 'time_iter': 0.05768, 'accuracy': 0.89188, 'precision': 0.84908, 'recall': 0.47334, 'f1': 0.60783, 'auc': 0.91948, 'accuracy-SBM': 0.72762}
2025-07-05 10:52:05,637 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:52:06,101 - INFO - test: {'epoch': 67, 'time_epoch': 3.67141, 'loss': 0.19742313, 'lr': 0, 'params': 345143, 'time_iter': 0.05828, 'accuracy': 0.89251, 'precision': 0.84841, 'recall': 0.47489, 'f1': 0.60894, 'auc': 0.92009, 'accuracy-SBM': 0.72837}
2025-07-05 10:52:06,103 - INFO - > Epoch 67: took 46.5s (avg 50.8s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:52:06,103 - INFO - === Epoch 68 ===
2025-07-05 10:52:44,790 - INFO - train: {'epoch': 68, 'time_epoch': 35.89869, 'eta': 1151.50418, 'eta_hours': 0.31986, 'loss': 0.08982506, 'lr': 0.00012739, 'params': 345143, 'time_iter': 0.11469, 'accuracy': 0.86307, 'precision': 0.57417, 'recall': 0.86798, 'f1': 0.69115, 'auc': 0.94114, 'accuracy-SBM': 0.865}
2025-07-05 10:52:48,927 - INFO - val: {'epoch': 68, 'time_epoch': 3.66215, 'loss': 0.13983344, 'lr': 0, 'params': 345143, 'time_iter': 0.05813, 'accuracy': 0.89659, 'precision': 0.75136, 'recall': 0.62151, 'f1': 0.68029, 'auc': 0.92405, 'accuracy-SBM': 0.78864}
2025-07-05 10:52:55,161 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:52:55,633 - INFO - test: {'epoch': 68, 'time_epoch': 3.67533, 'loss': 0.13899325, 'lr': 0, 'params': 345143, 'time_iter': 0.05834, 'accuracy': 0.89818, 'precision': 0.75574, 'recall': 0.6238, 'f1': 0.68346, 'auc': 0.92512, 'accuracy-SBM': 0.79033}
2025-07-05 10:52:55,635 - INFO - > Epoch 68: took 49.5s (avg 50.8s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:52:55,635 - INFO - === Epoch 69 ===
2025-07-05 10:53:33,336 - INFO - train: {'epoch': 69, 'time_epoch': 36.16107, 'eta': 1113.93707, 'eta_hours': 0.30943, 'loss': 0.08982834, 'lr': 0.00012026, 'params': 345143, 'time_iter': 0.11553, 'accuracy': 0.86327, 'precision': 0.57463, 'recall': 0.86777, 'f1': 0.69142, 'auc': 0.94113, 'accuracy-SBM': 0.86504}
2025-07-05 10:53:37,228 - INFO - val: {'epoch': 69, 'time_epoch': 3.60377, 'loss': 0.0977778, 'lr': 0, 'params': 345143, 'time_iter': 0.0572, 'accuracy': 0.80074, 'precision': 0.46828, 'recall': 0.92727, 'f1': 0.62229, 'auc': 0.94004, 'accuracy-SBM': 0.8504}
2025-07-05 10:53:43,007 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:53:43,498 - INFO - test: {'epoch': 69, 'time_epoch': 3.66808, 'loss': 0.09657357, 'lr': 0, 'params': 345143, 'time_iter': 0.05822, 'accuracy': 0.80258, 'precision': 0.46954, 'recall': 0.92708, 'f1': 0.62336, 'auc': 0.94087, 'accuracy-SBM': 0.85152}
2025-07-05 10:53:43,500 - INFO - > Epoch 69: took 47.9s (avg 50.7s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:53:43,500 - INFO - === Epoch 70 ===
2025-07-05 10:54:21,439 - INFO - train: {'epoch': 70, 'time_epoch': 36.31484, 'eta': 1076.47238, 'eta_hours': 0.29902, 'loss': 0.08987301, 'lr': 0.00011326, 'params': 345143, 'time_iter': 0.11602, 'accuracy': 0.86308, 'precision': 0.5742, 'recall': 0.86784, 'f1': 0.69113, 'auc': 0.94104, 'accuracy-SBM': 0.86495}
2025-07-05 10:54:25,558 - INFO - val: {'epoch': 70, 'time_epoch': 3.6492, 'loss': 0.16620247, 'lr': 0, 'params': 345143, 'time_iter': 0.05792, 'accuracy': 0.89394, 'precision': 0.7783, 'recall': 0.56053, 'f1': 0.6517, 'auc': 0.91783, 'accuracy-SBM': 0.76309}
2025-07-05 10:54:31,535 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:54:32,021 - INFO - test: {'epoch': 70, 'time_epoch': 3.73216, 'loss': 0.16531628, 'lr': 0, 'params': 345143, 'time_iter': 0.05924, 'accuracy': 0.89547, 'precision': 0.78155, 'recall': 0.56463, 'f1': 0.65561, 'auc': 0.91879, 'accuracy-SBM': 0.76543}
2025-07-05 10:54:32,023 - INFO - > Epoch 70: took 48.5s (avg 50.7s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:54:32,023 - INFO - === Epoch 71 ===
2025-07-05 10:55:11,292 - INFO - train: {'epoch': 71, 'time_epoch': 36.13295, 'eta': 1038.96889, 'eta_hours': 0.2886, 'loss': 0.08970735, 'lr': 0.00010642, 'params': 345143, 'time_iter': 0.11544, 'accuracy': 0.86295, 'precision': 0.57387, 'recall': 0.86859, 'f1': 0.69112, 'auc': 0.94131, 'accuracy-SBM': 0.86517}
2025-07-05 10:55:15,539 - INFO - val: {'epoch': 71, 'time_epoch': 3.77589, 'loss': 0.11808859, 'lr': 0, 'params': 345143, 'time_iter': 0.05993, 'accuracy': 0.89911, 'precision': 0.72381, 'recall': 0.69543, 'f1': 0.70933, 'auc': 0.93183, 'accuracy-SBM': 0.81917}
2025-07-05 10:55:21,504 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:55:21,968 - INFO - test: {'epoch': 71, 'time_epoch': 3.71147, 'loss': 0.11698262, 'lr': 0, 'params': 345143, 'time_iter': 0.05891, 'accuracy': 0.90024, 'precision': 0.72676, 'recall': 0.69528, 'f1': 0.71067, 'auc': 0.93315, 'accuracy-SBM': 0.81968}
2025-07-05 10:55:21,970 - INFO - > Epoch 71: took 49.9s (avg 50.7s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:55:21,970 - INFO - === Epoch 72 ===
2025-07-05 10:56:02,007 - INFO - train: {'epoch': 72, 'time_epoch': 36.86263, 'eta': 1001.77283, 'eta_hours': 0.27827, 'loss': 0.08973806, 'lr': 9.973e-05, 'params': 345143, 'time_iter': 0.11777, 'accuracy': 0.86249, 'precision': 0.57287, 'recall': 0.86863, 'f1': 0.69041, 'auc': 0.94124, 'accuracy-SBM': 0.8649}
2025-07-05 10:56:06,270 - INFO - val: {'epoch': 72, 'time_epoch': 3.74274, 'loss': 0.09090996, 'lr': 0, 'params': 345143, 'time_iter': 0.05941, 'accuracy': 0.85656, 'precision': 0.56105, 'recall': 0.87163, 'f1': 0.68267, 'auc': 0.93931, 'accuracy-SBM': 0.86247}
2025-07-05 10:56:12,557 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:56:13,082 - INFO - test: {'epoch': 72, 'time_epoch': 3.89084, 'loss': 0.08982683, 'lr': 0, 'params': 345143, 'time_iter': 0.06176, 'accuracy': 0.85897, 'precision': 0.56467, 'recall': 0.87196, 'f1': 0.68545, 'auc': 0.9402, 'accuracy-SBM': 0.86408}
2025-07-05 10:56:13,085 - INFO - > Epoch 72: took 51.1s (avg 50.7s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:56:13,085 - INFO - === Epoch 73 ===
2025-07-05 10:56:52,137 - INFO - train: {'epoch': 73, 'time_epoch': 36.30652, 'eta': 964.3904, 'eta_hours': 0.26789, 'loss': 0.0897705, 'lr': 9.321e-05, 'params': 345143, 'time_iter': 0.116, 'accuracy': 0.86287, 'precision': 0.57378, 'recall': 0.86778, 'f1': 0.6908, 'auc': 0.94116, 'accuracy-SBM': 0.8648}
2025-07-05 10:56:56,388 - INFO - val: {'epoch': 73, 'time_epoch': 3.77837, 'loss': 0.16033877, 'lr': 0, 'params': 345143, 'time_iter': 0.05997, 'accuracy': 0.89388, 'precision': 0.75937, 'recall': 0.58628, 'f1': 0.66169, 'auc': 0.91747, 'accuracy-SBM': 0.77316}
2025-07-05 10:57:02,553 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:57:03,043 - INFO - test: {'epoch': 73, 'time_epoch': 3.84052, 'loss': 0.15968597, 'lr': 0, 'params': 345143, 'time_iter': 0.06096, 'accuracy': 0.89552, 'precision': 0.76297, 'recall': 0.59057, 'f1': 0.66579, 'auc': 0.91816, 'accuracy-SBM': 0.77566}
2025-07-05 10:57:03,060 - INFO - > Epoch 73: took 50.0s (avg 50.7s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:57:03,061 - INFO - === Epoch 74 ===
2025-07-05 10:57:42,178 - INFO - train: {'epoch': 74, 'time_epoch': 36.32772, 'eta': 927.04372, 'eta_hours': 0.25751, 'loss': 0.0898141, 'lr': 8.685e-05, 'params': 345143, 'time_iter': 0.11606, 'accuracy': 0.86266, 'precision': 0.57322, 'recall': 0.86871, 'f1': 0.69069, 'auc': 0.94115, 'accuracy-SBM': 0.86504}
2025-07-05 10:57:46,152 - INFO - val: {'epoch': 74, 'time_epoch': 3.69587, 'loss': 0.10550127, 'lr': 0, 'params': 345143, 'time_iter': 0.05866, 'accuracy': 0.75866, 'precision': 0.4192, 'recall': 0.94264, 'f1': 0.58033, 'auc': 0.93514, 'accuracy-SBM': 0.83086}
2025-07-05 10:57:52,401 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:57:52,917 - INFO - test: {'epoch': 74, 'time_epoch': 3.7996, 'loss': 0.10424754, 'lr': 0, 'params': 345143, 'time_iter': 0.06031, 'accuracy': 0.76202, 'precision': 0.4215, 'recall': 0.94088, 'f1': 0.58218, 'auc': 0.93593, 'accuracy-SBM': 0.83232}
2025-07-05 10:57:52,919 - INFO - > Epoch 74: took 49.9s (avg 50.7s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:57:52,919 - INFO - === Epoch 75 ===
2025-07-05 10:58:32,366 - INFO - train: {'epoch': 75, 'time_epoch': 36.36092, 'eta': 889.73434, 'eta_hours': 0.24715, 'loss': 0.08973658, 'lr': 8.068e-05, 'params': 345143, 'time_iter': 0.11617, 'accuracy': 0.86306, 'precision': 0.57415, 'recall': 0.8681, 'f1': 0.69117, 'auc': 0.94127, 'accuracy-SBM': 0.86504}
2025-07-05 10:58:36,418 - INFO - val: {'epoch': 75, 'time_epoch': 3.76189, 'loss': 0.10127911, 'lr': 0, 'params': 345143, 'time_iter': 0.05971, 'accuracy': 0.78074, 'precision': 0.44363, 'recall': 0.9388, 'f1': 0.60253, 'auc': 0.93972, 'accuracy-SBM': 0.84277}
2025-07-05 10:58:42,449 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:58:42,958 - INFO - test: {'epoch': 75, 'time_epoch': 3.82776, 'loss': 0.10003724, 'lr': 0, 'params': 345143, 'time_iter': 0.06076, 'accuracy': 0.78307, 'precision': 0.44518, 'recall': 0.9379, 'f1': 0.60377, 'auc': 0.94047, 'accuracy-SBM': 0.84393}
2025-07-05 10:58:42,960 - INFO - > Epoch 75: took 50.0s (avg 50.7s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:58:42,961 - INFO - === Epoch 76 ===
2025-07-05 10:59:20,620 - INFO - train: {'epoch': 76, 'time_epoch': 36.11677, 'eta': 852.37667, 'eta_hours': 0.23677, 'loss': 0.08970817, 'lr': 7.469e-05, 'params': 345143, 'time_iter': 0.11539, 'accuracy': 0.86302, 'precision': 0.57403, 'recall': 0.86831, 'f1': 0.69115, 'auc': 0.94129, 'accuracy-SBM': 0.86509}
2025-07-05 10:59:24,673 - INFO - val: {'epoch': 76, 'time_epoch': 3.562, 'loss': 0.10152959, 'lr': 0, 'params': 345143, 'time_iter': 0.05654, 'accuracy': 0.8858, 'precision': 0.64648, 'recall': 0.78309, 'f1': 0.70825, 'auc': 0.93383, 'accuracy-SBM': 0.84549}
2025-07-05 10:59:30,465 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 10:59:30,936 - INFO - test: {'epoch': 76, 'time_epoch': 3.64875, 'loss': 0.10059378, 'lr': 0, 'params': 345143, 'time_iter': 0.05792, 'accuracy': 0.88771, 'precision': 0.65044, 'recall': 0.78423, 'f1': 0.7111, 'auc': 0.93479, 'accuracy-SBM': 0.84704}
2025-07-05 10:59:30,938 - INFO - > Epoch 76: took 48.0s (avg 50.6s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0915 val_accuracy-SBM: 0.8627	test_loss: 0.0905 test_accuracy-SBM: 0.8649
2025-07-05 10:59:30,938 - INFO - === Epoch 77 ===
2025-07-05 11:00:10,098 - INFO - train: {'epoch': 77, 'time_epoch': 36.2353, 'eta': 815.08425, 'eta_hours': 0.22641, 'loss': 0.08964003, 'lr': 6.889e-05, 'params': 345143, 'time_iter': 0.11577, 'accuracy': 0.86331, 'precision': 0.57459, 'recall': 0.86893, 'f1': 0.69175, 'auc': 0.94136, 'accuracy-SBM': 0.86551}
2025-07-05 11:00:14,282 - INFO - val: {'epoch': 77, 'time_epoch': 3.69693, 'loss': 0.09086825, 'lr': 0, 'params': 345143, 'time_iter': 0.05868, 'accuracy': 0.8572, 'precision': 0.56223, 'recall': 0.87325, 'f1': 0.68405, 'auc': 0.94, 'accuracy-SBM': 0.8635}
2025-07-05 11:00:20,244 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:00:20,773 - INFO - test: {'epoch': 77, 'time_epoch': 3.79366, 'loss': 0.08981821, 'lr': 0, 'params': 345143, 'time_iter': 0.06022, 'accuracy': 0.85974, 'precision': 0.56614, 'recall': 0.8733, 'f1': 0.68695, 'auc': 0.94081, 'accuracy-SBM': 0.86507}
2025-07-05 11:00:20,780 - INFO - > Epoch 77: took 49.8s (avg 50.6s) | Best so far: epoch 77	train_loss: 0.0896 train_accuracy-SBM: 0.8655	val_loss: 0.0909 val_accuracy-SBM: 0.8635	test_loss: 0.0898 test_accuracy-SBM: 0.8651
2025-07-05 11:00:20,780 - INFO - === Epoch 78 ===
2025-07-05 11:01:00,170 - INFO - train: {'epoch': 78, 'time_epoch': 36.42074, 'eta': 777.86788, 'eta_hours': 0.21607, 'loss': 0.08961271, 'lr': 6.329e-05, 'params': 345143, 'time_iter': 0.11636, 'accuracy': 0.86333, 'precision': 0.57473, 'recall': 0.86813, 'f1': 0.6916, 'auc': 0.94143, 'accuracy-SBM': 0.86522}
2025-07-05 11:01:04,387 - INFO - val: {'epoch': 78, 'time_epoch': 3.71933, 'loss': 0.10162536, 'lr': 0, 'params': 345143, 'time_iter': 0.05904, 'accuracy': 0.89014, 'precision': 0.66235, 'recall': 0.77396, 'f1': 0.71382, 'auc': 0.93511, 'accuracy-SBM': 0.84455}
2025-07-05 11:01:10,933 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:01:11,423 - INFO - test: {'epoch': 78, 'time_epoch': 3.81301, 'loss': 0.10078498, 'lr': 0, 'params': 345143, 'time_iter': 0.06052, 'accuracy': 0.89203, 'precision': 0.66683, 'recall': 0.77404, 'f1': 0.71644, 'auc': 0.93604, 'accuracy-SBM': 0.84565}
2025-07-05 11:01:11,425 - INFO - > Epoch 78: took 50.6s (avg 50.6s) | Best so far: epoch 77	train_loss: 0.0896 train_accuracy-SBM: 0.8655	val_loss: 0.0909 val_accuracy-SBM: 0.8635	test_loss: 0.0898 test_accuracy-SBM: 0.8651
2025-07-05 11:01:11,425 - INFO - === Epoch 79 ===
2025-07-05 11:01:50,934 - INFO - train: {'epoch': 79, 'time_epoch': 36.32278, 'eta': 740.64692, 'eta_hours': 0.20574, 'loss': 0.0896044, 'lr': 5.79e-05, 'params': 345143, 'time_iter': 0.11605, 'accuracy': 0.86353, 'precision': 0.57513, 'recall': 0.86835, 'f1': 0.69196, 'auc': 0.94145, 'accuracy-SBM': 0.86542}
2025-07-05 11:01:55,228 - INFO - val: {'epoch': 79, 'time_epoch': 3.78622, 'loss': 0.13918643, 'lr': 0, 'params': 345143, 'time_iter': 0.0601, 'accuracy': 0.89344, 'precision': 0.72455, 'recall': 0.64219, 'f1': 0.68089, 'auc': 0.92052, 'accuracy-SBM': 0.79484}
2025-07-05 11:02:01,215 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:02:01,674 - INFO - test: {'epoch': 79, 'time_epoch': 3.79614, 'loss': 0.13897044, 'lr': 0, 'params': 345143, 'time_iter': 0.06026, 'accuracy': 0.8947, 'precision': 0.72777, 'recall': 0.643, 'f1': 0.68276, 'auc': 0.92123, 'accuracy-SBM': 0.79577}
2025-07-05 11:02:01,676 - INFO - > Epoch 79: took 50.3s (avg 50.6s) | Best so far: epoch 77	train_loss: 0.0896 train_accuracy-SBM: 0.8655	val_loss: 0.0909 val_accuracy-SBM: 0.8635	test_loss: 0.0898 test_accuracy-SBM: 0.8651
2025-07-05 11:02:01,676 - INFO - === Epoch 80 ===
2025-07-05 11:02:40,458 - INFO - train: {'epoch': 80, 'time_epoch': 36.0293, 'eta': 703.37929, 'eta_hours': 0.19538, 'loss': 0.08963876, 'lr': 5.271e-05, 'params': 345143, 'time_iter': 0.11511, 'accuracy': 0.86304, 'precision': 0.57406, 'recall': 0.86849, 'f1': 0.69123, 'auc': 0.94139, 'accuracy-SBM': 0.86518}
2025-07-05 11:02:44,580 - INFO - val: {'epoch': 80, 'time_epoch': 3.6255, 'loss': 0.09149829, 'lr': 0, 'params': 345143, 'time_iter': 0.05755, 'accuracy': 0.84631, 'precision': 0.5402, 'recall': 0.88554, 'f1': 0.67105, 'auc': 0.93971, 'accuracy-SBM': 0.86171}
2025-07-05 11:02:50,650 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:02:51,149 - INFO - test: {'epoch': 80, 'time_epoch': 3.66346, 'loss': 0.09038561, 'lr': 0, 'params': 345143, 'time_iter': 0.05815, 'accuracy': 0.84907, 'precision': 0.5441, 'recall': 0.8853, 'f1': 0.67398, 'auc': 0.94055, 'accuracy-SBM': 0.86331}
2025-07-05 11:02:51,152 - INFO - > Epoch 80: took 49.5s (avg 50.6s) | Best so far: epoch 77	train_loss: 0.0896 train_accuracy-SBM: 0.8655	val_loss: 0.0909 val_accuracy-SBM: 0.8635	test_loss: 0.0898 test_accuracy-SBM: 0.8651
2025-07-05 11:02:51,152 - INFO - === Epoch 81 ===
2025-07-05 11:03:31,597 - INFO - train: {'epoch': 81, 'time_epoch': 37.41156, 'eta': 666.44529, 'eta_hours': 0.18512, 'loss': 0.08966858, 'lr': 4.775e-05, 'params': 345143, 'time_iter': 0.11953, 'accuracy': 0.86304, 'precision': 0.57408, 'recall': 0.8683, 'f1': 0.69118, 'auc': 0.94133, 'accuracy-SBM': 0.86511}
2025-07-05 11:03:35,778 - INFO - val: {'epoch': 81, 'time_epoch': 3.68108, 'loss': 0.09259546, 'lr': 0, 'params': 345143, 'time_iter': 0.05843, 'accuracy': 0.8373, 'precision': 0.52378, 'recall': 0.89119, 'f1': 0.65978, 'auc': 0.93857, 'accuracy-SBM': 0.85845}
2025-07-05 11:03:42,069 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:03:42,550 - INFO - test: {'epoch': 81, 'time_epoch': 3.84828, 'loss': 0.09150341, 'lr': 0, 'params': 345143, 'time_iter': 0.06108, 'accuracy': 0.83963, 'precision': 0.52655, 'recall': 0.89178, 'f1': 0.66214, 'auc': 0.93933, 'accuracy-SBM': 0.86013}
2025-07-05 11:03:42,552 - INFO - > Epoch 81: took 51.4s (avg 50.6s) | Best so far: epoch 77	train_loss: 0.0896 train_accuracy-SBM: 0.8655	val_loss: 0.0909 val_accuracy-SBM: 0.8635	test_loss: 0.0898 test_accuracy-SBM: 0.8651
2025-07-05 11:03:42,552 - INFO - === Epoch 82 ===
2025-07-05 11:04:21,661 - INFO - train: {'epoch': 82, 'time_epoch': 36.08035, 'eta': 629.22712, 'eta_hours': 0.17479, 'loss': 0.08961907, 'lr': 4.3e-05, 'params': 345143, 'time_iter': 0.11527, 'accuracy': 0.86306, 'precision': 0.57422, 'recall': 0.86743, 'f1': 0.69101, 'auc': 0.94142, 'accuracy-SBM': 0.86478}
2025-07-05 11:04:25,896 - INFO - val: {'epoch': 82, 'time_epoch': 3.76222, 'loss': 0.12184871, 'lr': 0, 'params': 345143, 'time_iter': 0.05972, 'accuracy': 0.89604, 'precision': 0.71143, 'recall': 0.69438, 'f1': 0.7028, 'auc': 0.92829, 'accuracy-SBM': 0.8169}
2025-07-05 11:04:31,799 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:04:32,259 - INFO - test: {'epoch': 82, 'time_epoch': 3.89823, 'loss': 0.12125111, 'lr': 0, 'params': 345143, 'time_iter': 0.06188, 'accuracy': 0.89729, 'precision': 0.71448, 'recall': 0.69485, 'f1': 0.70453, 'auc': 0.92925, 'accuracy-SBM': 0.81773}
2025-07-05 11:04:32,261 - INFO - > Epoch 82: took 49.7s (avg 50.6s) | Best so far: epoch 77	train_loss: 0.0896 train_accuracy-SBM: 0.8655	val_loss: 0.0909 val_accuracy-SBM: 0.8635	test_loss: 0.0898 test_accuracy-SBM: 0.8651
2025-07-05 11:04:32,261 - INFO - === Epoch 83 ===
2025-07-05 11:05:11,866 - INFO - train: {'epoch': 83, 'time_epoch': 36.39611, 'eta': 592.09619, 'eta_hours': 0.16447, 'loss': 0.08960642, 'lr': 3.848e-05, 'params': 345143, 'time_iter': 0.11628, 'accuracy': 0.86276, 'precision': 0.57348, 'recall': 0.86833, 'f1': 0.69076, 'auc': 0.94143, 'accuracy-SBM': 0.86495}
2025-07-05 11:05:16,167 - INFO - val: {'epoch': 83, 'time_epoch': 3.80399, 'loss': 0.09049939, 'lr': 0, 'params': 345143, 'time_iter': 0.06038, 'accuracy': 0.86014, 'precision': 0.56826, 'recall': 0.8738, 'f1': 0.68866, 'auc': 0.94122, 'accuracy-SBM': 0.8655}
2025-07-05 11:05:22,205 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:05:22,705 - INFO - test: {'epoch': 83, 'time_epoch': 3.6148, 'loss': 0.089356, 'lr': 0, 'params': 345143, 'time_iter': 0.05738, 'accuracy': 0.86282, 'precision': 0.57261, 'recall': 0.87358, 'f1': 0.69178, 'auc': 0.94211, 'accuracy-SBM': 0.86705}
2025-07-05 11:05:22,707 - INFO - > Epoch 83: took 50.4s (avg 50.6s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:05:22,708 - INFO - === Epoch 84 ===
2025-07-05 11:06:01,116 - INFO - train: {'epoch': 84, 'time_epoch': 35.78191, 'eta': 554.87416, 'eta_hours': 0.15413, 'loss': 0.08958575, 'lr': 3.419e-05, 'params': 345143, 'time_iter': 0.11432, 'accuracy': 0.86362, 'precision': 0.57529, 'recall': 0.86874, 'f1': 0.6922, 'auc': 0.94146, 'accuracy-SBM': 0.86563}
2025-07-05 11:06:05,190 - INFO - val: {'epoch': 84, 'time_epoch': 3.5935, 'loss': 0.09107864, 'lr': 0, 'params': 345143, 'time_iter': 0.05704, 'accuracy': 0.85347, 'precision': 0.55439, 'recall': 0.8777, 'f1': 0.67955, 'auc': 0.94009, 'accuracy-SBM': 0.86298}
2025-07-05 11:06:11,256 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:06:11,754 - INFO - test: {'epoch': 84, 'time_epoch': 3.6195, 'loss': 0.089984, 'lr': 0, 'params': 345143, 'time_iter': 0.05745, 'accuracy': 0.85595, 'precision': 0.55796, 'recall': 0.87859, 'f1': 0.68249, 'auc': 0.94092, 'accuracy-SBM': 0.86484}
2025-07-05 11:06:11,756 - INFO - > Epoch 84: took 49.0s (avg 50.6s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:06:11,756 - INFO - === Epoch 85 ===
2025-07-05 11:06:49,317 - INFO - train: {'epoch': 85, 'time_epoch': 37.02118, 'eta': 517.88736, 'eta_hours': 0.14386, 'loss': 0.08963673, 'lr': 3.013e-05, 'params': 345143, 'time_iter': 0.11828, 'accuracy': 0.86314, 'precision': 0.57432, 'recall': 0.86814, 'f1': 0.69131, 'auc': 0.94139, 'accuracy-SBM': 0.86511}
2025-07-05 11:06:53,468 - INFO - val: {'epoch': 85, 'time_epoch': 3.68153, 'loss': 0.09979577, 'lr': 0, 'params': 345143, 'time_iter': 0.05844, 'accuracy': 0.88109, 'precision': 0.63017, 'recall': 0.79469, 'f1': 0.70293, 'auc': 0.93295, 'accuracy-SBM': 0.84718}
2025-07-05 11:07:00,936 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:07:01,445 - INFO - test: {'epoch': 85, 'time_epoch': 3.93993, 'loss': 0.09901684, 'lr': 0, 'params': 345143, 'time_iter': 0.06254, 'accuracy': 0.88275, 'precision': 0.63348, 'recall': 0.79407, 'f1': 0.70474, 'auc': 0.93378, 'accuracy-SBM': 0.84789}
2025-07-05 11:07:01,448 - INFO - > Epoch 85: took 49.7s (avg 50.6s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:07:01,448 - INFO - === Epoch 86 ===
2025-07-05 11:07:39,696 - INFO - train: {'epoch': 86, 'time_epoch': 36.46477, 'eta': 480.81663, 'eta_hours': 0.13356, 'loss': 0.08953247, 'lr': 2.632e-05, 'params': 345143, 'time_iter': 0.1165, 'accuracy': 0.86343, 'precision': 0.57489, 'recall': 0.86852, 'f1': 0.69184, 'auc': 0.94152, 'accuracy-SBM': 0.86543}
2025-07-05 11:07:44,025 - INFO - val: {'epoch': 86, 'time_epoch': 3.83689, 'loss': 0.0926961, 'lr': 0, 'params': 345143, 'time_iter': 0.0609, 'accuracy': 0.87684, 'precision': 0.6114, 'recall': 0.83499, 'f1': 0.70592, 'auc': 0.93932, 'accuracy-SBM': 0.86042}
2025-07-05 11:07:50,508 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:07:50,986 - INFO - test: {'epoch': 86, 'time_epoch': 3.95514, 'loss': 0.09168776, 'lr': 0, 'params': 345143, 'time_iter': 0.06278, 'accuracy': 0.8789, 'precision': 0.61508, 'recall': 0.83595, 'f1': 0.70871, 'auc': 0.94022, 'accuracy-SBM': 0.86202}
2025-07-05 11:07:50,988 - INFO - > Epoch 86: took 49.5s (avg 50.6s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:07:50,989 - INFO - === Epoch 87 ===
2025-07-05 11:08:30,330 - INFO - train: {'epoch': 87, 'time_epoch': 37.22594, 'eta': 443.86347, 'eta_hours': 0.1233, 'loss': 0.08956051, 'lr': 2.275e-05, 'params': 345143, 'time_iter': 0.11893, 'accuracy': 0.86331, 'precision': 0.5747, 'recall': 0.86805, 'f1': 0.69155, 'auc': 0.94143, 'accuracy-SBM': 0.86518}
2025-07-05 11:08:34,622 - INFO - val: {'epoch': 87, 'time_epoch': 3.8154, 'loss': 0.0928024, 'lr': 0, 'params': 345143, 'time_iter': 0.06056, 'accuracy': 0.87257, 'precision': 0.60005, 'recall': 0.84011, 'f1': 0.70007, 'auc': 0.93812, 'accuracy-SBM': 0.85983}
2025-07-05 11:08:40,804 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:08:41,284 - INFO - test: {'epoch': 87, 'time_epoch': 3.62136, 'loss': 0.09182511, 'lr': 0, 'params': 345143, 'time_iter': 0.05748, 'accuracy': 0.87503, 'precision': 0.60462, 'recall': 0.84033, 'f1': 0.70325, 'auc': 0.93895, 'accuracy-SBM': 0.86139}
2025-07-05 11:08:41,286 - INFO - > Epoch 87: took 50.3s (avg 50.5s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:08:41,286 - INFO - === Epoch 88 ===
2025-07-05 11:09:20,155 - INFO - train: {'epoch': 88, 'time_epoch': 36.01641, 'eta': 406.75469, 'eta_hours': 0.11299, 'loss': 0.08957086, 'lr': 1.943e-05, 'params': 345143, 'time_iter': 0.11507, 'accuracy': 0.86324, 'precision': 0.57454, 'recall': 0.86804, 'f1': 0.69143, 'auc': 0.94144, 'accuracy-SBM': 0.86513}
2025-07-05 11:09:24,337 - INFO - val: {'epoch': 88, 'time_epoch': 3.68565, 'loss': 0.10883486, 'lr': 0, 'params': 345143, 'time_iter': 0.0585, 'accuracy': 0.88615, 'precision': 0.65574, 'recall': 0.75129, 'f1': 0.70027, 'auc': 0.92813, 'accuracy-SBM': 0.83322}
2025-07-05 11:09:31,394 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:09:31,876 - INFO - test: {'epoch': 88, 'time_epoch': 3.74973, 'loss': 0.10826605, 'lr': 0, 'params': 345143, 'time_iter': 0.05952, 'accuracy': 0.88787, 'precision': 0.65983, 'recall': 0.75076, 'f1': 0.70237, 'auc': 0.92888, 'accuracy-SBM': 0.83398}
2025-07-05 11:09:31,878 - INFO - > Epoch 88: took 50.6s (avg 50.5s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:09:31,878 - INFO - === Epoch 89 ===
2025-07-05 11:10:10,902 - INFO - train: {'epoch': 89, 'time_epoch': 35.95031, 'eta': 369.66283, 'eta_hours': 0.10268, 'loss': 0.0895297, 'lr': 1.636e-05, 'params': 345143, 'time_iter': 0.11486, 'accuracy': 0.86329, 'precision': 0.57458, 'recall': 0.86873, 'f1': 0.69168, 'auc': 0.94154, 'accuracy-SBM': 0.86543}
2025-07-05 11:10:15,189 - INFO - val: {'epoch': 89, 'time_epoch': 3.78598, 'loss': 0.0908758, 'lr': 0, 'params': 345143, 'time_iter': 0.06009, 'accuracy': 0.85183, 'precision': 0.55095, 'recall': 0.88125, 'f1': 0.67801, 'auc': 0.94027, 'accuracy-SBM': 0.86338}
2025-07-05 11:10:21,992 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:10:22,496 - INFO - test: {'epoch': 89, 'time_epoch': 3.61404, 'loss': 0.08976691, 'lr': 0, 'params': 345143, 'time_iter': 0.05737, 'accuracy': 0.8542, 'precision': 0.55433, 'recall': 0.88073, 'f1': 0.68041, 'auc': 0.9411, 'accuracy-SBM': 0.86463}
2025-07-05 11:10:22,498 - INFO - > Epoch 89: took 50.6s (avg 50.6s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:10:22,498 - INFO - === Epoch 90 ===
2025-07-05 11:11:00,255 - INFO - train: {'epoch': 90, 'time_epoch': 35.94839, 'eta': 332.59588, 'eta_hours': 0.09239, 'loss': 0.08952969, 'lr': 1.355e-05, 'params': 345143, 'time_iter': 0.11485, 'accuracy': 0.86319, 'precision': 0.57444, 'recall': 0.86789, 'f1': 0.69131, 'auc': 0.94152, 'accuracy-SBM': 0.86504}
2025-07-05 11:11:04,542 - INFO - val: {'epoch': 90, 'time_epoch': 3.78871, 'loss': 0.09209187, 'lr': 0, 'params': 345143, 'time_iter': 0.06014, 'accuracy': 0.87417, 'precision': 0.60346, 'recall': 0.84333, 'f1': 0.70351, 'auc': 0.93978, 'accuracy-SBM': 0.86206}
2025-07-05 11:11:15,086 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:11:15,578 - INFO - test: {'epoch': 90, 'time_epoch': 3.58705, 'loss': 0.09104515, 'lr': 0, 'params': 345143, 'time_iter': 0.05694, 'accuracy': 0.8763, 'precision': 0.60722, 'recall': 0.84388, 'f1': 0.70625, 'auc': 0.94068, 'accuracy-SBM': 0.86356}
2025-07-05 11:11:15,580 - INFO - > Epoch 90: took 53.1s (avg 50.6s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:11:15,581 - INFO - === Epoch 91 ===
2025-07-05 11:11:52,108 - INFO - train: {'epoch': 91, 'time_epoch': 36.09652, 'eta': 295.56612, 'eta_hours': 0.0821, 'loss': 0.08948012, 'lr': 1.099e-05, 'params': 345143, 'time_iter': 0.11532, 'accuracy': 0.86315, 'precision': 0.57428, 'recall': 0.86865, 'f1': 0.69144, 'auc': 0.94161, 'accuracy-SBM': 0.86531}
2025-07-05 11:11:56,181 - INFO - val: {'epoch': 91, 'time_epoch': 3.57437, 'loss': 0.09198736, 'lr': 0, 'params': 345143, 'time_iter': 0.05674, 'accuracy': 0.87377, 'precision': 0.60243, 'recall': 0.84376, 'f1': 0.70296, 'auc': 0.93958, 'accuracy-SBM': 0.86199}
2025-07-05 11:12:03,070 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:12:03,564 - INFO - test: {'epoch': 91, 'time_epoch': 3.6841, 'loss': 0.09094601, 'lr': 0, 'params': 345143, 'time_iter': 0.05848, 'accuracy': 0.87597, 'precision': 0.60629, 'recall': 0.84466, 'f1': 0.7059, 'auc': 0.94048, 'accuracy-SBM': 0.86367}
2025-07-05 11:12:03,669 - INFO - > Epoch 91: took 48.1s (avg 50.6s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:12:03,669 - INFO - === Epoch 92 ===
2025-07-05 11:12:39,771 - INFO - train: {'epoch': 92, 'time_epoch': 35.63708, 'eta': 258.52185, 'eta_hours': 0.07181, 'loss': 0.0895063, 'lr': 8.7e-06, 'params': 345143, 'time_iter': 0.11386, 'accuracy': 0.86343, 'precision': 0.5749, 'recall': 0.86842, 'f1': 0.69182, 'auc': 0.94157, 'accuracy-SBM': 0.86539}
2025-07-05 11:12:43,809 - INFO - val: {'epoch': 92, 'time_epoch': 3.56492, 'loss': 0.09964311, 'lr': 0, 'params': 345143, 'time_iter': 0.05659, 'accuracy': 0.88368, 'precision': 0.63812, 'recall': 0.79212, 'f1': 0.70683, 'auc': 0.93416, 'accuracy-SBM': 0.84774}
2025-07-05 11:12:49,850 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:12:50,357 - INFO - test: {'epoch': 92, 'time_epoch': 3.77618, 'loss': 0.0988908, 'lr': 0, 'params': 345143, 'time_iter': 0.05994, 'accuracy': 0.88528, 'precision': 0.64137, 'recall': 0.79162, 'f1': 0.70862, 'auc': 0.93498, 'accuracy-SBM': 0.84846}
2025-07-05 11:12:50,360 - INFO - > Epoch 92: took 46.7s (avg 50.5s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:12:50,360 - INFO - === Epoch 93 ===
2025-07-05 11:13:29,359 - INFO - train: {'epoch': 93, 'time_epoch': 35.7515, 'eta': 221.51483, 'eta_hours': 0.06153, 'loss': 0.08953439, 'lr': 6.67e-06, 'params': 345143, 'time_iter': 0.11422, 'accuracy': 0.86341, 'precision': 0.57486, 'recall': 0.8685, 'f1': 0.69181, 'auc': 0.94152, 'accuracy-SBM': 0.86541}
2025-07-05 11:13:33,609 - INFO - val: {'epoch': 93, 'time_epoch': 3.77902, 'loss': 0.09524968, 'lr': 0, 'params': 345143, 'time_iter': 0.05998, 'accuracy': 0.87782, 'precision': 0.61637, 'recall': 0.82051, 'f1': 0.70394, 'auc': 0.93648, 'accuracy-SBM': 0.85533}
2025-07-05 11:13:40,365 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:13:40,843 - INFO - test: {'epoch': 93, 'time_epoch': 3.58637, 'loss': 0.09434575, 'lr': 0, 'params': 345143, 'time_iter': 0.05693, 'accuracy': 0.87993, 'precision': 0.62047, 'recall': 0.82058, 'f1': 0.70663, 'auc': 0.93734, 'accuracy-SBM': 0.85661}
2025-07-05 11:13:40,845 - INFO - > Epoch 93: took 50.5s (avg 50.5s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:13:40,845 - INFO - === Epoch 94 ===
2025-07-05 11:14:20,439 - INFO - train: {'epoch': 94, 'time_epoch': 36.03583, 'eta': 184.5492, 'eta_hours': 0.05126, 'loss': 0.0895453, 'lr': 4.91e-06, 'params': 345143, 'time_iter': 0.11513, 'accuracy': 0.863, 'precision': 0.57394, 'recall': 0.8688, 'f1': 0.69124, 'auc': 0.94145, 'accuracy-SBM': 0.86528}
2025-07-05 11:14:24,587 - INFO - val: {'epoch': 94, 'time_epoch': 3.67248, 'loss': 0.09326393, 'lr': 0, 'params': 345143, 'time_iter': 0.05829, 'accuracy': 0.87382, 'precision': 0.60368, 'recall': 0.83604, 'f1': 0.70111, 'auc': 0.93796, 'accuracy-SBM': 0.85899}
2025-07-05 11:14:30,900 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:14:31,397 - INFO - test: {'epoch': 94, 'time_epoch': 3.63839, 'loss': 0.09228026, 'lr': 0, 'params': 345143, 'time_iter': 0.05775, 'accuracy': 0.87623, 'precision': 0.60819, 'recall': 0.83659, 'f1': 0.70434, 'auc': 0.93883, 'accuracy-SBM': 0.86065}
2025-07-05 11:14:31,645 - INFO - > Epoch 94: took 50.8s (avg 50.5s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:14:31,645 - INFO - === Epoch 95 ===
2025-07-05 11:15:10,795 - INFO - train: {'epoch': 95, 'time_epoch': 36.23147, 'eta': 147.6111, 'eta_hours': 0.041, 'loss': 0.08950603, 'lr': 3.41e-06, 'params': 345143, 'time_iter': 0.11576, 'accuracy': 0.86332, 'precision': 0.57468, 'recall': 0.86835, 'f1': 0.69163, 'auc': 0.94155, 'accuracy-SBM': 0.8653}
2025-07-05 11:15:14,888 - INFO - val: {'epoch': 95, 'time_epoch': 3.61188, 'loss': 0.09445059, 'lr': 0, 'params': 345143, 'time_iter': 0.05733, 'accuracy': 0.87495, 'precision': 0.60761, 'recall': 0.82889, 'f1': 0.70121, 'auc': 0.93687, 'accuracy-SBM': 0.85688}
2025-07-05 11:15:20,877 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:15:21,386 - INFO - test: {'epoch': 95, 'time_epoch': 3.66495, 'loss': 0.09353791, 'lr': 0, 'params': 345143, 'time_iter': 0.05817, 'accuracy': 0.87711, 'precision': 0.61171, 'recall': 0.82854, 'f1': 0.7038, 'auc': 0.93771, 'accuracy-SBM': 0.85802}
2025-07-05 11:15:21,388 - INFO - > Epoch 95: took 49.7s (avg 50.5s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:15:21,389 - INFO - === Epoch 96 ===
2025-07-05 11:15:59,959 - INFO - train: {'epoch': 96, 'time_epoch': 35.60224, 'eta': 110.6681, 'eta_hours': 0.03074, 'loss': 0.0894666, 'lr': 2.18e-06, 'params': 345143, 'time_iter': 0.11375, 'accuracy': 0.86338, 'precision': 0.5748, 'recall': 0.86848, 'f1': 0.69177, 'auc': 0.94159, 'accuracy-SBM': 0.86539}
2025-07-05 11:16:04,086 - INFO - val: {'epoch': 96, 'time_epoch': 3.634, 'loss': 0.09749699, 'lr': 0, 'params': 345143, 'time_iter': 0.05768, 'accuracy': 0.87941, 'precision': 0.62271, 'recall': 0.80881, 'f1': 0.70367, 'auc': 0.93466, 'accuracy-SBM': 0.8517}
2025-07-05 11:16:10,412 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:16:10,860 - INFO - test: {'epoch': 96, 'time_epoch': 3.81665, 'loss': 0.09669956, 'lr': 0, 'params': 345143, 'time_iter': 0.06058, 'accuracy': 0.88138, 'precision': 0.62681, 'recall': 0.80786, 'f1': 0.70591, 'auc': 0.93546, 'accuracy-SBM': 0.85248}
2025-07-05 11:16:10,862 - INFO - > Epoch 96: took 49.5s (avg 50.5s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:16:10,862 - INFO - === Epoch 97 ===
2025-07-05 11:16:50,181 - INFO - train: {'epoch': 97, 'time_epoch': 35.88193, 'eta': 73.75817, 'eta_hours': 0.02049, 'loss': 0.08952888, 'lr': 1.23e-06, 'params': 345143, 'time_iter': 0.11464, 'accuracy': 0.86314, 'precision': 0.57431, 'recall': 0.8682, 'f1': 0.69132, 'auc': 0.9415, 'accuracy-SBM': 0.86513}
2025-07-05 11:16:54,279 - INFO - val: {'epoch': 97, 'time_epoch': 3.62017, 'loss': 0.09196812, 'lr': 0, 'params': 345143, 'time_iter': 0.05746, 'accuracy': 0.87376, 'precision': 0.60238, 'recall': 0.8439, 'f1': 0.70297, 'auc': 0.93968, 'accuracy-SBM': 0.86204}
2025-07-05 11:17:00,277 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:17:00,745 - INFO - test: {'epoch': 97, 'time_epoch': 3.65814, 'loss': 0.09092219, 'lr': 0, 'params': 345143, 'time_iter': 0.05807, 'accuracy': 0.87597, 'precision': 0.60631, 'recall': 0.84457, 'f1': 0.70587, 'auc': 0.94058, 'accuracy-SBM': 0.86363}
2025-07-05 11:17:00,747 - INFO - > Epoch 97: took 49.9s (avg 50.5s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:17:00,747 - INFO - === Epoch 98 ===
2025-07-05 11:17:40,280 - INFO - train: {'epoch': 98, 'time_epoch': 36.03679, 'eta': 36.87058, 'eta_hours': 0.01024, 'loss': 0.08948889, 'lr': 5.5e-07, 'params': 345143, 'time_iter': 0.11513, 'accuracy': 0.8633, 'precision': 0.57465, 'recall': 0.86825, 'f1': 0.69158, 'auc': 0.94157, 'accuracy-SBM': 0.86525}
2025-07-05 11:17:44,321 - INFO - val: {'epoch': 98, 'time_epoch': 3.5638, 'loss': 0.09474516, 'lr': 0, 'params': 345143, 'time_iter': 0.05657, 'accuracy': 0.87355, 'precision': 0.60401, 'recall': 0.82942, 'f1': 0.69899, 'auc': 0.93616, 'accuracy-SBM': 0.85623}
2025-07-05 11:17:50,302 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:17:50,802 - INFO - test: {'epoch': 98, 'time_epoch': 3.68112, 'loss': 0.09386126, 'lr': 0, 'params': 345143, 'time_iter': 0.05843, 'accuracy': 0.87577, 'precision': 0.60822, 'recall': 0.82901, 'f1': 0.70166, 'auc': 0.93696, 'accuracy-SBM': 0.85739}
2025-07-05 11:17:50,804 - INFO - > Epoch 98: took 50.1s (avg 50.5s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:17:50,805 - INFO - === Epoch 99 ===
2025-07-05 11:18:29,653 - INFO - train: {'epoch': 99, 'time_epoch': 36.19018, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.0894762, 'lr': 1.4e-07, 'params': 345143, 'time_iter': 0.11562, 'accuracy': 0.86356, 'precision': 0.57523, 'recall': 0.86797, 'f1': 0.69191, 'auc': 0.94159, 'accuracy-SBM': 0.86529}
2025-07-05 11:18:33,780 - INFO - val: {'epoch': 99, 'time_epoch': 3.64196, 'loss': 0.09858919, 'lr': 0, 'params': 345143, 'time_iter': 0.05781, 'accuracy': 0.87577, 'precision': 0.61319, 'recall': 0.80774, 'f1': 0.69715, 'auc': 0.93255, 'accuracy-SBM': 0.84907}
2025-07-05 11:18:39,748 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-47/test_results
2025-07-05 11:18:40,230 - INFO - test: {'epoch': 99, 'time_epoch': 3.72299, 'loss': 0.09792146, 'lr': 0, 'params': 345143, 'time_iter': 0.0591, 'accuracy': 0.87793, 'precision': 0.61754, 'recall': 0.80724, 'f1': 0.69976, 'auc': 0.93321, 'accuracy-SBM': 0.85015}
2025-07-05 11:18:40,345 - INFO - > Epoch 99: took 49.4s (avg 50.5s) | Best so far: epoch 83	train_loss: 0.0896 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8655	test_loss: 0.0894 test_accuracy-SBM: 0.8670
2025-07-05 11:18:40,345 - INFO - ================================================================================
2025-07-05 11:18:40,345 - INFO - NAS TRAINING COMPLETED SUCCESSFULLY
2025-07-05 11:18:40,345 - INFO - ================================================================================
2025-07-05 11:18:40,345 - INFO - Avg time per epoch: 50.47s
2025-07-05 11:18:40,345 - INFO - Total train loop time: 1.40h
2025-07-05 11:18:40,346 - INFO - Routing mode: nas
2025-07-05 11:18:40,346 - INFO - Final optimal weights: {'layer_0': 2, 'layer_1': 1, 'layer_2': 1, 'layer_3': 1, 'layer_4': 1, 'layer_5': 2}
2025-07-05 11:18:40,346 - INFO - Results include routing uncertainty (test only, NO variance)
2025-07-05 11:18:40,374 - INFO - Task done, results saved in results/pattern/pattern-SPARSE-47
2025-07-05 11:18:40,376 - INFO - Total time: 6147.64s (1.71h)
2025-07-05 11:18:40,430 - INFO - Results aggregated across runs saved in results/pattern/pattern-SPARSE-47/agg
2025-07-05 11:18:40,430 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-07-05 11:18:40,430 - INFO - Results saved in: results/pattern/pattern-SPARSE-47
2025-07-05 11:18:40,430 - INFO - Test results JSON files saved in: results/pattern/pattern-SPARSE-47/test_results/
Completed seed 47. Results saved in results/pattern/pattern-SPARSE-47
----------------------------------------
All experiments completed!
/var/spool/slurmd/job5334983/slurm_script: line 72: syntax error near unexpected token `"/data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/PATTERN"'
/var/spool/slurmd/job5334983/slurm_script: line 72: `os.chdir("/data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/PATTERN")'
