Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          376Gi        53Gi       269Gi       3.3Gi        52Gi       316Gi
Swap:         1.9Gi       5.0Mi       1.9Gi
Sat Aug 16 11:15:34 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-16GB           On  |   00000000:3B:00.0 Off |                    0 |
| N/A   40C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 49
Starting training for seed 49...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/PATTERN/FINAL_SINGLE/SPARSE_E
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/PATTERN/FINAL_SINGLE/SPARSE_E/confignas.yaml
Using device: cuda
2025-08-16 11:16:57,938 - INFO - GPU Mem: 17.1GB
2025-08-16 11:16:57,938 - INFO - Run directory: results/pattern/pattern-NASSPARSE-49
2025-08-16 11:16:57,938 - INFO - Seed: 49
2025-08-16 11:16:57,938 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-08-16 11:16:57,938 - INFO - Routing mode: nas
2025-08-16 11:16:57,938 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-16 11:16:57,938 - INFO - Number of layers: 6
2025-08-16 11:16:57,938 - INFO - Uncertainty enabled: False
2025-08-16 11:16:57,938 - INFO - Training mode: NoMixNas_uncertainty_train
2025-08-16 11:16:57,938 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-08-16 11:16:57,938 - INFO - Additional features: Router weights logging + JSON export
2025-08-16 11:17:16,665 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 11:17:16,680 - INFO -   Data(x=[1664491, 3], edge_index=[2, 85099952], y=[1664491])
2025-08-16 11:17:16,763 - INFO -   undirected: True
2025-08-16 11:17:16,764 - INFO -   num graphs: 14000
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-08-16 11:17:16,764 - INFO -   avg num_nodes/graph: 118
2025-08-16 11:17:16,764 - INFO -   num node features: 3
2025-08-16 11:17:16,764 - INFO -   num edge features: 0
2025-08-16 11:17:16,766 - INFO -   num classes: 2
2025-08-16 11:17:16,766 - INFO - Precomputing Positional Encoding statistics: ['LapPE'] for all graphs...
2025-08-16 11:17:16,776 - INFO -   ...estimated to be undirected: True

  0%|          | 0/14000 [00:00<?, ?it/s]
 25%|██▌       | 3556/14000 [00:10<00:29, 355.51it/s]
 52%|█████▏    | 7287/14000 [00:20<00:18, 365.79it/s]
 79%|███████▉  | 11113/14000 [00:30<00:07, 373.44it/s]
100%|██████████| 14000/14000 [00:37<00:00, 372.71it/s]
2025-08-16 11:17:55,273 - INFO - Done! Took 00:00:38.51
2025-08-16 11:17:55,298 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset'
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/nni/nas/nn/pytorch/choice.py:252: UserWarning: "key" is deprecated. Assuming label.
  warnings.warn(f'"key" is deprecated. Assuming label.')
2025-08-16 11:17:55,894 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-08-16 11:17:55,894 - INFO - Inner model type: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-08-16 11:17:55,894 - INFO - Inner model has get_darts_model: True
2025-08-16 11:17:55,897 - INFO - GraphGymModule(
  (model): NASModelEdge(
    (encoder): FeatureEncoder(
      (node_encoder): LapPENodeEncoder(
        (linear_x): Linear(in_features=3, out_features=48, bias=True)
        (linear_A): Linear(in_features=2, out_features=32, bias=True)
        (pe_encoder): Sequential(
          (0): ReLU()
          (1): Linear(in_features=32, out_features=16, bias=True)
          (2): ReLU()
        )
      )
      (edge_encoder): DummyEdgeEncoder(
        (encoder): Embedding(1, 64)
      )
    )
    (darts_layers): ModuleList(
      (0): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (darts_sequential): Sequential(
      (0): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(64, 1, bias=True)
          )
        )
      )
    )
  )
)
2025-08-16 11:17:55,901 - INFO - Number of parameters: 487,351
2025-08-16 11:17:55,902 - INFO - Starting optimized training: 2025-08-16 11:17:55.902068
2025-08-16 11:18:02,484 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset':
2025-08-16 11:18:02,484 - INFO -   Data(x=[1664491, 3], edge_index=[2, 85099952], y=[1664491])
2025-08-16 11:18:02,485 - INFO -   undirected: True
2025-08-16 11:18:02,485 - INFO -   num graphs: 14000
2025-08-16 11:18:02,485 - INFO -   avg num_nodes/graph: 118
2025-08-16 11:18:02,486 - INFO -   num node features: 3
2025-08-16 11:18:02,486 - INFO -   num edge features: 0
2025-08-16 11:18:02,487 - INFO -   num classes: 2
2025-08-16 11:18:02,487 - INFO - Precomputing Positional Encoding statistics: ['LapPE'] for all graphs...
2025-08-16 11:18:02,497 - INFO -   ...estimated to be undirected: True

  0%|          | 0/14000 [00:00<?, ?it/s]
 26%|██▋       | 3700/14000 [00:10<00:27, 369.90it/s]
 53%|█████▎    | 7355/14000 [00:20<00:18, 367.27it/s]
 78%|███████▊  | 10856/14000 [00:30<00:08, 359.39it/s]
100%|██████████| 14000/14000 [00:38<00:00, 360.79it/s]
2025-08-16 11:18:42,188 - INFO - Done! Took 00:00:39.70
2025-08-16 11:18:42,217 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset'
2025-08-16 11:18:42,220 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-08-16 11:18:42,220 - INFO - Start from epoch 0
2025-08-16 11:18:42,220 - INFO - ================================================================================
2025-08-16 11:18:42,220 - INFO - STARTING TWO-PHASE NAS TRAINING
2025-08-16 11:18:42,220 - INFO - ================================================================================
2025-08-16 11:18:42,220 - INFO - Routing mode: nas
2025-08-16 11:18:42,220 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-08-16 11:18:42,220 - INFO - Phase 1: Architecture search/initialization
2025-08-16 11:18:42,221 - INFO - Phase 2: Discrete training with uncertainty (NO variance)
2025-08-16 11:18:42,221 - INFO - ============================================================
2025-08-16 11:18:42,221 - INFO - PHASE 1: ARCHITECTURE SEARCH/INITIALIZATION
2025-08-16 11:18:42,221 - INFO - ============================================================
2025-08-16 11:18:42,221 - INFO - Splitting dataset for DARTS:
2025-08-16 11:18:42,221 - INFO -   Original train size: 10000
2025-08-16 11:18:42,221 - INFO -   DARTS train size: 6000 (60.0%)
2025-08-16 11:18:42,221 - INFO -   DARTS val size: 4000 (40.0%)
2025-08-16 11:18:42,222 - INFO - Found GraphGym wrapper, using inner model: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-08-16 11:18:42,222 - INFO - Successfully configured model for DARTS training
2025-08-16 11:18:42,222 - INFO - NAS MODE: Running 20 epochs with DARTS
2025-08-16 11:18:42,222 - INFO - DARTS Configuration:
2025-08-16 11:18:42,222 - INFO -   Epochs: 20
2025-08-16 11:18:42,222 - INFO -   Architecture LR: 0.0004
2025-08-16 11:18:42,222 - INFO -   Grad clip: 5.0
2025-08-16 11:18:42,223 - INFO - Starting DARTS architecture search
2025-08-16 11:18:45,560 - WARNING - Epoch [1/20] Step [1/125]  acc 0.826566 (0.826566)  loss 0.667149 (0.667149)
GPU memory consumption  GPU Memory: Allocated: 130.0 MB, Reserved: 7596.0 MB
2025-08-16 11:18:51,114 - WARNING - Epoch [1/20] Step [11/125]  acc 0.815891 (0.823003)  loss 0.546138 (0.588888)
GPU memory consumption  GPU Memory: Allocated: 131.4 MB, Reserved: 9444.0 MB
2025-08-16 11:18:56,683 - WARNING - Epoch [1/20] Step [21/125]  acc 0.887224 (0.848684)  loss 0.497961 (0.555982)
GPU memory consumption  GPU Memory: Allocated: 123.4 MB, Reserved: 9498.0 MB
2025-08-16 11:19:02,229 - WARNING - Epoch [1/20] Step [31/125]  acc 0.887534 (0.861446)  loss 0.465701 (0.530740)
GPU memory consumption  GPU Memory: Allocated: 120.4 MB, Reserved: 9498.0 MB
2025-08-16 11:19:07,695 - WARNING - Epoch [1/20] Step [41/125]  acc 0.899699 (0.869201)  loss 0.423584 (0.509344)
GPU memory consumption  GPU Memory: Allocated: 117.3 MB, Reserved: 9498.0 MB
2025-08-16 11:19:13,488 - WARNING - Epoch [1/20] Step [51/125]  acc 0.879050 (0.873482)  loss 0.418134 (0.491850)
GPU memory consumption  GPU Memory: Allocated: 121.3 MB, Reserved: 9498.0 MB
2025-08-16 11:19:18,950 - WARNING - Epoch [1/20] Step [61/125]  acc 0.900611 (0.876819)  loss 0.381453 (0.476235)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 9498.0 MB
2025-08-16 11:19:24,473 - WARNING - Epoch [1/20] Step [71/125]  acc 0.896314 (0.879919)  loss 0.367872 (0.461982)
GPU memory consumption  GPU Memory: Allocated: 125.3 MB, Reserved: 11860.0 MB
2025-08-16 11:19:30,061 - WARNING - Epoch [1/20] Step [81/125]  acc 0.891487 (0.882037)  loss 0.362118 (0.449542)
GPU memory consumption  GPU Memory: Allocated: 129.0 MB, Reserved: 11860.0 MB
2025-08-16 11:19:35,534 - WARNING - Epoch [1/20] Step [91/125]  acc 0.904393 (0.883611)  loss 0.332539 (0.438678)
GPU memory consumption  GPU Memory: Allocated: 130.7 MB, Reserved: 14064.0 MB
2025-08-16 11:19:41,035 - WARNING - Epoch [1/20] Step [101/125]  acc 0.904515 (0.884517)  loss 0.321542 (0.429322)
GPU memory consumption  GPU Memory: Allocated: 132.2 MB, Reserved: 14064.0 MB
2025-08-16 11:19:46,490 - WARNING - Epoch [1/20] Step [111/125]  acc 0.899431 (0.885434)  loss 0.319025 (0.420520)
GPU memory consumption  GPU Memory: Allocated: 125.1 MB, Reserved: 14064.0 MB
2025-08-16 11:19:51,943 - WARNING - Epoch [1/20] Step [121/125]  acc 0.891754 (0.886319)  loss 0.322004 (0.412342)
GPU memory consumption  GPU Memory: Allocated: 124.2 MB, Reserved: 14064.0 MB
Epoch 1 completed in 0:01:11.930041
2025-08-16 11:20:09,327 - WARNING - Epoch [2/20] Step [1/125]  acc 0.886345 (0.886345)  loss 0.320229 (0.320229)
GPU memory consumption  GPU Memory: Allocated: 123.0 MB, Reserved: 14064.0 MB
2025-08-16 11:20:14,783 - WARNING - Epoch [2/20] Step [11/125]  acc 0.899575 (0.897987)  loss 0.301019 (0.308735)
GPU memory consumption  GPU Memory: Allocated: 127.7 MB, Reserved: 14066.0 MB
2025-08-16 11:20:20,322 - WARNING - Epoch [2/20] Step [21/125]  acc 0.898131 (0.897125)  loss 0.298184 (0.306417)
GPU memory consumption  GPU Memory: Allocated: 129.2 MB, Reserved: 14066.0 MB
2025-08-16 11:20:25,778 - WARNING - Epoch [2/20] Step [31/125]  acc 0.892487 (0.897119)  loss 0.309411 (0.303695)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 14066.0 MB
2025-08-16 11:20:31,293 - WARNING - Epoch [2/20] Step [41/125]  acc 0.903418 (0.897448)  loss 0.286030 (0.300790)
GPU memory consumption  GPU Memory: Allocated: 124.1 MB, Reserved: 14066.0 MB
2025-08-16 11:20:36,859 - WARNING - Epoch [2/20] Step [51/125]  acc 0.894483 (0.897400)  loss 0.285777 (0.298316)
GPU memory consumption  GPU Memory: Allocated: 127.1 MB, Reserved: 14066.0 MB
2025-08-16 11:20:42,330 - WARNING - Epoch [2/20] Step [61/125]  acc 0.888530 (0.896692)  loss 0.291398 (0.297443)
GPU memory consumption  GPU Memory: Allocated: 123.8 MB, Reserved: 14066.0 MB
2025-08-16 11:20:47,775 - WARNING - Epoch [2/20] Step [71/125]  acc 0.899296 (0.896345)  loss 0.269307 (0.295456)
GPU memory consumption  GPU Memory: Allocated: 123.7 MB, Reserved: 14066.0 MB
2025-08-16 11:20:53,326 - WARNING - Epoch [2/20] Step [81/125]  acc 0.903753 (0.896272)  loss 0.270087 (0.293572)
GPU memory consumption  GPU Memory: Allocated: 127.2 MB, Reserved: 14066.0 MB
2025-08-16 11:20:58,839 - WARNING - Epoch [2/20] Step [91/125]  acc 0.904739 (0.896594)  loss 0.260957 (0.291208)
GPU memory consumption  GPU Memory: Allocated: 136.5 MB, Reserved: 15686.0 MB
2025-08-16 11:21:04,388 - WARNING - Epoch [2/20] Step [101/125]  acc 0.902973 (0.896719)  loss 0.255178 (0.289323)
GPU memory consumption  GPU Memory: Allocated: 126.2 MB, Reserved: 15686.0 MB
2025-08-16 11:21:09,887 - WARNING - Epoch [2/20] Step [111/125]  acc 0.903596 (0.897299)  loss 0.252878 (0.286876)
GPU memory consumption  GPU Memory: Allocated: 128.7 MB, Reserved: 15686.0 MB
2025-08-16 11:21:15,341 - WARNING - Epoch [2/20] Step [121/125]  acc 0.904148 (0.897327)  loss 0.258693 (0.285459)
GPU memory consumption  GPU Memory: Allocated: 129.0 MB, Reserved: 15686.0 MB
Epoch 2 completed in 0:01:08.745324
2025-08-16 11:21:32,672 - WARNING - Epoch [3/20] Step [1/125]  acc 0.894293 (0.894293)  loss 0.278427 (0.278427)
GPU memory consumption  GPU Memory: Allocated: 122.4 MB, Reserved: 15686.0 MB
2025-08-16 11:21:38,202 - WARNING - Epoch [3/20] Step [11/125]  acc 0.921814 (0.900265)  loss 0.227213 (0.265453)
GPU memory consumption  GPU Memory: Allocated: 136.5 MB, Reserved: 15686.0 MB
2025-08-16 11:21:43,715 - WARNING - Epoch [3/20] Step [21/125]  acc 0.909640 (0.901300)  loss 0.237623 (0.262005)
GPU memory consumption  GPU Memory: Allocated: 130.1 MB, Reserved: 15686.0 MB
2025-08-16 11:21:49,150 - WARNING - Epoch [3/20] Step [31/125]  acc 0.896376 (0.899876)  loss 0.266859 (0.263185)
GPU memory consumption  GPU Memory: Allocated: 120.6 MB, Reserved: 15692.0 MB
2025-08-16 11:21:54,641 - WARNING - Epoch [3/20] Step [41/125]  acc 0.903349 (0.899528)  loss 0.250271 (0.262425)
GPU memory consumption  GPU Memory: Allocated: 126.1 MB, Reserved: 15692.0 MB
2025-08-16 11:22:00,117 - WARNING - Epoch [3/20] Step [51/125]  acc 0.897893 (0.899547)  loss 0.263457 (0.262441)
GPU memory consumption  GPU Memory: Allocated: 121.1 MB, Reserved: 15692.0 MB
2025-08-16 11:22:05,591 - WARNING - Epoch [3/20] Step [61/125]  acc 0.898103 (0.899887)  loss 0.265715 (0.261332)
GPU memory consumption  GPU Memory: Allocated: 123.4 MB, Reserved: 15692.0 MB
2025-08-16 11:22:11,141 - WARNING - Epoch [3/20] Step [71/125]  acc 0.896614 (0.900136)  loss 0.272234 (0.260464)
GPU memory consumption  GPU Memory: Allocated: 129.1 MB, Reserved: 15692.0 MB
2025-08-16 11:22:16,616 - WARNING - Epoch [3/20] Step [81/125]  acc 0.914745 (0.900265)  loss 0.240787 (0.259502)
GPU memory consumption  GPU Memory: Allocated: 125.4 MB, Reserved: 15692.0 MB
2025-08-16 11:22:22,241 - WARNING - Epoch [3/20] Step [91/125]  acc 0.897489 (0.900151)  loss 0.255397 (0.259055)
GPU memory consumption  GPU Memory: Allocated: 130.1 MB, Reserved: 15692.0 MB
2025-08-16 11:22:27,672 - WARNING - Epoch [3/20] Step [101/125]  acc 0.916788 (0.899718)  loss 0.228972 (0.259060)
GPU memory consumption  GPU Memory: Allocated: 132.8 MB, Reserved: 15692.0 MB
2025-08-16 11:22:33,183 - WARNING - Epoch [3/20] Step [111/125]  acc 0.904697 (0.899771)  loss 0.244582 (0.258628)
GPU memory consumption  GPU Memory: Allocated: 120.5 MB, Reserved: 15694.0 MB
2025-08-16 11:22:38,671 - WARNING - Epoch [3/20] Step [121/125]  acc 0.901343 (0.899887)  loss 0.255442 (0.258000)
GPU memory consumption  GPU Memory: Allocated: 129.0 MB, Reserved: 15694.0 MB
Epoch 3 completed in 0:01:08.714574
2025-08-16 11:22:56,042 - WARNING - Epoch [4/20] Step [1/125]  acc 0.894423 (0.894423)  loss 0.269768 (0.269768)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 15694.0 MB
2025-08-16 11:23:01,461 - WARNING - Epoch [4/20] Step [11/125]  acc 0.904724 (0.897887)  loss 0.249921 (0.257029)
GPU memory consumption  GPU Memory: Allocated: 128.2 MB, Reserved: 15694.0 MB
2025-08-16 11:23:06,912 - WARNING - Epoch [4/20] Step [21/125]  acc 0.894477 (0.899064)  loss 0.262740 (0.255368)
GPU memory consumption  GPU Memory: Allocated: 122.6 MB, Reserved: 15694.0 MB
2025-08-16 11:23:12,441 - WARNING - Epoch [4/20] Step [31/125]  acc 0.905313 (0.898960)  loss 0.241053 (0.254351)
GPU memory consumption  GPU Memory: Allocated: 121.9 MB, Reserved: 15694.0 MB
2025-08-16 11:23:17,844 - WARNING - Epoch [4/20] Step [41/125]  acc 0.899621 (0.898853)  loss 0.254399 (0.254598)
GPU memory consumption  GPU Memory: Allocated: 118.9 MB, Reserved: 15694.0 MB
2025-08-16 11:23:23,433 - WARNING - Epoch [4/20] Step [51/125]  acc 0.896976 (0.898948)  loss 0.255301 (0.254452)
GPU memory consumption  GPU Memory: Allocated: 127.1 MB, Reserved: 15694.0 MB
2025-08-16 11:23:29,401 - WARNING - Epoch [4/20] Step [61/125]  acc 0.904367 (0.899625)  loss 0.251145 (0.253380)
GPU memory consumption  GPU Memory: Allocated: 131.4 MB, Reserved: 4984.0 MB
2025-08-16 11:23:34,923 - WARNING - Epoch [4/20] Step [71/125]  acc 0.905369 (0.899848)  loss 0.249498 (0.252799)
GPU memory consumption  GPU Memory: Allocated: 125.4 MB, Reserved: 4990.0 MB
2025-08-16 11:23:40,416 - WARNING - Epoch [4/20] Step [81/125]  acc 0.895146 (0.899984)  loss 0.256790 (0.252153)
GPU memory consumption  GPU Memory: Allocated: 121.8 MB, Reserved: 4990.0 MB
2025-08-16 11:23:45,849 - WARNING - Epoch [4/20] Step [91/125]  acc 0.909684 (0.900049)  loss 0.226061 (0.251888)
GPU memory consumption  GPU Memory: Allocated: 130.2 MB, Reserved: 4990.0 MB
2025-08-16 11:23:51,325 - WARNING - Epoch [4/20] Step [101/125]  acc 0.909114 (0.900520)  loss 0.236128 (0.250781)
GPU memory consumption  GPU Memory: Allocated: 127.9 MB, Reserved: 4990.0 MB
2025-08-16 11:23:56,847 - WARNING - Epoch [4/20] Step [111/125]  acc 0.915109 (0.901024)  loss 0.214641 (0.249648)
GPU memory consumption  GPU Memory: Allocated: 128.8 MB, Reserved: 4990.0 MB
2025-08-16 11:24:02,221 - WARNING - Epoch [4/20] Step [121/125]  acc 0.905685 (0.901096)  loss 0.239326 (0.249355)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 4990.0 MB
Epoch 4 completed in 0:01:08.910975
2025-08-16 11:24:19,561 - WARNING - Epoch [5/20] Step [1/125]  acc 0.902470 (0.902470)  loss 0.244565 (0.244565)
GPU memory consumption  GPU Memory: Allocated: 126.2 MB, Reserved: 4990.0 MB
2025-08-16 11:24:25,065 - WARNING - Epoch [5/20] Step [11/125]  acc 0.900711 (0.899972)  loss 0.244434 (0.247387)
GPU memory consumption  GPU Memory: Allocated: 132.2 MB, Reserved: 4990.0 MB
2025-08-16 11:24:30,552 - WARNING - Epoch [5/20] Step [21/125]  acc 0.876972 (0.899508)  loss 0.289941 (0.248415)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 4990.0 MB
2025-08-16 11:24:36,026 - WARNING - Epoch [5/20] Step [31/125]  acc 0.886446 (0.899985)  loss 0.274502 (0.246875)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 4990.0 MB
2025-08-16 11:24:41,412 - WARNING - Epoch [5/20] Step [41/125]  acc 0.897823 (0.899471)  loss 0.245952 (0.248153)
GPU memory consumption  GPU Memory: Allocated: 124.1 MB, Reserved: 4990.0 MB
2025-08-16 11:24:46,980 - WARNING - Epoch [5/20] Step [51/125]  acc 0.905752 (0.900011)  loss 0.236443 (0.247748)
GPU memory consumption  GPU Memory: Allocated: 127.1 MB, Reserved: 4990.0 MB
2025-08-16 11:24:52,431 - WARNING - Epoch [5/20] Step [61/125]  acc 0.898764 (0.900264)  loss 0.258929 (0.247689)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 4990.0 MB
2025-08-16 11:24:57,869 - WARNING - Epoch [5/20] Step [71/125]  acc 0.898520 (0.900949)  loss 0.255156 (0.246413)
GPU memory consumption  GPU Memory: Allocated: 124.5 MB, Reserved: 4990.0 MB
2025-08-16 11:25:03,357 - WARNING - Epoch [5/20] Step [81/125]  acc 0.907525 (0.901046)  loss 0.227431 (0.246380)
GPU memory consumption  GPU Memory: Allocated: 122.8 MB, Reserved: 4990.0 MB
2025-08-16 11:25:08,711 - WARNING - Epoch [5/20] Step [91/125]  acc 0.901935 (0.900770)  loss 0.254318 (0.247096)
GPU memory consumption  GPU Memory: Allocated: 132.2 MB, Reserved: 4990.0 MB
2025-08-16 11:25:14,130 - WARNING - Epoch [5/20] Step [101/125]  acc 0.913113 (0.900763)  loss 0.230581 (0.246882)
GPU memory consumption  GPU Memory: Allocated: 123.4 MB, Reserved: 4990.0 MB
2025-08-16 11:25:19,593 - WARNING - Epoch [5/20] Step [111/125]  acc 0.895698 (0.900823)  loss 0.250227 (0.246467)
GPU memory consumption  GPU Memory: Allocated: 124.5 MB, Reserved: 4990.0 MB
2025-08-16 11:25:24,982 - WARNING - Epoch [5/20] Step [121/125]  acc 0.909625 (0.901287)  loss 0.230903 (0.245579)
GPU memory consumption  GPU Memory: Allocated: 129.1 MB, Reserved: 4990.0 MB
Epoch 5 completed in 0:01:08.221550
2025-08-16 11:25:42,374 - WARNING - Epoch [6/20] Step [1/125]  acc 0.903357 (0.903357)  loss 0.239235 (0.239235)
GPU memory consumption  GPU Memory: Allocated: 128.0 MB, Reserved: 4990.0 MB
2025-08-16 11:25:47,895 - WARNING - Epoch [6/20] Step [11/125]  acc 0.880972 (0.901261)  loss 0.280948 (0.242737)
GPU memory consumption  GPU Memory: Allocated: 126.6 MB, Reserved: 4990.0 MB
2025-08-16 11:25:53,349 - WARNING - Epoch [6/20] Step [21/125]  acc 0.905869 (0.901712)  loss 0.232145 (0.243472)
GPU memory consumption  GPU Memory: Allocated: 121.2 MB, Reserved: 4990.0 MB
2025-08-16 11:25:58,743 - WARNING - Epoch [6/20] Step [31/125]  acc 0.922730 (0.902314)  loss 0.213245 (0.243158)
GPU memory consumption  GPU Memory: Allocated: 127.2 MB, Reserved: 4990.0 MB
2025-08-16 11:26:04,247 - WARNING - Epoch [6/20] Step [41/125]  acc 0.910904 (0.902542)  loss 0.220683 (0.242432)
GPU memory consumption  GPU Memory: Allocated: 125.1 MB, Reserved: 4990.0 MB
2025-08-16 11:26:09,794 - WARNING - Epoch [6/20] Step [51/125]  acc 0.891068 (0.902794)  loss 0.261281 (0.241727)
GPU memory consumption  GPU Memory: Allocated: 122.9 MB, Reserved: 4990.0 MB
2025-08-16 11:26:15,258 - WARNING - Epoch [6/20] Step [61/125]  acc 0.903725 (0.902546)  loss 0.249861 (0.242260)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 4990.0 MB
2025-08-16 11:26:20,758 - WARNING - Epoch [6/20] Step [71/125]  acc 0.895746 (0.902239)  loss 0.250197 (0.242672)
GPU memory consumption  GPU Memory: Allocated: 120.7 MB, Reserved: 4990.0 MB
2025-08-16 11:26:26,302 - WARNING - Epoch [6/20] Step [81/125]  acc 0.891776 (0.902095)  loss 0.260361 (0.242804)
GPU memory consumption  GPU Memory: Allocated: 122.3 MB, Reserved: 4990.0 MB
2025-08-16 11:26:31,682 - WARNING - Epoch [6/20] Step [91/125]  acc 0.890667 (0.901967)  loss 0.262684 (0.243076)
GPU memory consumption  GPU Memory: Allocated: 128.4 MB, Reserved: 4990.0 MB
2025-08-16 11:26:37,078 - WARNING - Epoch [6/20] Step [101/125]  acc 0.895404 (0.901386)  loss 0.241053 (0.243710)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 4990.0 MB
2025-08-16 11:26:42,501 - WARNING - Epoch [6/20] Step [111/125]  acc 0.916887 (0.901541)  loss 0.210012 (0.243395)
GPU memory consumption  GPU Memory: Allocated: 123.2 MB, Reserved: 4990.0 MB
2025-08-16 11:26:47,900 - WARNING - Epoch [6/20] Step [121/125]  acc 0.906744 (0.901674)  loss 0.227158 (0.243093)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 4990.0 MB
Epoch 6 completed in 0:01:08.282840
2025-08-16 11:27:05,209 - WARNING - Epoch [7/20] Step [1/125]  acc 0.895474 (0.895474)  loss 0.248779 (0.248779)
GPU memory consumption  GPU Memory: Allocated: 123.0 MB, Reserved: 4990.0 MB
2025-08-16 11:27:10,658 - WARNING - Epoch [7/20] Step [11/125]  acc 0.902845 (0.899905)  loss 0.243528 (0.246094)
GPU memory consumption  GPU Memory: Allocated: 126.6 MB, Reserved: 4990.0 MB
2025-08-16 11:27:16,166 - WARNING - Epoch [7/20] Step [21/125]  acc 0.904798 (0.902856)  loss 0.228796 (0.241230)
GPU memory consumption  GPU Memory: Allocated: 129.1 MB, Reserved: 4990.0 MB
2025-08-16 11:27:21,570 - WARNING - Epoch [7/20] Step [31/125]  acc 0.908533 (0.902702)  loss 0.237028 (0.241317)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 4990.0 MB
2025-08-16 11:27:26,995 - WARNING - Epoch [7/20] Step [41/125]  acc 0.895759 (0.902296)  loss 0.246259 (0.241921)
GPU memory consumption  GPU Memory: Allocated: 117.7 MB, Reserved: 4990.0 MB
2025-08-16 11:27:32,495 - WARNING - Epoch [7/20] Step [51/125]  acc 0.907529 (0.902431)  loss 0.233105 (0.241368)
GPU memory consumption  GPU Memory: Allocated: 135.9 MB, Reserved: 4990.0 MB
2025-08-16 11:27:38,005 - WARNING - Epoch [7/20] Step [61/125]  acc 0.913629 (0.903237)  loss 0.223693 (0.239860)
GPU memory consumption  GPU Memory: Allocated: 133.0 MB, Reserved: 4990.0 MB
2025-08-16 11:27:43,483 - WARNING - Epoch [7/20] Step [71/125]  acc 0.899841 (0.903022)  loss 0.238362 (0.239551)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 4990.0 MB
2025-08-16 11:27:48,977 - WARNING - Epoch [7/20] Step [81/125]  acc 0.897319 (0.902919)  loss 0.249567 (0.239747)
GPU memory consumption  GPU Memory: Allocated: 123.0 MB, Reserved: 4990.0 MB
2025-08-16 11:27:54,415 - WARNING - Epoch [7/20] Step [91/125]  acc 0.903836 (0.903159)  loss 0.234616 (0.239107)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 4990.0 MB
2025-08-16 11:27:59,867 - WARNING - Epoch [7/20] Step [101/125]  acc 0.910347 (0.903541)  loss 0.217395 (0.238232)
GPU memory consumption  GPU Memory: Allocated: 130.0 MB, Reserved: 4990.0 MB
2025-08-16 11:28:05,227 - WARNING - Epoch [7/20] Step [111/125]  acc 0.905278 (0.903479)  loss 0.234812 (0.238503)
GPU memory consumption  GPU Memory: Allocated: 119.0 MB, Reserved: 4990.0 MB
2025-08-16 11:28:10,659 - WARNING - Epoch [7/20] Step [121/125]  acc 0.909674 (0.903389)  loss 0.229748 (0.238531)
GPU memory consumption  GPU Memory: Allocated: 124.7 MB, Reserved: 4990.0 MB
Epoch 7 completed in 0:01:08.154292
2025-08-16 11:28:27,970 - WARNING - Epoch [8/20] Step [1/125]  acc 0.911986 (0.911986)  loss 0.216691 (0.216691)
GPU memory consumption  GPU Memory: Allocated: 127.8 MB, Reserved: 4990.0 MB
2025-08-16 11:28:33,405 - WARNING - Epoch [8/20] Step [11/125]  acc 0.907729 (0.905212)  loss 0.233489 (0.233496)
GPU memory consumption  GPU Memory: Allocated: 127.1 MB, Reserved: 4990.0 MB
2025-08-16 11:28:38,914 - WARNING - Epoch [8/20] Step [21/125]  acc 0.909043 (0.905005)  loss 0.230326 (0.234411)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 4990.0 MB
2025-08-16 11:28:44,277 - WARNING - Epoch [8/20] Step [31/125]  acc 0.905115 (0.905186)  loss 0.234886 (0.234462)
GPU memory consumption  GPU Memory: Allocated: 121.8 MB, Reserved: 4990.0 MB
2025-08-16 11:28:49,730 - WARNING - Epoch [8/20] Step [41/125]  acc 0.893901 (0.904473)  loss 0.254787 (0.235783)
GPU memory consumption  GPU Memory: Allocated: 124.1 MB, Reserved: 4990.0 MB
2025-08-16 11:28:55,207 - WARNING - Epoch [8/20] Step [51/125]  acc 0.900672 (0.904708)  loss 0.245858 (0.235686)
GPU memory consumption  GPU Memory: Allocated: 118.7 MB, Reserved: 4990.0 MB
2025-08-16 11:29:00,727 - WARNING - Epoch [8/20] Step [61/125]  acc 0.902377 (0.904540)  loss 0.229928 (0.236030)
GPU memory consumption  GPU Memory: Allocated: 130.0 MB, Reserved: 4990.0 MB
2025-08-16 11:29:06,190 - WARNING - Epoch [8/20] Step [71/125]  acc 0.907942 (0.904650)  loss 0.228702 (0.235697)
GPU memory consumption  GPU Memory: Allocated: 129.1 MB, Reserved: 4990.0 MB
2025-08-16 11:29:11,692 - WARNING - Epoch [8/20] Step [81/125]  acc 0.912785 (0.904922)  loss 0.214833 (0.235194)
GPU memory consumption  GPU Memory: Allocated: 125.4 MB, Reserved: 4990.0 MB
2025-08-16 11:29:17,119 - WARNING - Epoch [8/20] Step [91/125]  acc 0.905230 (0.905040)  loss 0.237796 (0.234777)
GPU memory consumption  GPU Memory: Allocated: 130.8 MB, Reserved: 4990.0 MB
2025-08-16 11:29:22,584 - WARNING - Epoch [8/20] Step [101/125]  acc 0.907441 (0.905033)  loss 0.225641 (0.235028)
GPU memory consumption  GPU Memory: Allocated: 126.4 MB, Reserved: 4990.0 MB
2025-08-16 11:29:28,023 - WARNING - Epoch [8/20] Step [111/125]  acc 0.905377 (0.905039)  loss 0.247918 (0.234961)
GPU memory consumption  GPU Memory: Allocated: 124.4 MB, Reserved: 4990.0 MB
2025-08-16 11:29:33,418 - WARNING - Epoch [8/20] Step [121/125]  acc 0.903398 (0.904875)  loss 0.239567 (0.235522)
GPU memory consumption  GPU Memory: Allocated: 124.9 MB, Reserved: 4990.0 MB
Epoch 8 completed in 0:01:08.249159
2025-08-16 11:29:50,771 - WARNING - Epoch [9/20] Step [1/125]  acc 0.912384 (0.912384)  loss 0.218887 (0.218887)
GPU memory consumption  GPU Memory: Allocated: 127.9 MB, Reserved: 4990.0 MB
2025-08-16 11:29:56,177 - WARNING - Epoch [9/20] Step [11/125]  acc 0.910103 (0.906336)  loss 0.227115 (0.231082)
GPU memory consumption  GPU Memory: Allocated: 127.9 MB, Reserved: 4990.0 MB
2025-08-16 11:30:01,690 - WARNING - Epoch [9/20] Step [21/125]  acc 0.912356 (0.907208)  loss 0.220609 (0.230544)
GPU memory consumption  GPU Memory: Allocated: 124.2 MB, Reserved: 4990.0 MB
2025-08-16 11:30:07,172 - WARNING - Epoch [9/20] Step [31/125]  acc 0.916469 (0.907262)  loss 0.212006 (0.230339)
GPU memory consumption  GPU Memory: Allocated: 123.0 MB, Reserved: 4990.0 MB
2025-08-16 11:30:12,670 - WARNING - Epoch [9/20] Step [41/125]  acc 0.904187 (0.906753)  loss 0.232701 (0.231193)
GPU memory consumption  GPU Memory: Allocated: 124.2 MB, Reserved: 4990.0 MB
2025-08-16 11:30:18,131 - WARNING - Epoch [9/20] Step [51/125]  acc 0.900928 (0.906625)  loss 0.250560 (0.231710)
GPU memory consumption  GPU Memory: Allocated: 120.4 MB, Reserved: 4990.0 MB
2025-08-16 11:30:23,582 - WARNING - Epoch [9/20] Step [61/125]  acc 0.902258 (0.906342)  loss 0.246668 (0.232170)
GPU memory consumption  GPU Memory: Allocated: 121.9 MB, Reserved: 4990.0 MB
2025-08-16 11:30:29,059 - WARNING - Epoch [9/20] Step [71/125]  acc 0.909650 (0.906537)  loss 0.213693 (0.232053)
GPU memory consumption  GPU Memory: Allocated: 125.1 MB, Reserved: 4990.0 MB
2025-08-16 11:30:34,563 - WARNING - Epoch [9/20] Step [81/125]  acc 0.918207 (0.906568)  loss 0.207920 (0.231856)
GPU memory consumption  GPU Memory: Allocated: 127.7 MB, Reserved: 4990.0 MB
2025-08-16 11:30:39,993 - WARNING - Epoch [9/20] Step [91/125]  acc 0.899768 (0.906066)  loss 0.242831 (0.232375)
GPU memory consumption  GPU Memory: Allocated: 132.2 MB, Reserved: 4990.0 MB
2025-08-16 11:30:45,446 - WARNING - Epoch [9/20] Step [101/125]  acc 0.909163 (0.906071)  loss 0.221163 (0.232166)
GPU memory consumption  GPU Memory: Allocated: 124.5 MB, Reserved: 4990.0 MB
2025-08-16 11:30:50,900 - WARNING - Epoch [9/20] Step [111/125]  acc 0.903468 (0.906289)  loss 0.233407 (0.231797)
GPU memory consumption  GPU Memory: Allocated: 125.1 MB, Reserved: 4990.0 MB
2025-08-16 11:30:56,379 - WARNING - Epoch [9/20] Step [121/125]  acc 0.905919 (0.906062)  loss 0.231883 (0.232110)
GPU memory consumption  GPU Memory: Allocated: 127.6 MB, Reserved: 4990.0 MB
Epoch 9 completed in 0:01:08.345614
2025-08-16 11:31:13,649 - WARNING - Epoch [10/20] Step [1/125]  acc 0.899720 (0.899720)  loss 0.249007 (0.249007)
GPU memory consumption  GPU Memory: Allocated: 119.8 MB, Reserved: 4990.0 MB
2025-08-16 11:31:19,076 - WARNING - Epoch [10/20] Step [11/125]  acc 0.901829 (0.909225)  loss 0.226917 (0.225164)
GPU memory consumption  GPU Memory: Allocated: 126.6 MB, Reserved: 4990.0 MB
2025-08-16 11:31:24,541 - WARNING - Epoch [10/20] Step [21/125]  acc 0.906147 (0.908459)  loss 0.225420 (0.227394)
GPU memory consumption  GPU Memory: Allocated: 131.2 MB, Reserved: 4990.0 MB
2025-08-16 11:31:30,043 - WARNING - Epoch [10/20] Step [31/125]  acc 0.911173 (0.907351)  loss 0.228538 (0.228813)
GPU memory consumption  GPU Memory: Allocated: 127.2 MB, Reserved: 4990.0 MB
2025-08-16 11:31:35,533 - WARNING - Epoch [10/20] Step [41/125]  acc 0.907734 (0.907018)  loss 0.218946 (0.229193)
GPU memory consumption  GPU Memory: Allocated: 118.2 MB, Reserved: 4990.0 MB
2025-08-16 11:31:40,900 - WARNING - Epoch [10/20] Step [51/125]  acc 0.903572 (0.905662)  loss 0.235565 (0.232219)
GPU memory consumption  GPU Memory: Allocated: 121.5 MB, Reserved: 4990.0 MB
2025-08-16 11:31:46,354 - WARNING - Epoch [10/20] Step [61/125]  acc 0.915472 (0.905535)  loss 0.207621 (0.232252)
GPU memory consumption  GPU Memory: Allocated: 131.3 MB, Reserved: 4990.0 MB
2025-08-16 11:31:51,842 - WARNING - Epoch [10/20] Step [71/125]  acc 0.897495 (0.905450)  loss 0.244849 (0.232083)
GPU memory consumption  GPU Memory: Allocated: 129.1 MB, Reserved: 4990.0 MB
2025-08-16 11:31:57,341 - WARNING - Epoch [10/20] Step [81/125]  acc 0.912348 (0.905647)  loss 0.215653 (0.231846)
GPU memory consumption  GPU Memory: Allocated: 128.0 MB, Reserved: 4990.0 MB
2025-08-16 11:32:02,709 - WARNING - Epoch [10/20] Step [91/125]  acc 0.894723 (0.905684)  loss 0.254869 (0.232051)
GPU memory consumption  GPU Memory: Allocated: 132.2 MB, Reserved: 4990.0 MB
2025-08-16 11:32:08,194 - WARNING - Epoch [10/20] Step [101/125]  acc 0.911795 (0.905715)  loss 0.223315 (0.231733)
GPU memory consumption  GPU Memory: Allocated: 127.9 MB, Reserved: 4990.0 MB
2025-08-16 11:32:13,733 - WARNING - Epoch [10/20] Step [111/125]  acc 0.900457 (0.905891)  loss 0.257582 (0.231454)
GPU memory consumption  GPU Memory: Allocated: 122.3 MB, Reserved: 4990.0 MB
2025-08-16 11:32:19,158 - WARNING - Epoch [10/20] Step [121/125]  acc 0.903014 (0.905793)  loss 0.238512 (0.231759)
GPU memory consumption  GPU Memory: Allocated: 128.0 MB, Reserved: 4990.0 MB
Epoch 10 completed in 0:01:08.213316
2025-08-16 11:32:36,832 - WARNING - Epoch [11/20] Step [1/125]  acc 0.912253 (0.912253)  loss 0.218713 (0.218713)
GPU memory consumption  GPU Memory: Allocated: 124.6 MB, Reserved: 4990.0 MB
2025-08-16 11:32:42,395 - WARNING - Epoch [11/20] Step [11/125]  acc 0.906415 (0.903638)  loss 0.228578 (0.236460)
GPU memory consumption  GPU Memory: Allocated: 133.1 MB, Reserved: 4990.0 MB
2025-08-16 11:32:48,007 - WARNING - Epoch [11/20] Step [21/125]  acc 0.904439 (0.902920)  loss 0.231165 (0.237708)
GPU memory consumption  GPU Memory: Allocated: 131.2 MB, Reserved: 4990.0 MB
2025-08-16 11:32:53,464 - WARNING - Epoch [11/20] Step [31/125]  acc 0.897737 (0.903032)  loss 0.246333 (0.237231)
GPU memory consumption  GPU Memory: Allocated: 116.9 MB, Reserved: 4992.0 MB
2025-08-16 11:32:58,940 - WARNING - Epoch [11/20] Step [41/125]  acc 0.896552 (0.903957)  loss 0.249320 (0.235591)
GPU memory consumption  GPU Memory: Allocated: 120.4 MB, Reserved: 4992.0 MB
2025-08-16 11:33:04,547 - WARNING - Epoch [11/20] Step [51/125]  acc 0.915942 (0.905401)  loss 0.210573 (0.232303)
GPU memory consumption  GPU Memory: Allocated: 122.8 MB, Reserved: 4992.0 MB
2025-08-16 11:33:10,118 - WARNING - Epoch [11/20] Step [61/125]  acc 0.908185 (0.905425)  loss 0.229049 (0.232366)
GPU memory consumption  GPU Memory: Allocated: 124.4 MB, Reserved: 4992.0 MB
2025-08-16 11:33:15,592 - WARNING - Epoch [11/20] Step [71/125]  acc 0.915263 (0.905980)  loss 0.207442 (0.231271)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 4992.0 MB
2025-08-16 11:33:21,170 - WARNING - Epoch [11/20] Step [81/125]  acc 0.895985 (0.905722)  loss 0.251940 (0.231710)
GPU memory consumption  GPU Memory: Allocated: 121.9 MB, Reserved: 4992.0 MB
2025-08-16 11:33:26,649 - WARNING - Epoch [11/20] Step [91/125]  acc 0.906118 (0.905590)  loss 0.230852 (0.231419)
GPU memory consumption  GPU Memory: Allocated: 128.9 MB, Reserved: 4992.0 MB
2025-08-16 11:33:32,144 - WARNING - Epoch [11/20] Step [101/125]  acc 0.901940 (0.905206)  loss 0.237116 (0.232245)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 4992.0 MB
2025-08-16 11:33:37,711 - WARNING - Epoch [11/20] Step [111/125]  acc 0.906518 (0.905063)  loss 0.228060 (0.232413)
GPU memory consumption  GPU Memory: Allocated: 128.6 MB, Reserved: 4998.0 MB
2025-08-16 11:33:43,250 - WARNING - Epoch [11/20] Step [121/125]  acc 0.914271 (0.905417)  loss 0.215685 (0.231750)
GPU memory consumption  GPU Memory: Allocated: 131.2 MB, Reserved: 4998.0 MB
Epoch 11 completed in 0:01:09.245971
2025-08-16 11:34:00,729 - WARNING - Epoch [12/20] Step [1/125]  acc 0.897827 (0.897827)  loss 0.250175 (0.250175)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 4998.0 MB
2025-08-16 11:34:06,129 - WARNING - Epoch [12/20] Step [11/125]  acc 0.909213 (0.901828)  loss 0.223831 (0.240084)
GPU memory consumption  GPU Memory: Allocated: 126.8 MB, Reserved: 4998.0 MB
2025-08-16 11:34:11,723 - WARNING - Epoch [12/20] Step [21/125]  acc 0.900233 (0.903566)  loss 0.247334 (0.236762)
GPU memory consumption  GPU Memory: Allocated: 129.0 MB, Reserved: 4998.0 MB
2025-08-16 11:34:17,264 - WARNING - Epoch [12/20] Step [31/125]  acc 0.914381 (0.904265)  loss 0.209224 (0.233927)
GPU memory consumption  GPU Memory: Allocated: 125.2 MB, Reserved: 4998.0 MB
2025-08-16 11:34:22,748 - WARNING - Epoch [12/20] Step [41/125]  acc 0.920347 (0.905962)  loss 0.209363 (0.230303)
GPU memory consumption  GPU Memory: Allocated: 124.1 MB, Reserved: 4998.0 MB
2025-08-16 11:34:28,298 - WARNING - Epoch [12/20] Step [51/125]  acc 0.911004 (0.906377)  loss 0.230002 (0.230472)
GPU memory consumption  GPU Memory: Allocated: 127.1 MB, Reserved: 4998.0 MB
2025-08-16 11:34:33,785 - WARNING - Epoch [12/20] Step [61/125]  acc 0.909169 (0.906879)  loss 0.226540 (0.229203)
GPU memory consumption  GPU Memory: Allocated: 118.3 MB, Reserved: 4998.0 MB
2025-08-16 11:34:39,292 - WARNING - Epoch [12/20] Step [71/125]  acc 0.904611 (0.906957)  loss 0.231081 (0.229042)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 4998.0 MB
2025-08-16 11:34:44,826 - WARNING - Epoch [12/20] Step [81/125]  acc 0.898194 (0.906160)  loss 0.248564 (0.230552)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 4998.0 MB
2025-08-16 11:34:50,312 - WARNING - Epoch [12/20] Step [91/125]  acc 0.898345 (0.905782)  loss 0.243052 (0.231534)
GPU memory consumption  GPU Memory: Allocated: 130.1 MB, Reserved: 4998.0 MB
2025-08-16 11:34:55,851 - WARNING - Epoch [12/20] Step [101/125]  acc 0.909478 (0.905981)  loss 0.226393 (0.231283)
GPU memory consumption  GPU Memory: Allocated: 130.0 MB, Reserved: 4998.0 MB
2025-08-16 11:35:01,349 - WARNING - Epoch [12/20] Step [111/125]  acc 0.914888 (0.906197)  loss 0.218933 (0.231083)
GPU memory consumption  GPU Memory: Allocated: 120.5 MB, Reserved: 4998.0 MB
2025-08-16 11:35:06,834 - WARNING - Epoch [12/20] Step [121/125]  acc 0.911689 (0.906010)  loss 0.214973 (0.231106)
GPU memory consumption  GPU Memory: Allocated: 129.0 MB, Reserved: 4998.0 MB
Epoch 12 completed in 0:01:08.853874
2025-08-16 11:35:24,209 - WARNING - Epoch [13/20] Step [1/125]  acc 0.886578 (0.886578)  loss 0.269744 (0.269744)
GPU memory consumption  GPU Memory: Allocated: 122.8 MB, Reserved: 4998.0 MB
2025-08-16 11:35:29,667 - WARNING - Epoch [13/20] Step [11/125]  acc 0.910253 (0.903443)  loss 0.227476 (0.234521)
GPU memory consumption  GPU Memory: Allocated: 129.4 MB, Reserved: 4998.0 MB
2025-08-16 11:35:35,235 - WARNING - Epoch [13/20] Step [21/125]  acc 0.907962 (0.904167)  loss 0.230562 (0.233635)
GPU memory consumption  GPU Memory: Allocated: 124.4 MB, Reserved: 4998.0 MB
2025-08-16 11:35:40,726 - WARNING - Epoch [13/20] Step [31/125]  acc 0.915654 (0.905800)  loss 0.214209 (0.230531)
GPU memory consumption  GPU Memory: Allocated: 126.1 MB, Reserved: 4998.0 MB
2025-08-16 11:35:46,160 - WARNING - Epoch [13/20] Step [41/125]  acc 0.907677 (0.904960)  loss 0.225550 (0.232250)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 4998.0 MB
2025-08-16 11:35:51,629 - WARNING - Epoch [13/20] Step [51/125]  acc 0.906504 (0.904733)  loss 0.223347 (0.232743)
GPU memory consumption  GPU Memory: Allocated: 121.0 MB, Reserved: 4998.0 MB
2025-08-16 11:35:57,186 - WARNING - Epoch [13/20] Step [61/125]  acc 0.921220 (0.905185)  loss 0.204116 (0.231958)
GPU memory consumption  GPU Memory: Allocated: 129.6 MB, Reserved: 4998.0 MB
2025-08-16 11:36:02,616 - WARNING - Epoch [13/20] Step [71/125]  acc 0.919118 (0.905754)  loss 0.206430 (0.230928)
GPU memory consumption  GPU Memory: Allocated: 129.5 MB, Reserved: 4998.0 MB
2025-08-16 11:36:08,145 - WARNING - Epoch [13/20] Step [81/125]  acc 0.909043 (0.906062)  loss 0.221050 (0.230249)
GPU memory consumption  GPU Memory: Allocated: 123.1 MB, Reserved: 4998.0 MB
2025-08-16 11:36:13,563 - WARNING - Epoch [13/20] Step [91/125]  acc 0.902465 (0.905610)  loss 0.227488 (0.230951)
GPU memory consumption  GPU Memory: Allocated: 128.5 MB, Reserved: 4998.0 MB
2025-08-16 11:36:19,076 - WARNING - Epoch [13/20] Step [101/125]  acc 0.910475 (0.905842)  loss 0.220979 (0.230567)
GPU memory consumption  GPU Memory: Allocated: 126.0 MB, Reserved: 4998.0 MB
2025-08-16 11:36:24,524 - WARNING - Epoch [13/20] Step [111/125]  acc 0.902420 (0.905680)  loss 0.235370 (0.230789)
GPU memory consumption  GPU Memory: Allocated: 126.5 MB, Reserved: 4998.0 MB
2025-08-16 11:36:29,961 - WARNING - Epoch [13/20] Step [121/125]  acc 0.916863 (0.905213)  loss 0.206296 (0.231832)
GPU memory consumption  GPU Memory: Allocated: 127.1 MB, Reserved: 4998.0 MB
Epoch 13 completed in 0:01:08.509692
2025-08-16 11:36:47,300 - WARNING - Epoch [14/20] Step [1/125]  acc 0.910253 (0.910253)  loss 0.219323 (0.219323)
GPU memory consumption  GPU Memory: Allocated: 124.4 MB, Reserved: 4998.0 MB
2025-08-16 11:36:52,720 - WARNING - Epoch [14/20] Step [11/125]  acc 0.913043 (0.903844)  loss 0.211756 (0.233618)
GPU memory consumption  GPU Memory: Allocated: 131.5 MB, Reserved: 4998.0 MB
2025-08-16 11:36:58,288 - WARNING - Epoch [14/20] Step [21/125]  acc 0.893831 (0.907151)  loss 0.253887 (0.228030)
GPU memory consumption  GPU Memory: Allocated: 125.7 MB, Reserved: 4998.0 MB
2025-08-16 11:37:03,797 - WARNING - Epoch [14/20] Step [31/125]  acc 0.905584 (0.907745)  loss 0.227489 (0.227017)
GPU memory consumption  GPU Memory: Allocated: 125.1 MB, Reserved: 4998.0 MB
2025-08-16 11:37:09,257 - WARNING - Epoch [14/20] Step [41/125]  acc 0.893689 (0.906347)  loss 0.259080 (0.229386)
GPU memory consumption  GPU Memory: Allocated: 122.1 MB, Reserved: 4998.0 MB
2025-08-16 11:37:14,784 - WARNING - Epoch [14/20] Step [51/125]  acc 0.904359 (0.906188)  loss 0.240780 (0.229809)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 4998.0 MB
2025-08-16 11:37:20,274 - WARNING - Epoch [14/20] Step [61/125]  acc 0.894819 (0.905450)  loss 0.252469 (0.231180)
GPU memory consumption  GPU Memory: Allocated: 127.6 MB, Reserved: 4998.0 MB
2025-08-16 11:37:25,725 - WARNING - Epoch [14/20] Step [71/125]  acc 0.918008 (0.905310)  loss 0.206881 (0.232023)
GPU memory consumption  GPU Memory: Allocated: 132.3 MB, Reserved: 4998.0 MB
2025-08-16 11:37:31,249 - WARNING - Epoch [14/20] Step [81/125]  acc 0.913054 (0.905636)  loss 0.215769 (0.231442)
GPU memory consumption  GPU Memory: Allocated: 129.0 MB, Reserved: 4998.0 MB
2025-08-16 11:37:36,700 - WARNING - Epoch [14/20] Step [91/125]  acc 0.903389 (0.905685)  loss 0.241671 (0.231597)
GPU memory consumption  GPU Memory: Allocated: 133.8 MB, Reserved: 4998.0 MB
2025-08-16 11:37:42,176 - WARNING - Epoch [14/20] Step [101/125]  acc 0.897375 (0.905718)  loss 0.244577 (0.231626)
GPU memory consumption  GPU Memory: Allocated: 124.7 MB, Reserved: 4998.0 MB
2025-08-16 11:37:47,602 - WARNING - Epoch [14/20] Step [111/125]  acc 0.908325 (0.905789)  loss 0.227179 (0.231293)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 4998.0 MB
2025-08-16 11:37:53,032 - WARNING - Epoch [14/20] Step [121/125]  acc 0.903377 (0.905890)  loss 0.230604 (0.231130)
GPU memory consumption  GPU Memory: Allocated: 127.3 MB, Reserved: 4998.0 MB
Epoch 14 completed in 0:01:08.465569
2025-08-16 11:38:10,384 - WARNING - Epoch [15/20] Step [1/125]  acc 0.900340 (0.900340)  loss 0.234760 (0.234760)
GPU memory consumption  GPU Memory: Allocated: 125.7 MB, Reserved: 4998.0 MB
2025-08-16 11:38:15,825 - WARNING - Epoch [15/20] Step [11/125]  acc 0.909210 (0.904516)  loss 0.223797 (0.231332)
GPU memory consumption  GPU Memory: Allocated: 129.3 MB, Reserved: 4998.0 MB
2025-08-16 11:38:21,360 - WARNING - Epoch [15/20] Step [21/125]  acc 0.901104 (0.905233)  loss 0.228818 (0.231095)
GPU memory consumption  GPU Memory: Allocated: 131.8 MB, Reserved: 4998.0 MB
2025-08-16 11:38:26,881 - WARNING - Epoch [15/20] Step [31/125]  acc 0.900877 (0.906645)  loss 0.241623 (0.229449)
GPU memory consumption  GPU Memory: Allocated: 123.0 MB, Reserved: 4998.0 MB
2025-08-16 11:38:32,403 - WARNING - Epoch [15/20] Step [41/125]  acc 0.909997 (0.907622)  loss 0.219061 (0.228185)
GPU memory consumption  GPU Memory: Allocated: 124.1 MB, Reserved: 4998.0 MB
2025-08-16 11:38:37,886 - WARNING - Epoch [15/20] Step [51/125]  acc 0.917000 (0.907437)  loss 0.204037 (0.228623)
GPU memory consumption  GPU Memory: Allocated: 121.6 MB, Reserved: 4998.0 MB
2025-08-16 11:38:43,342 - WARNING - Epoch [15/20] Step [61/125]  acc 0.901202 (0.906965)  loss 0.243815 (0.229508)
GPU memory consumption  GPU Memory: Allocated: 127.2 MB, Reserved: 4998.0 MB
2025-08-16 11:38:48,852 - WARNING - Epoch [15/20] Step [71/125]  acc 0.903384 (0.906698)  loss 0.236410 (0.229816)
GPU memory consumption  GPU Memory: Allocated: 129.1 MB, Reserved: 4998.0 MB
2025-08-16 11:38:54,327 - WARNING - Epoch [15/20] Step [81/125]  acc 0.906484 (0.906669)  loss 0.223914 (0.229478)
GPU memory consumption  GPU Memory: Allocated: 122.6 MB, Reserved: 4998.0 MB
2025-08-16 11:38:59,829 - WARNING - Epoch [15/20] Step [91/125]  acc 0.912573 (0.906964)  loss 0.213909 (0.228759)
GPU memory consumption  GPU Memory: Allocated: 133.3 MB, Reserved: 4998.0 MB
2025-08-16 11:39:05,263 - WARNING - Epoch [15/20] Step [101/125]  acc 0.915792 (0.907137)  loss 0.212961 (0.228551)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 4998.0 MB
2025-08-16 11:39:10,690 - WARNING - Epoch [15/20] Step [111/125]  acc 0.908997 (0.907022)  loss 0.222545 (0.228839)
GPU memory consumption  GPU Memory: Allocated: 124.7 MB, Reserved: 4998.0 MB
2025-08-16 11:39:16,158 - WARNING - Epoch [15/20] Step [121/125]  acc 0.908730 (0.907185)  loss 0.228475 (0.228521)
GPU memory consumption  GPU Memory: Allocated: 125.5 MB, Reserved: 4998.0 MB
Epoch 15 completed in 0:01:08.505618
2025-08-16 11:39:34,138 - WARNING - Epoch [16/20] Step [1/125]  acc 0.912538 (0.912538)  loss 0.217682 (0.217682)
GPU memory consumption  GPU Memory: Allocated: 130.0 MB, Reserved: 4998.0 MB
2025-08-16 11:39:39,706 - WARNING - Epoch [16/20] Step [11/125]  acc 0.906030 (0.909102)  loss 0.228679 (0.227353)
GPU memory consumption  GPU Memory: Allocated: 129.7 MB, Reserved: 4998.0 MB
2025-08-16 11:39:45,352 - WARNING - Epoch [16/20] Step [21/125]  acc 0.902771 (0.907356)  loss 0.231533 (0.228652)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 4998.0 MB
2025-08-16 11:39:50,858 - WARNING - Epoch [16/20] Step [31/125]  acc 0.894486 (0.906627)  loss 0.238030 (0.229541)
GPU memory consumption  GPU Memory: Allocated: 116.6 MB, Reserved: 4998.0 MB
2025-08-16 11:39:56,298 - WARNING - Epoch [16/20] Step [41/125]  acc 0.911041 (0.906009)  loss 0.220390 (0.231085)
GPU memory consumption  GPU Memory: Allocated: 122.1 MB, Reserved: 4998.0 MB
2025-08-16 11:40:01,854 - WARNING - Epoch [16/20] Step [51/125]  acc 0.893852 (0.906201)  loss 0.258561 (0.230923)
GPU memory consumption  GPU Memory: Allocated: 124.3 MB, Reserved: 4998.0 MB
2025-08-16 11:40:07,281 - WARNING - Epoch [16/20] Step [61/125]  acc 0.903754 (0.906456)  loss 0.232711 (0.230151)
GPU memory consumption  GPU Memory: Allocated: 120.5 MB, Reserved: 4998.0 MB
2025-08-16 11:40:12,815 - WARNING - Epoch [16/20] Step [71/125]  acc 0.917209 (0.906684)  loss 0.210331 (0.229674)
GPU memory consumption  GPU Memory: Allocated: 127.2 MB, Reserved: 4998.0 MB
2025-08-16 11:40:18,350 - WARNING - Epoch [16/20] Step [81/125]  acc 0.892626 (0.906215)  loss 0.255753 (0.230471)
GPU memory consumption  GPU Memory: Allocated: 122.6 MB, Reserved: 5002.0 MB
2025-08-16 11:40:23,744 - WARNING - Epoch [16/20] Step [91/125]  acc 0.913860 (0.906099)  loss 0.216272 (0.230443)
GPU memory consumption  GPU Memory: Allocated: 132.2 MB, Reserved: 5002.0 MB
2025-08-16 11:40:29,194 - WARNING - Epoch [16/20] Step [101/125]  acc 0.901093 (0.906180)  loss 0.230748 (0.229874)
GPU memory consumption  GPU Memory: Allocated: 124.0 MB, Reserved: 5002.0 MB
2025-08-16 11:40:34,648 - WARNING - Epoch [16/20] Step [111/125]  acc 0.903165 (0.905922)  loss 0.237088 (0.230334)
GPU memory consumption  GPU Memory: Allocated: 121.5 MB, Reserved: 5002.0 MB
2025-08-16 11:40:40,039 - WARNING - Epoch [16/20] Step [121/125]  acc 0.914964 (0.905897)  loss 0.210951 (0.230383)
GPU memory consumption  GPU Memory: Allocated: 129.6 MB, Reserved: 5002.0 MB
Epoch 16 completed in 0:01:08.715204
2025-08-16 11:40:57,440 - WARNING - Epoch [17/20] Step [1/125]  acc 0.893865 (0.893865)  loss 0.256407 (0.256407)
GPU memory consumption  GPU Memory: Allocated: 122.6 MB, Reserved: 5002.0 MB
2025-08-16 11:41:03,148 - WARNING - Epoch [17/20] Step [11/125]  acc 0.895395 (0.901254)  loss 0.249000 (0.239484)
GPU memory consumption  GPU Memory: Allocated: 128.1 MB, Reserved: 5002.0 MB
2025-08-16 11:41:08,655 - WARNING - Epoch [17/20] Step [21/125]  acc 0.901269 (0.903883)  loss 0.245512 (0.236518)
GPU memory consumption  GPU Memory: Allocated: 120.5 MB, Reserved: 5002.0 MB
2025-08-16 11:41:14,174 - WARNING - Epoch [17/20] Step [31/125]  acc 0.900735 (0.905513)  loss 0.249208 (0.232579)
GPU memory consumption  GPU Memory: Allocated: 123.0 MB, Reserved: 5002.0 MB
2025-08-16 11:41:19,595 - WARNING - Epoch [17/20] Step [41/125]  acc 0.907281 (0.905861)  loss 0.223339 (0.231542)
GPU memory consumption  GPU Memory: Allocated: 122.1 MB, Reserved: 5002.0 MB
2025-08-16 11:41:25,110 - WARNING - Epoch [17/20] Step [51/125]  acc 0.915897 (0.905828)  loss 0.212939 (0.231521)
GPU memory consumption  GPU Memory: Allocated: 128.6 MB, Reserved: 5002.0 MB
2025-08-16 11:41:30,581 - WARNING - Epoch [17/20] Step [61/125]  acc 0.904976 (0.906161)  loss 0.227485 (0.230865)
GPU memory consumption  GPU Memory: Allocated: 125.4 MB, Reserved: 5002.0 MB
2025-08-16 11:41:36,012 - WARNING - Epoch [17/20] Step [71/125]  acc 0.889576 (0.906477)  loss 0.265687 (0.230125)
GPU memory consumption  GPU Memory: Allocated: 124.4 MB, Reserved: 5002.0 MB
2025-08-16 11:41:41,493 - WARNING - Epoch [17/20] Step [81/125]  acc 0.914024 (0.906711)  loss 0.215911 (0.229648)
GPU memory consumption  GPU Memory: Allocated: 124.8 MB, Reserved: 5002.0 MB
2025-08-16 11:41:46,922 - WARNING - Epoch [17/20] Step [91/125]  acc 0.914334 (0.906821)  loss 0.210658 (0.229601)
GPU memory consumption  GPU Memory: Allocated: 139.3 MB, Reserved: 5002.0 MB
2025-08-16 11:41:52,396 - WARNING - Epoch [17/20] Step [101/125]  acc 0.912723 (0.906752)  loss 0.218464 (0.229485)
GPU memory consumption  GPU Memory: Allocated: 124.7 MB, Reserved: 5002.0 MB
2025-08-16 11:41:57,848 - WARNING - Epoch [17/20] Step [111/125]  acc 0.908507 (0.907075)  loss 0.223855 (0.228448)
GPU memory consumption  GPU Memory: Allocated: 122.7 MB, Reserved: 5002.0 MB
2025-08-16 11:42:03,296 - WARNING - Epoch [17/20] Step [121/125]  acc 0.912314 (0.907174)  loss 0.207789 (0.228260)
GPU memory consumption  GPU Memory: Allocated: 122.8 MB, Reserved: 5002.0 MB
Epoch 17 completed in 0:01:08.625502
2025-08-16 11:42:20,639 - WARNING - Epoch [18/20] Step [1/125]  acc 0.890080 (0.890080)  loss 0.265249 (0.265249)
GPU memory consumption  GPU Memory: Allocated: 121.0 MB, Reserved: 5002.0 MB
2025-08-16 11:42:26,118 - WARNING - Epoch [18/20] Step [11/125]  acc 0.903937 (0.903313)  loss 0.228451 (0.235834)
GPU memory consumption  GPU Memory: Allocated: 129.3 MB, Reserved: 5002.0 MB
2025-08-16 11:42:31,599 - WARNING - Epoch [18/20] Step [21/125]  acc 0.902770 (0.904820)  loss 0.243253 (0.232215)
GPU memory consumption  GPU Memory: Allocated: 121.8 MB, Reserved: 5002.0 MB
2025-08-16 11:42:37,126 - WARNING - Epoch [18/20] Step [31/125]  acc 0.907158 (0.905471)  loss 0.235318 (0.231042)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 5002.0 MB
2025-08-16 11:42:42,568 - WARNING - Epoch [18/20] Step [41/125]  acc 0.901185 (0.905570)  loss 0.242635 (0.230718)
GPU memory consumption  GPU Memory: Allocated: 118.5 MB, Reserved: 5002.0 MB
2025-08-16 11:42:48,142 - WARNING - Epoch [18/20] Step [51/125]  acc 0.909377 (0.905298)  loss 0.223043 (0.231507)
GPU memory consumption  GPU Memory: Allocated: 124.3 MB, Reserved: 5002.0 MB
2025-08-16 11:42:53,632 - WARNING - Epoch [18/20] Step [61/125]  acc 0.914872 (0.906107)  loss 0.224336 (0.229779)
GPU memory consumption  GPU Memory: Allocated: 129.0 MB, Reserved: 5002.0 MB
2025-08-16 11:42:59,089 - WARNING - Epoch [18/20] Step [71/125]  acc 0.902013 (0.906093)  loss 0.234837 (0.229540)
GPU memory consumption  GPU Memory: Allocated: 124.5 MB, Reserved: 5002.0 MB
2025-08-16 11:43:04,558 - WARNING - Epoch [18/20] Step [81/125]  acc 0.897310 (0.905422)  loss 0.252989 (0.230587)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 5002.0 MB
2025-08-16 11:43:09,992 - WARNING - Epoch [18/20] Step [91/125]  acc 0.907864 (0.905424)  loss 0.232691 (0.230616)
GPU memory consumption  GPU Memory: Allocated: 130.4 MB, Reserved: 5002.0 MB
2025-08-16 11:43:15,426 - WARNING - Epoch [18/20] Step [101/125]  acc 0.905912 (0.905519)  loss 0.225591 (0.230561)
GPU memory consumption  GPU Memory: Allocated: 130.0 MB, Reserved: 5002.0 MB
2025-08-16 11:43:20,859 - WARNING - Epoch [18/20] Step [111/125]  acc 0.902287 (0.905715)  loss 0.242171 (0.230535)
GPU memory consumption  GPU Memory: Allocated: 125.4 MB, Reserved: 5002.0 MB
2025-08-16 11:43:26,302 - WARNING - Epoch [18/20] Step [121/125]  acc 0.918304 (0.906162)  loss 0.210527 (0.229789)
GPU memory consumption  GPU Memory: Allocated: 127.6 MB, Reserved: 5002.0 MB
Epoch 18 completed in 0:01:08.388154
2025-08-16 11:43:43,684 - WARNING - Epoch [19/20] Step [1/125]  acc 0.904970 (0.904970)  loss 0.224884 (0.224884)
GPU memory consumption  GPU Memory: Allocated: 127.9 MB, Reserved: 5002.0 MB
2025-08-16 11:43:49,112 - WARNING - Epoch [19/20] Step [11/125]  acc 0.914454 (0.903870)  loss 0.221956 (0.234096)
GPU memory consumption  GPU Memory: Allocated: 131.7 MB, Reserved: 5002.0 MB
2025-08-16 11:43:54,586 - WARNING - Epoch [19/20] Step [21/125]  acc 0.913869 (0.903611)  loss 0.217508 (0.234988)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 5002.0 MB
2025-08-16 11:44:00,057 - WARNING - Epoch [19/20] Step [31/125]  acc 0.898238 (0.903901)  loss 0.247173 (0.234723)
GPU memory consumption  GPU Memory: Allocated: 123.1 MB, Reserved: 5002.0 MB
2025-08-16 11:44:05,493 - WARNING - Epoch [19/20] Step [41/125]  acc 0.895477 (0.903957)  loss 0.246419 (0.234009)
GPU memory consumption  GPU Memory: Allocated: 117.2 MB, Reserved: 5002.0 MB
2025-08-16 11:44:10,988 - WARNING - Epoch [19/20] Step [51/125]  acc 0.908350 (0.904736)  loss 0.239765 (0.232962)
GPU memory consumption  GPU Memory: Allocated: 127.2 MB, Reserved: 5002.0 MB
2025-08-16 11:44:16,394 - WARNING - Epoch [19/20] Step [61/125]  acc 0.892876 (0.904822)  loss 0.242264 (0.232801)
GPU memory consumption  GPU Memory: Allocated: 125.4 MB, Reserved: 5002.0 MB
2025-08-16 11:44:21,851 - WARNING - Epoch [19/20] Step [71/125]  acc 0.915007 (0.905445)  loss 0.217420 (0.231711)
GPU memory consumption  GPU Memory: Allocated: 124.8 MB, Reserved: 5002.0 MB
2025-08-16 11:44:27,407 - WARNING - Epoch [19/20] Step [81/125]  acc 0.896104 (0.905925)  loss 0.243199 (0.230793)
GPU memory consumption  GPU Memory: Allocated: 125.5 MB, Reserved: 5002.0 MB
2025-08-16 11:44:32,836 - WARNING - Epoch [19/20] Step [91/125]  acc 0.903902 (0.905915)  loss 0.239369 (0.230569)
GPU memory consumption  GPU Memory: Allocated: 128.7 MB, Reserved: 5002.0 MB
2025-08-16 11:44:38,240 - WARNING - Epoch [19/20] Step [101/125]  acc 0.908586 (0.905526)  loss 0.214844 (0.231445)
GPU memory consumption  GPU Memory: Allocated: 130.0 MB, Reserved: 5002.0 MB
2025-08-16 11:44:43,731 - WARNING - Epoch [19/20] Step [111/125]  acc 0.908516 (0.905743)  loss 0.231635 (0.231054)
GPU memory consumption  GPU Memory: Allocated: 124.4 MB, Reserved: 5002.0 MB
2025-08-16 11:44:49,180 - WARNING - Epoch [19/20] Step [121/125]  acc 0.898301 (0.905662)  loss 0.247327 (0.230905)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 5002.0 MB
Epoch 19 completed in 0:01:08.224331
2025-08-16 11:45:06,483 - WARNING - Epoch [20/20] Step [1/125]  acc 0.891761 (0.891761)  loss 0.270512 (0.270512)
GPU memory consumption  GPU Memory: Allocated: 119.0 MB, Reserved: 5002.0 MB
2025-08-16 11:45:11,988 - WARNING - Epoch [20/20] Step [11/125]  acc 0.903268 (0.905930)  loss 0.236496 (0.232676)
GPU memory consumption  GPU Memory: Allocated: 129.6 MB, Reserved: 5002.0 MB
2025-08-16 11:45:17,529 - WARNING - Epoch [20/20] Step [21/125]  acc 0.903773 (0.905377)  loss 0.236258 (0.233151)
GPU memory consumption  GPU Memory: Allocated: 130.0 MB, Reserved: 5002.0 MB
2025-08-16 11:45:22,960 - WARNING - Epoch [20/20] Step [31/125]  acc 0.888337 (0.903624)  loss 0.260914 (0.234985)
GPU memory consumption  GPU Memory: Allocated: 118.8 MB, Reserved: 5002.0 MB
2025-08-16 11:45:28,387 - WARNING - Epoch [20/20] Step [41/125]  acc 0.889215 (0.904779)  loss 0.264168 (0.232602)
GPU memory consumption  GPU Memory: Allocated: 120.6 MB, Reserved: 5002.0 MB
2025-08-16 11:45:33,914 - WARNING - Epoch [20/20] Step [51/125]  acc 0.910404 (0.904699)  loss 0.220317 (0.233021)
GPU memory consumption  GPU Memory: Allocated: 121.2 MB, Reserved: 5002.0 MB
2025-08-16 11:45:39,310 - WARNING - Epoch [20/20] Step [61/125]  acc 0.892462 (0.905170)  loss 0.264202 (0.232934)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 5002.0 MB
2025-08-16 11:45:44,860 - WARNING - Epoch [20/20] Step [71/125]  acc 0.901489 (0.905521)  loss 0.236609 (0.231790)
GPU memory consumption  GPU Memory: Allocated: 127.4 MB, Reserved: 5002.0 MB
2025-08-16 11:45:50,326 - WARNING - Epoch [20/20] Step [81/125]  acc 0.910932 (0.905906)  loss 0.206568 (0.230802)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 5002.0 MB
2025-08-16 11:45:55,691 - WARNING - Epoch [20/20] Step [91/125]  acc 0.917229 (0.905980)  loss 0.211923 (0.230766)
GPU memory consumption  GPU Memory: Allocated: 134.0 MB, Reserved: 5002.0 MB
2025-08-16 11:46:01,197 - WARNING - Epoch [20/20] Step [101/125]  acc 0.914861 (0.906060)  loss 0.202179 (0.230314)
GPU memory consumption  GPU Memory: Allocated: 127.9 MB, Reserved: 5002.0 MB
2025-08-16 11:46:06,670 - WARNING - Epoch [20/20] Step [111/125]  acc 0.911525 (0.906092)  loss 0.221782 (0.230118)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 5002.0 MB
2025-08-16 11:46:12,064 - WARNING - Epoch [20/20] Step [121/125]  acc 0.909808 (0.906118)  loss 0.221775 (0.229817)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 5002.0 MB
Epoch 20 completed in 0:01:08.328767
2025-08-16 11:46:28,857 - INFO - DARTS search completed in 1666.63s
2025-08-16 11:46:28,857 - INFO - 
============================================================
2025-08-16 11:46:28,858 - INFO - Layer layer_0 Expert Selection:
2025-08-16 11:46:28,858 - INFO -   Expert 0: GINE (α=0.3317)
2025-08-16 11:46:28,858 - INFO -   Expert 1: CustomGatedGCN (α=0.3326)
2025-08-16 11:46:28,858 - INFO -   Expert 2: GATV2 (α=0.3358) ← SELECTED
2025-08-16 11:46:28,858 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-16 11:46:28,858 - INFO - ============================================================

2025-08-16 11:46:28,858 - INFO - 
============================================================
2025-08-16 11:46:28,858 - INFO - Layer layer_1 Expert Selection:
2025-08-16 11:46:28,858 - INFO -   Expert 0: GINE (α=0.3374) ← SELECTED
2025-08-16 11:46:28,858 - INFO -   Expert 1: CustomGatedGCN (α=0.3374)
2025-08-16 11:46:28,858 - INFO -   Expert 2: GATV2 (α=0.3252)
2025-08-16 11:46:28,858 - INFO - Selected Expert Index: 0 (GINE)
2025-08-16 11:46:28,858 - INFO - ============================================================

2025-08-16 11:46:28,858 - INFO - 
============================================================
2025-08-16 11:46:28,858 - INFO - Layer layer_2 Expert Selection:
2025-08-16 11:46:28,858 - INFO -   Expert 0: GINE (α=0.3064)
2025-08-16 11:46:28,858 - INFO -   Expert 1: CustomGatedGCN (α=0.3437)
2025-08-16 11:46:28,858 - INFO -   Expert 2: GATV2 (α=0.3498) ← SELECTED
2025-08-16 11:46:28,858 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-16 11:46:28,859 - INFO - ============================================================

2025-08-16 11:46:28,859 - INFO - 
============================================================
2025-08-16 11:46:28,859 - INFO - Layer layer_3 Expert Selection:
2025-08-16 11:46:28,859 - INFO -   Expert 0: GINE (α=0.3114)
2025-08-16 11:46:28,859 - INFO -   Expert 1: CustomGatedGCN (α=0.3763) ← SELECTED
2025-08-16 11:46:28,859 - INFO -   Expert 2: GATV2 (α=0.3122)
2025-08-16 11:46:28,859 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 11:46:28,859 - INFO - ============================================================

2025-08-16 11:46:28,859 - INFO - 
============================================================
2025-08-16 11:46:28,859 - INFO - Layer layer_4 Expert Selection:
2025-08-16 11:46:28,859 - INFO -   Expert 0: GINE (α=0.3115)
2025-08-16 11:46:28,859 - INFO -   Expert 1: CustomGatedGCN (α=0.3857) ← SELECTED
2025-08-16 11:46:28,859 - INFO -   Expert 2: GATV2 (α=0.3028)
2025-08-16 11:46:28,859 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-08-16 11:46:28,859 - INFO - ============================================================

2025-08-16 11:46:28,859 - INFO - 
============================================================
2025-08-16 11:46:28,859 - INFO - Layer layer_5 Expert Selection:
2025-08-16 11:46:28,859 - INFO -   Expert 0: GINE (α=0.3110)
2025-08-16 11:46:28,859 - INFO -   Expert 1: CustomGatedGCN (α=0.3410)
2025-08-16 11:46:28,859 - INFO -   Expert 2: GATV2 (α=0.3480) ← SELECTED
2025-08-16 11:46:28,859 - INFO - Selected Expert Index: 2 (GATV2)
2025-08-16 11:46:28,859 - INFO - ============================================================

=== MODEL PARAMETER COMPARISON ===
Original DARTS model parameters: 487,369
2025-08-16 11:46:29,052 - INFO - Layer 0: Using ONLY Expert 2 (GATV2)
2025-08-16 11:46:29,053 - INFO - DiscreteNASLayer 0: Using ONLY Expert 2 (GATV2)
2025-08-16 11:46:29,058 - INFO - Layer 1: Using ONLY Expert 0 (GINE)
2025-08-16 11:46:29,058 - INFO - DiscreteNASLayer 1: Using ONLY Expert 0 (GINE)
2025-08-16 11:46:29,060 - INFO - Layer 2: Using ONLY Expert 2 (GATV2)
2025-08-16 11:46:29,060 - INFO - DiscreteNASLayer 2: Using ONLY Expert 2 (GATV2)
2025-08-16 11:46:29,063 - INFO - Layer 3: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 11:46:29,063 - INFO - DiscreteNASLayer 3: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 11:46:29,066 - INFO - Layer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 11:46:29,066 - INFO - DiscreteNASLayer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-08-16 11:46:29,069 - INFO - Layer 5: Using ONLY Expert 2 (GATV2)
2025-08-16 11:46:29,069 - INFO - DiscreteNASLayer 5: Using ONLY Expert 2 (GATV2)
Fresh discrete model parameters: 323,895
Parameter difference: -163,474
✓ Used cfg.share.dim_in (raw input) instead of self.encoder.dim_in (processed)
✓ Fresh discrete model with correct input dimensions
2025-08-16 11:46:29,079 - INFO - Replaced inner model with discrete version
2025-08-16 11:46:29,080 - INFO - Creating fresh optimizer/scheduler for discrete model...
2025-08-16 11:46:29,082 - INFO - Fresh optimizer created: AdamW
2025-08-16 11:46:29,082 - INFO - Fresh scheduler created: LambdaLR
2025-08-16 11:46:29,082 - INFO - Discrete model parameters: 323,895
2025-08-16 11:46:29,082 - INFO - ============================================================
2025-08-16 11:46:29,082 - INFO - PHASE 2: DISCRETE TRAINING WITH UNCERTAINTY
2025-08-16 11:46:29,082 - INFO - ============================================================
2025-08-16 11:46:29,082 - INFO - === Epoch 0 ===
2025-08-16 11:47:25,094 - INFO - train: {'epoch': 0, 'time_epoch': 54.59166, 'eta': 5404.57418, 'eta_hours': 1.50127, 'loss': 0.20325744, 'lr': 0.0, 'params': 323895, 'time_iter': 0.17441, 'accuracy': 0.17652, 'precision': 0.17652, 'recall': 1.0, 'f1': 0.30007, 'auc': 0.39978, 'accuracy-SBM': 0.5}
2025-08-16 11:47:25,117 - INFO - ...computing epoch stats took: 1.44s
2025-08-16 11:47:30,255 - INFO - val: {'epoch': 0, 'time_epoch': 4.88974, 'loss': 0.20149582, 'lr': 0, 'params': 323895, 'time_iter': 0.07761, 'accuracy': 0.17702, 'precision': 0.17702, 'recall': 1.0, 'f1': 0.3008, 'auc': 0.38431, 'accuracy-SBM': 0.5}
2025-08-16 11:47:30,277 - INFO - ...computing epoch stats took: 0.27s
2025-08-16 11:47:36,947 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 11:47:37,192 - INFO - test: {'epoch': 0, 'time_epoch': 4.96605, 'loss': 0.20070492, 'lr': 0, 'params': 323895, 'time_iter': 0.07883, 'accuracy': 0.17622, 'precision': 0.17622, 'recall': 1.0, 'f1': 0.29964, 'auc': 0.3944, 'accuracy-SBM': 0.5}
2025-08-16 11:47:37,199 - INFO - ...computing epoch stats took: 0.25s
2025-08-16 11:47:37,200 - INFO - > Epoch 0: took 68.1s (avg 68.1s) | Best so far: epoch 0	train_loss: 0.2033 train_accuracy-SBM: 0.5000	val_loss: 0.2015 val_accuracy-SBM: 0.5000	test_loss: 0.2007 test_accuracy-SBM: 0.5000
2025-08-16 11:47:37,200 - INFO - === Epoch 1 ===
2025-08-16 11:48:33,022 - INFO - train: {'epoch': 1, 'time_epoch': 54.39247, 'eta': 5340.22205, 'eta_hours': 1.4834, 'loss': 0.16681292, 'lr': 0.0001, 'params': 323895, 'time_iter': 0.17378, 'accuracy': 0.77522, 'precision': 0.43234, 'recall': 0.87356, 'f1': 0.57842, 'auc': 0.87994, 'accuracy-SBM': 0.81385}
2025-08-16 11:48:33,027 - INFO - ...computing epoch stats took: 1.43s
2025-08-16 11:48:38,067 - INFO - val: {'epoch': 1, 'time_epoch': 4.60688, 'loss': 0.16351904, 'lr': 0, 'params': 323895, 'time_iter': 0.07313, 'accuracy': 0.90379, 'precision': 0.79489, 'recall': 0.61529, 'f1': 0.69366, 'auc': 0.91631, 'accuracy-SBM': 0.79057}
2025-08-16 11:48:38,070 - INFO - ...computing epoch stats took: 0.43s
2025-08-16 11:48:45,285 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 11:48:45,706 - INFO - test: {'epoch': 1, 'time_epoch': 4.71228, 'loss': 0.16276352, 'lr': 0, 'params': 323895, 'time_iter': 0.0748, 'accuracy': 0.9042, 'precision': 0.79412, 'recall': 0.61606, 'f1': 0.69384, 'auc': 0.91514, 'accuracy-SBM': 0.79094}
2025-08-16 11:48:45,710 - INFO - ...computing epoch stats took: 0.42s
2025-08-16 11:48:45,710 - INFO - > Epoch 1: took 68.5s (avg 68.3s) | Best so far: epoch 1	train_loss: 0.1668 train_accuracy-SBM: 0.8138	val_loss: 0.1635 val_accuracy-SBM: 0.7906	test_loss: 0.1628 test_accuracy-SBM: 0.7909
2025-08-16 11:48:45,711 - INFO - === Epoch 2 ===
2025-08-16 11:49:40,394 - INFO - train: {'epoch': 2, 'time_epoch': 54.3177, 'eta': 5280.09224, 'eta_hours': 1.46669, 'loss': 0.1440644, 'lr': 0.0002, 'params': 323895, 'time_iter': 0.17354, 'accuracy': 0.85359, 'precision': 0.55538, 'recall': 0.85526, 'f1': 0.67344, 'auc': 0.89693, 'accuracy-SBM': 0.85425}
2025-08-16 11:49:40,398 - INFO - ...computing epoch stats took: 0.36s
2025-08-16 11:49:45,434 - INFO - val: {'epoch': 2, 'time_epoch': 4.62511, 'loss': 0.18110489, 'lr': 0, 'params': 323895, 'time_iter': 0.07341, 'accuracy': 0.864, 'precision': 0.78407, 'recall': 0.31977, 'f1': 0.45427, 'auc': 0.91259, 'accuracy-SBM': 0.65041}
2025-08-16 11:49:45,436 - INFO - ...computing epoch stats took: 0.41s
2025-08-16 11:49:52,158 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 11:49:52,576 - INFO - test: {'epoch': 2, 'time_epoch': 4.70019, 'loss': 0.17986717, 'lr': 0, 'params': 323895, 'time_iter': 0.07461, 'accuracy': 0.8653, 'precision': 0.78173, 'recall': 0.32692, 'f1': 0.46103, 'auc': 0.91158, 'accuracy-SBM': 0.6537}
2025-08-16 11:49:52,578 - INFO - ...computing epoch stats took: 0.42s
2025-08-16 11:49:52,578 - INFO - > Epoch 2: took 66.9s (avg 67.8s) | Best so far: epoch 1	train_loss: 0.1668 train_accuracy-SBM: 0.8138	val_loss: 0.1635 val_accuracy-SBM: 0.7906	test_loss: 0.1628 test_accuracy-SBM: 0.7909
2025-08-16 11:49:52,578 - INFO - === Epoch 3 ===
2025-08-16 11:50:48,378 - INFO - train: {'epoch': 3, 'time_epoch': 54.4496, 'eta': 5226.03422, 'eta_hours': 1.45168, 'loss': 0.12631364, 'lr': 0.0003, 'params': 323895, 'time_iter': 0.17396, 'accuracy': 0.85632, 'precision': 0.56069, 'recall': 0.85926, 'f1': 0.67859, 'auc': 0.91277, 'accuracy-SBM': 0.85748}
2025-08-16 11:50:53,384 - INFO - val: {'epoch': 3, 'time_epoch': 4.58762, 'loss': 0.24852075, 'lr': 0, 'params': 323895, 'time_iter': 0.07282, 'accuracy': 0.82329, 'precision': 0.78462, 'recall': 0.00243, 'f1': 0.00484, 'auc': 0.89463, 'accuracy-SBM': 0.50114}
2025-08-16 11:51:00,049 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 11:51:00,462 - INFO - test: {'epoch': 3, 'time_epoch': 4.67419, 'loss': 0.24766184, 'lr': 0, 'params': 323895, 'time_iter': 0.07419, 'accuracy': 0.82416, 'precision': 0.84733, 'recall': 0.00264, 'f1': 0.00527, 'auc': 0.89462, 'accuracy-SBM': 0.50127}
2025-08-16 11:51:00,464 - INFO - > Epoch 3: took 67.9s (avg 67.8s) | Best so far: epoch 1	train_loss: 0.1668 train_accuracy-SBM: 0.8138	val_loss: 0.1635 val_accuracy-SBM: 0.7906	test_loss: 0.1628 test_accuracy-SBM: 0.7909
2025-08-16 11:51:00,465 - INFO - === Epoch 4 ===
2025-08-16 11:51:57,256 - INFO - train: {'epoch': 4, 'time_epoch': 54.35966, 'eta': 5170.11067, 'eta_hours': 1.43614, 'loss': 0.1131295, 'lr': 0.0004, 'params': 323895, 'time_iter': 0.17367, 'accuracy': 0.85836, 'precision': 0.56485, 'recall': 0.86044, 'f1': 0.682, 'auc': 0.92355, 'accuracy-SBM': 0.85918}
2025-08-16 11:52:02,318 - INFO - val: {'epoch': 4, 'time_epoch': 4.62981, 'loss': 0.1538365, 'lr': 0, 'params': 323895, 'time_iter': 0.07349, 'accuracy': 0.89059, 'precision': 0.77826, 'recall': 0.53409, 'f1': 0.63346, 'auc': 0.91184, 'accuracy-SBM': 0.75068}
2025-08-16 11:52:09,042 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 11:52:09,469 - INFO - test: {'epoch': 4, 'time_epoch': 4.70627, 'loss': 0.15257982, 'lr': 0, 'params': 323895, 'time_iter': 0.0747, 'accuracy': 0.89143, 'precision': 0.77911, 'recall': 0.53578, 'f1': 0.63493, 'auc': 0.9116, 'accuracy-SBM': 0.75164}
2025-08-16 11:52:09,471 - INFO - > Epoch 4: took 69.0s (avg 68.1s) | Best so far: epoch 1	train_loss: 0.1668 train_accuracy-SBM: 0.8138	val_loss: 0.1635 val_accuracy-SBM: 0.7906	test_loss: 0.1628 test_accuracy-SBM: 0.7909
2025-08-16 11:52:09,471 - INFO - === Epoch 5 ===
2025-08-16 11:53:06,534 - INFO - train: {'epoch': 5, 'time_epoch': 54.49925, 'eta': 5116.89528, 'eta_hours': 1.42136, 'loss': 0.10462306, 'lr': 0.0005, 'params': 323895, 'time_iter': 0.17412, 'accuracy': 0.86061, 'precision': 0.56973, 'recall': 0.85925, 'f1': 0.68516, 'auc': 0.92988, 'accuracy-SBM': 0.86008}
2025-08-16 11:53:11,468 - INFO - val: {'epoch': 5, 'time_epoch': 4.66313, 'loss': 0.11506717, 'lr': 0, 'params': 323895, 'time_iter': 0.07402, 'accuracy': 0.74875, 'precision': 0.40916, 'recall': 0.94445, 'f1': 0.57097, 'auc': 0.93451, 'accuracy-SBM': 0.82555}
2025-08-16 11:53:18,178 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 11:53:18,634 - INFO - test: {'epoch': 5, 'time_epoch': 4.71902, 'loss': 0.11361214, 'lr': 0, 'params': 323895, 'time_iter': 0.07491, 'accuracy': 0.7537, 'precision': 0.41288, 'recall': 0.94238, 'f1': 0.57419, 'auc': 0.93464, 'accuracy-SBM': 0.82786}
2025-08-16 11:53:18,636 - INFO - > Epoch 5: took 69.2s (avg 68.3s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 11:53:18,636 - INFO - === Epoch 6 ===
2025-08-16 11:54:15,633 - INFO - train: {'epoch': 6, 'time_epoch': 54.39575, 'eta': 5061.93795, 'eta_hours': 1.40609, 'loss': 0.0998815, 'lr': 0.00049986, 'params': 323895, 'time_iter': 0.17379, 'accuracy': 0.86033, 'precision': 0.56893, 'recall': 0.8615, 'f1': 0.68529, 'auc': 0.9337, 'accuracy-SBM': 0.86079}
2025-08-16 11:54:20,817 - INFO - val: {'epoch': 6, 'time_epoch': 4.76555, 'loss': 0.35640313, 'lr': 0, 'params': 323895, 'time_iter': 0.07564, 'accuracy': 0.82304, 'precision': 0.88889, 'recall': 0.00038, 'f1': 0.00076, 'auc': 0.91029, 'accuracy-SBM': 0.50019}
2025-08-16 11:54:27,510 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 11:54:27,924 - INFO - test: {'epoch': 6, 'time_epoch': 4.75874, 'loss': 0.35522724, 'lr': 0, 'params': 323895, 'time_iter': 0.07554, 'accuracy': 0.82384, 'precision': 0.88889, 'recall': 0.00038, 'f1': 0.00076, 'auc': 0.90974, 'accuracy-SBM': 0.50019}
2025-08-16 11:54:27,928 - INFO - > Epoch 6: took 69.3s (avg 68.4s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 11:54:27,928 - INFO - === Epoch 7 ===
2025-08-16 11:55:23,217 - INFO - train: {'epoch': 7, 'time_epoch': 54.93599, 'eta': 5013.33379, 'eta_hours': 1.39259, 'loss': 0.09717932, 'lr': 0.00049945, 'params': 323895, 'time_iter': 0.17551, 'accuracy': 0.86045, 'precision': 0.56915, 'recall': 0.86193, 'f1': 0.68559, 'auc': 0.9357, 'accuracy-SBM': 0.86103}
2025-08-16 11:55:28,122 - INFO - val: {'epoch': 7, 'time_epoch': 4.64964, 'loss': 0.16896934, 'lr': 0, 'params': 323895, 'time_iter': 0.0738, 'accuracy': 0.48304, 'precision': 0.25409, 'recall': 0.99209, 'f1': 0.40457, 'auc': 0.92949, 'accuracy-SBM': 0.68282}
2025-08-16 11:55:34,782 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 11:55:35,047 - INFO - test: {'epoch': 7, 'time_epoch': 4.71196, 'loss': 0.16693157, 'lr': 0, 'params': 323895, 'time_iter': 0.07479, 'accuracy': 0.48839, 'precision': 0.25517, 'recall': 0.99181, 'f1': 0.40591, 'auc': 0.92968, 'accuracy-SBM': 0.68625}
2025-08-16 11:55:35,051 - INFO - > Epoch 7: took 67.1s (avg 68.2s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 11:55:35,051 - INFO - === Epoch 8 ===
2025-08-16 11:56:31,962 - INFO - train: {'epoch': 8, 'time_epoch': 54.41052, 'eta': 4958.00948, 'eta_hours': 1.37722, 'loss': 0.09551524, 'lr': 0.00049877, 'params': 323895, 'time_iter': 0.17384, 'accuracy': 0.85993, 'precision': 0.56797, 'recall': 0.8627, 'f1': 0.68498, 'auc': 0.93687, 'accuracy-SBM': 0.86102}
2025-08-16 11:56:37,023 - INFO - val: {'epoch': 8, 'time_epoch': 4.64608, 'loss': 0.40308356, 'lr': 0, 'params': 323895, 'time_iter': 0.07375, 'accuracy': 0.8249, 'precision': 0.77737, 'recall': 0.01522, 'f1': 0.02986, 'auc': 0.89238, 'accuracy-SBM': 0.50714}
2025-08-16 11:56:43,720 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 11:56:44,146 - INFO - test: {'epoch': 8, 'time_epoch': 4.70942, 'loss': 0.4019336, 'lr': 0, 'params': 323895, 'time_iter': 0.07475, 'accuracy': 0.82558, 'precision': 0.79315, 'recall': 0.01379, 'f1': 0.02711, 'auc': 0.89244, 'accuracy-SBM': 0.50651}
2025-08-16 11:56:44,148 - INFO - > Epoch 8: took 69.1s (avg 68.3s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 11:56:44,148 - INFO - === Epoch 9 ===
2025-08-16 11:57:41,119 - INFO - train: {'epoch': 9, 'time_epoch': 54.40796, 'eta': 4902.84487, 'eta_hours': 1.3619, 'loss': 0.09439795, 'lr': 0.00049782, 'params': 323895, 'time_iter': 0.17383, 'accuracy': 0.86018, 'precision': 0.56845, 'recall': 0.86327, 'f1': 0.6855, 'auc': 0.93752, 'accuracy-SBM': 0.86139}
2025-08-16 11:57:46,210 - INFO - val: {'epoch': 9, 'time_epoch': 4.64347, 'loss': 0.18168297, 'lr': 0, 'params': 323895, 'time_iter': 0.07371, 'accuracy': 0.88329, 'precision': 0.75121, 'recall': 0.50939, 'f1': 0.6071, 'auc': 0.90472, 'accuracy-SBM': 0.73655}
2025-08-16 11:57:52,931 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 11:57:53,366 - INFO - test: {'epoch': 9, 'time_epoch': 4.76597, 'loss': 0.18157799, 'lr': 0, 'params': 323895, 'time_iter': 0.07565, 'accuracy': 0.8838, 'precision': 0.75218, 'recall': 0.50798, 'f1': 0.60642, 'auc': 0.90343, 'accuracy-SBM': 0.73609}
2025-08-16 11:57:53,369 - INFO - > Epoch 9: took 69.2s (avg 68.4s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 11:57:53,369 - INFO - === Epoch 10 ===
2025-08-16 11:58:49,124 - INFO - train: {'epoch': 10, 'time_epoch': 54.35547, 'eta': 4847.39314, 'eta_hours': 1.3465, 'loss': 0.09360576, 'lr': 0.00049659, 'params': 323895, 'time_iter': 0.17366, 'accuracy': 0.86034, 'precision': 0.56865, 'recall': 0.86482, 'f1': 0.68614, 'auc': 0.93814, 'accuracy-SBM': 0.8621}
2025-08-16 11:58:54,187 - INFO - val: {'epoch': 10, 'time_epoch': 4.64873, 'loss': 0.35579296, 'lr': 0, 'params': 323895, 'time_iter': 0.07379, 'accuracy': 0.83796, 'precision': 0.87806, 'recall': 0.09828, 'f1': 0.17678, 'auc': 0.885, 'accuracy-SBM': 0.54767}
2025-08-16 11:59:00,911 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 11:59:01,321 - INFO - test: {'epoch': 10, 'time_epoch': 4.71191, 'loss': 0.35412963, 'lr': 0, 'params': 323895, 'time_iter': 0.07479, 'accuracy': 0.8383, 'precision': 0.87886, 'recall': 0.09557, 'f1': 0.17239, 'auc': 0.88488, 'accuracy-SBM': 0.54638}
2025-08-16 11:59:01,323 - INFO - > Epoch 10: took 68.0s (avg 68.4s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 11:59:01,323 - INFO - === Epoch 11 ===
2025-08-16 11:59:57,160 - INFO - train: {'epoch': 11, 'time_epoch': 54.45901, 'eta': 4792.88348, 'eta_hours': 1.33136, 'loss': 0.09316427, 'lr': 0.00049509, 'params': 323895, 'time_iter': 0.17399, 'accuracy': 0.8605, 'precision': 0.569, 'recall': 0.8646, 'f1': 0.68633, 'auc': 0.93831, 'accuracy-SBM': 0.86211}
2025-08-16 12:00:02,245 - INFO - val: {'epoch': 11, 'time_epoch': 4.65512, 'loss': 0.23009481, 'lr': 0, 'params': 323895, 'time_iter': 0.07389, 'accuracy': 0.8773, 'precision': 0.86435, 'recall': 0.36398, 'f1': 0.51225, 'auc': 0.90514, 'accuracy-SBM': 0.67585}
2025-08-16 12:00:09,021 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:00:09,444 - INFO - test: {'epoch': 11, 'time_epoch': 4.72263, 'loss': 0.22955837, 'lr': 0, 'params': 323895, 'time_iter': 0.07496, 'accuracy': 0.87814, 'precision': 0.86345, 'recall': 0.36646, 'f1': 0.51454, 'auc': 0.90559, 'accuracy-SBM': 0.67703}
2025-08-16 12:00:09,446 - INFO - > Epoch 11: took 68.1s (avg 68.4s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 12:00:09,446 - INFO - === Epoch 12 ===
2025-08-16 12:01:06,513 - INFO - train: {'epoch': 12, 'time_epoch': 54.50473, 'eta': 4738.68755, 'eta_hours': 1.3163, 'loss': 0.09272086, 'lr': 0.00049333, 'params': 323895, 'time_iter': 0.17414, 'accuracy': 0.86012, 'precision': 0.56811, 'recall': 0.86555, 'f1': 0.68597, 'auc': 0.93858, 'accuracy-SBM': 0.86225}
2025-08-16 12:01:11,447 - INFO - val: {'epoch': 12, 'time_epoch': 4.67074, 'loss': 0.27590102, 'lr': 0, 'params': 323895, 'time_iter': 0.07414, 'accuracy': 0.18166, 'precision': 0.17784, 'recall': 0.99993, 'f1': 0.30197, 'auc': 0.9213, 'accuracy-SBM': 0.50279}
2025-08-16 12:01:18,147 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:01:18,401 - INFO - test: {'epoch': 12, 'time_epoch': 4.72382, 'loss': 0.27407857, 'lr': 0, 'params': 323895, 'time_iter': 0.07498, 'accuracy': 0.18087, 'precision': 0.17704, 'recall': 1.0, 'f1': 0.30083, 'auc': 0.92178, 'accuracy-SBM': 0.50282}
2025-08-16 12:01:18,403 - INFO - > Epoch 12: took 69.0s (avg 68.4s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 12:01:18,403 - INFO - === Epoch 13 ===
2025-08-16 12:02:14,330 - INFO - train: {'epoch': 13, 'time_epoch': 54.44035, 'eta': 4684.05201, 'eta_hours': 1.30113, 'loss': 0.09251126, 'lr': 0.0004913, 'params': 323895, 'time_iter': 0.17393, 'accuracy': 0.85992, 'precision': 0.5677, 'recall': 0.86553, 'f1': 0.68567, 'auc': 0.93863, 'accuracy-SBM': 0.86212}
2025-08-16 12:02:19,263 - INFO - val: {'epoch': 13, 'time_epoch': 4.65939, 'loss': 0.16015992, 'lr': 0, 'params': 323895, 'time_iter': 0.07396, 'accuracy': 0.53544, 'precision': 0.27458, 'recall': 0.98926, 'f1': 0.42985, 'auc': 0.92885, 'accuracy-SBM': 0.71354}
2025-08-16 12:02:25,960 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:02:26,222 - INFO - test: {'epoch': 13, 'time_epoch': 4.73658, 'loss': 0.15804898, 'lr': 0, 'params': 323895, 'time_iter': 0.07518, 'accuracy': 0.54166, 'precision': 0.27625, 'recall': 0.98835, 'f1': 0.43181, 'auc': 0.92938, 'accuracy-SBM': 0.71723}
2025-08-16 12:02:26,224 - INFO - > Epoch 13: took 67.8s (avg 68.4s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 12:02:26,224 - INFO - === Epoch 14 ===
2025-08-16 12:03:22,484 - INFO - train: {'epoch': 14, 'time_epoch': 54.79306, 'eta': 4631.44118, 'eta_hours': 1.28651, 'loss': 0.09216132, 'lr': 0.00048901, 'params': 323895, 'time_iter': 0.17506, 'accuracy': 0.86044, 'precision': 0.56885, 'recall': 0.86494, 'f1': 0.68632, 'auc': 0.9389, 'accuracy-SBM': 0.86221}
2025-08-16 12:03:27,416 - INFO - val: {'epoch': 14, 'time_epoch': 4.66708, 'loss': 0.13513669, 'lr': 0, 'params': 323895, 'time_iter': 0.07408, 'accuracy': 0.65263, 'precision': 0.3345, 'recall': 0.97253, 'f1': 0.49779, 'auc': 0.93107, 'accuracy-SBM': 0.77818}
2025-08-16 12:03:34,104 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:03:34,353 - INFO - test: {'epoch': 14, 'time_epoch': 4.70636, 'loss': 0.13340509, 'lr': 0, 'params': 323895, 'time_iter': 0.0747, 'accuracy': 0.65706, 'precision': 0.33619, 'recall': 0.97084, 'f1': 0.49944, 'auc': 0.9314, 'accuracy-SBM': 0.78039}
2025-08-16 12:03:34,356 - INFO - > Epoch 14: took 68.1s (avg 68.4s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 12:03:34,356 - INFO - === Epoch 15 ===
2025-08-16 12:04:30,142 - INFO - train: {'epoch': 15, 'time_epoch': 54.34036, 'eta': 4576.18094, 'eta_hours': 1.27116, 'loss': 0.09221559, 'lr': 0.00048645, 'params': 323895, 'time_iter': 0.17361, 'accuracy': 0.86032, 'precision': 0.56859, 'recall': 0.86497, 'f1': 0.68614, 'auc': 0.93872, 'accuracy-SBM': 0.86215}
2025-08-16 12:04:35,216 - INFO - val: {'epoch': 15, 'time_epoch': 4.65009, 'loss': 0.2214192, 'lr': 0, 'params': 323895, 'time_iter': 0.07381, 'accuracy': 0.88604, 'precision': 0.8743, 'recall': 0.41603, 'f1': 0.56379, 'auc': 0.9184, 'accuracy-SBM': 0.70158}
2025-08-16 12:04:41,899 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:04:42,341 - INFO - test: {'epoch': 15, 'time_epoch': 4.70766, 'loss': 0.21996998, 'lr': 0, 'params': 323895, 'time_iter': 0.07472, 'accuracy': 0.88688, 'precision': 0.8746, 'recall': 0.41801, 'f1': 0.56566, 'auc': 0.91866, 'accuracy-SBM': 0.70259}
2025-08-16 12:04:42,343 - INFO - > Epoch 15: took 68.0s (avg 68.3s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 12:04:42,344 - INFO - === Epoch 16 ===
2025-08-16 12:05:39,676 - INFO - train: {'epoch': 16, 'time_epoch': 55.83033, 'eta': 4528.30347, 'eta_hours': 1.25786, 'loss': 0.09187346, 'lr': 0.00048364, 'params': 323895, 'time_iter': 0.17837, 'accuracy': 0.85982, 'precision': 0.56747, 'recall': 0.86579, 'f1': 0.68558, 'auc': 0.93903, 'accuracy-SBM': 0.86217}
2025-08-16 12:05:44,775 - INFO - val: {'epoch': 16, 'time_epoch': 4.67084, 'loss': 0.52103895, 'lr': 0, 'params': 323895, 'time_iter': 0.07414, 'accuracy': 0.82389, 'precision': 0.85526, 'recall': 0.00619, 'f1': 0.0123, 'auc': 0.82234, 'accuracy-SBM': 0.50298}
2025-08-16 12:05:51,843 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:05:52,254 - INFO - test: {'epoch': 16, 'time_epoch': 4.7311, 'loss': 0.51963116, 'lr': 0, 'params': 323895, 'time_iter': 0.0751, 'accuracy': 0.82471, 'precision': 0.90182, 'recall': 0.00591, 'f1': 0.01174, 'auc': 0.82279, 'accuracy-SBM': 0.50288}
2025-08-16 12:05:52,256 - INFO - > Epoch 16: took 69.9s (avg 68.4s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 12:05:52,256 - INFO - === Epoch 17 ===
2025-08-16 12:06:49,219 - INFO - train: {'epoch': 17, 'time_epoch': 54.47596, 'eta': 4473.37242, 'eta_hours': 1.2426, 'loss': 0.0916718, 'lr': 0.00048057, 'params': 323895, 'time_iter': 0.17404, 'accuracy': 0.8611, 'precision': 0.57024, 'recall': 0.86511, 'f1': 0.68739, 'auc': 0.93927, 'accuracy-SBM': 0.86268}
2025-08-16 12:06:54,117 - INFO - val: {'epoch': 17, 'time_epoch': 4.64273, 'loss': 0.12215549, 'lr': 0, 'params': 323895, 'time_iter': 0.07369, 'accuracy': 0.69171, 'precision': 0.36128, 'recall': 0.96565, 'f1': 0.52583, 'auc': 0.93454, 'accuracy-SBM': 0.79922}
2025-08-16 12:07:01,208 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:07:01,660 - INFO - test: {'epoch': 17, 'time_epoch': 4.70273, 'loss': 0.12053461, 'lr': 0, 'params': 323895, 'time_iter': 0.07465, 'accuracy': 0.69665, 'precision': 0.36384, 'recall': 0.96391, 'f1': 0.52828, 'auc': 0.93493, 'accuracy-SBM': 0.8017}
2025-08-16 12:07:01,663 - INFO - > Epoch 17: took 69.4s (avg 68.5s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 12:07:01,663 - INFO - === Epoch 18 ===
2025-08-16 12:07:57,572 - INFO - train: {'epoch': 18, 'time_epoch': 54.50269, 'eta': 4418.60324, 'eta_hours': 1.22739, 'loss': 0.09166879, 'lr': 0.00047725, 'params': 323895, 'time_iter': 0.17413, 'accuracy': 0.86023, 'precision': 0.56836, 'recall': 0.8655, 'f1': 0.68614, 'auc': 0.93915, 'accuracy-SBM': 0.8623}
2025-08-16 12:08:02,457 - INFO - val: {'epoch': 18, 'time_epoch': 4.64804, 'loss': 0.26488267, 'lr': 0, 'params': 323895, 'time_iter': 0.07378, 'accuracy': 0.18204, 'precision': 0.17791, 'recall': 0.99995, 'f1': 0.30207, 'auc': 0.92309, 'accuracy-SBM': 0.50303}
2025-08-16 12:08:09,792 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:08:10,040 - INFO - test: {'epoch': 18, 'time_epoch': 4.70844, 'loss': 0.2635136, 'lr': 0, 'params': 323895, 'time_iter': 0.07474, 'accuracy': 0.18127, 'precision': 0.17712, 'recall': 1.0, 'f1': 0.30093, 'auc': 0.92355, 'accuracy-SBM': 0.50307}
2025-08-16 12:08:10,042 - INFO - > Epoch 18: took 68.4s (avg 68.5s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 12:08:10,042 - INFO - === Epoch 19 ===
2025-08-16 12:09:04,947 - INFO - train: {'epoch': 19, 'time_epoch': 54.45813, 'eta': 4363.68247, 'eta_hours': 1.21213, 'loss': 0.09145043, 'lr': 0.00047368, 'params': 323895, 'time_iter': 0.17399, 'accuracy': 0.86074, 'precision': 0.56934, 'recall': 0.8665, 'f1': 0.68717, 'auc': 0.93935, 'accuracy-SBM': 0.863}
2025-08-16 12:09:10,033 - INFO - val: {'epoch': 19, 'time_epoch': 4.66474, 'loss': 0.54941718, 'lr': 0, 'params': 323895, 'time_iter': 0.07404, 'accuracy': 0.8233, 'precision': 0.94186, 'recall': 0.00193, 'f1': 0.00385, 'auc': 0.88886, 'accuracy-SBM': 0.50095}
2025-08-16 12:09:17,409 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:09:17,803 - INFO - test: {'epoch': 19, 'time_epoch': 4.81577, 'loss': 0.54782325, 'lr': 0, 'params': 323895, 'time_iter': 0.07644, 'accuracy': 0.82405, 'precision': 0.94521, 'recall': 0.00164, 'f1': 0.00328, 'auc': 0.88938, 'accuracy-SBM': 0.50081}
2025-08-16 12:09:17,806 - INFO - > Epoch 19: took 67.8s (avg 68.4s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 12:09:17,807 - INFO - === Epoch 20 ===
2025-08-16 12:10:14,578 - INFO - train: {'epoch': 20, 'time_epoch': 55.27062, 'eta': 4311.86227, 'eta_hours': 1.19774, 'loss': 0.0914584, 'lr': 0.00046987, 'params': 323895, 'time_iter': 0.17658, 'accuracy': 0.8607, 'precision': 0.56929, 'recall': 0.86623, 'f1': 0.68705, 'auc': 0.93934, 'accuracy-SBM': 0.86287}
2025-08-16 12:10:19,512 - INFO - val: {'epoch': 20, 'time_epoch': 4.69133, 'loss': 0.27142456, 'lr': 0, 'params': 323895, 'time_iter': 0.07447, 'accuracy': 0.17711, 'precision': 0.17704, 'recall': 1.0, 'f1': 0.30082, 'auc': 0.91387, 'accuracy-SBM': 0.50005}
2025-08-16 12:10:26,700 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:10:26,937 - INFO - test: {'epoch': 20, 'time_epoch': 4.80365, 'loss': 0.26998699, 'lr': 0, 'params': 323895, 'time_iter': 0.07625, 'accuracy': 0.1765, 'precision': 0.17627, 'recall': 1.0, 'f1': 0.29971, 'auc': 0.91433, 'accuracy-SBM': 0.50017}
2025-08-16 12:10:26,939 - INFO - > Epoch 20: took 69.1s (avg 68.5s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 12:10:26,940 - INFO - === Epoch 21 ===
2025-08-16 12:11:22,603 - INFO - train: {'epoch': 21, 'time_epoch': 55.2367, 'eta': 4259.60814, 'eta_hours': 1.18322, 'loss': 0.09144305, 'lr': 0.00046581, 'params': 323895, 'time_iter': 0.17648, 'accuracy': 0.86036, 'precision': 0.56861, 'recall': 0.86566, 'f1': 0.68637, 'auc': 0.93928, 'accuracy-SBM': 0.86244}
2025-08-16 12:11:27,672 - INFO - val: {'epoch': 21, 'time_epoch': 4.64843, 'loss': 0.113741, 'lr': 0, 'params': 323895, 'time_iter': 0.07378, 'accuracy': 0.90076, 'precision': 0.72781, 'recall': 0.70186, 'f1': 0.7146, 'auc': 0.93434, 'accuracy-SBM': 0.8227}
2025-08-16 12:11:34,564 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:11:34,982 - INFO - test: {'epoch': 21, 'time_epoch': 4.72564, 'loss': 0.1125306, 'lr': 0, 'params': 323895, 'time_iter': 0.07501, 'accuracy': 0.90184, 'precision': 0.72927, 'recall': 0.7045, 'f1': 0.71667, 'auc': 0.93507, 'accuracy-SBM': 0.82428}
2025-08-16 12:11:34,984 - INFO - > Epoch 21: took 68.0s (avg 68.4s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 12:11:34,984 - INFO - === Epoch 22 ===
2025-08-16 12:12:30,715 - INFO - train: {'epoch': 22, 'time_epoch': 54.39236, 'eta': 4204.26797, 'eta_hours': 1.16785, 'loss': 0.09132396, 'lr': 0.00046152, 'params': 323895, 'time_iter': 0.17378, 'accuracy': 0.8611, 'precision': 0.57024, 'recall': 0.86521, 'f1': 0.68742, 'auc': 0.93936, 'accuracy-SBM': 0.86272}
2025-08-16 12:12:35,621 - INFO - val: {'epoch': 22, 'time_epoch': 4.65765, 'loss': 0.21468833, 'lr': 0, 'params': 323895, 'time_iter': 0.07393, 'accuracy': 0.28092, 'precision': 0.19745, 'recall': 0.99917, 'f1': 0.32973, 'auc': 0.92511, 'accuracy-SBM': 0.5628}
2025-08-16 12:12:42,423 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:12:42,661 - INFO - test: {'epoch': 22, 'time_epoch': 4.78381, 'loss': 0.21234157, 'lr': 0, 'params': 323895, 'time_iter': 0.07593, 'accuracy': 0.28438, 'precision': 0.1975, 'recall': 0.99924, 'f1': 0.32981, 'auc': 0.92554, 'accuracy-SBM': 0.56535}
2025-08-16 12:12:42,664 - INFO - > Epoch 22: took 67.7s (avg 68.4s) | Best so far: epoch 5	train_loss: 0.1046 train_accuracy-SBM: 0.8601	val_loss: 0.1151 val_accuracy-SBM: 0.8256	test_loss: 0.1136 test_accuracy-SBM: 0.8279
2025-08-16 12:12:42,665 - INFO - === Epoch 23 ===
2025-08-16 12:13:39,712 - INFO - train: {'epoch': 23, 'time_epoch': 54.46065, 'eta': 4149.22302, 'eta_hours': 1.15256, 'loss': 0.0912668, 'lr': 0.000457, 'params': 323895, 'time_iter': 0.174, 'accuracy': 0.86096, 'precision': 0.56983, 'recall': 0.86638, 'f1': 0.68749, 'auc': 0.93943, 'accuracy-SBM': 0.86309}
2025-08-16 12:13:44,610 - INFO - val: {'epoch': 23, 'time_epoch': 4.64892, 'loss': 0.09594679, 'lr': 0, 'params': 323895, 'time_iter': 0.07379, 'accuracy': 0.81527, 'precision': 0.48836, 'recall': 0.91377, 'f1': 0.63653, 'auc': 0.93827, 'accuracy-SBM': 0.85393}
2025-08-16 12:13:51,439 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:13:51,872 - INFO - test: {'epoch': 23, 'time_epoch': 4.76305, 'loss': 0.09487933, 'lr': 0, 'params': 323895, 'time_iter': 0.0756, 'accuracy': 0.81685, 'precision': 0.48947, 'recall': 0.91339, 'f1': 0.63738, 'auc': 0.93895, 'accuracy-SBM': 0.8548}
2025-08-16 12:13:51,875 - INFO - > Epoch 23: took 69.2s (avg 68.4s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:13:51,875 - INFO - === Epoch 24 ===
2025-08-16 12:14:48,754 - INFO - train: {'epoch': 24, 'time_epoch': 54.35081, 'eta': 4093.89528, 'eta_hours': 1.13719, 'loss': 0.0911562, 'lr': 0.00045225, 'params': 323895, 'time_iter': 0.17364, 'accuracy': 0.86133, 'precision': 0.57076, 'recall': 0.86466, 'f1': 0.68762, 'auc': 0.93959, 'accuracy-SBM': 0.86264}
2025-08-16 12:14:53,802 - INFO - val: {'epoch': 24, 'time_epoch': 4.64836, 'loss': 0.29740115, 'lr': 0, 'params': 323895, 'time_iter': 0.07378, 'accuracy': 0.86588, 'precision': 0.92258, 'recall': 0.26458, 'f1': 0.41123, 'auc': 0.91635, 'accuracy-SBM': 0.6299}
2025-08-16 12:15:00,564 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:15:00,980 - INFO - test: {'epoch': 24, 'time_epoch': 4.70768, 'loss': 0.29583708, 'lr': 0, 'params': 323895, 'time_iter': 0.07473, 'accuracy': 0.86686, 'precision': 0.92217, 'recall': 0.26701, 'f1': 0.41411, 'auc': 0.91629, 'accuracy-SBM': 0.63109}
2025-08-16 12:15:00,984 - INFO - > Epoch 24: took 69.1s (avg 68.5s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:15:00,984 - INFO - === Epoch 25 ===
2025-08-16 12:15:56,880 - INFO - train: {'epoch': 25, 'time_epoch': 54.51106, 'eta': 4039.09879, 'eta_hours': 1.12197, 'loss': 0.09112465, 'lr': 0.00044729, 'params': 323895, 'time_iter': 0.17416, 'accuracy': 0.86122, 'precision': 0.57044, 'recall': 0.86566, 'f1': 0.6877, 'auc': 0.93959, 'accuracy-SBM': 0.86296}
2025-08-16 12:16:01,784 - INFO - val: {'epoch': 25, 'time_epoch': 4.65457, 'loss': 0.21832208, 'lr': 0, 'params': 323895, 'time_iter': 0.07388, 'accuracy': 0.24128, 'precision': 0.18908, 'recall': 0.99919, 'f1': 0.31799, 'auc': 0.9203, 'accuracy-SBM': 0.53872}
2025-08-16 12:16:08,522 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:16:08,760 - INFO - test: {'epoch': 25, 'time_epoch': 4.72388, 'loss': 0.21677453, 'lr': 0, 'params': 323895, 'time_iter': 0.07498, 'accuracy': 0.24183, 'precision': 0.18853, 'recall': 0.99948, 'f1': 0.31723, 'auc': 0.92055, 'accuracy-SBM': 0.53962}
2025-08-16 12:16:08,762 - INFO - > Epoch 25: took 67.8s (avg 68.4s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:16:08,762 - INFO - === Epoch 26 ===
2025-08-16 12:17:04,509 - INFO - train: {'epoch': 26, 'time_epoch': 54.31968, 'eta': 3983.80601, 'eta_hours': 1.10661, 'loss': 0.09106808, 'lr': 0.0004421, 'params': 323895, 'time_iter': 0.17355, 'accuracy': 0.86111, 'precision': 0.57014, 'recall': 0.86642, 'f1': 0.68773, 'auc': 0.93959, 'accuracy-SBM': 0.8632}
2025-08-16 12:17:09,413 - INFO - val: {'epoch': 26, 'time_epoch': 4.65649, 'loss': 0.09923249, 'lr': 0, 'params': 323895, 'time_iter': 0.07391, 'accuracy': 0.79424, 'precision': 0.45969, 'recall': 0.92549, 'f1': 0.61427, 'auc': 0.93685, 'accuracy-SBM': 0.84575}
2025-08-16 12:17:16,203 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:17:16,646 - INFO - test: {'epoch': 26, 'time_epoch': 4.74997, 'loss': 0.09818317, 'lr': 0, 'params': 323895, 'time_iter': 0.0754, 'accuracy': 0.79644, 'precision': 0.46133, 'recall': 0.92549, 'f1': 0.61574, 'auc': 0.93752, 'accuracy-SBM': 0.84716}
2025-08-16 12:17:16,649 - INFO - > Epoch 26: took 67.9s (avg 68.4s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:17:16,649 - INFO - === Epoch 27 ===
2025-08-16 12:18:12,389 - INFO - train: {'epoch': 27, 'time_epoch': 54.30068, 'eta': 3928.5339, 'eta_hours': 1.09126, 'loss': 0.09116667, 'lr': 0.00043671, 'params': 323895, 'time_iter': 0.17348, 'accuracy': 0.86124, 'precision': 0.57056, 'recall': 0.8648, 'f1': 0.68752, 'auc': 0.93945, 'accuracy-SBM': 0.86264}
2025-08-16 12:18:17,550 - INFO - val: {'epoch': 27, 'time_epoch': 4.87359, 'loss': 0.11698971, 'lr': 0, 'params': 323895, 'time_iter': 0.07736, 'accuracy': 0.71305, 'precision': 0.37772, 'recall': 0.9591, 'f1': 0.54199, 'auc': 0.93506, 'accuracy-SBM': 0.80961}
2025-08-16 12:18:24,245 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:18:24,684 - INFO - test: {'epoch': 27, 'time_epoch': 4.75586, 'loss': 0.11567885, 'lr': 0, 'params': 323895, 'time_iter': 0.07549, 'accuracy': 0.71581, 'precision': 0.37886, 'recall': 0.958, 'f1': 0.54298, 'auc': 0.93585, 'accuracy-SBM': 0.81101}
2025-08-16 12:18:24,688 - INFO - > Epoch 27: took 68.0s (avg 68.4s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:18:24,688 - INFO - === Epoch 28 ===
2025-08-16 12:19:21,797 - INFO - train: {'epoch': 28, 'time_epoch': 54.60552, 'eta': 3874.0751, 'eta_hours': 1.07613, 'loss': 0.0910843, 'lr': 0.00043111, 'params': 323895, 'time_iter': 0.17446, 'accuracy': 0.86112, 'precision': 0.57022, 'recall': 0.86566, 'f1': 0.68755, 'auc': 0.93958, 'accuracy-SBM': 0.8629}
2025-08-16 12:19:26,687 - INFO - val: {'epoch': 28, 'time_epoch': 4.63418, 'loss': 0.12518852, 'lr': 0, 'params': 323895, 'time_iter': 0.07356, 'accuracy': 0.66642, 'precision': 0.34318, 'recall': 0.96772, 'f1': 0.50668, 'auc': 0.9322, 'accuracy-SBM': 0.78467}
2025-08-16 12:19:33,411 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:19:33,838 - INFO - test: {'epoch': 28, 'time_epoch': 4.7043, 'loss': 0.1232072, 'lr': 0, 'params': 323895, 'time_iter': 0.07467, 'accuracy': 0.67224, 'precision': 0.34604, 'recall': 0.96641, 'f1': 0.50961, 'auc': 0.93274, 'accuracy-SBM': 0.78786}
2025-08-16 12:19:33,840 - INFO - > Epoch 28: took 69.2s (avg 68.4s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:19:33,840 - INFO - === Epoch 29 ===
2025-08-16 12:20:30,509 - INFO - train: {'epoch': 29, 'time_epoch': 54.24735, 'eta': 3818.77079, 'eta_hours': 1.06077, 'loss': 0.0909291, 'lr': 0.00042531, 'params': 323895, 'time_iter': 0.17331, 'accuracy': 0.8614, 'precision': 0.57077, 'recall': 0.86626, 'f1': 0.68814, 'auc': 0.93979, 'accuracy-SBM': 0.86331}
2025-08-16 12:20:35,565 - INFO - val: {'epoch': 29, 'time_epoch': 4.64544, 'loss': 0.23067959, 'lr': 0, 'params': 323895, 'time_iter': 0.07374, 'accuracy': 0.87538, 'precision': 0.76264, 'recall': 0.42982, 'f1': 0.54979, 'auc': 0.89121, 'accuracy-SBM': 0.70052}
2025-08-16 12:20:42,236 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:20:42,634 - INFO - test: {'epoch': 29, 'time_epoch': 4.72161, 'loss': 0.23218898, 'lr': 0, 'params': 323895, 'time_iter': 0.07495, 'accuracy': 0.87646, 'precision': 0.76383, 'recall': 0.43275, 'f1': 0.55249, 'auc': 0.88922, 'accuracy-SBM': 0.70207}
2025-08-16 12:20:42,636 - INFO - > Epoch 29: took 68.8s (avg 68.5s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:20:42,636 - INFO - === Epoch 30 ===
2025-08-16 12:21:38,387 - INFO - train: {'epoch': 30, 'time_epoch': 54.33544, 'eta': 3763.73074, 'eta_hours': 1.04548, 'loss': 0.09089003, 'lr': 0.00041932, 'params': 323895, 'time_iter': 0.1736, 'accuracy': 0.86113, 'precision': 0.5702, 'recall': 0.86616, 'f1': 0.68769, 'auc': 0.93979, 'accuracy-SBM': 0.8631}
2025-08-16 12:21:43,463 - INFO - val: {'epoch': 30, 'time_epoch': 4.64019, 'loss': 0.20074675, 'lr': 0, 'params': 323895, 'time_iter': 0.07365, 'accuracy': 0.87904, 'precision': 0.77401, 'recall': 0.44733, 'f1': 0.56698, 'auc': 0.90249, 'accuracy-SBM': 0.70962}
2025-08-16 12:21:50,249 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:21:50,657 - INFO - test: {'epoch': 30, 'time_epoch': 4.71236, 'loss': 0.20140949, 'lr': 0, 'params': 323895, 'time_iter': 0.0748, 'accuracy': 0.87987, 'precision': 0.77576, 'recall': 0.44774, 'f1': 0.56778, 'auc': 0.90186, 'accuracy-SBM': 0.71003}
2025-08-16 12:21:50,660 - INFO - > Epoch 30: took 68.0s (avg 68.4s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:21:50,661 - INFO - === Epoch 31 ===
2025-08-16 12:22:45,402 - INFO - train: {'epoch': 31, 'time_epoch': 54.33017, 'eta': 3708.72353, 'eta_hours': 1.0302, 'loss': 0.09083838, 'lr': 0.00041315, 'params': 323895, 'time_iter': 0.17358, 'accuracy': 0.86185, 'precision': 0.5718, 'recall': 0.86557, 'f1': 0.68867, 'auc': 0.93985, 'accuracy-SBM': 0.86331}
2025-08-16 12:22:50,274 - INFO - val: {'epoch': 31, 'time_epoch': 4.63348, 'loss': 0.09827803, 'lr': 0, 'params': 323895, 'time_iter': 0.07355, 'accuracy': 0.80721, 'precision': 0.47681, 'recall': 0.91577, 'f1': 0.62711, 'auc': 0.93669, 'accuracy-SBM': 0.84982}
2025-08-16 12:22:57,141 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:22:57,581 - INFO - test: {'epoch': 31, 'time_epoch': 4.70716, 'loss': 0.09692525, 'lr': 0, 'params': 323895, 'time_iter': 0.07472, 'accuracy': 0.80934, 'precision': 0.47859, 'recall': 0.91548, 'f1': 0.62857, 'auc': 0.9375, 'accuracy-SBM': 0.85106}
2025-08-16 12:22:57,583 - INFO - > Epoch 31: took 66.9s (avg 68.4s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:22:57,583 - INFO - === Epoch 32 ===
2025-08-16 12:23:52,371 - INFO - train: {'epoch': 32, 'time_epoch': 54.3606, 'eta': 3653.81913, 'eta_hours': 1.01495, 'loss': 0.09092705, 'lr': 0.00040679, 'params': 323895, 'time_iter': 0.17368, 'accuracy': 0.86169, 'precision': 0.57154, 'recall': 0.86465, 'f1': 0.68819, 'auc': 0.93972, 'accuracy-SBM': 0.86286}
2025-08-16 12:23:57,271 - INFO - val: {'epoch': 32, 'time_epoch': 4.64685, 'loss': 0.11779711, 'lr': 0, 'params': 323895, 'time_iter': 0.07376, 'accuracy': 0.7044, 'precision': 0.37087, 'recall': 0.96191, 'f1': 0.53534, 'auc': 0.933, 'accuracy-SBM': 0.80546}
2025-08-16 12:24:04,109 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:24:04,559 - INFO - test: {'epoch': 32, 'time_epoch': 4.72524, 'loss': 0.11664813, 'lr': 0, 'params': 323895, 'time_iter': 0.075, 'accuracy': 0.70723, 'precision': 0.37188, 'recall': 0.95991, 'f1': 0.53608, 'auc': 0.93354, 'accuracy-SBM': 0.80654}
2025-08-16 12:24:04,562 - INFO - > Epoch 32: took 67.0s (avg 68.3s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:24:04,562 - INFO - === Epoch 33 ===
2025-08-16 12:25:01,460 - INFO - train: {'epoch': 33, 'time_epoch': 54.61167, 'eta': 3599.4341, 'eta_hours': 0.99984, 'loss': 0.09088297, 'lr': 0.00040027, 'params': 323895, 'time_iter': 0.17448, 'accuracy': 0.8622, 'precision': 0.57263, 'recall': 0.86459, 'f1': 0.68896, 'auc': 0.9398, 'accuracy-SBM': 0.86314}
2025-08-16 12:25:06,505 - INFO - val: {'epoch': 33, 'time_epoch': 4.63055, 'loss': 0.1301883, 'lr': 0, 'params': 323895, 'time_iter': 0.0735, 'accuracy': 0.90185, 'precision': 0.75986, 'recall': 0.65145, 'f1': 0.70149, 'auc': 0.93192, 'accuracy-SBM': 0.80358}
2025-08-16 12:25:13,216 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:25:13,620 - INFO - test: {'epoch': 33, 'time_epoch': 4.70991, 'loss': 0.12967131, 'lr': 0, 'params': 323895, 'time_iter': 0.07476, 'accuracy': 0.90261, 'precision': 0.76187, 'recall': 0.65071, 'f1': 0.70192, 'auc': 0.93272, 'accuracy-SBM': 0.8036}
2025-08-16 12:25:13,623 - INFO - > Epoch 33: took 69.1s (avg 68.4s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:25:13,623 - INFO - === Epoch 34 ===
2025-08-16 12:26:09,228 - INFO - train: {'epoch': 34, 'time_epoch': 54.3069, 'eta': 3544.47011, 'eta_hours': 0.98458, 'loss': 0.09086202, 'lr': 0.00039358, 'params': 323895, 'time_iter': 0.1735, 'accuracy': 0.86177, 'precision': 0.57163, 'recall': 0.86544, 'f1': 0.6885, 'auc': 0.93979, 'accuracy-SBM': 0.86321}
2025-08-16 12:26:14,280 - INFO - val: {'epoch': 34, 'time_epoch': 4.63725, 'loss': 0.18773888, 'lr': 0, 'params': 323895, 'time_iter': 0.07361, 'accuracy': 0.89118, 'precision': 0.84166, 'recall': 0.47456, 'f1': 0.60692, 'auc': 0.92444, 'accuracy-SBM': 0.72768}
2025-08-16 12:26:20,919 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:26:21,336 - INFO - test: {'epoch': 34, 'time_epoch': 4.72015, 'loss': 0.1860557, 'lr': 0, 'params': 323895, 'time_iter': 0.07492, 'accuracy': 0.89238, 'precision': 0.84332, 'recall': 0.47811, 'f1': 0.61025, 'auc': 0.92537, 'accuracy-SBM': 0.72955}
2025-08-16 12:26:21,338 - INFO - > Epoch 34: took 67.7s (avg 68.3s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:26:21,339 - INFO - === Epoch 35 ===
2025-08-16 12:27:17,095 - INFO - train: {'epoch': 35, 'time_epoch': 54.39548, 'eta': 3489.7001, 'eta_hours': 0.96936, 'loss': 0.09084333, 'lr': 0.00038674, 'params': 323895, 'time_iter': 0.17379, 'accuracy': 0.86129, 'precision': 0.5706, 'recall': 0.86552, 'f1': 0.68778, 'auc': 0.93976, 'accuracy-SBM': 0.86295}
2025-08-16 12:27:22,131 - INFO - val: {'epoch': 35, 'time_epoch': 4.64639, 'loss': 0.26614641, 'lr': 0, 'params': 323895, 'time_iter': 0.07375, 'accuracy': 0.87119, 'precision': 0.85825, 'recall': 0.32625, 'f1': 0.47278, 'auc': 0.90047, 'accuracy-SBM': 0.65733}
2025-08-16 12:27:28,803 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:27:29,200 - INFO - test: {'epoch': 35, 'time_epoch': 4.71666, 'loss': 0.26455851, 'lr': 0, 'params': 323895, 'time_iter': 0.07487, 'accuracy': 0.87266, 'precision': 0.85934, 'recall': 0.33166, 'f1': 0.4786, 'auc': 0.90077, 'accuracy-SBM': 0.66002}
2025-08-16 12:27:29,203 - INFO - > Epoch 35: took 67.9s (avg 68.3s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:27:29,203 - INFO - === Epoch 36 ===
2025-08-16 12:28:23,971 - INFO - train: {'epoch': 36, 'time_epoch': 54.34081, 'eta': 3434.85726, 'eta_hours': 0.95413, 'loss': 0.09081282, 'lr': 0.00037974, 'params': 323895, 'time_iter': 0.17361, 'accuracy': 0.86218, 'precision': 0.57264, 'recall': 0.86424, 'f1': 0.68885, 'auc': 0.93985, 'accuracy-SBM': 0.86299}
2025-08-16 12:28:29,017 - INFO - val: {'epoch': 36, 'time_epoch': 4.65425, 'loss': 0.40999903, 'lr': 0, 'params': 323895, 'time_iter': 0.07388, 'accuracy': 0.85122, 'precision': 0.91315, 'recall': 0.17632, 'f1': 0.29557, 'auc': 0.88795, 'accuracy-SBM': 0.58636}
2025-08-16 12:28:35,825 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:28:36,224 - INFO - test: {'epoch': 36, 'time_epoch': 4.71196, 'loss': 0.40579283, 'lr': 0, 'params': 323895, 'time_iter': 0.07479, 'accuracy': 0.85234, 'precision': 0.91097, 'recall': 0.17963, 'f1': 0.30009, 'auc': 0.88893, 'accuracy-SBM': 0.58794}
2025-08-16 12:28:36,226 - INFO - > Epoch 36: took 67.0s (avg 68.3s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:28:36,227 - INFO - === Epoch 37 ===
2025-08-16 12:29:32,827 - INFO - train: {'epoch': 37, 'time_epoch': 54.28259, 'eta': 3379.94585, 'eta_hours': 0.93887, 'loss': 0.09071402, 'lr': 0.00037261, 'params': 323895, 'time_iter': 0.17343, 'accuracy': 0.86113, 'precision': 0.5701, 'recall': 0.86731, 'f1': 0.68798, 'auc': 0.93998, 'accuracy-SBM': 0.86356}
2025-08-16 12:29:37,708 - INFO - val: {'epoch': 37, 'time_epoch': 4.63763, 'loss': 0.10868784, 'lr': 0, 'params': 323895, 'time_iter': 0.07361, 'accuracy': 0.75062, 'precision': 0.41053, 'recall': 0.93771, 'f1': 0.57105, 'auc': 0.92976, 'accuracy-SBM': 0.82404}
2025-08-16 12:29:44,408 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:29:44,835 - INFO - test: {'epoch': 37, 'time_epoch': 4.70328, 'loss': 0.1075274, 'lr': 0, 'params': 323895, 'time_iter': 0.07466, 'accuracy': 0.75398, 'precision': 0.4127, 'recall': 0.93623, 'f1': 0.57288, 'auc': 0.9306, 'accuracy-SBM': 0.82562}
2025-08-16 12:29:44,837 - INFO - > Epoch 37: took 68.6s (avg 68.3s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:29:44,837 - INFO - === Epoch 38 ===
2025-08-16 12:30:39,511 - INFO - train: {'epoch': 38, 'time_epoch': 54.31087, 'eta': 3325.11091, 'eta_hours': 0.92364, 'loss': 0.09072346, 'lr': 0.00036534, 'params': 323895, 'time_iter': 0.17352, 'accuracy': 0.86117, 'precision': 0.5703, 'recall': 0.86601, 'f1': 0.68772, 'auc': 0.94, 'accuracy-SBM': 0.86307}
2025-08-16 12:30:44,556 - INFO - val: {'epoch': 38, 'time_epoch': 4.64689, 'loss': 0.45238166, 'lr': 0, 'params': 323895, 'time_iter': 0.07376, 'accuracy': 0.84307, 'precision': 0.92581, 'recall': 0.12337, 'f1': 0.21772, 'auc': 0.8887, 'accuracy-SBM': 0.56062}
2025-08-16 12:30:51,361 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:30:51,746 - INFO - test: {'epoch': 38, 'time_epoch': 4.71361, 'loss': 0.44864751, 'lr': 0, 'params': 323895, 'time_iter': 0.07482, 'accuracy': 0.84386, 'precision': 0.92593, 'recall': 0.12387, 'f1': 0.21851, 'auc': 0.88899, 'accuracy-SBM': 0.56087}
2025-08-16 12:30:51,749 - INFO - > Epoch 38: took 66.9s (avg 68.3s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:30:51,749 - INFO - === Epoch 39 ===
2025-08-16 12:31:47,481 - INFO - train: {'epoch': 39, 'time_epoch': 54.37037, 'eta': 3270.39142, 'eta_hours': 0.90844, 'loss': 0.09066636, 'lr': 0.00035794, 'params': 323895, 'time_iter': 0.17371, 'accuracy': 0.86164, 'precision': 0.57118, 'recall': 0.86719, 'f1': 0.68873, 'auc': 0.94006, 'accuracy-SBM': 0.86382}
2025-08-16 12:31:52,529 - INFO - val: {'epoch': 39, 'time_epoch': 4.64908, 'loss': 0.15874591, 'lr': 0, 'params': 323895, 'time_iter': 0.07379, 'accuracy': 0.89813, 'precision': 0.8358, 'recall': 0.5283, 'f1': 0.64739, 'auc': 0.93032, 'accuracy-SBM': 0.75299}
2025-08-16 12:31:59,697 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:32:00,097 - INFO - test: {'epoch': 39, 'time_epoch': 4.72441, 'loss': 0.15707635, 'lr': 0, 'params': 323895, 'time_iter': 0.07499, 'accuracy': 0.89955, 'precision': 0.83781, 'recall': 0.53318, 'f1': 0.65165, 'auc': 0.93145, 'accuracy-SBM': 0.75555}
2025-08-16 12:32:00,100 - INFO - > Epoch 39: took 68.4s (avg 68.3s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:32:00,100 - INFO - === Epoch 40 ===
2025-08-16 12:32:54,933 - INFO - train: {'epoch': 40, 'time_epoch': 54.4118, 'eta': 3215.7486, 'eta_hours': 0.89326, 'loss': 0.09058881, 'lr': 0.00035042, 'params': 323895, 'time_iter': 0.17384, 'accuracy': 0.8618, 'precision': 0.57161, 'recall': 0.86643, 'f1': 0.6888, 'auc': 0.94015, 'accuracy-SBM': 0.86362}
2025-08-16 12:32:59,836 - INFO - val: {'epoch': 40, 'time_epoch': 4.65596, 'loss': 0.17542351, 'lr': 0, 'params': 323895, 'time_iter': 0.0739, 'accuracy': 0.47919, 'precision': 0.25254, 'recall': 0.99097, 'f1': 0.40251, 'auc': 0.92407, 'accuracy-SBM': 0.68004}
2025-08-16 12:33:06,707 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:33:06,958 - INFO - test: {'epoch': 40, 'time_epoch': 4.72436, 'loss': 0.17314671, 'lr': 0, 'params': 323895, 'time_iter': 0.07499, 'accuracy': 0.48626, 'precision': 0.25417, 'recall': 0.99016, 'f1': 0.40451, 'auc': 0.92458, 'accuracy-SBM': 0.68431}
2025-08-16 12:33:06,960 - INFO - > Epoch 40: took 66.9s (avg 68.2s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:33:06,960 - INFO - === Epoch 41 ===
2025-08-16 12:34:03,621 - INFO - train: {'epoch': 41, 'time_epoch': 54.31082, 'eta': 3160.97731, 'eta_hours': 0.87805, 'loss': 0.09062688, 'lr': 0.0003428, 'params': 323895, 'time_iter': 0.17352, 'accuracy': 0.86223, 'precision': 0.57252, 'recall': 0.86639, 'f1': 0.68945, 'auc': 0.94013, 'accuracy-SBM': 0.86386}
2025-08-16 12:34:08,470 - INFO - val: {'epoch': 41, 'time_epoch': 4.60709, 'loss': 0.14500557, 'lr': 0, 'params': 323895, 'time_iter': 0.07313, 'accuracy': 0.60927, 'precision': 0.30963, 'recall': 0.98178, 'f1': 0.47079, 'auc': 0.93378, 'accuracy-SBM': 0.75546}
2025-08-16 12:34:18,023 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:34:18,269 - INFO - test: {'epoch': 41, 'time_epoch': 4.67288, 'loss': 0.14399808, 'lr': 0, 'params': 323895, 'time_iter': 0.07417, 'accuracy': 0.61147, 'precision': 0.30978, 'recall': 0.98104, 'f1': 0.47087, 'auc': 0.93405, 'accuracy-SBM': 0.75672}
2025-08-16 12:34:18,271 - INFO - > Epoch 41: took 71.3s (avg 68.3s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:34:18,271 - INFO - === Epoch 42 ===
2025-08-16 12:35:14,075 - INFO - train: {'epoch': 42, 'time_epoch': 54.4349, 'eta': 3106.39193, 'eta_hours': 0.86289, 'loss': 0.09058846, 'lr': 0.00033507, 'params': 323895, 'time_iter': 0.17391, 'accuracy': 0.86173, 'precision': 0.57144, 'recall': 0.86653, 'f1': 0.68871, 'auc': 0.94015, 'accuracy-SBM': 0.86361}
2025-08-16 12:35:19,127 - INFO - val: {'epoch': 42, 'time_epoch': 4.6347, 'loss': 0.24935113, 'lr': 0, 'params': 323895, 'time_iter': 0.07357, 'accuracy': 0.87684, 'precision': 0.89421, 'recall': 0.34512, 'f1': 0.49802, 'auc': 0.92148, 'accuracy-SBM': 0.66817}
2025-08-16 12:35:25,986 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:35:26,394 - INFO - test: {'epoch': 42, 'time_epoch': 4.70662, 'loss': 0.24674631, 'lr': 0, 'params': 323895, 'time_iter': 0.07471, 'accuracy': 0.87828, 'precision': 0.89561, 'recall': 0.35007, 'f1': 0.50338, 'auc': 0.92219, 'accuracy-SBM': 0.67067}
2025-08-16 12:35:26,397 - INFO - > Epoch 42: took 68.1s (avg 68.3s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:35:26,398 - INFO - === Epoch 43 ===
2025-08-16 12:36:23,065 - INFO - train: {'epoch': 43, 'time_epoch': 54.35416, 'eta': 3051.71062, 'eta_hours': 0.8477, 'loss': 0.09066337, 'lr': 0.00032725, 'params': 323895, 'time_iter': 0.17366, 'accuracy': 0.86102, 'precision': 0.56987, 'recall': 0.86729, 'f1': 0.68781, 'auc': 0.94003, 'accuracy-SBM': 0.86349}
2025-08-16 12:36:28,088 - INFO - val: {'epoch': 43, 'time_epoch': 4.61252, 'loss': 0.1311232, 'lr': 0, 'params': 323895, 'time_iter': 0.07321, 'accuracy': 0.89299, 'precision': 0.72045, 'recall': 0.64621, 'f1': 0.68132, 'auc': 0.92245, 'accuracy-SBM': 0.79614}
2025-08-16 12:36:34,935 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:36:35,347 - INFO - test: {'epoch': 43, 'time_epoch': 4.71454, 'loss': 0.13052511, 'lr': 0, 'params': 323895, 'time_iter': 0.07483, 'accuracy': 0.89444, 'precision': 0.72444, 'recall': 0.64709, 'f1': 0.68359, 'auc': 0.9232, 'accuracy-SBM': 0.79722}
2025-08-16 12:36:35,349 - INFO - > Epoch 43: took 69.0s (avg 68.3s) | Best so far: epoch 23	train_loss: 0.0913 train_accuracy-SBM: 0.8631	val_loss: 0.0959 val_accuracy-SBM: 0.8539	test_loss: 0.0949 test_accuracy-SBM: 0.8548
2025-08-16 12:36:35,350 - INFO - === Epoch 44 ===
2025-08-16 12:37:31,960 - INFO - train: {'epoch': 44, 'time_epoch': 54.37928, 'eta': 2997.07456, 'eta_hours': 0.83252, 'loss': 0.09062318, 'lr': 0.00031935, 'params': 323895, 'time_iter': 0.17374, 'accuracy': 0.86153, 'precision': 0.57098, 'recall': 0.86707, 'f1': 0.68854, 'auc': 0.94008, 'accuracy-SBM': 0.86371}
2025-08-16 12:37:37,128 - INFO - val: {'epoch': 44, 'time_epoch': 4.64679, 'loss': 0.09119603, 'lr': 0, 'params': 323895, 'time_iter': 0.07376, 'accuracy': 0.866, 'precision': 0.58217, 'recall': 0.86093, 'f1': 0.69462, 'auc': 0.94056, 'accuracy-SBM': 0.86401}
2025-08-16 12:37:43,831 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:37:44,262 - INFO - test: {'epoch': 44, 'time_epoch': 4.70825, 'loss': 0.08995301, 'lr': 0, 'params': 323895, 'time_iter': 0.07473, 'accuracy': 0.86867, 'precision': 0.5866, 'recall': 0.86279, 'f1': 0.69838, 'auc': 0.94159, 'accuracy-SBM': 0.86636}
2025-08-16 12:37:44,265 - INFO - > Epoch 44: took 68.9s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:37:44,266 - INFO - === Epoch 45 ===
2025-08-16 12:38:40,056 - INFO - train: {'epoch': 45, 'time_epoch': 54.44331, 'eta': 2942.52482, 'eta_hours': 0.81737, 'loss': 0.09061313, 'lr': 0.00031137, 'params': 323895, 'time_iter': 0.17394, 'accuracy': 0.86149, 'precision': 0.57095, 'recall': 0.86629, 'f1': 0.68827, 'auc': 0.9401, 'accuracy-SBM': 0.86337}
2025-08-16 12:38:45,124 - INFO - val: {'epoch': 45, 'time_epoch': 4.65873, 'loss': 0.56064004, 'lr': 0, 'params': 323895, 'time_iter': 0.07395, 'accuracy': 0.83291, 'precision': 0.91622, 'recall': 0.06174, 'f1': 0.11569, 'auc': 0.88263, 'accuracy-SBM': 0.53026}
2025-08-16 12:38:51,932 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:38:52,322 - INFO - test: {'epoch': 45, 'time_epoch': 4.73516, 'loss': 0.5583727, 'lr': 0, 'params': 323895, 'time_iter': 0.07516, 'accuracy': 0.83334, 'precision': 0.92214, 'recall': 0.05924, 'f1': 0.11133, 'auc': 0.88309, 'accuracy-SBM': 0.52909}
2025-08-16 12:38:52,324 - INFO - > Epoch 45: took 68.1s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:38:52,325 - INFO - === Epoch 46 ===
2025-08-16 12:39:49,114 - INFO - train: {'epoch': 46, 'time_epoch': 54.34938, 'eta': 2887.87369, 'eta_hours': 0.80219, 'loss': 0.09054792, 'lr': 0.00030332, 'params': 323895, 'time_iter': 0.17364, 'accuracy': 0.86139, 'precision': 0.57065, 'recall': 0.86725, 'f1': 0.68836, 'auc': 0.94019, 'accuracy-SBM': 0.86369}
2025-08-16 12:39:54,274 - INFO - val: {'epoch': 46, 'time_epoch': 4.72297, 'loss': 0.11069832, 'lr': 0, 'params': 323895, 'time_iter': 0.07497, 'accuracy': 0.89097, 'precision': 0.6757, 'recall': 0.73854, 'f1': 0.70573, 'auc': 0.93043, 'accuracy-SBM': 0.83115}
2025-08-16 12:40:01,094 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:40:01,514 - INFO - test: {'epoch': 46, 'time_epoch': 4.77382, 'loss': 0.10967949, 'lr': 0, 'params': 323895, 'time_iter': 0.07577, 'accuracy': 0.893, 'precision': 0.68095, 'recall': 0.73911, 'f1': 0.70884, 'auc': 0.9315, 'accuracy-SBM': 0.83252}
2025-08-16 12:40:01,518 - INFO - > Epoch 46: took 69.2s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:40:01,518 - INFO - === Epoch 47 ===
2025-08-16 12:40:57,305 - INFO - train: {'epoch': 47, 'time_epoch': 54.47729, 'eta': 2833.37371, 'eta_hours': 0.78705, 'loss': 0.09056491, 'lr': 0.00029522, 'params': 323895, 'time_iter': 0.17405, 'accuracy': 0.86156, 'precision': 0.57105, 'recall': 0.86678, 'f1': 0.6885, 'auc': 0.9402, 'accuracy-SBM': 0.86361}
2025-08-16 12:41:02,354 - INFO - val: {'epoch': 47, 'time_epoch': 4.6474, 'loss': 0.38705306, 'lr': 0, 'params': 323895, 'time_iter': 0.07377, 'accuracy': 0.85209, 'precision': 0.90601, 'recall': 0.18347, 'f1': 0.30514, 'auc': 0.89916, 'accuracy-SBM': 0.58969}
2025-08-16 12:41:09,081 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:41:09,470 - INFO - test: {'epoch': 47, 'time_epoch': 4.72333, 'loss': 0.3873663, 'lr': 0, 'params': 323895, 'time_iter': 0.07497, 'accuracy': 0.85281, 'precision': 0.90633, 'recall': 0.18371, 'f1': 0.30549, 'auc': 0.89857, 'accuracy-SBM': 0.58982}
2025-08-16 12:41:09,473 - INFO - > Epoch 47: took 68.0s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:41:09,474 - INFO - === Epoch 48 ===
2025-08-16 12:42:05,219 - INFO - train: {'epoch': 48, 'time_epoch': 54.39911, 'eta': 2778.79329, 'eta_hours': 0.77189, 'loss': 0.09055983, 'lr': 0.00028707, 'params': 323895, 'time_iter': 0.1738, 'accuracy': 0.86144, 'precision': 0.57078, 'recall': 0.86698, 'f1': 0.68837, 'auc': 0.94013, 'accuracy-SBM': 0.86362}
2025-08-16 12:42:10,309 - INFO - val: {'epoch': 48, 'time_epoch': 4.65887, 'loss': 0.10749486, 'lr': 0, 'params': 323895, 'time_iter': 0.07395, 'accuracy': 0.83511, 'precision': 0.5217, 'recall': 0.82358, 'f1': 0.63877, 'auc': 0.91416, 'accuracy-SBM': 0.83058}
2025-08-16 12:42:17,065 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:42:17,476 - INFO - test: {'epoch': 48, 'time_epoch': 4.7477, 'loss': 0.10838844, 'lr': 0, 'params': 323895, 'time_iter': 0.07536, 'accuracy': 0.83568, 'precision': 0.52156, 'recall': 0.81729, 'f1': 0.63676, 'auc': 0.91277, 'accuracy-SBM': 0.82846}
2025-08-16 12:42:17,478 - INFO - > Epoch 48: took 68.0s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:42:17,479 - INFO - === Epoch 49 ===
2025-08-16 12:43:14,089 - INFO - train: {'epoch': 49, 'time_epoch': 54.32515, 'eta': 2724.14615, 'eta_hours': 0.75671, 'loss': 0.0905968, 'lr': 0.00027887, 'params': 323895, 'time_iter': 0.17356, 'accuracy': 0.86119, 'precision': 0.57021, 'recall': 0.86739, 'f1': 0.68808, 'auc': 0.94006, 'accuracy-SBM': 0.86362}
2025-08-16 12:43:19,120 - INFO - val: {'epoch': 49, 'time_epoch': 4.64181, 'loss': 0.39472889, 'lr': 0, 'params': 323895, 'time_iter': 0.07368, 'accuracy': 0.85365, 'precision': 0.91536, 'recall': 0.1909, 'f1': 0.31592, 'auc': 0.89997, 'accuracy-SBM': 0.59355}
2025-08-16 12:43:25,849 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:43:26,237 - INFO - test: {'epoch': 49, 'time_epoch': 4.70819, 'loss': 0.39385118, 'lr': 0, 'params': 323895, 'time_iter': 0.07473, 'accuracy': 0.85447, 'precision': 0.91478, 'recall': 0.19204, 'f1': 0.31745, 'auc': 0.90008, 'accuracy-SBM': 0.59411}
2025-08-16 12:43:26,239 - INFO - > Epoch 49: took 68.8s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:43:26,239 - INFO - === Epoch 50 ===
2025-08-16 12:44:22,728 - INFO - train: {'epoch': 50, 'time_epoch': 54.24141, 'eta': 2669.43119, 'eta_hours': 0.74151, 'loss': 0.09044516, 'lr': 0.00027064, 'params': 323895, 'time_iter': 0.1733, 'accuracy': 0.86202, 'precision': 0.57206, 'recall': 0.86654, 'f1': 0.68916, 'auc': 0.94031, 'accuracy-SBM': 0.86379}
2025-08-16 12:44:27,783 - INFO - val: {'epoch': 50, 'time_epoch': 4.65519, 'loss': 0.35468574, 'lr': 0, 'params': 323895, 'time_iter': 0.07389, 'accuracy': 0.86214, 'precision': 0.89104, 'recall': 0.25207, 'f1': 0.39297, 'auc': 0.89645, 'accuracy-SBM': 0.62272}
2025-08-16 12:44:34,544 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:44:34,944 - INFO - test: {'epoch': 50, 'time_epoch': 4.7185, 'loss': 0.35338256, 'lr': 0, 'params': 323895, 'time_iter': 0.0749, 'accuracy': 0.86313, 'precision': 0.88954, 'recall': 0.25493, 'f1': 0.39629, 'auc': 0.89666, 'accuracy-SBM': 0.62408}
2025-08-16 12:44:34,946 - INFO - > Epoch 50: took 68.7s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:44:34,946 - INFO - === Epoch 51 ===
2025-08-16 12:45:30,563 - INFO - train: {'epoch': 51, 'time_epoch': 54.31275, 'eta': 2614.80029, 'eta_hours': 0.72633, 'loss': 0.09049446, 'lr': 0.0002624, 'params': 323895, 'time_iter': 0.17352, 'accuracy': 0.8619, 'precision': 0.57184, 'recall': 0.86609, 'f1': 0.68886, 'auc': 0.94022, 'accuracy-SBM': 0.86354}
2025-08-16 12:45:35,449 - INFO - val: {'epoch': 51, 'time_epoch': 4.64023, 'loss': 0.09163696, 'lr': 0, 'params': 323895, 'time_iter': 0.07365, 'accuracy': 0.84798, 'precision': 0.54321, 'recall': 0.88773, 'f1': 0.674, 'auc': 0.94073, 'accuracy-SBM': 0.86358}
2025-08-16 12:45:42,167 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:45:42,597 - INFO - test: {'epoch': 51, 'time_epoch': 4.70927, 'loss': 0.09047085, 'lr': 0, 'params': 323895, 'time_iter': 0.07475, 'accuracy': 0.85078, 'precision': 0.54727, 'recall': 0.88687, 'f1': 0.67686, 'auc': 0.94151, 'accuracy-SBM': 0.86496}
2025-08-16 12:45:42,600 - INFO - > Epoch 51: took 67.7s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:45:42,600 - INFO - === Epoch 52 ===
2025-08-16 12:46:38,366 - INFO - train: {'epoch': 52, 'time_epoch': 54.41183, 'eta': 2560.26926, 'eta_hours': 0.71119, 'loss': 0.09044061, 'lr': 0.00025413, 'params': 323895, 'time_iter': 0.17384, 'accuracy': 0.86176, 'precision': 0.57153, 'recall': 0.86637, 'f1': 0.68872, 'auc': 0.94031, 'accuracy-SBM': 0.86357}
2025-08-16 12:46:43,465 - INFO - val: {'epoch': 52, 'time_epoch': 4.67265, 'loss': 0.0917166, 'lr': 0, 'params': 323895, 'time_iter': 0.07417, 'accuracy': 0.84701, 'precision': 0.54129, 'recall': 0.88992, 'f1': 0.67315, 'auc': 0.94106, 'accuracy-SBM': 0.86385}
2025-08-16 12:46:50,206 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:46:50,624 - INFO - test: {'epoch': 52, 'time_epoch': 4.72936, 'loss': 0.09050928, 'lr': 0, 'params': 323895, 'time_iter': 0.07507, 'accuracy': 0.84979, 'precision': 0.54523, 'recall': 0.88964, 'f1': 0.6761, 'auc': 0.94188, 'accuracy-SBM': 0.86545}
2025-08-16 12:46:50,626 - INFO - > Epoch 52: took 68.0s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:46:50,627 - INFO - === Epoch 53 ===
2025-08-16 12:47:47,497 - INFO - train: {'epoch': 53, 'time_epoch': 54.47435, 'eta': 2505.7959, 'eta_hours': 0.69605, 'loss': 0.09032628, 'lr': 0.00024587, 'params': 323895, 'time_iter': 0.17404, 'accuracy': 0.86279, 'precision': 0.57378, 'recall': 0.86601, 'f1': 0.69024, 'auc': 0.94048, 'accuracy-SBM': 0.86406}
2025-08-16 12:47:52,542 - INFO - val: {'epoch': 53, 'time_epoch': 4.64538, 'loss': 0.36151593, 'lr': 0, 'params': 323895, 'time_iter': 0.07374, 'accuracy': 0.86161, 'precision': 0.86398, 'recall': 0.25903, 'f1': 0.39856, 'auc': 0.89713, 'accuracy-SBM': 0.62513}
2025-08-16 12:47:59,324 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:47:59,726 - INFO - test: {'epoch': 53, 'time_epoch': 4.71352, 'loss': 0.361715, 'lr': 0, 'params': 323895, 'time_iter': 0.07482, 'accuracy': 0.86229, 'precision': 0.86496, 'recall': 0.25893, 'f1': 0.39856, 'auc': 0.89693, 'accuracy-SBM': 0.62514}
2025-08-16 12:47:59,728 - INFO - > Epoch 53: took 69.1s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:47:59,728 - INFO - === Epoch 54 ===
2025-08-16 12:48:56,350 - INFO - train: {'epoch': 54, 'time_epoch': 54.29295, 'eta': 2451.17409, 'eta_hours': 0.68088, 'loss': 0.09037099, 'lr': 0.0002376, 'params': 323895, 'time_iter': 0.17346, 'accuracy': 0.86202, 'precision': 0.57205, 'recall': 0.86679, 'f1': 0.68923, 'auc': 0.94037, 'accuracy-SBM': 0.8639}
2025-08-16 12:49:01,412 - INFO - val: {'epoch': 54, 'time_epoch': 4.64639, 'loss': 0.09301622, 'lr': 0, 'params': 323895, 'time_iter': 0.07375, 'accuracy': 0.86456, 'precision': 0.57961, 'recall': 0.85517, 'f1': 0.69093, 'auc': 0.93788, 'accuracy-SBM': 0.86088}
2025-08-16 12:49:08,125 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:49:08,558 - INFO - test: {'epoch': 54, 'time_epoch': 4.71404, 'loss': 0.09192964, 'lr': 0, 'params': 323895, 'time_iter': 0.07483, 'accuracy': 0.86672, 'precision': 0.58308, 'recall': 0.85505, 'f1': 0.69335, 'auc': 0.9388, 'accuracy-SBM': 0.86213}
2025-08-16 12:49:08,560 - INFO - > Epoch 54: took 68.8s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:49:08,560 - INFO - === Epoch 55 ===
2025-08-16 12:50:05,248 - INFO - train: {'epoch': 55, 'time_epoch': 54.31532, 'eta': 2396.5816, 'eta_hours': 0.66572, 'loss': 0.09039422, 'lr': 0.00022936, 'params': 323895, 'time_iter': 0.17353, 'accuracy': 0.86215, 'precision': 0.57229, 'recall': 0.86696, 'f1': 0.68946, 'auc': 0.94036, 'accuracy-SBM': 0.86403}
2025-08-16 12:50:10,135 - INFO - val: {'epoch': 55, 'time_epoch': 4.64912, 'loss': 0.23110716, 'lr': 0, 'params': 323895, 'time_iter': 0.0738, 'accuracy': 0.24418, 'precision': 0.18973, 'recall': 0.99967, 'f1': 0.31892, 'auc': 0.93229, 'accuracy-SBM': 0.54067}
2025-08-16 12:50:16,835 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:50:17,070 - INFO - test: {'epoch': 55, 'time_epoch': 4.71186, 'loss': 0.23010991, 'lr': 0, 'params': 323895, 'time_iter': 0.07479, 'accuracy': 0.24299, 'precision': 0.18878, 'recall': 0.99962, 'f1': 0.31759, 'auc': 0.93264, 'accuracy-SBM': 0.54038}
2025-08-16 12:50:17,072 - INFO - > Epoch 55: took 68.5s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:50:17,072 - INFO - === Epoch 56 ===
2025-08-16 12:51:13,687 - INFO - train: {'epoch': 56, 'time_epoch': 54.30869, 'eta': 2341.99384, 'eta_hours': 0.65055, 'loss': 0.09026702, 'lr': 0.00022113, 'params': 323895, 'time_iter': 0.17351, 'accuracy': 0.86215, 'precision': 0.57226, 'recall': 0.86746, 'f1': 0.68959, 'auc': 0.94056, 'accuracy-SBM': 0.86423}
2025-08-16 12:51:18,706 - INFO - val: {'epoch': 56, 'time_epoch': 4.62732, 'loss': 0.16903863, 'lr': 0, 'params': 323895, 'time_iter': 0.07345, 'accuracy': 0.89804, 'precision': 0.82461, 'recall': 0.53859, 'f1': 0.65159, 'auc': 0.92841, 'accuracy-SBM': 0.75697}
2025-08-16 12:51:25,560 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:51:25,946 - INFO - test: {'epoch': 56, 'time_epoch': 4.69, 'loss': 0.16780433, 'lr': 0, 'params': 323895, 'time_iter': 0.07444, 'accuracy': 0.8995, 'precision': 0.82825, 'recall': 0.54209, 'f1': 0.65529, 'auc': 0.92946, 'accuracy-SBM': 0.75902}
2025-08-16 12:51:25,948 - INFO - > Epoch 56: took 68.9s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:51:25,948 - INFO - === Epoch 57 ===
2025-08-16 12:52:21,554 - INFO - train: {'epoch': 57, 'time_epoch': 54.3007, 'eta': 2287.40991, 'eta_hours': 0.63539, 'loss': 0.09034765, 'lr': 0.00021293, 'params': 323895, 'time_iter': 0.17348, 'accuracy': 0.86196, 'precision': 0.57199, 'recall': 0.86595, 'f1': 0.68892, 'auc': 0.94041, 'accuracy-SBM': 0.86352}
2025-08-16 12:52:26,604 - INFO - val: {'epoch': 57, 'time_epoch': 4.63476, 'loss': 0.13959512, 'lr': 0, 'params': 323895, 'time_iter': 0.07357, 'accuracy': 0.88796, 'precision': 0.69684, 'recall': 0.64976, 'f1': 0.67248, 'auc': 0.9156, 'accuracy-SBM': 0.79448}
2025-08-16 12:52:33,370 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:52:33,765 - INFO - test: {'epoch': 57, 'time_epoch': 4.70948, 'loss': 0.14038321, 'lr': 0, 'params': 323895, 'time_iter': 0.07475, 'accuracy': 0.88879, 'precision': 0.69913, 'recall': 0.64767, 'f1': 0.67241, 'auc': 0.91549, 'accuracy-SBM': 0.79402}
2025-08-16 12:52:33,768 - INFO - > Epoch 57: took 67.8s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:52:33,768 - INFO - === Epoch 58 ===
2025-08-16 12:53:29,557 - INFO - train: {'epoch': 58, 'time_epoch': 54.40668, 'eta': 2232.90923, 'eta_hours': 0.62025, 'loss': 0.09018116, 'lr': 0.00020478, 'params': 323895, 'time_iter': 0.17382, 'accuracy': 0.86271, 'precision': 0.57346, 'recall': 0.8674, 'f1': 0.69045, 'auc': 0.94069, 'accuracy-SBM': 0.86455}
2025-08-16 12:53:34,600 - INFO - val: {'epoch': 58, 'time_epoch': 4.63798, 'loss': 0.14052082, 'lr': 0, 'params': 323895, 'time_iter': 0.07362, 'accuracy': 0.89851, 'precision': 0.7635, 'recall': 0.61813, 'f1': 0.68317, 'auc': 0.92736, 'accuracy-SBM': 0.78847}
2025-08-16 12:53:41,314 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:53:41,721 - INFO - test: {'epoch': 58, 'time_epoch': 4.69507, 'loss': 0.14022539, 'lr': 0, 'params': 323895, 'time_iter': 0.07452, 'accuracy': 0.89964, 'precision': 0.76745, 'recall': 0.61765, 'f1': 0.68445, 'auc': 0.9283, 'accuracy-SBM': 0.78881}
2025-08-16 12:53:41,724 - INFO - > Epoch 58: took 68.0s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:53:41,724 - INFO - === Epoch 59 ===
2025-08-16 12:54:37,456 - INFO - train: {'epoch': 59, 'time_epoch': 54.36244, 'eta': 2178.38218, 'eta_hours': 0.60511, 'loss': 0.09024766, 'lr': 0.00019668, 'params': 323895, 'time_iter': 0.17368, 'accuracy': 0.86183, 'precision': 0.57159, 'recall': 0.86733, 'f1': 0.68907, 'auc': 0.94054, 'accuracy-SBM': 0.86399}
2025-08-16 12:54:42,369 - INFO - val: {'epoch': 59, 'time_epoch': 4.66651, 'loss': 0.11434335, 'lr': 0, 'params': 323895, 'time_iter': 0.07407, 'accuracy': 0.72083, 'precision': 0.38427, 'recall': 0.95805, 'f1': 0.54853, 'auc': 0.93579, 'accuracy-SBM': 0.81393}
2025-08-16 12:54:49,224 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:54:49,701 - INFO - test: {'epoch': 59, 'time_epoch': 4.70046, 'loss': 0.11303419, 'lr': 0, 'params': 323895, 'time_iter': 0.07461, 'accuracy': 0.72434, 'precision': 0.38609, 'recall': 0.95636, 'f1': 0.5501, 'auc': 0.93642, 'accuracy-SBM': 0.81553}
2025-08-16 12:54:49,705 - INFO - > Epoch 59: took 68.0s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:54:49,705 - INFO - === Epoch 60 ===
2025-08-16 12:55:46,583 - INFO - train: {'epoch': 60, 'time_epoch': 54.57473, 'eta': 2123.99627, 'eta_hours': 0.59, 'loss': 0.09023674, 'lr': 0.00018863, 'params': 323895, 'time_iter': 0.17436, 'accuracy': 0.86229, 'precision': 0.57254, 'recall': 0.86749, 'f1': 0.68981, 'auc': 0.94062, 'accuracy-SBM': 0.86433}
2025-08-16 12:55:51,636 - INFO - val: {'epoch': 60, 'time_epoch': 4.63029, 'loss': 0.09422823, 'lr': 0, 'params': 323895, 'time_iter': 0.0735, 'accuracy': 0.88386, 'precision': 0.63349, 'recall': 0.8161, 'f1': 0.7133, 'auc': 0.93914, 'accuracy-SBM': 0.85727}
2025-08-16 12:55:58,673 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:55:59,098 - INFO - test: {'epoch': 60, 'time_epoch': 4.70675, 'loss': 0.09323972, 'lr': 0, 'params': 323895, 'time_iter': 0.07471, 'accuracy': 0.88625, 'precision': 0.63865, 'recall': 0.81641, 'f1': 0.71667, 'auc': 0.94009, 'accuracy-SBM': 0.8588}
2025-08-16 12:55:59,100 - INFO - > Epoch 60: took 69.4s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:55:59,100 - INFO - === Epoch 61 ===
2025-08-16 12:56:55,813 - INFO - train: {'epoch': 61, 'time_epoch': 54.40421, 'eta': 2069.49974, 'eta_hours': 0.57486, 'loss': 0.09021508, 'lr': 0.00018065, 'params': 323895, 'time_iter': 0.17382, 'accuracy': 0.86226, 'precision': 0.57253, 'recall': 0.86707, 'f1': 0.68967, 'auc': 0.94058, 'accuracy-SBM': 0.86415}
2025-08-16 12:57:00,692 - INFO - val: {'epoch': 61, 'time_epoch': 4.62481, 'loss': 0.1024493, 'lr': 0, 'params': 323895, 'time_iter': 0.07341, 'accuracy': 0.77442, 'precision': 0.43632, 'recall': 0.93978, 'f1': 0.59596, 'auc': 0.93829, 'accuracy-SBM': 0.83932}
2025-08-16 12:57:07,436 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:57:07,843 - INFO - test: {'epoch': 61, 'time_epoch': 4.68537, 'loss': 0.1011056, 'lr': 0, 'params': 323895, 'time_iter': 0.07437, 'accuracy': 0.77713, 'precision': 0.43818, 'recall': 0.93828, 'f1': 0.59738, 'auc': 0.93902, 'accuracy-SBM': 0.84047}
2025-08-16 12:57:07,845 - INFO - > Epoch 61: took 68.7s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:57:07,845 - INFO - === Epoch 62 ===
2025-08-16 12:58:04,391 - INFO - train: {'epoch': 62, 'time_epoch': 54.25316, 'eta': 2014.91744, 'eta_hours': 0.5597, 'loss': 0.090187, 'lr': 0.00017275, 'params': 323895, 'time_iter': 0.17333, 'accuracy': 0.86188, 'precision': 0.57169, 'recall': 0.86737, 'f1': 0.68915, 'auc': 0.94063, 'accuracy-SBM': 0.86403}
2025-08-16 12:58:09,437 - INFO - val: {'epoch': 62, 'time_epoch': 4.62411, 'loss': 0.09131127, 'lr': 0, 'params': 323895, 'time_iter': 0.0734, 'accuracy': 0.85885, 'precision': 0.56613, 'recall': 0.86751, 'f1': 0.68514, 'auc': 0.93931, 'accuracy-SBM': 0.86225}
2025-08-16 12:58:16,181 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:58:16,600 - INFO - test: {'epoch': 62, 'time_epoch': 4.7067, 'loss': 0.09018157, 'lr': 0, 'params': 323895, 'time_iter': 0.07471, 'accuracy': 0.8618, 'precision': 0.57092, 'recall': 0.86853, 'f1': 0.68896, 'auc': 0.94021, 'accuracy-SBM': 0.86445}
2025-08-16 12:58:16,603 - INFO - > Epoch 62: took 68.8s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:58:16,604 - INFO - === Epoch 63 ===
2025-08-16 12:59:13,340 - INFO - train: {'epoch': 63, 'time_epoch': 54.42178, 'eta': 1960.44027, 'eta_hours': 0.54457, 'loss': 0.09015073, 'lr': 0.00016493, 'params': 323895, 'time_iter': 0.17387, 'accuracy': 0.86198, 'precision': 0.57185, 'recall': 0.86797, 'f1': 0.68946, 'auc': 0.94073, 'accuracy-SBM': 0.86433}
2025-08-16 12:59:18,366 - INFO - val: {'epoch': 63, 'time_epoch': 4.62764, 'loss': 0.12968165, 'lr': 0, 'params': 323895, 'time_iter': 0.07345, 'accuracy': 0.8986, 'precision': 0.73836, 'recall': 0.66162, 'f1': 0.69789, 'auc': 0.92929, 'accuracy-SBM': 0.8056}
2025-08-16 12:59:25,069 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 12:59:25,470 - INFO - test: {'epoch': 63, 'time_epoch': 4.7101, 'loss': 0.12893271, 'lr': 0, 'params': 323895, 'time_iter': 0.07476, 'accuracy': 0.89983, 'precision': 0.74213, 'recall': 0.66134, 'f1': 0.69941, 'auc': 0.93038, 'accuracy-SBM': 0.80609}
2025-08-16 12:59:25,472 - INFO - > Epoch 63: took 68.9s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 12:59:25,472 - INFO - === Epoch 64 ===
2025-08-16 13:00:21,147 - INFO - train: {'epoch': 64, 'time_epoch': 54.34976, 'eta': 1905.92603, 'eta_hours': 0.52942, 'loss': 0.0900982, 'lr': 0.0001572, 'params': 323895, 'time_iter': 0.17364, 'accuracy': 0.86238, 'precision': 0.5728, 'recall': 0.86691, 'f1': 0.68981, 'auc': 0.94078, 'accuracy-SBM': 0.86416}
2025-08-16 13:00:26,221 - INFO - val: {'epoch': 64, 'time_epoch': 4.64664, 'loss': 0.09206251, 'lr': 0, 'params': 323895, 'time_iter': 0.07376, 'accuracy': 0.86148, 'precision': 0.57217, 'recall': 0.86217, 'f1': 0.68786, 'auc': 0.93861, 'accuracy-SBM': 0.86175}
2025-08-16 13:00:32,962 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:00:33,375 - INFO - test: {'epoch': 64, 'time_epoch': 4.72119, 'loss': 0.09084462, 'lr': 0, 'params': 323895, 'time_iter': 0.07494, 'accuracy': 0.86394, 'precision': 0.57606, 'recall': 0.86298, 'f1': 0.69092, 'auc': 0.93962, 'accuracy-SBM': 0.86356}
2025-08-16 13:00:33,378 - INFO - > Epoch 64: took 67.9s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 13:00:33,379 - INFO - === Epoch 65 ===
2025-08-16 13:01:29,111 - INFO - train: {'epoch': 65, 'time_epoch': 54.40113, 'eta': 1851.44323, 'eta_hours': 0.51429, 'loss': 0.09008725, 'lr': 0.00014958, 'params': 323895, 'time_iter': 0.17381, 'accuracy': 0.86241, 'precision': 0.57281, 'recall': 0.8674, 'f1': 0.68998, 'auc': 0.94079, 'accuracy-SBM': 0.86437}
2025-08-16 13:01:34,018 - INFO - val: {'epoch': 65, 'time_epoch': 4.65533, 'loss': 0.09575043, 'lr': 0, 'params': 323895, 'time_iter': 0.07389, 'accuracy': 0.81307, 'precision': 0.48522, 'recall': 0.91875, 'f1': 0.63505, 'auc': 0.93984, 'accuracy-SBM': 0.85454}
2025-08-16 13:01:41,124 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:01:41,542 - INFO - test: {'epoch': 65, 'time_epoch': 4.72075, 'loss': 0.09456571, 'lr': 0, 'params': 323895, 'time_iter': 0.07493, 'accuracy': 0.81498, 'precision': 0.48677, 'recall': 0.91906, 'f1': 0.63645, 'auc': 0.94066, 'accuracy-SBM': 0.85588}
2025-08-16 13:01:41,544 - INFO - > Epoch 65: took 68.2s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 13:01:41,544 - INFO - === Epoch 66 ===
2025-08-16 13:02:36,316 - INFO - train: {'epoch': 66, 'time_epoch': 54.32964, 'eta': 1796.92766, 'eta_hours': 0.49915, 'loss': 0.09011552, 'lr': 0.00014206, 'params': 323895, 'time_iter': 0.17358, 'accuracy': 0.86265, 'precision': 0.57339, 'recall': 0.86673, 'f1': 0.69019, 'auc': 0.94072, 'accuracy-SBM': 0.86425}
2025-08-16 13:02:41,368 - INFO - val: {'epoch': 66, 'time_epoch': 4.63865, 'loss': 0.11441131, 'lr': 0, 'params': 323895, 'time_iter': 0.07363, 'accuracy': 0.89997, 'precision': 0.72222, 'recall': 0.70674, 'f1': 0.7144, 'auc': 0.93442, 'accuracy-SBM': 0.82414}
2025-08-16 13:02:48,074 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:02:48,484 - INFO - test: {'epoch': 66, 'time_epoch': 4.70671, 'loss': 0.11366003, 'lr': 0, 'params': 323895, 'time_iter': 0.07471, 'accuracy': 0.90116, 'precision': 0.72621, 'recall': 0.70486, 'f1': 0.71537, 'auc': 0.93554, 'accuracy-SBM': 0.82401}
2025-08-16 13:02:48,486 - INFO - > Epoch 66: took 66.9s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 13:02:48,487 - INFO - === Epoch 67 ===
2025-08-16 13:03:44,098 - INFO - train: {'epoch': 67, 'time_epoch': 54.28557, 'eta': 1742.39682, 'eta_hours': 0.484, 'loss': 0.09013643, 'lr': 0.00013466, 'params': 323895, 'time_iter': 0.17344, 'accuracy': 0.86303, 'precision': 0.57418, 'recall': 0.86712, 'f1': 0.69088, 'auc': 0.94073, 'accuracy-SBM': 0.86464}
2025-08-16 13:03:49,151 - INFO - val: {'epoch': 67, 'time_epoch': 4.64003, 'loss': 0.12805127, 'lr': 0, 'params': 323895, 'time_iter': 0.07365, 'accuracy': 0.89583, 'precision': 0.72246, 'recall': 0.66827, 'f1': 0.69431, 'auc': 0.92669, 'accuracy-SBM': 0.80653}
2025-08-16 13:03:55,937 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:03:56,356 - INFO - test: {'epoch': 67, 'time_epoch': 4.71033, 'loss': 0.12779375, 'lr': 0, 'params': 323895, 'time_iter': 0.07477, 'accuracy': 0.8969, 'precision': 0.72607, 'recall': 0.66636, 'f1': 0.69494, 'auc': 0.92751, 'accuracy-SBM': 0.80629}
2025-08-16 13:03:56,359 - INFO - > Epoch 67: took 67.9s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 13:03:56,360 - INFO - === Epoch 68 ===
2025-08-16 13:04:53,065 - INFO - train: {'epoch': 68, 'time_epoch': 54.37457, 'eta': 1687.91308, 'eta_hours': 0.46886, 'loss': 0.09009651, 'lr': 0.00012739, 'params': 323895, 'time_iter': 0.17372, 'accuracy': 0.86215, 'precision': 0.57224, 'recall': 0.8676, 'f1': 0.68962, 'auc': 0.94076, 'accuracy-SBM': 0.86429}
2025-08-16 13:04:58,114 - INFO - val: {'epoch': 68, 'time_epoch': 4.63722, 'loss': 0.09157449, 'lr': 0, 'params': 323895, 'time_iter': 0.07361, 'accuracy': 0.86997, 'precision': 0.59217, 'recall': 0.85276, 'f1': 0.69897, 'auc': 0.9398, 'accuracy-SBM': 0.86322}
2025-08-16 13:05:05,106 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:05:05,540 - INFO - test: {'epoch': 68, 'time_epoch': 4.71178, 'loss': 0.09043128, 'lr': 0, 'params': 323895, 'time_iter': 0.07479, 'accuracy': 0.87282, 'precision': 0.59745, 'recall': 0.85305, 'f1': 0.70273, 'auc': 0.94078, 'accuracy-SBM': 0.86505}
2025-08-16 13:05:05,542 - INFO - > Epoch 68: took 69.2s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 13:05:05,542 - INFO - === Epoch 69 ===
2025-08-16 13:06:00,173 - INFO - train: {'epoch': 69, 'time_epoch': 54.27099, 'eta': 1633.38806, 'eta_hours': 0.45372, 'loss': 0.09011427, 'lr': 0.00012026, 'params': 323895, 'time_iter': 0.17339, 'accuracy': 0.86234, 'precision': 0.57269, 'recall': 0.8671, 'f1': 0.6898, 'auc': 0.94076, 'accuracy-SBM': 0.86421}
2025-08-16 13:06:05,051 - INFO - val: {'epoch': 69, 'time_epoch': 4.63629, 'loss': 0.1102499, 'lr': 0, 'params': 323895, 'time_iter': 0.07359, 'accuracy': 0.73946, 'precision': 0.40027, 'recall': 0.94683, 'f1': 0.56268, 'auc': 0.93299, 'accuracy-SBM': 0.82084}
2025-08-16 13:06:12,174 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:06:12,590 - INFO - test: {'epoch': 69, 'time_epoch': 4.71309, 'loss': 0.10911986, 'lr': 0, 'params': 323895, 'time_iter': 0.07481, 'accuracy': 0.74271, 'precision': 0.40221, 'recall': 0.94614, 'f1': 0.56447, 'auc': 0.9335, 'accuracy-SBM': 0.82267}
2025-08-16 13:06:12,592 - INFO - > Epoch 69: took 67.0s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 13:06:12,592 - INFO - === Epoch 70 ===
2025-08-16 13:07:09,283 - INFO - train: {'epoch': 70, 'time_epoch': 54.34035, 'eta': 1578.89853, 'eta_hours': 0.43858, 'loss': 0.09001438, 'lr': 0.00011326, 'params': 323895, 'time_iter': 0.17361, 'accuracy': 0.86282, 'precision': 0.5738, 'recall': 0.86637, 'f1': 0.69037, 'auc': 0.9409, 'accuracy-SBM': 0.86422}
2025-08-16 13:07:14,355 - INFO - val: {'epoch': 70, 'time_epoch': 4.64687, 'loss': 0.09722435, 'lr': 0, 'params': 323895, 'time_iter': 0.07376, 'accuracy': 0.87918, 'precision': 0.62164, 'recall': 0.81117, 'f1': 0.70387, 'auc': 0.93496, 'accuracy-SBM': 0.85249}
2025-08-16 13:07:21,459 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:07:21,891 - INFO - test: {'epoch': 70, 'time_epoch': 4.73115, 'loss': 0.09627253, 'lr': 0, 'params': 323895, 'time_iter': 0.0751, 'accuracy': 0.88087, 'precision': 0.62479, 'recall': 0.81108, 'f1': 0.70585, 'auc': 0.93593, 'accuracy-SBM': 0.85344}
2025-08-16 13:07:21,894 - INFO - > Epoch 70: took 69.3s (avg 68.3s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 13:07:21,895 - INFO - === Epoch 71 ===
2025-08-16 13:08:18,570 - INFO - train: {'epoch': 71, 'time_epoch': 54.29467, 'eta': 1524.39538, 'eta_hours': 0.42344, 'loss': 0.09001305, 'lr': 0.00010642, 'params': 323895, 'time_iter': 0.17347, 'accuracy': 0.86262, 'precision': 0.57327, 'recall': 0.86732, 'f1': 0.69029, 'auc': 0.94088, 'accuracy-SBM': 0.86447}
2025-08-16 13:08:23,460 - INFO - val: {'epoch': 71, 'time_epoch': 4.63266, 'loss': 0.09314234, 'lr': 0, 'params': 323895, 'time_iter': 0.07353, 'accuracy': 0.82838, 'precision': 0.50854, 'recall': 0.90889, 'f1': 0.65217, 'auc': 0.94106, 'accuracy-SBM': 0.85997}
2025-08-16 13:08:30,572 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:08:31,008 - INFO - test: {'epoch': 71, 'time_epoch': 4.68413, 'loss': 0.0919039, 'lr': 0, 'params': 323895, 'time_iter': 0.07435, 'accuracy': 0.83129, 'precision': 0.51201, 'recall': 0.90848, 'f1': 0.65492, 'auc': 0.94191, 'accuracy-SBM': 0.86163}
2025-08-16 13:08:31,011 - INFO - > Epoch 71: took 69.1s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 13:08:31,012 - INFO - === Epoch 72 ===
2025-08-16 13:09:26,726 - INFO - train: {'epoch': 72, 'time_epoch': 54.31865, 'eta': 1469.9068, 'eta_hours': 0.40831, 'loss': 0.08995296, 'lr': 9.973e-05, 'params': 323895, 'time_iter': 0.17354, 'accuracy': 0.8628, 'precision': 0.57367, 'recall': 0.86734, 'f1': 0.69058, 'auc': 0.94098, 'accuracy-SBM': 0.86459}
2025-08-16 13:09:31,816 - INFO - val: {'epoch': 72, 'time_epoch': 4.65511, 'loss': 0.10396558, 'lr': 0, 'params': 323895, 'time_iter': 0.07389, 'accuracy': 0.89657, 'precision': 0.68871, 'recall': 0.7586, 'f1': 0.72197, 'auc': 0.937, 'accuracy-SBM': 0.84242}
2025-08-16 13:09:38,887 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:09:39,348 - INFO - test: {'epoch': 72, 'time_epoch': 4.71774, 'loss': 0.10315505, 'lr': 0, 'params': 323895, 'time_iter': 0.07488, 'accuracy': 0.89826, 'precision': 0.69419, 'recall': 0.75541, 'f1': 0.72351, 'auc': 0.9381, 'accuracy-SBM': 0.84211}
2025-08-16 13:09:39,352 - INFO - > Epoch 72: took 68.3s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 13:09:39,353 - INFO - === Epoch 73 ===
2025-08-16 13:10:35,954 - INFO - train: {'epoch': 73, 'time_epoch': 54.32504, 'eta': 1415.42507, 'eta_hours': 0.39317, 'loss': 0.08998743, 'lr': 9.321e-05, 'params': 323895, 'time_iter': 0.17356, 'accuracy': 0.86286, 'precision': 0.57382, 'recall': 0.86705, 'f1': 0.6906, 'auc': 0.94093, 'accuracy-SBM': 0.8645}
2025-08-16 13:10:40,843 - INFO - val: {'epoch': 73, 'time_epoch': 4.60518, 'loss': 0.11125252, 'lr': 0, 'params': 323895, 'time_iter': 0.0731, 'accuracy': 0.7353, 'precision': 0.39689, 'recall': 0.95326, 'f1': 0.56044, 'auc': 0.93555, 'accuracy-SBM': 0.82084}
2025-08-16 13:10:48,085 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:10:48,510 - INFO - test: {'epoch': 73, 'time_epoch': 4.69622, 'loss': 0.10999814, 'lr': 0, 'params': 323895, 'time_iter': 0.07454, 'accuracy': 0.73865, 'precision': 0.3988, 'recall': 0.95188, 'f1': 0.5621, 'auc': 0.93619, 'accuracy-SBM': 0.82246}
2025-08-16 13:10:48,512 - INFO - > Epoch 73: took 69.2s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 13:10:48,512 - INFO - === Epoch 74 ===
2025-08-16 13:11:44,054 - INFO - train: {'epoch': 74, 'time_epoch': 54.20743, 'eta': 1360.90831, 'eta_hours': 0.37803, 'loss': 0.0899255, 'lr': 8.685e-05, 'params': 323895, 'time_iter': 0.17319, 'accuracy': 0.86298, 'precision': 0.57398, 'recall': 0.86802, 'f1': 0.69102, 'auc': 0.94099, 'accuracy-SBM': 0.86496}
2025-08-16 13:11:48,926 - INFO - val: {'epoch': 74, 'time_epoch': 4.6279, 'loss': 0.0957873, 'lr': 0, 'params': 323895, 'time_iter': 0.07346, 'accuracy': 0.81122, 'precision': 0.48258, 'recall': 0.92027, 'f1': 0.63315, 'auc': 0.93984, 'accuracy-SBM': 0.85402}
2025-08-16 13:11:56,026 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:11:56,446 - INFO - test: {'epoch': 74, 'time_epoch': 4.6903, 'loss': 0.0946365, 'lr': 0, 'params': 323895, 'time_iter': 0.07445, 'accuracy': 0.81297, 'precision': 0.48387, 'recall': 0.92044, 'f1': 0.6343, 'auc': 0.94069, 'accuracy-SBM': 0.85521}
2025-08-16 13:11:56,448 - INFO - > Epoch 74: took 67.9s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 13:11:56,448 - INFO - === Epoch 75 ===
2025-08-16 13:12:52,920 - INFO - train: {'epoch': 75, 'time_epoch': 54.15115, 'eta': 1306.38192, 'eta_hours': 0.36288, 'loss': 0.08994209, 'lr': 8.068e-05, 'params': 323895, 'time_iter': 0.17301, 'accuracy': 0.86317, 'precision': 0.57445, 'recall': 0.86733, 'f1': 0.69114, 'auc': 0.94097, 'accuracy-SBM': 0.8648}
2025-08-16 13:12:57,929 - INFO - val: {'epoch': 75, 'time_epoch': 4.61106, 'loss': 0.19039499, 'lr': 0, 'params': 323895, 'time_iter': 0.07319, 'accuracy': 0.89299, 'precision': 0.82939, 'recall': 0.49793, 'f1': 0.62227, 'auc': 0.92295, 'accuracy-SBM': 0.73795}
2025-08-16 13:13:04,798 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:13:05,213 - INFO - test: {'epoch': 75, 'time_epoch': 4.70328, 'loss': 0.19024496, 'lr': 0, 'params': 323895, 'time_iter': 0.07466, 'accuracy': 0.89371, 'precision': 0.83165, 'recall': 0.49752, 'f1': 0.62259, 'auc': 0.92363, 'accuracy-SBM': 0.73799}
2025-08-16 13:13:05,215 - INFO - > Epoch 75: took 68.8s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 13:13:05,215 - INFO - === Epoch 76 ===
2025-08-16 13:14:01,106 - INFO - train: {'epoch': 76, 'time_epoch': 55.5514, 'eta': 1252.28354, 'eta_hours': 0.34786, 'loss': 0.08978273, 'lr': 7.469e-05, 'params': 323895, 'time_iter': 0.17748, 'accuracy': 0.86284, 'precision': 0.57369, 'recall': 0.86784, 'f1': 0.69076, 'auc': 0.94119, 'accuracy-SBM': 0.8648}
2025-08-16 13:14:06,114 - INFO - val: {'epoch': 76, 'time_epoch': 4.59847, 'loss': 0.10855856, 'lr': 0, 'params': 323895, 'time_iter': 0.07299, 'accuracy': 0.89769, 'precision': 0.70014, 'recall': 0.73818, 'f1': 0.71866, 'auc': 0.93505, 'accuracy-SBM': 0.83509}
2025-08-16 13:14:13,053 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:14:13,458 - INFO - test: {'epoch': 76, 'time_epoch': 4.66484, 'loss': 0.10764537, 'lr': 0, 'params': 323895, 'time_iter': 0.07405, 'accuracy': 0.89888, 'precision': 0.70431, 'recall': 0.73456, 'f1': 0.71912, 'auc': 0.93629, 'accuracy-SBM': 0.8343}
2025-08-16 13:14:13,460 - INFO - > Epoch 76: took 68.2s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 13:14:13,460 - INFO - === Epoch 77 ===
2025-08-16 13:15:09,613 - INFO - train: {'epoch': 77, 'time_epoch': 53.90059, 'eta': 1197.68228, 'eta_hours': 0.33269, 'loss': 0.08985714, 'lr': 6.889e-05, 'params': 323895, 'time_iter': 0.17221, 'accuracy': 0.86316, 'precision': 0.57441, 'recall': 0.86766, 'f1': 0.69122, 'auc': 0.94114, 'accuracy-SBM': 0.86493}
2025-08-16 13:15:14,633 - INFO - val: {'epoch': 77, 'time_epoch': 4.60497, 'loss': 0.09252625, 'lr': 0, 'params': 323895, 'time_iter': 0.07309, 'accuracy': 0.87836, 'precision': 0.61506, 'recall': 0.83621, 'f1': 0.70879, 'auc': 0.94022, 'accuracy-SBM': 0.86182}
2025-08-16 13:15:22,014 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:15:22,425 - INFO - test: {'epoch': 77, 'time_epoch': 4.68488, 'loss': 0.09141507, 'lr': 0, 'params': 323895, 'time_iter': 0.07436, 'accuracy': 0.88081, 'precision': 0.62006, 'recall': 0.83573, 'f1': 0.71192, 'auc': 0.94127, 'accuracy-SBM': 0.86309}
2025-08-16 13:15:22,434 - INFO - > Epoch 77: took 69.0s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 13:15:22,435 - INFO - === Epoch 78 ===
2025-08-16 13:16:18,867 - INFO - train: {'epoch': 78, 'time_epoch': 54.07227, 'eta': 1143.1444, 'eta_hours': 0.31754, 'loss': 0.08989582, 'lr': 6.329e-05, 'params': 323895, 'time_iter': 0.17275, 'accuracy': 0.86276, 'precision': 0.57358, 'recall': 0.86731, 'f1': 0.6905, 'auc': 0.94105, 'accuracy-SBM': 0.86455}
2025-08-16 13:16:23,889 - INFO - val: {'epoch': 78, 'time_epoch': 4.60939, 'loss': 0.12224081, 'lr': 0, 'params': 323895, 'time_iter': 0.07316, 'accuracy': 0.89451, 'precision': 0.70464, 'recall': 0.69566, 'f1': 0.70013, 'auc': 0.92679, 'accuracy-SBM': 0.81647}
2025-08-16 13:16:30,962 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:16:31,374 - INFO - test: {'epoch': 78, 'time_epoch': 4.67615, 'loss': 0.12235164, 'lr': 0, 'params': 323895, 'time_iter': 0.07422, 'accuracy': 0.89555, 'precision': 0.70839, 'recall': 0.69226, 'f1': 0.70023, 'auc': 0.92735, 'accuracy-SBM': 0.81565}
2025-08-16 13:16:31,377 - INFO - > Epoch 78: took 68.9s (avg 68.4s) | Best so far: epoch 44	train_loss: 0.0906 train_accuracy-SBM: 0.8637	val_loss: 0.0912 val_accuracy-SBM: 0.8640	test_loss: 0.0900 test_accuracy-SBM: 0.8664
2025-08-16 13:16:31,378 - INFO - === Epoch 79 ===
2025-08-16 13:17:27,385 - INFO - train: {'epoch': 79, 'time_epoch': 54.67186, 'eta': 1088.76805, 'eta_hours': 0.30244, 'loss': 0.08983604, 'lr': 5.79e-05, 'params': 323895, 'time_iter': 0.17467, 'accuracy': 0.8629, 'precision': 0.57378, 'recall': 0.86834, 'f1': 0.69098, 'auc': 0.94112, 'accuracy-SBM': 0.86504}
2025-08-16 13:17:32,469 - INFO - val: {'epoch': 79, 'time_epoch': 4.66428, 'loss': 0.09089918, 'lr': 0, 'params': 323895, 'time_iter': 0.07404, 'accuracy': 0.866, 'precision': 0.58213, 'recall': 0.86129, 'f1': 0.69471, 'auc': 0.94038, 'accuracy-SBM': 0.86415}
2025-08-16 13:17:39,417 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:17:39,849 - INFO - test: {'epoch': 79, 'time_epoch': 4.70139, 'loss': 0.08974104, 'lr': 0, 'params': 323895, 'time_iter': 0.07463, 'accuracy': 0.86873, 'precision': 0.58686, 'recall': 0.86179, 'f1': 0.69824, 'auc': 0.94136, 'accuracy-SBM': 0.866}
2025-08-16 13:17:39,852 - INFO - > Epoch 79: took 68.5s (avg 68.4s) | Best so far: epoch 79	train_loss: 0.0898 train_accuracy-SBM: 0.8650	val_loss: 0.0909 val_accuracy-SBM: 0.8641	test_loss: 0.0897 test_accuracy-SBM: 0.8660
2025-08-16 13:17:39,852 - INFO - === Epoch 80 ===
2025-08-16 13:18:34,627 - INFO - train: {'epoch': 80, 'time_epoch': 54.3725, 'eta': 1034.31419, 'eta_hours': 0.28731, 'loss': 0.08987588, 'lr': 5.271e-05, 'params': 323895, 'time_iter': 0.17371, 'accuracy': 0.86285, 'precision': 0.57374, 'recall': 0.86754, 'f1': 0.6907, 'auc': 0.94107, 'accuracy-SBM': 0.86469}
2025-08-16 13:18:39,515 - INFO - val: {'epoch': 80, 'time_epoch': 4.64536, 'loss': 0.09271772, 'lr': 0, 'params': 323895, 'time_iter': 0.07374, 'accuracy': 0.83178, 'precision': 0.51414, 'recall': 0.90398, 'f1': 0.65547, 'auc': 0.9406, 'accuracy-SBM': 0.86011}
2025-08-16 13:18:46,314 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:18:46,750 - INFO - test: {'epoch': 80, 'time_epoch': 4.70464, 'loss': 0.09149388, 'lr': 0, 'params': 323895, 'time_iter': 0.07468, 'accuracy': 0.83435, 'precision': 0.51714, 'recall': 0.90462, 'f1': 0.65808, 'auc': 0.94154, 'accuracy-SBM': 0.86197}
2025-08-16 13:18:46,753 - INFO - > Epoch 80: took 66.9s (avg 68.4s) | Best so far: epoch 79	train_loss: 0.0898 train_accuracy-SBM: 0.8650	val_loss: 0.0909 val_accuracy-SBM: 0.8641	test_loss: 0.0897 test_accuracy-SBM: 0.8660
2025-08-16 13:18:46,753 - INFO - === Epoch 81 ===
2025-08-16 13:19:43,287 - INFO - train: {'epoch': 81, 'time_epoch': 54.25214, 'eta': 979.83589, 'eta_hours': 0.27218, 'loss': 0.08981416, 'lr': 4.775e-05, 'params': 323895, 'time_iter': 0.17333, 'accuracy': 0.86276, 'precision': 0.57353, 'recall': 0.86774, 'f1': 0.6906, 'auc': 0.94117, 'accuracy-SBM': 0.86471}
2025-08-16 13:19:48,340 - INFO - val: {'epoch': 81, 'time_epoch': 4.63388, 'loss': 0.091143, 'lr': 0, 'params': 323895, 'time_iter': 0.07355, 'accuracy': 0.85005, 'precision': 0.54739, 'recall': 0.88342, 'f1': 0.67594, 'auc': 0.94026, 'accuracy-SBM': 0.86315}
2025-08-16 13:19:55,273 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:19:55,694 - INFO - test: {'epoch': 81, 'time_epoch': 4.69716, 'loss': 0.08999851, 'lr': 0, 'params': 323895, 'time_iter': 0.07456, 'accuracy': 0.85265, 'precision': 0.55112, 'recall': 0.88311, 'f1': 0.67869, 'auc': 0.94112, 'accuracy-SBM': 0.86462}
2025-08-16 13:19:55,696 - INFO - > Epoch 81: took 68.9s (avg 68.4s) | Best so far: epoch 79	train_loss: 0.0898 train_accuracy-SBM: 0.8650	val_loss: 0.0909 val_accuracy-SBM: 0.8641	test_loss: 0.0897 test_accuracy-SBM: 0.8660
2025-08-16 13:19:55,697 - INFO - === Epoch 82 ===
2025-08-16 13:20:52,271 - INFO - train: {'epoch': 82, 'time_epoch': 54.27354, 'eta': 925.36743, 'eta_hours': 0.25705, 'loss': 0.08978912, 'lr': 4.3e-05, 'params': 323895, 'time_iter': 0.1734, 'accuracy': 0.86272, 'precision': 0.57339, 'recall': 0.86841, 'f1': 0.69072, 'auc': 0.9412, 'accuracy-SBM': 0.86496}
2025-08-16 13:20:57,310 - INFO - val: {'epoch': 82, 'time_epoch': 4.62667, 'loss': 0.10022724, 'lr': 0, 'params': 323895, 'time_iter': 0.07344, 'accuracy': 0.89286, 'precision': 0.67004, 'recall': 0.77782, 'f1': 0.71992, 'auc': 0.93757, 'accuracy-SBM': 0.84772}
2025-08-16 13:21:04,343 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:21:04,750 - INFO - test: {'epoch': 82, 'time_epoch': 4.71034, 'loss': 0.09923021, 'lr': 0, 'params': 323895, 'time_iter': 0.07477, 'accuracy': 0.89495, 'precision': 0.67554, 'recall': 0.77711, 'f1': 0.72277, 'auc': 0.9387, 'accuracy-SBM': 0.84863}
2025-08-16 13:21:04,752 - INFO - > Epoch 82: took 69.1s (avg 68.4s) | Best so far: epoch 79	train_loss: 0.0898 train_accuracy-SBM: 0.8650	val_loss: 0.0909 val_accuracy-SBM: 0.8641	test_loss: 0.0897 test_accuracy-SBM: 0.8660
2025-08-16 13:21:04,753 - INFO - === Epoch 83 ===
2025-08-16 13:22:00,350 - INFO - train: {'epoch': 83, 'time_epoch': 54.28065, 'eta': 870.90496, 'eta_hours': 0.24192, 'loss': 0.0897824, 'lr': 3.848e-05, 'params': 323895, 'time_iter': 0.17342, 'accuracy': 0.86309, 'precision': 0.57422, 'recall': 0.86809, 'f1': 0.69121, 'auc': 0.94123, 'accuracy-SBM': 0.86506}
2025-08-16 13:22:05,384 - INFO - val: {'epoch': 83, 'time_epoch': 4.62177, 'loss': 0.09189605, 'lr': 0, 'params': 323895, 'time_iter': 0.07336, 'accuracy': 0.86571, 'precision': 0.58214, 'recall': 0.85543, 'f1': 0.69281, 'auc': 0.93861, 'accuracy-SBM': 0.86168}
2025-08-16 13:22:12,192 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:22:12,621 - INFO - test: {'epoch': 83, 'time_epoch': 4.69229, 'loss': 0.09086318, 'lr': 0, 'params': 323895, 'time_iter': 0.07448, 'accuracy': 0.86823, 'precision': 0.58635, 'recall': 0.8565, 'f1': 0.69613, 'auc': 0.93948, 'accuracy-SBM': 0.86362}
2025-08-16 13:22:12,624 - INFO - > Epoch 83: took 67.9s (avg 68.4s) | Best so far: epoch 79	train_loss: 0.0898 train_accuracy-SBM: 0.8650	val_loss: 0.0909 val_accuracy-SBM: 0.8641	test_loss: 0.0897 test_accuracy-SBM: 0.8660
2025-08-16 13:22:12,625 - INFO - === Epoch 84 ===
2025-08-16 13:23:09,292 - INFO - train: {'epoch': 84, 'time_epoch': 54.31337, 'eta': 816.45254, 'eta_hours': 0.22679, 'loss': 0.0898143, 'lr': 3.419e-05, 'params': 323895, 'time_iter': 0.17353, 'accuracy': 0.8626, 'precision': 0.57322, 'recall': 0.8675, 'f1': 0.69031, 'auc': 0.94117, 'accuracy-SBM': 0.86453}
2025-08-16 13:23:14,338 - INFO - val: {'epoch': 84, 'time_epoch': 4.62091, 'loss': 0.10241046, 'lr': 0, 'params': 323895, 'time_iter': 0.07335, 'accuracy': 0.89135, 'precision': 0.66641, 'recall': 0.77332, 'f1': 0.71589, 'auc': 0.93564, 'accuracy-SBM': 0.84503}
2025-08-16 13:23:21,066 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:23:21,488 - INFO - test: {'epoch': 84, 'time_epoch': 4.69561, 'loss': 0.10168682, 'lr': 0, 'params': 323895, 'time_iter': 0.07453, 'accuracy': 0.89363, 'precision': 0.67259, 'recall': 0.77239, 'f1': 0.71905, 'auc': 0.93666, 'accuracy-SBM': 0.84598}
2025-08-16 13:23:21,491 - INFO - > Epoch 84: took 68.9s (avg 68.4s) | Best so far: epoch 79	train_loss: 0.0898 train_accuracy-SBM: 0.8650	val_loss: 0.0909 val_accuracy-SBM: 0.8641	test_loss: 0.0897 test_accuracy-SBM: 0.8660
2025-08-16 13:23:21,491 - INFO - === Epoch 85 ===
2025-08-16 13:24:16,086 - INFO - train: {'epoch': 85, 'time_epoch': 54.23026, 'eta': 761.98983, 'eta_hours': 0.21166, 'loss': 0.08980427, 'lr': 3.013e-05, 'params': 323895, 'time_iter': 0.17326, 'accuracy': 0.86268, 'precision': 0.57329, 'recall': 0.86852, 'f1': 0.69068, 'auc': 0.94118, 'accuracy-SBM': 0.86497}
2025-08-16 13:24:21,135 - INFO - val: {'epoch': 85, 'time_epoch': 4.63518, 'loss': 0.09337769, 'lr': 0, 'params': 323895, 'time_iter': 0.07357, 'accuracy': 0.87616, 'precision': 0.6099, 'recall': 0.83371, 'f1': 0.70445, 'auc': 0.93836, 'accuracy-SBM': 0.8595}
2025-08-16 13:24:27,914 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:24:28,331 - INFO - test: {'epoch': 85, 'time_epoch': 4.7105, 'loss': 0.09226043, 'lr': 0, 'params': 323895, 'time_iter': 0.07477, 'accuracy': 0.87846, 'precision': 0.6144, 'recall': 0.83325, 'f1': 0.70728, 'auc': 0.93939, 'accuracy-SBM': 0.86069}
2025-08-16 13:24:28,334 - INFO - > Epoch 85: took 66.8s (avg 68.4s) | Best so far: epoch 79	train_loss: 0.0898 train_accuracy-SBM: 0.8650	val_loss: 0.0909 val_accuracy-SBM: 0.8641	test_loss: 0.0897 test_accuracy-SBM: 0.8660
2025-08-16 13:24:28,334 - INFO - === Epoch 86 ===
2025-08-16 13:25:24,966 - INFO - train: {'epoch': 86, 'time_epoch': 54.33783, 'eta': 707.54854, 'eta_hours': 0.19654, 'loss': 0.0897733, 'lr': 2.632e-05, 'params': 323895, 'time_iter': 0.1736, 'accuracy': 0.86324, 'precision': 0.57456, 'recall': 0.86778, 'f1': 0.69137, 'auc': 0.94122, 'accuracy-SBM': 0.86503}
2025-08-16 13:25:29,993 - INFO - val: {'epoch': 86, 'time_epoch': 4.61943, 'loss': 0.10624437, 'lr': 0, 'params': 323895, 'time_iter': 0.07332, 'accuracy': 0.89383, 'precision': 0.68168, 'recall': 0.75091, 'f1': 0.71462, 'auc': 0.93417, 'accuracy-SBM': 0.83774}
2025-08-16 13:25:36,773 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:25:37,170 - INFO - test: {'epoch': 86, 'time_epoch': 4.69104, 'loss': 0.10548004, 'lr': 0, 'params': 323895, 'time_iter': 0.07446, 'accuracy': 0.8957, 'precision': 0.68728, 'recall': 0.74886, 'f1': 0.71675, 'auc': 0.93528, 'accuracy-SBM': 0.83798}
2025-08-16 13:25:37,172 - INFO - > Epoch 86: took 68.8s (avg 68.4s) | Best so far: epoch 79	train_loss: 0.0898 train_accuracy-SBM: 0.8650	val_loss: 0.0909 val_accuracy-SBM: 0.8641	test_loss: 0.0897 test_accuracy-SBM: 0.8660
2025-08-16 13:25:37,172 - INFO - === Epoch 87 ===
2025-08-16 13:26:32,681 - INFO - train: {'epoch': 87, 'time_epoch': 54.21818, 'eta': 653.09328, 'eta_hours': 0.18141, 'loss': 0.08971593, 'lr': 2.275e-05, 'params': 323895, 'time_iter': 0.17322, 'accuracy': 0.86293, 'precision': 0.57388, 'recall': 0.86794, 'f1': 0.69093, 'auc': 0.94127, 'accuracy-SBM': 0.8649}
2025-08-16 13:26:37,704 - INFO - val: {'epoch': 87, 'time_epoch': 4.62041, 'loss': 0.09100266, 'lr': 0, 'params': 323895, 'time_iter': 0.07334, 'accuracy': 0.84987, 'precision': 0.54696, 'recall': 0.88485, 'f1': 0.67603, 'auc': 0.94067, 'accuracy-SBM': 0.8636}
2025-08-16 13:26:44,609 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:26:45,026 - INFO - test: {'epoch': 87, 'time_epoch': 4.69227, 'loss': 0.08980083, 'lr': 0, 'params': 323895, 'time_iter': 0.07448, 'accuracy': 0.85256, 'precision': 0.5508, 'recall': 0.8853, 'f1': 0.6791, 'auc': 0.94162, 'accuracy-SBM': 0.86543}
2025-08-16 13:26:45,028 - INFO - > Epoch 87: took 67.9s (avg 68.4s) | Best so far: epoch 79	train_loss: 0.0898 train_accuracy-SBM: 0.8650	val_loss: 0.0909 val_accuracy-SBM: 0.8641	test_loss: 0.0897 test_accuracy-SBM: 0.8660
2025-08-16 13:26:45,028 - INFO - === Epoch 88 ===
2025-08-16 13:27:41,740 - INFO - train: {'epoch': 88, 'time_epoch': 54.3574, 'eta': 598.66055, 'eta_hours': 0.16629, 'loss': 0.0897831, 'lr': 1.943e-05, 'params': 323895, 'time_iter': 0.17367, 'accuracy': 0.86263, 'precision': 0.57322, 'recall': 0.86806, 'f1': 0.69048, 'auc': 0.94115, 'accuracy-SBM': 0.86476}
2025-08-16 13:27:46,793 - INFO - val: {'epoch': 88, 'time_epoch': 4.63199, 'loss': 0.10059089, 'lr': 0, 'params': 323895, 'time_iter': 0.07352, 'accuracy': 0.88921, 'precision': 0.65671, 'recall': 0.78392, 'f1': 0.7147, 'auc': 0.93589, 'accuracy-SBM': 0.84789}
2025-08-16 13:27:53,775 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:27:54,198 - INFO - test: {'epoch': 88, 'time_epoch': 4.71952, 'loss': 0.09977418, 'lr': 0, 'params': 323895, 'time_iter': 0.07491, 'accuracy': 0.89141, 'precision': 0.66235, 'recall': 0.7828, 'f1': 0.71756, 'auc': 0.93694, 'accuracy-SBM': 0.84872}
2025-08-16 13:27:54,201 - INFO - > Epoch 88: took 69.2s (avg 68.4s) | Best so far: epoch 79	train_loss: 0.0898 train_accuracy-SBM: 0.8650	val_loss: 0.0909 val_accuracy-SBM: 0.8641	test_loss: 0.0897 test_accuracy-SBM: 0.8660
2025-08-16 13:27:54,201 - INFO - === Epoch 89 ===
2025-08-16 13:28:49,888 - INFO - train: {'epoch': 89, 'time_epoch': 54.3514, 'eta': 544.22883, 'eta_hours': 0.15117, 'loss': 0.08975708, 'lr': 1.636e-05, 'params': 323895, 'time_iter': 0.17365, 'accuracy': 0.8627, 'precision': 0.57338, 'recall': 0.86808, 'f1': 0.6906, 'auc': 0.94121, 'accuracy-SBM': 0.86481}
2025-08-16 13:28:54,961 - INFO - val: {'epoch': 89, 'time_epoch': 4.63622, 'loss': 0.09144107, 'lr': 0, 'params': 323895, 'time_iter': 0.07359, 'accuracy': 0.86809, 'precision': 0.58742, 'recall': 0.85615, 'f1': 0.69677, 'auc': 0.93977, 'accuracy-SBM': 0.8634}
2025-08-16 13:29:02,033 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:29:02,467 - INFO - test: {'epoch': 89, 'time_epoch': 4.70392, 'loss': 0.09032848, 'lr': 0, 'params': 323895, 'time_iter': 0.07467, 'accuracy': 0.87068, 'precision': 0.59196, 'recall': 0.8566, 'f1': 0.70011, 'auc': 0.94073, 'accuracy-SBM': 0.86515}
2025-08-16 13:29:02,470 - INFO - > Epoch 89: took 68.3s (avg 68.4s) | Best so far: epoch 79	train_loss: 0.0898 train_accuracy-SBM: 0.8650	val_loss: 0.0909 val_accuracy-SBM: 0.8641	test_loss: 0.0897 test_accuracy-SBM: 0.8660
2025-08-16 13:29:02,470 - INFO - === Epoch 90 ===
2025-08-16 13:29:59,170 - INFO - train: {'epoch': 90, 'time_epoch': 54.33638, 'eta': 489.79739, 'eta_hours': 0.13605, 'loss': 0.08985632, 'lr': 1.355e-05, 'params': 323895, 'time_iter': 0.1736, 'accuracy': 0.86263, 'precision': 0.57322, 'recall': 0.868, 'f1': 0.69047, 'auc': 0.94109, 'accuracy-SBM': 0.86474}
2025-08-16 13:30:04,279 - INFO - val: {'epoch': 90, 'time_epoch': 4.68122, 'loss': 0.09782576, 'lr': 0, 'params': 323895, 'time_iter': 0.07431, 'accuracy': 0.87285, 'precision': 0.6042, 'recall': 0.8167, 'f1': 0.69456, 'auc': 0.93269, 'accuracy-SBM': 0.85081}
2025-08-16 13:30:11,094 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:30:11,495 - INFO - test: {'epoch': 90, 'time_epoch': 4.69579, 'loss': 0.09713531, 'lr': 0, 'params': 323895, 'time_iter': 0.07454, 'accuracy': 0.87474, 'precision': 0.6076, 'recall': 0.81648, 'f1': 0.69672, 'auc': 0.93335, 'accuracy-SBM': 0.85184}
2025-08-16 13:30:11,497 - INFO - > Epoch 90: took 69.0s (avg 68.4s) | Best so far: epoch 79	train_loss: 0.0898 train_accuracy-SBM: 0.8650	val_loss: 0.0909 val_accuracy-SBM: 0.8641	test_loss: 0.0897 test_accuracy-SBM: 0.8660
2025-08-16 13:30:11,497 - INFO - === Epoch 91 ===
2025-08-16 13:31:08,106 - INFO - train: {'epoch': 91, 'time_epoch': 54.29204, 'eta': 435.36417, 'eta_hours': 0.12093, 'loss': 0.08972382, 'lr': 1.099e-05, 'params': 323895, 'time_iter': 0.17346, 'accuracy': 0.8631, 'precision': 0.57424, 'recall': 0.86803, 'f1': 0.69122, 'auc': 0.94124, 'accuracy-SBM': 0.86504}
2025-08-16 13:31:13,141 - INFO - val: {'epoch': 91, 'time_epoch': 4.62559, 'loss': 0.09283823, 'lr': 0, 'params': 323895, 'time_iter': 0.07342, 'accuracy': 0.87515, 'precision': 0.6065, 'recall': 0.83926, 'f1': 0.70414, 'auc': 0.93894, 'accuracy-SBM': 0.86107}
2025-08-16 13:31:19,999 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:31:20,419 - INFO - test: {'epoch': 91, 'time_epoch': 4.68943, 'loss': 0.0917272, 'lr': 0, 'params': 323895, 'time_iter': 0.07444, 'accuracy': 0.87723, 'precision': 0.61041, 'recall': 0.83852, 'f1': 0.70651, 'auc': 0.93997, 'accuracy-SBM': 0.86202}
2025-08-16 13:31:20,423 - INFO - > Epoch 91: took 68.9s (avg 68.4s) | Best so far: epoch 79	train_loss: 0.0898 train_accuracy-SBM: 0.8650	val_loss: 0.0909 val_accuracy-SBM: 0.8641	test_loss: 0.0897 test_accuracy-SBM: 0.8660
2025-08-16 13:31:20,423 - INFO - === Epoch 92 ===
2025-08-16 13:32:17,088 - INFO - train: {'epoch': 92, 'time_epoch': 54.36374, 'eta': 380.93937, 'eta_hours': 0.10582, 'loss': 0.08975076, 'lr': 8.7e-06, 'params': 323895, 'time_iter': 0.17369, 'accuracy': 0.86264, 'precision': 0.5732, 'recall': 0.86842, 'f1': 0.69059, 'auc': 0.9412, 'accuracy-SBM': 0.86491}
2025-08-16 13:32:22,134 - INFO - val: {'epoch': 92, 'time_epoch': 4.63129, 'loss': 0.09209155, 'lr': 0, 'params': 323895, 'time_iter': 0.07351, 'accuracy': 0.86603, 'precision': 0.58284, 'recall': 0.85557, 'f1': 0.69335, 'auc': 0.93869, 'accuracy-SBM': 0.86193}
2025-08-16 13:32:28,930 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:32:29,336 - INFO - test: {'epoch': 92, 'time_epoch': 4.68999, 'loss': 0.09096108, 'lr': 0, 'params': 323895, 'time_iter': 0.07444, 'accuracy': 0.86824, 'precision': 0.58646, 'recall': 0.85572, 'f1': 0.69595, 'auc': 0.93967, 'accuracy-SBM': 0.86332}
2025-08-16 13:32:29,338 - INFO - > Epoch 92: took 68.9s (avg 68.4s) | Best so far: epoch 79	train_loss: 0.0898 train_accuracy-SBM: 0.8650	val_loss: 0.0909 val_accuracy-SBM: 0.8641	test_loss: 0.0897 test_accuracy-SBM: 0.8660
2025-08-16 13:32:29,338 - INFO - === Epoch 93 ===
2025-08-16 13:33:25,799 - INFO - train: {'epoch': 93, 'time_epoch': 54.2038, 'eta': 326.50567, 'eta_hours': 0.0907, 'loss': 0.08973042, 'lr': 6.67e-06, 'params': 323895, 'time_iter': 0.17318, 'accuracy': 0.86292, 'precision': 0.57381, 'recall': 0.86844, 'f1': 0.69103, 'auc': 0.94124, 'accuracy-SBM': 0.86509}
2025-08-16 13:33:30,823 - INFO - val: {'epoch': 93, 'time_epoch': 4.62075, 'loss': 0.09145904, 'lr': 0, 'params': 323895, 'time_iter': 0.07335, 'accuracy': 0.87073, 'precision': 0.59402, 'recall': 0.85214, 'f1': 0.70005, 'auc': 0.94014, 'accuracy-SBM': 0.86344}
2025-08-16 13:33:37,633 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:33:38,028 - INFO - test: {'epoch': 93, 'time_epoch': 4.69379, 'loss': 0.09031261, 'lr': 0, 'params': 323895, 'time_iter': 0.0745, 'accuracy': 0.87323, 'precision': 0.59834, 'recall': 0.85374, 'f1': 0.70358, 'auc': 0.94115, 'accuracy-SBM': 0.86557}
2025-08-16 13:33:38,030 - INFO - > Epoch 93: took 68.7s (avg 68.4s) | Best so far: epoch 79	train_loss: 0.0898 train_accuracy-SBM: 0.8650	val_loss: 0.0909 val_accuracy-SBM: 0.8641	test_loss: 0.0897 test_accuracy-SBM: 0.8660
2025-08-16 13:33:38,031 - INFO - === Epoch 94 ===
2025-08-16 13:34:32,753 - INFO - train: {'epoch': 94, 'time_epoch': 54.38965, 'eta': 272.08658, 'eta_hours': 0.07558, 'loss': 0.08969682, 'lr': 4.91e-06, 'params': 323895, 'time_iter': 0.17377, 'accuracy': 0.86317, 'precision': 0.5744, 'recall': 0.86788, 'f1': 0.69128, 'auc': 0.94132, 'accuracy-SBM': 0.86502}
2025-08-16 13:34:37,798 - INFO - val: {'epoch': 94, 'time_epoch': 4.62885, 'loss': 0.09059245, 'lr': 0, 'params': 323895, 'time_iter': 0.07347, 'accuracy': 0.86143, 'precision': 0.57127, 'recall': 0.87063, 'f1': 0.68987, 'auc': 0.94116, 'accuracy-SBM': 0.86504}
2025-08-16 13:34:44,589 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:34:45,020 - INFO - test: {'epoch': 94, 'time_epoch': 4.70434, 'loss': 0.08941322, 'lr': 0, 'params': 323895, 'time_iter': 0.07467, 'accuracy': 0.86462, 'precision': 0.57673, 'recall': 0.87094, 'f1': 0.69394, 'auc': 0.94212, 'accuracy-SBM': 0.8671}
2025-08-16 13:34:45,022 - INFO - > Epoch 94: took 67.0s (avg 68.4s) | Best so far: epoch 94	train_loss: 0.0897 train_accuracy-SBM: 0.8650	val_loss: 0.0906 val_accuracy-SBM: 0.8650	test_loss: 0.0894 test_accuracy-SBM: 0.8671
2025-08-16 13:34:45,022 - INFO - === Epoch 95 ===
2025-08-16 13:35:40,716 - INFO - train: {'epoch': 95, 'time_epoch': 54.34648, 'eta': 217.66632, 'eta_hours': 0.06046, 'loss': 0.08970309, 'lr': 3.41e-06, 'params': 323895, 'time_iter': 0.17363, 'accuracy': 0.86275, 'precision': 0.5734, 'recall': 0.86881, 'f1': 0.69085, 'auc': 0.94131, 'accuracy-SBM': 0.86513}
2025-08-16 13:35:45,757 - INFO - val: {'epoch': 95, 'time_epoch': 4.63067, 'loss': 0.0917199, 'lr': 0, 'params': 323895, 'time_iter': 0.0735, 'accuracy': 0.86447, 'precision': 0.579, 'recall': 0.85884, 'f1': 0.69169, 'auc': 0.939, 'accuracy-SBM': 0.86226}
2025-08-16 13:35:52,610 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:35:53,045 - INFO - test: {'epoch': 95, 'time_epoch': 4.70564, 'loss': 0.09058696, 'lr': 0, 'params': 323895, 'time_iter': 0.07469, 'accuracy': 0.86684, 'precision': 0.58283, 'recall': 0.85965, 'f1': 0.69467, 'auc': 0.93997, 'accuracy-SBM': 0.86401}
2025-08-16 13:35:53,048 - INFO - > Epoch 95: took 68.0s (avg 68.4s) | Best so far: epoch 94	train_loss: 0.0897 train_accuracy-SBM: 0.8650	val_loss: 0.0906 val_accuracy-SBM: 0.8650	test_loss: 0.0894 test_accuracy-SBM: 0.8671
2025-08-16 13:35:53,049 - INFO - === Epoch 96 ===
2025-08-16 13:36:49,708 - INFO - train: {'epoch': 96, 'time_epoch': 54.28407, 'eta': 163.24564, 'eta_hours': 0.04535, 'loss': 0.08976108, 'lr': 2.18e-06, 'params': 323895, 'time_iter': 0.17343, 'accuracy': 0.86294, 'precision': 0.57389, 'recall': 0.86805, 'f1': 0.69096, 'auc': 0.94123, 'accuracy-SBM': 0.86494}
2025-08-16 13:36:54,799 - INFO - val: {'epoch': 96, 'time_epoch': 4.66561, 'loss': 0.09173108, 'lr': 0, 'params': 323895, 'time_iter': 0.07406, 'accuracy': 0.86922, 'precision': 0.59045, 'recall': 0.8526, 'f1': 0.69771, 'auc': 0.93952, 'accuracy-SBM': 0.8627}
2025-08-16 13:37:01,624 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:37:02,034 - INFO - test: {'epoch': 96, 'time_epoch': 4.70723, 'loss': 0.09059195, 'lr': 0, 'params': 323895, 'time_iter': 0.07472, 'accuracy': 0.87158, 'precision': 0.59441, 'recall': 0.85388, 'f1': 0.7009, 'auc': 0.94052, 'accuracy-SBM': 0.86462}
2025-08-16 13:37:02,038 - INFO - > Epoch 96: took 69.0s (avg 68.4s) | Best so far: epoch 94	train_loss: 0.0897 train_accuracy-SBM: 0.8650	val_loss: 0.0906 val_accuracy-SBM: 0.8650	test_loss: 0.0894 test_accuracy-SBM: 0.8671
2025-08-16 13:37:02,038 - INFO - === Epoch 97 ===
2025-08-16 13:37:57,742 - INFO - train: {'epoch': 97, 'time_epoch': 54.35051, 'eta': 108.82911, 'eta_hours': 0.03023, 'loss': 0.08978029, 'lr': 1.23e-06, 'params': 323895, 'time_iter': 0.17364, 'accuracy': 0.8627, 'precision': 0.57346, 'recall': 0.86724, 'f1': 0.6904, 'auc': 0.9412, 'accuracy-SBM': 0.86448}
2025-08-16 13:38:02,800 - INFO - val: {'epoch': 97, 'time_epoch': 4.63834, 'loss': 0.09267213, 'lr': 0, 'params': 323895, 'time_iter': 0.07362, 'accuracy': 0.87361, 'precision': 0.60232, 'recall': 0.84181, 'f1': 0.70221, 'auc': 0.93876, 'accuracy-SBM': 0.86113}
2025-08-16 13:38:09,603 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:38:10,004 - INFO - test: {'epoch': 97, 'time_epoch': 4.707, 'loss': 0.09158137, 'lr': 0, 'params': 323895, 'time_iter': 0.07471, 'accuracy': 0.87575, 'precision': 0.60617, 'recall': 0.84192, 'f1': 0.70486, 'auc': 0.93976, 'accuracy-SBM': 0.86246}
2025-08-16 13:38:10,007 - INFO - > Epoch 97: took 68.0s (avg 68.4s) | Best so far: epoch 94	train_loss: 0.0897 train_accuracy-SBM: 0.8650	val_loss: 0.0906 val_accuracy-SBM: 0.8650	test_loss: 0.0894 test_accuracy-SBM: 0.8671
2025-08-16 13:38:10,007 - INFO - === Epoch 98 ===
2025-08-16 13:39:06,653 - INFO - train: {'epoch': 98, 'time_epoch': 54.29007, 'eta': 54.4133, 'eta_hours': 0.01511, 'loss': 0.08975495, 'lr': 5.5e-07, 'params': 323895, 'time_iter': 0.17345, 'accuracy': 0.86279, 'precision': 0.57353, 'recall': 0.86846, 'f1': 0.69083, 'auc': 0.94124, 'accuracy-SBM': 0.86502}
2025-08-16 13:39:11,719 - INFO - val: {'epoch': 98, 'time_epoch': 4.6326, 'loss': 0.09132753, 'lr': 0, 'params': 323895, 'time_iter': 0.07353, 'accuracy': 0.86612, 'precision': 0.58264, 'recall': 0.85908, 'f1': 0.69435, 'auc': 0.93987, 'accuracy-SBM': 0.86335}
2025-08-16 13:39:18,723 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:39:19,130 - INFO - test: {'epoch': 98, 'time_epoch': 4.70301, 'loss': 0.09017005, 'lr': 0, 'params': 323895, 'time_iter': 0.07465, 'accuracy': 0.86872, 'precision': 0.58699, 'recall': 0.86031, 'f1': 0.69785, 'auc': 0.94087, 'accuracy-SBM': 0.86541}
2025-08-16 13:39:19,132 - INFO - > Epoch 98: took 69.1s (avg 68.4s) | Best so far: epoch 94	train_loss: 0.0897 train_accuracy-SBM: 0.8650	val_loss: 0.0906 val_accuracy-SBM: 0.8650	test_loss: 0.0894 test_accuracy-SBM: 0.8671
2025-08-16 13:39:19,132 - INFO - === Epoch 99 ===
2025-08-16 13:40:15,799 - INFO - train: {'epoch': 99, 'time_epoch': 54.3677, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.08980288, 'lr': 1.4e-07, 'params': 323895, 'time_iter': 0.1737, 'accuracy': 0.8628, 'precision': 0.5736, 'recall': 0.86809, 'f1': 0.69076, 'auc': 0.94113, 'accuracy-SBM': 0.86488}
2025-08-16 13:40:20,840 - INFO - val: {'epoch': 99, 'time_epoch': 4.62666, 'loss': 0.09451249, 'lr': 0, 'params': 323895, 'time_iter': 0.07344, 'accuracy': 0.87452, 'precision': 0.60622, 'recall': 0.83078, 'f1': 0.70095, 'auc': 0.93662, 'accuracy-SBM': 0.85735}
2025-08-16 13:40:27,666 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-NASSPARSE-49/test_results
2025-08-16 13:40:28,085 - INFO - test: {'epoch': 99, 'time_epoch': 4.70203, 'loss': 0.09353355, 'lr': 0, 'params': 323895, 'time_iter': 0.07464, 'accuracy': 0.87652, 'precision': 0.60995, 'recall': 0.8302, 'f1': 0.70324, 'auc': 0.93753, 'accuracy-SBM': 0.85832}
2025-08-16 13:40:28,274 - INFO - > Epoch 99: took 69.0s (avg 68.4s) | Best so far: epoch 94	train_loss: 0.0897 train_accuracy-SBM: 0.8650	val_loss: 0.0906 val_accuracy-SBM: 0.8650	test_loss: 0.0894 test_accuracy-SBM: 0.8671
2025-08-16 13:40:28,274 - INFO - ================================================================================
2025-08-16 13:40:28,274 - INFO - NAS TRAINING COMPLETED SUCCESSFULLY
2025-08-16 13:40:28,274 - INFO - ================================================================================
2025-08-16 13:40:28,274 - INFO - Avg time per epoch: 68.39s
2025-08-16 13:40:28,274 - INFO - Total train loop time: 1.90h
2025-08-16 13:40:28,274 - INFO - Routing mode: nas
2025-08-16 13:40:28,274 - INFO - Final optimal weights: {'layer_0': 2, 'layer_1': 0, 'layer_2': 2, 'layer_3': 1, 'layer_4': 1, 'layer_5': 2}
Completed seed 49. Results saved in results/pattern/pattern-NASSPARSE-49
----------------------------------------
All experiments completed!
