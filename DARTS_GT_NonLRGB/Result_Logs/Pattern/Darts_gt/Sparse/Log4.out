Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          377Gi        12Gi       357Gi       1.7Gi       7.5Gi       360Gi
Swap:         1.9Gi       2.0Mi       1.9Gi
Sat Jul  5 05:37:08 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           On  |   00000000:06:00.0 Off |                    0 |
| N/A   47C    P0             26W /  250W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 45
Starting training for seed 45...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/PATTERN/FINAL_SINGLE/SPARSE_E
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/PATTERN/FINAL_SINGLE/SPARSE_E/confignas.yaml
Using device: cuda
2025-07-05 05:37:16,963 - INFO - GPU Mem: 34.1GB
2025-07-05 05:37:16,963 - INFO - Run directory: results/pattern/pattern-SPARSE-45
2025-07-05 05:37:16,963 - INFO - Seed: 45
2025-07-05 05:37:16,964 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-07-05 05:37:16,964 - INFO - Routing mode: nas
2025-07-05 05:37:16,964 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-07-05 05:37:16,964 - INFO - Number of layers: 6
2025-07-05 05:37:16,964 - INFO - Uncertainty enabled: False
2025-07-05 05:37:16,964 - INFO - Training mode: NoMixNas_uncertainty_train
2025-07-05 05:37:16,964 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-07-05 05:37:16,964 - INFO - Additional features: Router weights logging + JSON export
2025-07-05 05:37:36,455 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-05 05:37:36,457 - INFO -   Data(x=[1664491, 3], edge_index=[2, 85099952], y=[1664491])
2025-07-05 05:37:36,458 - INFO -   undirected: True
2025-07-05 05:37:36,458 - INFO -   num graphs: 14000
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-05 05:37:36,458 - INFO -   avg num_nodes/graph: 118
2025-07-05 05:37:36,458 - INFO -   num node features: 3
2025-07-05 05:37:36,458 - INFO -   num edge features: 0
2025-07-05 05:37:36,460 - INFO -   num classes: 2
2025-07-05 05:37:36,460 - INFO - Precomputing Positional Encoding statistics: ['LapPE'] for all graphs...
2025-07-05 05:37:36,468 - INFO -   ...estimated to be undirected: True
  0%|          | 0/14000 [00:00<?, ?it/s] 30%|██▉       | 4173/14000 [00:10<00:23, 417.25it/s] 59%|█████▉    | 8254/14000 [00:20<00:13, 411.84it/s] 90%|████████▉ | 12532/14000 [00:30<00:03, 419.11it/s]100%|██████████| 14000/14000 [00:33<00:00, 415.31it/s]
2025-07-05 05:38:10,994 - INFO - Done! Took 00:00:34.53
2025-07-05 05:38:11,014 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset'
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/nni/nas/nn/pytorch/choice.py:252: UserWarning: "key" is deprecated. Assuming label.
  warnings.warn(f'"key" is deprecated. Assuming label.')
2025-07-05 05:38:11,285 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-07-05 05:38:11,286 - INFO - Inner model type: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-07-05 05:38:11,286 - INFO - Inner model has get_darts_model: True
2025-07-05 05:38:11,288 - INFO - GraphGymModule(
  (model): NASModelEdge(
    (encoder): FeatureEncoder(
      (node_encoder): LapPENodeEncoder(
        (linear_x): Linear(in_features=3, out_features=48, bias=True)
        (linear_A): Linear(in_features=2, out_features=32, bias=True)
        (pe_encoder): Sequential(
          (0): ReLU()
          (1): Linear(in_features=32, out_features=16, bias=True)
          (2): ReLU()
        )
      )
      (edge_encoder): DummyEdgeEncoder(
        (encoder): Embedding(1, 64)
      )
    )
    (darts_layers): ModuleList(
      (0): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (darts_sequential): Sequential(
      (0): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(64, 1, bias=True)
          )
        )
      )
    )
  )
)
2025-07-05 05:38:11,291 - INFO - Number of parameters: 487,351
2025-07-05 05:38:11,291 - INFO - Starting optimized training: 2025-07-05 05:38:11.291872
2025-07-05 05:38:17,089 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset':
2025-07-05 05:38:17,089 - INFO -   Data(x=[1664491, 3], edge_index=[2, 85099952], y=[1664491])
2025-07-05 05:38:17,090 - INFO -   undirected: True
2025-07-05 05:38:17,090 - INFO -   num graphs: 14000
2025-07-05 05:38:17,090 - INFO -   avg num_nodes/graph: 118
2025-07-05 05:38:17,090 - INFO -   num node features: 3
2025-07-05 05:38:17,091 - INFO -   num edge features: 0
2025-07-05 05:38:17,092 - INFO -   num classes: 2
2025-07-05 05:38:17,092 - INFO - Precomputing Positional Encoding statistics: ['LapPE'] for all graphs...
2025-07-05 05:38:17,100 - INFO -   ...estimated to be undirected: True
  0%|          | 0/14000 [00:00<?, ?it/s] 29%|██▉       | 4115/14000 [00:10<00:24, 411.45it/s] 59%|█████▉    | 8271/14000 [00:20<00:13, 413.84it/s] 89%|████████▉ | 12499/14000 [00:30<00:03, 417.93it/s]100%|██████████| 14000/14000 [00:33<00:00, 416.80it/s]
2025-07-05 05:38:51,522 - INFO - Done! Took 00:00:34.43
2025-07-05 05:38:51,546 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset'
2025-07-05 05:38:51,559 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-07-05 05:38:51,559 - INFO - Start from epoch 0
2025-07-05 05:38:51,559 - INFO - ================================================================================
2025-07-05 05:38:51,559 - INFO - STARTING TWO-PHASE NAS TRAINING
2025-07-05 05:38:51,559 - INFO - ================================================================================
2025-07-05 05:38:51,559 - INFO - Routing mode: nas
2025-07-05 05:38:51,559 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-07-05 05:38:51,559 - INFO - Phase 1: Architecture search/initialization
2025-07-05 05:38:51,559 - INFO - Phase 2: Discrete training with uncertainty (NO variance)
2025-07-05 05:38:51,559 - INFO - ============================================================
2025-07-05 05:38:51,559 - INFO - PHASE 1: ARCHITECTURE SEARCH/INITIALIZATION
2025-07-05 05:38:51,560 - INFO - ============================================================
2025-07-05 05:38:51,560 - INFO - Splitting dataset for DARTS:
2025-07-05 05:38:51,560 - INFO -   Original train size: 10000
2025-07-05 05:38:51,560 - INFO -   DARTS train size: 6000 (60.0%)
2025-07-05 05:38:51,560 - INFO -   DARTS val size: 4000 (40.0%)
2025-07-05 05:38:51,561 - INFO - Found GraphGym wrapper, using inner model: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-07-05 05:38:51,561 - INFO - Successfully configured model for DARTS training
2025-07-05 05:38:51,561 - INFO - NAS MODE: Running 20 epochs with DARTS
2025-07-05 05:38:51,561 - INFO - DARTS Configuration:
2025-07-05 05:38:51,561 - INFO -   Epochs: 20
2025-07-05 05:38:51,561 - INFO -   Architecture LR: 0.0004
2025-07-05 05:38:51,561 - INFO -   Grad clip: 5.0
2025-07-05 05:38:51,563 - INFO - Starting DARTS architecture search
2025-07-05 05:38:52,830 - WARNING - Epoch [1/20] Step [1/125]  acc 0.796535 (0.796535)  loss 0.674006 (0.674006)
GPU memory consumption  GPU Memory: Allocated: 133.3 MB, Reserved: 7784.0 MB
2025-07-05 05:38:55,784 - WARNING - Epoch [1/20] Step [11/125]  acc 0.809301 (0.819736)  loss 0.545956 (0.591703)
GPU memory consumption  GPU Memory: Allocated: 125.3 MB, Reserved: 9416.0 MB
2025-07-05 05:38:58,729 - WARNING - Epoch [1/20] Step [21/125]  acc 0.882483 (0.831482)  loss 0.490865 (0.553080)
GPU memory consumption  GPU Memory: Allocated: 124.0 MB, Reserved: 9416.0 MB
2025-07-05 05:39:01,691 - WARNING - Epoch [1/20] Step [31/125]  acc 0.906098 (0.847394)  loss 0.434270 (0.524735)
GPU memory consumption  GPU Memory: Allocated: 134.0 MB, Reserved: 9416.0 MB
2025-07-05 05:39:04,643 - WARNING - Epoch [1/20] Step [41/125]  acc 0.892923 (0.858314)  loss 0.416805 (0.500873)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 9418.0 MB
2025-07-05 05:39:07,598 - WARNING - Epoch [1/20] Step [51/125]  acc 0.909115 (0.865973)  loss 0.373888 (0.480753)
GPU memory consumption  GPU Memory: Allocated: 129.3 MB, Reserved: 9418.0 MB
2025-07-05 05:39:10,538 - WARNING - Epoch [1/20] Step [61/125]  acc 0.890938 (0.870298)  loss 0.370432 (0.464206)
GPU memory consumption  GPU Memory: Allocated: 120.3 MB, Reserved: 9418.0 MB
2025-07-05 05:39:13,662 - WARNING - Epoch [1/20] Step [71/125]  acc 0.880959 (0.873379)  loss 0.364593 (0.450253)
GPU memory consumption  GPU Memory: Allocated: 121.1 MB, Reserved: 10984.0 MB
2025-07-05 05:39:16,641 - WARNING - Epoch [1/20] Step [81/125]  acc 0.903581 (0.876568)  loss 0.325794 (0.436889)
GPU memory consumption  GPU Memory: Allocated: 124.3 MB, Reserved: 10986.0 MB
2025-07-05 05:39:19,554 - WARNING - Epoch [1/20] Step [91/125]  acc 0.887204 (0.878629)  loss 0.342817 (0.425703)
GPU memory consumption  GPU Memory: Allocated: 124.1 MB, Reserved: 10986.0 MB
2025-07-05 05:39:22,513 - WARNING - Epoch [1/20] Step [101/125]  acc 0.906289 (0.880549)  loss 0.300808 (0.415393)
GPU memory consumption  GPU Memory: Allocated: 130.8 MB, Reserved: 10986.0 MB
2025-07-05 05:39:25,450 - WARNING - Epoch [1/20] Step [111/125]  acc 0.895647 (0.881504)  loss 0.306340 (0.406712)
GPU memory consumption  GPU Memory: Allocated: 121.5 MB, Reserved: 10986.0 MB
2025-07-05 05:39:28,421 - WARNING - Epoch [1/20] Step [121/125]  acc 0.901736 (0.882943)  loss 0.286188 (0.398205)
GPU memory consumption  GPU Memory: Allocated: 128.1 MB, Reserved: 13538.0 MB
Epoch 1 completed in 0:00:38.046032
2025-07-05 05:39:39,393 - WARNING - Epoch [2/20] Step [1/125]  acc 0.896880 (0.896880)  loss 0.302949 (0.302949)
GPU memory consumption  GPU Memory: Allocated: 125.7 MB, Reserved: 13548.0 MB
2025-07-05 05:39:42,266 - WARNING - Epoch [2/20] Step [11/125]  acc 0.886046 (0.894966)  loss 0.308923 (0.302516)
GPU memory consumption  GPU Memory: Allocated: 125.6 MB, Reserved: 13548.0 MB
2025-07-05 05:39:45,157 - WARNING - Epoch [2/20] Step [21/125]  acc 0.885422 (0.897260)  loss 0.314226 (0.297046)
GPU memory consumption  GPU Memory: Allocated: 129.5 MB, Reserved: 13548.0 MB
2025-07-05 05:39:48,058 - WARNING - Epoch [2/20] Step [31/125]  acc 0.898013 (0.898391)  loss 0.283531 (0.293528)
GPU memory consumption  GPU Memory: Allocated: 127.2 MB, Reserved: 13548.0 MB
2025-07-05 05:39:50,961 - WARNING - Epoch [2/20] Step [41/125]  acc 0.895263 (0.898166)  loss 0.301037 (0.291896)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 13548.0 MB
2025-07-05 05:39:53,841 - WARNING - Epoch [2/20] Step [51/125]  acc 0.886601 (0.897693)  loss 0.295573 (0.290543)
GPU memory consumption  GPU Memory: Allocated: 124.2 MB, Reserved: 13548.0 MB
2025-07-05 05:39:56,711 - WARNING - Epoch [2/20] Step [61/125]  acc 0.898580 (0.897523)  loss 0.273174 (0.289173)
GPU memory consumption  GPU Memory: Allocated: 126.1 MB, Reserved: 13548.0 MB
2025-07-05 05:39:59,616 - WARNING - Epoch [2/20] Step [71/125]  acc 0.889533 (0.898078)  loss 0.280790 (0.286530)
GPU memory consumption  GPU Memory: Allocated: 124.5 MB, Reserved: 13548.0 MB
2025-07-05 05:40:02,551 - WARNING - Epoch [2/20] Step [81/125]  acc 0.913140 (0.898677)  loss 0.256501 (0.283864)
GPU memory consumption  GPU Memory: Allocated: 128.4 MB, Reserved: 13548.0 MB
2025-07-05 05:40:05,460 - WARNING - Epoch [2/20] Step [91/125]  acc 0.902360 (0.899442)  loss 0.255718 (0.281158)
GPU memory consumption  GPU Memory: Allocated: 123.7 MB, Reserved: 13548.0 MB
2025-07-05 05:40:08,441 - WARNING - Epoch [2/20] Step [101/125]  acc 0.904750 (0.899138)  loss 0.254253 (0.280469)
GPU memory consumption  GPU Memory: Allocated: 126.6 MB, Reserved: 13548.0 MB
2025-07-05 05:40:11,349 - WARNING - Epoch [2/20] Step [111/125]  acc 0.906389 (0.899193)  loss 0.253367 (0.279261)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 13548.0 MB
2025-07-05 05:40:14,199 - WARNING - Epoch [2/20] Step [121/125]  acc 0.870662 (0.898919)  loss 0.317667 (0.278606)
GPU memory consumption  GPU Memory: Allocated: 122.5 MB, Reserved: 13548.0 MB
Epoch 2 completed in 0:00:36.289643
2025-07-05 05:40:25,146 - WARNING - Epoch [3/20] Step [1/125]  acc 0.887001 (0.887001)  loss 0.283247 (0.283247)
GPU memory consumption  GPU Memory: Allocated: 124.7 MB, Reserved: 13548.0 MB
2025-07-05 05:40:28,019 - WARNING - Epoch [3/20] Step [11/125]  acc 0.893715 (0.899167)  loss 0.274868 (0.262301)
GPU memory consumption  GPU Memory: Allocated: 121.2 MB, Reserved: 13548.0 MB
2025-07-05 05:40:30,947 - WARNING - Epoch [3/20] Step [21/125]  acc 0.903851 (0.898182)  loss 0.256177 (0.264949)
GPU memory consumption  GPU Memory: Allocated: 125.7 MB, Reserved: 13548.0 MB
2025-07-05 05:40:33,848 - WARNING - Epoch [3/20] Step [31/125]  acc 0.912109 (0.898842)  loss 0.249877 (0.263085)
GPU memory consumption  GPU Memory: Allocated: 123.7 MB, Reserved: 13552.0 MB
2025-07-05 05:40:36,764 - WARNING - Epoch [3/20] Step [41/125]  acc 0.899809 (0.899159)  loss 0.263553 (0.261806)
GPU memory consumption  GPU Memory: Allocated: 123.3 MB, Reserved: 13552.0 MB
2025-07-05 05:40:39,679 - WARNING - Epoch [3/20] Step [51/125]  acc 0.907605 (0.899418)  loss 0.247933 (0.261504)
GPU memory consumption  GPU Memory: Allocated: 129.4 MB, Reserved: 13552.0 MB
2025-07-05 05:40:42,586 - WARNING - Epoch [3/20] Step [61/125]  acc 0.902012 (0.899693)  loss 0.245905 (0.260685)
GPU memory consumption  GPU Memory: Allocated: 123.0 MB, Reserved: 13552.0 MB
2025-07-05 05:40:45,473 - WARNING - Epoch [3/20] Step [71/125]  acc 0.905742 (0.900185)  loss 0.245300 (0.259213)
GPU memory consumption  GPU Memory: Allocated: 122.9 MB, Reserved: 13552.0 MB
2025-07-05 05:40:48,422 - WARNING - Epoch [3/20] Step [81/125]  acc 0.898597 (0.900978)  loss 0.259902 (0.257444)
GPU memory consumption  GPU Memory: Allocated: 122.3 MB, Reserved: 13552.0 MB
2025-07-05 05:40:51,313 - WARNING - Epoch [3/20] Step [91/125]  acc 0.895542 (0.901085)  loss 0.262231 (0.256859)
GPU memory consumption  GPU Memory: Allocated: 123.8 MB, Reserved: 13552.0 MB
2025-07-05 05:40:54,238 - WARNING - Epoch [3/20] Step [101/125]  acc 0.910228 (0.901039)  loss 0.241618 (0.256661)
GPU memory consumption  GPU Memory: Allocated: 121.6 MB, Reserved: 13552.0 MB
2025-07-05 05:40:57,140 - WARNING - Epoch [3/20] Step [111/125]  acc 0.897569 (0.901075)  loss 0.264686 (0.256153)
GPU memory consumption  GPU Memory: Allocated: 131.3 MB, Reserved: 13552.0 MB
2025-07-05 05:41:00,002 - WARNING - Epoch [3/20] Step [121/125]  acc 0.895845 (0.900941)  loss 0.272721 (0.256163)
GPU memory consumption  GPU Memory: Allocated: 121.0 MB, Reserved: 13552.0 MB
Epoch 3 completed in 0:00:36.286726
2025-07-05 05:41:10,898 - WARNING - Epoch [4/20] Step [1/125]  acc 0.906864 (0.906864)  loss 0.234392 (0.234392)
GPU memory consumption  GPU Memory: Allocated: 129.1 MB, Reserved: 13552.0 MB
2025-07-05 05:41:13,767 - WARNING - Epoch [4/20] Step [11/125]  acc 0.897227 (0.898841)  loss 0.255956 (0.256423)
GPU memory consumption  GPU Memory: Allocated: 121.0 MB, Reserved: 13552.0 MB
2025-07-05 05:41:16,650 - WARNING - Epoch [4/20] Step [21/125]  acc 0.904505 (0.899694)  loss 0.239576 (0.253653)
GPU memory consumption  GPU Memory: Allocated: 131.2 MB, Reserved: 13552.0 MB
2025-07-05 05:41:19,561 - WARNING - Epoch [4/20] Step [31/125]  acc 0.886179 (0.898853)  loss 0.279039 (0.254758)
GPU memory consumption  GPU Memory: Allocated: 123.9 MB, Reserved: 13552.0 MB
2025-07-05 05:41:22,465 - WARNING - Epoch [4/20] Step [41/125]  acc 0.892270 (0.899603)  loss 0.264483 (0.253705)
GPU memory consumption  GPU Memory: Allocated: 124.4 MB, Reserved: 13552.0 MB
2025-07-05 05:41:25,380 - WARNING - Epoch [4/20] Step [51/125]  acc 0.897964 (0.901292)  loss 0.255230 (0.250617)
GPU memory consumption  GPU Memory: Allocated: 131.4 MB, Reserved: 13552.0 MB
2025-07-05 05:41:28,284 - WARNING - Epoch [4/20] Step [61/125]  acc 0.899686 (0.901082)  loss 0.246032 (0.250228)
GPU memory consumption  GPU Memory: Allocated: 123.4 MB, Reserved: 13552.0 MB
2025-07-05 05:41:31,175 - WARNING - Epoch [4/20] Step [71/125]  acc 0.910233 (0.901294)  loss 0.236490 (0.249676)
GPU memory consumption  GPU Memory: Allocated: 125.9 MB, Reserved: 13552.0 MB
2025-07-05 05:41:34,057 - WARNING - Epoch [4/20] Step [81/125]  acc 0.899240 (0.901705)  loss 0.252689 (0.248707)
GPU memory consumption  GPU Memory: Allocated: 118.9 MB, Reserved: 13552.0 MB
2025-07-05 05:41:36,940 - WARNING - Epoch [4/20] Step [91/125]  acc 0.893305 (0.901937)  loss 0.267589 (0.248378)
GPU memory consumption  GPU Memory: Allocated: 123.9 MB, Reserved: 13552.0 MB
2025-07-05 05:41:39,865 - WARNING - Epoch [4/20] Step [101/125]  acc 0.905655 (0.901776)  loss 0.237544 (0.248366)
GPU memory consumption  GPU Memory: Allocated: 122.9 MB, Reserved: 13552.0 MB
2025-07-05 05:41:42,749 - WARNING - Epoch [4/20] Step [111/125]  acc 0.895000 (0.901720)  loss 0.261752 (0.248402)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 13552.0 MB
2025-07-05 05:41:45,569 - WARNING - Epoch [4/20] Step [121/125]  acc 0.889103 (0.901595)  loss 0.274942 (0.248351)
GPU memory consumption  GPU Memory: Allocated: 121.1 MB, Reserved: 13552.0 MB
Epoch 4 completed in 0:00:36.116826
2025-07-05 05:41:56,456 - WARNING - Epoch [5/20] Step [1/125]  acc 0.913272 (0.913272)  loss 0.229207 (0.229207)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 13552.0 MB
2025-07-05 05:41:59,355 - WARNING - Epoch [5/20] Step [11/125]  acc 0.908574 (0.901255)  loss 0.227833 (0.247777)
GPU memory consumption  GPU Memory: Allocated: 131.0 MB, Reserved: 13552.0 MB
2025-07-05 05:42:02,272 - WARNING - Epoch [5/20] Step [21/125]  acc 0.897189 (0.900983)  loss 0.256408 (0.249165)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 13552.0 MB
2025-07-05 05:42:05,334 - WARNING - Epoch [5/20] Step [31/125]  acc 0.900159 (0.901239)  loss 0.247380 (0.247112)
GPU memory consumption  GPU Memory: Allocated: 125.2 MB, Reserved: 13552.0 MB
2025-07-05 05:42:08,187 - WARNING - Epoch [5/20] Step [41/125]  acc 0.906317 (0.901912)  loss 0.236692 (0.245184)
GPU memory consumption  GPU Memory: Allocated: 124.2 MB, Reserved: 13552.0 MB
2025-07-05 05:42:11,095 - WARNING - Epoch [5/20] Step [51/125]  acc 0.893939 (0.901719)  loss 0.256244 (0.245634)
GPU memory consumption  GPU Memory: Allocated: 129.3 MB, Reserved: 13552.0 MB
2025-07-05 05:42:13,957 - WARNING - Epoch [5/20] Step [61/125]  acc 0.905133 (0.901889)  loss 0.228348 (0.244801)
GPU memory consumption  GPU Memory: Allocated: 119.8 MB, Reserved: 13552.0 MB
2025-07-05 05:42:16,863 - WARNING - Epoch [5/20] Step [71/125]  acc 0.896819 (0.902179)  loss 0.251342 (0.244355)
GPU memory consumption  GPU Memory: Allocated: 123.9 MB, Reserved: 13552.0 MB
2025-07-05 05:42:19,733 - WARNING - Epoch [5/20] Step [81/125]  acc 0.899773 (0.901965)  loss 0.245139 (0.244664)
GPU memory consumption  GPU Memory: Allocated: 125.7 MB, Reserved: 13552.0 MB
2025-07-05 05:42:22,625 - WARNING - Epoch [5/20] Step [91/125]  acc 0.907712 (0.902359)  loss 0.222781 (0.243984)
GPU memory consumption  GPU Memory: Allocated: 129.0 MB, Reserved: 13552.0 MB
2025-07-05 05:42:25,530 - WARNING - Epoch [5/20] Step [101/125]  acc 0.908663 (0.902430)  loss 0.231647 (0.243893)
GPU memory consumption  GPU Memory: Allocated: 120.0 MB, Reserved: 13552.0 MB
2025-07-05 05:42:28,443 - WARNING - Epoch [5/20] Step [111/125]  acc 0.901951 (0.902118)  loss 0.242601 (0.244422)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 13552.0 MB
2025-07-05 05:42:31,300 - WARNING - Epoch [5/20] Step [121/125]  acc 0.914644 (0.902245)  loss 0.208539 (0.243973)
GPU memory consumption  GPU Memory: Allocated: 125.5 MB, Reserved: 13552.0 MB
Epoch 5 completed in 0:00:36.288586
2025-07-05 05:42:42,167 - WARNING - Epoch [6/20] Step [1/125]  acc 0.889067 (0.889067)  loss 0.270774 (0.270774)
GPU memory consumption  GPU Memory: Allocated: 125.1 MB, Reserved: 13552.0 MB
2025-07-05 05:42:45,038 - WARNING - Epoch [6/20] Step [11/125]  acc 0.904002 (0.903453)  loss 0.230218 (0.241045)
GPU memory consumption  GPU Memory: Allocated: 124.8 MB, Reserved: 13552.0 MB
2025-07-05 05:42:47,939 - WARNING - Epoch [6/20] Step [21/125]  acc 0.916560 (0.905308)  loss 0.211651 (0.237392)
GPU memory consumption  GPU Memory: Allocated: 132.3 MB, Reserved: 13552.0 MB
2025-07-05 05:42:50,817 - WARNING - Epoch [6/20] Step [31/125]  acc 0.902245 (0.904523)  loss 0.248073 (0.239301)
GPU memory consumption  GPU Memory: Allocated: 119.6 MB, Reserved: 13552.0 MB
2025-07-05 05:42:53,744 - WARNING - Epoch [6/20] Step [41/125]  acc 0.893305 (0.904240)  loss 0.257788 (0.239407)
GPU memory consumption  GPU Memory: Allocated: 125.4 MB, Reserved: 13552.0 MB
2025-07-05 05:42:56,621 - WARNING - Epoch [6/20] Step [51/125]  acc 0.900908 (0.903859)  loss 0.246571 (0.239741)
GPU memory consumption  GPU Memory: Allocated: 130.2 MB, Reserved: 13552.0 MB
2025-07-05 05:42:59,496 - WARNING - Epoch [6/20] Step [61/125]  acc 0.904989 (0.904169)  loss 0.245675 (0.239403)
GPU memory consumption  GPU Memory: Allocated: 121.5 MB, Reserved: 13552.0 MB
2025-07-05 05:43:02,422 - WARNING - Epoch [6/20] Step [71/125]  acc 0.915752 (0.904754)  loss 0.223391 (0.238778)
GPU memory consumption  GPU Memory: Allocated: 128.0 MB, Reserved: 13552.0 MB
2025-07-05 05:43:05,329 - WARNING - Epoch [6/20] Step [81/125]  acc 0.889366 (0.904690)  loss 0.265450 (0.238760)
GPU memory consumption  GPU Memory: Allocated: 120.4 MB, Reserved: 13552.0 MB
2025-07-05 05:43:08,194 - WARNING - Epoch [6/20] Step [91/125]  acc 0.885729 (0.904479)  loss 0.280369 (0.239075)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 13552.0 MB
2025-07-05 05:43:11,110 - WARNING - Epoch [6/20] Step [101/125]  acc 0.908245 (0.904590)  loss 0.231301 (0.238715)
GPU memory consumption  GPU Memory: Allocated: 130.0 MB, Reserved: 13552.0 MB
2025-07-05 05:43:13,992 - WARNING - Epoch [6/20] Step [111/125]  acc 0.894556 (0.904112)  loss 0.256357 (0.239478)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 13552.0 MB
2025-07-05 05:43:16,836 - WARNING - Epoch [6/20] Step [121/125]  acc 0.895282 (0.903340)  loss 0.258333 (0.240823)
GPU memory consumption  GPU Memory: Allocated: 122.2 MB, Reserved: 13552.0 MB
Epoch 6 completed in 0:00:36.119581
2025-07-05 05:43:27,708 - WARNING - Epoch [7/20] Step [1/125]  acc 0.890738 (0.890738)  loss 0.266454 (0.266454)
GPU memory consumption  GPU Memory: Allocated: 124.7 MB, Reserved: 13552.0 MB
2025-07-05 05:43:30,562 - WARNING - Epoch [7/20] Step [11/125]  acc 0.906333 (0.904061)  loss 0.236817 (0.239238)
GPU memory consumption  GPU Memory: Allocated: 122.9 MB, Reserved: 13552.0 MB
2025-07-05 05:43:33,447 - WARNING - Epoch [7/20] Step [21/125]  acc 0.917326 (0.905234)  loss 0.209743 (0.236192)
GPU memory consumption  GPU Memory: Allocated: 123.8 MB, Reserved: 13552.0 MB
2025-07-05 05:43:36,343 - WARNING - Epoch [7/20] Step [31/125]  acc 0.905748 (0.903502)  loss 0.233891 (0.239491)
GPU memory consumption  GPU Memory: Allocated: 128.3 MB, Reserved: 13552.0 MB
2025-07-05 05:43:39,211 - WARNING - Epoch [7/20] Step [41/125]  acc 0.905419 (0.903141)  loss 0.237545 (0.240095)
GPU memory consumption  GPU Memory: Allocated: 127.8 MB, Reserved: 13552.0 MB
2025-07-05 05:43:42,109 - WARNING - Epoch [7/20] Step [51/125]  acc 0.920651 (0.903963)  loss 0.207421 (0.238490)
GPU memory consumption  GPU Memory: Allocated: 132.6 MB, Reserved: 13552.0 MB
2025-07-05 05:43:45,000 - WARNING - Epoch [7/20] Step [61/125]  acc 0.902873 (0.903867)  loss 0.241927 (0.238582)
GPU memory consumption  GPU Memory: Allocated: 118.7 MB, Reserved: 13552.0 MB
2025-07-05 05:43:47,910 - WARNING - Epoch [7/20] Step [71/125]  acc 0.893362 (0.903635)  loss 0.255198 (0.238857)
GPU memory consumption  GPU Memory: Allocated: 124.3 MB, Reserved: 13552.0 MB
2025-07-05 05:43:50,784 - WARNING - Epoch [7/20] Step [81/125]  acc 0.912333 (0.903362)  loss 0.227619 (0.239244)
GPU memory consumption  GPU Memory: Allocated: 118.4 MB, Reserved: 13552.0 MB
2025-07-05 05:43:53,640 - WARNING - Epoch [7/20] Step [91/125]  acc 0.892914 (0.902669)  loss 0.252905 (0.240328)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 13552.0 MB
2025-07-05 05:43:56,546 - WARNING - Epoch [7/20] Step [101/125]  acc 0.887214 (0.902811)  loss 0.271829 (0.240175)
GPU memory consumption  GPU Memory: Allocated: 119.9 MB, Reserved: 13552.0 MB
2025-07-05 05:43:59,422 - WARNING - Epoch [7/20] Step [111/125]  acc 0.916827 (0.903444)  loss 0.219013 (0.239029)
GPU memory consumption  GPU Memory: Allocated: 120.5 MB, Reserved: 13552.0 MB
2025-07-05 05:44:02,323 - WARNING - Epoch [7/20] Step [121/125]  acc 0.908874 (0.903822)  loss 0.220730 (0.238247)
GPU memory consumption  GPU Memory: Allocated: 123.5 MB, Reserved: 13552.0 MB
Epoch 7 completed in 0:00:36.065172
2025-07-05 05:44:13,193 - WARNING - Epoch [8/20] Step [1/125]  acc 0.900235 (0.900235)  loss 0.249861 (0.249861)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 13552.0 MB
2025-07-05 05:44:16,085 - WARNING - Epoch [8/20] Step [11/125]  acc 0.913354 (0.905534)  loss 0.218719 (0.233739)
GPU memory consumption  GPU Memory: Allocated: 127.5 MB, Reserved: 13552.0 MB
2025-07-05 05:44:18,992 - WARNING - Epoch [8/20] Step [21/125]  acc 0.912587 (0.905416)  loss 0.216442 (0.233414)
GPU memory consumption  GPU Memory: Allocated: 131.4 MB, Reserved: 13552.0 MB
2025-07-05 05:44:21,891 - WARNING - Epoch [8/20] Step [31/125]  acc 0.903311 (0.905595)  loss 0.231206 (0.234470)
GPU memory consumption  GPU Memory: Allocated: 125.5 MB, Reserved: 13552.0 MB
2025-07-05 05:44:24,778 - WARNING - Epoch [8/20] Step [41/125]  acc 0.892817 (0.904963)  loss 0.258223 (0.235312)
GPU memory consumption  GPU Memory: Allocated: 121.3 MB, Reserved: 13552.0 MB
2025-07-05 05:44:27,687 - WARNING - Epoch [8/20] Step [51/125]  acc 0.911640 (0.904132)  loss 0.215139 (0.237340)
GPU memory consumption  GPU Memory: Allocated: 133.9 MB, Reserved: 13552.0 MB
2025-07-05 05:44:30,607 - WARNING - Epoch [8/20] Step [61/125]  acc 0.909068 (0.904362)  loss 0.226805 (0.236724)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 13552.0 MB
2025-07-05 05:44:33,494 - WARNING - Epoch [8/20] Step [71/125]  acc 0.901189 (0.904365)  loss 0.235074 (0.236479)
GPU memory consumption  GPU Memory: Allocated: 125.9 MB, Reserved: 13552.0 MB
2025-07-05 05:44:36,383 - WARNING - Epoch [8/20] Step [81/125]  acc 0.904418 (0.904680)  loss 0.238936 (0.236104)
GPU memory consumption  GPU Memory: Allocated: 124.3 MB, Reserved: 13552.0 MB
2025-07-05 05:44:39,303 - WARNING - Epoch [8/20] Step [91/125]  acc 0.913744 (0.905172)  loss 0.213727 (0.234778)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 13552.0 MB
2025-07-05 05:44:42,193 - WARNING - Epoch [8/20] Step [101/125]  acc 0.902995 (0.904959)  loss 0.239540 (0.234931)
GPU memory consumption  GPU Memory: Allocated: 125.7 MB, Reserved: 13552.0 MB
2025-07-05 05:44:45,067 - WARNING - Epoch [8/20] Step [111/125]  acc 0.902364 (0.904677)  loss 0.232866 (0.235299)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 13552.0 MB
2025-07-05 05:44:47,930 - WARNING - Epoch [8/20] Step [121/125]  acc 0.904481 (0.904634)  loss 0.233367 (0.235238)
GPU memory consumption  GPU Memory: Allocated: 122.5 MB, Reserved: 13552.0 MB
Epoch 8 completed in 0:00:36.193447
2025-07-05 05:44:58,811 - WARNING - Epoch [9/20] Step [1/125]  acc 0.898035 (0.898035)  loss 0.250686 (0.250686)
GPU memory consumption  GPU Memory: Allocated: 125.2 MB, Reserved: 13552.0 MB
2025-07-05 05:45:01,688 - WARNING - Epoch [9/20] Step [11/125]  acc 0.888613 (0.905405)  loss 0.269715 (0.232550)
GPU memory consumption  GPU Memory: Allocated: 120.5 MB, Reserved: 13552.0 MB
2025-07-05 05:45:04,582 - WARNING - Epoch [9/20] Step [21/125]  acc 0.898441 (0.905073)  loss 0.244047 (0.233452)
GPU memory consumption  GPU Memory: Allocated: 133.6 MB, Reserved: 13552.0 MB
2025-07-05 05:45:07,471 - WARNING - Epoch [9/20] Step [31/125]  acc 0.888245 (0.904215)  loss 0.248881 (0.234183)
GPU memory consumption  GPU Memory: Allocated: 127.2 MB, Reserved: 13552.0 MB
2025-07-05 05:45:10,423 - WARNING - Epoch [9/20] Step [41/125]  acc 0.901868 (0.903528)  loss 0.230626 (0.235715)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 13552.0 MB
2025-07-05 05:45:13,306 - WARNING - Epoch [9/20] Step [51/125]  acc 0.894568 (0.903905)  loss 0.264409 (0.235554)
GPU memory consumption  GPU Memory: Allocated: 127.3 MB, Reserved: 13552.0 MB
2025-07-05 05:45:16,181 - WARNING - Epoch [9/20] Step [61/125]  acc 0.901188 (0.903519)  loss 0.244324 (0.236529)
GPU memory consumption  GPU Memory: Allocated: 119.8 MB, Reserved: 13552.0 MB
2025-07-05 05:45:19,064 - WARNING - Epoch [9/20] Step [71/125]  acc 0.911322 (0.904169)  loss 0.217388 (0.235584)
GPU memory consumption  GPU Memory: Allocated: 124.1 MB, Reserved: 13552.0 MB
2025-07-05 05:45:21,961 - WARNING - Epoch [9/20] Step [81/125]  acc 0.899038 (0.904193)  loss 0.250365 (0.235588)
GPU memory consumption  GPU Memory: Allocated: 119.9 MB, Reserved: 13552.0 MB
2025-07-05 05:45:24,823 - WARNING - Epoch [9/20] Step [91/125]  acc 0.897712 (0.903839)  loss 0.250878 (0.236371)
GPU memory consumption  GPU Memory: Allocated: 124.4 MB, Reserved: 13552.0 MB
2025-07-05 05:45:27,739 - WARNING - Epoch [9/20] Step [101/125]  acc 0.904392 (0.903945)  loss 0.235095 (0.236025)
GPU memory consumption  GPU Memory: Allocated: 123.7 MB, Reserved: 13552.0 MB
2025-07-05 05:45:30,637 - WARNING - Epoch [9/20] Step [111/125]  acc 0.901061 (0.904030)  loss 0.238334 (0.236061)
GPU memory consumption  GPU Memory: Allocated: 123.3 MB, Reserved: 13552.0 MB
2025-07-05 05:45:33,529 - WARNING - Epoch [9/20] Step [121/125]  acc 0.910112 (0.904346)  loss 0.222038 (0.235587)
GPU memory consumption  GPU Memory: Allocated: 127.5 MB, Reserved: 13552.0 MB
Epoch 9 completed in 0:00:36.152494
2025-07-05 05:45:44,379 - WARNING - Epoch [10/20] Step [1/125]  acc 0.904400 (0.904400)  loss 0.240244 (0.240244)
GPU memory consumption  GPU Memory: Allocated: 123.2 MB, Reserved: 13552.0 MB
2025-07-05 05:45:47,294 - WARNING - Epoch [10/20] Step [11/125]  acc 0.908184 (0.902942)  loss 0.223006 (0.235642)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 13552.0 MB
2025-07-05 05:45:50,186 - WARNING - Epoch [10/20] Step [21/125]  acc 0.902614 (0.902999)  loss 0.233916 (0.236982)
GPU memory consumption  GPU Memory: Allocated: 131.9 MB, Reserved: 13552.0 MB
2025-07-05 05:45:53,041 - WARNING - Epoch [10/20] Step [31/125]  acc 0.899146 (0.902541)  loss 0.244622 (0.238004)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 13552.0 MB
2025-07-05 05:45:55,944 - WARNING - Epoch [10/20] Step [41/125]  acc 0.890761 (0.902848)  loss 0.258770 (0.237403)
GPU memory consumption  GPU Memory: Allocated: 127.1 MB, Reserved: 13552.0 MB
2025-07-05 05:45:58,819 - WARNING - Epoch [10/20] Step [51/125]  acc 0.913264 (0.902907)  loss 0.217303 (0.237353)
GPU memory consumption  GPU Memory: Allocated: 126.8 MB, Reserved: 13552.0 MB
2025-07-05 05:46:01,704 - WARNING - Epoch [10/20] Step [61/125]  acc 0.902272 (0.902863)  loss 0.235208 (0.237652)
GPU memory consumption  GPU Memory: Allocated: 123.0 MB, Reserved: 13552.0 MB
2025-07-05 05:46:04,607 - WARNING - Epoch [10/20] Step [71/125]  acc 0.903961 (0.903309)  loss 0.243355 (0.237130)
GPU memory consumption  GPU Memory: Allocated: 126.2 MB, Reserved: 13552.0 MB
2025-07-05 05:46:07,462 - WARNING - Epoch [10/20] Step [81/125]  acc 0.895951 (0.903281)  loss 0.255173 (0.237418)
GPU memory consumption  GPU Memory: Allocated: 120.3 MB, Reserved: 13552.0 MB
2025-07-05 05:46:10,354 - WARNING - Epoch [10/20] Step [91/125]  acc 0.919367 (0.903708)  loss 0.203291 (0.236616)
GPU memory consumption  GPU Memory: Allocated: 129.2 MB, Reserved: 13552.0 MB
2025-07-05 05:46:13,298 - WARNING - Epoch [10/20] Step [101/125]  acc 0.910882 (0.904042)  loss 0.216160 (0.236043)
GPU memory consumption  GPU Memory: Allocated: 136.3 MB, Reserved: 15172.0 MB
2025-07-05 05:46:16,161 - WARNING - Epoch [10/20] Step [111/125]  acc 0.904167 (0.904293)  loss 0.231849 (0.235807)
GPU memory consumption  GPU Memory: Allocated: 125.4 MB, Reserved: 15172.0 MB
2025-07-05 05:46:19,044 - WARNING - Epoch [10/20] Step [121/125]  acc 0.910962 (0.904621)  loss 0.224519 (0.234750)
GPU memory consumption  GPU Memory: Allocated: 126.4 MB, Reserved: 15172.0 MB
Epoch 10 completed in 0:00:36.096632
2025-07-05 05:46:29,895 - WARNING - Epoch [11/20] Step [1/125]  acc 0.904383 (0.904383)  loss 0.233486 (0.233486)
GPU memory consumption  GPU Memory: Allocated: 125.6 MB, Reserved: 15172.0 MB
2025-07-05 05:46:32,811 - WARNING - Epoch [11/20] Step [11/125]  acc 0.910112 (0.908885)  loss 0.221508 (0.224435)
GPU memory consumption  GPU Memory: Allocated: 129.4 MB, Reserved: 15172.0 MB
2025-07-05 05:46:35,692 - WARNING - Epoch [11/20] Step [21/125]  acc 0.886165 (0.905657)  loss 0.278566 (0.232348)
GPU memory consumption  GPU Memory: Allocated: 123.4 MB, Reserved: 15172.0 MB
2025-07-05 05:46:38,546 - WARNING - Epoch [11/20] Step [31/125]  acc 0.924038 (0.905254)  loss 0.190523 (0.231870)
GPU memory consumption  GPU Memory: Allocated: 131.2 MB, Reserved: 15172.0 MB
2025-07-05 05:46:41,436 - WARNING - Epoch [11/20] Step [41/125]  acc 0.898296 (0.904881)  loss 0.243921 (0.232814)
GPU memory consumption  GPU Memory: Allocated: 123.8 MB, Reserved: 15172.0 MB
2025-07-05 05:46:44,326 - WARNING - Epoch [11/20] Step [51/125]  acc 0.895562 (0.904877)  loss 0.256706 (0.233239)
GPU memory consumption  GPU Memory: Allocated: 128.1 MB, Reserved: 15172.0 MB
2025-07-05 05:46:47,214 - WARNING - Epoch [11/20] Step [61/125]  acc 0.901753 (0.905574)  loss 0.248217 (0.232166)
GPU memory consumption  GPU Memory: Allocated: 117.7 MB, Reserved: 15172.0 MB
2025-07-05 05:46:50,114 - WARNING - Epoch [11/20] Step [71/125]  acc 0.895287 (0.905455)  loss 0.249336 (0.232332)
GPU memory consumption  GPU Memory: Allocated: 128.5 MB, Reserved: 15172.0 MB
2025-07-05 05:46:53,008 - WARNING - Epoch [11/20] Step [81/125]  acc 0.905086 (0.905321)  loss 0.242455 (0.232438)
GPU memory consumption  GPU Memory: Allocated: 118.5 MB, Reserved: 15172.0 MB
2025-07-05 05:46:55,900 - WARNING - Epoch [11/20] Step [91/125]  acc 0.913599 (0.905353)  loss 0.222826 (0.232391)
GPU memory consumption  GPU Memory: Allocated: 130.0 MB, Reserved: 15172.0 MB
2025-07-05 05:46:58,859 - WARNING - Epoch [11/20] Step [101/125]  acc 0.903587 (0.905575)  loss 0.228494 (0.232000)
GPU memory consumption  GPU Memory: Allocated: 132.0 MB, Reserved: 15172.0 MB
2025-07-05 05:47:01,767 - WARNING - Epoch [11/20] Step [111/125]  acc 0.908217 (0.905489)  loss 0.222765 (0.232059)
GPU memory consumption  GPU Memory: Allocated: 120.2 MB, Reserved: 15172.0 MB
2025-07-05 05:47:04,609 - WARNING - Epoch [11/20] Step [121/125]  acc 0.904173 (0.905373)  loss 0.229898 (0.232458)
GPU memory consumption  GPU Memory: Allocated: 127.5 MB, Reserved: 15172.0 MB
Epoch 11 completed in 0:00:36.147200
2025-07-05 05:47:15,461 - WARNING - Epoch [12/20] Step [1/125]  acc 0.912681 (0.912681)  loss 0.217008 (0.217008)
GPU memory consumption  GPU Memory: Allocated: 124.7 MB, Reserved: 15172.0 MB
2025-07-05 05:47:18,326 - WARNING - Epoch [12/20] Step [11/125]  acc 0.899890 (0.905246)  loss 0.239510 (0.231826)
GPU memory consumption  GPU Memory: Allocated: 120.3 MB, Reserved: 15172.0 MB
2025-07-05 05:47:21,209 - WARNING - Epoch [12/20] Step [21/125]  acc 0.901956 (0.905605)  loss 0.239811 (0.232028)
GPU memory consumption  GPU Memory: Allocated: 131.3 MB, Reserved: 15172.0 MB
2025-07-05 05:47:24,093 - WARNING - Epoch [12/20] Step [31/125]  acc 0.907895 (0.904685)  loss 0.229006 (0.233055)
GPU memory consumption  GPU Memory: Allocated: 122.5 MB, Reserved: 15172.0 MB
2025-07-05 05:47:27,006 - WARNING - Epoch [12/20] Step [41/125]  acc 0.893653 (0.904396)  loss 0.253220 (0.234617)
GPU memory consumption  GPU Memory: Allocated: 121.0 MB, Reserved: 15172.0 MB
2025-07-05 05:47:29,920 - WARNING - Epoch [12/20] Step [51/125]  acc 0.901720 (0.904230)  loss 0.229670 (0.234513)
GPU memory consumption  GPU Memory: Allocated: 125.5 MB, Reserved: 15172.0 MB
2025-07-05 05:47:32,819 - WARNING - Epoch [12/20] Step [61/125]  acc 0.902925 (0.904892)  loss 0.240149 (0.233579)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 15172.0 MB
2025-07-05 05:47:35,724 - WARNING - Epoch [12/20] Step [71/125]  acc 0.895518 (0.904545)  loss 0.257231 (0.234541)
GPU memory consumption  GPU Memory: Allocated: 122.7 MB, Reserved: 15172.0 MB
2025-07-05 05:47:38,652 - WARNING - Epoch [12/20] Step [81/125]  acc 0.902476 (0.904555)  loss 0.230172 (0.234169)
GPU memory consumption  GPU Memory: Allocated: 125.6 MB, Reserved: 15172.0 MB
2025-07-05 05:47:41,514 - WARNING - Epoch [12/20] Step [91/125]  acc 0.900297 (0.904686)  loss 0.232029 (0.233836)
GPU memory consumption  GPU Memory: Allocated: 123.0 MB, Reserved: 15172.0 MB
2025-07-05 05:47:44,452 - WARNING - Epoch [12/20] Step [101/125]  acc 0.899659 (0.904318)  loss 0.238683 (0.234432)
GPU memory consumption  GPU Memory: Allocated: 125.7 MB, Reserved: 15172.0 MB
2025-07-05 05:47:47,335 - WARNING - Epoch [12/20] Step [111/125]  acc 0.902879 (0.904538)  loss 0.231024 (0.233647)
GPU memory consumption  GPU Memory: Allocated: 130.0 MB, Reserved: 15172.0 MB
2025-07-05 05:47:50,176 - WARNING - Epoch [12/20] Step [121/125]  acc 0.902689 (0.904770)  loss 0.234835 (0.233028)
GPU memory consumption  GPU Memory: Allocated: 128.0 MB, Reserved: 15172.0 MB
Epoch 12 completed in 0:00:36.146055
2025-07-05 05:48:01,024 - WARNING - Epoch [13/20] Step [1/125]  acc 0.906284 (0.906284)  loss 0.230899 (0.230899)
GPU memory consumption  GPU Memory: Allocated: 124.3 MB, Reserved: 15172.0 MB
2025-07-05 05:48:03,895 - WARNING - Epoch [13/20] Step [11/125]  acc 0.892819 (0.903089)  loss 0.265133 (0.235685)
GPU memory consumption  GPU Memory: Allocated: 124.7 MB, Reserved: 15172.0 MB
2025-07-05 05:48:06,783 - WARNING - Epoch [13/20] Step [21/125]  acc 0.908604 (0.904693)  loss 0.222289 (0.233899)
GPU memory consumption  GPU Memory: Allocated: 131.2 MB, Reserved: 15172.0 MB
2025-07-05 05:48:09,621 - WARNING - Epoch [13/20] Step [31/125]  acc 0.897609 (0.905936)  loss 0.248527 (0.231011)
GPU memory consumption  GPU Memory: Allocated: 120.6 MB, Reserved: 15172.0 MB
2025-07-05 05:48:12,513 - WARNING - Epoch [13/20] Step [41/125]  acc 0.902789 (0.905869)  loss 0.241023 (0.231645)
GPU memory consumption  GPU Memory: Allocated: 127.9 MB, Reserved: 15172.0 MB
2025-07-05 05:48:15,417 - WARNING - Epoch [13/20] Step [51/125]  acc 0.915033 (0.906548)  loss 0.211660 (0.230471)
GPU memory consumption  GPU Memory: Allocated: 129.6 MB, Reserved: 15172.0 MB
2025-07-05 05:48:18,301 - WARNING - Epoch [13/20] Step [61/125]  acc 0.914206 (0.906347)  loss 0.214906 (0.231148)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 15172.0 MB
2025-07-05 05:48:21,210 - WARNING - Epoch [13/20] Step [71/125]  acc 0.904865 (0.905874)  loss 0.228774 (0.231783)
GPU memory consumption  GPU Memory: Allocated: 122.6 MB, Reserved: 15172.0 MB
2025-07-05 05:48:24,073 - WARNING - Epoch [13/20] Step [81/125]  acc 0.907457 (0.905629)  loss 0.230698 (0.232601)
GPU memory consumption  GPU Memory: Allocated: 120.2 MB, Reserved: 15172.0 MB
2025-07-05 05:48:26,933 - WARNING - Epoch [13/20] Step [91/125]  acc 0.906339 (0.905536)  loss 0.235736 (0.232709)
GPU memory consumption  GPU Memory: Allocated: 126.8 MB, Reserved: 15172.0 MB
2025-07-05 05:48:29,867 - WARNING - Epoch [13/20] Step [101/125]  acc 0.920717 (0.905587)  loss 0.200584 (0.232450)
GPU memory consumption  GPU Memory: Allocated: 125.9 MB, Reserved: 15172.0 MB
2025-07-05 05:48:32,790 - WARNING - Epoch [13/20] Step [111/125]  acc 0.902296 (0.905821)  loss 0.234793 (0.231832)
GPU memory consumption  GPU Memory: Allocated: 123.1 MB, Reserved: 15172.0 MB
2025-07-05 05:48:35,674 - WARNING - Epoch [13/20] Step [121/125]  acc 0.911450 (0.905956)  loss 0.228678 (0.231453)
GPU memory consumption  GPU Memory: Allocated: 123.2 MB, Reserved: 15172.0 MB
Epoch 13 completed in 0:00:36.120723
2025-07-05 05:48:46,563 - WARNING - Epoch [14/20] Step [1/125]  acc 0.889603 (0.889603)  loss 0.261516 (0.261516)
GPU memory consumption  GPU Memory: Allocated: 125.4 MB, Reserved: 15172.0 MB
2025-07-05 05:48:49,476 - WARNING - Epoch [14/20] Step [11/125]  acc 0.905923 (0.903076)  loss 0.226553 (0.237597)
GPU memory consumption  GPU Memory: Allocated: 129.5 MB, Reserved: 15172.0 MB
2025-07-05 05:48:52,346 - WARNING - Epoch [14/20] Step [21/125]  acc 0.916797 (0.904034)  loss 0.216423 (0.234546)
GPU memory consumption  GPU Memory: Allocated: 128.1 MB, Reserved: 15172.0 MB
2025-07-05 05:48:55,221 - WARNING - Epoch [14/20] Step [31/125]  acc 0.912736 (0.905042)  loss 0.219689 (0.232437)
GPU memory consumption  GPU Memory: Allocated: 131.3 MB, Reserved: 15172.0 MB
2025-07-05 05:48:58,105 - WARNING - Epoch [14/20] Step [41/125]  acc 0.900946 (0.905891)  loss 0.241301 (0.231112)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 15172.0 MB
2025-07-05 05:49:01,029 - WARNING - Epoch [14/20] Step [51/125]  acc 0.912766 (0.906656)  loss 0.211489 (0.229259)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 15172.0 MB
2025-07-05 05:49:03,924 - WARNING - Epoch [14/20] Step [61/125]  acc 0.914691 (0.906325)  loss 0.210502 (0.229826)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 15172.0 MB
2025-07-05 05:49:06,823 - WARNING - Epoch [14/20] Step [71/125]  acc 0.917585 (0.906181)  loss 0.217653 (0.230004)
GPU memory consumption  GPU Memory: Allocated: 124.7 MB, Reserved: 15172.0 MB
2025-07-05 05:49:09,751 - WARNING - Epoch [14/20] Step [81/125]  acc 0.913309 (0.906441)  loss 0.211393 (0.229666)
GPU memory consumption  GPU Memory: Allocated: 129.1 MB, Reserved: 15172.0 MB
2025-07-05 05:49:12,612 - WARNING - Epoch [14/20] Step [91/125]  acc 0.922918 (0.906563)  loss 0.201525 (0.229733)
GPU memory consumption  GPU Memory: Allocated: 127.9 MB, Reserved: 15172.0 MB
2025-07-05 05:49:15,553 - WARNING - Epoch [14/20] Step [101/125]  acc 0.909692 (0.906812)  loss 0.219736 (0.229454)
GPU memory consumption  GPU Memory: Allocated: 128.8 MB, Reserved: 15172.0 MB
2025-07-05 05:49:18,450 - WARNING - Epoch [14/20] Step [111/125]  acc 0.897402 (0.906846)  loss 0.244804 (0.229224)
GPU memory consumption  GPU Memory: Allocated: 122.7 MB, Reserved: 15172.0 MB
2025-07-05 05:49:21,278 - WARNING - Epoch [14/20] Step [121/125]  acc 0.910415 (0.906672)  loss 0.223974 (0.229561)
GPU memory consumption  GPU Memory: Allocated: 120.6 MB, Reserved: 15172.0 MB
Epoch 14 completed in 0:00:36.170707
2025-07-05 05:49:32,170 - WARNING - Epoch [15/20] Step [1/125]  acc 0.909299 (0.909299)  loss 0.224713 (0.224713)
GPU memory consumption  GPU Memory: Allocated: 130.3 MB, Reserved: 15172.0 MB
2025-07-05 05:49:35,038 - WARNING - Epoch [15/20] Step [11/125]  acc 0.904343 (0.909064)  loss 0.234286 (0.226971)
GPU memory consumption  GPU Memory: Allocated: 122.9 MB, Reserved: 15172.0 MB
2025-07-05 05:49:37,905 - WARNING - Epoch [15/20] Step [21/125]  acc 0.907020 (0.908109)  loss 0.232075 (0.227825)
GPU memory consumption  GPU Memory: Allocated: 126.5 MB, Reserved: 15172.0 MB
2025-07-05 05:49:40,804 - WARNING - Epoch [15/20] Step [31/125]  acc 0.898650 (0.907672)  loss 0.242478 (0.229073)
GPU memory consumption  GPU Memory: Allocated: 129.6 MB, Reserved: 15172.0 MB
2025-07-05 05:49:43,738 - WARNING - Epoch [15/20] Step [41/125]  acc 0.907478 (0.907721)  loss 0.228172 (0.228526)
GPU memory consumption  GPU Memory: Allocated: 130.9 MB, Reserved: 15172.0 MB
2025-07-05 05:49:46,636 - WARNING - Epoch [15/20] Step [51/125]  acc 0.905924 (0.906824)  loss 0.232594 (0.230558)
GPU memory consumption  GPU Memory: Allocated: 131.9 MB, Reserved: 15172.0 MB
2025-07-05 05:49:49,498 - WARNING - Epoch [15/20] Step [61/125]  acc 0.913993 (0.907189)  loss 0.216206 (0.229591)
GPU memory consumption  GPU Memory: Allocated: 123.0 MB, Reserved: 15172.0 MB
2025-07-05 05:49:52,416 - WARNING - Epoch [15/20] Step [71/125]  acc 0.903022 (0.906568)  loss 0.234228 (0.230876)
GPU memory consumption  GPU Memory: Allocated: 126.1 MB, Reserved: 15172.0 MB
2025-07-05 05:49:55,316 - WARNING - Epoch [15/20] Step [81/125]  acc 0.917279 (0.906661)  loss 0.211072 (0.230490)
GPU memory consumption  GPU Memory: Allocated: 121.2 MB, Reserved: 15172.0 MB
2025-07-05 05:49:58,186 - WARNING - Epoch [15/20] Step [91/125]  acc 0.898581 (0.906203)  loss 0.244559 (0.231226)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 15172.0 MB
2025-07-05 05:50:01,123 - WARNING - Epoch [15/20] Step [101/125]  acc 0.911141 (0.906690)  loss 0.220934 (0.230179)
GPU memory consumption  GPU Memory: Allocated: 121.9 MB, Reserved: 15172.0 MB
2025-07-05 05:50:04,021 - WARNING - Epoch [15/20] Step [111/125]  acc 0.912545 (0.906709)  loss 0.217730 (0.230238)
GPU memory consumption  GPU Memory: Allocated: 127.4 MB, Reserved: 15172.0 MB
2025-07-05 05:50:06,853 - WARNING - Epoch [15/20] Step [121/125]  acc 0.901282 (0.906480)  loss 0.236589 (0.230581)
GPU memory consumption  GPU Memory: Allocated: 121.3 MB, Reserved: 15172.0 MB
Epoch 15 completed in 0:00:36.151420
2025-07-05 05:50:17,731 - WARNING - Epoch [16/20] Step [1/125]  acc 0.901489 (0.901489)  loss 0.238346 (0.238346)
GPU memory consumption  GPU Memory: Allocated: 127.4 MB, Reserved: 15172.0 MB
2025-07-05 05:50:20,620 - WARNING - Epoch [16/20] Step [11/125]  acc 0.901961 (0.905687)  loss 0.237028 (0.231960)
GPU memory consumption  GPU Memory: Allocated: 124.7 MB, Reserved: 15172.0 MB
2025-07-05 05:50:23,503 - WARNING - Epoch [16/20] Step [21/125]  acc 0.916278 (0.905346)  loss 0.217700 (0.231109)
GPU memory consumption  GPU Memory: Allocated: 129.2 MB, Reserved: 15172.0 MB
2025-07-05 05:50:26,378 - WARNING - Epoch [16/20] Step [31/125]  acc 0.902743 (0.906434)  loss 0.233237 (0.230082)
GPU memory consumption  GPU Memory: Allocated: 130.2 MB, Reserved: 15172.0 MB
2025-07-05 05:50:29,277 - WARNING - Epoch [16/20] Step [41/125]  acc 0.903553 (0.906467)  loss 0.242360 (0.229631)
GPU memory consumption  GPU Memory: Allocated: 124.8 MB, Reserved: 15172.0 MB
2025-07-05 05:50:32,201 - WARNING - Epoch [16/20] Step [51/125]  acc 0.906134 (0.906613)  loss 0.233834 (0.229166)
GPU memory consumption  GPU Memory: Allocated: 135.7 MB, Reserved: 15172.0 MB
2025-07-05 05:50:35,095 - WARNING - Epoch [16/20] Step [61/125]  acc 0.902993 (0.906806)  loss 0.226020 (0.228927)
GPU memory consumption  GPU Memory: Allocated: 120.6 MB, Reserved: 15172.0 MB
2025-07-05 05:50:37,979 - WARNING - Epoch [16/20] Step [71/125]  acc 0.910845 (0.906505)  loss 0.220530 (0.229619)
GPU memory consumption  GPU Memory: Allocated: 125.9 MB, Reserved: 15172.0 MB
2025-07-05 05:50:40,902 - WARNING - Epoch [16/20] Step [81/125]  acc 0.917760 (0.906817)  loss 0.208246 (0.229193)
GPU memory consumption  GPU Memory: Allocated: 125.1 MB, Reserved: 15172.0 MB
2025-07-05 05:50:43,765 - WARNING - Epoch [16/20] Step [91/125]  acc 0.899841 (0.906930)  loss 0.244261 (0.229106)
GPU memory consumption  GPU Memory: Allocated: 123.9 MB, Reserved: 15172.0 MB
2025-07-05 05:50:46,696 - WARNING - Epoch [16/20] Step [101/125]  acc 0.912953 (0.906798)  loss 0.207610 (0.229229)
GPU memory consumption  GPU Memory: Allocated: 126.1 MB, Reserved: 15172.0 MB
2025-07-05 05:50:49,580 - WARNING - Epoch [16/20] Step [111/125]  acc 0.880172 (0.906740)  loss 0.277736 (0.229272)
GPU memory consumption  GPU Memory: Allocated: 123.1 MB, Reserved: 15172.0 MB
2025-07-05 05:50:52,424 - WARNING - Epoch [16/20] Step [121/125]  acc 0.906507 (0.906473)  loss 0.227466 (0.229734)
GPU memory consumption  GPU Memory: Allocated: 123.9 MB, Reserved: 15172.0 MB
Epoch 16 completed in 0:00:36.138050
2025-07-05 05:51:03,291 - WARNING - Epoch [17/20] Step [1/125]  acc 0.896862 (0.896862)  loss 0.250063 (0.250063)
GPU memory consumption  GPU Memory: Allocated: 123.7 MB, Reserved: 15172.0 MB
2025-07-05 05:51:06,175 - WARNING - Epoch [17/20] Step [11/125]  acc 0.902426 (0.905873)  loss 0.234348 (0.230445)
GPU memory consumption  GPU Memory: Allocated: 122.5 MB, Reserved: 15172.0 MB
2025-07-05 05:51:09,060 - WARNING - Epoch [17/20] Step [21/125]  acc 0.916194 (0.905456)  loss 0.208642 (0.231937)
GPU memory consumption  GPU Memory: Allocated: 126.2 MB, Reserved: 15172.0 MB
2025-07-05 05:51:11,981 - WARNING - Epoch [17/20] Step [31/125]  acc 0.910765 (0.906455)  loss 0.222972 (0.231027)
GPU memory consumption  GPU Memory: Allocated: 129.5 MB, Reserved: 15172.0 MB
2025-07-05 05:51:14,880 - WARNING - Epoch [17/20] Step [41/125]  acc 0.902186 (0.905339)  loss 0.242279 (0.232355)
GPU memory consumption  GPU Memory: Allocated: 122.9 MB, Reserved: 15172.0 MB
2025-07-05 05:51:17,809 - WARNING - Epoch [17/20] Step [51/125]  acc 0.913241 (0.905960)  loss 0.208900 (0.231177)
GPU memory consumption  GPU Memory: Allocated: 127.6 MB, Reserved: 15172.0 MB
2025-07-05 05:51:20,701 - WARNING - Epoch [17/20] Step [61/125]  acc 0.899894 (0.905406)  loss 0.235412 (0.231970)
GPU memory consumption  GPU Memory: Allocated: 120.8 MB, Reserved: 15172.0 MB
2025-07-05 05:51:23,580 - WARNING - Epoch [17/20] Step [71/125]  acc 0.898200 (0.905657)  loss 0.246478 (0.231909)
GPU memory consumption  GPU Memory: Allocated: 119.7 MB, Reserved: 15172.0 MB
2025-07-05 05:51:26,464 - WARNING - Epoch [17/20] Step [81/125]  acc 0.914771 (0.905688)  loss 0.213117 (0.231640)
GPU memory consumption  GPU Memory: Allocated: 122.4 MB, Reserved: 15172.0 MB
2025-07-05 05:51:29,332 - WARNING - Epoch [17/20] Step [91/125]  acc 0.910256 (0.906099)  loss 0.220376 (0.230836)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 15172.0 MB
2025-07-05 05:51:32,228 - WARNING - Epoch [17/20] Step [101/125]  acc 0.906143 (0.906054)  loss 0.225146 (0.230745)
GPU memory consumption  GPU Memory: Allocated: 125.7 MB, Reserved: 15172.0 MB
2025-07-05 05:51:35,110 - WARNING - Epoch [17/20] Step [111/125]  acc 0.889545 (0.905871)  loss 0.273266 (0.231205)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 15172.0 MB
2025-07-05 05:51:37,953 - WARNING - Epoch [17/20] Step [121/125]  acc 0.902400 (0.905718)  loss 0.226954 (0.231473)
GPU memory consumption  GPU Memory: Allocated: 124.1 MB, Reserved: 15172.0 MB
Epoch 17 completed in 0:00:36.095084
2025-07-05 05:51:48,814 - WARNING - Epoch [18/20] Step [1/125]  acc 0.912651 (0.912651)  loss 0.218044 (0.218044)
GPU memory consumption  GPU Memory: Allocated: 129.1 MB, Reserved: 15172.0 MB
2025-07-05 05:51:51,886 - WARNING - Epoch [18/20] Step [11/125]  acc 0.902114 (0.902842)  loss 0.235588 (0.234240)
GPU memory consumption  GPU Memory: Allocated: 124.7 MB, Reserved: 15172.0 MB
2025-07-05 05:51:54,766 - WARNING - Epoch [18/20] Step [21/125]  acc 0.896292 (0.905722)  loss 0.246543 (0.229859)
GPU memory consumption  GPU Memory: Allocated: 131.2 MB, Reserved: 15172.0 MB
2025-07-05 05:51:57,647 - WARNING - Epoch [18/20] Step [31/125]  acc 0.891310 (0.905253)  loss 0.253843 (0.230988)
GPU memory consumption  GPU Memory: Allocated: 122.5 MB, Reserved: 15172.0 MB
2025-07-05 05:52:00,558 - WARNING - Epoch [18/20] Step [41/125]  acc 0.911937 (0.904805)  loss 0.230801 (0.232473)
GPU memory consumption  GPU Memory: Allocated: 130.3 MB, Reserved: 15172.0 MB
2025-07-05 05:52:03,423 - WARNING - Epoch [18/20] Step [51/125]  acc 0.917491 (0.905184)  loss 0.217386 (0.232330)
GPU memory consumption  GPU Memory: Allocated: 129.4 MB, Reserved: 15172.0 MB
2025-07-05 05:52:06,297 - WARNING - Epoch [18/20] Step [61/125]  acc 0.904958 (0.904619)  loss 0.228872 (0.232980)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 15172.0 MB
2025-07-05 05:52:09,210 - WARNING - Epoch [18/20] Step [71/125]  acc 0.911933 (0.905522)  loss 0.225212 (0.231236)
GPU memory consumption  GPU Memory: Allocated: 121.8 MB, Reserved: 15172.0 MB
2025-07-05 05:52:12,132 - WARNING - Epoch [18/20] Step [81/125]  acc 0.895159 (0.905909)  loss 0.244206 (0.230137)
GPU memory consumption  GPU Memory: Allocated: 118.1 MB, Reserved: 15172.0 MB
2025-07-05 05:52:15,025 - WARNING - Epoch [18/20] Step [91/125]  acc 0.908031 (0.906129)  loss 0.235370 (0.229993)
GPU memory consumption  GPU Memory: Allocated: 125.9 MB, Reserved: 15172.0 MB
2025-07-05 05:52:17,941 - WARNING - Epoch [18/20] Step [101/125]  acc 0.906677 (0.906374)  loss 0.235988 (0.229650)
GPU memory consumption  GPU Memory: Allocated: 125.7 MB, Reserved: 15172.0 MB
2025-07-05 05:52:20,832 - WARNING - Epoch [18/20] Step [111/125]  acc 0.914209 (0.906470)  loss 0.219906 (0.229807)
GPU memory consumption  GPU Memory: Allocated: 122.0 MB, Reserved: 15172.0 MB
2025-07-05 05:52:23,722 - WARNING - Epoch [18/20] Step [121/125]  acc 0.898718 (0.906312)  loss 0.241667 (0.230036)
GPU memory consumption  GPU Memory: Allocated: 125.5 MB, Reserved: 15172.0 MB
Epoch 18 completed in 0:00:36.367176
2025-07-05 05:52:34,619 - WARNING - Epoch [19/20] Step [1/125]  acc 0.899692 (0.899692)  loss 0.245581 (0.245581)
GPU memory consumption  GPU Memory: Allocated: 129.3 MB, Reserved: 15172.0 MB
2025-07-05 05:52:37,511 - WARNING - Epoch [19/20] Step [11/125]  acc 0.906778 (0.903107)  loss 0.222803 (0.237543)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 15172.0 MB
2025-07-05 05:52:40,390 - WARNING - Epoch [19/20] Step [21/125]  acc 0.901039 (0.904886)  loss 0.234101 (0.233764)
GPU memory consumption  GPU Memory: Allocated: 124.6 MB, Reserved: 15172.0 MB
2025-07-05 05:52:43,290 - WARNING - Epoch [19/20] Step [31/125]  acc 0.895107 (0.904639)  loss 0.251887 (0.233121)
GPU memory consumption  GPU Memory: Allocated: 123.8 MB, Reserved: 15172.0 MB
2025-07-05 05:52:46,209 - WARNING - Epoch [19/20] Step [41/125]  acc 0.908158 (0.905498)  loss 0.224871 (0.230728)
GPU memory consumption  GPU Memory: Allocated: 123.6 MB, Reserved: 15172.0 MB
2025-07-05 05:52:49,112 - WARNING - Epoch [19/20] Step [51/125]  acc 0.911467 (0.906585)  loss 0.214713 (0.229051)
GPU memory consumption  GPU Memory: Allocated: 127.2 MB, Reserved: 15172.0 MB
2025-07-05 05:52:51,957 - WARNING - Epoch [19/20] Step [61/125]  acc 0.904279 (0.906725)  loss 0.238175 (0.228914)
GPU memory consumption  GPU Memory: Allocated: 118.4 MB, Reserved: 15172.0 MB
2025-07-05 05:52:54,837 - WARNING - Epoch [19/20] Step [71/125]  acc 0.893680 (0.906437)  loss 0.255794 (0.229113)
GPU memory consumption  GPU Memory: Allocated: 123.3 MB, Reserved: 15172.0 MB
2025-07-05 05:52:57,719 - WARNING - Epoch [19/20] Step [81/125]  acc 0.907860 (0.906249)  loss 0.228507 (0.229722)
GPU memory consumption  GPU Memory: Allocated: 120.8 MB, Reserved: 15172.0 MB
2025-07-05 05:53:00,644 - WARNING - Epoch [19/20] Step [91/125]  acc 0.912281 (0.906470)  loss 0.227190 (0.229672)
GPU memory consumption  GPU Memory: Allocated: 127.9 MB, Reserved: 15172.0 MB
2025-07-05 05:53:03,590 - WARNING - Epoch [19/20] Step [101/125]  acc 0.913203 (0.906764)  loss 0.211559 (0.229240)
GPU memory consumption  GPU Memory: Allocated: 126.4 MB, Reserved: 15172.0 MB
2025-07-05 05:53:06,516 - WARNING - Epoch [19/20] Step [111/125]  acc 0.909183 (0.906797)  loss 0.230001 (0.229375)
GPU memory consumption  GPU Memory: Allocated: 128.1 MB, Reserved: 15172.0 MB
2025-07-05 05:53:09,394 - WARNING - Epoch [19/20] Step [121/125]  acc 0.927175 (0.906955)  loss 0.189020 (0.228934)
GPU memory consumption  GPU Memory: Allocated: 122.8 MB, Reserved: 15172.0 MB
Epoch 19 completed in 0:00:36.237967
2025-07-05 05:53:20,284 - WARNING - Epoch [20/20] Step [1/125]  acc 0.913296 (0.913296)  loss 0.217145 (0.217145)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 15172.0 MB
2025-07-05 05:53:23,192 - WARNING - Epoch [20/20] Step [11/125]  acc 0.904984 (0.908276)  loss 0.231687 (0.227854)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 15172.0 MB
2025-07-05 05:53:26,065 - WARNING - Epoch [20/20] Step [21/125]  acc 0.922067 (0.905867)  loss 0.203762 (0.231410)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 15172.0 MB
2025-07-05 05:53:28,987 - WARNING - Epoch [20/20] Step [31/125]  acc 0.910437 (0.905794)  loss 0.228059 (0.231964)
GPU memory consumption  GPU Memory: Allocated: 133.6 MB, Reserved: 15172.0 MB
2025-07-05 05:53:31,906 - WARNING - Epoch [20/20] Step [41/125]  acc 0.904490 (0.906876)  loss 0.231054 (0.229110)
GPU memory consumption  GPU Memory: Allocated: 127.6 MB, Reserved: 15172.0 MB
2025-07-05 05:53:34,760 - WARNING - Epoch [20/20] Step [51/125]  acc 0.904775 (0.906013)  loss 0.237947 (0.230798)
GPU memory consumption  GPU Memory: Allocated: 129.3 MB, Reserved: 15172.0 MB
2025-07-05 05:53:37,666 - WARNING - Epoch [20/20] Step [61/125]  acc 0.906863 (0.905966)  loss 0.234198 (0.231051)
GPU memory consumption  GPU Memory: Allocated: 119.1 MB, Reserved: 15172.0 MB
2025-07-05 05:53:40,543 - WARNING - Epoch [20/20] Step [71/125]  acc 0.914140 (0.905710)  loss 0.212325 (0.231353)
GPU memory consumption  GPU Memory: Allocated: 123.2 MB, Reserved: 15172.0 MB
2025-07-05 05:53:43,433 - WARNING - Epoch [20/20] Step [81/125]  acc 0.917079 (0.905856)  loss 0.204367 (0.230810)
GPU memory consumption  GPU Memory: Allocated: 128.4 MB, Reserved: 15172.0 MB
2025-07-05 05:53:46,339 - WARNING - Epoch [20/20] Step [91/125]  acc 0.902483 (0.906357)  loss 0.234419 (0.229847)
GPU memory consumption  GPU Memory: Allocated: 128.3 MB, Reserved: 15172.0 MB
2025-07-05 05:53:49,288 - WARNING - Epoch [20/20] Step [101/125]  acc 0.910971 (0.906312)  loss 0.222508 (0.229812)
GPU memory consumption  GPU Memory: Allocated: 129.1 MB, Reserved: 15172.0 MB
2025-07-05 05:53:52,203 - WARNING - Epoch [20/20] Step [111/125]  acc 0.920778 (0.906409)  loss 0.207443 (0.229621)
GPU memory consumption  GPU Memory: Allocated: 132.4 MB, Reserved: 15172.0 MB
2025-07-05 05:53:55,066 - WARNING - Epoch [20/20] Step [121/125]  acc 0.908686 (0.906333)  loss 0.219813 (0.229746)
GPU memory consumption  GPU Memory: Allocated: 131.8 MB, Reserved: 15172.0 MB
Epoch 20 completed in 0:00:36.241335
2025-07-05 05:54:05,680 - INFO - DARTS search completed in 914.12s
2025-07-05 05:54:05,680 - INFO - 
============================================================
2025-07-05 05:54:05,680 - INFO - Layer layer_0 Expert Selection:
2025-07-05 05:54:05,680 - INFO -   Expert 0: GINE (α=0.3340)
2025-07-05 05:54:05,680 - INFO -   Expert 1: CustomGatedGCN (α=0.3312)
2025-07-05 05:54:05,680 - INFO -   Expert 2: GATV2 (α=0.3348) ← SELECTED
2025-07-05 05:54:05,680 - INFO - Selected Expert Index: 2 (GATV2)
2025-07-05 05:54:05,680 - INFO - ============================================================

2025-07-05 05:54:05,680 - INFO - 
============================================================
2025-07-05 05:54:05,680 - INFO - Layer layer_1 Expert Selection:
2025-07-05 05:54:05,680 - INFO -   Expert 0: GINE (α=0.3225)
2025-07-05 05:54:05,680 - INFO -   Expert 1: CustomGatedGCN (α=0.3503) ← SELECTED
2025-07-05 05:54:05,680 - INFO -   Expert 2: GATV2 (α=0.3272)
2025-07-05 05:54:05,681 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 05:54:05,681 - INFO - ============================================================

2025-07-05 05:54:05,681 - INFO - 
============================================================
2025-07-05 05:54:05,681 - INFO - Layer layer_2 Expert Selection:
2025-07-05 05:54:05,681 - INFO -   Expert 0: GINE (α=0.3723) ← SELECTED
2025-07-05 05:54:05,681 - INFO -   Expert 1: CustomGatedGCN (α=0.3515)
2025-07-05 05:54:05,681 - INFO -   Expert 2: GATV2 (α=0.2762)
2025-07-05 05:54:05,681 - INFO - Selected Expert Index: 0 (GINE)
2025-07-05 05:54:05,681 - INFO - ============================================================

2025-07-05 05:54:05,681 - INFO - 
============================================================
2025-07-05 05:54:05,681 - INFO - Layer layer_3 Expert Selection:
2025-07-05 05:54:05,681 - INFO -   Expert 0: GINE (α=0.3195)
2025-07-05 05:54:05,681 - INFO -   Expert 1: CustomGatedGCN (α=0.3766) ← SELECTED
2025-07-05 05:54:05,681 - INFO -   Expert 2: GATV2 (α=0.3040)
2025-07-05 05:54:05,681 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 05:54:05,681 - INFO - ============================================================

2025-07-05 05:54:05,681 - INFO - 
============================================================
2025-07-05 05:54:05,681 - INFO - Layer layer_4 Expert Selection:
2025-07-05 05:54:05,681 - INFO -   Expert 0: GINE (α=0.3170)
2025-07-05 05:54:05,681 - INFO -   Expert 1: CustomGatedGCN (α=0.3788) ← SELECTED
2025-07-05 05:54:05,681 - INFO -   Expert 2: GATV2 (α=0.3042)
2025-07-05 05:54:05,681 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 05:54:05,681 - INFO - ============================================================

2025-07-05 05:54:05,681 - INFO - 
============================================================
2025-07-05 05:54:05,681 - INFO - Layer layer_5 Expert Selection:
2025-07-05 05:54:05,681 - INFO -   Expert 0: GINE (α=0.3201)
2025-07-05 05:54:05,681 - INFO -   Expert 1: CustomGatedGCN (α=0.3609) ← SELECTED
2025-07-05 05:54:05,681 - INFO -   Expert 2: GATV2 (α=0.3190)
2025-07-05 05:54:05,681 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 05:54:05,681 - INFO - ============================================================

=== MODEL PARAMETER COMPARISON ===
Original DARTS model parameters: 487,369
2025-07-05 05:54:05,716 - INFO - Layer 0: Using ONLY Expert 2 (GATV2)
2025-07-05 05:54:05,716 - INFO - DiscreteNASLayer 0: Using ONLY Expert 2 (GATV2)
2025-07-05 05:54:05,720 - INFO - Layer 1: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:54:05,720 - INFO - DiscreteNASLayer 1: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:54:05,722 - INFO - Layer 2: Using ONLY Expert 0 (GINE)
2025-07-05 05:54:05,722 - INFO - DiscreteNASLayer 2: Using ONLY Expert 0 (GINE)
2025-07-05 05:54:05,724 - INFO - Layer 3: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:54:05,724 - INFO - DiscreteNASLayer 3: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:54:05,727 - INFO - Layer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:54:05,727 - INFO - DiscreteNASLayer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:54:05,729 - INFO - Layer 5: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 05:54:05,729 - INFO - DiscreteNASLayer 5: Using ONLY Expert 1 (CustomGatedGCN)
Fresh discrete model parameters: 340,919
Parameter difference: -146,450
✓ Used cfg.share.dim_in (raw input) instead of self.encoder.dim_in (processed)
✓ Fresh discrete model with correct input dimensions
2025-07-05 05:54:05,738 - INFO - Replaced inner model with discrete version
2025-07-05 05:54:05,739 - INFO - Creating fresh optimizer/scheduler for discrete model...
2025-07-05 05:54:05,740 - INFO - Fresh optimizer created: AdamW
2025-07-05 05:54:05,741 - INFO - Fresh scheduler created: LambdaLR
2025-07-05 05:54:05,741 - INFO - Discrete model parameters: 340,919
2025-07-05 05:54:05,741 - INFO - ============================================================
2025-07-05 05:54:05,741 - INFO - PHASE 2: DISCRETE TRAINING WITH UNCERTAINTY
2025-07-05 05:54:05,741 - INFO - ============================================================
2025-07-05 05:54:05,741 - INFO - === Epoch 0 ===
2025-07-05 05:54:37,943 - INFO - train: {'epoch': 0, 'time_epoch': 30.23489, 'eta': 2993.2538, 'eta_hours': 0.83146, 'loss': 0.20278196, 'lr': 0.0, 'params': 340919, 'time_iter': 0.0966, 'accuracy': 0.61091, 'precision': 0.10203, 'recall': 0.15437, 'f1': 0.12286, 'auc': 0.36623, 'accuracy-SBM': 0.43157}
2025-07-05 05:54:37,999 - INFO - ...computing epoch stats took: 2.02s
2025-07-05 05:54:41,773 - INFO - val: {'epoch': 0, 'time_epoch': 3.42995, 'loss': 0.20089452, 'lr': 0, 'params': 340919, 'time_iter': 0.05444, 'accuracy': 0.60807, 'precision': 0.09629, 'recall': 0.14478, 'f1': 0.11566, 'auc': 0.36048, 'accuracy-SBM': 0.42625}
2025-07-05 05:54:41,790 - INFO - ...computing epoch stats took: 0.36s
2025-07-05 05:54:49,539 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 05:54:49,898 - INFO - test: {'epoch': 0, 'time_epoch': 3.47442, 'loss': 0.20016326, 'lr': 0, 'params': 340919, 'time_iter': 0.05515, 'accuracy': 0.61155, 'precision': 0.09951, 'recall': 0.14962, 'f1': 0.11952, 'auc': 0.36514, 'accuracy-SBM': 0.42999}
2025-07-05 05:54:50,019 - INFO - ...computing epoch stats took: 0.48s
2025-07-05 05:54:50,019 - INFO - > Epoch 0: took 44.3s (avg 44.3s) | Best so far: epoch 0	train_loss: 0.2028 train_accuracy-SBM: 0.4316	val_loss: 0.2009 val_accuracy-SBM: 0.4263	test_loss: 0.2002 test_accuracy-SBM: 0.4300
2025-07-05 05:54:50,019 - INFO - === Epoch 1 ===
2025-07-05 05:55:22,013 - INFO - train: {'epoch': 1, 'time_epoch': 30.01217, 'eta': 2952.10602, 'eta_hours': 0.82003, 'loss': 0.16846101, 'lr': 0.0001, 'params': 340919, 'time_iter': 0.09589, 'accuracy': 0.83252, 'precision': 0.51567, 'recall': 0.84278, 'f1': 0.63984, 'auc': 0.87316, 'accuracy-SBM': 0.83655}
2025-07-05 05:55:22,016 - INFO - ...computing epoch stats took: 1.98s
2025-07-05 05:55:25,624 - INFO - val: {'epoch': 1, 'time_epoch': 3.24717, 'loss': 0.15690914, 'lr': 0, 'params': 340919, 'time_iter': 0.05154, 'accuracy': 0.86405, 'precision': 0.58439, 'recall': 0.80341, 'f1': 0.67662, 'auc': 0.92131, 'accuracy-SBM': 0.84025}
2025-07-05 05:55:25,626 - INFO - ...computing epoch stats took: 0.36s
2025-07-05 05:55:45,323 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 05:55:45,675 - INFO - test: {'epoch': 1, 'time_epoch': 3.28933, 'loss': 0.15622708, 'lr': 0, 'params': 340919, 'time_iter': 0.05221, 'accuracy': 0.86529, 'precision': 0.58585, 'recall': 0.80376, 'f1': 0.67772, 'auc': 0.92163, 'accuracy-SBM': 0.84111}
2025-07-05 05:55:45,692 - INFO - ...computing epoch stats took: 0.37s
2025-07-05 05:55:45,693 - INFO - > Epoch 1: took 55.7s (avg 50.0s) | Best so far: epoch 1	train_loss: 0.1685 train_accuracy-SBM: 0.8366	val_loss: 0.1569 val_accuracy-SBM: 0.8403	test_loss: 0.1562 test_accuracy-SBM: 0.8411
2025-07-05 05:55:45,693 - INFO - === Epoch 2 ===
2025-07-05 05:56:17,650 - INFO - train: {'epoch': 2, 'time_epoch': 30.02812, 'eta': 2918.8974, 'eta_hours': 0.8108, 'loss': 0.14729479, 'lr': 0.0002, 'params': 340919, 'time_iter': 0.09594, 'accuracy': 0.84955, 'precision': 0.54725, 'recall': 0.85522, 'f1': 0.66742, 'auc': 0.89372, 'accuracy-SBM': 0.85178}
2025-07-05 05:56:17,653 - INFO - ...computing epoch stats took: 1.93s
2025-07-05 05:56:21,115 - INFO - val: {'epoch': 2, 'time_epoch': 3.25492, 'loss': 0.1980254, 'lr': 0, 'params': 340919, 'time_iter': 0.05167, 'accuracy': 0.23864, 'precision': 0.18831, 'recall': 0.99714, 'f1': 0.31679, 'auc': 0.9046, 'accuracy-SBM': 0.53631}
2025-07-05 05:56:21,144 - INFO - ...computing epoch stats took: 0.23s
2025-07-05 05:56:39,452 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 05:56:39,659 - INFO - test: {'epoch': 2, 'time_epoch': 3.29675, 'loss': 0.19728634, 'lr': 0, 'params': 340919, 'time_iter': 0.05233, 'accuracy': 0.23672, 'precision': 0.18726, 'recall': 0.9974, 'f1': 0.31532, 'auc': 0.90298, 'accuracy-SBM': 0.5357}
2025-07-05 05:56:39,749 - INFO - ...computing epoch stats took: 0.30s
2025-07-05 05:56:39,749 - INFO - > Epoch 2: took 54.1s (avg 51.3s) | Best so far: epoch 1	train_loss: 0.1685 train_accuracy-SBM: 0.8366	val_loss: 0.1569 val_accuracy-SBM: 0.8403	test_loss: 0.1562 test_accuracy-SBM: 0.8411
2025-07-05 05:56:39,749 - INFO - === Epoch 3 ===
2025-07-05 05:57:11,849 - INFO - train: {'epoch': 3, 'time_epoch': 30.11366, 'eta': 2889.33213, 'eta_hours': 0.80259, 'loss': 0.12887488, 'lr': 0.0003, 'params': 340919, 'time_iter': 0.09621, 'accuracy': 0.85609, 'precision': 0.56008, 'recall': 0.86111, 'f1': 0.67872, 'auc': 0.91047, 'accuracy-SBM': 0.85807}
2025-07-05 05:57:15,325 - INFO - val: {'epoch': 3, 'time_epoch': 3.25907, 'loss': 0.1238118, 'lr': 0, 'params': 340919, 'time_iter': 0.05173, 'accuracy': 0.81977, 'precision': 0.495, 'recall': 0.89902, 'f1': 0.63847, 'auc': 0.93283, 'accuracy-SBM': 0.85087}
2025-07-05 05:57:30,349 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 05:57:30,719 - INFO - test: {'epoch': 3, 'time_epoch': 3.30077, 'loss': 0.12312278, 'lr': 0, 'params': 340919, 'time_iter': 0.05239, 'accuracy': 0.82124, 'precision': 0.49602, 'recall': 0.8974, 'f1': 0.6389, 'auc': 0.93269, 'accuracy-SBM': 0.85118}
2025-07-05 05:57:30,742 - INFO - > Epoch 3: took 51.0s (avg 51.3s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 05:57:30,742 - INFO - === Epoch 4 ===
2025-07-05 05:58:02,856 - INFO - train: {'epoch': 4, 'time_epoch': 30.12888, 'eta': 2859.83666, 'eta_hours': 0.7944, 'loss': 0.11528555, 'lr': 0.0004, 'params': 340919, 'time_iter': 0.09626, 'accuracy': 0.8581, 'precision': 0.56431, 'recall': 0.86037, 'f1': 0.68158, 'auc': 0.92181, 'accuracy-SBM': 0.85899}
2025-07-05 05:58:06,320 - INFO - val: {'epoch': 4, 'time_epoch': 3.25474, 'loss': 0.1903129, 'lr': 0, 'params': 340919, 'time_iter': 0.05166, 'accuracy': 0.26335, 'precision': 0.19353, 'recall': 0.99817, 'f1': 0.3242, 'auc': 0.87742, 'accuracy-SBM': 0.55173}
2025-07-05 05:58:20,913 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 05:58:21,116 - INFO - test: {'epoch': 4, 'time_epoch': 3.2961, 'loss': 0.18968648, 'lr': 0, 'params': 340919, 'time_iter': 0.05232, 'accuracy': 0.25872, 'precision': 0.19185, 'recall': 0.99817, 'f1': 0.32184, 'auc': 0.87964, 'accuracy-SBM': 0.54935}
2025-07-05 05:58:21,130 - INFO - > Epoch 4: took 50.4s (avg 51.1s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 05:58:21,130 - INFO - === Epoch 5 ===
2025-07-05 05:58:52,333 - INFO - train: {'epoch': 5, 'time_epoch': 30.11783, 'eta': 2829.95689, 'eta_hours': 0.7861, 'loss': 0.10651119, 'lr': 0.0005, 'params': 340919, 'time_iter': 0.09622, 'accuracy': 0.85991, 'precision': 0.56817, 'recall': 0.86007, 'f1': 0.68429, 'auc': 0.92842, 'accuracy-SBM': 0.85997}
2025-07-05 05:58:55,946 - INFO - val: {'epoch': 5, 'time_epoch': 3.25736, 'loss': 0.14837747, 'lr': 0, 'params': 340919, 'time_iter': 0.0517, 'accuracy': 0.89923, 'precision': 0.83259, 'recall': 0.53916, 'f1': 0.65449, 'auc': 0.92566, 'accuracy-SBM': 0.75792}
2025-07-05 05:59:16,212 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 05:59:16,567 - INFO - test: {'epoch': 5, 'time_epoch': 3.30436, 'loss': 0.14623487, 'lr': 0, 'params': 340919, 'time_iter': 0.05245, 'accuracy': 0.90105, 'precision': 0.83325, 'recall': 0.54817, 'f1': 0.66129, 'auc': 0.92573, 'accuracy-SBM': 0.76235}
2025-07-05 05:59:16,577 - INFO - > Epoch 5: took 55.4s (avg 51.8s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 05:59:16,577 - INFO - === Epoch 6 ===
2025-07-05 05:59:48,682 - INFO - train: {'epoch': 6, 'time_epoch': 30.11137, 'eta': 2799.92334, 'eta_hours': 0.77776, 'loss': 0.10081726, 'lr': 0.00049986, 'params': 340919, 'time_iter': 0.0962, 'accuracy': 0.85989, 'precision': 0.56783, 'recall': 0.86323, 'f1': 0.68504, 'auc': 0.93321, 'accuracy-SBM': 0.8612}
2025-07-05 05:59:52,299 - INFO - val: {'epoch': 6, 'time_epoch': 3.25503, 'loss': 0.25564935, 'lr': 0, 'params': 340919, 'time_iter': 0.05167, 'accuracy': 0.85442, 'precision': 0.81423, 'recall': 0.23011, 'f1': 0.35881, 'auc': 0.89317, 'accuracy-SBM': 0.60941}
2025-07-05 05:59:57,956 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 05:59:58,303 - INFO - test: {'epoch': 6, 'time_epoch': 3.29709, 'loss': 0.25351024, 'lr': 0, 'params': 340919, 'time_iter': 0.05233, 'accuracy': 0.85538, 'precision': 0.81423, 'recall': 0.2323, 'f1': 0.36147, 'auc': 0.89389, 'accuracy-SBM': 0.61048}
2025-07-05 05:59:58,305 - INFO - > Epoch 6: took 41.7s (avg 50.4s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 05:59:58,305 - INFO - === Epoch 7 ===
2025-07-05 06:00:29,649 - INFO - train: {'epoch': 7, 'time_epoch': 30.21198, 'eta': 2771.02728, 'eta_hours': 0.76973, 'loss': 0.09798708, 'lr': 0.00049945, 'params': 340919, 'time_iter': 0.09652, 'accuracy': 0.85959, 'precision': 0.56723, 'recall': 0.8628, 'f1': 0.68447, 'auc': 0.93491, 'accuracy-SBM': 0.86085}
2025-07-05 06:00:33,121 - INFO - val: {'epoch': 7, 'time_epoch': 3.25792, 'loss': 0.16486055, 'lr': 0, 'params': 340919, 'time_iter': 0.05171, 'accuracy': 0.51461, 'precision': 0.26346, 'recall': 0.97013, 'f1': 0.41439, 'auc': 0.87056, 'accuracy-SBM': 0.69338}
2025-07-05 06:00:38,606 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:00:38,816 - INFO - test: {'epoch': 7, 'time_epoch': 3.29982, 'loss': 0.16351284, 'lr': 0, 'params': 340919, 'time_iter': 0.05238, 'accuracy': 0.52223, 'precision': 0.26549, 'recall': 0.96868, 'f1': 0.41676, 'auc': 0.86996, 'accuracy-SBM': 0.6977}
2025-07-05 06:00:38,817 - INFO - > Epoch 7: took 40.5s (avg 49.1s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:00:38,818 - INFO - === Epoch 8 ===
2025-07-05 06:01:09,170 - INFO - train: {'epoch': 8, 'time_epoch': 30.08669, 'eta': 2740.57204, 'eta_hours': 0.76127, 'loss': 0.09611783, 'lr': 0.00049877, 'params': 340919, 'time_iter': 0.09612, 'accuracy': 0.86022, 'precision': 0.56853, 'recall': 0.86335, 'f1': 0.68559, 'auc': 0.93642, 'accuracy-SBM': 0.86145}
2025-07-05 06:01:12,638 - INFO - val: {'epoch': 8, 'time_epoch': 3.25427, 'loss': 0.1401887, 'lr': 0, 'params': 340919, 'time_iter': 0.05166, 'accuracy': 0.60767, 'precision': 0.30781, 'recall': 0.97399, 'f1': 0.46778, 'auc': 0.91645, 'accuracy-SBM': 0.75143}
2025-07-05 06:01:18,417 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:01:18,636 - INFO - test: {'epoch': 8, 'time_epoch': 3.29544, 'loss': 0.1384644, 'lr': 0, 'params': 340919, 'time_iter': 0.05231, 'accuracy': 0.61288, 'precision': 0.30956, 'recall': 0.97273, 'f1': 0.46966, 'auc': 0.91605, 'accuracy-SBM': 0.75432}
2025-07-05 06:01:18,637 - INFO - > Epoch 8: took 39.8s (avg 48.1s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:01:18,637 - INFO - === Epoch 9 ===
2025-07-05 06:01:50,828 - INFO - train: {'epoch': 9, 'time_epoch': 30.152, 'eta': 2710.77832, 'eta_hours': 0.75299, 'loss': 0.09477026, 'lr': 0.00049782, 'params': 340919, 'time_iter': 0.09633, 'accuracy': 0.86079, 'precision': 0.56964, 'recall': 0.86434, 'f1': 0.68671, 'auc': 0.93745, 'accuracy-SBM': 0.86218}
2025-07-05 06:01:54,313 - INFO - val: {'epoch': 9, 'time_epoch': 3.26665, 'loss': 0.13505289, 'lr': 0, 'params': 340919, 'time_iter': 0.05185, 'accuracy': 0.64221, 'precision': 0.32762, 'recall': 0.97044, 'f1': 0.48987, 'auc': 0.92444, 'accuracy-SBM': 0.77102}
2025-07-05 06:01:59,598 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:01:59,811 - INFO - test: {'epoch': 9, 'time_epoch': 3.31154, 'loss': 0.13330347, 'lr': 0, 'params': 340919, 'time_iter': 0.05256, 'accuracy': 0.64715, 'precision': 0.32966, 'recall': 0.96991, 'f1': 0.49207, 'auc': 0.925, 'accuracy-SBM': 0.77401}
2025-07-05 06:01:59,813 - INFO - > Epoch 9: took 41.2s (avg 47.4s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:01:59,813 - INFO - === Epoch 10 ===
2025-07-05 06:02:30,255 - INFO - train: {'epoch': 10, 'time_epoch': 30.12962, 'eta': 2680.73836, 'eta_hours': 0.74465, 'loss': 0.09427108, 'lr': 0.00049659, 'params': 340919, 'time_iter': 0.09626, 'accuracy': 0.86109, 'precision': 0.5704, 'recall': 0.86309, 'f1': 0.68687, 'auc': 0.93741, 'accuracy-SBM': 0.86188}
2025-07-05 06:02:33,735 - INFO - val: {'epoch': 10, 'time_epoch': 3.26238, 'loss': 0.14212343, 'lr': 0, 'params': 340919, 'time_iter': 0.05178, 'accuracy': 0.60095, 'precision': 0.30448, 'recall': 0.97661, 'f1': 0.46423, 'auc': 0.9166, 'accuracy-SBM': 0.74838}
2025-07-05 06:02:39,539 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:02:39,758 - INFO - test: {'epoch': 10, 'time_epoch': 3.32044, 'loss': 0.14052558, 'lr': 0, 'params': 340919, 'time_iter': 0.05271, 'accuracy': 0.60586, 'precision': 0.30601, 'recall': 0.97537, 'f1': 0.46586, 'auc': 0.91624, 'accuracy-SBM': 0.7511}
2025-07-05 06:02:39,759 - INFO - > Epoch 10: took 39.9s (avg 46.7s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:02:39,759 - INFO - === Epoch 11 ===
2025-07-05 06:03:11,950 - INFO - train: {'epoch': 11, 'time_epoch': 30.15378, 'eta': 2650.86063, 'eta_hours': 0.73635, 'loss': 0.09359531, 'lr': 0.00049509, 'params': 340919, 'time_iter': 0.09634, 'accuracy': 0.86026, 'precision': 0.56854, 'recall': 0.86414, 'f1': 0.68584, 'auc': 0.93796, 'accuracy-SBM': 0.86178}
2025-07-05 06:03:15,435 - INFO - val: {'epoch': 11, 'time_epoch': 3.26612, 'loss': 0.12078073, 'lr': 0, 'params': 340919, 'time_iter': 0.05184, 'accuracy': 0.69731, 'precision': 0.36516, 'recall': 0.96124, 'f1': 0.52926, 'auc': 0.92956, 'accuracy-SBM': 0.80089}
2025-07-05 06:03:20,734 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:03:21,119 - INFO - test: {'epoch': 11, 'time_epoch': 3.30844, 'loss': 0.11934097, 'lr': 0, 'params': 340919, 'time_iter': 0.05251, 'accuracy': 0.70159, 'precision': 0.3672, 'recall': 0.95867, 'f1': 0.53101, 'auc': 0.92995, 'accuracy-SBM': 0.80263}
2025-07-05 06:03:21,121 - INFO - > Epoch 11: took 41.4s (avg 46.3s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:03:21,121 - INFO - === Epoch 12 ===
2025-07-05 06:03:53,269 - INFO - train: {'epoch': 12, 'time_epoch': 30.12895, 'eta': 2620.77423, 'eta_hours': 0.72799, 'loss': 0.09289503, 'lr': 0.00049333, 'params': 340919, 'time_iter': 0.09626, 'accuracy': 0.86087, 'precision': 0.56987, 'recall': 0.86365, 'f1': 0.68666, 'auc': 0.93855, 'accuracy-SBM': 0.86196}
2025-07-05 06:03:56,750 - INFO - val: {'epoch': 12, 'time_epoch': 3.26424, 'loss': 0.15570128, 'lr': 0, 'params': 340919, 'time_iter': 0.05181, 'accuracy': 0.54127, 'precision': 0.27612, 'recall': 0.98137, 'f1': 0.43098, 'auc': 0.90414, 'accuracy-SBM': 0.71399}
2025-07-05 06:04:02,098 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:04:02,316 - INFO - test: {'epoch': 12, 'time_epoch': 3.30913, 'loss': 0.15392267, 'lr': 0, 'params': 340919, 'time_iter': 0.05253, 'accuracy': 0.54802, 'precision': 0.27805, 'recall': 0.98018, 'f1': 0.43321, 'auc': 0.90369, 'accuracy-SBM': 0.71787}
2025-07-05 06:04:02,317 - INFO - > Epoch 12: took 41.2s (avg 45.9s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:04:02,317 - INFO - === Epoch 13 ===
2025-07-05 06:04:33,569 - INFO - train: {'epoch': 13, 'time_epoch': 30.12665, 'eta': 2590.66763, 'eta_hours': 0.71963, 'loss': 0.09267572, 'lr': 0.0004913, 'params': 340919, 'time_iter': 0.09625, 'accuracy': 0.8613, 'precision': 0.57079, 'recall': 0.86358, 'f1': 0.6873, 'auc': 0.93855, 'accuracy-SBM': 0.86219}
2025-07-05 06:04:37,055 - INFO - val: {'epoch': 13, 'time_epoch': 3.26687, 'loss': 0.12411382, 'lr': 0, 'params': 340919, 'time_iter': 0.05186, 'accuracy': 0.67642, 'precision': 0.34929, 'recall': 0.95941, 'f1': 0.51213, 'auc': 0.92437, 'accuracy-SBM': 0.78748}
2025-07-05 06:04:42,288 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:04:42,670 - INFO - test: {'epoch': 13, 'time_epoch': 3.30785, 'loss': 0.12263947, 'lr': 0, 'params': 340919, 'time_iter': 0.05251, 'accuracy': 0.68081, 'precision': 0.35114, 'recall': 0.95691, 'f1': 0.51375, 'auc': 0.92425, 'accuracy-SBM': 0.78933}
2025-07-05 06:04:42,671 - INFO - > Epoch 13: took 40.4s (avg 45.5s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:04:42,672 - INFO - === Epoch 14 ===
2025-07-05 06:05:14,817 - INFO - train: {'epoch': 14, 'time_epoch': 30.15307, 'eta': 2560.7081, 'eta_hours': 0.71131, 'loss': 0.09247627, 'lr': 0.00048901, 'params': 340919, 'time_iter': 0.09634, 'accuracy': 0.8617, 'precision': 0.57168, 'recall': 0.86328, 'f1': 0.68785, 'auc': 0.93862, 'accuracy-SBM': 0.86232}
2025-07-05 06:05:18,415 - INFO - val: {'epoch': 14, 'time_epoch': 3.25761, 'loss': 0.32686661, 'lr': 0, 'params': 340919, 'time_iter': 0.05171, 'accuracy': 0.85397, 'precision': 0.93275, 'recall': 0.18866, 'f1': 0.31384, 'auc': 0.89676, 'accuracy-SBM': 0.59287}
2025-07-05 06:05:23,944 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:05:24,288 - INFO - test: {'epoch': 14, 'time_epoch': 3.29949, 'loss': 0.3240997, 'lr': 0, 'params': 340919, 'time_iter': 0.05237, 'accuracy': 0.8557, 'precision': 0.9368, 'recall': 0.19421, 'f1': 0.32173, 'auc': 0.89775, 'accuracy-SBM': 0.5957}
2025-07-05 06:05:24,289 - INFO - > Epoch 14: took 41.6s (avg 45.2s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:05:24,289 - INFO - === Epoch 15 ===
2025-07-05 06:05:56,299 - INFO - train: {'epoch': 15, 'time_epoch': 30.02931, 'eta': 2530.07463, 'eta_hours': 0.7028, 'loss': 0.09214071, 'lr': 0.00048645, 'params': 340919, 'time_iter': 0.09594, 'accuracy': 0.86062, 'precision': 0.56924, 'recall': 0.8649, 'f1': 0.68659, 'auc': 0.93889, 'accuracy-SBM': 0.8623}
2025-07-05 06:05:59,905 - INFO - val: {'epoch': 15, 'time_epoch': 3.24836, 'loss': 0.12322733, 'lr': 0, 'params': 340919, 'time_iter': 0.05156, 'accuracy': 0.90482, 'precision': 0.77375, 'recall': 0.65336, 'f1': 0.70848, 'auc': 0.93478, 'accuracy-SBM': 0.80613}
2025-07-05 06:06:05,384 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:06:05,738 - INFO - test: {'epoch': 15, 'time_epoch': 3.29508, 'loss': 0.12237885, 'lr': 0, 'params': 340919, 'time_iter': 0.0523, 'accuracy': 0.9053, 'precision': 0.77398, 'recall': 0.65338, 'f1': 0.70859, 'auc': 0.93484, 'accuracy-SBM': 0.80628}
2025-07-05 06:06:05,740 - INFO - > Epoch 15: took 41.5s (avg 45.0s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:06:05,740 - INFO - === Epoch 16 ===
2025-07-05 06:06:36,845 - INFO - train: {'epoch': 16, 'time_epoch': 30.00977, 'eta': 2499.41684, 'eta_hours': 0.69428, 'loss': 0.0918665, 'lr': 0.00048364, 'params': 340919, 'time_iter': 0.09588, 'accuracy': 0.86058, 'precision': 0.56908, 'recall': 0.86563, 'f1': 0.6867, 'auc': 0.93913, 'accuracy-SBM': 0.86256}
2025-07-05 06:06:40,433 - INFO - val: {'epoch': 16, 'time_epoch': 3.24494, 'loss': 0.51200922, 'lr': 0, 'params': 340919, 'time_iter': 0.05151, 'accuracy': 0.82615, 'precision': 0.88379, 'recall': 0.02065, 'f1': 0.04036, 'auc': 0.78669, 'accuracy-SBM': 0.51003}
2025-07-05 06:06:46,168 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:06:46,505 - INFO - test: {'epoch': 16, 'time_epoch': 3.28801, 'loss': 0.51001835, 'lr': 0, 'params': 340919, 'time_iter': 0.05219, 'accuracy': 0.82681, 'precision': 0.89422, 'recall': 0.01953, 'f1': 0.03823, 'auc': 0.78577, 'accuracy-SBM': 0.50952}
2025-07-05 06:06:46,506 - INFO - > Epoch 16: took 40.8s (avg 44.8s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:06:46,506 - INFO - === Epoch 17 ===
2025-07-05 06:07:16,807 - INFO - train: {'epoch': 17, 'time_epoch': 30.0519, 'eta': 2469.02296, 'eta_hours': 0.68584, 'loss': 0.09170625, 'lr': 0.00048057, 'params': 340919, 'time_iter': 0.09601, 'accuracy': 0.86049, 'precision': 0.56882, 'recall': 0.86643, 'f1': 0.68677, 'auc': 0.93914, 'accuracy-SBM': 0.86282}
2025-07-05 06:07:20,266 - INFO - val: {'epoch': 17, 'time_epoch': 3.24668, 'loss': 0.11906068, 'lr': 0, 'params': 340919, 'time_iter': 0.05153, 'accuracy': 0.70367, 'precision': 0.36978, 'recall': 0.95693, 'f1': 0.53343, 'auc': 0.92896, 'accuracy-SBM': 0.80306}
2025-07-05 06:07:26,296 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:07:26,667 - INFO - test: {'epoch': 17, 'time_epoch': 3.29326, 'loss': 0.11777001, 'lr': 0, 'params': 340919, 'time_iter': 0.05227, 'accuracy': 0.70697, 'precision': 0.37117, 'recall': 0.95481, 'f1': 0.53454, 'auc': 0.92934, 'accuracy-SBM': 0.80438}
2025-07-05 06:07:26,668 - INFO - > Epoch 17: took 40.2s (avg 44.5s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:07:26,669 - INFO - === Epoch 18 ===
2025-07-05 06:07:57,959 - INFO - train: {'epoch': 18, 'time_epoch': 30.18429, 'eta': 2439.22948, 'eta_hours': 0.67756, 'loss': 0.09171938, 'lr': 0.00047725, 'params': 340919, 'time_iter': 0.09644, 'accuracy': 0.86091, 'precision': 0.56988, 'recall': 0.86449, 'f1': 0.68693, 'auc': 0.93913, 'accuracy-SBM': 0.86231}
2025-07-05 06:08:01,593 - INFO - val: {'epoch': 18, 'time_epoch': 3.27756, 'loss': 0.16720204, 'lr': 0, 'params': 340919, 'time_iter': 0.05202, 'accuracy': 0.8905, 'precision': 0.77075, 'recall': 0.5429, 'f1': 0.63706, 'auc': 0.91575, 'accuracy-SBM': 0.75408}
2025-07-05 06:08:07,667 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:08:08,021 - INFO - test: {'epoch': 18, 'time_epoch': 3.32179, 'loss': 0.16553372, 'lr': 0, 'params': 340919, 'time_iter': 0.05273, 'accuracy': 0.89195, 'precision': 0.77276, 'recall': 0.548, 'f1': 0.64125, 'auc': 0.91652, 'accuracy-SBM': 0.75676}
2025-07-05 06:08:08,080 - INFO - > Epoch 18: took 41.4s (avg 44.3s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:08:08,080 - INFO - === Epoch 19 ===
2025-07-05 06:08:40,349 - INFO - train: {'epoch': 19, 'time_epoch': 30.23661, 'eta': 2409.60621, 'eta_hours': 0.66934, 'loss': 0.09141606, 'lr': 0.00047368, 'params': 340919, 'time_iter': 0.0966, 'accuracy': 0.86123, 'precision': 0.57043, 'recall': 0.86606, 'f1': 0.68782, 'auc': 0.93946, 'accuracy-SBM': 0.86313}
2025-07-05 06:08:43,823 - INFO - val: {'epoch': 19, 'time_epoch': 3.2637, 'loss': 0.11215125, 'lr': 0, 'params': 340919, 'time_iter': 0.0518, 'accuracy': 0.73524, 'precision': 0.39602, 'recall': 0.94388, 'f1': 0.55795, 'auc': 0.92948, 'accuracy-SBM': 0.81712}
2025-07-05 06:08:49,845 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:08:50,215 - INFO - test: {'epoch': 19, 'time_epoch': 3.31856, 'loss': 0.1109796, 'lr': 0, 'params': 340919, 'time_iter': 0.05268, 'accuracy': 0.73813, 'precision': 0.39744, 'recall': 0.94171, 'f1': 0.55897, 'auc': 0.92993, 'accuracy-SBM': 0.81815}
2025-07-05 06:08:50,217 - INFO - > Epoch 19: took 42.1s (avg 44.2s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:08:50,217 - INFO - === Epoch 20 ===
2025-07-05 06:09:22,434 - INFO - train: {'epoch': 20, 'time_epoch': 30.16992, 'eta': 2379.67362, 'eta_hours': 0.66102, 'loss': 0.0914093, 'lr': 0.00046987, 'params': 340919, 'time_iter': 0.09639, 'accuracy': 0.86075, 'precision': 0.56947, 'recall': 0.8654, 'f1': 0.68692, 'auc': 0.93936, 'accuracy-SBM': 0.86258}
2025-07-05 06:09:26,038 - INFO - val: {'epoch': 20, 'time_epoch': 3.2627, 'loss': 0.53779131, 'lr': 0, 'params': 340919, 'time_iter': 0.05179, 'accuracy': 0.82726, 'precision': 0.79083, 'recall': 0.03287, 'f1': 0.06312, 'auc': 0.72804, 'accuracy-SBM': 0.5155}
2025-07-05 06:09:32,991 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:09:33,320 - INFO - test: {'epoch': 20, 'time_epoch': 3.3047, 'loss': 0.5345907, 'lr': 0, 'params': 340919, 'time_iter': 0.05246, 'accuracy': 0.82797, 'precision': 0.80415, 'recall': 0.0314, 'f1': 0.06043, 'auc': 0.72394, 'accuracy-SBM': 0.51488}
2025-07-05 06:09:33,321 - INFO - > Epoch 20: took 43.1s (avg 44.2s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:09:33,322 - INFO - === Epoch 21 ===
2025-07-05 06:10:05,376 - INFO - train: {'epoch': 21, 'time_epoch': 30.09432, 'eta': 2349.45142, 'eta_hours': 0.65263, 'loss': 0.0915614, 'lr': 0.00046581, 'params': 340919, 'time_iter': 0.09615, 'accuracy': 0.86096, 'precision': 0.57002, 'recall': 0.86414, 'f1': 0.68692, 'auc': 0.93907, 'accuracy-SBM': 0.86221}
2025-07-05 06:10:08,855 - INFO - val: {'epoch': 21, 'time_epoch': 3.26657, 'loss': 0.12371422, 'lr': 0, 'params': 340919, 'time_iter': 0.05185, 'accuracy': 0.75644, 'precision': 0.41073, 'recall': 0.86467, 'f1': 0.55692, 'auc': 0.88281, 'accuracy-SBM': 0.79892}
2025-07-05 06:10:16,076 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:10:16,439 - INFO - test: {'epoch': 21, 'time_epoch': 3.30764, 'loss': 0.12347072, 'lr': 0, 'params': 340919, 'time_iter': 0.0525, 'accuracy': 0.75736, 'precision': 0.40989, 'recall': 0.85727, 'f1': 0.5546, 'auc': 0.88157, 'accuracy-SBM': 0.79662}
2025-07-05 06:10:16,441 - INFO - > Epoch 21: took 43.1s (avg 44.1s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:10:16,441 - INFO - === Epoch 22 ===
2025-07-05 06:10:46,782 - INFO - train: {'epoch': 22, 'time_epoch': 30.07515, 'eta': 2319.17618, 'eta_hours': 0.64422, 'loss': 0.09130462, 'lr': 0.00046152, 'params': 340919, 'time_iter': 0.09609, 'accuracy': 0.86216, 'precision': 0.5726, 'recall': 0.86416, 'f1': 0.6888, 'auc': 0.93946, 'accuracy-SBM': 0.86295}
2025-07-05 06:10:50,256 - INFO - val: {'epoch': 22, 'time_epoch': 3.2598, 'loss': 0.14004751, 'lr': 0, 'params': 340919, 'time_iter': 0.05174, 'accuracy': 0.61291, 'precision': 0.31043, 'recall': 0.97161, 'f1': 0.47053, 'auc': 0.91115, 'accuracy-SBM': 0.75368}
2025-07-05 06:10:56,514 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:10:56,723 - INFO - test: {'epoch': 22, 'time_epoch': 3.3052, 'loss': 0.13875852, 'lr': 0, 'params': 340919, 'time_iter': 0.05246, 'accuracy': 0.61632, 'precision': 0.31127, 'recall': 0.97082, 'f1': 0.4714, 'auc': 0.91105, 'accuracy-SBM': 0.75566}
2025-07-05 06:10:56,724 - INFO - > Epoch 22: took 40.3s (avg 44.0s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:10:56,724 - INFO - === Epoch 23 ===
2025-07-05 06:11:28,841 - INFO - train: {'epoch': 23, 'time_epoch': 30.13051, 'eta': 2289.09292, 'eta_hours': 0.63586, 'loss': 0.09132396, 'lr': 0.000457, 'params': 340919, 'time_iter': 0.09626, 'accuracy': 0.86202, 'precision': 0.57229, 'recall': 0.86423, 'f1': 0.6886, 'auc': 0.93936, 'accuracy-SBM': 0.86289}
2025-07-05 06:11:32,321 - INFO - val: {'epoch': 23, 'time_epoch': 3.26495, 'loss': 0.13098199, 'lr': 0, 'params': 340919, 'time_iter': 0.05182, 'accuracy': 0.65622, 'precision': 0.3367, 'recall': 0.97113, 'f1': 0.50003, 'auc': 0.9308, 'accuracy-SBM': 0.77981}
2025-07-05 06:11:37,962 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:11:38,166 - INFO - test: {'epoch': 23, 'time_epoch': 3.30434, 'loss': 0.12975845, 'lr': 0, 'params': 340919, 'time_iter': 0.05245, 'accuracy': 0.6585, 'precision': 0.33699, 'recall': 0.96941, 'f1': 0.50012, 'auc': 0.93139, 'accuracy-SBM': 0.7807}
2025-07-05 06:11:38,168 - INFO - > Epoch 23: took 41.4s (avg 43.9s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:11:38,168 - INFO - === Epoch 24 ===
2025-07-05 06:12:10,285 - INFO - train: {'epoch': 24, 'time_epoch': 30.11019, 'eta': 2258.94492, 'eta_hours': 0.62748, 'loss': 0.09112726, 'lr': 0.00045225, 'params': 340919, 'time_iter': 0.0962, 'accuracy': 0.86153, 'precision': 0.57106, 'recall': 0.86619, 'f1': 0.68832, 'auc': 0.9396, 'accuracy-SBM': 0.86336}
2025-07-05 06:12:13,759 - INFO - val: {'epoch': 24, 'time_epoch': 3.26085, 'loss': 0.13680415, 'lr': 0, 'params': 340919, 'time_iter': 0.05176, 'accuracy': 0.63613, 'precision': 0.3228, 'recall': 0.96139, 'f1': 0.48332, 'auc': 0.90382, 'accuracy-SBM': 0.76378}
2025-07-05 06:12:19,545 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:12:19,759 - INFO - test: {'epoch': 24, 'time_epoch': 3.30208, 'loss': 0.13549929, 'lr': 0, 'params': 340919, 'time_iter': 0.05241, 'accuracy': 0.64047, 'precision': 0.32429, 'recall': 0.95996, 'f1': 0.48481, 'auc': 0.90422, 'accuracy-SBM': 0.76604}
2025-07-05 06:12:19,760 - INFO - > Epoch 24: took 41.6s (avg 43.8s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:12:19,760 - INFO - === Epoch 25 ===
2025-07-05 06:12:51,837 - INFO - train: {'epoch': 25, 'time_epoch': 30.10045, 'eta': 2228.77211, 'eta_hours': 0.6191, 'loss': 0.09115752, 'lr': 0.00044729, 'params': 340919, 'time_iter': 0.09617, 'accuracy': 0.86094, 'precision': 0.56989, 'recall': 0.86525, 'f1': 0.68718, 'auc': 0.93951, 'accuracy-SBM': 0.86263}
2025-07-05 06:12:55,444 - INFO - val: {'epoch': 25, 'time_epoch': 3.2605, 'loss': 0.42475701, 'lr': 0, 'params': 340919, 'time_iter': 0.05175, 'accuracy': 0.83856, 'precision': 0.88983, 'recall': 0.10043, 'f1': 0.18049, 'auc': 0.84695, 'accuracy-SBM': 0.54888}
2025-07-05 06:13:02,524 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:13:02,857 - INFO - test: {'epoch': 25, 'time_epoch': 3.30282, 'loss': 0.4240115, 'lr': 0, 'params': 340919, 'time_iter': 0.05243, 'accuracy': 0.8393, 'precision': 0.89591, 'recall': 0.09964, 'f1': 0.17934, 'auc': 0.84633, 'accuracy-SBM': 0.54858}
2025-07-05 06:13:02,859 - INFO - > Epoch 25: took 43.1s (avg 43.7s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:13:02,859 - INFO - === Epoch 26 ===
2025-07-05 06:13:33,965 - INFO - train: {'epoch': 26, 'time_epoch': 29.99394, 'eta': 2198.31667, 'eta_hours': 0.61064, 'loss': 0.09118209, 'lr': 0.0004421, 'params': 340919, 'time_iter': 0.09583, 'accuracy': 0.86163, 'precision': 0.57142, 'recall': 0.86459, 'f1': 0.68808, 'auc': 0.93948, 'accuracy-SBM': 0.86279}
2025-07-05 06:13:37,570 - INFO - val: {'epoch': 26, 'time_epoch': 3.25137, 'loss': 0.17051696, 'lr': 0, 'params': 340919, 'time_iter': 0.05161, 'accuracy': 0.89079, 'precision': 0.80993, 'recall': 0.50052, 'f1': 0.6187, 'auc': 0.91571, 'accuracy-SBM': 0.73763}
2025-07-05 06:13:43,922 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:13:44,266 - INFO - test: {'epoch': 26, 'time_epoch': 3.29388, 'loss': 0.1696642, 'lr': 0, 'params': 340919, 'time_iter': 0.05228, 'accuracy': 0.89165, 'precision': 0.80895, 'recall': 0.50422, 'f1': 0.62123, 'auc': 0.91628, 'accuracy-SBM': 0.73937}
2025-07-05 06:13:44,267 - INFO - > Epoch 26: took 41.4s (avg 43.6s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:13:44,267 - INFO - === Epoch 27 ===
2025-07-05 06:14:15,370 - INFO - train: {'epoch': 27, 'time_epoch': 29.99624, 'eta': 2167.90011, 'eta_hours': 0.60219, 'loss': 0.09100221, 'lr': 0.00043671, 'params': 340919, 'time_iter': 0.09583, 'accuracy': 0.86196, 'precision': 0.57209, 'recall': 0.86491, 'f1': 0.68867, 'auc': 0.93972, 'accuracy-SBM': 0.86312}
2025-07-05 06:14:18,962 - INFO - val: {'epoch': 27, 'time_epoch': 3.25014, 'loss': 0.59808232, 'lr': 0, 'params': 340919, 'time_iter': 0.05159, 'accuracy': 0.82619, 'precision': 0.91046, 'recall': 0.0201, 'f1': 0.03934, 'auc': 0.58099, 'accuracy-SBM': 0.50984}
2025-07-05 06:14:24,331 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:14:24,670 - INFO - test: {'epoch': 27, 'time_epoch': 3.28973, 'loss': 0.59525224, 'lr': 0, 'params': 340919, 'time_iter': 0.05222, 'accuracy': 0.82679, 'precision': 0.92426, 'recall': 0.0186, 'f1': 0.03647, 'auc': 0.58678, 'accuracy-SBM': 0.50914}
2025-07-05 06:14:24,672 - INFO - > Epoch 27: took 40.4s (avg 43.5s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:14:24,672 - INFO - === Epoch 28 ===
2025-07-05 06:14:56,601 - INFO - train: {'epoch': 28, 'time_epoch': 29.99934, 'eta': 2137.52014, 'eta_hours': 0.59376, 'loss': 0.09100708, 'lr': 0.00043111, 'params': 340919, 'time_iter': 0.09584, 'accuracy': 0.8616, 'precision': 0.57138, 'recall': 0.86431, 'f1': 0.68796, 'auc': 0.93961, 'accuracy-SBM': 0.86267}
2025-07-05 06:15:00,065 - INFO - val: {'epoch': 28, 'time_epoch': 3.24971, 'loss': 0.10009758, 'lr': 0, 'params': 340919, 'time_iter': 0.05158, 'accuracy': 0.78645, 'precision': 0.45021, 'recall': 0.93304, 'f1': 0.60736, 'auc': 0.93823, 'accuracy-SBM': 0.84398}
2025-07-05 06:15:05,601 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:15:05,972 - INFO - test: {'epoch': 28, 'time_epoch': 3.29746, 'loss': 0.09879209, 'lr': 0, 'params': 340919, 'time_iter': 0.05234, 'accuracy': 0.78911, 'precision': 0.45225, 'recall': 0.93171, 'f1': 0.60892, 'auc': 0.93888, 'accuracy-SBM': 0.84515}
2025-07-05 06:15:05,974 - INFO - > Epoch 28: took 41.3s (avg 43.5s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:15:05,974 - INFO - === Epoch 29 ===
2025-07-05 06:15:36,330 - INFO - train: {'epoch': 29, 'time_epoch': 30.04688, 'eta': 2107.27646, 'eta_hours': 0.58535, 'loss': 0.09089329, 'lr': 0.00042531, 'params': 340919, 'time_iter': 0.096, 'accuracy': 0.86261, 'precision': 0.57351, 'recall': 0.86472, 'f1': 0.68963, 'auc': 0.93985, 'accuracy-SBM': 0.86344}
2025-07-05 06:15:39,790 - INFO - val: {'epoch': 29, 'time_epoch': 3.24737, 'loss': 0.13682979, 'lr': 0, 'params': 340919, 'time_iter': 0.05155, 'accuracy': 0.62176, 'precision': 0.31479, 'recall': 0.96596, 'f1': 0.47484, 'auc': 0.90155, 'accuracy-SBM': 0.75684}
2025-07-05 06:15:45,034 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:15:45,246 - INFO - test: {'epoch': 29, 'time_epoch': 3.28874, 'loss': 0.13564649, 'lr': 0, 'params': 340919, 'time_iter': 0.0522, 'accuracy': 0.62588, 'precision': 0.31602, 'recall': 0.96453, 'f1': 0.47607, 'auc': 0.90123, 'accuracy-SBM': 0.75899}
2025-07-05 06:15:45,247 - INFO - > Epoch 29: took 39.3s (avg 43.3s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:15:45,247 - INFO - === Epoch 30 ===
2025-07-05 06:16:17,228 - INFO - train: {'epoch': 30, 'time_epoch': 29.99798, 'eta': 2076.93665, 'eta_hours': 0.57693, 'loss': 0.09090783, 'lr': 0.00041932, 'params': 340919, 'time_iter': 0.09584, 'accuracy': 0.86206, 'precision': 0.57227, 'recall': 0.86523, 'f1': 0.6889, 'auc': 0.93978, 'accuracy-SBM': 0.8633}
2025-07-05 06:16:20,820 - INFO - val: {'epoch': 30, 'time_epoch': 3.24359, 'loss': 0.4376304, 'lr': 0, 'params': 340919, 'time_iter': 0.05149, 'accuracy': 0.8451, 'precision': 0.92251, 'recall': 0.1364, 'f1': 0.23766, 'auc': 0.8096, 'accuracy-SBM': 0.56697}
2025-07-05 06:16:26,449 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:16:26,792 - INFO - test: {'epoch': 30, 'time_epoch': 3.28488, 'loss': 0.43593003, 'lr': 0, 'params': 340919, 'time_iter': 0.05214, 'accuracy': 0.84562, 'precision': 0.92076, 'recall': 0.13564, 'f1': 0.23644, 'auc': 0.80931, 'accuracy-SBM': 0.56657}
2025-07-05 06:16:26,793 - INFO - > Epoch 30: took 41.5s (avg 43.3s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:16:26,793 - INFO - === Epoch 31 ===
2025-07-05 06:16:58,701 - INFO - train: {'epoch': 31, 'time_epoch': 29.93148, 'eta': 2046.47689, 'eta_hours': 0.56847, 'loss': 0.09076217, 'lr': 0.00041315, 'params': 340919, 'time_iter': 0.09563, 'accuracy': 0.86178, 'precision': 0.57159, 'recall': 0.866, 'f1': 0.68865, 'auc': 0.93996, 'accuracy-SBM': 0.86344}
2025-07-05 06:17:02,157 - INFO - val: {'epoch': 31, 'time_epoch': 3.24331, 'loss': 0.14098314, 'lr': 0, 'params': 340919, 'time_iter': 0.05148, 'accuracy': 0.60864, 'precision': 0.30715, 'recall': 0.96417, 'f1': 0.46588, 'auc': 0.88858, 'accuracy-SBM': 0.74817}
2025-07-05 06:17:07,789 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:17:07,994 - INFO - test: {'epoch': 31, 'time_epoch': 3.28096, 'loss': 0.13983777, 'lr': 0, 'params': 340919, 'time_iter': 0.05208, 'accuracy': 0.61278, 'precision': 0.30834, 'recall': 0.96313, 'f1': 0.46713, 'auc': 0.88849, 'accuracy-SBM': 0.75048}
2025-07-05 06:17:07,996 - INFO - > Epoch 31: took 41.2s (avg 43.2s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:17:07,996 - INFO - === Epoch 32 ===
2025-07-05 06:17:39,148 - INFO - train: {'epoch': 32, 'time_epoch': 30.00033, 'eta': 2016.18892, 'eta_hours': 0.56005, 'loss': 0.0907149, 'lr': 0.00040679, 'params': 340919, 'time_iter': 0.09585, 'accuracy': 0.86201, 'precision': 0.57213, 'recall': 0.86565, 'f1': 0.68893, 'auc': 0.94004, 'accuracy-SBM': 0.86344}
2025-07-05 06:17:42,743 - INFO - val: {'epoch': 32, 'time_epoch': 3.25029, 'loss': 0.21027641, 'lr': 0, 'params': 340919, 'time_iter': 0.05159, 'accuracy': 0.88796, 'precision': 0.83047, 'recall': 0.46127, 'f1': 0.59311, 'auc': 0.9124, 'accuracy-SBM': 0.72051}
2025-07-05 06:17:48,111 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:17:48,456 - INFO - test: {'epoch': 32, 'time_epoch': 3.28653, 'loss': 0.21021189, 'lr': 0, 'params': 340919, 'time_iter': 0.05217, 'accuracy': 0.88855, 'precision': 0.83132, 'recall': 0.46115, 'f1': 0.59322, 'auc': 0.91193, 'accuracy-SBM': 0.72057}
2025-07-05 06:17:48,457 - INFO - > Epoch 32: took 40.5s (avg 43.1s) | Best so far: epoch 3	train_loss: 0.1289 train_accuracy-SBM: 0.8581	val_loss: 0.1238 val_accuracy-SBM: 0.8509	test_loss: 0.1231 test_accuracy-SBM: 0.8512
2025-07-05 06:17:48,457 - INFO - === Epoch 33 ===
2025-07-05 06:18:19,574 - INFO - train: {'epoch': 33, 'time_epoch': 29.99151, 'eta': 1985.90075, 'eta_hours': 0.55164, 'loss': 0.09082843, 'lr': 0.00040027, 'params': 340919, 'time_iter': 0.09582, 'accuracy': 0.86124, 'precision': 0.5704, 'recall': 0.86651, 'f1': 0.68795, 'auc': 0.93982, 'accuracy-SBM': 0.86331}
2025-07-05 06:18:23,037 - INFO - val: {'epoch': 33, 'time_epoch': 3.24653, 'loss': 0.09557721, 'lr': 0, 'params': 340919, 'time_iter': 0.05153, 'accuracy': 0.81505, 'precision': 0.48801, 'recall': 0.91124, 'f1': 0.63562, 'auc': 0.93762, 'accuracy-SBM': 0.8528}
2025-07-05 06:18:28,212 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:18:28,568 - INFO - test: {'epoch': 33, 'time_epoch': 3.28721, 'loss': 0.09449106, 'lr': 0, 'params': 340919, 'time_iter': 0.05218, 'accuracy': 0.81794, 'precision': 0.49107, 'recall': 0.91101, 'f1': 0.63815, 'auc': 0.93832, 'accuracy-SBM': 0.85452}
2025-07-05 06:18:28,569 - INFO - > Epoch 33: took 40.1s (avg 43.0s) | Best so far: epoch 33	train_loss: 0.0908 train_accuracy-SBM: 0.8633	val_loss: 0.0956 val_accuracy-SBM: 0.8528	test_loss: 0.0945 test_accuracy-SBM: 0.8545
2025-07-05 06:18:28,569 - INFO - === Epoch 34 ===
2025-07-05 06:19:00,449 - INFO - train: {'epoch': 34, 'time_epoch': 29.89347, 'eta': 1955.44747, 'eta_hours': 0.54318, 'loss': 0.09077766, 'lr': 0.00039358, 'params': 340919, 'time_iter': 0.09551, 'accuracy': 0.86134, 'precision': 0.57062, 'recall': 0.86646, 'f1': 0.68809, 'auc': 0.93994, 'accuracy-SBM': 0.86335}
2025-07-05 06:19:03,896 - INFO - val: {'epoch': 34, 'time_epoch': 3.24023, 'loss': 0.13615175, 'lr': 0, 'params': 340919, 'time_iter': 0.05143, 'accuracy': 0.61544, 'precision': 0.31175, 'recall': 0.97077, 'f1': 0.47194, 'auc': 0.90917, 'accuracy-SBM': 0.75489}
2025-07-05 06:19:09,326 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:19:09,528 - INFO - test: {'epoch': 34, 'time_epoch': 3.28306, 'loss': 0.13506225, 'lr': 0, 'params': 340919, 'time_iter': 0.05211, 'accuracy': 0.61912, 'precision': 0.31266, 'recall': 0.96918, 'f1': 0.4728, 'auc': 0.90891, 'accuracy-SBM': 0.75671}
2025-07-05 06:19:09,529 - INFO - > Epoch 34: took 41.0s (avg 43.0s) | Best so far: epoch 33	train_loss: 0.0908 train_accuracy-SBM: 0.8633	val_loss: 0.0956 val_accuracy-SBM: 0.8528	test_loss: 0.0945 test_accuracy-SBM: 0.8545
2025-07-05 06:19:09,529 - INFO - === Epoch 35 ===
2025-07-05 06:19:40,532 - INFO - train: {'epoch': 35, 'time_epoch': 29.8953, 'eta': 1925.02854, 'eta_hours': 0.53473, 'loss': 0.09062335, 'lr': 0.00038674, 'params': 340919, 'time_iter': 0.09551, 'accuracy': 0.86188, 'precision': 0.57173, 'recall': 0.86686, 'f1': 0.68902, 'auc': 0.94015, 'accuracy-SBM': 0.86383}
2025-07-05 06:19:44,110 - INFO - val: {'epoch': 35, 'time_epoch': 3.23656, 'loss': 0.71695569, 'lr': 0, 'params': 340919, 'time_iter': 0.05137, 'accuracy': 0.8232, 'precision': 0.88406, 'recall': 0.00145, 'f1': 0.0029, 'auc': 0.52387, 'accuracy-SBM': 0.50071}
2025-07-05 06:19:49,363 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:19:49,700 - INFO - test: {'epoch': 35, 'time_epoch': 3.27786, 'loss': 0.71436954, 'lr': 0, 'params': 340919, 'time_iter': 0.05203, 'accuracy': 0.82399, 'precision': 0.85507, 'recall': 0.00141, 'f1': 0.00281, 'auc': 0.53019, 'accuracy-SBM': 0.50068}
2025-07-05 06:19:49,701 - INFO - > Epoch 35: took 40.2s (avg 42.9s) | Best so far: epoch 33	train_loss: 0.0908 train_accuracy-SBM: 0.8633	val_loss: 0.0956 val_accuracy-SBM: 0.8528	test_loss: 0.0945 test_accuracy-SBM: 0.8545
2025-07-05 06:19:49,701 - INFO - === Epoch 36 ===
2025-07-05 06:20:21,589 - INFO - train: {'epoch': 36, 'time_epoch': 29.92039, 'eta': 1894.68064, 'eta_hours': 0.5263, 'loss': 0.09068735, 'lr': 0.00037974, 'params': 340919, 'time_iter': 0.09559, 'accuracy': 0.86158, 'precision': 0.57113, 'recall': 0.86652, 'f1': 0.68848, 'auc': 0.94006, 'accuracy-SBM': 0.86352}
2025-07-05 06:20:25,173 - INFO - val: {'epoch': 36, 'time_epoch': 3.23764, 'loss': 0.35416231, 'lr': 0, 'params': 340919, 'time_iter': 0.05139, 'accuracy': 0.85179, 'precision': 0.82796, 'recall': 0.20543, 'f1': 0.32919, 'auc': 0.86488, 'accuracy-SBM': 0.59812}
2025-07-05 06:20:30,511 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:20:30,859 - INFO - test: {'epoch': 36, 'time_epoch': 3.27672, 'loss': 0.35391529, 'lr': 0, 'params': 340919, 'time_iter': 0.05201, 'accuracy': 0.85286, 'precision': 0.82901, 'recall': 0.20788, 'f1': 0.33241, 'auc': 0.86379, 'accuracy-SBM': 0.59936}
2025-07-05 06:20:30,874 - INFO - > Epoch 36: took 41.2s (avg 42.8s) | Best so far: epoch 33	train_loss: 0.0908 train_accuracy-SBM: 0.8633	val_loss: 0.0956 val_accuracy-SBM: 0.8528	test_loss: 0.0945 test_accuracy-SBM: 0.8545
2025-07-05 06:20:30,874 - INFO - === Epoch 37 ===
2025-07-05 06:21:02,824 - INFO - train: {'epoch': 37, 'time_epoch': 29.95001, 'eta': 1864.40356, 'eta_hours': 0.51789, 'loss': 0.09061327, 'lr': 0.00037261, 'params': 340919, 'time_iter': 0.09569, 'accuracy': 0.86137, 'precision': 0.57066, 'recall': 0.86677, 'f1': 0.68822, 'auc': 0.94013, 'accuracy-SBM': 0.8635}
2025-07-05 06:21:06,423 - INFO - val: {'epoch': 37, 'time_epoch': 3.24417, 'loss': 0.22063261, 'lr': 0, 'params': 340919, 'time_iter': 0.05149, 'accuracy': 0.88053, 'precision': 0.80788, 'recall': 0.42651, 'f1': 0.55828, 'auc': 0.90147, 'accuracy-SBM': 0.70235}
2025-07-05 06:21:11,588 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:21:11,941 - INFO - test: {'epoch': 37, 'time_epoch': 3.28523, 'loss': 0.22071256, 'lr': 0, 'params': 340919, 'time_iter': 0.05215, 'accuracy': 0.88154, 'precision': 0.80886, 'recall': 0.42923, 'f1': 0.56084, 'auc': 0.90095, 'accuracy-SBM': 0.70377}
2025-07-05 06:21:11,942 - INFO - > Epoch 37: took 41.1s (avg 42.8s) | Best so far: epoch 33	train_loss: 0.0908 train_accuracy-SBM: 0.8633	val_loss: 0.0956 val_accuracy-SBM: 0.8528	test_loss: 0.0945 test_accuracy-SBM: 0.8545
2025-07-05 06:21:11,942 - INFO - === Epoch 38 ===
2025-07-05 06:21:42,206 - INFO - train: {'epoch': 38, 'time_epoch': 29.98037, 'eta': 1834.19074, 'eta_hours': 0.5095, 'loss': 0.09059486, 'lr': 0.00036534, 'params': 340919, 'time_iter': 0.09578, 'accuracy': 0.8622, 'precision': 0.57255, 'recall': 0.86543, 'f1': 0.68916, 'auc': 0.94018, 'accuracy-SBM': 0.86346}
2025-07-05 06:21:45,650 - INFO - val: {'epoch': 38, 'time_epoch': 3.24004, 'loss': 0.12459431, 'lr': 0, 'params': 340919, 'time_iter': 0.05143, 'accuracy': 0.67943, 'precision': 0.35052, 'recall': 0.95076, 'f1': 0.5122, 'auc': 0.91123, 'accuracy-SBM': 0.78591}
2025-07-05 06:21:50,961 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:21:51,334 - INFO - test: {'epoch': 38, 'time_epoch': 3.28242, 'loss': 0.12358473, 'lr': 0, 'params': 340919, 'time_iter': 0.0521, 'accuracy': 0.68173, 'precision': 0.35108, 'recall': 0.95012, 'f1': 0.5127, 'auc': 0.91198, 'accuracy-SBM': 0.78722}
2025-07-05 06:21:51,335 - INFO - > Epoch 38: took 39.4s (avg 42.7s) | Best so far: epoch 33	train_loss: 0.0908 train_accuracy-SBM: 0.8633	val_loss: 0.0956 val_accuracy-SBM: 0.8528	test_loss: 0.0945 test_accuracy-SBM: 0.8545
2025-07-05 06:21:51,335 - INFO - === Epoch 39 ===
2025-07-05 06:22:22,421 - INFO - train: {'epoch': 39, 'time_epoch': 29.95861, 'eta': 1803.9569, 'eta_hours': 0.5011, 'loss': 0.09061974, 'lr': 0.00035794, 'params': 340919, 'time_iter': 0.09571, 'accuracy': 0.86176, 'precision': 0.57158, 'recall': 0.86564, 'f1': 0.68853, 'auc': 0.94005, 'accuracy-SBM': 0.86328}
2025-07-05 06:22:25,997 - INFO - val: {'epoch': 39, 'time_epoch': 3.23671, 'loss': 0.18903554, 'lr': 0, 'params': 340919, 'time_iter': 0.05138, 'accuracy': 0.8858, 'precision': 0.78579, 'recall': 0.48785, 'f1': 0.60197, 'auc': 0.91051, 'accuracy-SBM': 0.72962}
2025-07-05 06:22:31,144 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:22:31,480 - INFO - test: {'epoch': 39, 'time_epoch': 3.27967, 'loss': 0.1890256, 'lr': 0, 'params': 340919, 'time_iter': 0.05206, 'accuracy': 0.88667, 'precision': 0.78744, 'recall': 0.4888, 'f1': 0.60318, 'auc': 0.91064, 'accuracy-SBM': 0.73029}
2025-07-05 06:22:31,481 - INFO - > Epoch 39: took 40.1s (avg 42.6s) | Best so far: epoch 33	train_loss: 0.0908 train_accuracy-SBM: 0.8633	val_loss: 0.0956 val_accuracy-SBM: 0.8528	test_loss: 0.0945 test_accuracy-SBM: 0.8545
2025-07-05 06:22:31,481 - INFO - === Epoch 40 ===
2025-07-05 06:23:02,422 - INFO - train: {'epoch': 40, 'time_epoch': 29.81713, 'eta': 1773.5329, 'eta_hours': 0.49265, 'loss': 0.09049621, 'lr': 0.00035042, 'params': 340919, 'time_iter': 0.09526, 'accuracy': 0.86258, 'precision': 0.57334, 'recall': 0.8657, 'f1': 0.68983, 'auc': 0.94027, 'accuracy-SBM': 0.86381}
2025-07-05 06:23:05,986 - INFO - val: {'epoch': 40, 'time_epoch': 3.23499, 'loss': 0.367804, 'lr': 0, 'params': 340919, 'time_iter': 0.05135, 'accuracy': 0.84707, 'precision': 0.82816, 'recall': 0.17175, 'f1': 0.2845, 'auc': 0.87397, 'accuracy-SBM': 0.58204}
2025-07-05 06:23:11,246 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:23:11,572 - INFO - test: {'epoch': 40, 'time_epoch': 3.27295, 'loss': 0.36714551, 'lr': 0, 'params': 340919, 'time_iter': 0.05195, 'accuracy': 0.84806, 'precision': 0.82938, 'recall': 0.17346, 'f1': 0.28692, 'auc': 0.87318, 'accuracy-SBM': 0.58292}
2025-07-05 06:23:11,573 - INFO - > Epoch 40: took 40.1s (avg 42.6s) | Best so far: epoch 33	train_loss: 0.0908 train_accuracy-SBM: 0.8633	val_loss: 0.0956 val_accuracy-SBM: 0.8528	test_loss: 0.0945 test_accuracy-SBM: 0.8545
2025-07-05 06:23:11,574 - INFO - === Epoch 41 ===
2025-07-05 06:23:43,327 - INFO - train: {'epoch': 41, 'time_epoch': 29.80318, 'eta': 1743.11853, 'eta_hours': 0.4842, 'loss': 0.09053026, 'lr': 0.0003428, 'params': 340919, 'time_iter': 0.09522, 'accuracy': 0.86234, 'precision': 0.57286, 'recall': 0.86528, 'f1': 0.68934, 'auc': 0.94018, 'accuracy-SBM': 0.86349}
2025-07-05 06:23:46,760 - INFO - val: {'epoch': 41, 'time_epoch': 3.22789, 'loss': 0.12982006, 'lr': 0, 'params': 340919, 'time_iter': 0.05124, 'accuracy': 0.73823, 'precision': 0.3893, 'recall': 0.84181, 'f1': 0.53239, 'auc': 0.86402, 'accuracy-SBM': 0.77888}
2025-07-05 06:23:51,992 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:23:52,343 - INFO - test: {'epoch': 41, 'time_epoch': 3.26974, 'loss': 0.12956704, 'lr': 0, 'params': 340919, 'time_iter': 0.0519, 'accuracy': 0.7393, 'precision': 0.38829, 'recall': 0.83321, 'f1': 0.52972, 'auc': 0.8628, 'accuracy-SBM': 0.77621}
2025-07-05 06:23:52,344 - INFO - > Epoch 41: took 40.8s (avg 42.5s) | Best so far: epoch 33	train_loss: 0.0908 train_accuracy-SBM: 0.8633	val_loss: 0.0956 val_accuracy-SBM: 0.8528	test_loss: 0.0945 test_accuracy-SBM: 0.8545
2025-07-05 06:23:52,344 - INFO - === Epoch 42 ===
2025-07-05 06:24:23,233 - INFO - train: {'epoch': 42, 'time_epoch': 29.78117, 'eta': 1712.70342, 'eta_hours': 0.47575, 'loss': 0.09065632, 'lr': 0.00033507, 'params': 340919, 'time_iter': 0.09515, 'accuracy': 0.86201, 'precision': 0.57216, 'recall': 0.86517, 'f1': 0.6888, 'auc': 0.94003, 'accuracy-SBM': 0.86325}
2025-07-05 06:24:26,794 - INFO - val: {'epoch': 42, 'time_epoch': 3.22994, 'loss': 0.463601, 'lr': 0, 'params': 340919, 'time_iter': 0.05127, 'accuracy': 0.84168, 'precision': 0.89762, 'recall': 0.11925, 'f1': 0.21053, 'auc': 0.85553, 'accuracy-SBM': 0.55816}
2025-07-05 06:24:32,094 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:24:32,419 - INFO - test: {'epoch': 42, 'time_epoch': 3.2779, 'loss': 0.46303577, 'lr': 0, 'params': 340919, 'time_iter': 0.05203, 'accuracy': 0.8423, 'precision': 0.89951, 'recall': 0.11834, 'f1': 0.20917, 'auc': 0.85285, 'accuracy-SBM': 0.55776}
2025-07-05 06:24:32,420 - INFO - > Epoch 42: took 40.1s (avg 42.5s) | Best so far: epoch 33	train_loss: 0.0908 train_accuracy-SBM: 0.8633	val_loss: 0.0956 val_accuracy-SBM: 0.8528	test_loss: 0.0945 test_accuracy-SBM: 0.8545
2025-07-05 06:24:32,420 - INFO - === Epoch 43 ===
2025-07-05 06:25:04,112 - INFO - train: {'epoch': 43, 'time_epoch': 29.71579, 'eta': 1682.2339, 'eta_hours': 0.46729, 'loss': 0.09053316, 'lr': 0.00032725, 'params': 340919, 'time_iter': 0.09494, 'accuracy': 0.86227, 'precision': 0.57268, 'recall': 0.86566, 'f1': 0.68933, 'auc': 0.94021, 'accuracy-SBM': 0.8636}
2025-07-05 06:25:07,680 - INFO - val: {'epoch': 43, 'time_epoch': 3.23359, 'loss': 0.26740236, 'lr': 0, 'params': 340919, 'time_iter': 0.05133, 'accuracy': 0.87048, 'precision': 0.8232, 'recall': 0.34171, 'f1': 0.48295, 'auc': 0.89026, 'accuracy-SBM': 0.66296}
2025-07-05 06:25:12,970 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:25:13,307 - INFO - test: {'epoch': 43, 'time_epoch': 3.27309, 'loss': 0.26907695, 'lr': 0, 'params': 340919, 'time_iter': 0.05195, 'accuracy': 0.87172, 'precision': 0.82315, 'recall': 0.34647, 'f1': 0.48768, 'auc': 0.88889, 'accuracy-SBM': 0.66528}
2025-07-05 06:25:13,308 - INFO - > Epoch 43: took 40.9s (avg 42.4s) | Best so far: epoch 33	train_loss: 0.0908 train_accuracy-SBM: 0.8633	val_loss: 0.0956 val_accuracy-SBM: 0.8528	test_loss: 0.0945 test_accuracy-SBM: 0.8545
2025-07-05 06:25:13,308 - INFO - === Epoch 44 ===
2025-07-05 06:25:44,988 - INFO - train: {'epoch': 44, 'time_epoch': 29.75075, 'eta': 1651.84061, 'eta_hours': 0.45884, 'loss': 0.09044421, 'lr': 0.00031935, 'params': 340919, 'time_iter': 0.09505, 'accuracy': 0.86222, 'precision': 0.5725, 'recall': 0.86651, 'f1': 0.68947, 'auc': 0.94031, 'accuracy-SBM': 0.86391}
2025-07-05 06:25:48,570 - INFO - val: {'epoch': 44, 'time_epoch': 3.22908, 'loss': 0.09955957, 'lr': 0, 'params': 340919, 'time_iter': 0.05126, 'accuracy': 0.79394, 'precision': 0.45909, 'recall': 0.92058, 'f1': 0.61266, 'auc': 0.93447, 'accuracy-SBM': 0.84364}
2025-07-05 06:25:53,766 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:25:54,125 - INFO - test: {'epoch': 44, 'time_epoch': 3.27103, 'loss': 0.09843551, 'lr': 0, 'params': 340919, 'time_iter': 0.05192, 'accuracy': 0.79609, 'precision': 0.46067, 'recall': 0.9201, 'f1': 0.61395, 'auc': 0.93528, 'accuracy-SBM': 0.84483}
2025-07-05 06:25:54,126 - INFO - > Epoch 44: took 40.8s (avg 42.4s) | Best so far: epoch 33	train_loss: 0.0908 train_accuracy-SBM: 0.8633	val_loss: 0.0956 val_accuracy-SBM: 0.8528	test_loss: 0.0945 test_accuracy-SBM: 0.8545
2025-07-05 06:25:54,126 - INFO - === Epoch 45 ===
2025-07-05 06:26:25,996 - INFO - train: {'epoch': 45, 'time_epoch': 29.84104, 'eta': 1621.58126, 'eta_hours': 0.45044, 'loss': 0.09049827, 'lr': 0.00031137, 'params': 340919, 'time_iter': 0.09534, 'accuracy': 0.86201, 'precision': 0.57211, 'recall': 0.86596, 'f1': 0.68901, 'auc': 0.94025, 'accuracy-SBM': 0.86356}
2025-07-05 06:26:29,457 - INFO - val: {'epoch': 45, 'time_epoch': 3.2421, 'loss': 0.11048866, 'lr': 0, 'params': 340919, 'time_iter': 0.05146, 'accuracy': 0.73044, 'precision': 0.39195, 'recall': 0.94814, 'f1': 0.55462, 'auc': 0.93031, 'accuracy-SBM': 0.81587}
2025-07-05 06:26:34,727 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:26:35,078 - INFO - test: {'epoch': 45, 'time_epoch': 3.286, 'loss': 0.10925163, 'lr': 0, 'params': 340919, 'time_iter': 0.05216, 'accuracy': 0.73429, 'precision': 0.39423, 'recall': 0.94636, 'f1': 0.55659, 'auc': 0.93105, 'accuracy-SBM': 0.81764}
2025-07-05 06:26:35,080 - INFO - > Epoch 45: took 41.0s (avg 42.4s) | Best so far: epoch 33	train_loss: 0.0908 train_accuracy-SBM: 0.8633	val_loss: 0.0956 val_accuracy-SBM: 0.8528	test_loss: 0.0945 test_accuracy-SBM: 0.8545
2025-07-05 06:26:35,080 - INFO - === Epoch 46 ===
2025-07-05 06:27:05,864 - INFO - train: {'epoch': 46, 'time_epoch': 29.6847, 'eta': 1591.1634, 'eta_hours': 0.44199, 'loss': 0.09035215, 'lr': 0.00030332, 'params': 340919, 'time_iter': 0.09484, 'accuracy': 0.86225, 'precision': 0.57257, 'recall': 0.86646, 'f1': 0.68951, 'auc': 0.94046, 'accuracy-SBM': 0.86391}
2025-07-05 06:27:09,429 - INFO - val: {'epoch': 46, 'time_epoch': 3.22408, 'loss': 0.12211567, 'lr': 0, 'params': 340919, 'time_iter': 0.05118, 'accuracy': 0.88603, 'precision': 0.67195, 'recall': 0.69597, 'f1': 0.68375, 'auc': 0.91987, 'accuracy-SBM': 0.81144}
2025-07-05 06:27:14,666 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:27:15,007 - INFO - test: {'epoch': 46, 'time_epoch': 3.26489, 'loss': 0.12219925, 'lr': 0, 'params': 340919, 'time_iter': 0.05182, 'accuracy': 0.88726, 'precision': 0.67459, 'recall': 0.69597, 'f1': 0.68511, 'auc': 0.92002, 'accuracy-SBM': 0.81208}
2025-07-05 06:27:15,008 - INFO - > Epoch 46: took 39.9s (avg 42.3s) | Best so far: epoch 33	train_loss: 0.0908 train_accuracy-SBM: 0.8633	val_loss: 0.0956 val_accuracy-SBM: 0.8528	test_loss: 0.0945 test_accuracy-SBM: 0.8545
2025-07-05 06:27:15,008 - INFO - === Epoch 47 ===
2025-07-05 06:27:45,005 - INFO - train: {'epoch': 47, 'time_epoch': 29.74244, 'eta': 1560.83864, 'eta_hours': 0.43357, 'loss': 0.09034469, 'lr': 0.00029522, 'params': 340919, 'time_iter': 0.09502, 'accuracy': 0.86295, 'precision': 0.57416, 'recall': 0.86563, 'f1': 0.69039, 'auc': 0.94043, 'accuracy-SBM': 0.86401}
2025-07-05 06:27:48,431 - INFO - val: {'epoch': 47, 'time_epoch': 3.22327, 'loss': 0.09644492, 'lr': 0, 'params': 340919, 'time_iter': 0.05116, 'accuracy': 0.80931, 'precision': 0.47989, 'recall': 0.92125, 'f1': 0.63106, 'auc': 0.93969, 'accuracy-SBM': 0.85324}
2025-07-05 06:27:53,706 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:27:54,051 - INFO - test: {'epoch': 47, 'time_epoch': 3.26449, 'loss': 0.09517869, 'lr': 0, 'params': 340919, 'time_iter': 0.05182, 'accuracy': 0.81134, 'precision': 0.48154, 'recall': 0.92087, 'f1': 0.63239, 'auc': 0.94061, 'accuracy-SBM': 0.85439}
2025-07-05 06:27:54,052 - INFO - > Epoch 47: took 39.0s (avg 42.3s) | Best so far: epoch 47	train_loss: 0.0903 train_accuracy-SBM: 0.8640	val_loss: 0.0964 val_accuracy-SBM: 0.8532	test_loss: 0.0952 test_accuracy-SBM: 0.8544
2025-07-05 06:27:54,052 - INFO - === Epoch 48 ===
2025-07-05 06:28:24,868 - INFO - train: {'epoch': 48, 'time_epoch': 29.69262, 'eta': 1530.4858, 'eta_hours': 0.42513, 'loss': 0.0904898, 'lr': 0.00028707, 'params': 340919, 'time_iter': 0.09486, 'accuracy': 0.86256, 'precision': 0.57333, 'recall': 0.86552, 'f1': 0.68975, 'auc': 0.94023, 'accuracy-SBM': 0.86372}
2025-07-05 06:28:28,297 - INFO - val: {'epoch': 48, 'time_epoch': 3.22544, 'loss': 0.13764742, 'lr': 0, 'params': 340919, 'time_iter': 0.0512, 'accuracy': 0.61314, 'precision': 0.31133, 'recall': 0.97799, 'f1': 0.4723, 'auc': 0.92552, 'accuracy-SBM': 0.75632}
2025-07-05 06:28:33,747 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:28:33,951 - INFO - test: {'epoch': 48, 'time_epoch': 3.26904, 'loss': 0.13604124, 'lr': 0, 'params': 340919, 'time_iter': 0.05189, 'accuracy': 0.61716, 'precision': 0.31248, 'recall': 0.97697, 'f1': 0.47351, 'auc': 0.92614, 'accuracy-SBM': 0.75858}
2025-07-05 06:28:33,952 - INFO - > Epoch 48: took 39.9s (avg 42.2s) | Best so far: epoch 47	train_loss: 0.0903 train_accuracy-SBM: 0.8640	val_loss: 0.0964 val_accuracy-SBM: 0.8532	test_loss: 0.0952 test_accuracy-SBM: 0.8544
2025-07-05 06:28:33,952 - INFO - === Epoch 49 ===
2025-07-05 06:29:05,631 - INFO - train: {'epoch': 49, 'time_epoch': 29.71085, 'eta': 1500.17759, 'eta_hours': 0.41672, 'loss': 0.09031303, 'lr': 0.00027887, 'params': 340919, 'time_iter': 0.09492, 'accuracy': 0.86287, 'precision': 0.57389, 'recall': 0.86658, 'f1': 0.6905, 'auc': 0.94045, 'accuracy-SBM': 0.86433}
2025-07-05 06:29:09,061 - INFO - val: {'epoch': 49, 'time_epoch': 3.22662, 'loss': 0.12463819, 'lr': 0, 'params': 340919, 'time_iter': 0.05122, 'accuracy': 0.67794, 'precision': 0.34969, 'recall': 0.95312, 'f1': 0.51166, 'auc': 0.91402, 'accuracy-SBM': 0.78593}
2025-07-05 06:29:14,815 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:29:15,170 - INFO - test: {'epoch': 49, 'time_epoch': 3.26684, 'loss': 0.12354136, 'lr': 0, 'params': 340919, 'time_iter': 0.05185, 'accuracy': 0.68066, 'precision': 0.3506, 'recall': 0.95298, 'f1': 0.51261, 'auc': 0.91516, 'accuracy-SBM': 0.78769}
2025-07-05 06:29:15,171 - INFO - > Epoch 49: took 41.2s (avg 42.2s) | Best so far: epoch 47	train_loss: 0.0903 train_accuracy-SBM: 0.8640	val_loss: 0.0964 val_accuracy-SBM: 0.8532	test_loss: 0.0952 test_accuracy-SBM: 0.8544
2025-07-05 06:29:15,171 - INFO - === Epoch 50 ===
2025-07-05 06:29:45,148 - INFO - train: {'epoch': 50, 'time_epoch': 29.69604, 'eta': 1469.87859, 'eta_hours': 0.4083, 'loss': 0.09026928, 'lr': 0.00027064, 'params': 340919, 'time_iter': 0.09488, 'accuracy': 0.8623, 'precision': 0.57262, 'recall': 0.86692, 'f1': 0.68969, 'auc': 0.94052, 'accuracy-SBM': 0.86411}
2025-07-05 06:29:48,703 - INFO - val: {'epoch': 50, 'time_epoch': 3.22448, 'loss': 0.31203478, 'lr': 0, 'params': 340919, 'time_iter': 0.05118, 'accuracy': 0.86111, 'precision': 0.92563, 'recall': 0.23423, 'f1': 0.37386, 'auc': 0.90509, 'accuracy-SBM': 0.61509}
2025-07-05 06:29:54,153 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:29:54,481 - INFO - test: {'epoch': 50, 'time_epoch': 3.26634, 'loss': 0.31486159, 'lr': 0, 'params': 340919, 'time_iter': 0.05185, 'accuracy': 0.86177, 'precision': 0.92362, 'recall': 0.23504, 'f1': 0.37472, 'auc': 0.90311, 'accuracy-SBM': 0.61544}
2025-07-05 06:29:54,483 - INFO - > Epoch 50: took 39.3s (avg 42.1s) | Best so far: epoch 47	train_loss: 0.0903 train_accuracy-SBM: 0.8640	val_loss: 0.0964 val_accuracy-SBM: 0.8532	test_loss: 0.0952 test_accuracy-SBM: 0.8544
2025-07-05 06:29:54,483 - INFO - === Epoch 51 ===
2025-07-05 06:30:26,258 - INFO - train: {'epoch': 51, 'time_epoch': 29.7993, 'eta': 1439.69809, 'eta_hours': 0.39992, 'loss': 0.0902535, 'lr': 0.0002624, 'params': 340919, 'time_iter': 0.09521, 'accuracy': 0.86285, 'precision': 0.57388, 'recall': 0.86615, 'f1': 0.69035, 'auc': 0.94057, 'accuracy-SBM': 0.86414}
2025-07-05 06:30:29,828 - INFO - val: {'epoch': 51, 'time_epoch': 3.22398, 'loss': 0.09911649, 'lr': 0, 'params': 340919, 'time_iter': 0.05117, 'accuracy': 0.88341, 'precision': 0.63701, 'recall': 0.79364, 'f1': 0.70675, 'auc': 0.93336, 'accuracy-SBM': 0.84818}
2025-07-05 06:30:35,049 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:30:35,394 - INFO - test: {'epoch': 51, 'time_epoch': 3.26963, 'loss': 0.0986667, 'lr': 0, 'params': 340919, 'time_iter': 0.0519, 'accuracy': 0.88526, 'precision': 0.64092, 'recall': 0.79331, 'f1': 0.70902, 'auc': 0.93376, 'accuracy-SBM': 0.84912}
2025-07-05 06:30:35,395 - INFO - > Epoch 51: took 40.9s (avg 42.1s) | Best so far: epoch 47	train_loss: 0.0903 train_accuracy-SBM: 0.8640	val_loss: 0.0964 val_accuracy-SBM: 0.8532	test_loss: 0.0952 test_accuracy-SBM: 0.8544
2025-07-05 06:30:35,395 - INFO - === Epoch 52 ===
2025-07-05 06:31:07,029 - INFO - train: {'epoch': 52, 'time_epoch': 29.66212, 'eta': 1409.41033, 'eta_hours': 0.3915, 'loss': 0.09016807, 'lr': 0.00025413, 'params': 340919, 'time_iter': 0.09477, 'accuracy': 0.86275, 'precision': 0.57356, 'recall': 0.86735, 'f1': 0.6905, 'auc': 0.94065, 'accuracy-SBM': 0.86456}
2025-07-05 06:31:10,823 - INFO - val: {'epoch': 52, 'time_epoch': 3.22445, 'loss': 0.09504509, 'lr': 0, 'params': 340919, 'time_iter': 0.05118, 'accuracy': 0.88695, 'precision': 0.64304, 'recall': 0.81227, 'f1': 0.71781, 'auc': 0.93965, 'accuracy-SBM': 0.85764}
2025-07-05 06:31:16,745 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:31:17,091 - INFO - test: {'epoch': 52, 'time_epoch': 3.26506, 'loss': 0.09422301, 'lr': 0, 'params': 340919, 'time_iter': 0.05183, 'accuracy': 0.8891, 'precision': 0.64763, 'recall': 0.81303, 'f1': 0.72097, 'auc': 0.9404, 'accuracy-SBM': 0.8592}
2025-07-05 06:31:17,092 - INFO - > Epoch 52: took 41.7s (avg 42.1s) | Best so far: epoch 52	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0950 val_accuracy-SBM: 0.8576	test_loss: 0.0942 test_accuracy-SBM: 0.8592
2025-07-05 06:31:17,092 - INFO - === Epoch 53 ===
2025-07-05 06:31:47,886 - INFO - train: {'epoch': 53, 'time_epoch': 29.68927, 'eta': 1379.16886, 'eta_hours': 0.3831, 'loss': 0.0902786, 'lr': 0.00024587, 'params': 340919, 'time_iter': 0.09485, 'accuracy': 0.86225, 'precision': 0.57251, 'recall': 0.86698, 'f1': 0.68963, 'auc': 0.94048, 'accuracy-SBM': 0.86411}
2025-07-05 06:31:51,451 - INFO - val: {'epoch': 53, 'time_epoch': 3.22796, 'loss': 0.25924232, 'lr': 0, 'params': 340919, 'time_iter': 0.05124, 'accuracy': 0.87261, 'precision': 0.82431, 'recall': 0.35631, 'f1': 0.49756, 'auc': 0.88969, 'accuracy-SBM': 0.66999}
2025-07-05 06:31:56,562 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:31:56,895 - INFO - test: {'epoch': 53, 'time_epoch': 3.26934, 'loss': 0.26382264, 'lr': 0, 'params': 340919, 'time_iter': 0.05189, 'accuracy': 0.87315, 'precision': 0.82341, 'recall': 0.35665, 'f1': 0.49771, 'auc': 0.88656, 'accuracy-SBM': 0.67014}
2025-07-05 06:31:56,896 - INFO - > Epoch 53: took 39.8s (avg 42.1s) | Best so far: epoch 52	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0950 val_accuracy-SBM: 0.8576	test_loss: 0.0942 test_accuracy-SBM: 0.8592
2025-07-05 06:31:56,896 - INFO - === Epoch 54 ===
2025-07-05 06:32:28,656 - INFO - train: {'epoch': 54, 'time_epoch': 29.76876, 'eta': 1349.01251, 'eta_hours': 0.37473, 'loss': 0.09026175, 'lr': 0.0002376, 'params': 340919, 'time_iter': 0.09511, 'accuracy': 0.86301, 'precision': 0.57421, 'recall': 0.86636, 'f1': 0.69066, 'auc': 0.94054, 'accuracy-SBM': 0.86433}
2025-07-05 06:32:32,095 - INFO - val: {'epoch': 54, 'time_epoch': 3.23484, 'loss': 0.12721804, 'lr': 0, 'params': 340919, 'time_iter': 0.05135, 'accuracy': 0.67959, 'precision': 0.34913, 'recall': 0.93718, 'f1': 0.50873, 'auc': 0.89867, 'accuracy-SBM': 0.78068}
2025-07-05 06:32:37,371 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:32:37,727 - INFO - test: {'epoch': 54, 'time_epoch': 3.27437, 'loss': 0.12660851, 'lr': 0, 'params': 340919, 'time_iter': 0.05197, 'accuracy': 0.68272, 'precision': 0.34983, 'recall': 0.93232, 'f1': 0.50876, 'auc': 0.89697, 'accuracy-SBM': 0.78083}
2025-07-05 06:32:37,728 - INFO - > Epoch 54: took 40.8s (avg 42.0s) | Best so far: epoch 52	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0950 val_accuracy-SBM: 0.8576	test_loss: 0.0942 test_accuracy-SBM: 0.8592
2025-07-05 06:32:37,729 - INFO - === Epoch 55 ===
2025-07-05 06:33:09,538 - INFO - train: {'epoch': 55, 'time_epoch': 29.82299, 'eta': 1318.91262, 'eta_hours': 0.36636, 'loss': 0.09016862, 'lr': 0.00022936, 'params': 340919, 'time_iter': 0.09528, 'accuracy': 0.86218, 'precision': 0.57233, 'recall': 0.86735, 'f1': 0.68962, 'auc': 0.94069, 'accuracy-SBM': 0.86421}
2025-07-05 06:33:13,119 - INFO - val: {'epoch': 55, 'time_epoch': 3.23182, 'loss': 0.09441533, 'lr': 0, 'params': 340919, 'time_iter': 0.0513, 'accuracy': 0.87419, 'precision': 0.60522, 'recall': 0.83197, 'f1': 0.70071, 'auc': 0.93647, 'accuracy-SBM': 0.85762}
2025-07-05 06:33:18,264 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:33:18,609 - INFO - test: {'epoch': 55, 'time_epoch': 3.27149, 'loss': 0.09354471, 'lr': 0, 'params': 340919, 'time_iter': 0.05193, 'accuracy': 0.87665, 'precision': 0.60997, 'recall': 0.83206, 'f1': 0.70391, 'auc': 0.9372, 'accuracy-SBM': 0.85913}
2025-07-05 06:33:18,637 - INFO - > Epoch 55: took 40.9s (avg 42.0s) | Best so far: epoch 52	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0950 val_accuracy-SBM: 0.8576	test_loss: 0.0942 test_accuracy-SBM: 0.8592
2025-07-05 06:33:18,637 - INFO - === Epoch 56 ===
2025-07-05 06:33:50,353 - INFO - train: {'epoch': 56, 'time_epoch': 29.73787, 'eta': 1288.75824, 'eta_hours': 0.35799, 'loss': 0.09016147, 'lr': 0.00022113, 'params': 340919, 'time_iter': 0.09501, 'accuracy': 0.86234, 'precision': 0.5726, 'recall': 0.86802, 'f1': 0.69002, 'auc': 0.94068, 'accuracy-SBM': 0.86457}
2025-07-05 06:33:53,938 - INFO - val: {'epoch': 56, 'time_epoch': 3.23352, 'loss': 0.09046487, 'lr': 0, 'params': 340919, 'time_iter': 0.05133, 'accuracy': 0.86094, 'precision': 0.57025, 'recall': 0.8703, 'f1': 0.68903, 'auc': 0.94084, 'accuracy-SBM': 0.86461}
2025-07-05 06:33:59,130 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:33:59,477 - INFO - test: {'epoch': 56, 'time_epoch': 3.27334, 'loss': 0.08934929, 'lr': 0, 'params': 340919, 'time_iter': 0.05196, 'accuracy': 0.86344, 'precision': 0.57431, 'recall': 0.8697, 'f1': 0.69179, 'auc': 0.94163, 'accuracy-SBM': 0.8659}
2025-07-05 06:33:59,478 - INFO - > Epoch 56: took 40.8s (avg 42.0s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:33:59,478 - INFO - === Epoch 57 ===
2025-07-05 06:34:31,113 - INFO - train: {'epoch': 57, 'time_epoch': 29.65933, 'eta': 1258.56134, 'eta_hours': 0.3496, 'loss': 0.09013567, 'lr': 0.00021293, 'params': 340919, 'time_iter': 0.09476, 'accuracy': 0.86232, 'precision': 0.57263, 'recall': 0.86736, 'f1': 0.68983, 'auc': 0.94073, 'accuracy-SBM': 0.8643}
2025-07-05 06:34:34,663 - INFO - val: {'epoch': 57, 'time_epoch': 3.22251, 'loss': 0.44893638, 'lr': 0, 'params': 340919, 'time_iter': 0.05115, 'accuracy': 0.84379, 'precision': 0.90834, 'recall': 0.13078, 'f1': 0.22864, 'auc': 0.86279, 'accuracy-SBM': 0.56397}
2025-07-05 06:34:41,097 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:34:41,424 - INFO - test: {'epoch': 57, 'time_epoch': 3.26351, 'loss': 0.45179492, 'lr': 0, 'params': 340919, 'time_iter': 0.0518, 'accuracy': 0.84441, 'precision': 0.91142, 'recall': 0.12966, 'f1': 0.22702, 'auc': 0.85979, 'accuracy-SBM': 0.56348}
2025-07-05 06:34:41,425 - INFO - > Epoch 57: took 41.9s (avg 42.0s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:34:41,425 - INFO - === Epoch 58 ===
2025-07-05 06:35:13,157 - INFO - train: {'epoch': 58, 'time_epoch': 29.75727, 'eta': 1228.45072, 'eta_hours': 0.34124, 'loss': 0.09011751, 'lr': 0.00020478, 'params': 340919, 'time_iter': 0.09507, 'accuracy': 0.86261, 'precision': 0.5732, 'recall': 0.86788, 'f1': 0.69041, 'auc': 0.94072, 'accuracy-SBM': 0.86468}
2025-07-05 06:35:16,734 - INFO - val: {'epoch': 58, 'time_epoch': 3.23128, 'loss': 0.12631834, 'lr': 0, 'params': 340919, 'time_iter': 0.05129, 'accuracy': 0.90004, 'precision': 0.74458, 'recall': 0.66267, 'f1': 0.70124, 'auc': 0.93134, 'accuracy-SBM': 0.80689}
2025-07-05 06:35:22,445 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:35:22,786 - INFO - test: {'epoch': 58, 'time_epoch': 3.27214, 'loss': 0.12558809, 'lr': 0, 'params': 340919, 'time_iter': 0.05194, 'accuracy': 0.90124, 'precision': 0.74792, 'recall': 0.66301, 'f1': 0.70291, 'auc': 0.93226, 'accuracy-SBM': 0.8076}
2025-07-05 06:35:22,787 - INFO - > Epoch 58: took 41.4s (avg 42.0s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:35:22,787 - INFO - === Epoch 59 ===
2025-07-05 06:35:53,692 - INFO - train: {'epoch': 59, 'time_epoch': 29.77635, 'eta': 1198.3646, 'eta_hours': 0.33288, 'loss': 0.09008881, 'lr': 0.00019668, 'params': 340919, 'time_iter': 0.09513, 'accuracy': 0.86209, 'precision': 0.57214, 'recall': 0.86743, 'f1': 0.6895, 'auc': 0.94077, 'accuracy-SBM': 0.86419}
2025-07-05 06:35:57,128 - INFO - val: {'epoch': 59, 'time_epoch': 3.2332, 'loss': 0.10329926, 'lr': 0, 'params': 340919, 'time_iter': 0.05132, 'accuracy': 0.77312, 'precision': 0.4347, 'recall': 0.93745, 'f1': 0.59397, 'auc': 0.93626, 'accuracy-SBM': 0.83761}
2025-07-05 06:36:02,846 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:36:03,200 - INFO - test: {'epoch': 59, 'time_epoch': 3.27627, 'loss': 0.10210759, 'lr': 0, 'params': 340919, 'time_iter': 0.052, 'accuracy': 0.77617, 'precision': 0.43694, 'recall': 0.93604, 'f1': 0.59578, 'auc': 0.93698, 'accuracy-SBM': 0.83901}
2025-07-05 06:36:03,202 - INFO - > Epoch 59: took 40.4s (avg 42.0s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:36:03,202 - INFO - === Epoch 60 ===
2025-07-05 06:36:34,992 - INFO - train: {'epoch': 60, 'time_epoch': 29.80587, 'eta': 1168.30751, 'eta_hours': 0.32453, 'loss': 0.08996136, 'lr': 0.00018863, 'params': 340919, 'time_iter': 0.09523, 'accuracy': 0.86297, 'precision': 0.57405, 'recall': 0.86703, 'f1': 0.69076, 'auc': 0.94094, 'accuracy-SBM': 0.86456}
2025-07-05 06:36:38,588 - INFO - val: {'epoch': 60, 'time_epoch': 3.23407, 'loss': 0.0922858, 'lr': 0, 'params': 340919, 'time_iter': 0.05133, 'accuracy': 0.83216, 'precision': 0.51483, 'recall': 0.90071, 'f1': 0.65517, 'auc': 0.93961, 'accuracy-SBM': 0.85907}
2025-07-05 06:36:43,696 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:36:44,045 - INFO - test: {'epoch': 60, 'time_epoch': 3.27663, 'loss': 0.09120758, 'lr': 0, 'params': 340919, 'time_iter': 0.05201, 'accuracy': 0.83474, 'precision': 0.51789, 'recall': 0.90045, 'f1': 0.65758, 'auc': 0.94039, 'accuracy-SBM': 0.86057}
2025-07-05 06:36:44,047 - INFO - > Epoch 60: took 40.8s (avg 41.9s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:36:44,047 - INFO - === Epoch 61 ===
2025-07-05 06:37:14,096 - INFO - train: {'epoch': 61, 'time_epoch': 29.76734, 'eta': 1138.23491, 'eta_hours': 0.31618, 'loss': 0.09003218, 'lr': 0.00018065, 'params': 340919, 'time_iter': 0.0951, 'accuracy': 0.86238, 'precision': 0.57276, 'recall': 0.86721, 'f1': 0.68988, 'auc': 0.94084, 'accuracy-SBM': 0.86427}
2025-07-05 06:37:17,683 - INFO - val: {'epoch': 61, 'time_epoch': 3.23525, 'loss': 0.09203714, 'lr': 0, 'params': 340919, 'time_iter': 0.05135, 'accuracy': 0.8437, 'precision': 0.53505, 'recall': 0.89333, 'f1': 0.66925, 'auc': 0.94091, 'accuracy-SBM': 0.86317}
2025-07-05 06:37:22,979 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:37:23,333 - INFO - test: {'epoch': 61, 'time_epoch': 3.27507, 'loss': 0.09074329, 'lr': 0, 'params': 340919, 'time_iter': 0.05199, 'accuracy': 0.84672, 'precision': 0.53929, 'recall': 0.8935, 'f1': 0.67261, 'auc': 0.94192, 'accuracy-SBM': 0.86511}
2025-07-05 06:37:23,334 - INFO - > Epoch 61: took 39.3s (avg 41.9s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:37:23,335 - INFO - === Epoch 62 ===
2025-07-05 06:37:54,456 - INFO - train: {'epoch': 62, 'time_epoch': 29.97604, 'eta': 1108.29457, 'eta_hours': 0.30786, 'loss': 0.08996022, 'lr': 0.00017275, 'params': 340919, 'time_iter': 0.09577, 'accuracy': 0.86266, 'precision': 0.57328, 'recall': 0.86814, 'f1': 0.69055, 'auc': 0.94098, 'accuracy-SBM': 0.86481}
2025-07-05 06:37:58,026 - INFO - val: {'epoch': 62, 'time_epoch': 3.23075, 'loss': 0.16050608, 'lr': 0, 'params': 340919, 'time_iter': 0.05128, 'accuracy': 0.8943, 'precision': 0.77652, 'recall': 0.56572, 'f1': 0.65457, 'auc': 0.9195, 'accuracy-SBM': 0.76535}
2025-07-05 06:38:04,061 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:38:04,397 - INFO - test: {'epoch': 62, 'time_epoch': 3.27271, 'loss': 0.16138807, 'lr': 0, 'params': 340919, 'time_iter': 0.05195, 'accuracy': 0.89524, 'precision': 0.78125, 'recall': 0.5632, 'f1': 0.65454, 'auc': 0.9198, 'accuracy-SBM': 0.76473}
2025-07-05 06:38:04,399 - INFO - > Epoch 62: took 41.1s (avg 41.9s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:38:04,399 - INFO - === Epoch 63 ===
2025-07-05 06:38:36,134 - INFO - train: {'epoch': 63, 'time_epoch': 29.77395, 'eta': 1078.23943, 'eta_hours': 0.29951, 'loss': 0.08993402, 'lr': 0.00016493, 'params': 340919, 'time_iter': 0.09512, 'accuracy': 0.86237, 'precision': 0.57266, 'recall': 0.86815, 'f1': 0.6901, 'auc': 0.94097, 'accuracy-SBM': 0.86464}
2025-07-05 06:38:39,698 - INFO - val: {'epoch': 63, 'time_epoch': 3.2297, 'loss': 0.25315278, 'lr': 0, 'params': 340919, 'time_iter': 0.05127, 'accuracy': 0.87556, 'precision': 0.84542, 'recall': 0.36348, 'f1': 0.50839, 'auc': 0.90234, 'accuracy-SBM': 0.67459}
2025-07-05 06:38:44,927 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:38:45,259 - INFO - test: {'epoch': 63, 'time_epoch': 3.27523, 'loss': 0.25683028, 'lr': 0, 'params': 340919, 'time_iter': 0.05199, 'accuracy': 0.87593, 'precision': 0.84545, 'recall': 0.36212, 'f1': 0.50706, 'auc': 0.90044, 'accuracy-SBM': 0.67398}
2025-07-05 06:38:45,261 - INFO - > Epoch 63: took 40.9s (avg 41.9s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:38:45,261 - INFO - === Epoch 64 ===
2025-07-05 06:39:17,033 - INFO - train: {'epoch': 64, 'time_epoch': 29.78408, 'eta': 1048.19841, 'eta_hours': 0.29117, 'loss': 0.08993391, 'lr': 0.0001572, 'params': 340919, 'time_iter': 0.09516, 'accuracy': 0.86228, 'precision': 0.57248, 'recall': 0.86812, 'f1': 0.68996, 'auc': 0.94097, 'accuracy-SBM': 0.86458}
2025-07-05 06:39:20,612 - INFO - val: {'epoch': 64, 'time_epoch': 3.23654, 'loss': 0.0999367, 'lr': 0, 'params': 340919, 'time_iter': 0.05137, 'accuracy': 0.88321, 'precision': 0.63615, 'recall': 0.7949, 'f1': 0.70672, 'auc': 0.93393, 'accuracy-SBM': 0.84855}
2025-07-05 06:39:25,965 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:39:26,311 - INFO - test: {'epoch': 64, 'time_epoch': 3.27642, 'loss': 0.09930456, 'lr': 0, 'params': 340919, 'time_iter': 0.05201, 'accuracy': 0.88526, 'precision': 0.64082, 'recall': 0.79376, 'f1': 0.70914, 'auc': 0.93468, 'accuracy-SBM': 0.84929}
2025-07-05 06:39:26,313 - INFO - > Epoch 64: took 41.1s (avg 41.9s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:39:26,313 - INFO - === Epoch 65 ===
2025-07-05 06:39:58,079 - INFO - train: {'epoch': 65, 'time_epoch': 29.7907, 'eta': 1018.16857, 'eta_hours': 0.28282, 'loss': 0.08998828, 'lr': 0.00014958, 'params': 340919, 'time_iter': 0.09518, 'accuracy': 0.86262, 'precision': 0.57327, 'recall': 0.86743, 'f1': 0.69032, 'auc': 0.94089, 'accuracy-SBM': 0.86451}
2025-07-05 06:40:01,669 - INFO - val: {'epoch': 65, 'time_epoch': 3.24093, 'loss': 0.09064737, 'lr': 0, 'params': 340919, 'time_iter': 0.05144, 'accuracy': 0.86197, 'precision': 0.57266, 'recall': 0.86806, 'f1': 0.69007, 'auc': 0.94062, 'accuracy-SBM': 0.86436}
2025-07-05 06:40:10,452 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:40:10,797 - INFO - test: {'epoch': 65, 'time_epoch': 3.27927, 'loss': 0.08952099, 'lr': 0, 'params': 340919, 'time_iter': 0.05205, 'accuracy': 0.86486, 'precision': 0.57739, 'recall': 0.86965, 'f1': 0.69401, 'auc': 0.9415, 'accuracy-SBM': 0.86675}
2025-07-05 06:40:10,798 - INFO - > Epoch 65: took 44.5s (avg 41.9s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:40:10,798 - INFO - === Epoch 66 ===
2025-07-05 06:40:42,504 - INFO - train: {'epoch': 66, 'time_epoch': 29.73115, 'eta': 988.11655, 'eta_hours': 0.27448, 'loss': 0.08987607, 'lr': 0.00014206, 'params': 340919, 'time_iter': 0.09499, 'accuracy': 0.86308, 'precision': 0.57426, 'recall': 0.8673, 'f1': 0.691, 'auc': 0.94107, 'accuracy-SBM': 0.86474}
2025-07-05 06:40:46,062 - INFO - val: {'epoch': 66, 'time_epoch': 3.22482, 'loss': 0.22053801, 'lr': 0, 'params': 340919, 'time_iter': 0.05119, 'accuracy': 0.88254, 'precision': 0.83096, 'recall': 0.42237, 'f1': 0.56006, 'auc': 0.91177, 'accuracy-SBM': 0.70194}
2025-07-05 06:40:51,526 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:40:51,861 - INFO - test: {'epoch': 66, 'time_epoch': 3.26737, 'loss': 0.22251764, 'lr': 0, 'params': 340919, 'time_iter': 0.05186, 'accuracy': 0.88284, 'precision': 0.83328, 'recall': 0.41896, 'f1': 0.55758, 'auc': 0.91133, 'accuracy-SBM': 0.70051}
2025-07-05 06:40:51,863 - INFO - > Epoch 66: took 41.1s (avg 41.9s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:40:51,863 - INFO - === Epoch 67 ===
2025-07-05 06:41:23,589 - INFO - train: {'epoch': 67, 'time_epoch': 29.74373, 'eta': 958.07989, 'eta_hours': 0.26613, 'loss': 0.08986166, 'lr': 0.00013466, 'params': 340919, 'time_iter': 0.09503, 'accuracy': 0.86258, 'precision': 0.57315, 'recall': 0.86771, 'f1': 0.69032, 'auc': 0.94105, 'accuracy-SBM': 0.86459}
2025-07-05 06:41:27,164 - INFO - val: {'epoch': 67, 'time_epoch': 3.23221, 'loss': 0.13272138, 'lr': 0, 'params': 340919, 'time_iter': 0.0513, 'accuracy': 0.88518, 'precision': 0.67581, 'recall': 0.67539, 'f1': 0.6756, 'auc': 0.91395, 'accuracy-SBM': 0.80285}
2025-07-05 06:41:32,655 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:41:32,996 - INFO - test: {'epoch': 67, 'time_epoch': 3.27758, 'loss': 0.13273712, 'lr': 0, 'params': 340919, 'time_iter': 0.05203, 'accuracy': 0.88656, 'precision': 0.67905, 'recall': 0.67554, 'f1': 0.67729, 'auc': 0.91435, 'accuracy-SBM': 0.80362}
2025-07-05 06:41:32,997 - INFO - > Epoch 67: took 41.1s (avg 41.9s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:41:32,997 - INFO - === Epoch 68 ===
2025-07-05 06:42:03,887 - INFO - train: {'epoch': 68, 'time_epoch': 29.77399, 'eta': 928.06531, 'eta_hours': 0.2578, 'loss': 0.08987938, 'lr': 0.00012739, 'params': 340919, 'time_iter': 0.09512, 'accuracy': 0.86212, 'precision': 0.57213, 'recall': 0.86823, 'f1': 0.68974, 'auc': 0.94102, 'accuracy-SBM': 0.86452}
2025-07-05 06:42:07,322 - INFO - val: {'epoch': 68, 'time_epoch': 3.23236, 'loss': 0.11069524, 'lr': 0, 'params': 340919, 'time_iter': 0.05131, 'accuracy': 0.73878, 'precision': 0.39994, 'recall': 0.9506, 'f1': 0.56301, 'auc': 0.93531, 'accuracy-SBM': 0.82191}
2025-07-05 06:42:15,411 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:42:15,767 - INFO - test: {'epoch': 68, 'time_epoch': 3.27165, 'loss': 0.10942079, 'lr': 0, 'params': 340919, 'time_iter': 0.05193, 'accuracy': 0.74221, 'precision': 0.40198, 'recall': 0.94909, 'f1': 0.56476, 'auc': 0.93607, 'accuracy-SBM': 0.82353}
2025-07-05 06:42:15,769 - INFO - > Epoch 68: took 42.8s (avg 41.9s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:42:15,769 - INFO - === Epoch 69 ===
2025-07-05 06:42:47,683 - INFO - train: {'epoch': 69, 'time_epoch': 29.93167, 'eta': 898.12518, 'eta_hours': 0.24948, 'loss': 0.08986093, 'lr': 0.00012026, 'params': 340919, 'time_iter': 0.09563, 'accuracy': 0.86309, 'precision': 0.57432, 'recall': 0.86704, 'f1': 0.69096, 'auc': 0.94107, 'accuracy-SBM': 0.86464}
2025-07-05 06:42:51,249 - INFO - val: {'epoch': 69, 'time_epoch': 3.22998, 'loss': 0.23089862, 'lr': 0, 'params': 340919, 'time_iter': 0.05127, 'accuracy': 0.88138, 'precision': 0.8152, 'recall': 0.42663, 'f1': 0.56013, 'auc': 0.90322, 'accuracy-SBM': 0.70291}
2025-07-05 06:42:56,516 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:42:56,848 - INFO - test: {'epoch': 69, 'time_epoch': 3.26948, 'loss': 0.2326864, 'lr': 0, 'params': 340919, 'time_iter': 0.0519, 'accuracy': 0.88188, 'precision': 0.81717, 'recall': 0.4247, 'f1': 0.55892, 'auc': 0.90265, 'accuracy-SBM': 0.70219}
2025-07-05 06:42:56,849 - INFO - > Epoch 69: took 41.1s (avg 41.9s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:42:56,849 - INFO - === Epoch 70 ===
2025-07-05 06:43:28,471 - INFO - train: {'epoch': 70, 'time_epoch': 29.65747, 'eta': 868.07329, 'eta_hours': 0.24113, 'loss': 0.0898407, 'lr': 0.00011326, 'params': 340919, 'time_iter': 0.09475, 'accuracy': 0.86303, 'precision': 0.57416, 'recall': 0.8672, 'f1': 0.69089, 'auc': 0.94113, 'accuracy-SBM': 0.86466}
2025-07-05 06:43:32,033 - INFO - val: {'epoch': 70, 'time_epoch': 3.22031, 'loss': 0.09683541, 'lr': 0, 'params': 340919, 'time_iter': 0.05112, 'accuracy': 0.88946, 'precision': 0.65478, 'recall': 0.79445, 'f1': 0.71788, 'auc': 0.93792, 'accuracy-SBM': 0.85218}
2025-07-05 06:43:37,554 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:43:37,895 - INFO - test: {'epoch': 70, 'time_epoch': 3.26144, 'loss': 0.09604271, 'lr': 0, 'params': 340919, 'time_iter': 0.05177, 'accuracy': 0.89083, 'precision': 0.65766, 'recall': 0.79357, 'f1': 0.71925, 'auc': 0.93874, 'accuracy-SBM': 0.8526}
2025-07-05 06:43:37,896 - INFO - > Epoch 70: took 41.0s (avg 41.9s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:43:37,896 - INFO - === Epoch 71 ===
2025-07-05 06:44:08,663 - INFO - train: {'epoch': 71, 'time_epoch': 29.65715, 'eta': 838.03224, 'eta_hours': 0.23279, 'loss': 0.0897699, 'lr': 0.00010642, 'params': 340919, 'time_iter': 0.09475, 'accuracy': 0.86323, 'precision': 0.57456, 'recall': 0.86771, 'f1': 0.69134, 'auc': 0.94118, 'accuracy-SBM': 0.86499}
2025-07-05 06:44:12,084 - INFO - val: {'epoch': 71, 'time_epoch': 3.21986, 'loss': 0.1046701, 'lr': 0, 'params': 340919, 'time_iter': 0.05111, 'accuracy': 0.76354, 'precision': 0.42428, 'recall': 0.94069, 'f1': 0.58479, 'auc': 0.93505, 'accuracy-SBM': 0.83306}
2025-07-05 06:44:17,164 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:44:17,519 - INFO - test: {'epoch': 71, 'time_epoch': 3.26206, 'loss': 0.10354129, 'lr': 0, 'params': 340919, 'time_iter': 0.05178, 'accuracy': 0.76684, 'precision': 0.42667, 'recall': 0.94002, 'f1': 0.58694, 'auc': 0.93575, 'accuracy-SBM': 0.83491}
2025-07-05 06:44:17,520 - INFO - > Epoch 71: took 39.6s (avg 41.8s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:44:17,520 - INFO - === Epoch 72 ===
2025-07-05 06:44:48,263 - INFO - train: {'epoch': 72, 'time_epoch': 29.64877, 'eta': 807.9986, 'eta_hours': 0.22444, 'loss': 0.08975, 'lr': 9.973e-05, 'params': 340919, 'time_iter': 0.09472, 'accuracy': 0.86294, 'precision': 0.57391, 'recall': 0.86785, 'f1': 0.69092, 'auc': 0.94123, 'accuracy-SBM': 0.86487}
2025-07-05 06:44:51,833 - INFO - val: {'epoch': 72, 'time_epoch': 3.22358, 'loss': 0.09106437, 'lr': 0, 'params': 340919, 'time_iter': 0.05117, 'accuracy': 0.86782, 'precision': 0.58658, 'recall': 0.85819, 'f1': 0.69685, 'auc': 0.94046, 'accuracy-SBM': 0.86404}
2025-07-05 06:44:57,188 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:44:57,534 - INFO - test: {'epoch': 72, 'time_epoch': 3.26592, 'loss': 0.08998274, 'lr': 0, 'params': 340919, 'time_iter': 0.05184, 'accuracy': 0.87092, 'precision': 0.59216, 'recall': 0.85943, 'f1': 0.70119, 'auc': 0.9414, 'accuracy-SBM': 0.86641}
2025-07-05 06:44:57,535 - INFO - > Epoch 72: took 40.0s (avg 41.8s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:44:57,535 - INFO - === Epoch 73 ===
2025-07-05 06:45:29,205 - INFO - train: {'epoch': 73, 'time_epoch': 29.70419, 'eta': 777.99483, 'eta_hours': 0.21611, 'loss': 0.0897162, 'lr': 9.321e-05, 'params': 340919, 'time_iter': 0.0949, 'accuracy': 0.86286, 'precision': 0.5737, 'recall': 0.86836, 'f1': 0.69092, 'auc': 0.94129, 'accuracy-SBM': 0.86502}
2025-07-05 06:45:32,774 - INFO - val: {'epoch': 73, 'time_epoch': 3.22547, 'loss': 0.10542619, 'lr': 0, 'params': 340919, 'time_iter': 0.0512, 'accuracy': 0.89302, 'precision': 0.67706, 'recall': 0.75653, 'f1': 0.71459, 'auc': 0.93441, 'accuracy-SBM': 0.83946}
2025-07-05 06:45:37,956 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:45:38,293 - INFO - test: {'epoch': 73, 'time_epoch': 3.26309, 'loss': 0.1045784, 'lr': 0, 'params': 340919, 'time_iter': 0.0518, 'accuracy': 0.8949, 'precision': 0.68223, 'recall': 0.7555, 'f1': 0.717, 'auc': 0.93547, 'accuracy-SBM': 0.84011}
2025-07-05 06:45:38,306 - INFO - > Epoch 73: took 40.8s (avg 41.8s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:45:38,306 - INFO - === Epoch 74 ===
2025-07-05 06:46:09,161 - INFO - train: {'epoch': 74, 'time_epoch': 29.69139, 'eta': 747.99479, 'eta_hours': 0.20778, 'loss': 0.08982285, 'lr': 8.685e-05, 'params': 340919, 'time_iter': 0.09486, 'accuracy': 0.86263, 'precision': 0.57321, 'recall': 0.86816, 'f1': 0.69051, 'auc': 0.94115, 'accuracy-SBM': 0.8648}
2025-07-05 06:46:12,729 - INFO - val: {'epoch': 74, 'time_epoch': 3.22248, 'loss': 0.0908636, 'lr': 0, 'params': 340919, 'time_iter': 0.05115, 'accuracy': 0.85387, 'precision': 0.55523, 'recall': 0.87735, 'f1': 0.68007, 'auc': 0.94015, 'accuracy-SBM': 0.86309}
2025-07-05 06:46:17,955 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:46:18,304 - INFO - test: {'epoch': 74, 'time_epoch': 3.26409, 'loss': 0.08971493, 'lr': 0, 'params': 340919, 'time_iter': 0.05181, 'accuracy': 0.85684, 'precision': 0.55981, 'recall': 0.87806, 'f1': 0.68371, 'auc': 0.94106, 'accuracy-SBM': 0.86518}
2025-07-05 06:46:18,305 - INFO - > Epoch 74: took 40.0s (avg 41.8s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:46:18,305 - INFO - === Epoch 75 ===
2025-07-05 06:46:49,910 - INFO - train: {'epoch': 75, 'time_epoch': 29.67003, 'eta': 717.99613, 'eta_hours': 0.19944, 'loss': 0.0897543, 'lr': 8.068e-05, 'params': 340919, 'time_iter': 0.09479, 'accuracy': 0.86286, 'precision': 0.57372, 'recall': 0.86795, 'f1': 0.69081, 'auc': 0.94121, 'accuracy-SBM': 0.86486}
2025-07-05 06:46:53,487 - INFO - val: {'epoch': 75, 'time_epoch': 3.22779, 'loss': 0.09180196, 'lr': 0, 'params': 340919, 'time_iter': 0.05123, 'accuracy': 0.84845, 'precision': 0.54457, 'recall': 0.87916, 'f1': 0.67255, 'auc': 0.93836, 'accuracy-SBM': 0.8605}
2025-07-05 06:46:58,806 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:46:59,153 - INFO - test: {'epoch': 75, 'time_epoch': 3.26281, 'loss': 0.0907261, 'lr': 0, 'params': 340919, 'time_iter': 0.05179, 'accuracy': 0.85023, 'precision': 0.54669, 'recall': 0.87894, 'f1': 0.6741, 'auc': 0.93916, 'accuracy-SBM': 0.86152}
2025-07-05 06:46:59,154 - INFO - > Epoch 75: took 40.8s (avg 41.8s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:46:59,154 - INFO - === Epoch 76 ===
2025-07-05 06:47:30,814 - INFO - train: {'epoch': 76, 'time_epoch': 29.68977, 'eta': 688.0119, 'eta_hours': 0.19111, 'loss': 0.08968396, 'lr': 7.469e-05, 'params': 340919, 'time_iter': 0.09486, 'accuracy': 0.86257, 'precision': 0.57302, 'recall': 0.86879, 'f1': 0.69057, 'auc': 0.94131, 'accuracy-SBM': 0.86501}
2025-07-05 06:47:34,379 - INFO - val: {'epoch': 76, 'time_epoch': 3.22273, 'loss': 0.09894597, 'lr': 0, 'params': 340919, 'time_iter': 0.05115, 'accuracy': 0.88738, 'precision': 0.65043, 'recall': 0.78647, 'f1': 0.71201, 'auc': 0.9358, 'accuracy-SBM': 0.84778}
2025-07-05 06:47:39,809 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:47:40,154 - INFO - test: {'epoch': 76, 'time_epoch': 3.2646, 'loss': 0.09806559, 'lr': 0, 'params': 340919, 'time_iter': 0.05182, 'accuracy': 0.88946, 'precision': 0.65489, 'recall': 0.78795, 'f1': 0.71529, 'auc': 0.93674, 'accuracy-SBM': 0.84956}
2025-07-05 06:47:40,155 - INFO - > Epoch 76: took 41.0s (avg 41.7s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:47:40,155 - INFO - === Epoch 77 ===
2025-07-05 06:48:11,891 - INFO - train: {'epoch': 77, 'time_epoch': 29.75016, 'eta': 658.05225, 'eta_hours': 0.18279, 'loss': 0.08963585, 'lr': 6.889e-05, 'params': 340919, 'time_iter': 0.09505, 'accuracy': 0.86269, 'precision': 0.57331, 'recall': 0.86848, 'f1': 0.69068, 'auc': 0.94136, 'accuracy-SBM': 0.86496}
2025-07-05 06:48:15,468 - INFO - val: {'epoch': 77, 'time_epoch': 3.2308, 'loss': 0.09218931, 'lr': 0, 'params': 340919, 'time_iter': 0.05128, 'accuracy': 0.87861, 'precision': 0.61582, 'recall': 0.8354, 'f1': 0.709, 'auc': 0.94014, 'accuracy-SBM': 0.86165}
2025-07-05 06:48:20,616 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:48:20,957 - INFO - test: {'epoch': 77, 'time_epoch': 3.27127, 'loss': 0.09115045, 'lr': 0, 'params': 340919, 'time_iter': 0.05192, 'accuracy': 0.88078, 'precision': 0.61989, 'recall': 0.83616, 'f1': 0.71196, 'auc': 0.94107, 'accuracy-SBM': 0.86324}
2025-07-05 06:48:20,959 - INFO - > Epoch 77: took 40.8s (avg 41.7s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:48:20,959 - INFO - === Epoch 78 ===
2025-07-05 06:48:52,657 - INFO - train: {'epoch': 78, 'time_epoch': 29.74565, 'eta': 628.09671, 'eta_hours': 0.17447, 'loss': 0.08970435, 'lr': 6.329e-05, 'params': 340919, 'time_iter': 0.09503, 'accuracy': 0.86289, 'precision': 0.5738, 'recall': 0.86785, 'f1': 0.69084, 'auc': 0.94126, 'accuracy-SBM': 0.86484}
2025-07-05 06:48:56,237 - INFO - val: {'epoch': 78, 'time_epoch': 3.23076, 'loss': 0.0917414, 'lr': 0, 'params': 340919, 'time_iter': 0.05128, 'accuracy': 0.86556, 'precision': 0.58169, 'recall': 0.85653, 'f1': 0.69285, 'auc': 0.93874, 'accuracy-SBM': 0.86202}
2025-07-05 06:49:01,497 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:49:01,844 - INFO - test: {'epoch': 78, 'time_epoch': 3.27424, 'loss': 0.0906813, 'lr': 0, 'params': 340919, 'time_iter': 0.05197, 'accuracy': 0.86795, 'precision': 0.58574, 'recall': 0.85626, 'f1': 0.69562, 'auc': 0.93962, 'accuracy-SBM': 0.86336}
2025-07-05 06:49:01,845 - INFO - > Epoch 78: took 40.9s (avg 41.7s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:49:01,846 - INFO - === Epoch 79 ===
2025-07-05 06:49:33,583 - INFO - train: {'epoch': 79, 'time_epoch': 29.76821, 'eta': 598.15205, 'eta_hours': 0.16615, 'loss': 0.08965429, 'lr': 5.79e-05, 'params': 340919, 'time_iter': 0.09511, 'accuracy': 0.86303, 'precision': 0.57415, 'recall': 0.86741, 'f1': 0.69095, 'auc': 0.94132, 'accuracy-SBM': 0.86475}
2025-07-05 06:49:37,163 - INFO - val: {'epoch': 79, 'time_epoch': 3.22891, 'loss': 0.09066418, 'lr': 0, 'params': 340919, 'time_iter': 0.05125, 'accuracy': 0.85154, 'precision': 0.55023, 'recall': 0.88383, 'f1': 0.67823, 'auc': 0.94094, 'accuracy-SBM': 0.86421}
2025-07-05 06:49:42,650 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:49:43,000 - INFO - test: {'epoch': 79, 'time_epoch': 3.27145, 'loss': 0.08956449, 'lr': 0, 'params': 340919, 'time_iter': 0.05193, 'accuracy': 0.85413, 'precision': 0.55398, 'recall': 0.88368, 'f1': 0.68103, 'auc': 0.94179, 'accuracy-SBM': 0.86575}
2025-07-05 06:49:43,001 - INFO - > Epoch 79: took 41.2s (avg 41.7s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:49:43,001 - INFO - === Epoch 80 ===
2025-07-05 06:50:14,767 - INFO - train: {'epoch': 80, 'time_epoch': 29.78768, 'eta': 568.21632, 'eta_hours': 0.15784, 'loss': 0.08963543, 'lr': 5.271e-05, 'params': 340919, 'time_iter': 0.09517, 'accuracy': 0.86335, 'precision': 0.57476, 'recall': 0.86813, 'f1': 0.69162, 'auc': 0.94139, 'accuracy-SBM': 0.86523}
2025-07-05 06:50:18,342 - INFO - val: {'epoch': 80, 'time_epoch': 3.22925, 'loss': 0.09965164, 'lr': 0, 'params': 340919, 'time_iter': 0.05126, 'accuracy': 0.89059, 'precision': 0.66214, 'recall': 0.77994, 'f1': 0.71623, 'auc': 0.93632, 'accuracy-SBM': 0.84717}
2025-07-05 06:50:23,785 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:50:24,121 - INFO - test: {'epoch': 80, 'time_epoch': 3.27426, 'loss': 0.09892224, 'lr': 0, 'params': 340919, 'time_iter': 0.05197, 'accuracy': 0.89282, 'precision': 0.66758, 'recall': 0.78042, 'f1': 0.7196, 'auc': 0.93718, 'accuracy-SBM': 0.84864}
2025-07-05 06:50:24,122 - INFO - > Epoch 80: took 41.1s (avg 41.7s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:50:24,122 - INFO - === Epoch 81 ===
2025-07-05 06:50:55,814 - INFO - train: {'epoch': 81, 'time_epoch': 29.72221, 'eta': 538.26982, 'eta_hours': 0.14952, 'loss': 0.08963174, 'lr': 4.775e-05, 'params': 340919, 'time_iter': 0.09496, 'accuracy': 0.86315, 'precision': 0.57435, 'recall': 0.86808, 'f1': 0.69131, 'auc': 0.94138, 'accuracy-SBM': 0.86509}
2025-07-05 06:51:01,184 - INFO - val: {'epoch': 81, 'time_epoch': 4.91613, 'loss': 0.09460668, 'lr': 0, 'params': 340919, 'time_iter': 0.07803, 'accuracy': 0.88046, 'precision': 0.62377, 'recall': 0.81827, 'f1': 0.7079, 'auc': 0.93725, 'accuracy-SBM': 0.85605}
2025-07-05 06:51:06,508 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:51:06,855 - INFO - test: {'epoch': 81, 'time_epoch': 3.27367, 'loss': 0.09372977, 'lr': 0, 'params': 340919, 'time_iter': 0.05196, 'accuracy': 0.88246, 'precision': 0.62771, 'recall': 0.81839, 'f1': 0.71048, 'auc': 0.93805, 'accuracy-SBM': 0.85728}
2025-07-05 06:51:06,857 - INFO - > Epoch 81: took 42.7s (avg 41.7s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:51:06,857 - INFO - === Epoch 82 ===
2025-07-05 06:51:38,077 - INFO - train: {'epoch': 82, 'time_epoch': 30.10955, 'eta': 508.40807, 'eta_hours': 0.14122, 'loss': 0.08955514, 'lr': 4.3e-05, 'params': 340919, 'time_iter': 0.0962, 'accuracy': 0.86354, 'precision': 0.57514, 'recall': 0.86846, 'f1': 0.692, 'auc': 0.94151, 'accuracy-SBM': 0.86547}
2025-07-05 06:51:41,660 - INFO - val: {'epoch': 82, 'time_epoch': 3.23806, 'loss': 0.09954495, 'lr': 0, 'params': 340919, 'time_iter': 0.0514, 'accuracy': 0.88759, 'precision': 0.65079, 'recall': 0.78766, 'f1': 0.71271, 'auc': 0.93589, 'accuracy-SBM': 0.84837}
2025-07-05 06:51:46,927 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:51:47,271 - INFO - test: {'epoch': 82, 'time_epoch': 3.28087, 'loss': 0.09877488, 'lr': 0, 'params': 340919, 'time_iter': 0.05208, 'accuracy': 0.89005, 'precision': 0.65667, 'recall': 0.78811, 'f1': 0.71641, 'auc': 0.93676, 'accuracy-SBM': 0.84998}
2025-07-05 06:51:47,272 - INFO - > Epoch 82: took 40.4s (avg 41.7s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:51:47,272 - INFO - === Epoch 83 ===
2025-07-05 06:52:19,267 - INFO - train: {'epoch': 83, 'time_epoch': 30.00934, 'eta': 478.52133, 'eta_hours': 0.13292, 'loss': 0.08959171, 'lr': 3.848e-05, 'params': 340919, 'time_iter': 0.09588, 'accuracy': 0.86308, 'precision': 0.57415, 'recall': 0.86856, 'f1': 0.69131, 'auc': 0.94143, 'accuracy-SBM': 0.86523}
2025-07-05 06:52:22,848 - INFO - val: {'epoch': 83, 'time_epoch': 3.23872, 'loss': 0.11028172, 'lr': 0, 'params': 340919, 'time_iter': 0.05141, 'accuracy': 0.89803, 'precision': 0.70451, 'recall': 0.7303, 'f1': 0.71717, 'auc': 0.9343, 'accuracy-SBM': 0.83221}
2025-07-05 06:52:28,059 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:52:28,400 - INFO - test: {'epoch': 83, 'time_epoch': 3.27911, 'loss': 0.10967594, 'lr': 0, 'params': 340919, 'time_iter': 0.05205, 'accuracy': 0.89937, 'precision': 0.70908, 'recall': 0.72739, 'f1': 0.71812, 'auc': 0.93531, 'accuracy-SBM': 0.83178}
2025-07-05 06:52:28,402 - INFO - > Epoch 83: took 41.1s (avg 41.7s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:52:28,402 - INFO - === Epoch 84 ===
2025-07-05 06:53:00,134 - INFO - train: {'epoch': 84, 'time_epoch': 30.59779, 'eta': 448.73555, 'eta_hours': 0.12465, 'loss': 0.08957312, 'lr': 3.419e-05, 'params': 340919, 'time_iter': 0.09776, 'accuracy': 0.86288, 'precision': 0.57368, 'recall': 0.86883, 'f1': 0.69106, 'auc': 0.94148, 'accuracy-SBM': 0.86522}
2025-07-05 06:53:03,766 - INFO - val: {'epoch': 84, 'time_epoch': 3.27955, 'loss': 0.09524892, 'lr': 0, 'params': 340919, 'time_iter': 0.05206, 'accuracy': 0.87839, 'precision': 0.6178, 'recall': 0.82087, 'f1': 0.705, 'auc': 0.93649, 'accuracy-SBM': 0.85582}
2025-07-05 06:53:09,242 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:53:09,598 - INFO - test: {'epoch': 84, 'time_epoch': 3.31292, 'loss': 0.09444375, 'lr': 0, 'params': 340919, 'time_iter': 0.05259, 'accuracy': 0.8801, 'precision': 0.62095, 'recall': 0.82046, 'f1': 0.7069, 'auc': 0.93722, 'accuracy-SBM': 0.85666}
2025-07-05 06:53:09,600 - INFO - > Epoch 84: took 41.2s (avg 41.7s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:53:09,600 - INFO - === Epoch 85 ===
2025-07-05 06:53:40,288 - INFO - train: {'epoch': 85, 'time_epoch': 30.40639, 'eta': 418.89972, 'eta_hours': 0.11636, 'loss': 0.08961099, 'lr': 3.013e-05, 'params': 340919, 'time_iter': 0.09715, 'accuracy': 0.86296, 'precision': 0.57387, 'recall': 0.86875, 'f1': 0.69117, 'auc': 0.94143, 'accuracy-SBM': 0.86524}
2025-07-05 06:53:43,924 - INFO - val: {'epoch': 85, 'time_epoch': 3.29063, 'loss': 0.09436282, 'lr': 0, 'params': 340919, 'time_iter': 0.05223, 'accuracy': 0.87863, 'precision': 0.61763, 'recall': 0.82539, 'f1': 0.70655, 'auc': 0.93774, 'accuracy-SBM': 0.85774}
2025-07-05 06:53:49,307 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:53:49,653 - INFO - test: {'epoch': 85, 'time_epoch': 3.3366, 'loss': 0.0933804, 'lr': 0, 'params': 340919, 'time_iter': 0.05296, 'accuracy': 0.88071, 'precision': 0.62147, 'recall': 0.82635, 'f1': 0.70941, 'auc': 0.93865, 'accuracy-SBM': 0.85934}
2025-07-05 06:53:49,655 - INFO - > Epoch 85: took 40.1s (avg 41.7s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:53:49,655 - INFO - === Epoch 86 ===
2025-07-05 06:54:21,541 - INFO - train: {'epoch': 86, 'time_epoch': 29.90529, 'eta': 388.97591, 'eta_hours': 0.10805, 'loss': 0.08960927, 'lr': 2.632e-05, 'params': 340919, 'time_iter': 0.09554, 'accuracy': 0.86318, 'precision': 0.57443, 'recall': 0.86791, 'f1': 0.69131, 'auc': 0.94142, 'accuracy-SBM': 0.86504}
2025-07-05 06:54:25,121 - INFO - val: {'epoch': 86, 'time_epoch': 3.23782, 'loss': 0.09566874, 'lr': 0, 'params': 340919, 'time_iter': 0.05139, 'accuracy': 0.8808, 'precision': 0.62526, 'recall': 0.8152, 'f1': 0.70771, 'auc': 0.9365, 'accuracy-SBM': 0.85505}
2025-07-05 06:54:30,574 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:54:30,932 - INFO - test: {'epoch': 86, 'time_epoch': 3.28225, 'loss': 0.09485733, 'lr': 0, 'params': 340919, 'time_iter': 0.0521, 'accuracy': 0.88262, 'precision': 0.62891, 'recall': 0.81448, 'f1': 0.70977, 'auc': 0.93728, 'accuracy-SBM': 0.85584}
2025-07-05 06:54:30,933 - INFO - > Epoch 86: took 41.3s (avg 41.7s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:54:30,933 - INFO - === Epoch 87 ===
2025-07-05 06:55:02,020 - INFO - train: {'epoch': 87, 'time_epoch': 29.95514, 'eta': 359.05931, 'eta_hours': 0.09974, 'loss': 0.08953394, 'lr': 2.275e-05, 'params': 340919, 'time_iter': 0.0957, 'accuracy': 0.86334, 'precision': 0.57469, 'recall': 0.86882, 'f1': 0.69179, 'auc': 0.94153, 'accuracy-SBM': 0.86549}
2025-07-05 06:55:05,635 - INFO - val: {'epoch': 87, 'time_epoch': 3.25778, 'loss': 0.0921402, 'lr': 0, 'params': 340919, 'time_iter': 0.05171, 'accuracy': 0.8662, 'precision': 0.58356, 'recall': 0.8526, 'f1': 0.69288, 'auc': 0.93827, 'accuracy-SBM': 0.86086}
2025-07-05 06:55:11,044 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:55:11,394 - INFO - test: {'epoch': 87, 'time_epoch': 3.29955, 'loss': 0.09114591, 'lr': 0, 'params': 340919, 'time_iter': 0.05237, 'accuracy': 0.86856, 'precision': 0.58757, 'recall': 0.85245, 'f1': 0.69565, 'auc': 0.93911, 'accuracy-SBM': 0.86223}
2025-07-05 06:55:11,395 - INFO - > Epoch 87: took 40.5s (avg 41.7s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:55:11,395 - INFO - === Epoch 88 ===
2025-07-05 06:55:43,288 - INFO - train: {'epoch': 88, 'time_epoch': 29.91832, 'eta': 329.13729, 'eta_hours': 0.09143, 'loss': 0.08954445, 'lr': 1.943e-05, 'params': 340919, 'time_iter': 0.09559, 'accuracy': 0.86295, 'precision': 0.57388, 'recall': 0.86842, 'f1': 0.69108, 'auc': 0.94149, 'accuracy-SBM': 0.8651}
2025-07-05 06:55:46,889 - INFO - val: {'epoch': 88, 'time_epoch': 3.25108, 'loss': 0.09138465, 'lr': 0, 'params': 340919, 'time_iter': 0.0516, 'accuracy': 0.87323, 'precision': 0.60056, 'recall': 0.84764, 'f1': 0.70303, 'auc': 0.94037, 'accuracy-SBM': 0.86319}
2025-07-05 06:55:52,374 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:55:52,732 - INFO - test: {'epoch': 88, 'time_epoch': 3.2924, 'loss': 0.09035466, 'lr': 0, 'params': 340919, 'time_iter': 0.05226, 'accuracy': 0.87542, 'precision': 0.60435, 'recall': 0.84867, 'f1': 0.70597, 'auc': 0.94125, 'accuracy-SBM': 0.86491}
2025-07-05 06:55:52,734 - INFO - > Epoch 88: took 41.3s (avg 41.7s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:55:52,734 - INFO - === Epoch 89 ===
2025-07-05 06:56:24,649 - INFO - train: {'epoch': 89, 'time_epoch': 29.91408, 'eta': 299.21489, 'eta_hours': 0.08312, 'loss': 0.08951033, 'lr': 1.636e-05, 'params': 340919, 'time_iter': 0.09557, 'accuracy': 0.86329, 'precision': 0.57458, 'recall': 0.86866, 'f1': 0.69166, 'auc': 0.94156, 'accuracy-SBM': 0.8654}
2025-07-05 06:56:28,261 - INFO - val: {'epoch': 89, 'time_epoch': 3.25612, 'loss': 0.09204865, 'lr': 0, 'params': 340919, 'time_iter': 0.05168, 'accuracy': 0.87719, 'precision': 0.61184, 'recall': 0.83761, 'f1': 0.70714, 'auc': 0.94002, 'accuracy-SBM': 0.86166}
2025-07-05 06:56:33,855 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:56:34,214 - INFO - test: {'epoch': 89, 'time_epoch': 3.30222, 'loss': 0.09102255, 'lr': 0, 'params': 340919, 'time_iter': 0.05242, 'accuracy': 0.8791, 'precision': 0.61517, 'recall': 0.83835, 'f1': 0.70963, 'auc': 0.94092, 'accuracy-SBM': 0.86308}
2025-07-05 06:56:34,215 - INFO - > Epoch 89: took 41.5s (avg 41.6s) | Best so far: epoch 56	train_loss: 0.0902 train_accuracy-SBM: 0.8646	val_loss: 0.0905 val_accuracy-SBM: 0.8646	test_loss: 0.0893 test_accuracy-SBM: 0.8659
2025-07-05 06:56:34,216 - INFO - === Epoch 90 ===
2025-07-05 06:57:04,544 - INFO - train: {'epoch': 90, 'time_epoch': 29.93411, 'eta': 269.29465, 'eta_hours': 0.0748, 'loss': 0.0895267, 'lr': 1.355e-05, 'params': 340919, 'time_iter': 0.09564, 'accuracy': 0.86342, 'precision': 0.57492, 'recall': 0.86813, 'f1': 0.69174, 'auc': 0.94154, 'accuracy-SBM': 0.86527}
2025-07-05 06:57:08,152 - INFO - val: {'epoch': 90, 'time_epoch': 3.25395, 'loss': 0.09042793, 'lr': 0, 'params': 340919, 'time_iter': 0.05165, 'accuracy': 0.86312, 'precision': 0.57507, 'recall': 0.86853, 'f1': 0.69197, 'auc': 0.94109, 'accuracy-SBM': 0.86524}
2025-07-05 06:57:13,626 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:57:13,983 - INFO - test: {'epoch': 90, 'time_epoch': 3.29816, 'loss': 0.08932774, 'lr': 0, 'params': 340919, 'time_iter': 0.05235, 'accuracy': 0.86547, 'precision': 0.5788, 'recall': 0.86891, 'f1': 0.69479, 'auc': 0.94197, 'accuracy-SBM': 0.86682}
2025-07-05 06:57:13,984 - INFO - > Epoch 90: took 39.8s (avg 41.6s) | Best so far: epoch 90	train_loss: 0.0895 train_accuracy-SBM: 0.8653	val_loss: 0.0904 val_accuracy-SBM: 0.8652	test_loss: 0.0893 test_accuracy-SBM: 0.8668
2025-07-05 06:57:13,984 - INFO - === Epoch 91 ===
2025-07-05 06:57:45,925 - INFO - train: {'epoch': 91, 'time_epoch': 29.921, 'eta': 239.37297, 'eta_hours': 0.06649, 'loss': 0.08949025, 'lr': 1.099e-05, 'params': 340919, 'time_iter': 0.09559, 'accuracy': 0.86362, 'precision': 0.57535, 'recall': 0.86808, 'f1': 0.69203, 'auc': 0.94157, 'accuracy-SBM': 0.86537}
2025-07-05 06:57:49,537 - INFO - val: {'epoch': 91, 'time_epoch': 3.25472, 'loss': 0.09118122, 'lr': 0, 'params': 340919, 'time_iter': 0.05166, 'accuracy': 0.87089, 'precision': 0.59439, 'recall': 0.85219, 'f1': 0.70032, 'auc': 0.94042, 'accuracy-SBM': 0.86355}
2025-07-05 06:57:55,128 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:57:55,482 - INFO - test: {'epoch': 91, 'time_epoch': 3.2952, 'loss': 0.09014045, 'lr': 0, 'params': 340919, 'time_iter': 0.0523, 'accuracy': 0.87347, 'precision': 0.599, 'recall': 0.85303, 'f1': 0.70379, 'auc': 0.94129, 'accuracy-SBM': 0.86543}
2025-07-05 06:57:55,495 - INFO - > Epoch 91: took 41.5s (avg 41.6s) | Best so far: epoch 90	train_loss: 0.0895 train_accuracy-SBM: 0.8653	val_loss: 0.0904 val_accuracy-SBM: 0.8652	test_loss: 0.0893 test_accuracy-SBM: 0.8668
2025-07-05 06:57:55,495 - INFO - === Epoch 92 ===
2025-07-05 06:58:27,457 - INFO - train: {'epoch': 92, 'time_epoch': 29.93655, 'eta': 209.45247, 'eta_hours': 0.05818, 'loss': 0.08950114, 'lr': 8.7e-06, 'params': 340919, 'time_iter': 0.09564, 'accuracy': 0.86285, 'precision': 0.57364, 'recall': 0.8687, 'f1': 0.69099, 'auc': 0.94156, 'accuracy-SBM': 0.86515}
2025-07-05 06:58:31,069 - INFO - val: {'epoch': 92, 'time_epoch': 3.25558, 'loss': 0.09205022, 'lr': 0, 'params': 340919, 'time_iter': 0.05168, 'accuracy': 0.86986, 'precision': 0.59252, 'recall': 0.84809, 'f1': 0.69764, 'auc': 0.93885, 'accuracy-SBM': 0.86132}
2025-07-05 06:58:36,928 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:58:37,279 - INFO - test: {'epoch': 92, 'time_epoch': 3.29902, 'loss': 0.09106196, 'lr': 0, 'params': 340919, 'time_iter': 0.05237, 'accuracy': 0.87238, 'precision': 0.59713, 'recall': 0.84778, 'f1': 0.70071, 'auc': 0.93967, 'accuracy-SBM': 0.86271}
2025-07-05 06:58:37,281 - INFO - > Epoch 92: took 41.8s (avg 41.6s) | Best so far: epoch 90	train_loss: 0.0895 train_accuracy-SBM: 0.8653	val_loss: 0.0904 val_accuracy-SBM: 0.8652	test_loss: 0.0893 test_accuracy-SBM: 0.8668
2025-07-05 06:58:37,281 - INFO - === Epoch 93 ===
2025-07-05 06:59:09,134 - INFO - train: {'epoch': 93, 'time_epoch': 29.87014, 'eta': 179.52739, 'eta_hours': 0.04987, 'loss': 0.08952091, 'lr': 6.67e-06, 'params': 340919, 'time_iter': 0.09543, 'accuracy': 0.86328, 'precision': 0.57462, 'recall': 0.86814, 'f1': 0.69152, 'auc': 0.94152, 'accuracy-SBM': 0.86519}
2025-07-05 06:59:12,735 - INFO - val: {'epoch': 93, 'time_epoch': 3.2522, 'loss': 0.09225885, 'lr': 0, 'params': 340919, 'time_iter': 0.05162, 'accuracy': 0.87481, 'precision': 0.60546, 'recall': 0.84052, 'f1': 0.70388, 'auc': 0.93934, 'accuracy-SBM': 0.86135}
2025-07-05 06:59:18,521 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:59:18,868 - INFO - test: {'epoch': 93, 'time_epoch': 3.29128, 'loss': 0.09125906, 'lr': 0, 'params': 340919, 'time_iter': 0.05224, 'accuracy': 0.877, 'precision': 0.60947, 'recall': 0.84078, 'f1': 0.70668, 'auc': 0.94021, 'accuracy-SBM': 0.86277}
2025-07-05 06:59:18,870 - INFO - > Epoch 93: took 41.6s (avg 41.6s) | Best so far: epoch 90	train_loss: 0.0895 train_accuracy-SBM: 0.8653	val_loss: 0.0904 val_accuracy-SBM: 0.8652	test_loss: 0.0893 test_accuracy-SBM: 0.8668
2025-07-05 06:59:18,870 - INFO - === Epoch 94 ===
2025-07-05 06:59:50,719 - INFO - train: {'epoch': 94, 'time_epoch': 29.86654, 'eta': 149.60328, 'eta_hours': 0.04156, 'loss': 0.089561, 'lr': 4.91e-06, 'params': 340919, 'time_iter': 0.09542, 'accuracy': 0.8629, 'precision': 0.57376, 'recall': 0.86853, 'f1': 0.69102, 'auc': 0.94145, 'accuracy-SBM': 0.86511}
2025-07-05 06:59:54,313 - INFO - val: {'epoch': 94, 'time_epoch': 3.24618, 'loss': 0.10117318, 'lr': 0, 'params': 340919, 'time_iter': 0.05153, 'accuracy': 0.87554, 'precision': 0.61463, 'recall': 0.79597, 'f1': 0.69365, 'auc': 0.9298, 'accuracy-SBM': 0.84431}
2025-07-05 06:59:59,594 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 06:59:59,940 - INFO - test: {'epoch': 94, 'time_epoch': 3.29053, 'loss': 0.10073534, 'lr': 0, 'params': 340919, 'time_iter': 0.05223, 'accuracy': 0.87768, 'precision': 0.61879, 'recall': 0.79664, 'f1': 0.69654, 'auc': 0.93023, 'accuracy-SBM': 0.84583}
2025-07-05 06:59:59,942 - INFO - > Epoch 94: took 41.1s (avg 41.6s) | Best so far: epoch 90	train_loss: 0.0895 train_accuracy-SBM: 0.8653	val_loss: 0.0904 val_accuracy-SBM: 0.8652	test_loss: 0.0893 test_accuracy-SBM: 0.8668
2025-07-05 06:59:59,942 - INFO - === Epoch 95 ===
2025-07-05 07:00:31,751 - INFO - train: {'epoch': 95, 'time_epoch': 29.83815, 'eta': 119.67919, 'eta_hours': 0.03324, 'loss': 0.08944718, 'lr': 3.41e-06, 'params': 340919, 'time_iter': 0.09533, 'accuracy': 0.86346, 'precision': 0.57496, 'recall': 0.86854, 'f1': 0.6919, 'auc': 0.94163, 'accuracy-SBM': 0.86546}
2025-07-05 07:00:35,346 - INFO - val: {'epoch': 95, 'time_epoch': 3.24604, 'loss': 0.09161739, 'lr': 0, 'params': 340919, 'time_iter': 0.05152, 'accuracy': 0.86804, 'precision': 0.58769, 'recall': 0.8531, 'f1': 0.69595, 'auc': 0.93927, 'accuracy-SBM': 0.86218}
2025-07-05 07:00:40,528 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 07:00:40,881 - INFO - test: {'epoch': 95, 'time_epoch': 3.2899, 'loss': 0.09060465, 'lr': 0, 'params': 340919, 'time_iter': 0.05222, 'accuracy': 0.87053, 'precision': 0.59201, 'recall': 0.85336, 'f1': 0.69906, 'auc': 0.94012, 'accuracy-SBM': 0.86378}
2025-07-05 07:00:40,883 - INFO - > Epoch 95: took 40.9s (avg 41.6s) | Best so far: epoch 90	train_loss: 0.0895 train_accuracy-SBM: 0.8653	val_loss: 0.0904 val_accuracy-SBM: 0.8652	test_loss: 0.0893 test_accuracy-SBM: 0.8668
2025-07-05 07:00:40,883 - INFO - === Epoch 96 ===
2025-07-05 07:01:12,801 - INFO - train: {'epoch': 96, 'time_epoch': 29.92632, 'eta': 89.75959, 'eta_hours': 0.02493, 'loss': 0.08947623, 'lr': 2.18e-06, 'params': 340919, 'time_iter': 0.09561, 'accuracy': 0.86326, 'precision': 0.57449, 'recall': 0.86903, 'f1': 0.69171, 'auc': 0.94158, 'accuracy-SBM': 0.86553}
2025-07-05 07:01:16,398 - INFO - val: {'epoch': 96, 'time_epoch': 3.24846, 'loss': 0.09209847, 'lr': 0, 'params': 340919, 'time_iter': 0.05156, 'accuracy': 0.87374, 'precision': 0.6025, 'recall': 0.84269, 'f1': 0.70264, 'auc': 0.93936, 'accuracy-SBM': 0.86155}
2025-07-05 07:01:22,072 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 07:01:22,430 - INFO - test: {'epoch': 96, 'time_epoch': 3.29073, 'loss': 0.09109903, 'lr': 0, 'params': 340919, 'time_iter': 0.05223, 'accuracy': 0.87572, 'precision': 0.60593, 'recall': 0.84297, 'f1': 0.70506, 'auc': 0.94022, 'accuracy-SBM': 0.86285}
2025-07-05 07:01:22,432 - INFO - > Epoch 96: took 41.5s (avg 41.6s) | Best so far: epoch 90	train_loss: 0.0895 train_accuracy-SBM: 0.8653	val_loss: 0.0904 val_accuracy-SBM: 0.8652	test_loss: 0.0893 test_accuracy-SBM: 0.8668
2025-07-05 07:01:22,432 - INFO - === Epoch 97 ===
2025-07-05 07:01:53,535 - INFO - train: {'epoch': 97, 'time_epoch': 29.9658, 'eta': 59.84067, 'eta_hours': 0.01662, 'loss': 0.08940862, 'lr': 1.23e-06, 'params': 340919, 'time_iter': 0.09574, 'accuracy': 0.86356, 'precision': 0.57513, 'recall': 0.86899, 'f1': 0.69216, 'auc': 0.9417, 'accuracy-SBM': 0.86569}
2025-07-05 07:01:57,154 - INFO - val: {'epoch': 97, 'time_epoch': 3.26076, 'loss': 0.09092445, 'lr': 0, 'params': 340919, 'time_iter': 0.05176, 'accuracy': 0.86785, 'precision': 0.5867, 'recall': 0.85772, 'f1': 0.69678, 'auc': 0.94042, 'accuracy-SBM': 0.86388}
2025-07-05 07:02:03,343 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 07:02:03,702 - INFO - test: {'epoch': 97, 'time_epoch': 3.30225, 'loss': 0.08987701, 'lr': 0, 'params': 340919, 'time_iter': 0.05242, 'accuracy': 0.87053, 'precision': 0.59135, 'recall': 0.85872, 'f1': 0.70038, 'auc': 0.94129, 'accuracy-SBM': 0.86589}
2025-07-05 07:02:03,704 - INFO - > Epoch 97: took 41.3s (avg 41.6s) | Best so far: epoch 90	train_loss: 0.0895 train_accuracy-SBM: 0.8653	val_loss: 0.0904 val_accuracy-SBM: 0.8652	test_loss: 0.0893 test_accuracy-SBM: 0.8668
2025-07-05 07:02:03,704 - INFO - === Epoch 98 ===
2025-07-05 07:02:34,852 - INFO - train: {'epoch': 98, 'time_epoch': 29.96088, 'eta': 29.92074, 'eta_hours': 0.00831, 'loss': 0.08946495, 'lr': 5.5e-07, 'params': 340919, 'time_iter': 0.09572, 'accuracy': 0.86339, 'precision': 0.57481, 'recall': 0.86861, 'f1': 0.69181, 'auc': 0.94159, 'accuracy-SBM': 0.86544}
2025-07-05 07:02:38,467 - INFO - val: {'epoch': 98, 'time_epoch': 3.25608, 'loss': 0.09164313, 'lr': 0, 'params': 340919, 'time_iter': 0.05168, 'accuracy': 0.86789, 'precision': 0.58731, 'recall': 0.85336, 'f1': 0.69577, 'auc': 0.93925, 'accuracy-SBM': 0.86219}
2025-07-05 07:02:44,807 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 07:02:45,162 - INFO - test: {'epoch': 98, 'time_epoch': 3.29897, 'loss': 0.09063508, 'lr': 0, 'params': 340919, 'time_iter': 0.05236, 'accuracy': 0.87049, 'precision': 0.59191, 'recall': 0.85357, 'f1': 0.69906, 'auc': 0.94008, 'accuracy-SBM': 0.86384}
2025-07-05 07:02:45,164 - INFO - > Epoch 98: took 41.5s (avg 41.6s) | Best so far: epoch 90	train_loss: 0.0895 train_accuracy-SBM: 0.8653	val_loss: 0.0904 val_accuracy-SBM: 0.8652	test_loss: 0.0893 test_accuracy-SBM: 0.8668
2025-07-05 07:02:45,164 - INFO - === Epoch 99 ===
2025-07-05 07:03:16,455 - INFO - train: {'epoch': 99, 'time_epoch': 30.14289, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.08955616, 'lr': 1.4e-07, 'params': 340919, 'time_iter': 0.0963, 'accuracy': 0.86315, 'precision': 0.57431, 'recall': 0.86842, 'f1': 0.69139, 'auc': 0.94148, 'accuracy-SBM': 0.86522}
2025-07-05 07:03:20,067 - INFO - val: {'epoch': 99, 'time_epoch': 3.25446, 'loss': 0.09084727, 'lr': 0, 'params': 340919, 'time_iter': 0.05166, 'accuracy': 0.86992, 'precision': 0.5918, 'recall': 0.85479, 'f1': 0.69939, 'auc': 0.94094, 'accuracy-SBM': 0.86398}
2025-07-05 07:03:26,290 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-45/test_results
2025-07-05 07:03:26,644 - INFO - test: {'epoch': 99, 'time_epoch': 3.29522, 'loss': 0.08979097, 'lr': 0, 'params': 340919, 'time_iter': 0.05231, 'accuracy': 0.87273, 'precision': 0.59685, 'recall': 0.85591, 'f1': 0.70328, 'auc': 0.94182, 'accuracy-SBM': 0.86612}
2025-07-05 07:03:26,782 - INFO - > Epoch 99: took 41.5s (avg 41.6s) | Best so far: epoch 90	train_loss: 0.0895 train_accuracy-SBM: 0.8653	val_loss: 0.0904 val_accuracy-SBM: 0.8652	test_loss: 0.0893 test_accuracy-SBM: 0.8668
2025-07-05 07:03:26,782 - INFO - ================================================================================
2025-07-05 07:03:26,782 - INFO - NAS TRAINING COMPLETED SUCCESSFULLY
2025-07-05 07:03:26,782 - INFO - ================================================================================
2025-07-05 07:03:26,782 - INFO - Avg time per epoch: 41.61s
2025-07-05 07:03:26,782 - INFO - Total train loop time: 1.16h
2025-07-05 07:03:26,782 - INFO - Routing mode: nas
2025-07-05 07:03:26,782 - INFO - Final optimal weights: {'layer_0': 2, 'layer_1': 1, 'layer_2': 0, 'layer_3': 1, 'layer_4': 1, 'layer_5': 1}
2025-07-05 07:03:26,782 - INFO - Results include routing uncertainty (test only, NO variance)
2025-07-05 07:03:26,783 - INFO - Task done, results saved in results/pattern/pattern-SPARSE-45
2025-07-05 07:03:26,784 - INFO - Total time: 5115.49s (1.42h)
2025-07-05 07:03:26,820 - INFO - Results aggregated across runs saved in results/pattern/pattern-SPARSE-45/agg
2025-07-05 07:03:26,820 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-07-05 07:03:26,820 - INFO - Results saved in: results/pattern/pattern-SPARSE-45
2025-07-05 07:03:26,820 - INFO - Test results JSON files saved in: results/pattern/pattern-SPARSE-45/test_results/
Completed seed 45. Results saved in results/pattern/pattern-SPARSE-45
----------------------------------------
Submitting next job for seed 41
Submitted batch job 5334700
/var/spool/slurmd/job5334629/slurm_script: line 72: syntax error near unexpected token `"/data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/PATTERN"'
/var/spool/slurmd/job5334629/slurm_script: line 72: `os.chdir("/data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/PATTERN")'
