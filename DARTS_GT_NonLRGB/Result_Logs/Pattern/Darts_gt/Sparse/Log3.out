Lmod has detected the following error: The following module(s) are unknown:
"cuda/12.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/12.0"

Also make sure that all modulefiles written in TCL start with the string
#%Module



              total        used        free      shared  buff/cache   available
Mem:          376Gi        18Gi       346Gi       801Mi        11Gi       354Gi
Swap:         1.9Gi       2.0Mi       1.9Gi
Sat Jul  5 07:03:59 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla P100-PCIE-16GB           On  |   00000000:5E:00.0 Off |                    0 |
| N/A   32C    P0             25W /  250W |       0MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running experiment with seed: 41
Starting training for seed 41...
Changed working directory to: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/PATTERN/FINAL_SINGLE/SPARSE_E
Loading config from: /data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/PATTERN/FINAL_SINGLE/SPARSE_E/confignas.yaml
Using device: cuda
2025-07-05 07:04:41,227 - INFO - GPU Mem: 17.1GB
2025-07-05 07:04:41,227 - INFO - Run directory: results/pattern/pattern-SPARSE-41
2025-07-05 07:04:41,227 - INFO - Seed: 41
2025-07-05 07:04:41,227 - INFO - === OPTIMIZED MOE CONFIGURATION ===
2025-07-05 07:04:41,227 - INFO - Routing mode: nas
2025-07-05 07:04:41,227 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-07-05 07:04:41,227 - INFO - Number of layers: 6
2025-07-05 07:04:41,227 - INFO - Uncertainty enabled: False
2025-07-05 07:04:41,227 - INFO - Training mode: NoMixNas_uncertainty_train
2025-07-05 07:04:41,227 - INFO - Optimization: Uncertainty only for last layer + test/val
2025-07-05 07:04:41,227 - INFO - Additional features: Router weights logging + JSON export
2025-07-05 07:04:59,874 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset':
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-05 07:04:59,877 - INFO -   Data(x=[1664491, 3], edge_index=[2, 85099952], y=[1664491])
2025-07-05 07:04:59,927 - INFO -   undirected: True
2025-07-05 07:04:59,927 - INFO -   num graphs: 14000
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
2025-07-05 07:04:59,927 - INFO -   avg num_nodes/graph: 118
2025-07-05 07:04:59,927 - INFO -   num node features: 3
2025-07-05 07:04:59,927 - INFO -   num edge features: 0
2025-07-05 07:04:59,929 - INFO -   num classes: 2
2025-07-05 07:04:59,929 - INFO - Precomputing Positional Encoding statistics: ['LapPE'] for all graphs...
2025-07-05 07:04:59,939 - INFO -   ...estimated to be undirected: True
  0%|          | 0/14000 [00:00<?, ?it/s] 22%|██▏       | 3078/14000 [00:10<00:35, 307.76it/s] 45%|████▍     | 6252/14000 [00:20<00:24, 313.42it/s] 69%|██████▊   | 9620/14000 [00:30<00:13, 324.10it/s] 92%|█████████▏| 12949/14000 [00:40<00:03, 327.53it/s]100%|██████████| 14000/14000 [00:42<00:00, 326.06it/s]
2025-07-05 07:05:43,788 - INFO - Done! Took 00:00:43.86
2025-07-05 07:05:43,812 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset'
/data/coml-deepcmb/lady6973/py310_new_venv/lib/python3.9/site-packages/nni/nas/nn/pytorch/choice.py:252: UserWarning: "key" is deprecated. Assuming label.
  warnings.warn(f'"key" is deprecated. Assuming label.')
2025-07-05 07:05:44,169 - INFO - Created model type: <class 'torch_geometric.graphgym.model_builder.GraphGymModule'>
2025-07-05 07:05:44,169 - INFO - Inner model type: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-07-05 07:05:44,169 - INFO - Inner model has get_darts_model: True
2025-07-05 07:05:44,176 - INFO - GraphGymModule(
  (model): NASModelEdge(
    (encoder): FeatureEncoder(
      (node_encoder): LapPENodeEncoder(
        (linear_x): Linear(in_features=3, out_features=48, bias=True)
        (linear_A): Linear(in_features=2, out_features=32, bias=True)
        (pe_encoder): Sequential(
          (0): ReLU()
          (1): Linear(in_features=32, out_features=16, bias=True)
          (2): ReLU()
        )
      )
      (edge_encoder): DummyEdgeEncoder(
        (encoder): Embedding(1, 64)
      )
    )
    (darts_layers): ModuleList(
      (0): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (darts_sequential): Sequential(
      (0): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_0')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (1): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_1')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (2): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_2')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (3): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_3')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (4): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_4')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
      (5): NASLayer(
        summary: dim_h=64, global_model_type=SparseTransformer, num_heads=4, num_experts=3, routing_mode=nas, is_last_layer=False
        (expert_dropout): Dropout(p=0.3, inplace=False)
        (kv_model): ModuleDict(
          (0): GINEConv(nn=Sequential(
            (0): Linear(64, 64, bias=True)
            (1): ReLU()
            (2): Linear(64, 64, bias=True)
          ))
          (1): GatedGCNLayer()
          (2): GATv2Conv(64, 16, heads=4)
        )
        (input_choice): InputChoice(n_candidates=3, n_chosen=1, reduction='sum', label='gnn_mixture_choice_group_5')
        (self_attn): SparseGraphAttention(
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (W_o): Linear(in_features=64, out_features=64, bias=True)
        )
        (norm1_kv): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout_kv): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)
        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)
        (act_fn_ff): ReLU()
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
        (edge_processor): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(64, 1, bias=True)
          )
        )
      )
    )
  )
)
2025-07-05 07:05:44,180 - INFO - Number of parameters: 487,351
2025-07-05 07:05:44,180 - INFO - Starting optimized training: 2025-07-05 07:05:44.180682
2025-07-05 07:05:50,691 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset':
2025-07-05 07:05:50,691 - INFO -   Data(x=[1664491, 3], edge_index=[2, 85099952], y=[1664491])
2025-07-05 07:05:50,692 - INFO -   undirected: True
2025-07-05 07:05:50,692 - INFO -   num graphs: 14000
2025-07-05 07:05:50,692 - INFO -   avg num_nodes/graph: 118
2025-07-05 07:05:50,693 - INFO -   num node features: 3
2025-07-05 07:05:50,693 - INFO -   num edge features: 0
2025-07-05 07:05:50,695 - INFO -   num classes: 2
2025-07-05 07:05:50,695 - INFO - Precomputing Positional Encoding statistics: ['LapPE'] for all graphs...
2025-07-05 07:05:50,704 - INFO -   ...estimated to be undirected: True
  0%|          | 0/14000 [00:00<?, ?it/s] 26%|██▌       | 3616/14000 [00:10<00:28, 361.56it/s] 50%|████▉     | 6952/14000 [00:20<00:20, 345.11it/s] 75%|███████▌  | 10521/14000 [00:30<00:09, 350.43it/s]100%|██████████| 14000/14000 [00:39<00:00, 353.03it/s]
2025-07-05 07:06:31,233 - INFO - Done! Took 00:00:40.54
2025-07-05 07:06:31,260 - INFO - [*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset'
2025-07-05 07:06:31,264 - INFO - === STARTING OPTIMIZED TRAINING ===
2025-07-05 07:06:31,264 - INFO - Start from epoch 0
2025-07-05 07:06:31,264 - INFO - ================================================================================
2025-07-05 07:06:31,264 - INFO - STARTING TWO-PHASE NAS TRAINING
2025-07-05 07:06:31,264 - INFO - ================================================================================
2025-07-05 07:06:31,264 - INFO - Routing mode: nas
2025-07-05 07:06:31,264 - INFO - Expert types: ['GINE', 'CustomGatedGCN', 'GATV2']
2025-07-05 07:06:31,264 - INFO - Phase 1: Architecture search/initialization
2025-07-05 07:06:31,264 - INFO - Phase 2: Discrete training with uncertainty (NO variance)
2025-07-05 07:06:31,264 - INFO - ============================================================
2025-07-05 07:06:31,264 - INFO - PHASE 1: ARCHITECTURE SEARCH/INITIALIZATION
2025-07-05 07:06:31,264 - INFO - ============================================================
2025-07-05 07:06:31,264 - INFO - Splitting dataset for DARTS:
2025-07-05 07:06:31,264 - INFO -   Original train size: 10000
2025-07-05 07:06:31,264 - INFO -   DARTS train size: 6000 (60.0%)
2025-07-05 07:06:31,265 - INFO -   DARTS val size: 4000 (40.0%)
2025-07-05 07:06:31,265 - INFO - Found GraphGym wrapper, using inner model: <class 'graphgps.network.NAS_model_edge.NASModelEdge'>
2025-07-05 07:06:31,266 - INFO - Successfully configured model for DARTS training
2025-07-05 07:06:31,266 - INFO - NAS MODE: Running 20 epochs with DARTS
2025-07-05 07:06:31,266 - INFO - DARTS Configuration:
2025-07-05 07:06:31,266 - INFO -   Epochs: 20
2025-07-05 07:06:31,266 - INFO -   Architecture LR: 0.0004
2025-07-05 07:06:31,266 - INFO -   Grad clip: 5.0
2025-07-05 07:06:31,269 - INFO - Starting DARTS architecture search
2025-07-05 07:06:38,018 - WARNING - Epoch [1/20] Step [1/125]  acc 0.389196 (0.389196)  loss 0.698763 (0.698763)
GPU memory consumption  GPU Memory: Allocated: 129.6 MB, Reserved: 4126.0 MB
2025-07-05 07:06:43,533 - WARNING - Epoch [1/20] Step [11/125]  acc 0.818884 (0.784259)  loss 0.574305 (0.616713)
GPU memory consumption  GPU Memory: Allocated: 140.2 MB, Reserved: 11132.0 MB
2025-07-05 07:06:49,093 - WARNING - Epoch [1/20] Step [21/125]  acc 0.815145 (0.801092)  loss 0.524340 (0.583183)
GPU memory consumption  GPU Memory: Allocated: 132.7 MB, Reserved: 11132.0 MB
2025-07-05 07:06:54,661 - WARNING - Epoch [1/20] Step [31/125]  acc 0.902451 (0.815879)  loss 0.466237 (0.553803)
GPU memory consumption  GPU Memory: Allocated: 132.8 MB, Reserved: 11132.0 MB
2025-07-05 07:07:00,059 - WARNING - Epoch [1/20] Step [41/125]  acc 0.886706 (0.833712)  loss 0.449151 (0.530810)
GPU memory consumption  GPU Memory: Allocated: 121.7 MB, Reserved: 11132.0 MB
2025-07-05 07:07:05,662 - WARNING - Epoch [1/20] Step [51/125]  acc 0.856988 (0.845800)  loss 0.446787 (0.510024)
GPU memory consumption  GPU Memory: Allocated: 120.8 MB, Reserved: 11134.0 MB
2025-07-05 07:07:11,119 - WARNING - Epoch [1/20] Step [61/125]  acc 0.889781 (0.853293)  loss 0.402230 (0.493011)
GPU memory consumption  GPU Memory: Allocated: 121.4 MB, Reserved: 11134.0 MB
2025-07-05 07:07:16,756 - WARNING - Epoch [1/20] Step [71/125]  acc 0.894088 (0.859011)  loss 0.379160 (0.477749)
GPU memory consumption  GPU Memory: Allocated: 131.6 MB, Reserved: 11134.0 MB
2025-07-05 07:07:22,356 - WARNING - Epoch [1/20] Step [81/125]  acc 0.896608 (0.863753)  loss 0.363332 (0.464051)
GPU memory consumption  GPU Memory: Allocated: 129.3 MB, Reserved: 11134.0 MB
2025-07-05 07:07:27,827 - WARNING - Epoch [1/20] Step [91/125]  acc 0.891927 (0.867025)  loss 0.350252 (0.452115)
GPU memory consumption  GPU Memory: Allocated: 129.2 MB, Reserved: 11134.0 MB
2025-07-05 07:07:33,347 - WARNING - Epoch [1/20] Step [101/125]  acc 0.895730 (0.869596)  loss 0.331033 (0.441378)
GPU memory consumption  GPU Memory: Allocated: 128.2 MB, Reserved: 11134.0 MB
2025-07-05 07:07:38,858 - WARNING - Epoch [1/20] Step [111/125]  acc 0.884354 (0.871292)  loss 0.340774 (0.432412)
GPU memory consumption  GPU Memory: Allocated: 123.7 MB, Reserved: 11134.0 MB
2025-07-05 07:07:44,244 - WARNING - Epoch [1/20] Step [121/125]  acc 0.892684 (0.872925)  loss 0.333401 (0.424238)
GPU memory consumption  GPU Memory: Allocated: 126.5 MB, Reserved: 11134.0 MB
Epoch 1 completed in 0:01:15.191032
2025-07-05 07:08:01,677 - WARNING - Epoch [2/20] Step [1/125]  acc 0.907019 (0.907019)  loss 0.304779 (0.304779)
GPU memory consumption  GPU Memory: Allocated: 129.7 MB, Reserved: 11138.0 MB
2025-07-05 07:08:07,147 - WARNING - Epoch [2/20] Step [11/125]  acc 0.897553 (0.896443)  loss 0.310580 (0.316278)
GPU memory consumption  GPU Memory: Allocated: 133.0 MB, Reserved: 11138.0 MB
2025-07-05 07:08:12,581 - WARNING - Epoch [2/20] Step [21/125]  acc 0.892954 (0.897191)  loss 0.318353 (0.311691)
GPU memory consumption  GPU Memory: Allocated: 126.6 MB, Reserved: 11146.0 MB
2025-07-05 07:08:18,070 - WARNING - Epoch [2/20] Step [31/125]  acc 0.887675 (0.896817)  loss 0.315222 (0.308698)
GPU memory consumption  GPU Memory: Allocated: 121.7 MB, Reserved: 11146.0 MB
2025-07-05 07:08:23,518 - WARNING - Epoch [2/20] Step [41/125]  acc 0.883351 (0.897207)  loss 0.309893 (0.305699)
GPU memory consumption  GPU Memory: Allocated: 123.5 MB, Reserved: 11146.0 MB
2025-07-05 07:08:29,056 - WARNING - Epoch [2/20] Step [51/125]  acc 0.883823 (0.896711)  loss 0.312190 (0.303594)
GPU memory consumption  GPU Memory: Allocated: 120.2 MB, Reserved: 11146.0 MB
2025-07-05 07:08:34,491 - WARNING - Epoch [2/20] Step [61/125]  acc 0.897816 (0.896743)  loss 0.293635 (0.302243)
GPU memory consumption  GPU Memory: Allocated: 121.3 MB, Reserved: 11146.0 MB
2025-07-05 07:08:39,847 - WARNING - Epoch [2/20] Step [71/125]  acc 0.905786 (0.897737)  loss 0.266744 (0.298577)
GPU memory consumption  GPU Memory: Allocated: 124.7 MB, Reserved: 11146.0 MB
2025-07-05 07:08:45,398 - WARNING - Epoch [2/20] Step [81/125]  acc 0.900181 (0.897797)  loss 0.282131 (0.296872)
GPU memory consumption  GPU Memory: Allocated: 134.8 MB, Reserved: 11146.0 MB
2025-07-05 07:08:50,866 - WARNING - Epoch [2/20] Step [91/125]  acc 0.915798 (0.898514)  loss 0.254065 (0.294116)
GPU memory consumption  GPU Memory: Allocated: 129.5 MB, Reserved: 11146.0 MB
2025-07-05 07:08:56,388 - WARNING - Epoch [2/20] Step [101/125]  acc 0.897697 (0.898539)  loss 0.274569 (0.292665)
GPU memory consumption  GPU Memory: Allocated: 124.6 MB, Reserved: 11146.0 MB
2025-07-05 07:09:01,991 - WARNING - Epoch [2/20] Step [111/125]  acc 0.893678 (0.898761)  loss 0.282938 (0.290940)
GPU memory consumption  GPU Memory: Allocated: 127.9 MB, Reserved: 11146.0 MB
2025-07-05 07:09:07,525 - WARNING - Epoch [2/20] Step [121/125]  acc 0.895366 (0.898819)  loss 0.282338 (0.289447)
GPU memory consumption  GPU Memory: Allocated: 129.0 MB, Reserved: 11146.0 MB
Epoch 2 completed in 0:01:08.596494
2025-07-05 07:09:25,028 - WARNING - Epoch [3/20] Step [1/125]  acc 0.884038 (0.884038)  loss 0.299802 (0.299802)
GPU memory consumption  GPU Memory: Allocated: 126.5 MB, Reserved: 11146.0 MB
2025-07-05 07:09:30,572 - WARNING - Epoch [3/20] Step [11/125]  acc 0.900000 (0.898819)  loss 0.274831 (0.272402)
GPU memory consumption  GPU Memory: Allocated: 134.9 MB, Reserved: 11146.0 MB
2025-07-05 07:09:36,067 - WARNING - Epoch [3/20] Step [21/125]  acc 0.911326 (0.897329)  loss 0.250431 (0.274087)
GPU memory consumption  GPU Memory: Allocated: 134.8 MB, Reserved: 11146.0 MB
2025-07-05 07:09:41,586 - WARNING - Epoch [3/20] Step [31/125]  acc 0.899061 (0.898646)  loss 0.268010 (0.270682)
GPU memory consumption  GPU Memory: Allocated: 128.6 MB, Reserved: 11146.0 MB
2025-07-05 07:09:47,095 - WARNING - Epoch [3/20] Step [41/125]  acc 0.905999 (0.899374)  loss 0.255439 (0.269216)
GPU memory consumption  GPU Memory: Allocated: 122.6 MB, Reserved: 11146.0 MB
2025-07-05 07:09:52,596 - WARNING - Epoch [3/20] Step [51/125]  acc 0.894175 (0.898729)  loss 0.268970 (0.269336)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 11146.0 MB
2025-07-05 07:09:58,047 - WARNING - Epoch [3/20] Step [61/125]  acc 0.902760 (0.899246)  loss 0.260630 (0.267829)
GPU memory consumption  GPU Memory: Allocated: 125.4 MB, Reserved: 11146.0 MB
2025-07-05 07:10:03,480 - WARNING - Epoch [3/20] Step [71/125]  acc 0.900181 (0.899550)  loss 0.269498 (0.267207)
GPU memory consumption  GPU Memory: Allocated: 127.7 MB, Reserved: 11146.0 MB
2025-07-05 07:10:09,013 - WARNING - Epoch [3/20] Step [81/125]  acc 0.898458 (0.899809)  loss 0.262872 (0.266214)
GPU memory consumption  GPU Memory: Allocated: 135.3 MB, Reserved: 11146.0 MB
2025-07-05 07:10:14,360 - WARNING - Epoch [3/20] Step [91/125]  acc 0.893752 (0.899659)  loss 0.275150 (0.265986)
GPU memory consumption  GPU Memory: Allocated: 121.7 MB, Reserved: 11146.0 MB
2025-07-05 07:10:19,759 - WARNING - Epoch [3/20] Step [101/125]  acc 0.894652 (0.899367)  loss 0.268918 (0.266173)
GPU memory consumption  GPU Memory: Allocated: 126.1 MB, Reserved: 11146.0 MB
2025-07-05 07:10:25,285 - WARNING - Epoch [3/20] Step [111/125]  acc 0.909744 (0.899619)  loss 0.234486 (0.265038)
GPU memory consumption  GPU Memory: Allocated: 129.3 MB, Reserved: 11146.0 MB
2025-07-05 07:10:30,745 - WARNING - Epoch [3/20] Step [121/125]  acc 0.882885 (0.899715)  loss 0.294196 (0.264405)
GPU memory consumption  GPU Memory: Allocated: 117.0 MB, Reserved: 11146.0 MB
Epoch 3 completed in 0:01:08.464669
2025-07-05 07:10:48,160 - WARNING - Epoch [4/20] Step [1/125]  acc 0.910884 (0.910884)  loss 0.236308 (0.236308)
GPU memory consumption  GPU Memory: Allocated: 131.3 MB, Reserved: 11146.0 MB
2025-07-05 07:10:53,593 - WARNING - Epoch [4/20] Step [11/125]  acc 0.903217 (0.899173)  loss 0.249093 (0.256943)
GPU memory consumption  GPU Memory: Allocated: 132.4 MB, Reserved: 11146.0 MB
2025-07-05 07:10:59,028 - WARNING - Epoch [4/20] Step [21/125]  acc 0.902439 (0.899622)  loss 0.254803 (0.257256)
GPU memory consumption  GPU Memory: Allocated: 134.0 MB, Reserved: 11146.0 MB
2025-07-05 07:11:04,567 - WARNING - Epoch [4/20] Step [31/125]  acc 0.902236 (0.900435)  loss 0.255159 (0.256606)
GPU memory consumption  GPU Memory: Allocated: 128.8 MB, Reserved: 11146.0 MB
2025-07-05 07:11:09,995 - WARNING - Epoch [4/20] Step [41/125]  acc 0.905942 (0.901072)  loss 0.243060 (0.255365)
GPU memory consumption  GPU Memory: Allocated: 122.9 MB, Reserved: 13770.0 MB
2025-07-05 07:11:15,546 - WARNING - Epoch [4/20] Step [51/125]  acc 0.902382 (0.901124)  loss 0.254985 (0.255296)
GPU memory consumption  GPU Memory: Allocated: 124.3 MB, Reserved: 13770.0 MB
2025-07-05 07:11:20,967 - WARNING - Epoch [4/20] Step [61/125]  acc 0.902371 (0.900856)  loss 0.249037 (0.255475)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 13770.0 MB
2025-07-05 07:11:26,324 - WARNING - Epoch [4/20] Step [71/125]  acc 0.904138 (0.900861)  loss 0.235416 (0.254981)
GPU memory consumption  GPU Memory: Allocated: 127.6 MB, Reserved: 13770.0 MB
2025-07-05 07:11:31,890 - WARNING - Epoch [4/20] Step [81/125]  acc 0.906134 (0.901170)  loss 0.240114 (0.254173)
GPU memory consumption  GPU Memory: Allocated: 138.6 MB, Reserved: 13770.0 MB
2025-07-05 07:11:37,360 - WARNING - Epoch [4/20] Step [91/125]  acc 0.907988 (0.901394)  loss 0.234737 (0.253325)
GPU memory consumption  GPU Memory: Allocated: 126.1 MB, Reserved: 13770.0 MB
2025-07-05 07:11:42,755 - WARNING - Epoch [4/20] Step [101/125]  acc 0.896258 (0.900783)  loss 0.262477 (0.254358)
GPU memory consumption  GPU Memory: Allocated: 122.7 MB, Reserved: 13770.0 MB
2025-07-05 07:11:48,352 - WARNING - Epoch [4/20] Step [111/125]  acc 0.897812 (0.900636)  loss 0.265997 (0.254490)
GPU memory consumption  GPU Memory: Allocated: 129.0 MB, Reserved: 13770.0 MB
2025-07-05 07:11:53,663 - WARNING - Epoch [4/20] Step [121/125]  acc 0.896542 (0.900536)  loss 0.252908 (0.254500)
GPU memory consumption  GPU Memory: Allocated: 120.0 MB, Reserved: 13770.0 MB
Epoch 4 completed in 0:01:08.270631
2025-07-05 07:12:11,024 - WARNING - Epoch [5/20] Step [1/125]  acc 0.891147 (0.891147)  loss 0.266190 (0.266190)
GPU memory consumption  GPU Memory: Allocated: 124.4 MB, Reserved: 13770.0 MB
2025-07-05 07:12:16,423 - WARNING - Epoch [5/20] Step [11/125]  acc 0.903396 (0.897582)  loss 0.255491 (0.254892)
GPU memory consumption  GPU Memory: Allocated: 135.5 MB, Reserved: 13770.0 MB
2025-07-05 07:12:21,916 - WARNING - Epoch [5/20] Step [21/125]  acc 0.899267 (0.899083)  loss 0.250217 (0.251838)
GPU memory consumption  GPU Memory: Allocated: 125.7 MB, Reserved: 13770.0 MB
2025-07-05 07:12:27,570 - WARNING - Epoch [5/20] Step [31/125]  acc 0.894912 (0.900120)  loss 0.251776 (0.250196)
GPU memory consumption  GPU Memory: Allocated: 129.6 MB, Reserved: 13770.0 MB
2025-07-05 07:12:32,985 - WARNING - Epoch [5/20] Step [41/125]  acc 0.899405 (0.900658)  loss 0.249480 (0.249832)
GPU memory consumption  GPU Memory: Allocated: 125.9 MB, Reserved: 13770.0 MB
2025-07-05 07:12:38,485 - WARNING - Epoch [5/20] Step [51/125]  acc 0.902003 (0.900185)  loss 0.251906 (0.250635)
GPU memory consumption  GPU Memory: Allocated: 121.6 MB, Reserved: 13770.0 MB
2025-07-05 07:12:44,019 - WARNING - Epoch [5/20] Step [61/125]  acc 0.908166 (0.900248)  loss 0.239664 (0.250543)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 13770.0 MB
2025-07-05 07:12:49,464 - WARNING - Epoch [5/20] Step [71/125]  acc 0.891438 (0.900557)  loss 0.265245 (0.249685)
GPU memory consumption  GPU Memory: Allocated: 121.1 MB, Reserved: 13770.0 MB
2025-07-05 07:12:54,994 - WARNING - Epoch [5/20] Step [81/125]  acc 0.900080 (0.900454)  loss 0.255145 (0.249904)
GPU memory consumption  GPU Memory: Allocated: 130.5 MB, Reserved: 13770.0 MB
2025-07-05 07:13:00,411 - WARNING - Epoch [5/20] Step [91/125]  acc 0.895174 (0.900455)  loss 0.255383 (0.249664)
GPU memory consumption  GPU Memory: Allocated: 128.3 MB, Reserved: 13770.0 MB
2025-07-05 07:13:05,859 - WARNING - Epoch [5/20] Step [101/125]  acc 0.893506 (0.900412)  loss 0.256939 (0.249398)
GPU memory consumption  GPU Memory: Allocated: 133.4 MB, Reserved: 13770.0 MB
2025-07-05 07:13:11,364 - WARNING - Epoch [5/20] Step [111/125]  acc 0.906160 (0.900769)  loss 0.236871 (0.248683)
GPU memory consumption  GPU Memory: Allocated: 127.9 MB, Reserved: 13770.0 MB
2025-07-05 07:13:16,803 - WARNING - Epoch [5/20] Step [121/125]  acc 0.913488 (0.900953)  loss 0.217595 (0.248330)
GPU memory consumption  GPU Memory: Allocated: 128.4 MB, Reserved: 13770.0 MB
Epoch 5 completed in 0:01:08.479212
2025-07-05 07:13:34,122 - WARNING - Epoch [6/20] Step [1/125]  acc 0.897740 (0.897740)  loss 0.258067 (0.258067)
GPU memory consumption  GPU Memory: Allocated: 125.3 MB, Reserved: 13770.0 MB
2025-07-05 07:13:39,519 - WARNING - Epoch [6/20] Step [11/125]  acc 0.905635 (0.899533)  loss 0.236358 (0.250834)
GPU memory consumption  GPU Memory: Allocated: 133.6 MB, Reserved: 13770.0 MB
2025-07-05 07:13:44,976 - WARNING - Epoch [6/20] Step [21/125]  acc 0.895807 (0.899198)  loss 0.257353 (0.251240)
GPU memory consumption  GPU Memory: Allocated: 131.2 MB, Reserved: 13770.0 MB
2025-07-05 07:13:50,361 - WARNING - Epoch [6/20] Step [31/125]  acc 0.900641 (0.900890)  loss 0.240823 (0.247454)
GPU memory consumption  GPU Memory: Allocated: 126.5 MB, Reserved: 13770.0 MB
2025-07-05 07:13:55,802 - WARNING - Epoch [6/20] Step [41/125]  acc 0.892284 (0.900477)  loss 0.250713 (0.247461)
GPU memory consumption  GPU Memory: Allocated: 126.8 MB, Reserved: 13770.0 MB
2025-07-05 07:14:01,333 - WARNING - Epoch [6/20] Step [51/125]  acc 0.894004 (0.900439)  loss 0.259720 (0.247539)
GPU memory consumption  GPU Memory: Allocated: 122.4 MB, Reserved: 13770.0 MB
2025-07-05 07:14:06,806 - WARNING - Epoch [6/20] Step [61/125]  acc 0.895522 (0.901450)  loss 0.260869 (0.245676)
GPU memory consumption  GPU Memory: Allocated: 125.2 MB, Reserved: 13770.0 MB
2025-07-05 07:14:12,165 - WARNING - Epoch [6/20] Step [71/125]  acc 0.895654 (0.901274)  loss 0.248878 (0.245980)
GPU memory consumption  GPU Memory: Allocated: 124.6 MB, Reserved: 13770.0 MB
2025-07-05 07:14:17,776 - WARNING - Epoch [6/20] Step [81/125]  acc 0.900246 (0.901879)  loss 0.236400 (0.244885)
GPU memory consumption  GPU Memory: Allocated: 139.7 MB, Reserved: 13770.0 MB
2025-07-05 07:14:23,155 - WARNING - Epoch [6/20] Step [91/125]  acc 0.910303 (0.901534)  loss 0.224214 (0.245521)
GPU memory consumption  GPU Memory: Allocated: 127.4 MB, Reserved: 13770.0 MB
2025-07-05 07:14:28,631 - WARNING - Epoch [6/20] Step [101/125]  acc 0.914438 (0.901422)  loss 0.220772 (0.245431)
GPU memory consumption  GPU Memory: Allocated: 131.0 MB, Reserved: 13770.0 MB
2025-07-05 07:14:34,125 - WARNING - Epoch [6/20] Step [111/125]  acc 0.908800 (0.901133)  loss 0.238023 (0.245976)
GPU memory consumption  GPU Memory: Allocated: 125.9 MB, Reserved: 13770.0 MB
2025-07-05 07:14:39,606 - WARNING - Epoch [6/20] Step [121/125]  acc 0.905477 (0.901503)  loss 0.228654 (0.245104)
GPU memory consumption  GPU Memory: Allocated: 122.6 MB, Reserved: 13770.0 MB
Epoch 6 completed in 0:01:08.230840
2025-07-05 07:14:57,014 - WARNING - Epoch [7/20] Step [1/125]  acc 0.902007 (0.902007)  loss 0.238317 (0.238317)
GPU memory consumption  GPU Memory: Allocated: 129.1 MB, Reserved: 13770.0 MB
2025-07-05 07:15:02,381 - WARNING - Epoch [7/20] Step [11/125]  acc 0.895647 (0.904885)  loss 0.253773 (0.239814)
GPU memory consumption  GPU Memory: Allocated: 131.9 MB, Reserved: 13770.0 MB
2025-07-05 07:15:07,920 - WARNING - Epoch [7/20] Step [21/125]  acc 0.913479 (0.903259)  loss 0.228304 (0.242120)
GPU memory consumption  GPU Memory: Allocated: 130.9 MB, Reserved: 13770.0 MB
2025-07-05 07:15:13,425 - WARNING - Epoch [7/20] Step [31/125]  acc 0.907001 (0.904193)  loss 0.231651 (0.239458)
GPU memory consumption  GPU Memory: Allocated: 129.2 MB, Reserved: 13770.0 MB
2025-07-05 07:15:18,835 - WARNING - Epoch [7/20] Step [41/125]  acc 0.893750 (0.902726)  loss 0.253099 (0.241757)
GPU memory consumption  GPU Memory: Allocated: 121.9 MB, Reserved: 13770.0 MB
2025-07-05 07:15:24,363 - WARNING - Epoch [7/20] Step [51/125]  acc 0.898794 (0.903081)  loss 0.239100 (0.240803)
GPU memory consumption  GPU Memory: Allocated: 124.2 MB, Reserved: 13770.0 MB
2025-07-05 07:15:29,801 - WARNING - Epoch [7/20] Step [61/125]  acc 0.903718 (0.903049)  loss 0.245013 (0.240970)
GPU memory consumption  GPU Memory: Allocated: 122.3 MB, Reserved: 13770.0 MB
2025-07-05 07:15:35,229 - WARNING - Epoch [7/20] Step [71/125]  acc 0.903502 (0.903174)  loss 0.242361 (0.240823)
GPU memory consumption  GPU Memory: Allocated: 126.9 MB, Reserved: 13770.0 MB
2025-07-05 07:15:40,792 - WARNING - Epoch [7/20] Step [81/125]  acc 0.896244 (0.902599)  loss 0.259812 (0.241652)
GPU memory consumption  GPU Memory: Allocated: 129.8 MB, Reserved: 13770.0 MB
2025-07-05 07:15:46,173 - WARNING - Epoch [7/20] Step [91/125]  acc 0.887910 (0.902218)  loss 0.289727 (0.242573)
GPU memory consumption  GPU Memory: Allocated: 122.6 MB, Reserved: 13770.0 MB
2025-07-05 07:15:51,602 - WARNING - Epoch [7/20] Step [101/125]  acc 0.901125 (0.902099)  loss 0.248279 (0.243062)
GPU memory consumption  GPU Memory: Allocated: 125.9 MB, Reserved: 13770.0 MB
2025-07-05 07:15:57,105 - WARNING - Epoch [7/20] Step [111/125]  acc 0.921093 (0.902491)  loss 0.202222 (0.242260)
GPU memory consumption  GPU Memory: Allocated: 128.4 MB, Reserved: 13770.0 MB
2025-07-05 07:16:02,557 - WARNING - Epoch [7/20] Step [121/125]  acc 0.896819 (0.902792)  loss 0.249152 (0.241658)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 13770.0 MB
Epoch 7 completed in 0:01:08.326583
2025-07-05 07:16:20,031 - WARNING - Epoch [8/20] Step [1/125]  acc 0.888180 (0.888180)  loss 0.260216 (0.260216)
GPU memory consumption  GPU Memory: Allocated: 132.4 MB, Reserved: 13770.0 MB
2025-07-05 07:16:25,471 - WARNING - Epoch [8/20] Step [11/125]  acc 0.909972 (0.904603)  loss 0.231066 (0.236058)
GPU memory consumption  GPU Memory: Allocated: 138.5 MB, Reserved: 13770.0 MB
2025-07-05 07:16:30,945 - WARNING - Epoch [8/20] Step [21/125]  acc 0.908312 (0.902871)  loss 0.240193 (0.239877)
GPU memory consumption  GPU Memory: Allocated: 133.9 MB, Reserved: 13770.0 MB
2025-07-05 07:16:36,380 - WARNING - Epoch [8/20] Step [31/125]  acc 0.894694 (0.902479)  loss 0.255850 (0.241074)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 13770.0 MB
2025-07-05 07:16:41,802 - WARNING - Epoch [8/20] Step [41/125]  acc 0.895856 (0.902754)  loss 0.258501 (0.241033)
GPU memory consumption  GPU Memory: Allocated: 120.7 MB, Reserved: 13770.0 MB
2025-07-05 07:16:47,256 - WARNING - Epoch [8/20] Step [51/125]  acc 0.903090 (0.902100)  loss 0.245629 (0.242599)
GPU memory consumption  GPU Memory: Allocated: 123.4 MB, Reserved: 13770.0 MB
2025-07-05 07:16:52,637 - WARNING - Epoch [8/20] Step [61/125]  acc 0.902571 (0.902101)  loss 0.241149 (0.242780)
GPU memory consumption  GPU Memory: Allocated: 120.8 MB, Reserved: 13770.0 MB
2025-07-05 07:16:58,128 - WARNING - Epoch [8/20] Step [71/125]  acc 0.902646 (0.902322)  loss 0.239536 (0.242016)
GPU memory consumption  GPU Memory: Allocated: 125.6 MB, Reserved: 13770.0 MB
2025-07-05 07:17:03,762 - WARNING - Epoch [8/20] Step [81/125]  acc 0.908869 (0.902611)  loss 0.224677 (0.241514)
GPU memory consumption  GPU Memory: Allocated: 129.7 MB, Reserved: 13770.0 MB
2025-07-05 07:17:09,087 - WARNING - Epoch [8/20] Step [91/125]  acc 0.907206 (0.903124)  loss 0.226797 (0.240453)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 13770.0 MB
2025-07-05 07:17:14,519 - WARNING - Epoch [8/20] Step [101/125]  acc 0.897789 (0.902814)  loss 0.265929 (0.241073)
GPU memory consumption  GPU Memory: Allocated: 128.7 MB, Reserved: 13770.0 MB
2025-07-05 07:17:20,034 - WARNING - Epoch [8/20] Step [111/125]  acc 0.898413 (0.902861)  loss 0.249153 (0.240838)
GPU memory consumption  GPU Memory: Allocated: 126.0 MB, Reserved: 13770.0 MB
2025-07-05 07:17:25,485 - WARNING - Epoch [8/20] Step [121/125]  acc 0.905445 (0.903123)  loss 0.230989 (0.239998)
GPU memory consumption  GPU Memory: Allocated: 121.9 MB, Reserved: 13770.0 MB
Epoch 8 completed in 0:01:08.203344
2025-07-05 07:17:42,894 - WARNING - Epoch [9/20] Step [1/125]  acc 0.909136 (0.909136)  loss 0.229134 (0.229134)
GPU memory consumption  GPU Memory: Allocated: 136.7 MB, Reserved: 13770.0 MB
2025-07-05 07:17:48,353 - WARNING - Epoch [9/20] Step [11/125]  acc 0.914503 (0.907355)  loss 0.215824 (0.230158)
GPU memory consumption  GPU Memory: Allocated: 135.2 MB, Reserved: 13770.0 MB
2025-07-05 07:17:53,784 - WARNING - Epoch [9/20] Step [21/125]  acc 0.896139 (0.905082)  loss 0.255709 (0.235040)
GPU memory consumption  GPU Memory: Allocated: 125.5 MB, Reserved: 13770.0 MB
2025-07-05 07:17:59,179 - WARNING - Epoch [9/20] Step [31/125]  acc 0.899443 (0.904627)  loss 0.241260 (0.235904)
GPU memory consumption  GPU Memory: Allocated: 122.4 MB, Reserved: 13770.0 MB
2025-07-05 07:18:04,617 - WARNING - Epoch [9/20] Step [41/125]  acc 0.919970 (0.904354)  loss 0.208506 (0.236251)
GPU memory consumption  GPU Memory: Allocated: 127.6 MB, Reserved: 13770.0 MB
2025-07-05 07:18:10,228 - WARNING - Epoch [9/20] Step [51/125]  acc 0.908057 (0.904616)  loss 0.231977 (0.235748)
GPU memory consumption  GPU Memory: Allocated: 130.9 MB, Reserved: 13770.0 MB
2025-07-05 07:18:15,610 - WARNING - Epoch [9/20] Step [61/125]  acc 0.878947 (0.904309)  loss 0.285169 (0.236748)
GPU memory consumption  GPU Memory: Allocated: 118.8 MB, Reserved: 13770.0 MB
2025-07-05 07:18:20,897 - WARNING - Epoch [9/20] Step [71/125]  acc 0.898772 (0.904717)  loss 0.244846 (0.236180)
GPU memory consumption  GPU Memory: Allocated: 122.3 MB, Reserved: 13770.0 MB
2025-07-05 07:18:26,523 - WARNING - Epoch [9/20] Step [81/125]  acc 0.901913 (0.904259)  loss 0.245404 (0.236988)
GPU memory consumption  GPU Memory: Allocated: 129.9 MB, Reserved: 13770.0 MB
2025-07-05 07:18:31,896 - WARNING - Epoch [9/20] Step [91/125]  acc 0.910865 (0.904206)  loss 0.219707 (0.236953)
GPU memory consumption  GPU Memory: Allocated: 127.3 MB, Reserved: 13770.0 MB
2025-07-05 07:18:37,392 - WARNING - Epoch [9/20] Step [101/125]  acc 0.906310 (0.904014)  loss 0.230416 (0.237329)
GPU memory consumption  GPU Memory: Allocated: 123.9 MB, Reserved: 13770.0 MB
2025-07-05 07:18:42,937 - WARNING - Epoch [9/20] Step [111/125]  acc 0.890743 (0.903916)  loss 0.266480 (0.237546)
GPU memory consumption  GPU Memory: Allocated: 124.7 MB, Reserved: 13770.0 MB
2025-07-05 07:18:48,408 - WARNING - Epoch [9/20] Step [121/125]  acc 0.903947 (0.904088)  loss 0.238799 (0.237295)
GPU memory consumption  GPU Memory: Allocated: 123.2 MB, Reserved: 13770.0 MB
Epoch 9 completed in 0:01:08.270389
2025-07-05 07:19:05,770 - WARNING - Epoch [10/20] Step [1/125]  acc 0.908853 (0.908853)  loss 0.231414 (0.231414)
GPU memory consumption  GPU Memory: Allocated: 129.9 MB, Reserved: 13770.0 MB
2025-07-05 07:19:11,222 - WARNING - Epoch [10/20] Step [11/125]  acc 0.898728 (0.904881)  loss 0.242239 (0.235281)
GPU memory consumption  GPU Memory: Allocated: 133.9 MB, Reserved: 13770.0 MB
2025-07-05 07:19:16,601 - WARNING - Epoch [10/20] Step [21/125]  acc 0.890101 (0.901812)  loss 0.249458 (0.239830)
GPU memory consumption  GPU Memory: Allocated: 128.1 MB, Reserved: 13770.0 MB
2025-07-05 07:19:22,122 - WARNING - Epoch [10/20] Step [31/125]  acc 0.915742 (0.903356)  loss 0.212035 (0.236885)
GPU memory consumption  GPU Memory: Allocated: 126.8 MB, Reserved: 13770.0 MB
2025-07-05 07:19:27,553 - WARNING - Epoch [10/20] Step [41/125]  acc 0.893896 (0.903872)  loss 0.256346 (0.236851)
GPU memory consumption  GPU Memory: Allocated: 124.4 MB, Reserved: 13770.0 MB
2025-07-05 07:19:33,000 - WARNING - Epoch [10/20] Step [51/125]  acc 0.897772 (0.903608)  loss 0.249445 (0.237368)
GPU memory consumption  GPU Memory: Allocated: 118.0 MB, Reserved: 13770.0 MB
2025-07-05 07:19:38,400 - WARNING - Epoch [10/20] Step [61/125]  acc 0.921168 (0.903549)  loss 0.213971 (0.237458)
GPU memory consumption  GPU Memory: Allocated: 125.3 MB, Reserved: 13770.0 MB
2025-07-05 07:19:43,768 - WARNING - Epoch [10/20] Step [71/125]  acc 0.911461 (0.903436)  loss 0.227019 (0.237514)
GPU memory consumption  GPU Memory: Allocated: 127.8 MB, Reserved: 13770.0 MB
2025-07-05 07:19:49,418 - WARNING - Epoch [10/20] Step [81/125]  acc 0.911921 (0.903677)  loss 0.227168 (0.237153)
GPU memory consumption  GPU Memory: Allocated: 136.4 MB, Reserved: 13770.0 MB
2025-07-05 07:19:54,914 - WARNING - Epoch [10/20] Step [91/125]  acc 0.904065 (0.903258)  loss 0.230901 (0.238122)
GPU memory consumption  GPU Memory: Allocated: 130.3 MB, Reserved: 13770.0 MB
2025-07-05 07:20:00,417 - WARNING - Epoch [10/20] Step [101/125]  acc 0.896579 (0.903246)  loss 0.247102 (0.238137)
GPU memory consumption  GPU Memory: Allocated: 125.7 MB, Reserved: 13770.0 MB
2025-07-05 07:20:05,959 - WARNING - Epoch [10/20] Step [111/125]  acc 0.901670 (0.902987)  loss 0.250489 (0.238722)
GPU memory consumption  GPU Memory: Allocated: 125.9 MB, Reserved: 13770.0 MB
2025-07-05 07:20:11,406 - WARNING - Epoch [10/20] Step [121/125]  acc 0.888623 (0.902518)  loss 0.254164 (0.239312)
GPU memory consumption  GPU Memory: Allocated: 122.0 MB, Reserved: 13770.0 MB
Epoch 10 completed in 0:01:08.448648
2025-07-05 07:20:28,865 - WARNING - Epoch [11/20] Step [1/125]  acc 0.896778 (0.896778)  loss 0.250258 (0.250258)
GPU memory consumption  GPU Memory: Allocated: 129.8 MB, Reserved: 13770.0 MB
2025-07-05 07:20:34,357 - WARNING - Epoch [11/20] Step [11/125]  acc 0.895337 (0.898070)  loss 0.258403 (0.249967)
GPU memory consumption  GPU Memory: Allocated: 134.6 MB, Reserved: 13770.0 MB
2025-07-05 07:20:39,741 - WARNING - Epoch [11/20] Step [21/125]  acc 0.897216 (0.900196)  loss 0.256077 (0.245787)
GPU memory consumption  GPU Memory: Allocated: 127.5 MB, Reserved: 13770.0 MB
2025-07-05 07:20:45,212 - WARNING - Epoch [11/20] Step [31/125]  acc 0.894173 (0.901691)  loss 0.256738 (0.243183)
GPU memory consumption  GPU Memory: Allocated: 123.7 MB, Reserved: 13770.0 MB
2025-07-05 07:20:50,665 - WARNING - Epoch [11/20] Step [41/125]  acc 0.907932 (0.902110)  loss 0.236320 (0.242509)
GPU memory consumption  GPU Memory: Allocated: 125.2 MB, Reserved: 13770.0 MB
2025-07-05 07:20:56,252 - WARNING - Epoch [11/20] Step [51/125]  acc 0.906773 (0.903368)  loss 0.222487 (0.239634)
GPU memory consumption  GPU Memory: Allocated: 126.2 MB, Reserved: 13770.0 MB
2025-07-05 07:21:01,659 - WARNING - Epoch [11/20] Step [61/125]  acc 0.914780 (0.903775)  loss 0.208751 (0.238285)
GPU memory consumption  GPU Memory: Allocated: 126.4 MB, Reserved: 13770.0 MB
2025-07-05 07:21:07,065 - WARNING - Epoch [11/20] Step [71/125]  acc 0.903057 (0.903828)  loss 0.237969 (0.237844)
GPU memory consumption  GPU Memory: Allocated: 121.6 MB, Reserved: 13770.0 MB
2025-07-05 07:21:12,704 - WARNING - Epoch [11/20] Step [81/125]  acc 0.905000 (0.904348)  loss 0.234261 (0.236527)
GPU memory consumption  GPU Memory: Allocated: 132.2 MB, Reserved: 13770.0 MB
2025-07-05 07:21:18,117 - WARNING - Epoch [11/20] Step [91/125]  acc 0.905115 (0.904850)  loss 0.234958 (0.235628)
GPU memory consumption  GPU Memory: Allocated: 126.6 MB, Reserved: 13770.0 MB
2025-07-05 07:21:23,570 - WARNING - Epoch [11/20] Step [101/125]  acc 0.889527 (0.904555)  loss 0.260277 (0.235920)
GPU memory consumption  GPU Memory: Allocated: 124.2 MB, Reserved: 13770.0 MB
2025-07-05 07:21:29,053 - WARNING - Epoch [11/20] Step [111/125]  acc 0.900958 (0.904458)  loss 0.249353 (0.236282)
GPU memory consumption  GPU Memory: Allocated: 126.5 MB, Reserved: 13770.0 MB
2025-07-05 07:21:34,446 - WARNING - Epoch [11/20] Step [121/125]  acc 0.896080 (0.904346)  loss 0.257306 (0.236265)
GPU memory consumption  GPU Memory: Allocated: 123.4 MB, Reserved: 13770.0 MB
Epoch 11 completed in 0:01:08.376145
2025-07-05 07:21:51,888 - WARNING - Epoch [12/20] Step [1/125]  acc 0.906475 (0.906475)  loss 0.225078 (0.225078)
GPU memory consumption  GPU Memory: Allocated: 131.4 MB, Reserved: 13770.0 MB
2025-07-05 07:21:57,390 - WARNING - Epoch [12/20] Step [11/125]  acc 0.913111 (0.904774)  loss 0.220824 (0.235157)
GPU memory consumption  GPU Memory: Allocated: 137.2 MB, Reserved: 13770.0 MB
2025-07-05 07:22:02,851 - WARNING - Epoch [12/20] Step [21/125]  acc 0.903830 (0.904597)  loss 0.234845 (0.236146)
GPU memory consumption  GPU Memory: Allocated: 126.2 MB, Reserved: 13770.0 MB
2025-07-05 07:22:08,340 - WARNING - Epoch [12/20] Step [31/125]  acc 0.916623 (0.905971)  loss 0.211701 (0.233864)
GPU memory consumption  GPU Memory: Allocated: 127.2 MB, Reserved: 13770.0 MB
2025-07-05 07:22:13,858 - WARNING - Epoch [12/20] Step [41/125]  acc 0.900961 (0.905814)  loss 0.243138 (0.233413)
GPU memory consumption  GPU Memory: Allocated: 123.5 MB, Reserved: 13770.0 MB
2025-07-05 07:22:19,358 - WARNING - Epoch [12/20] Step [51/125]  acc 0.899185 (0.904880)  loss 0.242683 (0.235163)
GPU memory consumption  GPU Memory: Allocated: 120.7 MB, Reserved: 13770.0 MB
2025-07-05 07:22:24,832 - WARNING - Epoch [12/20] Step [61/125]  acc 0.910728 (0.904841)  loss 0.218279 (0.234817)
GPU memory consumption  GPU Memory: Allocated: 126.0 MB, Reserved: 13770.0 MB
2025-07-05 07:22:30,276 - WARNING - Epoch [12/20] Step [71/125]  acc 0.907926 (0.904366)  loss 0.237071 (0.235928)
GPU memory consumption  GPU Memory: Allocated: 125.8 MB, Reserved: 13770.0 MB
2025-07-05 07:22:35,833 - WARNING - Epoch [12/20] Step [81/125]  acc 0.914235 (0.904559)  loss 0.221252 (0.235317)
GPU memory consumption  GPU Memory: Allocated: 134.9 MB, Reserved: 13770.0 MB
2025-07-05 07:22:41,305 - WARNING - Epoch [12/20] Step [91/125]  acc 0.898666 (0.904957)  loss 0.242736 (0.234470)
GPU memory consumption  GPU Memory: Allocated: 128.8 MB, Reserved: 13770.0 MB
2025-07-05 07:22:46,773 - WARNING - Epoch [12/20] Step [101/125]  acc 0.912379 (0.905260)  loss 0.218382 (0.233870)
GPU memory consumption  GPU Memory: Allocated: 130.5 MB, Reserved: 13770.0 MB
2025-07-05 07:22:52,329 - WARNING - Epoch [12/20] Step [111/125]  acc 0.899430 (0.905247)  loss 0.235107 (0.233976)
GPU memory consumption  GPU Memory: Allocated: 128.9 MB, Reserved: 13770.0 MB
2025-07-05 07:22:57,718 - WARNING - Epoch [12/20] Step [121/125]  acc 0.908213 (0.904904)  loss 0.227038 (0.234487)
GPU memory consumption  GPU Memory: Allocated: 120.9 MB, Reserved: 13770.0 MB
Epoch 12 completed in 0:01:08.607708
2025-07-05 07:23:15,107 - WARNING - Epoch [13/20] Step [1/125]  acc 0.893542 (0.893542)  loss 0.261733 (0.261733)
GPU memory consumption  GPU Memory: Allocated: 126.4 MB, Reserved: 13770.0 MB
2025-07-05 07:23:20,574 - WARNING - Epoch [13/20] Step [11/125]  acc 0.916606 (0.902995)  loss 0.208986 (0.238720)
GPU memory consumption  GPU Memory: Allocated: 144.0 MB, Reserved: 13770.0 MB
2025-07-05 07:23:26,142 - WARNING - Epoch [13/20] Step [21/125]  acc 0.901431 (0.904824)  loss 0.247287 (0.234550)
GPU memory consumption  GPU Memory: Allocated: 128.6 MB, Reserved: 13770.0 MB
2025-07-05 07:23:31,612 - WARNING - Epoch [13/20] Step [31/125]  acc 0.907374 (0.904836)  loss 0.221709 (0.233999)
GPU memory consumption  GPU Memory: Allocated: 129.0 MB, Reserved: 13770.0 MB
2025-07-05 07:23:36,986 - WARNING - Epoch [13/20] Step [41/125]  acc 0.913406 (0.904977)  loss 0.221177 (0.233363)
GPU memory consumption  GPU Memory: Allocated: 124.7 MB, Reserved: 13770.0 MB
2025-07-05 07:23:42,495 - WARNING - Epoch [13/20] Step [51/125]  acc 0.900245 (0.904848)  loss 0.243624 (0.233901)
GPU memory consumption  GPU Memory: Allocated: 120.6 MB, Reserved: 13770.0 MB
2025-07-05 07:23:47,907 - WARNING - Epoch [13/20] Step [61/125]  acc 0.902632 (0.904554)  loss 0.233919 (0.234051)
GPU memory consumption  GPU Memory: Allocated: 123.5 MB, Reserved: 13770.0 MB
2025-07-05 07:23:53,257 - WARNING - Epoch [13/20] Step [71/125]  acc 0.898967 (0.904718)  loss 0.244972 (0.233719)
GPU memory consumption  GPU Memory: Allocated: 119.8 MB, Reserved: 13770.0 MB
2025-07-05 07:23:58,842 - WARNING - Epoch [13/20] Step [81/125]  acc 0.911863 (0.904834)  loss 0.217004 (0.233584)
GPU memory consumption  GPU Memory: Allocated: 135.0 MB, Reserved: 13770.0 MB
2025-07-05 07:24:04,246 - WARNING - Epoch [13/20] Step [91/125]  acc 0.901442 (0.905003)  loss 0.246176 (0.233363)
GPU memory consumption  GPU Memory: Allocated: 125.9 MB, Reserved: 13770.0 MB
2025-07-05 07:24:09,713 - WARNING - Epoch [13/20] Step [101/125]  acc 0.917958 (0.904950)  loss 0.201884 (0.233400)
GPU memory consumption  GPU Memory: Allocated: 132.4 MB, Reserved: 13770.0 MB
2025-07-05 07:24:15,262 - WARNING - Epoch [13/20] Step [111/125]  acc 0.905352 (0.904722)  loss 0.232834 (0.233940)
GPU memory consumption  GPU Memory: Allocated: 134.0 MB, Reserved: 13770.0 MB
2025-07-05 07:24:20,681 - WARNING - Epoch [13/20] Step [121/125]  acc 0.908826 (0.905072)  loss 0.228900 (0.233276)
GPU memory consumption  GPU Memory: Allocated: 122.6 MB, Reserved: 13770.0 MB
Epoch 13 completed in 0:01:08.298786
2025-07-05 07:24:38,031 - WARNING - Epoch [14/20] Step [1/125]  acc 0.911726 (0.911726)  loss 0.222027 (0.222027)
GPU memory consumption  GPU Memory: Allocated: 129.4 MB, Reserved: 13770.0 MB
2025-07-05 07:24:43,402 - WARNING - Epoch [14/20] Step [11/125]  acc 0.902737 (0.900217)  loss 0.243227 (0.241607)
GPU memory consumption  GPU Memory: Allocated: 133.6 MB, Reserved: 13770.0 MB
2025-07-05 07:24:48,828 - WARNING - Epoch [14/20] Step [21/125]  acc 0.920775 (0.903994)  loss 0.202654 (0.234489)
GPU memory consumption  GPU Memory: Allocated: 133.9 MB, Reserved: 13770.0 MB
2025-07-05 07:24:54,356 - WARNING - Epoch [14/20] Step [31/125]  acc 0.917282 (0.905507)  loss 0.213036 (0.231565)
GPU memory consumption  GPU Memory: Allocated: 132.5 MB, Reserved: 13770.0 MB
2025-07-05 07:24:59,806 - WARNING - Epoch [14/20] Step [41/125]  acc 0.898738 (0.905206)  loss 0.245848 (0.232158)
GPU memory consumption  GPU Memory: Allocated: 120.2 MB, Reserved: 13770.0 MB
2025-07-05 07:25:05,396 - WARNING - Epoch [14/20] Step [51/125]  acc 0.907273 (0.904832)  loss 0.220971 (0.232900)
GPU memory consumption  GPU Memory: Allocated: 128.8 MB, Reserved: 13770.0 MB
2025-07-05 07:25:10,835 - WARNING - Epoch [14/20] Step [61/125]  acc 0.912349 (0.905530)  loss 0.216421 (0.231567)
GPU memory consumption  GPU Memory: Allocated: 125.3 MB, Reserved: 13770.0 MB
2025-07-05 07:25:16,196 - WARNING - Epoch [14/20] Step [71/125]  acc 0.912503 (0.905511)  loss 0.213484 (0.231746)
GPU memory consumption  GPU Memory: Allocated: 127.2 MB, Reserved: 13770.0 MB
2025-07-05 07:25:21,710 - WARNING - Epoch [14/20] Step [81/125]  acc 0.898094 (0.905056)  loss 0.245343 (0.232756)
GPU memory consumption  GPU Memory: Allocated: 131.9 MB, Reserved: 13770.0 MB
2025-07-05 07:25:27,093 - WARNING - Epoch [14/20] Step [91/125]  acc 0.902954 (0.905455)  loss 0.228785 (0.232195)
GPU memory consumption  GPU Memory: Allocated: 120.3 MB, Reserved: 13770.0 MB
2025-07-05 07:25:32,569 - WARNING - Epoch [14/20] Step [101/125]  acc 0.909717 (0.905552)  loss 0.226042 (0.231768)
GPU memory consumption  GPU Memory: Allocated: 126.7 MB, Reserved: 13770.0 MB
2025-07-05 07:25:38,119 - WARNING - Epoch [14/20] Step [111/125]  acc 0.899441 (0.905434)  loss 0.241550 (0.232003)
GPU memory consumption  GPU Memory: Allocated: 130.6 MB, Reserved: 13770.0 MB
2025-07-05 07:25:43,478 - WARNING - Epoch [14/20] Step [121/125]  acc 0.903595 (0.905145)  loss 0.230518 (0.232584)
GPU memory consumption  GPU Memory: Allocated: 121.6 MB, Reserved: 13770.0 MB
Epoch 14 completed in 0:01:08.200262
2025-07-05 07:26:00,919 - WARNING - Epoch [15/20] Step [1/125]  acc 0.917332 (0.917332)  loss 0.204691 (0.204691)
GPU memory consumption  GPU Memory: Allocated: 131.4 MB, Reserved: 13770.0 MB
2025-07-05 07:26:06,360 - WARNING - Epoch [15/20] Step [11/125]  acc 0.900080 (0.905251)  loss 0.240876 (0.233819)
GPU memory consumption  GPU Memory: Allocated: 134.3 MB, Reserved: 13770.0 MB
2025-07-05 07:26:11,738 - WARNING - Epoch [15/20] Step [21/125]  acc 0.910647 (0.904840)  loss 0.220067 (0.233559)
GPU memory consumption  GPU Memory: Allocated: 127.7 MB, Reserved: 13770.0 MB
2025-07-05 07:26:17,215 - WARNING - Epoch [15/20] Step [31/125]  acc 0.905769 (0.905131)  loss 0.242408 (0.233990)
GPU memory consumption  GPU Memory: Allocated: 123.5 MB, Reserved: 13770.0 MB
2025-07-05 07:26:22,632 - WARNING - Epoch [15/20] Step [41/125]  acc 0.908052 (0.904683)  loss 0.219288 (0.234377)
GPU memory consumption  GPU Memory: Allocated: 127.7 MB, Reserved: 13770.0 MB
2025-07-05 07:26:28,149 - WARNING - Epoch [15/20] Step [51/125]  acc 0.905186 (0.904347)  loss 0.229684 (0.234793)
GPU memory consumption  GPU Memory: Allocated: 127.1 MB, Reserved: 13770.0 MB
2025-07-05 07:26:33,553 - WARNING - Epoch [15/20] Step [61/125]  acc 0.903106 (0.903992)  loss 0.241129 (0.236179)
GPU memory consumption  GPU Memory: Allocated: 122.3 MB, Reserved: 13770.0 MB
2025-07-05 07:26:38,950 - WARNING - Epoch [15/20] Step [71/125]  acc 0.890973 (0.904057)  loss 0.253984 (0.236014)
GPU memory consumption  GPU Memory: Allocated: 122.8 MB, Reserved: 13770.0 MB
2025-07-05 07:26:44,542 - WARNING - Epoch [15/20] Step [81/125]  acc 0.903856 (0.904458)  loss 0.229379 (0.235239)
GPU memory consumption  GPU Memory: Allocated: 132.1 MB, Reserved: 13778.0 MB
2025-07-05 07:26:50,042 - WARNING - Epoch [15/20] Step [91/125]  acc 0.898982 (0.904937)  loss 0.239103 (0.233933)
GPU memory consumption  GPU Memory: Allocated: 127.5 MB, Reserved: 13778.0 MB
2025-07-05 07:26:55,558 - WARNING - Epoch [15/20] Step [101/125]  acc 0.901644 (0.904914)  loss 0.232238 (0.233902)
GPU memory consumption  GPU Memory: Allocated: 129.5 MB, Reserved: 13778.0 MB
2025-07-05 07:27:01,099 - WARNING - Epoch [15/20] Step [111/125]  acc 0.911819 (0.905126)  loss 0.211612 (0.233194)
GPU memory consumption  GPU Memory: Allocated: 126.4 MB, Reserved: 13778.0 MB
2025-07-05 07:27:06,525 - WARNING - Epoch [15/20] Step [121/125]  acc 0.909163 (0.904768)  loss 0.226546 (0.233866)
GPU memory consumption  GPU Memory: Allocated: 122.0 MB, Reserved: 13778.0 MB
Epoch 15 completed in 0:01:08.347946
2025-07-05 07:27:23,882 - WARNING - Epoch [16/20] Step [1/125]  acc 0.909592 (0.909592)  loss 0.230179 (0.230179)
GPU memory consumption  GPU Memory: Allocated: 124.3 MB, Reserved: 13778.0 MB
2025-07-05 07:27:29,291 - WARNING - Epoch [16/20] Step [11/125]  acc 0.907761 (0.903177)  loss 0.224405 (0.234983)
GPU memory consumption  GPU Memory: Allocated: 135.7 MB, Reserved: 13778.0 MB
2025-07-05 07:27:34,686 - WARNING - Epoch [16/20] Step [21/125]  acc 0.910578 (0.904554)  loss 0.224740 (0.234118)
GPU memory consumption  GPU Memory: Allocated: 128.4 MB, Reserved: 13778.0 MB
2025-07-05 07:27:40,220 - WARNING - Epoch [16/20] Step [31/125]  acc 0.916054 (0.905839)  loss 0.210963 (0.231238)
GPU memory consumption  GPU Memory: Allocated: 128.1 MB, Reserved: 13778.0 MB
2025-07-05 07:27:45,618 - WARNING - Epoch [16/20] Step [41/125]  acc 0.893316 (0.904863)  loss 0.252989 (0.233106)
GPU memory consumption  GPU Memory: Allocated: 124.7 MB, Reserved: 13778.0 MB
2025-07-05 07:27:51,081 - WARNING - Epoch [16/20] Step [51/125]  acc 0.898089 (0.904297)  loss 0.249581 (0.233699)
GPU memory consumption  GPU Memory: Allocated: 123.6 MB, Reserved: 13778.0 MB
2025-07-05 07:27:56,560 - WARNING - Epoch [16/20] Step [61/125]  acc 0.915789 (0.904658)  loss 0.207860 (0.233060)
GPU memory consumption  GPU Memory: Allocated: 128.9 MB, Reserved: 13778.0 MB
2025-07-05 07:28:01,961 - WARNING - Epoch [16/20] Step [71/125]  acc 0.906161 (0.904583)  loss 0.216818 (0.233381)
GPU memory consumption  GPU Memory: Allocated: 127.7 MB, Reserved: 13778.0 MB
2025-07-05 07:28:07,489 - WARNING - Epoch [16/20] Step [81/125]  acc 0.908094 (0.904872)  loss 0.229174 (0.232770)
GPU memory consumption  GPU Memory: Allocated: 126.6 MB, Reserved: 13778.0 MB
2025-07-05 07:28:12,893 - WARNING - Epoch [16/20] Step [91/125]  acc 0.898057 (0.905082)  loss 0.246062 (0.232495)
GPU memory consumption  GPU Memory: Allocated: 125.5 MB, Reserved: 13778.0 MB
2025-07-05 07:28:18,354 - WARNING - Epoch [16/20] Step [101/125]  acc 0.907478 (0.905265)  loss 0.228163 (0.232375)
GPU memory consumption  GPU Memory: Allocated: 124.6 MB, Reserved: 13778.0 MB
2025-07-05 07:28:23,885 - WARNING - Epoch [16/20] Step [111/125]  acc 0.911511 (0.905599)  loss 0.220785 (0.231775)
GPU memory consumption  GPU Memory: Allocated: 131.8 MB, Reserved: 13778.0 MB
2025-07-05 07:28:29,311 - WARNING - Epoch [16/20] Step [121/125]  acc 0.899239 (0.905624)  loss 0.248765 (0.231679)
GPU memory consumption  GPU Memory: Allocated: 123.3 MB, Reserved: 13778.0 MB
Epoch 16 completed in 0:01:08.175994
2025-07-05 07:28:46,698 - WARNING - Epoch [17/20] Step [1/125]  acc 0.912764 (0.912764)  loss 0.214665 (0.214665)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 13778.0 MB
2025-07-05 07:28:52,157 - WARNING - Epoch [17/20] Step [11/125]  acc 0.910938 (0.905347)  loss 0.222671 (0.230508)
GPU memory consumption  GPU Memory: Allocated: 139.8 MB, Reserved: 13778.0 MB
2025-07-05 07:28:57,610 - WARNING - Epoch [17/20] Step [21/125]  acc 0.909305 (0.905278)  loss 0.216567 (0.232203)
GPU memory consumption  GPU Memory: Allocated: 129.8 MB, Reserved: 13778.0 MB
2025-07-05 07:29:03,035 - WARNING - Epoch [17/20] Step [31/125]  acc 0.908623 (0.905450)  loss 0.219799 (0.232278)
GPU memory consumption  GPU Memory: Allocated: 130.2 MB, Reserved: 13778.0 MB
2025-07-05 07:29:08,483 - WARNING - Epoch [17/20] Step [41/125]  acc 0.901620 (0.904861)  loss 0.243663 (0.233496)
GPU memory consumption  GPU Memory: Allocated: 114.0 MB, Reserved: 13778.0 MB
2025-07-05 07:29:14,070 - WARNING - Epoch [17/20] Step [51/125]  acc 0.907717 (0.905696)  loss 0.225794 (0.231991)
GPU memory consumption  GPU Memory: Allocated: 123.2 MB, Reserved: 13778.0 MB
2025-07-05 07:29:19,443 - WARNING - Epoch [17/20] Step [61/125]  acc 0.905695 (0.905346)  loss 0.233573 (0.232777)
GPU memory consumption  GPU Memory: Allocated: 122.5 MB, Reserved: 13778.0 MB
2025-07-05 07:29:24,804 - WARNING - Epoch [17/20] Step [71/125]  acc 0.904737 (0.905343)  loss 0.231978 (0.232555)
GPU memory consumption  GPU Memory: Allocated: 126.3 MB, Reserved: 13778.0 MB
2025-07-05 07:29:30,330 - WARNING - Epoch [17/20] Step [81/125]  acc 0.909927 (0.905199)  loss 0.215140 (0.232677)
GPU memory consumption  GPU Memory: Allocated: 132.8 MB, Reserved: 13778.0 MB
2025-07-05 07:29:35,731 - WARNING - Epoch [17/20] Step [91/125]  acc 0.913161 (0.905360)  loss 0.228474 (0.232312)
GPU memory consumption  GPU Memory: Allocated: 124.2 MB, Reserved: 13778.0 MB
2025-07-05 07:29:41,238 - WARNING - Epoch [17/20] Step [101/125]  acc 0.898828 (0.905369)  loss 0.249298 (0.232332)
GPU memory consumption  GPU Memory: Allocated: 120.3 MB, Reserved: 13778.0 MB
2025-07-05 07:29:46,794 - WARNING - Epoch [17/20] Step [111/125]  acc 0.910560 (0.905429)  loss 0.222325 (0.232064)
GPU memory consumption  GPU Memory: Allocated: 121.7 MB, Reserved: 13778.0 MB
2025-07-05 07:29:52,216 - WARNING - Epoch [17/20] Step [121/125]  acc 0.909482 (0.905220)  loss 0.223517 (0.232317)
GPU memory consumption  GPU Memory: Allocated: 120.9 MB, Reserved: 13778.0 MB
Epoch 17 completed in 0:01:08.274901
2025-07-05 07:30:09,724 - WARNING - Epoch [18/20] Step [1/125]  acc 0.904642 (0.904642)  loss 0.228039 (0.228039)
GPU memory consumption  GPU Memory: Allocated: 134.3 MB, Reserved: 13778.0 MB
2025-07-05 07:30:15,442 - WARNING - Epoch [18/20] Step [11/125]  acc 0.917667 (0.906941)  loss 0.204519 (0.227811)
GPU memory consumption  GPU Memory: Allocated: 141.9 MB, Reserved: 13778.0 MB
2025-07-05 07:30:20,892 - WARNING - Epoch [18/20] Step [21/125]  acc 0.907481 (0.906242)  loss 0.231475 (0.229713)
GPU memory consumption  GPU Memory: Allocated: 128.3 MB, Reserved: 13778.0 MB
2025-07-05 07:30:26,376 - WARNING - Epoch [18/20] Step [31/125]  acc 0.891720 (0.905795)  loss 0.262860 (0.230870)
GPU memory consumption  GPU Memory: Allocated: 127.0 MB, Reserved: 13778.0 MB
2025-07-05 07:30:31,827 - WARNING - Epoch [18/20] Step [41/125]  acc 0.904999 (0.907614)  loss 0.232030 (0.226857)
GPU memory consumption  GPU Memory: Allocated: 124.4 MB, Reserved: 13778.0 MB
2025-07-05 07:30:37,369 - WARNING - Epoch [18/20] Step [51/125]  acc 0.908416 (0.907559)  loss 0.222532 (0.226679)
GPU memory consumption  GPU Memory: Allocated: 118.5 MB, Reserved: 13778.0 MB
2025-07-05 07:30:42,785 - WARNING - Epoch [18/20] Step [61/125]  acc 0.898967 (0.907279)  loss 0.236971 (0.227060)
GPU memory consumption  GPU Memory: Allocated: 118.6 MB, Reserved: 13778.0 MB
2025-07-05 07:30:48,199 - WARNING - Epoch [18/20] Step [71/125]  acc 0.906557 (0.907342)  loss 0.224010 (0.227034)
GPU memory consumption  GPU Memory: Allocated: 126.8 MB, Reserved: 13778.0 MB
2025-07-05 07:30:53,822 - WARNING - Epoch [18/20] Step [81/125]  acc 0.908295 (0.907471)  loss 0.222190 (0.226558)
GPU memory consumption  GPU Memory: Allocated: 135.0 MB, Reserved: 13778.0 MB
2025-07-05 07:30:59,186 - WARNING - Epoch [18/20] Step [91/125]  acc 0.910038 (0.907202)  loss 0.224607 (0.227407)
GPU memory consumption  GPU Memory: Allocated: 121.9 MB, Reserved: 13778.0 MB
2025-07-05 07:31:04,726 - WARNING - Epoch [18/20] Step [101/125]  acc 0.908082 (0.906959)  loss 0.219060 (0.228062)
GPU memory consumption  GPU Memory: Allocated: 128.8 MB, Reserved: 13778.0 MB
2025-07-05 07:31:10,227 - WARNING - Epoch [18/20] Step [111/125]  acc 0.911083 (0.906799)  loss 0.219984 (0.228301)
GPU memory consumption  GPU Memory: Allocated: 128.6 MB, Reserved: 13778.0 MB
2025-07-05 07:31:15,630 - WARNING - Epoch [18/20] Step [121/125]  acc 0.907857 (0.906243)  loss 0.230073 (0.229351)
GPU memory consumption  GPU Memory: Allocated: 123.2 MB, Reserved: 13778.0 MB
Epoch 18 completed in 0:01:08.648014
2025-07-05 07:31:32,966 - WARNING - Epoch [19/20] Step [1/125]  acc 0.904670 (0.904670)  loss 0.231752 (0.231752)
GPU memory consumption  GPU Memory: Allocated: 125.0 MB, Reserved: 13778.0 MB
2025-07-05 07:31:38,508 - WARNING - Epoch [19/20] Step [11/125]  acc 0.904689 (0.907606)  loss 0.235398 (0.230494)
GPU memory consumption  GPU Memory: Allocated: 137.1 MB, Reserved: 13778.0 MB
2025-07-05 07:31:44,001 - WARNING - Epoch [19/20] Step [21/125]  acc 0.895023 (0.905833)  loss 0.247560 (0.231458)
GPU memory consumption  GPU Memory: Allocated: 126.0 MB, Reserved: 13778.0 MB
2025-07-05 07:31:49,418 - WARNING - Epoch [19/20] Step [31/125]  acc 0.890411 (0.904231)  loss 0.256545 (0.233975)
GPU memory consumption  GPU Memory: Allocated: 124.2 MB, Reserved: 13778.0 MB
2025-07-05 07:31:54,768 - WARNING - Epoch [19/20] Step [41/125]  acc 0.905200 (0.905035)  loss 0.235582 (0.232573)
GPU memory consumption  GPU Memory: Allocated: 121.1 MB, Reserved: 13778.0 MB
2025-07-05 07:32:00,276 - WARNING - Epoch [19/20] Step [51/125]  acc 0.895844 (0.905205)  loss 0.248806 (0.232126)
GPU memory consumption  GPU Memory: Allocated: 123.9 MB, Reserved: 13778.0 MB
2025-07-05 07:32:05,740 - WARNING - Epoch [19/20] Step [61/125]  acc 0.902710 (0.905514)  loss 0.238374 (0.231297)
GPU memory consumption  GPU Memory: Allocated: 121.0 MB, Reserved: 13778.0 MB
2025-07-05 07:32:11,197 - WARNING - Epoch [19/20] Step [71/125]  acc 0.904035 (0.905681)  loss 0.237914 (0.231138)
GPU memory consumption  GPU Memory: Allocated: 127.8 MB, Reserved: 13778.0 MB
2025-07-05 07:32:16,728 - WARNING - Epoch [19/20] Step [81/125]  acc 0.917227 (0.905439)  loss 0.210561 (0.231787)
GPU memory consumption  GPU Memory: Allocated: 133.8 MB, Reserved: 13778.0 MB
2025-07-05 07:32:22,129 - WARNING - Epoch [19/20] Step [91/125]  acc 0.904528 (0.905420)  loss 0.237148 (0.231973)
GPU memory consumption  GPU Memory: Allocated: 128.0 MB, Reserved: 13778.0 MB
2025-07-05 07:32:27,625 - WARNING - Epoch [19/20] Step [101/125]  acc 0.911890 (0.905671)  loss 0.219810 (0.231252)
GPU memory consumption  GPU Memory: Allocated: 133.0 MB, Reserved: 13778.0 MB
2025-07-05 07:32:33,142 - WARNING - Epoch [19/20] Step [111/125]  acc 0.916211 (0.906054)  loss 0.212909 (0.230611)
GPU memory consumption  GPU Memory: Allocated: 127.4 MB, Reserved: 13778.0 MB
2025-07-05 07:32:38,512 - WARNING - Epoch [19/20] Step [121/125]  acc 0.910741 (0.905610)  loss 0.226130 (0.231558)
GPU memory consumption  GPU Memory: Allocated: 128.1 MB, Reserved: 13778.0 MB
Epoch 19 completed in 0:01:08.302003
2025-07-05 07:32:55,929 - WARNING - Epoch [20/20] Step [1/125]  acc 0.913730 (0.913730)  loss 0.219101 (0.219101)
GPU memory consumption  GPU Memory: Allocated: 129.1 MB, Reserved: 13778.0 MB
2025-07-05 07:33:01,329 - WARNING - Epoch [20/20] Step [11/125]  acc 0.898609 (0.905212)  loss 0.257853 (0.233575)
GPU memory consumption  GPU Memory: Allocated: 133.7 MB, Reserved: 13778.0 MB
2025-07-05 07:33:06,881 - WARNING - Epoch [20/20] Step [21/125]  acc 0.912730 (0.905356)  loss 0.218010 (0.232445)
GPU memory consumption  GPU Memory: Allocated: 135.0 MB, Reserved: 13778.0 MB
2025-07-05 07:33:12,322 - WARNING - Epoch [20/20] Step [31/125]  acc 0.919150 (0.903838)  loss 0.203170 (0.235329)
GPU memory consumption  GPU Memory: Allocated: 135.2 MB, Reserved: 13778.0 MB
2025-07-05 07:33:17,706 - WARNING - Epoch [20/20] Step [41/125]  acc 0.905910 (0.904014)  loss 0.224634 (0.235467)
GPU memory consumption  GPU Memory: Allocated: 121.9 MB, Reserved: 13778.0 MB
2025-07-05 07:33:23,258 - WARNING - Epoch [20/20] Step [51/125]  acc 0.911640 (0.904620)  loss 0.226551 (0.234593)
GPU memory consumption  GPU Memory: Allocated: 123.5 MB, Reserved: 13778.0 MB
2025-07-05 07:33:28,609 - WARNING - Epoch [20/20] Step [61/125]  acc 0.905330 (0.904932)  loss 0.238598 (0.234350)
GPU memory consumption  GPU Memory: Allocated: 122.6 MB, Reserved: 13778.0 MB
2025-07-05 07:33:34,054 - WARNING - Epoch [20/20] Step [71/125]  acc 0.903175 (0.904969)  loss 0.232818 (0.233954)
GPU memory consumption  GPU Memory: Allocated: 126.6 MB, Reserved: 13778.0 MB
2025-07-05 07:33:39,614 - WARNING - Epoch [20/20] Step [81/125]  acc 0.902875 (0.904826)  loss 0.232958 (0.234276)
GPU memory consumption  GPU Memory: Allocated: 134.0 MB, Reserved: 13778.0 MB
2025-07-05 07:33:44,968 - WARNING - Epoch [20/20] Step [91/125]  acc 0.902534 (0.904653)  loss 0.230859 (0.234473)
GPU memory consumption  GPU Memory: Allocated: 127.9 MB, Reserved: 13778.0 MB
2025-07-05 07:33:50,501 - WARNING - Epoch [20/20] Step [101/125]  acc 0.911117 (0.904697)  loss 0.221773 (0.234193)
GPU memory consumption  GPU Memory: Allocated: 132.4 MB, Reserved: 13778.0 MB
2025-07-05 07:33:56,027 - WARNING - Epoch [20/20] Step [111/125]  acc 0.911549 (0.904990)  loss 0.212738 (0.233280)
GPU memory consumption  GPU Memory: Allocated: 130.7 MB, Reserved: 13778.0 MB
2025-07-05 07:34:01,488 - WARNING - Epoch [20/20] Step [121/125]  acc 0.898396 (0.905074)  loss 0.244407 (0.232952)
GPU memory consumption  GPU Memory: Allocated: 126.3 MB, Reserved: 13778.0 MB
Epoch 20 completed in 0:01:08.277303
2025-07-05 07:34:18,359 - INFO - DARTS search completed in 1667.09s
2025-07-05 07:34:18,360 - INFO - 
============================================================
2025-07-05 07:34:18,360 - INFO - Layer layer_0 Expert Selection:
2025-07-05 07:34:18,360 - INFO -   Expert 0: GINE (α=0.3323)
2025-07-05 07:34:18,360 - INFO -   Expert 1: CustomGatedGCN (α=0.3331)
2025-07-05 07:34:18,360 - INFO -   Expert 2: GATV2 (α=0.3345) ← SELECTED
2025-07-05 07:34:18,360 - INFO - Selected Expert Index: 2 (GATV2)
2025-07-05 07:34:18,360 - INFO - ============================================================

2025-07-05 07:34:18,360 - INFO - 
============================================================
2025-07-05 07:34:18,360 - INFO - Layer layer_1 Expert Selection:
2025-07-05 07:34:18,360 - INFO -   Expert 0: GINE (α=0.3302)
2025-07-05 07:34:18,360 - INFO -   Expert 1: CustomGatedGCN (α=0.3342)
2025-07-05 07:34:18,360 - INFO -   Expert 2: GATV2 (α=0.3356) ← SELECTED
2025-07-05 07:34:18,360 - INFO - Selected Expert Index: 2 (GATV2)
2025-07-05 07:34:18,360 - INFO - ============================================================

2025-07-05 07:34:18,360 - INFO - 
============================================================
2025-07-05 07:34:18,360 - INFO - Layer layer_2 Expert Selection:
2025-07-05 07:34:18,360 - INFO -   Expert 0: GINE (α=0.3209)
2025-07-05 07:34:18,361 - INFO -   Expert 1: CustomGatedGCN (α=0.3664) ← SELECTED
2025-07-05 07:34:18,361 - INFO -   Expert 2: GATV2 (α=0.3128)
2025-07-05 07:34:18,361 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 07:34:18,361 - INFO - ============================================================

2025-07-05 07:34:18,361 - INFO - 
============================================================
2025-07-05 07:34:18,361 - INFO - Layer layer_3 Expert Selection:
2025-07-05 07:34:18,361 - INFO -   Expert 0: GINE (α=0.3265)
2025-07-05 07:34:18,361 - INFO -   Expert 1: CustomGatedGCN (α=0.3696) ← SELECTED
2025-07-05 07:34:18,361 - INFO -   Expert 2: GATV2 (α=0.3039)
2025-07-05 07:34:18,361 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 07:34:18,361 - INFO - ============================================================

2025-07-05 07:34:18,361 - INFO - 
============================================================
2025-07-05 07:34:18,361 - INFO - Layer layer_4 Expert Selection:
2025-07-05 07:34:18,361 - INFO -   Expert 0: GINE (α=0.3132)
2025-07-05 07:34:18,361 - INFO -   Expert 1: CustomGatedGCN (α=0.3673) ← SELECTED
2025-07-05 07:34:18,361 - INFO -   Expert 2: GATV2 (α=0.3195)
2025-07-05 07:34:18,361 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 07:34:18,361 - INFO - ============================================================

2025-07-05 07:34:18,361 - INFO - 
============================================================
2025-07-05 07:34:18,361 - INFO - Layer layer_5 Expert Selection:
2025-07-05 07:34:18,361 - INFO -   Expert 0: GINE (α=0.3005)
2025-07-05 07:34:18,361 - INFO -   Expert 1: CustomGatedGCN (α=0.3548) ← SELECTED
2025-07-05 07:34:18,361 - INFO -   Expert 2: GATV2 (α=0.3447)
2025-07-05 07:34:18,361 - INFO - Selected Expert Index: 1 (CustomGatedGCN)
2025-07-05 07:34:18,361 - INFO - ============================================================

=== MODEL PARAMETER COMPARISON ===
Original DARTS model parameters: 487,369
2025-07-05 07:34:18,872 - INFO - Layer 0: Using ONLY Expert 2 (GATV2)
2025-07-05 07:34:18,872 - INFO - DiscreteNASLayer 0: Using ONLY Expert 2 (GATV2)
2025-07-05 07:34:18,878 - INFO - Layer 1: Using ONLY Expert 2 (GATV2)
2025-07-05 07:34:18,878 - INFO - DiscreteNASLayer 1: Using ONLY Expert 2 (GATV2)
2025-07-05 07:34:18,880 - INFO - Layer 2: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 07:34:18,880 - INFO - DiscreteNASLayer 2: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 07:34:18,883 - INFO - Layer 3: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 07:34:18,883 - INFO - DiscreteNASLayer 3: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 07:34:18,886 - INFO - Layer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 07:34:18,886 - INFO - DiscreteNASLayer 4: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 07:34:18,889 - INFO - Layer 5: Using ONLY Expert 1 (CustomGatedGCN)
2025-07-05 07:34:18,889 - INFO - DiscreteNASLayer 5: Using ONLY Expert 1 (CustomGatedGCN)
Fresh discrete model parameters: 345,143
Parameter difference: -142,226
✓ Used cfg.share.dim_in (raw input) instead of self.encoder.dim_in (processed)
✓ Fresh discrete model with correct input dimensions
2025-07-05 07:34:18,901 - INFO - Replaced inner model with discrete version
2025-07-05 07:34:18,901 - INFO - Creating fresh optimizer/scheduler for discrete model...
2025-07-05 07:34:18,903 - INFO - Fresh optimizer created: AdamW
2025-07-05 07:34:18,903 - INFO - Fresh scheduler created: LambdaLR
2025-07-05 07:34:18,903 - INFO - Discrete model parameters: 345,143
2025-07-05 07:34:18,904 - INFO - ============================================================
2025-07-05 07:34:18,904 - INFO - PHASE 2: DISCRETE TRAINING WITH UNCERTAINTY
2025-07-05 07:34:18,904 - INFO - ============================================================
2025-07-05 07:34:18,904 - INFO - === Epoch 0 ===
2025-07-05 07:35:17,386 - INFO - train: {'epoch': 0, 'time_epoch': 56.6184, 'eta': 5605.22156, 'eta_hours': 1.55701, 'loss': 0.19907562, 'lr': 0.0, 'params': 345143, 'time_iter': 0.18089, 'accuracy': 0.17658, 'precision': 0.17652, 'recall': 0.99992, 'f1': 0.30007, 'auc': 0.74432, 'accuracy-SBM': 0.50001}
2025-07-05 07:35:17,418 - INFO - ...computing epoch stats took: 1.89s
2025-07-05 07:35:22,675 - INFO - val: {'epoch': 0, 'time_epoch': 5.01766, 'loss': 0.19756883, 'lr': 0, 'params': 345143, 'time_iter': 0.07965, 'accuracy': 0.17702, 'precision': 0.17702, 'recall': 1.0, 'f1': 0.3008, 'auc': 0.73944, 'accuracy-SBM': 0.5}
2025-07-05 07:35:22,697 - INFO - ...computing epoch stats took: 0.26s
2025-07-05 07:35:30,257 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:35:30,514 - INFO - test: {'epoch': 0, 'time_epoch': 5.62477, 'loss': 0.19700492, 'lr': 0, 'params': 345143, 'time_iter': 0.08928, 'accuracy': 0.17622, 'precision': 0.17622, 'recall': 1.0, 'f1': 0.29964, 'auc': 0.73177, 'accuracy-SBM': 0.5}
2025-07-05 07:35:30,547 - INFO - ...computing epoch stats took: 0.29s
2025-07-05 07:35:30,548 - INFO - > Epoch 0: took 71.6s (avg 71.6s) | Best so far: epoch 0	train_loss: 0.1991 train_accuracy-SBM: 0.5000	val_loss: 0.1976 val_accuracy-SBM: 0.5000	test_loss: 0.1970 test_accuracy-SBM: 0.5000
2025-07-05 07:35:30,548 - INFO - === Epoch 1 ===
2025-07-05 07:36:28,345 - INFO - train: {'epoch': 1, 'time_epoch': 56.37923, 'eta': 5536.88403, 'eta_hours': 1.53802, 'loss': 0.16561582, 'lr': 0.0001, 'params': 345143, 'time_iter': 0.18013, 'accuracy': 0.80572, 'precision': 0.47268, 'recall': 0.87068, 'f1': 0.61272, 'auc': 0.8826, 'accuracy-SBM': 0.83124}
2025-07-05 07:36:28,356 - INFO - ...computing epoch stats took: 1.42s
2025-07-05 07:36:33,567 - INFO - val: {'epoch': 1, 'time_epoch': 4.81501, 'loss': 0.20216415, 'lr': 0, 'params': 345143, 'time_iter': 0.07643, 'accuracy': 0.83175, 'precision': 0.90749, 'recall': 0.05515, 'f1': 0.10397, 'auc': 0.87588, 'accuracy-SBM': 0.52697}
2025-07-05 07:36:33,569 - INFO - ...computing epoch stats took: 0.40s
2025-07-05 07:36:40,620 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:36:41,011 - INFO - test: {'epoch': 1, 'time_epoch': 4.89012, 'loss': 0.20133422, 'lr': 0, 'params': 345143, 'time_iter': 0.07762, 'accuracy': 0.83252, 'precision': 0.90345, 'recall': 0.0555, 'f1': 0.10458, 'auc': 0.8736, 'accuracy-SBM': 0.52712}
2025-07-05 07:36:41,013 - INFO - ...computing epoch stats took: 0.39s
2025-07-05 07:36:41,013 - INFO - > Epoch 1: took 70.5s (avg 71.1s) | Best so far: epoch 1	train_loss: 0.1656 train_accuracy-SBM: 0.8312	val_loss: 0.2022 val_accuracy-SBM: 0.5270	test_loss: 0.2013 test_accuracy-SBM: 0.5271
2025-07-05 07:36:41,013 - INFO - === Epoch 2 ===
2025-07-05 07:37:39,837 - INFO - train: {'epoch': 2, 'time_epoch': 56.33873, 'eta': 5475.20898, 'eta_hours': 1.52089, 'loss': 0.14396076, 'lr': 0.0002, 'params': 345143, 'time_iter': 0.18, 'accuracy': 0.85429, 'precision': 0.55641, 'recall': 0.86077, 'f1': 0.67591, 'auc': 0.89973, 'accuracy-SBM': 0.85683}
2025-07-05 07:37:39,841 - INFO - ...computing epoch stats took: 2.48s
2025-07-05 07:37:45,039 - INFO - val: {'epoch': 2, 'time_epoch': 4.81129, 'loss': 0.22345581, 'lr': 0, 'params': 345143, 'time_iter': 0.07637, 'accuracy': 0.82474, 'precision': 0.90485, 'recall': 0.0111, 'f1': 0.02193, 'auc': 0.90889, 'accuracy-SBM': 0.50542}
2025-07-05 07:37:45,042 - INFO - ...computing epoch stats took: 0.39s
2025-07-05 07:37:52,018 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:37:52,434 - INFO - test: {'epoch': 2, 'time_epoch': 4.8205, 'loss': 0.22275633, 'lr': 0, 'params': 345143, 'time_iter': 0.07652, 'accuracy': 0.82543, 'precision': 0.92094, 'recall': 0.01027, 'f1': 0.02031, 'auc': 0.90816, 'accuracy-SBM': 0.50504}
2025-07-05 07:37:52,436 - INFO - ...computing epoch stats took: 0.42s
2025-07-05 07:37:52,436 - INFO - > Epoch 2: took 71.4s (avg 71.2s) | Best so far: epoch 1	train_loss: 0.1656 train_accuracy-SBM: 0.8312	val_loss: 0.2022 val_accuracy-SBM: 0.5270	test_loss: 0.2013 test_accuracy-SBM: 0.5271
2025-07-05 07:37:52,436 - INFO - === Epoch 3 ===
2025-07-05 07:38:49,729 - INFO - train: {'epoch': 3, 'time_epoch': 55.8951, 'eta': 5405.55499, 'eta_hours': 1.50154, 'loss': 0.12692904, 'lr': 0.0003, 'params': 345143, 'time_iter': 0.17858, 'accuracy': 0.85764, 'precision': 0.56332, 'recall': 0.86087, 'f1': 0.68101, 'auc': 0.91251, 'accuracy-SBM': 0.85891}
2025-07-05 07:38:54,927 - INFO - val: {'epoch': 3, 'time_epoch': 4.78841, 'loss': 0.12427711, 'lr': 0, 'params': 345143, 'time_iter': 0.07601, 'accuracy': 0.8352, 'precision': 0.5213, 'recall': 0.84464, 'f1': 0.6447, 'auc': 0.92005, 'accuracy-SBM': 0.8389}
2025-07-05 07:39:01,876 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:39:02,329 - INFO - test: {'epoch': 3, 'time_epoch': 4.79228, 'loss': 0.12350432, 'lr': 0, 'params': 345143, 'time_iter': 0.07607, 'accuracy': 0.83719, 'precision': 0.52355, 'recall': 0.84588, 'f1': 0.64678, 'auc': 0.92034, 'accuracy-SBM': 0.8406}
2025-07-05 07:39:02,331 - INFO - > Epoch 3: took 69.9s (avg 70.9s) | Best so far: epoch 3	train_loss: 0.1269 train_accuracy-SBM: 0.8589	val_loss: 0.1243 val_accuracy-SBM: 0.8389	test_loss: 0.1235 test_accuracy-SBM: 0.8406
2025-07-05 07:39:02,331 - INFO - === Epoch 4 ===
2025-07-05 07:40:00,478 - INFO - train: {'epoch': 4, 'time_epoch': 55.8772, 'eta': 5341.0644, 'eta_hours': 1.48363, 'loss': 0.11413567, 'lr': 0.0004, 'params': 345143, 'time_iter': 0.17852, 'accuracy': 0.85929, 'precision': 0.56686, 'recall': 0.85998, 'f1': 0.68331, 'auc': 0.92266, 'accuracy-SBM': 0.85956}
2025-07-05 07:40:05,639 - INFO - val: {'epoch': 4, 'time_epoch': 4.74305, 'loss': 0.14146121, 'lr': 0, 'params': 345143, 'time_iter': 0.07529, 'accuracy': 0.88184, 'precision': 0.71169, 'recall': 0.55898, 'f1': 0.62616, 'auc': 0.91855, 'accuracy-SBM': 0.75514}
2025-07-05 07:40:12,502 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:40:12,924 - INFO - test: {'epoch': 4, 'time_epoch': 4.82277, 'loss': 0.14055211, 'lr': 0, 'params': 345143, 'time_iter': 0.07655, 'accuracy': 0.8827, 'precision': 0.71126, 'recall': 0.56284, 'f1': 0.6284, 'auc': 0.91893, 'accuracy-SBM': 0.75698}
2025-07-05 07:40:12,926 - INFO - > Epoch 4: took 70.6s (avg 70.8s) | Best so far: epoch 3	train_loss: 0.1269 train_accuracy-SBM: 0.8589	val_loss: 0.1243 val_accuracy-SBM: 0.8389	test_loss: 0.1235 test_accuracy-SBM: 0.8406
2025-07-05 07:40:12,927 - INFO - === Epoch 5 ===
2025-07-05 07:41:11,338 - INFO - train: {'epoch': 5, 'time_epoch': 56.10445, 'eta': 5283.00521, 'eta_hours': 1.4675, 'loss': 0.10552313, 'lr': 0.0005, 'params': 345143, 'time_iter': 0.17925, 'accuracy': 0.8611, 'precision': 0.5708, 'recall': 0.85919, 'f1': 0.68591, 'auc': 0.92894, 'accuracy-SBM': 0.86035}
2025-07-05 07:41:16,534 - INFO - val: {'epoch': 5, 'time_epoch': 4.79048, 'loss': 0.20468138, 'lr': 0, 'params': 345143, 'time_iter': 0.07604, 'accuracy': 0.8755, 'precision': 0.88054, 'recall': 0.34326, 'f1': 0.49396, 'auc': 0.89627, 'accuracy-SBM': 0.66662}
2025-07-05 07:41:23,468 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:41:23,863 - INFO - test: {'epoch': 5, 'time_epoch': 4.81457, 'loss': 0.20259465, 'lr': 0, 'params': 345143, 'time_iter': 0.07642, 'accuracy': 0.8766, 'precision': 0.87939, 'recall': 0.34738, 'f1': 0.49803, 'auc': 0.896, 'accuracy-SBM': 0.66859}
2025-07-05 07:41:23,868 - INFO - > Epoch 5: took 70.9s (avg 70.8s) | Best so far: epoch 3	train_loss: 0.1269 train_accuracy-SBM: 0.8589	val_loss: 0.1243 val_accuracy-SBM: 0.8389	test_loss: 0.1235 test_accuracy-SBM: 0.8406
2025-07-05 07:41:23,868 - INFO - === Epoch 6 ===
2025-07-05 07:42:22,136 - INFO - train: {'epoch': 6, 'time_epoch': 55.93186, 'eta': 5223.2116, 'eta_hours': 1.45089, 'loss': 0.10030258, 'lr': 0.00049986, 'params': 345143, 'time_iter': 0.1787, 'accuracy': 0.86136, 'precision': 0.57128, 'recall': 0.85981, 'f1': 0.68646, 'auc': 0.93333, 'accuracy-SBM': 0.86075}
2025-07-05 07:42:27,300 - INFO - val: {'epoch': 6, 'time_epoch': 4.77329, 'loss': 0.16523913, 'lr': 0, 'params': 345143, 'time_iter': 0.07577, 'accuracy': 0.88596, 'precision': 0.83777, 'recall': 0.44126, 'f1': 0.57805, 'auc': 0.91943, 'accuracy-SBM': 0.71144}
2025-07-05 07:42:34,155 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:42:34,544 - INFO - test: {'epoch': 6, 'time_epoch': 4.8327, 'loss': 0.163773, 'lr': 0, 'params': 345143, 'time_iter': 0.07671, 'accuracy': 0.88673, 'precision': 0.83608, 'recall': 0.44433, 'f1': 0.58028, 'auc': 0.91955, 'accuracy-SBM': 0.71285}
2025-07-05 07:42:34,546 - INFO - > Epoch 6: took 70.7s (avg 70.8s) | Best so far: epoch 3	train_loss: 0.1269 train_accuracy-SBM: 0.8589	val_loss: 0.1243 val_accuracy-SBM: 0.8389	test_loss: 0.1235 test_accuracy-SBM: 0.8406
2025-07-05 07:42:34,546 - INFO - === Epoch 7 ===
2025-07-05 07:43:32,729 - INFO - train: {'epoch': 7, 'time_epoch': 55.94569, 'eta': 5164.54248, 'eta_hours': 1.4346, 'loss': 0.09746343, 'lr': 0.00049945, 'params': 345143, 'time_iter': 0.17874, 'accuracy': 0.86054, 'precision': 0.56925, 'recall': 0.86286, 'f1': 0.68595, 'auc': 0.93546, 'accuracy-SBM': 0.86145}
2025-07-05 07:43:37,696 - INFO - val: {'epoch': 7, 'time_epoch': 4.73144, 'loss': 0.11351931, 'lr': 0, 'params': 345143, 'time_iter': 0.0751, 'accuracy': 0.7325, 'precision': 0.39382, 'recall': 0.94786, 'f1': 0.55644, 'auc': 0.93133, 'accuracy-SBM': 0.81702}
2025-07-05 07:43:44,540 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:43:44,977 - INFO - test: {'epoch': 7, 'time_epoch': 4.81204, 'loss': 0.11216595, 'lr': 0, 'params': 345143, 'time_iter': 0.07638, 'accuracy': 0.73633, 'precision': 0.39604, 'recall': 0.94516, 'f1': 0.55818, 'auc': 0.93179, 'accuracy-SBM': 0.81841}
2025-07-05 07:43:44,979 - INFO - > Epoch 7: took 70.4s (avg 70.8s) | Best so far: epoch 3	train_loss: 0.1269 train_accuracy-SBM: 0.8589	val_loss: 0.1243 val_accuracy-SBM: 0.8389	test_loss: 0.1235 test_accuracy-SBM: 0.8406
2025-07-05 07:43:44,979 - INFO - === Epoch 8 ===
2025-07-05 07:44:43,258 - INFO - train: {'epoch': 8, 'time_epoch': 55.94448, 'eta': 5106.46628, 'eta_hours': 1.41846, 'loss': 0.09560063, 'lr': 0.00049877, 'params': 345143, 'time_iter': 0.17874, 'accuracy': 0.8607, 'precision': 0.56952, 'recall': 0.86368, 'f1': 0.68641, 'auc': 0.93687, 'accuracy-SBM': 0.86187}
2025-07-05 07:44:48,350 - INFO - val: {'epoch': 8, 'time_epoch': 4.71284, 'loss': 0.36615826, 'lr': 0, 'params': 345143, 'time_iter': 0.07481, 'accuracy': 0.8316, 'precision': 0.83931, 'recall': 0.06022, 'f1': 0.11238, 'auc': 0.85841, 'accuracy-SBM': 0.52887}
2025-07-05 07:44:55,520 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:44:55,925 - INFO - test: {'epoch': 8, 'time_epoch': 4.78766, 'loss': 0.36469588, 'lr': 0, 'params': 345143, 'time_iter': 0.07599, 'accuracy': 0.83252, 'precision': 0.84985, 'recall': 0.06027, 'f1': 0.11255, 'auc': 0.85897, 'accuracy-SBM': 0.52899}
2025-07-05 07:44:55,927 - INFO - > Epoch 8: took 70.9s (avg 70.8s) | Best so far: epoch 3	train_loss: 0.1269 train_accuracy-SBM: 0.8589	val_loss: 0.1243 val_accuracy-SBM: 0.8389	test_loss: 0.1235 test_accuracy-SBM: 0.8406
2025-07-05 07:44:55,927 - INFO - === Epoch 9 ===
2025-07-05 07:45:54,126 - INFO - train: {'epoch': 9, 'time_epoch': 55.90152, 'eta': 5048.42983, 'eta_hours': 1.40234, 'loss': 0.0944838, 'lr': 0.00049782, 'params': 345143, 'time_iter': 0.1786, 'accuracy': 0.86079, 'precision': 0.56966, 'recall': 0.86414, 'f1': 0.68666, 'auc': 0.93743, 'accuracy-SBM': 0.8621}
2025-07-05 07:45:59,083 - INFO - val: {'epoch': 9, 'time_epoch': 4.71881, 'loss': 0.15469259, 'lr': 0, 'params': 345143, 'time_iter': 0.0749, 'accuracy': 0.56458, 'precision': 0.28708, 'recall': 0.98404, 'f1': 0.44448, 'auc': 0.92694, 'accuracy-SBM': 0.7292}
2025-07-05 07:46:06,026 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:46:06,271 - INFO - test: {'epoch': 9, 'time_epoch': 4.79907, 'loss': 0.15283496, 'lr': 0, 'params': 345143, 'time_iter': 0.07618, 'accuracy': 0.56882, 'precision': 0.28808, 'recall': 0.98337, 'f1': 0.44561, 'auc': 0.92719, 'accuracy-SBM': 0.73176}
2025-07-05 07:46:06,273 - INFO - > Epoch 9: took 70.3s (avg 70.7s) | Best so far: epoch 3	train_loss: 0.1269 train_accuracy-SBM: 0.8589	val_loss: 0.1243 val_accuracy-SBM: 0.8389	test_loss: 0.1235 test_accuracy-SBM: 0.8406
2025-07-05 07:46:06,273 - INFO - === Epoch 10 ===
2025-07-05 07:47:02,631 - INFO - train: {'epoch': 10, 'time_epoch': 55.95133, 'eta': 4991.18454, 'eta_hours': 1.38644, 'loss': 0.09377757, 'lr': 0.00049659, 'params': 345143, 'time_iter': 0.17876, 'accuracy': 0.86046, 'precision': 0.56893, 'recall': 0.86437, 'f1': 0.6862, 'auc': 0.93797, 'accuracy-SBM': 0.86199}
2025-07-05 07:47:07,834 - INFO - val: {'epoch': 10, 'time_epoch': 4.78217, 'loss': 0.12501232, 'lr': 0, 'params': 345143, 'time_iter': 0.07591, 'accuracy': 0.8946, 'precision': 0.71325, 'recall': 0.67658, 'f1': 0.69443, 'auc': 0.92498, 'accuracy-SBM': 0.80904}
2025-07-05 07:47:14,842 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:47:15,249 - INFO - test: {'epoch': 10, 'time_epoch': 4.83953, 'loss': 0.12467147, 'lr': 0, 'params': 345143, 'time_iter': 0.07682, 'accuracy': 0.89584, 'precision': 0.71736, 'recall': 0.6748, 'f1': 0.69543, 'auc': 0.92529, 'accuracy-SBM': 0.80896}
2025-07-05 07:47:15,251 - INFO - > Epoch 10: took 69.0s (avg 70.6s) | Best so far: epoch 3	train_loss: 0.1269 train_accuracy-SBM: 0.8589	val_loss: 0.1243 val_accuracy-SBM: 0.8389	test_loss: 0.1235 test_accuracy-SBM: 0.8406
2025-07-05 07:47:15,252 - INFO - === Epoch 11 ===
2025-07-05 07:48:13,394 - INFO - train: {'epoch': 11, 'time_epoch': 55.86225, 'eta': 4933.50166, 'eta_hours': 1.37042, 'loss': 0.09321457, 'lr': 0.00049509, 'params': 345143, 'time_iter': 0.17847, 'accuracy': 0.86003, 'precision': 0.56793, 'recall': 0.86555, 'f1': 0.68585, 'auc': 0.93819, 'accuracy-SBM': 0.8622}
2025-07-05 07:48:18,528 - INFO - val: {'epoch': 11, 'time_epoch': 4.74243, 'loss': 0.21236081, 'lr': 0, 'params': 345143, 'time_iter': 0.07528, 'accuracy': 0.87294, 'precision': 0.81012, 'recall': 0.36863, 'f1': 0.5067, 'auc': 0.9042, 'accuracy-SBM': 0.67502}
2025-07-05 07:48:25,584 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:48:25,974 - INFO - test: {'epoch': 11, 'time_epoch': 4.77768, 'loss': 0.21217718, 'lr': 0, 'params': 345143, 'time_iter': 0.07584, 'accuracy': 0.8739, 'precision': 0.80965, 'recall': 0.37184, 'f1': 0.50963, 'auc': 0.90428, 'accuracy-SBM': 0.67657}
2025-07-05 07:48:25,976 - INFO - > Epoch 11: took 70.7s (avg 70.6s) | Best so far: epoch 3	train_loss: 0.1269 train_accuracy-SBM: 0.8589	val_loss: 0.1243 val_accuracy-SBM: 0.8389	test_loss: 0.1235 test_accuracy-SBM: 0.8406
2025-07-05 07:48:25,977 - INFO - === Epoch 12 ===
2025-07-05 07:49:23,893 - INFO - train: {'epoch': 12, 'time_epoch': 55.62435, 'eta': 4874.50676, 'eta_hours': 1.35403, 'loss': 0.09293351, 'lr': 0.00049333, 'params': 345143, 'time_iter': 0.17771, 'accuracy': 0.86042, 'precision': 0.56883, 'recall': 0.86471, 'f1': 0.68624, 'auc': 0.93832, 'accuracy-SBM': 0.86211}
2025-07-05 07:49:28,857 - INFO - val: {'epoch': 12, 'time_epoch': 4.7051, 'loss': 0.11970111, 'lr': 0, 'params': 345143, 'time_iter': 0.07468, 'accuracy': 0.69681, 'precision': 0.36354, 'recall': 0.94938, 'f1': 0.52575, 'auc': 0.9234, 'accuracy-SBM': 0.79593}
2025-07-05 07:49:36,121 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:49:36,538 - INFO - test: {'epoch': 12, 'time_epoch': 4.821, 'loss': 0.11837351, 'lr': 0, 'params': 345143, 'time_iter': 0.07652, 'accuracy': 0.70016, 'precision': 0.36495, 'recall': 0.94788, 'f1': 0.527, 'auc': 0.92388, 'accuracy-SBM': 0.79752}
2025-07-05 07:49:36,540 - INFO - > Epoch 12: took 70.6s (avg 70.6s) | Best so far: epoch 3	train_loss: 0.1269 train_accuracy-SBM: 0.8589	val_loss: 0.1243 val_accuracy-SBM: 0.8389	test_loss: 0.1235 test_accuracy-SBM: 0.8406
2025-07-05 07:49:36,540 - INFO - === Epoch 13 ===
2025-07-05 07:50:33,848 - INFO - train: {'epoch': 13, 'time_epoch': 55.87757, 'eta': 4817.54888, 'eta_hours': 1.33821, 'loss': 0.09249797, 'lr': 0.0004913, 'params': 345143, 'time_iter': 0.17852, 'accuracy': 0.86044, 'precision': 0.56878, 'recall': 0.86554, 'f1': 0.68646, 'auc': 0.93867, 'accuracy-SBM': 0.86244}
2025-07-05 07:50:39,030 - INFO - val: {'epoch': 13, 'time_epoch': 4.77351, 'loss': 0.43248355, 'lr': 0, 'params': 345143, 'time_iter': 0.07577, 'accuracy': 0.83103, 'precision': 0.85736, 'recall': 0.05455, 'f1': 0.10257, 'auc': 0.69951, 'accuracy-SBM': 0.5263}
2025-07-05 07:50:46,345 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:50:46,733 - INFO - test: {'epoch': 13, 'time_epoch': 4.83403, 'loss': 0.43101685, 'lr': 0, 'params': 345143, 'time_iter': 0.07673, 'accuracy': 0.83162, 'precision': 0.86479, 'recall': 0.05272, 'f1': 0.09937, 'auc': 0.70279, 'accuracy-SBM': 0.52548}
2025-07-05 07:50:46,735 - INFO - > Epoch 13: took 70.2s (avg 70.6s) | Best so far: epoch 3	train_loss: 0.1269 train_accuracy-SBM: 0.8589	val_loss: 0.1243 val_accuracy-SBM: 0.8389	test_loss: 0.1235 test_accuracy-SBM: 0.8406
2025-07-05 07:50:46,735 - INFO - === Epoch 14 ===
2025-07-05 07:51:43,914 - INFO - train: {'epoch': 14, 'time_epoch': 55.86901, 'eta': 4760.68651, 'eta_hours': 1.32241, 'loss': 0.09221243, 'lr': 0.00048901, 'params': 345143, 'time_iter': 0.1785, 'accuracy': 0.86068, 'precision': 0.56932, 'recall': 0.86539, 'f1': 0.6868, 'auc': 0.93888, 'accuracy-SBM': 0.86253}
2025-07-05 07:51:48,896 - INFO - val: {'epoch': 14, 'time_epoch': 4.72341, 'loss': 0.14199243, 'lr': 0, 'params': 345143, 'time_iter': 0.07497, 'accuracy': 0.58996, 'precision': 0.2988, 'recall': 0.97742, 'f1': 0.45768, 'auc': 0.91982, 'accuracy-SBM': 0.74202}
2025-07-05 07:51:56,046 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:51:56,284 - INFO - test: {'epoch': 14, 'time_epoch': 4.84288, 'loss': 0.14024672, 'lr': 0, 'params': 345143, 'time_iter': 0.07687, 'accuracy': 0.59461, 'precision': 0.30012, 'recall': 0.97635, 'f1': 0.45911, 'auc': 0.92023, 'accuracy-SBM': 0.74465}
2025-07-05 07:51:56,286 - INFO - > Epoch 14: took 69.6s (avg 70.5s) | Best so far: epoch 3	train_loss: 0.1269 train_accuracy-SBM: 0.8589	val_loss: 0.1243 val_accuracy-SBM: 0.8389	test_loss: 0.1235 test_accuracy-SBM: 0.8406
2025-07-05 07:51:56,286 - INFO - === Epoch 15 ===
2025-07-05 07:52:54,581 - INFO - train: {'epoch': 15, 'time_epoch': 56.00031, 'eta': 4704.63766, 'eta_hours': 1.30684, 'loss': 0.09201128, 'lr': 0.00048645, 'params': 345143, 'time_iter': 0.17891, 'accuracy': 0.86093, 'precision': 0.5699, 'recall': 0.86482, 'f1': 0.68705, 'auc': 0.93896, 'accuracy-SBM': 0.86246}
2025-07-05 07:52:59,743 - INFO - val: {'epoch': 15, 'time_epoch': 4.76664, 'loss': 0.09875947, 'lr': 0, 'params': 345143, 'time_iter': 0.07566, 'accuracy': 0.89069, 'precision': 0.66234, 'recall': 0.78028, 'f1': 0.71649, 'auc': 0.9365, 'accuracy-SBM': 0.84736}
2025-07-05 07:53:06,830 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:53:07,258 - INFO - test: {'epoch': 15, 'time_epoch': 4.7962, 'loss': 0.09818322, 'lr': 0, 'params': 345143, 'time_iter': 0.07613, 'accuracy': 0.89251, 'precision': 0.66623, 'recall': 0.78161, 'f1': 0.71932, 'auc': 0.93708, 'accuracy-SBM': 0.84892}
2025-07-05 07:53:07,260 - INFO - > Epoch 15: took 71.0s (avg 70.5s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 07:53:07,260 - INFO - === Epoch 16 ===
2025-07-05 07:54:04,591 - INFO - train: {'epoch': 16, 'time_epoch': 56.00598, 'eta': 4648.62219, 'eta_hours': 1.29128, 'loss': 0.09183826, 'lr': 0.00048364, 'params': 345143, 'time_iter': 0.17893, 'accuracy': 0.86068, 'precision': 0.56937, 'recall': 0.86488, 'f1': 0.68668, 'auc': 0.93914, 'accuracy-SBM': 0.86233}
2025-07-05 07:54:09,619 - INFO - val: {'epoch': 16, 'time_epoch': 4.779, 'loss': 0.16899726, 'lr': 0, 'params': 345143, 'time_iter': 0.07586, 'accuracy': 0.47965, 'precision': 0.25287, 'recall': 0.99228, 'f1': 0.40304, 'auc': 0.92695, 'accuracy-SBM': 0.68084}
2025-07-05 07:54:16,621 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:54:16,852 - INFO - test: {'epoch': 16, 'time_epoch': 4.85102, 'loss': 0.16741912, 'lr': 0, 'params': 345143, 'time_iter': 0.077, 'accuracy': 0.48424, 'precision': 0.25365, 'recall': 0.99195, 'f1': 0.404, 'auc': 0.92745, 'accuracy-SBM': 0.68379}
2025-07-05 07:54:16,854 - INFO - > Epoch 16: took 69.6s (avg 70.5s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 07:54:16,854 - INFO - === Epoch 17 ===
2025-07-05 07:55:14,974 - INFO - train: {'epoch': 17, 'time_epoch': 55.90494, 'eta': 4592.14751, 'eta_hours': 1.2756, 'loss': 0.0916335, 'lr': 0.00048057, 'params': 345143, 'time_iter': 0.17861, 'accuracy': 0.86115, 'precision': 0.57038, 'recall': 0.86464, 'f1': 0.68734, 'auc': 0.93931, 'accuracy-SBM': 0.86252}
2025-07-05 07:55:19,975 - INFO - val: {'epoch': 17, 'time_epoch': 4.75491, 'loss': 0.17747308, 'lr': 0, 'params': 345143, 'time_iter': 0.07547, 'accuracy': 0.3988, 'precision': 0.22697, 'recall': 0.996, 'f1': 0.3697, 'auc': 0.92264, 'accuracy-SBM': 0.63317}
2025-07-05 07:55:27,155 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:55:27,388 - INFO - test: {'epoch': 17, 'time_epoch': 4.84004, 'loss': 0.17578618, 'lr': 0, 'params': 345143, 'time_iter': 0.07683, 'accuracy': 0.40274, 'precision': 0.22726, 'recall': 0.99543, 'f1': 0.37004, 'auc': 0.92305, 'accuracy-SBM': 0.63569}
2025-07-05 07:55:27,390 - INFO - > Epoch 17: took 70.5s (avg 70.5s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 07:55:27,390 - INFO - === Epoch 18 ===
2025-07-05 07:56:25,602 - INFO - train: {'epoch': 18, 'time_epoch': 55.927, 'eta': 4535.82681, 'eta_hours': 1.25995, 'loss': 0.09151461, 'lr': 0.00047725, 'params': 345143, 'time_iter': 0.17868, 'accuracy': 0.86167, 'precision': 0.57149, 'recall': 0.86471, 'f1': 0.68817, 'auc': 0.93939, 'accuracy-SBM': 0.86286}
2025-07-05 07:56:30,614 - INFO - val: {'epoch': 18, 'time_epoch': 4.775, 'loss': 0.19923755, 'lr': 0, 'params': 345143, 'time_iter': 0.07579, 'accuracy': 0.33858, 'precision': 0.21088, 'recall': 0.9979, 'f1': 0.34818, 'auc': 0.92389, 'accuracy-SBM': 0.59733}
2025-07-05 07:56:37,760 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:56:38,012 - INFO - test: {'epoch': 18, 'time_epoch': 4.84551, 'loss': 0.19784168, 'lr': 0, 'params': 345143, 'time_iter': 0.07691, 'accuracy': 0.33999, 'precision': 0.21048, 'recall': 0.99795, 'f1': 0.34764, 'auc': 0.92419, 'accuracy-SBM': 0.5986}
2025-07-05 07:56:38,014 - INFO - > Epoch 18: took 70.6s (avg 70.5s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 07:56:38,014 - INFO - === Epoch 19 ===
2025-07-05 07:57:36,137 - INFO - train: {'epoch': 19, 'time_epoch': 55.80945, 'eta': 4479.07531, 'eta_hours': 1.24419, 'loss': 0.09139733, 'lr': 0.00047368, 'params': 345143, 'time_iter': 0.1783, 'accuracy': 0.86145, 'precision': 0.57097, 'recall': 0.86515, 'f1': 0.68793, 'auc': 0.93945, 'accuracy-SBM': 0.8629}
2025-07-05 07:57:41,246 - INFO - val: {'epoch': 19, 'time_epoch': 4.7181, 'loss': 0.27130221, 'lr': 0, 'params': 345143, 'time_iter': 0.07489, 'accuracy': 0.86488, 'precision': 0.87615, 'recall': 0.27568, 'f1': 0.4194, 'auc': 0.89896, 'accuracy-SBM': 0.63365}
2025-07-05 07:57:48,267 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:57:48,655 - INFO - test: {'epoch': 19, 'time_epoch': 4.79562, 'loss': 0.27172841, 'lr': 0, 'params': 345143, 'time_iter': 0.07612, 'accuracy': 0.86551, 'precision': 0.87595, 'recall': 0.27587, 'f1': 0.41959, 'auc': 0.89833, 'accuracy-SBM': 0.63376}
2025-07-05 07:57:48,657 - INFO - > Epoch 19: took 70.6s (avg 70.5s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 07:57:48,657 - INFO - === Epoch 20 ===
2025-07-05 07:58:46,659 - INFO - train: {'epoch': 20, 'time_epoch': 55.76693, 'eta': 4422.25355, 'eta_hours': 1.2284, 'loss': 0.09131707, 'lr': 0.00046987, 'params': 345143, 'time_iter': 0.17817, 'accuracy': 0.86105, 'precision': 0.57007, 'recall': 0.86568, 'f1': 0.68744, 'auc': 0.93953, 'accuracy-SBM': 0.86287}
2025-07-05 07:58:51,675 - INFO - val: {'epoch': 20, 'time_epoch': 4.76214, 'loss': 0.10079064, 'lr': 0, 'params': 345143, 'time_iter': 0.07559, 'accuracy': 0.78699, 'precision': 0.45062, 'recall': 0.92758, 'f1': 0.60657, 'auc': 0.93524, 'accuracy-SBM': 0.84217}
2025-07-05 07:58:58,797 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 07:58:59,239 - INFO - test: {'epoch': 20, 'time_epoch': 4.82872, 'loss': 0.09970933, 'lr': 0, 'params': 345143, 'time_iter': 0.07665, 'accuracy': 0.78954, 'precision': 0.45255, 'recall': 0.92661, 'f1': 0.6081, 'auc': 0.93584, 'accuracy-SBM': 0.84341}
2025-07-05 07:58:59,241 - INFO - > Epoch 20: took 70.6s (avg 70.5s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 07:58:59,241 - INFO - === Epoch 21 ===
2025-07-05 07:59:57,408 - INFO - train: {'epoch': 21, 'time_epoch': 55.91376, 'eta': 4366.04826, 'eta_hours': 1.21279, 'loss': 0.09122768, 'lr': 0.00046581, 'params': 345143, 'time_iter': 0.17864, 'accuracy': 0.86202, 'precision': 0.57227, 'recall': 0.86447, 'f1': 0.68865, 'auc': 0.93963, 'accuracy-SBM': 0.86299}
2025-07-05 08:00:02,410 - INFO - val: {'epoch': 21, 'time_epoch': 4.75964, 'loss': 0.10804999, 'lr': 0, 'params': 345143, 'time_iter': 0.07555, 'accuracy': 0.75056, 'precision': 0.41035, 'recall': 0.93628, 'f1': 0.57062, 'auc': 0.93039, 'accuracy-SBM': 0.82345}
2025-07-05 08:00:09,237 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:00:09,695 - INFO - test: {'epoch': 21, 'time_epoch': 4.80612, 'loss': 0.10685633, 'lr': 0, 'params': 345143, 'time_iter': 0.07629, 'accuracy': 0.7539, 'precision': 0.41244, 'recall': 0.93385, 'f1': 0.57217, 'auc': 0.93101, 'accuracy-SBM': 0.82463}
2025-07-05 08:00:09,699 - INFO - > Epoch 21: took 70.5s (avg 70.5s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 08:00:09,699 - INFO - === Epoch 22 ===
2025-07-05 08:01:07,924 - INFO - train: {'epoch': 22, 'time_epoch': 55.91638, 'eta': 4309.87712, 'eta_hours': 1.19719, 'loss': 0.09119983, 'lr': 0.00046152, 'params': 345143, 'time_iter': 0.17865, 'accuracy': 0.86164, 'precision': 0.5714, 'recall': 0.86507, 'f1': 0.68821, 'auc': 0.93956, 'accuracy-SBM': 0.86299}
2025-07-05 08:01:13,084 - INFO - val: {'epoch': 22, 'time_epoch': 4.77316, 'loss': 0.48075493, 'lr': 0, 'params': 345143, 'time_iter': 0.07576, 'accuracy': 0.83595, 'precision': 0.83761, 'recall': 0.09092, 'f1': 0.16404, 'auc': 0.79532, 'accuracy-SBM': 0.54357}
2025-07-05 08:01:20,135 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:01:20,551 - INFO - test: {'epoch': 22, 'time_epoch': 4.8181, 'loss': 0.47828303, 'lr': 0, 'params': 345143, 'time_iter': 0.07648, 'accuracy': 0.83644, 'precision': 0.83676, 'recall': 0.08926, 'f1': 0.16131, 'auc': 0.79458, 'accuracy-SBM': 0.54277}
2025-07-05 08:01:20,553 - INFO - > Epoch 22: took 70.9s (avg 70.5s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 08:01:20,553 - INFO - === Epoch 23 ===
2025-07-05 08:02:17,794 - INFO - train: {'epoch': 23, 'time_epoch': 55.88875, 'eta': 4253.6397, 'eta_hours': 1.18157, 'loss': 0.09112462, 'lr': 0.000457, 'params': 345143, 'time_iter': 0.17856, 'accuracy': 0.8619, 'precision': 0.572, 'recall': 0.86449, 'f1': 0.68847, 'auc': 0.93958, 'accuracy-SBM': 0.86292}
2025-07-05 08:02:22,814 - INFO - val: {'epoch': 23, 'time_epoch': 4.77371, 'loss': 0.21271895, 'lr': 0, 'params': 345143, 'time_iter': 0.07577, 'accuracy': 0.33963, 'precision': 0.21118, 'recall': 0.99821, 'f1': 0.34861, 'auc': 0.92866, 'accuracy-SBM': 0.59809}
2025-07-05 08:02:29,738 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:02:29,971 - INFO - test: {'epoch': 23, 'time_epoch': 4.83451, 'loss': 0.21117977, 'lr': 0, 'params': 345143, 'time_iter': 0.07674, 'accuracy': 0.34125, 'precision': 0.21084, 'recall': 0.99828, 'f1': 0.34815, 'auc': 0.92895, 'accuracy-SBM': 0.59949}
2025-07-05 08:02:29,973 - INFO - > Epoch 23: took 69.4s (avg 70.5s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 08:02:29,974 - INFO - === Epoch 24 ===
2025-07-05 08:03:28,169 - INFO - train: {'epoch': 24, 'time_epoch': 55.91109, 'eta': 4197.49718, 'eta_hours': 1.16597, 'loss': 0.09120068, 'lr': 0.00045225, 'params': 345143, 'time_iter': 0.17863, 'accuracy': 0.86146, 'precision': 0.571, 'recall': 0.86518, 'f1': 0.68796, 'auc': 0.93953, 'accuracy-SBM': 0.86292}
2025-07-05 08:03:33,182 - INFO - val: {'epoch': 24, 'time_epoch': 4.76816, 'loss': 0.16007016, 'lr': 0, 'params': 345143, 'time_iter': 0.07569, 'accuracy': 0.52024, 'precision': 0.26802, 'recall': 0.98795, 'f1': 0.42165, 'auc': 0.92569, 'accuracy-SBM': 0.70379}
2025-07-05 08:03:41,379 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:03:41,617 - INFO - test: {'epoch': 24, 'time_epoch': 4.82758, 'loss': 0.15926687, 'lr': 0, 'params': 345143, 'time_iter': 0.07663, 'accuracy': 0.52104, 'precision': 0.26731, 'recall': 0.9868, 'f1': 0.42067, 'auc': 0.92581, 'accuracy-SBM': 0.70411}
2025-07-05 08:03:41,618 - INFO - > Epoch 24: took 71.6s (avg 70.5s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 08:03:41,619 - INFO - === Epoch 25 ===
2025-07-05 08:04:39,898 - INFO - train: {'epoch': 25, 'time_epoch': 55.91421, 'eta': 4141.38137, 'eta_hours': 1.15038, 'loss': 0.09111914, 'lr': 0.00044729, 'params': 345143, 'time_iter': 0.17864, 'accuracy': 0.86185, 'precision': 0.57179, 'recall': 0.86554, 'f1': 0.68865, 'auc': 0.93962, 'accuracy-SBM': 0.8633}
2025-07-05 08:04:44,870 - INFO - val: {'epoch': 25, 'time_epoch': 4.73114, 'loss': 0.10063905, 'lr': 0, 'params': 345143, 'time_iter': 0.0751, 'accuracy': 0.7902, 'precision': 0.45487, 'recall': 0.93309, 'f1': 0.61159, 'auc': 0.93955, 'accuracy-SBM': 0.84628}
2025-07-05 08:04:51,820 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:04:52,264 - INFO - test: {'epoch': 25, 'time_epoch': 4.7817, 'loss': 0.09925505, 'lr': 0, 'params': 345143, 'time_iter': 0.0759, 'accuracy': 0.79294, 'precision': 0.45708, 'recall': 0.93194, 'f1': 0.61334, 'auc': 0.94028, 'accuracy-SBM': 0.84757}
2025-07-05 08:04:52,266 - INFO - > Epoch 25: took 70.6s (avg 70.5s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 08:04:52,266 - INFO - === Epoch 26 ===
2025-07-05 08:05:48,387 - INFO - train: {'epoch': 26, 'time_epoch': 55.75981, 'eta': 4084.86302, 'eta_hours': 1.13468, 'loss': 0.09096827, 'lr': 0.0004421, 'params': 345143, 'time_iter': 0.17815, 'accuracy': 0.86149, 'precision': 0.57102, 'recall': 0.86558, 'f1': 0.6881, 'auc': 0.93982, 'accuracy-SBM': 0.86309}
2025-07-05 08:05:53,547 - INFO - val: {'epoch': 26, 'time_epoch': 4.73834, 'loss': 0.14049637, 'lr': 0, 'params': 345143, 'time_iter': 0.07521, 'accuracy': 0.89569, 'precision': 0.75399, 'recall': 0.6097, 'f1': 0.67421, 'auc': 0.92272, 'accuracy-SBM': 0.78345}
2025-07-05 08:06:01,109 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:06:01,511 - INFO - test: {'epoch': 26, 'time_epoch': 4.80923, 'loss': 0.14041231, 'lr': 0, 'params': 345143, 'time_iter': 0.07634, 'accuracy': 0.89648, 'precision': 0.75681, 'recall': 0.60793, 'f1': 0.67425, 'auc': 0.9232, 'accuracy-SBM': 0.78307}
2025-07-05 08:06:01,514 - INFO - > Epoch 26: took 69.2s (avg 70.5s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 08:06:01,514 - INFO - === Epoch 27 ===
2025-07-05 08:06:59,756 - INFO - train: {'epoch': 27, 'time_epoch': 55.91053, 'eta': 4028.78642, 'eta_hours': 1.11911, 'loss': 0.09087323, 'lr': 0.00043671, 'params': 345143, 'time_iter': 0.17863, 'accuracy': 0.86205, 'precision': 0.57216, 'recall': 0.86611, 'f1': 0.6891, 'auc': 0.93993, 'accuracy-SBM': 0.86364}
2025-07-05 08:07:04,782 - INFO - val: {'epoch': 27, 'time_epoch': 4.76394, 'loss': 0.13948594, 'lr': 0, 'params': 345143, 'time_iter': 0.07562, 'accuracy': 0.60392, 'precision': 0.30621, 'recall': 0.97763, 'f1': 0.46635, 'auc': 0.91813, 'accuracy-SBM': 0.75059}
2025-07-05 08:07:12,463 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:07:12,697 - INFO - test: {'epoch': 27, 'time_epoch': 4.83683, 'loss': 0.13808356, 'lr': 0, 'params': 345143, 'time_iter': 0.07678, 'accuracy': 0.6081, 'precision': 0.30739, 'recall': 0.97661, 'f1': 0.4676, 'auc': 0.91802, 'accuracy-SBM': 0.75294}
2025-07-05 08:07:12,699 - INFO - > Epoch 27: took 71.2s (avg 70.5s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 08:07:12,699 - INFO - === Epoch 28 ===
2025-07-05 08:08:10,925 - INFO - train: {'epoch': 28, 'time_epoch': 55.94532, 'eta': 3972.80646, 'eta_hours': 1.10356, 'loss': 0.0909893, 'lr': 0.00043111, 'params': 345143, 'time_iter': 0.17874, 'accuracy': 0.86242, 'precision': 0.5731, 'recall': 0.86474, 'f1': 0.68934, 'auc': 0.93967, 'accuracy-SBM': 0.86333}
2025-07-05 08:08:16,150 - INFO - val: {'epoch': 28, 'time_epoch': 4.78888, 'loss': 0.10138059, 'lr': 0, 'params': 345143, 'time_iter': 0.07601, 'accuracy': 0.79452, 'precision': 0.45934, 'recall': 0.90808, 'f1': 0.61008, 'auc': 0.92878, 'accuracy-SBM': 0.83909}
2025-07-05 08:08:23,830 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:08:24,245 - INFO - test: {'epoch': 28, 'time_epoch': 4.84413, 'loss': 0.1003715, 'lr': 0, 'params': 345143, 'time_iter': 0.07689, 'accuracy': 0.7961, 'precision': 0.46012, 'recall': 0.90615, 'f1': 0.61033, 'auc': 0.92927, 'accuracy-SBM': 0.83935}
2025-07-05 08:08:24,247 - INFO - > Epoch 28: took 71.5s (avg 70.5s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 08:08:24,247 - INFO - === Epoch 29 ===
2025-07-05 08:09:22,433 - INFO - train: {'epoch': 29, 'time_epoch': 55.91612, 'eta': 3916.76068, 'eta_hours': 1.08799, 'loss': 0.09088374, 'lr': 0.00042531, 'params': 345143, 'time_iter': 0.17865, 'accuracy': 0.86199, 'precision': 0.57213, 'recall': 0.86524, 'f1': 0.6888, 'auc': 0.93983, 'accuracy-SBM': 0.86327}
2025-07-05 08:09:27,680 - INFO - val: {'epoch': 29, 'time_epoch': 4.80467, 'loss': 0.56880698, 'lr': 0, 'params': 345143, 'time_iter': 0.07626, 'accuracy': 0.82785, 'precision': 0.88321, 'recall': 0.03171, 'f1': 0.06121, 'auc': 0.86482, 'accuracy-SBM': 0.5154}
2025-07-05 08:09:34,952 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:09:35,349 - INFO - test: {'epoch': 29, 'time_epoch': 4.86677, 'loss': 0.56639368, 'lr': 0, 'params': 345143, 'time_iter': 0.07725, 'accuracy': 0.82844, 'precision': 0.88231, 'recall': 0.03054, 'f1': 0.05903, 'auc': 0.86468, 'accuracy-SBM': 0.51483}
2025-07-05 08:09:35,351 - INFO - > Epoch 29: took 71.1s (avg 70.5s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 08:09:35,351 - INFO - === Epoch 30 ===
2025-07-05 08:10:32,602 - INFO - train: {'epoch': 30, 'time_epoch': 55.90646, 'eta': 3860.70174, 'eta_hours': 1.07242, 'loss': 0.09076846, 'lr': 0.00041932, 'params': 345143, 'time_iter': 0.17861, 'accuracy': 0.86234, 'precision': 0.57288, 'recall': 0.86509, 'f1': 0.6893, 'auc': 0.93997, 'accuracy-SBM': 0.86342}
2025-07-05 08:10:37,640 - INFO - val: {'epoch': 30, 'time_epoch': 4.77934, 'loss': 0.16996621, 'lr': 0, 'params': 345143, 'time_iter': 0.07586, 'accuracy': 0.45527, 'precision': 0.24442, 'recall': 0.99326, 'f1': 0.3923, 'auc': 0.92194, 'accuracy-SBM': 0.6664}
2025-07-05 08:10:46,131 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:10:46,381 - INFO - test: {'epoch': 30, 'time_epoch': 4.84775, 'loss': 0.16861413, 'lr': 0, 'params': 345143, 'time_iter': 0.07695, 'accuracy': 0.45771, 'precision': 0.24437, 'recall': 0.99295, 'f1': 0.39222, 'auc': 0.92277, 'accuracy-SBM': 0.66808}
2025-07-05 08:10:46,384 - INFO - > Epoch 30: took 71.0s (avg 70.6s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 08:10:46,384 - INFO - === Epoch 31 ===
2025-07-05 08:11:44,542 - INFO - train: {'epoch': 31, 'time_epoch': 55.90857, 'eta': 3804.65682, 'eta_hours': 1.05685, 'loss': 0.09066549, 'lr': 0.00041315, 'params': 345143, 'time_iter': 0.17862, 'accuracy': 0.86143, 'precision': 0.5708, 'recall': 0.86649, 'f1': 0.68823, 'auc': 0.94013, 'accuracy-SBM': 0.86342}
2025-07-05 08:11:49,552 - INFO - val: {'epoch': 31, 'time_epoch': 4.76953, 'loss': 0.16471283, 'lr': 0, 'params': 345143, 'time_iter': 0.07571, 'accuracy': 0.50448, 'precision': 0.26195, 'recall': 0.98995, 'f1': 0.41428, 'auc': 0.92424, 'accuracy-SBM': 0.695}
2025-07-05 08:11:58,840 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:11:59,083 - INFO - test: {'epoch': 31, 'time_epoch': 4.79311, 'loss': 0.16357098, 'lr': 0, 'params': 345143, 'time_iter': 0.07608, 'accuracy': 0.50622, 'precision': 0.26162, 'recall': 0.98885, 'f1': 0.41376, 'auc': 0.92442, 'accuracy-SBM': 0.69591}
2025-07-05 08:11:59,085 - INFO - > Epoch 31: took 72.7s (avg 70.6s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 08:11:59,085 - INFO - === Epoch 32 ===
2025-07-05 08:12:56,308 - INFO - train: {'epoch': 32, 'time_epoch': 55.93483, 'eta': 3748.67349, 'eta_hours': 1.0413, 'loss': 0.09073113, 'lr': 0.00040679, 'params': 345143, 'time_iter': 0.17871, 'accuracy': 0.86201, 'precision': 0.57214, 'recall': 0.86552, 'f1': 0.6889, 'auc': 0.93999, 'accuracy-SBM': 0.86339}
2025-07-05 08:13:01,464 - INFO - val: {'epoch': 32, 'time_epoch': 4.76651, 'loss': 0.17336722, 'lr': 0, 'params': 345143, 'time_iter': 0.07566, 'accuracy': 0.89479, 'precision': 0.81815, 'recall': 0.52161, 'f1': 0.63706, 'auc': 0.92403, 'accuracy-SBM': 0.74833}
2025-07-05 08:13:08,353 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:13:08,769 - INFO - test: {'epoch': 32, 'time_epoch': 4.7849, 'loss': 0.17360878, 'lr': 0, 'params': 345143, 'time_iter': 0.07595, 'accuracy': 0.89567, 'precision': 0.82215, 'recall': 0.52053, 'f1': 0.63747, 'auc': 0.92438, 'accuracy-SBM': 0.74822}
2025-07-05 08:13:08,771 - INFO - > Epoch 32: took 69.7s (avg 70.6s) | Best so far: epoch 15	train_loss: 0.0920 train_accuracy-SBM: 0.8625	val_loss: 0.0988 val_accuracy-SBM: 0.8474	test_loss: 0.0982 test_accuracy-SBM: 0.8489
2025-07-05 08:13:08,771 - INFO - === Epoch 33 ===
2025-07-05 08:14:06,976 - INFO - train: {'epoch': 33, 'time_epoch': 55.91188, 'eta': 3692.64847, 'eta_hours': 1.02574, 'loss': 0.09064681, 'lr': 0.00040027, 'params': 345143, 'time_iter': 0.17863, 'accuracy': 0.86185, 'precision': 0.57177, 'recall': 0.86574, 'f1': 0.6887, 'auc': 0.94004, 'accuracy-SBM': 0.86337}
2025-07-05 08:14:12,180 - INFO - val: {'epoch': 33, 'time_epoch': 4.77589, 'loss': 0.09288701, 'lr': 0, 'params': 345143, 'time_iter': 0.07581, 'accuracy': 0.84114, 'precision': 0.53075, 'recall': 0.88518, 'f1': 0.66361, 'auc': 0.93698, 'accuracy-SBM': 0.85842}
2025-07-05 08:14:19,173 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:14:19,597 - INFO - test: {'epoch': 33, 'time_epoch': 4.83026, 'loss': 0.0918506, 'lr': 0, 'params': 345143, 'time_iter': 0.07667, 'accuracy': 0.84325, 'precision': 0.53335, 'recall': 0.88366, 'f1': 0.6652, 'auc': 0.93762, 'accuracy-SBM': 0.85913}
2025-07-05 08:14:19,599 - INFO - > Epoch 33: took 70.8s (avg 70.6s) | Best so far: epoch 33	train_loss: 0.0906 train_accuracy-SBM: 0.8634	val_loss: 0.0929 val_accuracy-SBM: 0.8584	test_loss: 0.0919 test_accuracy-SBM: 0.8591
2025-07-05 08:14:19,599 - INFO - === Epoch 34 ===
2025-07-05 08:15:16,930 - INFO - train: {'epoch': 34, 'time_epoch': 55.94179, 'eta': 3636.68545, 'eta_hours': 1.01019, 'loss': 0.09069499, 'lr': 0.00039358, 'params': 345143, 'time_iter': 0.17873, 'accuracy': 0.86159, 'precision': 0.5712, 'recall': 0.86603, 'f1': 0.68838, 'auc': 0.94, 'accuracy-SBM': 0.86334}
2025-07-05 08:15:22,138 - INFO - val: {'epoch': 34, 'time_epoch': 4.78546, 'loss': 0.11123897, 'lr': 0, 'params': 345143, 'time_iter': 0.07596, 'accuracy': 0.89992, 'precision': 0.71745, 'recall': 0.71706, 'f1': 0.71725, 'auc': 0.93517, 'accuracy-SBM': 0.82816}
2025-07-05 08:15:29,187 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:15:29,628 - INFO - test: {'epoch': 34, 'time_epoch': 4.84472, 'loss': 0.11020429, 'lr': 0, 'params': 345143, 'time_iter': 0.0769, 'accuracy': 0.90124, 'precision': 0.72011, 'recall': 0.71901, 'f1': 0.71956, 'auc': 0.9362, 'accuracy-SBM': 0.82961}
2025-07-05 08:15:29,630 - INFO - > Epoch 34: took 70.0s (avg 70.6s) | Best so far: epoch 33	train_loss: 0.0906 train_accuracy-SBM: 0.8634	val_loss: 0.0929 val_accuracy-SBM: 0.8584	test_loss: 0.0919 test_accuracy-SBM: 0.8591
2025-07-05 08:15:29,630 - INFO - === Epoch 35 ===
2025-07-05 08:16:26,886 - INFO - train: {'epoch': 35, 'time_epoch': 55.9557, 'eta': 3580.74834, 'eta_hours': 0.99465, 'loss': 0.09064914, 'lr': 0.00038674, 'params': 345143, 'time_iter': 0.17877, 'accuracy': 0.86247, 'precision': 0.57317, 'recall': 0.8651, 'f1': 0.68951, 'auc': 0.94008, 'accuracy-SBM': 0.8635}
2025-07-05 08:16:32,042 - INFO - val: {'epoch': 35, 'time_epoch': 4.76061, 'loss': 0.11806426, 'lr': 0, 'params': 345143, 'time_iter': 0.07557, 'accuracy': 0.90255, 'precision': 0.73973, 'recall': 0.69354, 'f1': 0.71589, 'auc': 0.93512, 'accuracy-SBM': 0.82053}
2025-07-05 08:16:38,990 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:16:39,395 - INFO - test: {'epoch': 35, 'time_epoch': 4.82276, 'loss': 0.11685676, 'lr': 0, 'params': 345143, 'time_iter': 0.07655, 'accuracy': 0.90365, 'precision': 0.74178, 'recall': 0.69524, 'f1': 0.71775, 'auc': 0.93627, 'accuracy-SBM': 0.82173}
2025-07-05 08:16:39,397 - INFO - > Epoch 35: took 69.8s (avg 70.6s) | Best so far: epoch 33	train_loss: 0.0906 train_accuracy-SBM: 0.8634	val_loss: 0.0929 val_accuracy-SBM: 0.8584	test_loss: 0.0919 test_accuracy-SBM: 0.8591
2025-07-05 08:16:39,397 - INFO - === Epoch 36 ===
2025-07-05 08:17:36,684 - INFO - train: {'epoch': 36, 'time_epoch': 55.96093, 'eta': 3524.81913, 'eta_hours': 0.97912, 'loss': 0.09065478, 'lr': 0.00037974, 'params': 345143, 'time_iter': 0.17879, 'accuracy': 0.86249, 'precision': 0.57321, 'recall': 0.86516, 'f1': 0.68956, 'auc': 0.94007, 'accuracy-SBM': 0.86354}
2025-07-05 08:17:41,739 - INFO - val: {'epoch': 36, 'time_epoch': 4.80126, 'loss': 0.14233112, 'lr': 0, 'params': 345143, 'time_iter': 0.07621, 'accuracy': 0.59121, 'precision': 0.29983, 'recall': 0.98056, 'f1': 0.45924, 'auc': 0.92642, 'accuracy-SBM': 0.74401}
2025-07-05 08:17:48,701 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:17:48,949 - INFO - test: {'epoch': 36, 'time_epoch': 4.8595, 'loss': 0.141337, 'lr': 0, 'params': 345143, 'time_iter': 0.07713, 'accuracy': 0.59285, 'precision': 0.29957, 'recall': 0.97932, 'f1': 0.4588, 'auc': 0.92695, 'accuracy-SBM': 0.74475}
2025-07-05 08:17:48,951 - INFO - > Epoch 36: took 69.6s (avg 70.5s) | Best so far: epoch 33	train_loss: 0.0906 train_accuracy-SBM: 0.8634	val_loss: 0.0929 val_accuracy-SBM: 0.8584	test_loss: 0.0919 test_accuracy-SBM: 0.8591
2025-07-05 08:17:48,951 - INFO - === Epoch 37 ===
2025-07-05 08:18:47,147 - INFO - train: {'epoch': 37, 'time_epoch': 55.9461, 'eta': 3468.86405, 'eta_hours': 0.96357, 'loss': 0.09070466, 'lr': 0.00037261, 'params': 345143, 'time_iter': 0.17874, 'accuracy': 0.86205, 'precision': 0.57221, 'recall': 0.86561, 'f1': 0.68897, 'auc': 0.93992, 'accuracy-SBM': 0.86345}
2025-07-05 08:18:52,338 - INFO - val: {'epoch': 37, 'time_epoch': 4.78613, 'loss': 0.20458737, 'lr': 0, 'params': 345143, 'time_iter': 0.07597, 'accuracy': 0.88445, 'precision': 0.77323, 'recall': 0.49133, 'f1': 0.60086, 'auc': 0.89979, 'accuracy-SBM': 0.73017}
2025-07-05 08:18:59,358 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:18:59,777 - INFO - test: {'epoch': 37, 'time_epoch': 4.85267, 'loss': 0.20631104, 'lr': 0, 'params': 345143, 'time_iter': 0.07703, 'accuracy': 0.88495, 'precision': 0.77372, 'recall': 0.49059, 'f1': 0.60045, 'auc': 0.89884, 'accuracy-SBM': 0.72995}
2025-07-05 08:18:59,779 - INFO - > Epoch 37: took 70.8s (avg 70.5s) | Best so far: epoch 33	train_loss: 0.0906 train_accuracy-SBM: 0.8634	val_loss: 0.0929 val_accuracy-SBM: 0.8584	test_loss: 0.0919 test_accuracy-SBM: 0.8591
2025-07-05 08:18:59,780 - INFO - === Epoch 38 ===
2025-07-05 08:19:58,085 - INFO - train: {'epoch': 38, 'time_epoch': 56.02353, 'eta': 3413.03055, 'eta_hours': 0.94806, 'loss': 0.09061552, 'lr': 0.00036534, 'params': 345143, 'time_iter': 0.17899, 'accuracy': 0.86233, 'precision': 0.57287, 'recall': 0.86515, 'f1': 0.68931, 'auc': 0.94008, 'accuracy-SBM': 0.86344}
2025-07-05 08:20:03,109 - INFO - val: {'epoch': 38, 'time_epoch': 4.77784, 'loss': 0.10299821, 'lr': 0, 'params': 345143, 'time_iter': 0.07584, 'accuracy': 0.78379, 'precision': 0.44681, 'recall': 0.9298, 'f1': 0.60357, 'auc': 0.93501, 'accuracy-SBM': 0.84109}
2025-07-05 08:20:10,256 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:20:10,672 - INFO - test: {'epoch': 38, 'time_epoch': 4.84137, 'loss': 0.10201624, 'lr': 0, 'params': 345143, 'time_iter': 0.07685, 'accuracy': 0.7855, 'precision': 0.44764, 'recall': 0.92847, 'f1': 0.60405, 'auc': 0.93567, 'accuracy-SBM': 0.84169}
2025-07-05 08:20:10,674 - INFO - > Epoch 38: took 70.9s (avg 70.6s) | Best so far: epoch 33	train_loss: 0.0906 train_accuracy-SBM: 0.8634	val_loss: 0.0929 val_accuracy-SBM: 0.8584	test_loss: 0.0919 test_accuracy-SBM: 0.8591
2025-07-05 08:20:10,674 - INFO - === Epoch 39 ===
2025-07-05 08:21:08,968 - INFO - train: {'epoch': 39, 'time_epoch': 55.96602, 'eta': 3357.10128, 'eta_hours': 0.93253, 'loss': 0.09064294, 'lr': 0.00035794, 'params': 345143, 'time_iter': 0.17881, 'accuracy': 0.86237, 'precision': 0.57296, 'recall': 0.86496, 'f1': 0.68931, 'auc': 0.94006, 'accuracy-SBM': 0.86339}
2025-07-05 08:21:13,993 - INFO - val: {'epoch': 39, 'time_epoch': 4.77832, 'loss': 0.11009387, 'lr': 0, 'params': 345143, 'time_iter': 0.07585, 'accuracy': 0.73698, 'precision': 0.3973, 'recall': 0.93973, 'f1': 0.55849, 'auc': 0.92558, 'accuracy-SBM': 0.81655}
2025-07-05 08:21:20,849 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:21:21,267 - INFO - test: {'epoch': 39, 'time_epoch': 4.84999, 'loss': 0.10895028, 'lr': 0, 'params': 345143, 'time_iter': 0.07698, 'accuracy': 0.7397, 'precision': 0.39864, 'recall': 0.93821, 'f1': 0.55954, 'auc': 0.92651, 'accuracy-SBM': 0.81772}
2025-07-05 08:21:21,269 - INFO - > Epoch 39: took 70.6s (avg 70.6s) | Best so far: epoch 33	train_loss: 0.0906 train_accuracy-SBM: 0.8634	val_loss: 0.0929 val_accuracy-SBM: 0.8584	test_loss: 0.0919 test_accuracy-SBM: 0.8591
2025-07-05 08:21:21,270 - INFO - === Epoch 40 ===
2025-07-05 08:22:19,523 - INFO - train: {'epoch': 40, 'time_epoch': 55.98864, 'eta': 3301.20277, 'eta_hours': 0.917, 'loss': 0.09051053, 'lr': 0.00035042, 'params': 345143, 'time_iter': 0.17888, 'accuracy': 0.86265, 'precision': 0.57352, 'recall': 0.86545, 'f1': 0.68987, 'auc': 0.94024, 'accuracy-SBM': 0.86375}
2025-07-05 08:22:24,687 - INFO - val: {'epoch': 40, 'time_epoch': 4.75092, 'loss': 0.42848938, 'lr': 0, 'params': 345143, 'time_iter': 0.07541, 'accuracy': 0.84523, 'precision': 0.88081, 'recall': 0.1454, 'f1': 0.2496, 'auc': 0.87332, 'accuracy-SBM': 0.57059}
2025-07-05 08:22:31,694 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:22:32,072 - INFO - test: {'epoch': 40, 'time_epoch': 4.84416, 'loss': 0.42959827, 'lr': 0, 'params': 345143, 'time_iter': 0.07689, 'accuracy': 0.8456, 'precision': 0.87505, 'recall': 0.14447, 'f1': 0.248, 'auc': 0.8725, 'accuracy-SBM': 0.57003}
2025-07-05 08:22:32,075 - INFO - > Epoch 40: took 70.8s (avg 70.6s) | Best so far: epoch 33	train_loss: 0.0906 train_accuracy-SBM: 0.8634	val_loss: 0.0929 val_accuracy-SBM: 0.8584	test_loss: 0.0919 test_accuracy-SBM: 0.8591
2025-07-05 08:22:32,075 - INFO - === Epoch 41 ===
2025-07-05 08:23:30,369 - INFO - train: {'epoch': 41, 'time_epoch': 55.98832, 'eta': 3245.29952, 'eta_hours': 0.90147, 'loss': 0.09059601, 'lr': 0.0003428, 'params': 345143, 'time_iter': 0.17888, 'accuracy': 0.8624, 'precision': 0.57293, 'recall': 0.86598, 'f1': 0.68962, 'auc': 0.94011, 'accuracy-SBM': 0.86381}
2025-07-05 08:23:35,378 - INFO - val: {'epoch': 41, 'time_epoch': 4.76602, 'loss': 0.14111029, 'lr': 0, 'params': 345143, 'time_iter': 0.07565, 'accuracy': 0.59161, 'precision': 0.30008, 'recall': 0.98094, 'f1': 0.45958, 'auc': 0.92642, 'accuracy-SBM': 0.7444}
2025-07-05 08:23:42,333 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:23:42,591 - INFO - test: {'epoch': 41, 'time_epoch': 4.79474, 'loss': 0.14015534, 'lr': 0, 'params': 345143, 'time_iter': 0.07611, 'accuracy': 0.59343, 'precision': 0.30008, 'recall': 0.98109, 'f1': 0.45959, 'auc': 0.92693, 'accuracy-SBM': 0.74579}
2025-07-05 08:23:42,593 - INFO - > Epoch 41: took 70.5s (avg 70.6s) | Best so far: epoch 33	train_loss: 0.0906 train_accuracy-SBM: 0.8634	val_loss: 0.0929 val_accuracy-SBM: 0.8584	test_loss: 0.0919 test_accuracy-SBM: 0.8591
2025-07-05 08:23:42,593 - INFO - === Epoch 42 ===
2025-07-05 08:24:40,857 - INFO - train: {'epoch': 42, 'time_epoch': 56.0167, 'eta': 3189.42994, 'eta_hours': 0.88595, 'loss': 0.0904577, 'lr': 0.00033507, 'params': 345143, 'time_iter': 0.17897, 'accuracy': 0.86163, 'precision': 0.57114, 'recall': 0.86757, 'f1': 0.68881, 'auc': 0.94033, 'accuracy-SBM': 0.86396}
2025-07-05 08:24:45,831 - INFO - val: {'epoch': 42, 'time_epoch': 4.7295, 'loss': 0.10254158, 'lr': 0, 'params': 345143, 'time_iter': 0.07507, 'accuracy': 0.77895, 'precision': 0.44135, 'recall': 0.93583, 'f1': 0.59982, 'auc': 0.93704, 'accuracy-SBM': 0.84052}
2025-07-05 08:24:52,632 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:24:53,081 - INFO - test: {'epoch': 42, 'time_epoch': 4.79477, 'loss': 0.10129625, 'lr': 0, 'params': 345143, 'time_iter': 0.07611, 'accuracy': 0.78175, 'precision': 0.44344, 'recall': 0.93495, 'f1': 0.60156, 'auc': 0.93781, 'accuracy-SBM': 0.84196}
2025-07-05 08:24:53,083 - INFO - > Epoch 42: took 70.5s (avg 70.6s) | Best so far: epoch 33	train_loss: 0.0906 train_accuracy-SBM: 0.8634	val_loss: 0.0929 val_accuracy-SBM: 0.8584	test_loss: 0.0919 test_accuracy-SBM: 0.8591
2025-07-05 08:24:53,083 - INFO - === Epoch 43 ===
2025-07-05 08:25:51,194 - INFO - train: {'epoch': 43, 'time_epoch': 55.69735, 'eta': 3133.14722, 'eta_hours': 0.87032, 'loss': 0.09036584, 'lr': 0.00032725, 'params': 345143, 'time_iter': 0.17795, 'accuracy': 0.86243, 'precision': 0.57297, 'recall': 0.86616, 'f1': 0.6897, 'auc': 0.94043, 'accuracy-SBM': 0.86389}
2025-07-05 08:25:56,358 - INFO - val: {'epoch': 43, 'time_epoch': 4.75973, 'loss': 0.32265233, 'lr': 0, 'params': 345143, 'time_iter': 0.07555, 'accuracy': 0.86819, 'precision': 0.85884, 'recall': 0.30565, 'f1': 0.45084, 'auc': 0.89163, 'accuracy-SBM': 0.64742}
2025-07-05 08:26:03,166 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:26:03,596 - INFO - test: {'epoch': 43, 'time_epoch': 4.82597, 'loss': 0.32348668, 'lr': 0, 'params': 345143, 'time_iter': 0.0766, 'accuracy': 0.86859, 'precision': 0.85606, 'recall': 0.30572, 'f1': 0.45054, 'auc': 0.89081, 'accuracy-SBM': 0.64736}
2025-07-05 08:26:03,599 - INFO - > Epoch 43: took 70.5s (avg 70.6s) | Best so far: epoch 33	train_loss: 0.0906 train_accuracy-SBM: 0.8634	val_loss: 0.0929 val_accuracy-SBM: 0.8584	test_loss: 0.0919 test_accuracy-SBM: 0.8591
2025-07-05 08:26:03,599 - INFO - === Epoch 44 ===
2025-07-05 08:27:00,895 - INFO - train: {'epoch': 44, 'time_epoch': 55.99843, 'eta': 3077.25851, 'eta_hours': 0.85479, 'loss': 0.0903883, 'lr': 0.00031935, 'params': 345143, 'time_iter': 0.17891, 'accuracy': 0.8621, 'precision': 0.57221, 'recall': 0.86671, 'f1': 0.68932, 'auc': 0.94041, 'accuracy-SBM': 0.86391}
2025-07-05 08:27:06,054 - INFO - val: {'epoch': 44, 'time_epoch': 4.75247, 'loss': 0.10712134, 'lr': 0, 'params': 345143, 'time_iter': 0.07544, 'accuracy': 0.9024, 'precision': 0.719, 'recall': 0.73647, 'f1': 0.72763, 'auc': 0.93905, 'accuracy-SBM': 0.83728}
2025-07-05 08:27:12,832 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:27:13,243 - INFO - test: {'epoch': 44, 'time_epoch': 4.80155, 'loss': 0.10626729, 'lr': 0, 'params': 345143, 'time_iter': 0.07622, 'accuracy': 0.90351, 'precision': 0.72219, 'recall': 0.7353, 'f1': 0.72869, 'auc': 0.94007, 'accuracy-SBM': 0.8374}
2025-07-05 08:27:13,245 - INFO - > Epoch 44: took 69.6s (avg 70.5s) | Best so far: epoch 33	train_loss: 0.0906 train_accuracy-SBM: 0.8634	val_loss: 0.0929 val_accuracy-SBM: 0.8584	test_loss: 0.0919 test_accuracy-SBM: 0.8591
2025-07-05 08:27:13,245 - INFO - === Epoch 45 ===
2025-07-05 08:28:09,622 - INFO - train: {'epoch': 45, 'time_epoch': 55.9713, 'eta': 3021.33318, 'eta_hours': 0.83926, 'loss': 0.09042359, 'lr': 0.00031137, 'params': 345143, 'time_iter': 0.17882, 'accuracy': 0.86252, 'precision': 0.57317, 'recall': 0.86621, 'f1': 0.68986, 'auc': 0.94038, 'accuracy-SBM': 0.86397}
2025-07-05 08:28:14,832 - INFO - val: {'epoch': 45, 'time_epoch': 4.76938, 'loss': 0.09225459, 'lr': 0, 'params': 345143, 'time_iter': 0.0757, 'accuracy': 0.84858, 'precision': 0.54487, 'recall': 0.87813, 'f1': 0.67247, 'auc': 0.93794, 'accuracy-SBM': 0.86018}
2025-07-05 08:28:21,747 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:28:22,168 - INFO - test: {'epoch': 45, 'time_epoch': 4.84527, 'loss': 0.09104807, 'lr': 0, 'params': 345143, 'time_iter': 0.07691, 'accuracy': 0.85151, 'precision': 0.54915, 'recall': 0.87918, 'f1': 0.67604, 'auc': 0.93884, 'accuracy-SBM': 0.86239}
2025-07-05 08:28:22,170 - INFO - > Epoch 45: took 68.9s (avg 70.5s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0923 val_accuracy-SBM: 0.8602	test_loss: 0.0910 test_accuracy-SBM: 0.8624
2025-07-05 08:28:22,170 - INFO - === Epoch 46 ===
2025-07-05 08:29:20,536 - INFO - train: {'epoch': 46, 'time_epoch': 56.03348, 'eta': 2965.476, 'eta_hours': 0.82374, 'loss': 0.09041669, 'lr': 0.00030332, 'params': 345143, 'time_iter': 0.17902, 'accuracy': 0.86247, 'precision': 0.57307, 'recall': 0.86621, 'f1': 0.68979, 'auc': 0.94034, 'accuracy-SBM': 0.86394}
2025-07-05 08:29:25,566 - INFO - val: {'epoch': 46, 'time_epoch': 4.78207, 'loss': 0.14147234, 'lr': 0, 'params': 345143, 'time_iter': 0.07591, 'accuracy': 0.57779, 'precision': 0.29327, 'recall': 0.98249, 'f1': 0.45171, 'auc': 0.9222, 'accuracy-SBM': 0.73661}
2025-07-05 08:29:32,498 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:29:32,752 - INFO - test: {'epoch': 46, 'time_epoch': 4.84181, 'loss': 0.14006238, 'lr': 0, 'params': 345143, 'time_iter': 0.07685, 'accuracy': 0.58111, 'precision': 0.29388, 'recall': 0.98175, 'f1': 0.45236, 'auc': 0.92274, 'accuracy-SBM': 0.73858}
2025-07-05 08:29:32,754 - INFO - > Epoch 46: took 70.6s (avg 70.5s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0923 val_accuracy-SBM: 0.8602	test_loss: 0.0910 test_accuracy-SBM: 0.8624
2025-07-05 08:29:32,754 - INFO - === Epoch 47 ===
2025-07-05 08:30:30,133 - INFO - train: {'epoch': 47, 'time_epoch': 55.94229, 'eta': 2909.5127, 'eta_hours': 0.8082, 'loss': 0.09038859, 'lr': 0.00029522, 'params': 345143, 'time_iter': 0.17873, 'accuracy': 0.86313, 'precision': 0.57448, 'recall': 0.86622, 'f1': 0.69081, 'auc': 0.94039, 'accuracy-SBM': 0.86434}
2025-07-05 08:30:35,172 - INFO - val: {'epoch': 47, 'time_epoch': 4.77297, 'loss': 0.17626722, 'lr': 0, 'params': 345143, 'time_iter': 0.07576, 'accuracy': 0.46155, 'precision': 0.24652, 'recall': 0.99283, 'f1': 0.39497, 'auc': 0.92428, 'accuracy-SBM': 0.67005}
2025-07-05 08:30:42,185 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:30:42,425 - INFO - test: {'epoch': 47, 'time_epoch': 4.8528, 'loss': 0.17399701, 'lr': 0, 'params': 345143, 'time_iter': 0.07703, 'accuracy': 0.46704, 'precision': 0.24752, 'recall': 0.99231, 'f1': 0.39621, 'auc': 0.92488, 'accuracy-SBM': 0.67349}
2025-07-05 08:30:42,427 - INFO - > Epoch 47: took 69.7s (avg 70.5s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0923 val_accuracy-SBM: 0.8602	test_loss: 0.0910 test_accuracy-SBM: 0.8624
2025-07-05 08:30:42,427 - INFO - === Epoch 48 ===
2025-07-05 08:31:40,729 - INFO - train: {'epoch': 48, 'time_epoch': 55.97317, 'eta': 2853.58238, 'eta_hours': 0.79266, 'loss': 0.09038011, 'lr': 0.00028707, 'params': 345143, 'time_iter': 0.17883, 'accuracy': 0.86271, 'precision': 0.57362, 'recall': 0.86587, 'f1': 0.69007, 'auc': 0.94039, 'accuracy-SBM': 0.86395}
2025-07-05 08:31:45,906 - INFO - val: {'epoch': 48, 'time_epoch': 4.78281, 'loss': 0.38316471, 'lr': 0, 'params': 345143, 'time_iter': 0.07592, 'accuracy': 0.84946, 'precision': 0.85114, 'recall': 0.18128, 'f1': 0.29889, 'auc': 0.87446, 'accuracy-SBM': 0.58723}
2025-07-05 08:31:53,177 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:31:53,562 - INFO - test: {'epoch': 48, 'time_epoch': 4.8025, 'loss': 0.38750139, 'lr': 0, 'params': 345143, 'time_iter': 0.07623, 'accuracy': 0.84964, 'precision': 0.84828, 'recall': 0.17873, 'f1': 0.29525, 'auc': 0.87193, 'accuracy-SBM': 0.58594}
2025-07-05 08:31:53,564 - INFO - > Epoch 48: took 71.1s (avg 70.5s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0923 val_accuracy-SBM: 0.8602	test_loss: 0.0910 test_accuracy-SBM: 0.8624
2025-07-05 08:31:53,564 - INFO - === Epoch 49 ===
2025-07-05 08:32:51,876 - INFO - train: {'epoch': 49, 'time_epoch': 55.9925, 'eta': 2797.66969, 'eta_hours': 0.77713, 'loss': 0.09034044, 'lr': 0.00027887, 'params': 345143, 'time_iter': 0.17889, 'accuracy': 0.86281, 'precision': 0.5738, 'recall': 0.86606, 'f1': 0.69027, 'auc': 0.94047, 'accuracy-SBM': 0.86409}
2025-07-05 08:32:57,060 - INFO - val: {'epoch': 49, 'time_epoch': 4.77953, 'loss': 0.11887391, 'lr': 0, 'params': 345143, 'time_iter': 0.07587, 'accuracy': 0.90047, 'precision': 0.73373, 'recall': 0.68707, 'f1': 0.70963, 'auc': 0.93313, 'accuracy-SBM': 0.81672}
2025-07-05 08:33:03,936 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:33:04,347 - INFO - test: {'epoch': 49, 'time_epoch': 4.79377, 'loss': 0.11822553, 'lr': 0, 'params': 345143, 'time_iter': 0.07609, 'accuracy': 0.90194, 'precision': 0.73912, 'recall': 0.68547, 'f1': 0.71128, 'auc': 0.93422, 'accuracy-SBM': 0.81686}
2025-07-05 08:33:04,349 - INFO - > Epoch 49: took 70.8s (avg 70.5s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0923 val_accuracy-SBM: 0.8602	test_loss: 0.0910 test_accuracy-SBM: 0.8624
2025-07-05 08:33:04,349 - INFO - === Epoch 50 ===
2025-07-05 08:34:02,649 - INFO - train: {'epoch': 50, 'time_epoch': 55.94265, 'eta': 2741.70597, 'eta_hours': 0.76158, 'loss': 0.09025229, 'lr': 0.00027064, 'params': 345143, 'time_iter': 0.17873, 'accuracy': 0.8627, 'precision': 0.57355, 'recall': 0.86617, 'f1': 0.69013, 'auc': 0.94058, 'accuracy-SBM': 0.86406}
2025-07-05 08:34:07,846 - INFO - val: {'epoch': 50, 'time_epoch': 4.77449, 'loss': 0.10817398, 'lr': 0, 'params': 345143, 'time_iter': 0.07579, 'accuracy': 0.8904, 'precision': 0.67204, 'recall': 0.7439, 'f1': 0.70615, 'auc': 0.93087, 'accuracy-SBM': 0.83291}
2025-07-05 08:34:14,689 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:34:15,102 - INFO - test: {'epoch': 50, 'time_epoch': 4.82103, 'loss': 0.10739366, 'lr': 0, 'params': 345143, 'time_iter': 0.07652, 'accuracy': 0.89234, 'precision': 0.67683, 'recall': 0.74459, 'f1': 0.7091, 'auc': 0.93186, 'accuracy-SBM': 0.83427}
2025-07-05 08:34:15,104 - INFO - > Epoch 50: took 70.8s (avg 70.5s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0923 val_accuracy-SBM: 0.8602	test_loss: 0.0910 test_accuracy-SBM: 0.8624
2025-07-05 08:34:15,104 - INFO - === Epoch 51 ===
2025-07-05 08:35:12,370 - INFO - train: {'epoch': 51, 'time_epoch': 55.9476, 'eta': 2685.74763, 'eta_hours': 0.74604, 'loss': 0.09031017, 'lr': 0.0002624, 'params': 345143, 'time_iter': 0.17875, 'accuracy': 0.86271, 'precision': 0.57358, 'recall': 0.86606, 'f1': 0.69011, 'auc': 0.94048, 'accuracy-SBM': 0.86403}
2025-07-05 08:35:17,529 - INFO - val: {'epoch': 51, 'time_epoch': 4.77033, 'loss': 0.46954319, 'lr': 0, 'params': 345143, 'time_iter': 0.07572, 'accuracy': 0.83703, 'precision': 0.86426, 'recall': 0.09419, 'f1': 0.16986, 'auc': 0.84423, 'accuracy-SBM': 0.5455}
2025-07-05 08:35:24,378 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:35:24,765 - INFO - test: {'epoch': 51, 'time_epoch': 4.78822, 'loss': 0.47287446, 'lr': 0, 'params': 345143, 'time_iter': 0.076, 'accuracy': 0.83759, 'precision': 0.85904, 'recall': 0.09378, 'f1': 0.1691, 'auc': 0.83907, 'accuracy-SBM': 0.54525}
2025-07-05 08:35:24,766 - INFO - > Epoch 51: took 69.7s (avg 70.5s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0923 val_accuracy-SBM: 0.8602	test_loss: 0.0910 test_accuracy-SBM: 0.8624
2025-07-05 08:35:24,766 - INFO - === Epoch 52 ===
2025-07-05 08:36:22,147 - INFO - train: {'epoch': 52, 'time_epoch': 55.99359, 'eta': 2629.83048, 'eta_hours': 0.73051, 'loss': 0.09024962, 'lr': 0.00025413, 'params': 345143, 'time_iter': 0.17889, 'accuracy': 0.86244, 'precision': 0.57297, 'recall': 0.86653, 'f1': 0.68982, 'auc': 0.94056, 'accuracy-SBM': 0.86405}
2025-07-05 08:36:27,289 - INFO - val: {'epoch': 52, 'time_epoch': 4.72393, 'loss': 0.47506405, 'lr': 0, 'params': 345143, 'time_iter': 0.07498, 'accuracy': 0.83656, 'precision': 0.86202, 'recall': 0.09138, 'f1': 0.16524, 'auc': 0.84551, 'accuracy-SBM': 0.54412}
2025-07-05 08:36:34,241 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:36:34,636 - INFO - test: {'epoch': 52, 'time_epoch': 4.83978, 'loss': 0.47662831, 'lr': 0, 'params': 345143, 'time_iter': 0.07682, 'accuracy': 0.83711, 'precision': 0.85993, 'recall': 0.09038, 'f1': 0.16356, 'auc': 0.84107, 'accuracy-SBM': 0.54361}
2025-07-05 08:36:34,638 - INFO - > Epoch 52: took 69.9s (avg 70.5s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0923 val_accuracy-SBM: 0.8602	test_loss: 0.0910 test_accuracy-SBM: 0.8624
2025-07-05 08:36:34,638 - INFO - === Epoch 53 ===
2025-07-05 08:37:32,882 - INFO - train: {'epoch': 53, 'time_epoch': 55.91539, 'eta': 2573.84389, 'eta_hours': 0.71496, 'loss': 0.0902242, 'lr': 0.00024587, 'params': 345143, 'time_iter': 0.17864, 'accuracy': 0.86255, 'precision': 0.57321, 'recall': 0.86649, 'f1': 0.68998, 'auc': 0.94059, 'accuracy-SBM': 0.8641}
2025-07-05 08:37:38,069 - INFO - val: {'epoch': 53, 'time_epoch': 4.77267, 'loss': 0.22941562, 'lr': 0, 'params': 345143, 'time_iter': 0.07576, 'accuracy': 0.87962, 'precision': 0.81564, 'recall': 0.41343, 'f1': 0.54873, 'auc': 0.90562, 'accuracy-SBM': 0.69667}
2025-07-05 08:37:45,009 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:37:45,398 - INFO - test: {'epoch': 53, 'time_epoch': 4.83525, 'loss': 0.22966166, 'lr': 0, 'params': 345143, 'time_iter': 0.07675, 'accuracy': 0.88082, 'precision': 0.81909, 'recall': 0.41544, 'f1': 0.55127, 'auc': 0.90574, 'accuracy-SBM': 0.6979}
2025-07-05 08:37:45,400 - INFO - > Epoch 53: took 70.8s (avg 70.5s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0923 val_accuracy-SBM: 0.8602	test_loss: 0.0910 test_accuracy-SBM: 0.8624
2025-07-05 08:37:45,400 - INFO - === Epoch 54 ===
2025-07-05 08:38:43,735 - INFO - train: {'epoch': 54, 'time_epoch': 55.92768, 'eta': 2517.86994, 'eta_hours': 0.69941, 'loss': 0.09026447, 'lr': 0.0002376, 'params': 345143, 'time_iter': 0.17868, 'accuracy': 0.86233, 'precision': 0.5727, 'recall': 0.86689, 'f1': 0.68974, 'auc': 0.94053, 'accuracy-SBM': 0.86412}
2025-07-05 08:38:48,700 - INFO - val: {'epoch': 54, 'time_epoch': 4.72011, 'loss': 0.10989093, 'lr': 0, 'params': 345143, 'time_iter': 0.07492, 'accuracy': 0.73779, 'precision': 0.39885, 'recall': 0.94881, 'f1': 0.56161, 'auc': 0.9319, 'accuracy-SBM': 0.8206}
2025-07-05 08:38:55,774 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:38:56,204 - INFO - test: {'epoch': 54, 'time_epoch': 4.86931, 'loss': 0.10861834, 'lr': 0, 'params': 345143, 'time_iter': 0.07729, 'accuracy': 0.74108, 'precision': 0.40074, 'recall': 0.94733, 'f1': 0.56322, 'auc': 0.93272, 'accuracy-SBM': 0.82214}
2025-07-05 08:38:56,206 - INFO - > Epoch 54: took 70.8s (avg 70.5s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0923 val_accuracy-SBM: 0.8602	test_loss: 0.0910 test_accuracy-SBM: 0.8624
2025-07-05 08:38:56,207 - INFO - === Epoch 55 ===
2025-07-05 08:39:53,561 - INFO - train: {'epoch': 55, 'time_epoch': 56.03036, 'eta': 2461.97832, 'eta_hours': 0.68388, 'loss': 0.09021207, 'lr': 0.00022936, 'params': 345143, 'time_iter': 0.17901, 'accuracy': 0.86263, 'precision': 0.57337, 'recall': 0.86664, 'f1': 0.69014, 'auc': 0.94061, 'accuracy-SBM': 0.86421}
2025-07-05 08:39:58,605 - INFO - val: {'epoch': 55, 'time_epoch': 4.786, 'loss': 0.13617243, 'lr': 0, 'params': 345143, 'time_iter': 0.07597, 'accuracy': 0.62934, 'precision': 0.32071, 'recall': 0.9783, 'f1': 0.48306, 'auc': 0.93184, 'accuracy-SBM': 0.76629}
2025-07-05 08:40:05,799 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:40:06,071 - INFO - test: {'epoch': 55, 'time_epoch': 4.83034, 'loss': 0.13475237, 'lr': 0, 'params': 345143, 'time_iter': 0.07667, 'accuracy': 0.63383, 'precision': 0.32232, 'recall': 0.97773, 'f1': 0.48482, 'auc': 0.93227, 'accuracy-SBM': 0.76899}
2025-07-05 08:40:06,075 - INFO - > Epoch 55: took 69.9s (avg 70.5s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0923 val_accuracy-SBM: 0.8602	test_loss: 0.0910 test_accuracy-SBM: 0.8624
2025-07-05 08:40:06,075 - INFO - === Epoch 56 ===
2025-07-05 08:41:02,863 - INFO - train: {'epoch': 56, 'time_epoch': 56.37799, 'eta': 2406.34408, 'eta_hours': 0.66843, 'loss': 0.09015976, 'lr': 0.00022113, 'params': 345143, 'time_iter': 0.18012, 'accuracy': 0.86273, 'precision': 0.57358, 'recall': 0.86668, 'f1': 0.6903, 'auc': 0.94068, 'accuracy-SBM': 0.86428}
2025-07-05 08:41:08,044 - INFO - val: {'epoch': 56, 'time_epoch': 4.75716, 'loss': 0.17803264, 'lr': 0, 'params': 345143, 'time_iter': 0.07551, 'accuracy': 0.89175, 'precision': 0.79261, 'recall': 0.52613, 'f1': 0.63245, 'auc': 0.91671, 'accuracy-SBM': 0.74826}
2025-07-05 08:41:15,014 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:41:15,429 - INFO - test: {'epoch': 56, 'time_epoch': 4.79737, 'loss': 0.17874161, 'lr': 0, 'params': 345143, 'time_iter': 0.07615, 'accuracy': 0.89276, 'precision': 0.79573, 'recall': 0.52661, 'f1': 0.63378, 'auc': 0.91685, 'accuracy-SBM': 0.74884}
2025-07-05 08:41:15,431 - INFO - > Epoch 56: took 69.4s (avg 70.5s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0923 val_accuracy-SBM: 0.8602	test_loss: 0.0910 test_accuracy-SBM: 0.8624
2025-07-05 08:41:15,431 - INFO - === Epoch 57 ===
2025-07-05 08:42:11,760 - INFO - train: {'epoch': 57, 'time_epoch': 55.97048, 'eta': 2350.3891, 'eta_hours': 0.65289, 'loss': 0.09009965, 'lr': 0.00021293, 'params': 345143, 'time_iter': 0.17882, 'accuracy': 0.86315, 'precision': 0.57452, 'recall': 0.86628, 'f1': 0.69086, 'auc': 0.94074, 'accuracy-SBM': 0.86438}
2025-07-05 08:42:16,811 - INFO - val: {'epoch': 57, 'time_epoch': 4.79352, 'loss': 0.11022894, 'lr': 0, 'params': 345143, 'time_iter': 0.07609, 'accuracy': 0.73779, 'precision': 0.39929, 'recall': 0.95393, 'f1': 0.56294, 'auc': 0.93678, 'accuracy-SBM': 0.82261}
2025-07-05 08:42:24,136 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:42:24,560 - INFO - test: {'epoch': 57, 'time_epoch': 4.79794, 'loss': 0.10868785, 'lr': 0, 'params': 345143, 'time_iter': 0.07616, 'accuracy': 0.74167, 'precision': 0.40171, 'recall': 0.95222, 'f1': 0.56505, 'auc': 0.93763, 'accuracy-SBM': 0.82442}
2025-07-05 08:42:24,562 - INFO - > Epoch 57: took 69.1s (avg 70.4s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0923 val_accuracy-SBM: 0.8602	test_loss: 0.0910 test_accuracy-SBM: 0.8624
2025-07-05 08:42:24,562 - INFO - === Epoch 58 ===
2025-07-05 08:43:22,725 - INFO - train: {'epoch': 58, 'time_epoch': 55.86824, 'eta': 2294.36254, 'eta_hours': 0.63732, 'loss': 0.09013508, 'lr': 0.00020478, 'params': 345143, 'time_iter': 0.17849, 'accuracy': 0.86266, 'precision': 0.57339, 'recall': 0.86707, 'f1': 0.6903, 'auc': 0.94071, 'accuracy-SBM': 0.8644}
2025-07-05 08:43:27,756 - INFO - val: {'epoch': 58, 'time_epoch': 4.7762, 'loss': 0.10775724, 'lr': 0, 'params': 345143, 'time_iter': 0.07581, 'accuracy': 0.75623, 'precision': 0.4165, 'recall': 0.9405, 'f1': 0.57733, 'auc': 0.93203, 'accuracy-SBM': 0.82854}
2025-07-05 08:43:34,703 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:43:35,130 - INFO - test: {'epoch': 58, 'time_epoch': 4.84552, 'loss': 0.10673554, 'lr': 0, 'params': 345143, 'time_iter': 0.07691, 'accuracy': 0.75835, 'precision': 0.4175, 'recall': 0.93954, 'f1': 0.57811, 'auc': 0.93246, 'accuracy-SBM': 0.82956}
2025-07-05 08:43:35,131 - INFO - > Epoch 58: took 70.6s (avg 70.4s) | Best so far: epoch 45	train_loss: 0.0904 train_accuracy-SBM: 0.8640	val_loss: 0.0923 val_accuracy-SBM: 0.8602	test_loss: 0.0910 test_accuracy-SBM: 0.8624
2025-07-05 08:43:35,131 - INFO - === Epoch 59 ===
2025-07-05 08:44:33,399 - INFO - train: {'epoch': 59, 'time_epoch': 55.91073, 'eta': 2238.36959, 'eta_hours': 0.62177, 'loss': 0.09005996, 'lr': 0.00019668, 'params': 345143, 'time_iter': 0.17863, 'accuracy': 0.86332, 'precision': 0.57491, 'recall': 0.866, 'f1': 0.69105, 'auc': 0.94081, 'accuracy-SBM': 0.86437}
2025-07-05 08:44:38,430 - INFO - val: {'epoch': 59, 'time_epoch': 4.7799, 'loss': 0.09191314, 'lr': 0, 'params': 345143, 'time_iter': 0.07587, 'accuracy': 0.84076, 'precision': 0.52973, 'recall': 0.89481, 'f1': 0.66549, 'auc': 0.9403, 'accuracy-SBM': 0.86197}
2025-07-05 08:44:45,302 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:44:45,712 - INFO - test: {'epoch': 59, 'time_epoch': 4.79321, 'loss': 0.09095425, 'lr': 0, 'params': 345143, 'time_iter': 0.07608, 'accuracy': 0.8438, 'precision': 0.53393, 'recall': 0.894, 'f1': 0.66857, 'auc': 0.94091, 'accuracy-SBM': 0.86353}
2025-07-05 08:44:45,714 - INFO - > Epoch 59: took 70.6s (avg 70.4s) | Best so far: epoch 59	train_loss: 0.0901 train_accuracy-SBM: 0.8644	val_loss: 0.0919 val_accuracy-SBM: 0.8620	test_loss: 0.0910 test_accuracy-SBM: 0.8635
2025-07-05 08:44:45,715 - INFO - === Epoch 60 ===
2025-07-05 08:45:44,043 - INFO - train: {'epoch': 60, 'time_epoch': 55.91505, 'eta': 2182.3821, 'eta_hours': 0.60622, 'loss': 0.09002595, 'lr': 0.00018863, 'params': 345143, 'time_iter': 0.17864, 'accuracy': 0.86281, 'precision': 0.57369, 'recall': 0.86732, 'f1': 0.69059, 'auc': 0.94082, 'accuracy-SBM': 0.86458}
2025-07-05 08:45:49,017 - INFO - val: {'epoch': 60, 'time_epoch': 4.72506, 'loss': 0.09141354, 'lr': 0, 'params': 345143, 'time_iter': 0.075, 'accuracy': 0.85084, 'precision': 0.54888, 'recall': 0.88378, 'f1': 0.67719, 'auc': 0.94075, 'accuracy-SBM': 0.86377}
2025-07-05 08:45:56,023 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:45:56,429 - INFO - test: {'epoch': 60, 'time_epoch': 4.80332, 'loss': 0.09036597, 'lr': 0, 'params': 345143, 'time_iter': 0.07624, 'accuracy': 0.85354, 'precision': 0.55281, 'recall': 0.88387, 'f1': 0.6802, 'auc': 0.94141, 'accuracy-SBM': 0.86546}
2025-07-05 08:45:56,431 - INFO - > Epoch 60: took 70.7s (avg 70.5s) | Best so far: epoch 60	train_loss: 0.0900 train_accuracy-SBM: 0.8646	val_loss: 0.0914 val_accuracy-SBM: 0.8638	test_loss: 0.0904 test_accuracy-SBM: 0.8655
2025-07-05 08:45:56,432 - INFO - === Epoch 61 ===
2025-07-05 08:46:53,732 - INFO - train: {'epoch': 61, 'time_epoch': 55.97483, 'eta': 2126.43359, 'eta_hours': 0.59068, 'loss': 0.09007325, 'lr': 0.00018065, 'params': 345143, 'time_iter': 0.17883, 'accuracy': 0.86297, 'precision': 0.57412, 'recall': 0.86642, 'f1': 0.69061, 'auc': 0.94079, 'accuracy-SBM': 0.86433}
2025-07-05 08:46:58,949 - INFO - val: {'epoch': 61, 'time_epoch': 4.78588, 'loss': 0.09064119, 'lr': 0, 'params': 345143, 'time_iter': 0.07597, 'accuracy': 0.85555, 'precision': 0.55846, 'recall': 0.87897, 'f1': 0.68298, 'auc': 0.94097, 'accuracy-SBM': 0.86474}
2025-07-05 08:47:05,877 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:47:06,312 - INFO - test: {'epoch': 61, 'time_epoch': 4.82673, 'loss': 0.08950646, 'lr': 0, 'params': 345143, 'time_iter': 0.07661, 'accuracy': 0.85789, 'precision': 0.56186, 'recall': 0.87901, 'f1': 0.68554, 'auc': 0.94184, 'accuracy-SBM': 0.86619}
2025-07-05 08:47:06,314 - INFO - > Epoch 61: took 69.9s (avg 70.4s) | Best so far: epoch 61	train_loss: 0.0901 train_accuracy-SBM: 0.8643	val_loss: 0.0906 val_accuracy-SBM: 0.8647	test_loss: 0.0895 test_accuracy-SBM: 0.8662
2025-07-05 08:47:06,314 - INFO - === Epoch 62 ===
2025-07-05 08:48:03,919 - INFO - train: {'epoch': 62, 'time_epoch': 56.05246, 'eta': 2070.52983, 'eta_hours': 0.57515, 'loss': 0.08989563, 'lr': 0.00017275, 'params': 345143, 'time_iter': 0.17908, 'accuracy': 0.86298, 'precision': 0.57399, 'recall': 0.86785, 'f1': 0.69098, 'auc': 0.94106, 'accuracy-SBM': 0.86489}
2025-07-05 08:48:09,359 - INFO - val: {'epoch': 62, 'time_epoch': 4.96219, 'loss': 0.45158875, 'lr': 0, 'params': 345143, 'time_iter': 0.07876, 'accuracy': 0.84393, 'precision': 0.88861, 'recall': 0.1353, 'f1': 0.23485, 'auc': 0.86035, 'accuracy-SBM': 0.56583}
2025-07-05 08:48:17,425 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:48:17,924 - INFO - test: {'epoch': 62, 'time_epoch': 5.0707, 'loss': 0.45558377, 'lr': 0, 'params': 345143, 'time_iter': 0.08049, 'accuracy': 0.84385, 'precision': 0.87949, 'recall': 0.13194, 'f1': 0.22946, 'auc': 0.85729, 'accuracy-SBM': 0.56404}
2025-07-05 08:48:17,926 - INFO - > Epoch 62: took 71.6s (avg 70.5s) | Best so far: epoch 61	train_loss: 0.0901 train_accuracy-SBM: 0.8643	val_loss: 0.0906 val_accuracy-SBM: 0.8647	test_loss: 0.0895 test_accuracy-SBM: 0.8662
2025-07-05 08:48:17,926 - INFO - === Epoch 63 ===
2025-07-05 08:49:17,960 - INFO - train: {'epoch': 63, 'time_epoch': 57.77388, 'eta': 2015.58972, 'eta_hours': 0.55989, 'loss': 0.08997834, 'lr': 0.00016493, 'params': 345143, 'time_iter': 0.18458, 'accuracy': 0.86262, 'precision': 0.57326, 'recall': 0.86752, 'f1': 0.69034, 'auc': 0.94091, 'accuracy-SBM': 0.86455}
2025-07-05 08:49:23,352 - INFO - val: {'epoch': 63, 'time_epoch': 4.91123, 'loss': 0.31559825, 'lr': 0, 'params': 345143, 'time_iter': 0.07796, 'accuracy': 0.86287, 'precision': 0.8928, 'recall': 0.25612, 'f1': 0.39805, 'auc': 0.89838, 'accuracy-SBM': 0.62475}
2025-07-05 08:49:30,735 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:49:31,223 - INFO - test: {'epoch': 63, 'time_epoch': 5.07197, 'loss': 0.31833198, 'lr': 0, 'params': 345143, 'time_iter': 0.08051, 'accuracy': 0.86318, 'precision': 0.88825, 'recall': 0.25579, 'f1': 0.3972, 'auc': 0.89741, 'accuracy-SBM': 0.62445}
2025-07-05 08:49:31,225 - INFO - > Epoch 63: took 73.3s (avg 70.5s) | Best so far: epoch 61	train_loss: 0.0901 train_accuracy-SBM: 0.8643	val_loss: 0.0906 val_accuracy-SBM: 0.8647	test_loss: 0.0895 test_accuracy-SBM: 0.8662
2025-07-05 08:49:31,226 - INFO - === Epoch 64 ===
2025-07-05 08:50:29,381 - INFO - train: {'epoch': 64, 'time_epoch': 57.70019, 'eta': 1960.52274, 'eta_hours': 0.54459, 'loss': 0.09003102, 'lr': 0.0001572, 'params': 345143, 'time_iter': 0.18435, 'accuracy': 0.86263, 'precision': 0.57329, 'recall': 0.86729, 'f1': 0.69029, 'auc': 0.94084, 'accuracy-SBM': 0.86446}
2025-07-05 08:50:34,681 - INFO - val: {'epoch': 64, 'time_epoch': 4.99258, 'loss': 0.09669911, 'lr': 0, 'params': 345143, 'time_iter': 0.07925, 'accuracy': 0.80725, 'precision': 0.47691, 'recall': 0.91756, 'f1': 0.62761, 'auc': 0.93746, 'accuracy-SBM': 0.85054}
2025-07-05 08:50:42,259 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:50:42,751 - INFO - test: {'epoch': 64, 'time_epoch': 5.15884, 'loss': 0.09555537, 'lr': 0, 'params': 345143, 'time_iter': 0.08189, 'accuracy': 0.80968, 'precision': 0.47908, 'recall': 0.91663, 'f1': 0.62927, 'auc': 0.9383, 'accuracy-SBM': 0.85171}
2025-07-05 08:50:42,753 - INFO - > Epoch 64: took 71.5s (avg 70.5s) | Best so far: epoch 61	train_loss: 0.0901 train_accuracy-SBM: 0.8643	val_loss: 0.0906 val_accuracy-SBM: 0.8647	test_loss: 0.0895 test_accuracy-SBM: 0.8662
2025-07-05 08:50:42,753 - INFO - === Epoch 65 ===
2025-07-05 08:51:42,089 - INFO - train: {'epoch': 65, 'time_epoch': 57.66601, 'eta': 1905.35836, 'eta_hours': 0.52927, 'loss': 0.0899515, 'lr': 0.00014958, 'params': 345143, 'time_iter': 0.18424, 'accuracy': 0.86318, 'precision': 0.57455, 'recall': 0.86659, 'f1': 0.69098, 'auc': 0.94099, 'accuracy-SBM': 0.86452}
2025-07-05 08:51:47,291 - INFO - val: {'epoch': 65, 'time_epoch': 4.91199, 'loss': 0.16461575, 'lr': 0, 'params': 345143, 'time_iter': 0.07797, 'accuracy': 0.47418, 'precision': 0.251, 'recall': 0.99312, 'f1': 0.40072, 'auc': 0.925, 'accuracy-SBM': 0.67783}
2025-07-05 08:51:54,465 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:51:54,744 - INFO - test: {'epoch': 65, 'time_epoch': 4.91606, 'loss': 0.16312628, 'lr': 0, 'params': 345143, 'time_iter': 0.07803, 'accuracy': 0.47773, 'precision': 0.25135, 'recall': 0.99254, 'f1': 0.40112, 'auc': 0.92559, 'accuracy-SBM': 0.68007}
2025-07-05 08:51:54,746 - INFO - > Epoch 65: took 72.0s (avg 70.5s) | Best so far: epoch 61	train_loss: 0.0901 train_accuracy-SBM: 0.8643	val_loss: 0.0906 val_accuracy-SBM: 0.8647	test_loss: 0.0895 test_accuracy-SBM: 0.8662
2025-07-05 08:51:54,746 - INFO - === Epoch 66 ===
2025-07-05 08:52:53,581 - INFO - train: {'epoch': 66, 'time_epoch': 57.06336, 'eta': 1849.82247, 'eta_hours': 0.51384, 'loss': 0.09001251, 'lr': 0.00014206, 'params': 345143, 'time_iter': 0.18231, 'accuracy': 0.86241, 'precision': 0.57278, 'recall': 0.86788, 'f1': 0.69011, 'auc': 0.94083, 'accuracy-SBM': 0.86456}
2025-07-05 08:52:59,000 - INFO - val: {'epoch': 66, 'time_epoch': 4.92788, 'loss': 0.09727234, 'lr': 0, 'params': 345143, 'time_iter': 0.07822, 'accuracy': 0.88377, 'precision': 0.63722, 'recall': 0.79733, 'f1': 0.70834, 'auc': 0.93553, 'accuracy-SBM': 0.84985}
2025-07-05 08:53:06,480 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:53:06,957 - INFO - test: {'epoch': 66, 'time_epoch': 4.96729, 'loss': 0.09646891, 'lr': 0, 'params': 345143, 'time_iter': 0.07885, 'accuracy': 0.88566, 'precision': 0.64123, 'recall': 0.79717, 'f1': 0.71074, 'auc': 0.93632, 'accuracy-SBM': 0.85088}
2025-07-05 08:53:06,959 - INFO - > Epoch 66: took 72.2s (avg 70.6s) | Best so far: epoch 61	train_loss: 0.0901 train_accuracy-SBM: 0.8643	val_loss: 0.0906 val_accuracy-SBM: 0.8647	test_loss: 0.0895 test_accuracy-SBM: 0.8662
2025-07-05 08:53:06,959 - INFO - === Epoch 67 ===
2025-07-05 08:54:06,642 - INFO - train: {'epoch': 67, 'time_epoch': 56.99106, 'eta': 1794.20764, 'eta_hours': 0.49839, 'loss': 0.08995139, 'lr': 0.00013466, 'params': 345143, 'time_iter': 0.18208, 'accuracy': 0.86281, 'precision': 0.57368, 'recall': 0.86734, 'f1': 0.69059, 'auc': 0.94095, 'accuracy-SBM': 0.86459}
2025-07-05 08:54:12,002 - INFO - val: {'epoch': 67, 'time_epoch': 4.90981, 'loss': 0.36913801, 'lr': 0, 'params': 345143, 'time_iter': 0.07793, 'accuracy': 0.85856, 'precision': 0.86023, 'recall': 0.24, 'f1': 0.37529, 'auc': 0.87768, 'accuracy-SBM': 0.6158}
2025-07-05 08:54:19,558 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:54:19,999 - INFO - test: {'epoch': 67, 'time_epoch': 5.03673, 'loss': 0.3737659, 'lr': 0, 'params': 345143, 'time_iter': 0.07995, 'accuracy': 0.85886, 'precision': 0.85755, 'recall': 0.23876, 'f1': 0.37352, 'auc': 0.87565, 'accuracy-SBM': 0.61514}
2025-07-05 08:54:20,001 - INFO - > Epoch 67: took 73.0s (avg 70.6s) | Best so far: epoch 61	train_loss: 0.0901 train_accuracy-SBM: 0.8643	val_loss: 0.0906 val_accuracy-SBM: 0.8647	test_loss: 0.0895 test_accuracy-SBM: 0.8662
2025-07-05 08:54:20,001 - INFO - === Epoch 68 ===
2025-07-05 08:55:19,010 - INFO - train: {'epoch': 68, 'time_epoch': 57.34137, 'eta': 1738.7103, 'eta_hours': 0.48298, 'loss': 0.08993959, 'lr': 0.00012739, 'params': 345143, 'time_iter': 0.1832, 'accuracy': 0.8628, 'precision': 0.57365, 'recall': 0.86747, 'f1': 0.69061, 'auc': 0.94098, 'accuracy-SBM': 0.86464}
2025-07-05 08:55:24,170 - INFO - val: {'epoch': 68, 'time_epoch': 4.87965, 'loss': 0.11702674, 'lr': 0, 'params': 345143, 'time_iter': 0.07745, 'accuracy': 0.70314, 'precision': 0.3697, 'recall': 0.96043, 'f1': 0.53389, 'auc': 0.93042, 'accuracy-SBM': 0.80411}
2025-07-05 08:55:31,579 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:55:32,084 - INFO - test: {'epoch': 68, 'time_epoch': 5.00423, 'loss': 0.11575562, 'lr': 0, 'params': 345143, 'time_iter': 0.07943, 'accuracy': 0.70694, 'precision': 0.37146, 'recall': 0.95803, 'f1': 0.53535, 'auc': 0.93101, 'accuracy-SBM': 0.80563}
2025-07-05 08:55:32,087 - INFO - > Epoch 68: took 72.1s (avg 70.6s) | Best so far: epoch 61	train_loss: 0.0901 train_accuracy-SBM: 0.8643	val_loss: 0.0906 val_accuracy-SBM: 0.8647	test_loss: 0.0895 test_accuracy-SBM: 0.8662
2025-07-05 08:55:32,087 - INFO - === Epoch 69 ===
2025-07-05 08:56:32,330 - INFO - train: {'epoch': 69, 'time_epoch': 57.58969, 'eta': 1683.2667, 'eta_hours': 0.46757, 'loss': 0.0898986, 'lr': 0.00012026, 'params': 345143, 'time_iter': 0.18399, 'accuracy': 0.86295, 'precision': 0.57394, 'recall': 0.86776, 'f1': 0.69091, 'auc': 0.94104, 'accuracy-SBM': 0.86484}
2025-07-05 08:56:37,751 - INFO - val: {'epoch': 69, 'time_epoch': 4.93612, 'loss': 0.09208431, 'lr': 0, 'params': 345143, 'time_iter': 0.07835, 'accuracy': 0.86954, 'precision': 0.59181, 'recall': 0.84764, 'f1': 0.69699, 'auc': 0.93893, 'accuracy-SBM': 0.86094}
2025-07-05 08:56:45,896 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:56:46,369 - INFO - test: {'epoch': 69, 'time_epoch': 5.03837, 'loss': 0.09091392, 'lr': 0, 'params': 345143, 'time_iter': 0.07997, 'accuracy': 0.87232, 'precision': 0.5967, 'recall': 0.8499, 'f1': 0.70114, 'auc': 0.93992, 'accuracy-SBM': 0.86351}
2025-07-05 08:56:46,371 - INFO - > Epoch 69: took 74.3s (avg 70.7s) | Best so far: epoch 61	train_loss: 0.0901 train_accuracy-SBM: 0.8643	val_loss: 0.0906 val_accuracy-SBM: 0.8647	test_loss: 0.0895 test_accuracy-SBM: 0.8662
2025-07-05 08:56:46,371 - INFO - === Epoch 70 ===
2025-07-05 08:57:45,880 - INFO - train: {'epoch': 70, 'time_epoch': 57.48954, 'eta': 1627.72174, 'eta_hours': 0.45214, 'loss': 0.08989772, 'lr': 0.00011326, 'params': 345143, 'time_iter': 0.18367, 'accuracy': 0.8635, 'precision': 0.57522, 'recall': 0.86674, 'f1': 0.69151, 'auc': 0.94101, 'accuracy-SBM': 0.86477}
2025-07-05 08:57:51,268 - INFO - val: {'epoch': 70, 'time_epoch': 5.07959, 'loss': 0.12784787, 'lr': 0, 'params': 345143, 'time_iter': 0.08063, 'accuracy': 0.65762, 'precision': 0.33791, 'recall': 0.97368, 'f1': 0.50171, 'auc': 0.93053, 'accuracy-SBM': 0.78166}
2025-07-05 08:57:58,485 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:57:58,975 - INFO - test: {'epoch': 70, 'time_epoch': 4.95543, 'loss': 0.12672584, 'lr': 0, 'params': 345143, 'time_iter': 0.07866, 'accuracy': 0.66105, 'precision': 0.33906, 'recall': 0.9728, 'f1': 0.50286, 'auc': 0.93093, 'accuracy-SBM': 0.78358}
2025-07-05 08:57:58,983 - INFO - > Epoch 70: took 72.6s (avg 70.7s) | Best so far: epoch 61	train_loss: 0.0901 train_accuracy-SBM: 0.8643	val_loss: 0.0906 val_accuracy-SBM: 0.8647	test_loss: 0.0895 test_accuracy-SBM: 0.8662
2025-07-05 08:57:58,984 - INFO - === Epoch 71 ===
2025-07-05 08:59:00,180 - INFO - train: {'epoch': 71, 'time_epoch': 58.33203, 'eta': 1572.45039, 'eta_hours': 0.43679, 'loss': 0.08993101, 'lr': 0.00010642, 'params': 345143, 'time_iter': 0.18636, 'accuracy': 0.86342, 'precision': 0.57504, 'recall': 0.86682, 'f1': 0.69141, 'auc': 0.941, 'accuracy-SBM': 0.86475}
2025-07-05 08:59:05,476 - INFO - val: {'epoch': 71, 'time_epoch': 4.97499, 'loss': 0.11302051, 'lr': 0, 'params': 345143, 'time_iter': 0.07897, 'accuracy': 0.72263, 'precision': 0.38555, 'recall': 0.95484, 'f1': 0.5493, 'auc': 0.93231, 'accuracy-SBM': 0.81376}
2025-07-05 08:59:12,642 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 08:59:13,126 - INFO - test: {'epoch': 71, 'time_epoch': 5.14891, 'loss': 0.11187204, 'lr': 0, 'params': 345143, 'time_iter': 0.08173, 'accuracy': 0.72583, 'precision': 0.38712, 'recall': 0.95312, 'f1': 0.55061, 'auc': 0.93292, 'accuracy-SBM': 0.81517}
2025-07-05 08:59:13,128 - INFO - > Epoch 71: took 74.1s (avg 70.8s) | Best so far: epoch 61	train_loss: 0.0901 train_accuracy-SBM: 0.8643	val_loss: 0.0906 val_accuracy-SBM: 0.8647	test_loss: 0.0895 test_accuracy-SBM: 0.8662
2025-07-05 08:59:13,128 - INFO - === Epoch 72 ===
2025-07-05 09:00:11,238 - INFO - train: {'epoch': 72, 'time_epoch': 57.68381, 'eta': 1516.85544, 'eta_hours': 0.42135, 'loss': 0.08984017, 'lr': 9.973e-05, 'params': 345143, 'time_iter': 0.18429, 'accuracy': 0.86299, 'precision': 0.57406, 'recall': 0.86735, 'f1': 0.69086, 'auc': 0.94112, 'accuracy-SBM': 0.8647}
2025-07-05 09:00:16,647 - INFO - val: {'epoch': 72, 'time_epoch': 5.0981, 'loss': 0.12107586, 'lr': 0, 'params': 345143, 'time_iter': 0.08092, 'accuracy': 0.68877, 'precision': 0.35928, 'recall': 0.96782, 'f1': 0.52403, 'auc': 0.93501, 'accuracy-SBM': 0.79828}
2025-07-05 09:00:24,095 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:00:24,600 - INFO - test: {'epoch': 72, 'time_epoch': 4.95113, 'loss': 0.11988323, 'lr': 0, 'params': 345143, 'time_iter': 0.07859, 'accuracy': 0.69247, 'precision': 0.36092, 'recall': 0.96689, 'f1': 0.52563, 'auc': 0.93549, 'accuracy-SBM': 0.80033}
2025-07-05 09:00:24,605 - INFO - > Epoch 72: took 71.5s (avg 70.8s) | Best so far: epoch 61	train_loss: 0.0901 train_accuracy-SBM: 0.8643	val_loss: 0.0906 val_accuracy-SBM: 0.8647	test_loss: 0.0895 test_accuracy-SBM: 0.8662
2025-07-05 09:00:24,605 - INFO - === Epoch 73 ===
2025-07-05 09:01:22,817 - INFO - train: {'epoch': 73, 'time_epoch': 57.64839, 'eta': 1461.19159, 'eta_hours': 0.40589, 'loss': 0.08982431, 'lr': 9.321e-05, 'params': 345143, 'time_iter': 0.18418, 'accuracy': 0.86325, 'precision': 0.57464, 'recall': 0.86733, 'f1': 0.69128, 'auc': 0.94113, 'accuracy-SBM': 0.86486}
2025-07-05 09:01:28,368 - INFO - val: {'epoch': 73, 'time_epoch': 5.05988, 'loss': 0.09226545, 'lr': 0, 'params': 345143, 'time_iter': 0.08032, 'accuracy': 0.87975, 'precision': 0.6191, 'recall': 0.83359, 'f1': 0.71051, 'auc': 0.94058, 'accuracy-SBM': 0.86164}
2025-07-05 09:01:35,936 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:01:36,419 - INFO - test: {'epoch': 73, 'time_epoch': 4.96673, 'loss': 0.09121504, 'lr': 0, 'params': 345143, 'time_iter': 0.07884, 'accuracy': 0.88192, 'precision': 0.62326, 'recall': 0.83416, 'f1': 0.71345, 'auc': 0.94152, 'accuracy-SBM': 0.86315}
2025-07-05 09:01:36,421 - INFO - > Epoch 73: took 71.8s (avg 70.8s) | Best so far: epoch 61	train_loss: 0.0901 train_accuracy-SBM: 0.8643	val_loss: 0.0906 val_accuracy-SBM: 0.8647	test_loss: 0.0895 test_accuracy-SBM: 0.8662
2025-07-05 09:01:36,421 - INFO - === Epoch 74 ===
2025-07-05 09:02:37,836 - INFO - train: {'epoch': 74, 'time_epoch': 58.3754, 'eta': 1405.71716, 'eta_hours': 0.39048, 'loss': 0.0897426, 'lr': 8.685e-05, 'params': 345143, 'time_iter': 0.1865, 'accuracy': 0.86367, 'precision': 0.57558, 'recall': 0.86702, 'f1': 0.69186, 'auc': 0.94126, 'accuracy-SBM': 0.86499}
2025-07-05 09:02:43,379 - INFO - val: {'epoch': 74, 'time_epoch': 5.04677, 'loss': 0.09408154, 'lr': 0, 'params': 345143, 'time_iter': 0.08011, 'accuracy': 0.87036, 'precision': 0.59506, 'recall': 0.8378, 'f1': 0.69587, 'auc': 0.93641, 'accuracy-SBM': 0.85758}
2025-07-05 09:02:51,214 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:02:51,706 - INFO - test: {'epoch': 74, 'time_epoch': 4.97623, 'loss': 0.09318178, 'lr': 0, 'params': 345143, 'time_iter': 0.07899, 'accuracy': 0.87226, 'precision': 0.59818, 'recall': 0.83797, 'f1': 0.69806, 'auc': 0.93716, 'accuracy-SBM': 0.85878}
2025-07-05 09:02:51,708 - INFO - > Epoch 74: took 75.3s (avg 70.8s) | Best so far: epoch 61	train_loss: 0.0901 train_accuracy-SBM: 0.8643	val_loss: 0.0906 val_accuracy-SBM: 0.8647	test_loss: 0.0895 test_accuracy-SBM: 0.8662
2025-07-05 09:02:51,709 - INFO - === Epoch 75 ===
2025-07-05 09:03:49,120 - INFO - train: {'epoch': 75, 'time_epoch': 57.04673, 'eta': 1349.7468, 'eta_hours': 0.37493, 'loss': 0.0898625, 'lr': 8.068e-05, 'params': 345143, 'time_iter': 0.18226, 'accuracy': 0.86312, 'precision': 0.57434, 'recall': 0.86737, 'f1': 0.69107, 'auc': 0.94105, 'accuracy-SBM': 0.86479}
2025-07-05 09:03:54,469 - INFO - val: {'epoch': 75, 'time_epoch': 4.86992, 'loss': 0.09072661, 'lr': 0, 'params': 345143, 'time_iter': 0.0773, 'accuracy': 0.85859, 'precision': 0.56498, 'recall': 0.87439, 'f1': 0.68643, 'auc': 0.94103, 'accuracy-SBM': 0.86479}
2025-07-05 09:04:02,445 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:04:02,920 - INFO - test: {'epoch': 75, 'time_epoch': 4.96084, 'loss': 0.08959519, 'lr': 0, 'params': 345143, 'time_iter': 0.07874, 'accuracy': 0.8615, 'precision': 0.56963, 'recall': 0.87546, 'f1': 0.69018, 'auc': 0.94191, 'accuracy-SBM': 0.86699}
2025-07-05 09:04:02,922 - INFO - > Epoch 75: took 71.2s (avg 70.8s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:04:02,922 - INFO - === Epoch 76 ===
2025-07-05 09:05:00,413 - INFO - train: {'epoch': 76, 'time_epoch': 57.06514, 'eta': 1293.75399, 'eta_hours': 0.35938, 'loss': 0.08978709, 'lr': 7.469e-05, 'params': 345143, 'time_iter': 0.18232, 'accuracy': 0.86332, 'precision': 0.57483, 'recall': 0.86692, 'f1': 0.69129, 'auc': 0.94117, 'accuracy-SBM': 0.86474}
2025-07-05 09:05:07,591 - INFO - val: {'epoch': 76, 'time_epoch': 4.93133, 'loss': 0.1002203, 'lr': 0, 'params': 345143, 'time_iter': 0.07828, 'accuracy': 0.78904, 'precision': 0.45328, 'recall': 0.93001, 'f1': 0.6095, 'auc': 0.93693, 'accuracy-SBM': 0.84437}
2025-07-05 09:05:15,338 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:05:15,810 - INFO - test: {'epoch': 76, 'time_epoch': 5.01994, 'loss': 0.09916563, 'lr': 0, 'params': 345143, 'time_iter': 0.07968, 'accuracy': 0.79153, 'precision': 0.45516, 'recall': 0.92878, 'f1': 0.61092, 'auc': 0.93763, 'accuracy-SBM': 0.84547}
2025-07-05 09:05:15,812 - INFO - > Epoch 76: took 72.9s (avg 70.9s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:05:15,812 - INFO - === Epoch 77 ===
2025-07-05 09:06:15,748 - INFO - train: {'epoch': 77, 'time_epoch': 56.97905, 'eta': 1237.70939, 'eta_hours': 0.34381, 'loss': 0.08973736, 'lr': 6.889e-05, 'params': 345143, 'time_iter': 0.18204, 'accuracy': 0.86305, 'precision': 0.57415, 'recall': 0.86791, 'f1': 0.69111, 'auc': 0.94127, 'accuracy-SBM': 0.86496}
2025-07-05 09:06:21,157 - INFO - val: {'epoch': 77, 'time_epoch': 4.92659, 'loss': 0.10239639, 'lr': 0, 'params': 345143, 'time_iter': 0.0782, 'accuracy': 0.89102, 'precision': 0.66709, 'recall': 0.76722, 'f1': 0.71366, 'auc': 0.93481, 'accuracy-SBM': 0.84243}
2025-07-05 09:06:29,256 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:06:29,734 - INFO - test: {'epoch': 77, 'time_epoch': 4.95597, 'loss': 0.10175075, 'lr': 0, 'params': 345143, 'time_iter': 0.07867, 'accuracy': 0.89285, 'precision': 0.6717, 'recall': 0.76672, 'f1': 0.71607, 'auc': 0.93564, 'accuracy-SBM': 0.84328}
2025-07-05 09:06:29,736 - INFO - > Epoch 77: took 73.9s (avg 70.9s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:06:29,736 - INFO - === Epoch 78 ===
2025-07-05 09:07:29,973 - INFO - train: {'epoch': 78, 'time_epoch': 57.61835, 'eta': 1181.81108, 'eta_hours': 0.32828, 'loss': 0.08977639, 'lr': 6.329e-05, 'params': 345143, 'time_iter': 0.18408, 'accuracy': 0.86334, 'precision': 0.5748, 'recall': 0.86763, 'f1': 0.69149, 'auc': 0.94119, 'accuracy-SBM': 0.86503}
2025-07-05 09:07:35,592 - INFO - val: {'epoch': 78, 'time_epoch': 5.10448, 'loss': 0.10204284, 'lr': 0, 'params': 345143, 'time_iter': 0.08102, 'accuracy': 0.89199, 'precision': 0.6696, 'recall': 0.76953, 'f1': 0.7161, 'auc': 0.93547, 'accuracy-SBM': 0.84393}
2025-07-05 09:07:44,002 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:07:44,498 - INFO - test: {'epoch': 78, 'time_epoch': 5.00805, 'loss': 0.10135131, 'lr': 0, 'params': 345143, 'time_iter': 0.07949, 'accuracy': 0.89363, 'precision': 0.67399, 'recall': 0.76772, 'f1': 0.71781, 'auc': 0.93634, 'accuracy-SBM': 0.84414}
2025-07-05 09:07:44,502 - INFO - > Epoch 78: took 74.8s (avg 71.0s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:07:44,502 - INFO - === Epoch 79 ===
2025-07-05 09:08:45,073 - INFO - train: {'epoch': 79, 'time_epoch': 58.04241, 'eta': 1125.97579, 'eta_hours': 0.31277, 'loss': 0.08976215, 'lr': 5.79e-05, 'params': 345143, 'time_iter': 0.18544, 'accuracy': 0.86333, 'precision': 0.57475, 'recall': 0.86783, 'f1': 0.69152, 'auc': 0.94123, 'accuracy-SBM': 0.8651}
2025-07-05 09:08:50,376 - INFO - val: {'epoch': 79, 'time_epoch': 5.01248, 'loss': 0.09367082, 'lr': 0, 'params': 345143, 'time_iter': 0.07956, 'accuracy': 0.82607, 'precision': 0.50485, 'recall': 0.90917, 'f1': 0.6492, 'auc': 0.9404, 'accuracy-SBM': 0.85868}
2025-07-05 09:08:59,299 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:08:59,782 - INFO - test: {'epoch': 79, 'time_epoch': 5.06027, 'loss': 0.09252015, 'lr': 0, 'params': 345143, 'time_iter': 0.08032, 'accuracy': 0.82873, 'precision': 0.50785, 'recall': 0.90877, 'f1': 0.65158, 'auc': 0.94122, 'accuracy-SBM': 0.86019}
2025-07-05 09:08:59,784 - INFO - > Epoch 79: took 75.3s (avg 71.0s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:08:59,785 - INFO - === Epoch 80 ===
2025-07-05 09:10:00,320 - INFO - train: {'epoch': 80, 'time_epoch': 57.61413, 'eta': 1069.98554, 'eta_hours': 0.29722, 'loss': 0.08973515, 'lr': 5.271e-05, 'params': 345143, 'time_iter': 0.18407, 'accuracy': 0.86318, 'precision': 0.57445, 'recall': 0.86758, 'f1': 0.69122, 'auc': 0.94126, 'accuracy-SBM': 0.86491}
2025-07-05 09:10:05,935 - INFO - val: {'epoch': 80, 'time_epoch': 5.11819, 'loss': 0.09352359, 'lr': 0, 'params': 345143, 'time_iter': 0.08124, 'accuracy': 0.88294, 'precision': 0.62924, 'recall': 0.82458, 'f1': 0.71379, 'auc': 0.93993, 'accuracy-SBM': 0.86004}
2025-07-05 09:10:14,801 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:10:15,280 - INFO - test: {'epoch': 80, 'time_epoch': 5.03696, 'loss': 0.09251637, 'lr': 0, 'params': 345143, 'time_iter': 0.07995, 'accuracy': 0.88449, 'precision': 0.6321, 'recall': 0.82427, 'f1': 0.71551, 'auc': 0.94084, 'accuracy-SBM': 0.86082}
2025-07-05 09:10:15,282 - INFO - > Epoch 80: took 75.5s (avg 71.1s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:10:15,282 - INFO - === Epoch 81 ===
2025-07-05 09:11:15,436 - INFO - train: {'epoch': 81, 'time_epoch': 57.26066, 'eta': 1013.87809, 'eta_hours': 0.28163, 'loss': 0.08972218, 'lr': 4.775e-05, 'params': 345143, 'time_iter': 0.18294, 'accuracy': 0.86324, 'precision': 0.57455, 'recall': 0.8678, 'f1': 0.69137, 'auc': 0.94131, 'accuracy-SBM': 0.86503}
2025-07-05 09:11:20,969 - INFO - val: {'epoch': 81, 'time_epoch': 5.08037, 'loss': 0.122967, 'lr': 0, 'params': 345143, 'time_iter': 0.08064, 'accuracy': 0.89953, 'precision': 0.73215, 'recall': 0.68192, 'f1': 0.70614, 'auc': 0.93121, 'accuracy-SBM': 0.81413}
2025-07-05 09:11:30,735 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:11:31,198 - INFO - test: {'epoch': 81, 'time_epoch': 5.03567, 'loss': 0.12280467, 'lr': 0, 'params': 345143, 'time_iter': 0.07993, 'accuracy': 0.90067, 'precision': 0.7366, 'recall': 0.6792, 'f1': 0.70674, 'auc': 0.93208, 'accuracy-SBM': 0.81362}
2025-07-05 09:11:31,200 - INFO - > Epoch 81: took 75.9s (avg 71.1s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:11:31,201 - INFO - === Epoch 82 ===
2025-07-05 09:12:31,416 - INFO - train: {'epoch': 82, 'time_epoch': 57.39434, 'eta': 957.77023, 'eta_hours': 0.26605, 'loss': 0.0897008, 'lr': 4.3e-05, 'params': 345143, 'time_iter': 0.18337, 'accuracy': 0.86297, 'precision': 0.57398, 'recall': 0.86789, 'f1': 0.69098, 'auc': 0.94129, 'accuracy-SBM': 0.86491}
2025-07-05 09:12:36,766 - INFO - val: {'epoch': 82, 'time_epoch': 5.07046, 'loss': 0.10562213, 'lr': 0, 'params': 345143, 'time_iter': 0.08048, 'accuracy': 0.76056, 'precision': 0.42111, 'recall': 0.94109, 'f1': 0.58186, 'auc': 0.93425, 'accuracy-SBM': 0.83141}
2025-07-05 09:12:43,868 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:12:44,361 - INFO - test: {'epoch': 82, 'time_epoch': 4.98589, 'loss': 0.10458413, 'lr': 0, 'params': 345143, 'time_iter': 0.07914, 'accuracy': 0.76304, 'precision': 0.42252, 'recall': 0.9399, 'f1': 0.58298, 'auc': 0.9349, 'accuracy-SBM': 0.83255}
2025-07-05 09:12:44,363 - INFO - > Epoch 82: took 73.2s (avg 71.1s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:12:44,363 - INFO - === Epoch 83 ===
2025-07-05 09:13:44,494 - INFO - train: {'epoch': 83, 'time_epoch': 57.47217, 'eta': 901.64656, 'eta_hours': 0.25046, 'loss': 0.08968404, 'lr': 3.848e-05, 'params': 345143, 'time_iter': 0.18362, 'accuracy': 0.86362, 'precision': 0.57544, 'recall': 0.86725, 'f1': 0.69183, 'auc': 0.94132, 'accuracy-SBM': 0.86505}
2025-07-05 09:13:49,742 - INFO - val: {'epoch': 83, 'time_epoch': 4.95562, 'loss': 0.09432134, 'lr': 0, 'params': 345143, 'time_iter': 0.07866, 'accuracy': 0.81939, 'precision': 0.49452, 'recall': 0.91358, 'f1': 0.64169, 'auc': 0.94013, 'accuracy-SBM': 0.85636}
2025-07-05 09:13:57,274 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:13:57,754 - INFO - test: {'epoch': 83, 'time_epoch': 5.09596, 'loss': 0.09317397, 'lr': 0, 'params': 345143, 'time_iter': 0.08089, 'accuracy': 0.82147, 'precision': 0.49643, 'recall': 0.91365, 'f1': 0.64332, 'auc': 0.94095, 'accuracy-SBM': 0.8577}
2025-07-05 09:13:57,756 - INFO - > Epoch 83: took 73.4s (avg 71.2s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:13:57,756 - INFO - === Epoch 84 ===
2025-07-05 09:14:55,455 - INFO - train: {'epoch': 84, 'time_epoch': 57.2789, 'eta': 845.45706, 'eta_hours': 0.23485, 'loss': 0.08965317, 'lr': 3.419e-05, 'params': 345143, 'time_iter': 0.183, 'accuracy': 0.86322, 'precision': 0.57448, 'recall': 0.86808, 'f1': 0.6914, 'auc': 0.94136, 'accuracy-SBM': 0.86513}
2025-07-05 09:15:00,868 - INFO - val: {'epoch': 84, 'time_epoch': 4.92577, 'loss': 0.09076408, 'lr': 0, 'params': 345143, 'time_iter': 0.07819, 'accuracy': 0.85161, 'precision': 0.55042, 'recall': 0.88302, 'f1': 0.67813, 'auc': 0.94089, 'accuracy-SBM': 0.86394}
2025-07-05 09:15:08,644 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:15:09,112 - INFO - test: {'epoch': 84, 'time_epoch': 5.03779, 'loss': 0.08966336, 'lr': 0, 'params': 345143, 'time_iter': 0.07996, 'accuracy': 0.85431, 'precision': 0.5544, 'recall': 0.88297, 'f1': 0.68113, 'auc': 0.94173, 'accuracy-SBM': 0.86558}
2025-07-05 09:15:09,115 - INFO - > Epoch 84: took 71.4s (avg 71.2s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:15:09,115 - INFO - === Epoch 85 ===
2025-07-05 09:16:08,224 - INFO - train: {'epoch': 85, 'time_epoch': 57.39883, 'eta': 789.26175, 'eta_hours': 0.21924, 'loss': 0.08959595, 'lr': 3.013e-05, 'params': 345143, 'time_iter': 0.18338, 'accuracy': 0.86385, 'precision': 0.57586, 'recall': 0.86793, 'f1': 0.69235, 'auc': 0.94146, 'accuracy-SBM': 0.86545}
2025-07-05 09:16:13,498 - INFO - val: {'epoch': 85, 'time_epoch': 4.9729, 'loss': 0.10482668, 'lr': 0, 'params': 345143, 'time_iter': 0.07893, 'accuracy': 0.76425, 'precision': 0.42516, 'recall': 0.94221, 'f1': 0.58592, 'auc': 0.93638, 'accuracy-SBM': 0.83409}
2025-07-05 09:16:21,106 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:16:21,601 - INFO - test: {'epoch': 85, 'time_epoch': 5.02541, 'loss': 0.10368374, 'lr': 0, 'params': 345143, 'time_iter': 0.07977, 'accuracy': 0.76683, 'precision': 0.42676, 'recall': 0.94169, 'f1': 0.58735, 'auc': 0.93706, 'accuracy-SBM': 0.83555}
2025-07-05 09:16:21,603 - INFO - > Epoch 85: took 72.5s (avg 71.2s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:16:21,603 - INFO - === Epoch 86 ===
2025-07-05 09:17:21,835 - INFO - train: {'epoch': 86, 'time_epoch': 57.37854, 'eta': 733.03574, 'eta_hours': 0.20362, 'loss': 0.08968734, 'lr': 2.632e-05, 'params': 345143, 'time_iter': 0.18332, 'accuracy': 0.86301, 'precision': 0.57409, 'recall': 0.86753, 'f1': 0.69094, 'auc': 0.94131, 'accuracy-SBM': 0.86478}
2025-07-05 09:17:27,373 - INFO - val: {'epoch': 86, 'time_epoch': 5.02865, 'loss': 0.09118629, 'lr': 0, 'params': 345143, 'time_iter': 0.07982, 'accuracy': 0.86276, 'precision': 0.57473, 'recall': 0.8641, 'f1': 0.69031, 'auc': 0.93966, 'accuracy-SBM': 0.86328}
2025-07-05 09:17:34,794 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:17:35,285 - INFO - test: {'epoch': 86, 'time_epoch': 5.07399, 'loss': 0.0901138, 'lr': 0, 'params': 345143, 'time_iter': 0.08054, 'accuracy': 0.8654, 'precision': 0.57909, 'recall': 0.86455, 'f1': 0.6936, 'auc': 0.94052, 'accuracy-SBM': 0.86507}
2025-07-05 09:17:35,287 - INFO - > Epoch 86: took 73.7s (avg 71.2s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:17:35,288 - INFO - === Epoch 87 ===
2025-07-05 09:18:34,150 - INFO - train: {'epoch': 87, 'time_epoch': 57.31568, 'eta': 676.77496, 'eta_hours': 0.18799, 'loss': 0.08965804, 'lr': 2.275e-05, 'params': 345143, 'time_iter': 0.18312, 'accuracy': 0.86326, 'precision': 0.5746, 'recall': 0.86797, 'f1': 0.69145, 'auc': 0.94136, 'accuracy-SBM': 0.86511}
2025-07-05 09:18:39,585 - INFO - val: {'epoch': 87, 'time_epoch': 4.93858, 'loss': 0.09120396, 'lr': 0, 'params': 345143, 'time_iter': 0.07839, 'accuracy': 0.86933, 'precision': 0.59044, 'recall': 0.85479, 'f1': 0.69844, 'auc': 0.94038, 'accuracy-SBM': 0.86363}
2025-07-05 09:18:47,043 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:18:47,514 - INFO - test: {'epoch': 87, 'time_epoch': 5.15104, 'loss': 0.09012199, 'lr': 0, 'params': 345143, 'time_iter': 0.08176, 'accuracy': 0.87195, 'precision': 0.59497, 'recall': 0.85626, 'f1': 0.7021, 'auc': 0.94126, 'accuracy-SBM': 0.86579}
2025-07-05 09:18:47,516 - INFO - > Epoch 87: took 72.2s (avg 71.2s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:18:47,516 - INFO - === Epoch 88 ===
2025-07-05 09:19:47,799 - INFO - train: {'epoch': 88, 'time_epoch': 57.48185, 'eta': 620.51102, 'eta_hours': 0.17236, 'loss': 0.08965293, 'lr': 1.943e-05, 'params': 345143, 'time_iter': 0.18365, 'accuracy': 0.86332, 'precision': 0.57471, 'recall': 0.86817, 'f1': 0.69159, 'auc': 0.94135, 'accuracy-SBM': 0.86523}
2025-07-05 09:19:53,309 - INFO - val: {'epoch': 88, 'time_epoch': 5.01328, 'loss': 0.10646316, 'lr': 0, 'params': 345143, 'time_iter': 0.07958, 'accuracy': 0.89913, 'precision': 0.70353, 'recall': 0.74352, 'f1': 0.72298, 'auc': 0.93699, 'accuracy-SBM': 0.83806}
2025-07-05 09:20:00,673 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:20:01,164 - INFO - test: {'epoch': 88, 'time_epoch': 5.17356, 'loss': 0.1057655, 'lr': 0, 'params': 345143, 'time_iter': 0.08212, 'accuracy': 0.90041, 'precision': 0.70742, 'recall': 0.74154, 'f1': 0.72408, 'auc': 0.93803, 'accuracy-SBM': 0.83797}
2025-07-05 09:20:01,166 - INFO - > Epoch 88: took 73.6s (avg 71.3s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:20:01,166 - INFO - === Epoch 89 ===
2025-07-05 09:21:02,563 - INFO - train: {'epoch': 89, 'time_epoch': 58.01775, 'eta': 564.27956, 'eta_hours': 0.15674, 'loss': 0.08959058, 'lr': 1.636e-05, 'params': 345143, 'time_iter': 0.18536, 'accuracy': 0.86335, 'precision': 0.5748, 'recall': 0.86779, 'f1': 0.69154, 'auc': 0.94142, 'accuracy-SBM': 0.86509}
2025-07-05 09:21:08,026 - INFO - val: {'epoch': 89, 'time_epoch': 4.96926, 'loss': 0.09260515, 'lr': 0, 'params': 345143, 'time_iter': 0.07888, 'accuracy': 0.87888, 'precision': 0.61677, 'recall': 0.83402, 'f1': 0.70913, 'auc': 0.93981, 'accuracy-SBM': 0.86127}
2025-07-05 09:21:15,473 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:21:15,984 - INFO - test: {'epoch': 89, 'time_epoch': 5.12166, 'loss': 0.09159787, 'lr': 0, 'params': 345143, 'time_iter': 0.0813, 'accuracy': 0.88056, 'precision': 0.61975, 'recall': 0.83383, 'f1': 0.71102, 'auc': 0.94069, 'accuracy-SBM': 0.86219}
2025-07-05 09:21:15,986 - INFO - > Epoch 89: took 74.8s (avg 71.3s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:21:15,987 - INFO - === Epoch 90 ===
2025-07-05 09:22:17,325 - INFO - train: {'epoch': 90, 'time_epoch': 58.399, 'eta': 508.04654, 'eta_hours': 0.14112, 'loss': 0.08962146, 'lr': 1.355e-05, 'params': 345143, 'time_iter': 0.18658, 'accuracy': 0.86322, 'precision': 0.57454, 'recall': 0.8676, 'f1': 0.69129, 'auc': 0.94138, 'accuracy-SBM': 0.86494}
2025-07-05 09:22:22,799 - INFO - val: {'epoch': 90, 'time_epoch': 4.97513, 'loss': 0.09453103, 'lr': 0, 'params': 345143, 'time_iter': 0.07897, 'accuracy': 0.8852, 'precision': 0.6375, 'recall': 0.81486, 'f1': 0.71535, 'auc': 0.93946, 'accuracy-SBM': 0.8576}
2025-07-05 09:22:30,347 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:22:30,831 - INFO - test: {'epoch': 90, 'time_epoch': 5.07884, 'loss': 0.0935741, 'lr': 0, 'params': 345143, 'time_iter': 0.08062, 'accuracy': 0.88705, 'precision': 0.64129, 'recall': 0.81484, 'f1': 0.71772, 'auc': 0.94038, 'accuracy-SBM': 0.85867}
2025-07-05 09:22:30,833 - INFO - > Epoch 90: took 74.8s (avg 71.3s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:22:30,833 - INFO - === Epoch 91 ===
2025-07-05 09:23:32,728 - INFO - train: {'epoch': 91, 'time_epoch': 59.17995, 'eta': 451.83434, 'eta_hours': 0.12551, 'loss': 0.0896256, 'lr': 1.099e-05, 'params': 345143, 'time_iter': 0.18907, 'accuracy': 0.86335, 'precision': 0.57475, 'recall': 0.86824, 'f1': 0.69165, 'auc': 0.94142, 'accuracy-SBM': 0.86527}
2025-07-05 09:23:38,238 - INFO - val: {'epoch': 91, 'time_epoch': 5.00969, 'loss': 0.09091771, 'lr': 0, 'params': 345143, 'time_iter': 0.07952, 'accuracy': 0.86984, 'precision': 0.59152, 'recall': 0.85543, 'f1': 0.69941, 'auc': 0.94076, 'accuracy-SBM': 0.86418}
2025-07-05 09:23:45,846 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:23:46,308 - INFO - test: {'epoch': 91, 'time_epoch': 5.19153, 'loss': 0.0898646, 'lr': 0, 'params': 345143, 'time_iter': 0.08241, 'accuracy': 0.87278, 'precision': 0.59682, 'recall': 0.85712, 'f1': 0.70367, 'auc': 0.94161, 'accuracy-SBM': 0.86663}
2025-07-05 09:23:46,324 - INFO - > Epoch 91: took 75.5s (avg 71.4s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:23:46,324 - INFO - === Epoch 92 ===
2025-07-05 09:24:47,070 - INFO - train: {'epoch': 92, 'time_epoch': 58.96356, 'eta': 395.54204, 'eta_hours': 0.10987, 'loss': 0.08962734, 'lr': 8.7e-06, 'params': 345143, 'time_iter': 0.18838, 'accuracy': 0.86325, 'precision': 0.57455, 'recall': 0.86812, 'f1': 0.69146, 'auc': 0.94141, 'accuracy-SBM': 0.86516}
2025-07-05 09:24:52,437 - INFO - val: {'epoch': 92, 'time_epoch': 4.87329, 'loss': 0.09188753, 'lr': 0, 'params': 345143, 'time_iter': 0.07735, 'accuracy': 0.86104, 'precision': 0.57124, 'recall': 0.86208, 'f1': 0.68715, 'auc': 0.93835, 'accuracy-SBM': 0.86145}
2025-07-05 09:25:00,467 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:25:00,958 - INFO - test: {'epoch': 92, 'time_epoch': 5.18257, 'loss': 0.09088308, 'lr': 0, 'params': 345143, 'time_iter': 0.08226, 'accuracy': 0.86305, 'precision': 0.57424, 'recall': 0.86179, 'f1': 0.68922, 'auc': 0.93915, 'accuracy-SBM': 0.86255}
2025-07-05 09:25:00,960 - INFO - > Epoch 92: took 74.6s (avg 71.4s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:25:00,960 - INFO - === Epoch 93 ===
2025-07-05 09:26:00,752 - INFO - train: {'epoch': 93, 'time_epoch': 58.04977, 'eta': 339.13457, 'eta_hours': 0.0942, 'loss': 0.08964117, 'lr': 6.67e-06, 'params': 345143, 'time_iter': 0.18546, 'accuracy': 0.86346, 'precision': 0.57507, 'recall': 0.86755, 'f1': 0.69166, 'auc': 0.94137, 'accuracy-SBM': 0.86507}
2025-07-05 09:26:06,237 - INFO - val: {'epoch': 93, 'time_epoch': 4.98266, 'loss': 0.09179845, 'lr': 0, 'params': 345143, 'time_iter': 0.07909, 'accuracy': 0.87425, 'precision': 0.60358, 'recall': 0.84385, 'f1': 0.70378, 'auc': 0.93992, 'accuracy-SBM': 0.86232}
2025-07-05 09:26:13,926 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:26:14,408 - INFO - test: {'epoch': 93, 'time_epoch': 5.19412, 'loss': 0.0907563, 'lr': 0, 'params': 345143, 'time_iter': 0.08245, 'accuracy': 0.87652, 'precision': 0.6075, 'recall': 0.84557, 'f1': 0.70703, 'auc': 0.9408, 'accuracy-SBM': 0.86435}
2025-07-05 09:26:14,411 - INFO - > Epoch 93: took 73.5s (avg 71.4s) | Best so far: epoch 75	train_loss: 0.0899 train_accuracy-SBM: 0.8648	val_loss: 0.0907 val_accuracy-SBM: 0.8648	test_loss: 0.0896 test_accuracy-SBM: 0.8670
2025-07-05 09:26:14,411 - INFO - === Epoch 94 ===
2025-07-05 09:27:14,944 - INFO - train: {'epoch': 94, 'time_epoch': 57.62746, 'eta': 282.6703, 'eta_hours': 0.07852, 'loss': 0.08965437, 'lr': 4.91e-06, 'params': 345143, 'time_iter': 0.18411, 'accuracy': 0.86328, 'precision': 0.57469, 'recall': 0.86746, 'f1': 0.69136, 'auc': 0.94135, 'accuracy-SBM': 0.86492}
2025-07-05 09:27:20,359 - INFO - val: {'epoch': 94, 'time_epoch': 4.92429, 'loss': 0.09050983, 'lr': 0, 'params': 345143, 'time_iter': 0.07816, 'accuracy': 0.86333, 'precision': 0.57559, 'recall': 0.86798, 'f1': 0.69217, 'auc': 0.94105, 'accuracy-SBM': 0.86516}
2025-07-05 09:27:28,020 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:27:28,498 - INFO - test: {'epoch': 94, 'time_epoch': 5.03769, 'loss': 0.08941999, 'lr': 0, 'params': 345143, 'time_iter': 0.07996, 'accuracy': 0.86616, 'precision': 0.58033, 'recall': 0.86868, 'f1': 0.69582, 'auc': 0.94192, 'accuracy-SBM': 0.86715}
2025-07-05 09:27:28,500 - INFO - > Epoch 94: took 74.1s (avg 71.5s) | Best so far: epoch 94	train_loss: 0.0897 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8652	test_loss: 0.0894 test_accuracy-SBM: 0.8671
2025-07-05 09:27:28,500 - INFO - === Epoch 95 ===
2025-07-05 09:28:27,559 - INFO - train: {'epoch': 95, 'time_epoch': 57.25728, 'eta': 226.16638, 'eta_hours': 0.06282, 'loss': 0.08963171, 'lr': 3.41e-06, 'params': 345143, 'time_iter': 0.18293, 'accuracy': 0.8631, 'precision': 0.57422, 'recall': 0.86822, 'f1': 0.69126, 'auc': 0.94139, 'accuracy-SBM': 0.86511}
2025-07-05 09:28:33,000 - INFO - val: {'epoch': 95, 'time_epoch': 4.94836, 'loss': 0.09067362, 'lr': 0, 'params': 345143, 'time_iter': 0.07855, 'accuracy': 0.86236, 'precision': 0.57346, 'recall': 0.86839, 'f1': 0.69076, 'auc': 0.94068, 'accuracy-SBM': 0.86473}
2025-07-05 09:28:40,725 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:28:41,206 - INFO - test: {'epoch': 95, 'time_epoch': 4.98424, 'loss': 0.08957997, 'lr': 0, 'params': 345143, 'time_iter': 0.07911, 'accuracy': 0.86519, 'precision': 0.57816, 'recall': 0.86927, 'f1': 0.69444, 'auc': 0.94156, 'accuracy-SBM': 0.8668}
2025-07-05 09:28:41,208 - INFO - > Epoch 95: took 72.7s (avg 71.5s) | Best so far: epoch 94	train_loss: 0.0897 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8652	test_loss: 0.0894 test_accuracy-SBM: 0.8671
2025-07-05 09:28:41,208 - INFO - === Epoch 96 ===
2025-07-05 09:29:41,590 - INFO - train: {'epoch': 96, 'time_epoch': 57.42468, 'eta': 169.65209, 'eta_hours': 0.04713, 'loss': 0.08951707, 'lr': 2.18e-06, 'params': 345143, 'time_iter': 0.18347, 'accuracy': 0.86334, 'precision': 0.57473, 'recall': 0.86828, 'f1': 0.69165, 'auc': 0.94158, 'accuracy-SBM': 0.86528}
2025-07-05 09:29:47,006 - INFO - val: {'epoch': 96, 'time_epoch': 4.92935, 'loss': 0.09241269, 'lr': 0, 'params': 345143, 'time_iter': 0.07824, 'accuracy': 0.87283, 'precision': 0.60023, 'recall': 0.84319, 'f1': 0.70126, 'auc': 0.93876, 'accuracy-SBM': 0.8612}
2025-07-05 09:29:54,430 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:29:54,899 - INFO - test: {'epoch': 96, 'time_epoch': 5.011, 'loss': 0.09144344, 'lr': 0, 'params': 345143, 'time_iter': 0.07954, 'accuracy': 0.87512, 'precision': 0.60442, 'recall': 0.84316, 'f1': 0.7041, 'auc': 0.93957, 'accuracy-SBM': 0.86256}
2025-07-05 09:29:54,902 - INFO - > Epoch 96: took 73.7s (avg 71.5s) | Best so far: epoch 94	train_loss: 0.0897 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8652	test_loss: 0.0894 test_accuracy-SBM: 0.8671
2025-07-05 09:29:54,902 - INFO - === Epoch 97 ===
2025-07-05 09:30:55,602 - INFO - train: {'epoch': 97, 'time_epoch': 57.66759, 'eta': 113.12419, 'eta_hours': 0.03142, 'loss': 0.08953921, 'lr': 1.23e-06, 'params': 345143, 'time_iter': 0.18424, 'accuracy': 0.86345, 'precision': 0.57499, 'recall': 0.868, 'f1': 0.69175, 'auc': 0.9415, 'accuracy-SBM': 0.86524}
2025-07-05 09:31:01,038 - INFO - val: {'epoch': 97, 'time_epoch': 4.95708, 'loss': 0.09261183, 'lr': 0, 'params': 345143, 'time_iter': 0.07868, 'accuracy': 0.87702, 'precision': 0.61169, 'recall': 0.8359, 'f1': 0.70643, 'auc': 0.93926, 'accuracy-SBM': 0.86088}
2025-07-05 09:31:08,352 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:31:08,830 - INFO - test: {'epoch': 97, 'time_epoch': 4.96055, 'loss': 0.09164601, 'lr': 0, 'params': 345143, 'time_iter': 0.07874, 'accuracy': 0.87872, 'precision': 0.61469, 'recall': 0.8354, 'f1': 0.70825, 'auc': 0.9401, 'accuracy-SBM': 0.86169}
2025-07-05 09:31:08,832 - INFO - > Epoch 97: took 73.9s (avg 71.5s) | Best so far: epoch 94	train_loss: 0.0897 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8652	test_loss: 0.0894 test_accuracy-SBM: 0.8671
2025-07-05 09:31:08,832 - INFO - === Epoch 98 ===
2025-07-05 09:32:09,137 - INFO - train: {'epoch': 98, 'time_epoch': 57.37846, 'eta': 56.57034, 'eta_hours': 0.01571, 'loss': 0.08964138, 'lr': 5.5e-07, 'params': 345143, 'time_iter': 0.18332, 'accuracy': 0.86328, 'precision': 0.57465, 'recall': 0.86775, 'f1': 0.69142, 'auc': 0.94141, 'accuracy-SBM': 0.86503}
2025-07-05 09:32:14,550 - INFO - val: {'epoch': 98, 'time_epoch': 4.9147, 'loss': 0.09078889, 'lr': 0, 'params': 345143, 'time_iter': 0.07801, 'accuracy': 0.867, 'precision': 0.58454, 'recall': 0.85979, 'f1': 0.69594, 'auc': 0.94065, 'accuracy-SBM': 0.86417}
2025-07-05 09:32:21,805 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:32:22,298 - INFO - test: {'epoch': 98, 'time_epoch': 5.00039, 'loss': 0.08971773, 'lr': 0, 'params': 345143, 'time_iter': 0.07937, 'accuracy': 0.86983, 'precision': 0.58944, 'recall': 0.86117, 'f1': 0.69985, 'auc': 0.94151, 'accuracy-SBM': 0.86643}
2025-07-05 09:32:22,300 - INFO - > Epoch 98: took 73.5s (avg 71.5s) | Best so far: epoch 94	train_loss: 0.0897 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8652	test_loss: 0.0894 test_accuracy-SBM: 0.8671
2025-07-05 09:32:22,300 - INFO - === Epoch 99 ===
2025-07-05 09:33:20,144 - INFO - train: {'epoch': 99, 'time_epoch': 57.42316, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.08958996, 'lr': 1.4e-07, 'params': 345143, 'time_iter': 0.18346, 'accuracy': 0.86354, 'precision': 0.57522, 'recall': 0.86772, 'f1': 0.69182, 'auc': 0.94145, 'accuracy-SBM': 0.86518}
2025-07-05 09:33:25,634 - INFO - val: {'epoch': 99, 'time_epoch': 5.00471, 'loss': 0.09082035, 'lr': 0, 'params': 345143, 'time_iter': 0.07944, 'accuracy': 0.869, 'precision': 0.58933, 'recall': 0.85762, 'f1': 0.69861, 'auc': 0.94092, 'accuracy-SBM': 0.86454}
2025-07-05 09:33:33,298 - INFO - Saved test results for 2000 graphs to results/pattern/pattern-SPARSE-41/test_results
2025-07-05 09:33:33,784 - INFO - test: {'epoch': 99, 'time_epoch': 5.04842, 'loss': 0.08972837, 'lr': 0, 'params': 345143, 'time_iter': 0.08013, 'accuracy': 0.8716, 'precision': 0.59378, 'recall': 0.85917, 'f1': 0.70224, 'auc': 0.94182, 'accuracy-SBM': 0.86672}
2025-07-05 09:33:33,896 - INFO - > Epoch 99: took 71.5s (avg 71.5s) | Best so far: epoch 94	train_loss: 0.0897 train_accuracy-SBM: 0.8649	val_loss: 0.0905 val_accuracy-SBM: 0.8652	test_loss: 0.0894 test_accuracy-SBM: 0.8671
2025-07-05 09:33:33,896 - INFO - ================================================================================
2025-07-05 09:33:33,896 - INFO - NAS TRAINING COMPLETED SUCCESSFULLY
2025-07-05 09:33:33,896 - INFO - ================================================================================
2025-07-05 09:33:33,896 - INFO - Avg time per epoch: 71.55s
2025-07-05 09:33:33,896 - INFO - Total train loop time: 1.99h
2025-07-05 09:33:33,897 - INFO - Routing mode: nas
2025-07-05 09:33:33,897 - INFO - Final optimal weights: {'layer_0': 2, 'layer_1': 2, 'layer_2': 1, 'layer_3': 1, 'layer_4': 1, 'layer_5': 1}
2025-07-05 09:33:33,897 - INFO - Results include routing uncertainty (test only, NO variance)
2025-07-05 09:33:33,898 - INFO - Task done, results saved in results/pattern/pattern-SPARSE-41
2025-07-05 09:33:33,900 - INFO - Total time: 8869.72s (2.46h)
2025-07-05 09:33:33,930 - INFO - Results aggregated across runs saved in results/pattern/pattern-SPARSE-41/agg
2025-07-05 09:33:33,931 - INFO - === OPTIMIZED TRAINING COMPLETED SUCCESSFULLY! ===
2025-07-05 09:33:33,931 - INFO - Results saved in: results/pattern/pattern-SPARSE-41
2025-07-05 09:33:33,931 - INFO - Test results JSON files saved in: results/pattern/pattern-SPARSE-41/test_results/
Completed seed 41. Results saved in results/pattern/pattern-SPARSE-41
----------------------------------------
Submitting next job for seed 47
Submitted batch job 5334983
/var/spool/slurmd/job5334700/slurm_script: line 72: syntax error near unexpected token `"/data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/PATTERN"'
/var/spool/slurmd/job5334700/slurm_script: line 72: `os.chdir("/data/coml-deepcmb/lady6973/ABLATION_FINAL/RACE_TO_SUP/PATTERN")'
